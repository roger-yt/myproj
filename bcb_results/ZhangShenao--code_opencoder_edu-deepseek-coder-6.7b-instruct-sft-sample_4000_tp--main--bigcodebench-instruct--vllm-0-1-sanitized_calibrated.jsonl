{"task_id": "BigCodeBench/0", "solution": "import itertools\nfrom random import shuffle\ndef task_func(numbers=list(range(1, 11))):\n    total_sum = 0\n    for p in itertools.permutations(numbers):\n        shuffle(p)\n        sum_diff = 0\n        for i in range(len(p) - 1):\n            sum_diff += abs(p[i] - p[i + 1])\n        total_sum += sum_diff\n    return total_sum / len(list(itertools.permutations(numbers)))", "raw_solution": "import itertools\nfrom random import shuffle\n\ndef task_func(numbers=list(range(1, 11))):\n    total_sum = 0\n    for p in itertools.permutations(numbers):\n        shuffle(p)\n        sum_diff = 0\n        for i in range(len(p) - 1):\n            sum_diff += abs(p[i] - p[i + 1])\n        total_sum += sum_diff\n    return total_sum / len(list(itertools.permutations(numbers)))\n```"}
{"task_id": "BigCodeBench/1", "solution": "import collections\nimport random\nimport string\ndef task_func(length=100):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    random_string = ''.join(random.choice(string.ascii_letters) for _ in range(length))\n    return dict(collections.Counter(random_string))", "raw_solution": "import collections\nimport random\nimport string\n\ndef task_func(length=100):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    random_string = ''.join(random.choice(string.ascii_letters) for _ in range(length))\n    return dict(collections.Counter(random_string))\n```"}
{"task_id": "BigCodeBench/2", "solution": "import random\nimport statistics\ndef task_func(LETTERS):\n    # Create a dictionary with random letters as keys and lists of random integers as values\n    dict_letters = {chr(65 + i): [random.randint(1, 100) for _ in range(10)] for i in range(LETTERS)}\n\n    # Calculate the mean of the values in the dictionary and sort it in descending order\n    dict_letters = {k: v for k, v in sorted(dict_letters.items(), key=lambda item: statistics.mean(item[1]), reverse=True)}\n\n    return dict_letters", "raw_solution": "import random\nimport statistics\n\ndef task_func(LETTERS):\n    # Create a dictionary with random letters as keys and lists of random integers as values\n    dict_letters = {chr(65 + i): [random.randint(1, 100) for _ in range(10)] for i in range(LETTERS)}\n\n    # Calculate the mean of the values in the dictionary and sort it in descending order\n    dict_letters = {k: v for k, v in sorted(dict_letters.items(), key=lambda item: statistics.mean(item[1]), reverse=True)}\n\n    return dict_letters\n```"}
{"task_id": "BigCodeBench/3", "solution": "import random\nimport numpy as np\ndef task_func(LETTERS):\n    result = {}\n    for letter in LETTERS:\n        random_list = [random.randint(0, 100) for _ in range(random.randint(1, 10))]\n        result[letter] = np.mean(random_list)\n    return result", "raw_solution": "import random\nimport numpy as np\n\ndef task_func(LETTERS):\n    result = {}\n    for letter in LETTERS:\n        random_list = [random.randint(0, 100) for _ in range(random.randint(1, 10))]\n        result[letter] = np.mean(random_list)\n    return result\n```"}
{"task_id": "BigCodeBench/4", "solution": "from collections import Counter\nimport itertools\ndef task_func(d):\n    flat_list = list(itertools.chain(*d.values()))\n    count_dict = dict(Counter(flat_list))\n    return count_dict", "raw_solution": "from collections import Counter\nimport itertools\n\ndef task_func(d):\n    flat_list = list(itertools.chain(*d.values()))\n    count_dict = dict(Counter(flat_list))\n    return count_dict\n```"}
{"task_id": "BigCodeBench/5", "solution": "import random\nimport math\ndef task_func(LETTERS=[chr(i) for i in range(97, 123)]):\n    random.seed(1)\n    result = {}\n    for letter in LETTERS:\n        list_length = random.randint(1, 10)\n        random_list = [random.randint(0, 100) for _ in range(list_length)]\n        mean = sum(random_list) / list_length\n        variance = sum((x - mean) ** 2 for x in random_list) / list_length\n        std_dev = math.sqrt(variance)\n        result[letter] = std_dev\n    return result", "raw_solution": "import random\nimport math\n\ndef task_func(LETTERS=[chr(i) for i in range(97, 123)]):\n    random.seed(1)\n    result = {}\n    for letter in LETTERS:\n        list_length = random.randint(1, 10)\n        random_list = [random.randint(0, 100) for _ in range(list_length)]\n        mean = sum(random_list) / list_length\n        variance = sum((x - mean) ** 2 for x in random_list) / list_length\n        std_dev = math.sqrt(variance)\n        result[letter] = std_dev\n    return result\n```"}
{"task_id": "BigCodeBench/6", "solution": "import os\nimport re\ndef task_func(pattern, log_dir='/var/log/'):\n    regex = re.compile(pattern)\n    files = [f for f in os.listdir(log_dir) if regex.match(f)]\n    if not files:\n        return None\n    files.sort(key=lambda x: os.path.getmtime(os.path.join(log_dir, x)))\n    return os.path.join(log_dir, files[-1])", "raw_solution": "import os\nimport re\n\ndef task_func(pattern, log_dir='/var/log/'):\n    regex = re.compile(pattern)\n    files = [f for f in os.listdir(log_dir) if regex.match(f)]\n    if not files:\n        return None\n    files.sort(key=lambda x: os.path.getmtime(os.path.join(log_dir, x)))\n    return os.path.join(log_dir, files[-1])\n```"}
{"task_id": "BigCodeBench/7", "solution": "import csv\nimport collections\nimport operator\ndef task_func(csv_file_path):\n    with open(csv_file_path, 'r') as file:\n        reader = csv.DictReader(file)\n        sales = collections.defaultdict(int)\n        for row in reader:\n            product = row['product']\n            quantity = int(row['quantity'])\n            sales[product] += quantity\n    return max(sales.items(), key=operator.itemgetter(1))[0]", "raw_solution": "import csv\nimport collections\nimport operator\n\ndef task_func(csv_file_path):\n    with open(csv_file_path, 'r') as file:\n        reader = csv.DictReader(file)\n        sales = collections.defaultdict(int)\n        for row in reader:\n            product = row['product']\n            quantity = int(row['quantity'])\n            sales[product] += quantity\n    return max(sales.items(), key=operator.itemgetter(1))[0]\n```"}
{"task_id": "BigCodeBench/8", "solution": "from collections import Counter\nimport itertools\nfrom random import randint\ndef task_func(T1, RANGE=100):\n    T1 = list(map(int, T1))\n    total_sum = sum(T1)\n    random_list = [randint(0, RANGE) for _ in range(total_sum)]\n    counter = Counter(random_list)\n    return counter", "raw_solution": "from collections import Counter\nimport itertools\nfrom random import randint\n\ndef task_func(T1, RANGE=100):\n    T1 = list(map(int, T1))\n    total_sum = sum(T1)\n    random_list = [randint(0, RANGE) for _ in range(total_sum)]\n    counter = Counter(random_list)\n    return counter\n```"}
{"task_id": "BigCodeBench/9", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(list_of_pairs):\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    ax = df.plot(kind='bar', x='Category', y='Value', legend=False)\n    ax.set_title('Category vs Value')\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(list_of_pairs):\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    ax = df.plot(kind='bar', x='Category', y='Value', legend=False)\n    ax.set_title('Category vs Value')\n    return df, ax\n```"}
{"task_id": "BigCodeBench/10", "solution": "import numpy as np\nimport itertools\nimport random\nimport statistics\ndef task_func(T1, RANGE=100):\n    if not T1:\n        raise statistics.StatisticsError(\"T1 is empty\")\n    T1 = [int(i) for i in T1]\n    total = sum(T1)\n    random_list = [random.randint(0, RANGE) for _ in range(total)]\n    mean = statistics.mean(random_list)\n    median = statistics.median(random_list)\n    mode = statistics.mode(random_list)\n    return (mean, median, mode)", "raw_solution": "import numpy as np\nimport itertools\nimport random\nimport statistics\n\ndef task_func(T1, RANGE=100):\n    if not T1:\n        raise statistics.StatisticsError(\"T1 is empty\")\n    T1 = [int(i) for i in T1]\n    total = sum(T1)\n    random_list = [random.randint(0, RANGE) for _ in range(total)]\n    mean = statistics.mean(random_list)\n    median = statistics.median(random_list)\n    mode = statistics.mode(random_list)\n    return (mean, median, mode)\n```"}
{"task_id": "BigCodeBench/11", "solution": "import numpy as np\nimport itertools\nimport random\ndef task_func(T1, max_value=100):\n    # Convert elements in T1 to integers\n    T1 = [int(i) for i in itertools.chain.from_iterable(T1)]\n    # Create a list of random integers with size equal to the sum of T1\n    T1_sum = sum(T1)\n    T1_list = [random.randint(0, max_value) for _ in range(T1_sum)]\n    # Calculate the 25th, 50th, and 75th percentiles of the list\n    p25 = np.percentile(T1_list, 25)\n    p50 = np.percentile(T1_list, 50)\n    p75 = np.percentile(T1_list, 75)\n    return (p25, p50, p75)", "raw_solution": "import numpy as np\nimport itertools\nimport random\n\ndef task_func(T1, max_value=100):\n    # Convert elements in T1 to integers\n    T1 = [int(i) for i in itertools.chain.from_iterable(T1)]\n    # Create a list of random integers with size equal to the sum of T1\n    T1_sum = sum(T1)\n    T1_list = [random.randint(0, max_value) for _ in range(T1_sum)]\n    # Calculate the 25th, 50th, and 75th percentiles of the list\n    p25 = np.percentile(T1_list, 25)\n    p50 = np.percentile(T1_list, 50)\n    p75 = np.percentile(T1_list, 75)\n    return (p25, p50, p75)\n```"}
{"task_id": "BigCodeBench/12", "solution": "import subprocess\nimport os\nimport json\nfrom datetime import datetime\ndef task_func(script_name='backup.sh', log_file='/home/user/backup_log.json'):\n    if not os.path.exists(script_name):\n        raise FileNotFoundError(f\"Script file {script_name} does not exist.\")\n\n    start_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    try:\n        subprocess.run([\"bash\", script_name], check=True)\n        exit_status = 0\n    except subprocess.CalledProcessError as e:\n        exit_status = e.returncode\n        raise RuntimeError(f\"Error executing script {script_name}: {e}\")\n    end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n    with open(log_file, 'w') as file:\n        json.dump({\n            'start_time': start_time,\n            'end_time': end_time,\n            'exit_status': exit_status\n        }, file)\n\n    return {\n        'start_time': start_time,\n        'end_time': end_time,\n        'exit_status': exit_status\n    }", "raw_solution": "import subprocess\nimport os\nimport json\nfrom datetime import datetime\n\ndef task_func(script_name='backup.sh', log_file='/home/user/backup_log.json'):\n    if not os.path.exists(script_name):\n        raise FileNotFoundError(f\"Script file {script_name} does not exist.\")\n\n    start_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    try:\n        subprocess.run([\"bash\", script_name], check=True)\n        exit_status = 0\n    except subprocess.CalledProcessError as e:\n        exit_status = e.returncode\n        raise RuntimeError(f\"Error executing script {script_name}: {e}\")\n    end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n    with open(log_file, 'w') as file:\n        json.dump({\n            'start_time': start_time,\n            'end_time': end_time,\n            'exit_status': exit_status\n        }, file)\n\n    return {\n        'start_time': start_time,\n        'end_time': end_time,\n        'exit_status': exit_status\n    }\n```"}
{"task_id": "BigCodeBench/13", "solution": "import subprocess\nimport ftplib\nimport os\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        ftp = ftplib.FTP(ftp_server)\n        ftp.login(ftp_user, ftp_password)\n    except Exception as e:\n        raise Exception(f\"Failed to connect to FTP server {ftp_server}: {str(e)}\")\n\n    try:\n        ftp.cwd(ftp_dir)\n    except Exception as e:\n        raise Exception(f\"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n\n    filenames = []\n    try:\n        ftp.retrlines('LIST', lambda x: filenames.append(x.split()[-1]))\n    except Exception as e:\n        raise Exception(f\"Failed to list files in directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n\n    for filename in filenames:\n        try:\n            with open(filename, 'wb') as file:\n                ftp.retrbinary('RETR ' + filename, file.write)\n        except Exception as e:\n            print(f\"Failed to download file {filename} from server {ftp_server}: {str(e)}\")\n\n    ftp.quit()\n    return filenames", "raw_solution": "import subprocess\nimport ftplib\nimport os\n\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        ftp = ftplib.FTP(ftp_server)\n        ftp.login(ftp_user, ftp_password)\n    except Exception as e:\n        raise Exception(f\"Failed to connect to FTP server {ftp_server}: {str(e)}\")\n\n    try:\n        ftp.cwd(ftp_dir)\n    except Exception as e:\n        raise Exception(f\"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n\n    filenames = []\n    try:\n        ftp.retrlines('LIST', lambda x: filenames.append(x.split()[-1]))\n    except Exception as e:\n        raise Exception(f\"Failed to list files in directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n\n    for filename in filenames:\n        try:\n            with open(filename, 'wb') as file:\n                ftp.retrbinary('RETR ' + filename, file.write)\n        except Exception as e:\n            print(f\"Failed to download file {filename} from server {ftp_server}: {str(e)}\")\n\n    ftp.quit()\n    return filenames\n```"}
{"task_id": "BigCodeBench/14", "solution": "import configparser\nimport os\nimport shutil\ndef task_func(config_file_path, archive_dir='/home/user/archive'):\n    if not os.path.exists(config_file_path):\n        raise FileNotFoundError(\"Config file does not exist\")\n    if not os.path.exists(archive_dir):\n        raise FileNotFoundError(\"Archive directory does not exist\")\n\n    config = configparser.ConfigParser()\n    config.read(config_file_path)\n\n    if 'Project' not in config:\n        raise Exception(\"Project section not found in config file\")\n\n    project_dir = config['Project'].get('directory')\n    if not os.path.exists(project_dir):\n        raise FileNotFoundError(\"Project directory does not exist\")\n\n    archive_file_path = os.path.join(archive_dir, os.path.basename(project_dir) + '.zip')\n\n    try:\n        shutil.make_archive(archive_file_path, 'zip', project_dir)\n    except Exception as e:\n        raise Exception(\"Failed to create ZIP archive\") from e\n\n    return True", "raw_solution": "import configparser\nimport os\nimport shutil\n\ndef task_func(config_file_path, archive_dir='/home/user/archive'):\n    if not os.path.exists(config_file_path):\n        raise FileNotFoundError(\"Config file does not exist\")\n    if not os.path.exists(archive_dir):\n        raise FileNotFoundError(\"Archive directory does not exist\")\n\n    config = configparser.ConfigParser()\n    config.read(config_file_path)\n\n    if 'Project' not in config:\n        raise Exception(\"Project section not found in config file\")\n\n    project_dir = config['Project'].get('directory')\n    if not os.path.exists(project_dir):\n        raise FileNotFoundError(\"Project directory does not exist\")\n\n    archive_file_path = os.path.join(archive_dir, os.path.basename(project_dir) + '.zip')\n\n    try:\n        shutil.make_archive(archive_file_path, 'zip', project_dir)\n    except Exception as e:\n        raise Exception(\"Failed to create ZIP archive\") from e\n\n    return True\n```"}
{"task_id": "BigCodeBench/15", "solution": "import subprocess\nimport csv\nimport os\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(f\"File {commands_file_path} does not exist.\")\n\n    with open(commands_file_path, 'r') as file:\n        reader = csv.reader(file)\n        commands = list(reader)\n\n    output_files = []\n    for i, command in enumerate(commands):\n        output_file_path = os.path.join(output_dir_path, f'command_{i}_output.txt')\n        output_files.append(output_file_path)\n\n        try:\n            result = subprocess.run(command, capture_output=True, text=True, check=True)\n            with open(output_file_path, 'w') as file:\n                file.write(result.stdout)\n        except subprocess.CalledProcessError as e:\n            with open(output_file_path, 'w') as file:\n                file.write(f\"Error: {e.output}\")\n                file.write(f\"Exit code: {e.returncode}\")\n\n    return output_files", "raw_solution": "import subprocess\nimport csv\nimport os\n\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(f\"File {commands_file_path} does not exist.\")\n\n    with open(commands_file_path, 'r') as file:\n        reader = csv.reader(file)\n        commands = list(reader)\n\n    output_files = []\n    for i, command in enumerate(commands):\n        output_file_path = os.path.join(output_dir_path, f'command_{i}_output.txt')\n        output_files.append(output_file_path)\n\n        try:\n            result = subprocess.run(command, capture_output=True, text=True, check=True)\n            with open(output_file_path, 'w') as file:\n                file.write(result.stdout)\n        except subprocess.CalledProcessError as e:\n            with open(output_file_path, 'w') as file:\n                file.write(f\"Error: {e.output}\")\n                file.write(f\"Exit code: {e.returncode}\")\n\n    return output_files\n```"}
{"task_id": "BigCodeBench/16", "solution": "import os\nimport glob\nimport subprocess\ndef task_func(directory, backup_dir='/path/to/backup'):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    log_files = glob.glob(os.path.join(directory, '*.log'))\n    if not log_files:\n        return 'No logs found to backup'\n    backup_file = os.path.join(backup_dir, 'logs_backup.tar.gz')\n    with open(backup_file, 'wb') as outfile:\n        subprocess.run(['tar', '-czf', '-', '-C', directory, '--remove-files'] + log_files, stdout=outfile)\n    return backup_file", "raw_solution": "import os\nimport glob\nimport subprocess\n\ndef task_func(directory, backup_dir='/path/to/backup'):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    log_files = glob.glob(os.path.join(directory, '*.log'))\n    if not log_files:\n        return 'No logs found to backup'\n    backup_file = os.path.join(backup_dir, 'logs_backup.tar.gz')\n    with open(backup_file, 'wb') as outfile:\n        subprocess.run(['tar', '-czf', '-', '-C', directory, '--remove-files'] + log_files, stdout=outfile)\n    return backup_file\n```"}
{"task_id": "BigCodeBench/17", "solution": "import subprocess\nimport psutil\nimport time\ndef task_func(process_name: str) -> str:\n    if process_name not in (p.name() for p in psutil.process_iter(['name'])):\n        subprocess.Popen(process_name, shell=True)\n        return f\"Process not found. Starting {process_name}.\"\n    else:\n        for proc in psutil.process_iter(['pid', 'name']):\n            if proc.info['name'] == process_name:\n                proc.terminate()\n                time.sleep(1)\n                subprocess.Popen(process_name, shell=True)\n                return f\"Process found. Restarting {process_name}.\"", "raw_solution": "import subprocess\nimport psutil\nimport time\n\ndef task_func(process_name: str) -> str:\n    if process_name not in (p.name() for p in psutil.process_iter(['name'])):\n        subprocess.Popen(process_name, shell=True)\n        return f\"Process not found. Starting {process_name}.\"\n    else:\n        for proc in psutil.process_iter(['pid', 'name']):\n            if proc.info['name'] == process_name:\n                proc.terminate()\n                time.sleep(1)\n                subprocess.Popen(process_name, shell=True)\n                return f\"Process found. Restarting {process_name}.\"\n```"}
{"task_id": "BigCodeBench/18", "solution": "import subprocess\nimport csv\nimport glob\nimport random\nimport os\ndef task_func(file):\n    try:\n        if not os.path.exists(file):\n            return []\n        if not file.endswith('.csv'):\n            return []\n        with open(file, 'r') as f:\n            reader = csv.reader(f)\n            data = list(reader)\n        if len(data) == 0:\n            return []\n        random.shuffle(data)\n        subprocess.run(['split', '-l', '1000', file, 'split_'])\n        files = glob.glob('split_*')\n        for f in files:\n            with open(f, 'w') as f:\n                writer = csv.writer(f)\n                writer.writerows(data)\n        return files\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return []", "raw_solution": "import subprocess\nimport csv\nimport glob\nimport random\nimport os\n\ndef task_func(file):\n    try:\n        if not os.path.exists(file):\n            return []\n        if not file.endswith('.csv'):\n            return []\n        with open(file, 'r') as f:\n            reader = csv.reader(f)\n            data = list(reader)\n        if len(data) == 0:\n            return []\n        random.shuffle(data)\n        subprocess.run(['split', '-l', '1000', file, 'split_'])\n        files = glob.glob('split_*')\n        for f in files:\n            with open(f, 'w') as f:\n                writer = csv.writer(f)\n                writer.writerows(data)\n        return files\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return []\n```"}
{"task_id": "BigCodeBench/19", "solution": "import os\nimport glob\nimport zipfile\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n\n    files = glob.glob(os.path.join(directory, \"*\"))\n    files = [file for file in files if os.path.isfile(file)]\n\n    if not files:\n        return None\n\n    zip_path = os.path.join(directory, \"files.zip\")\n    with zipfile.ZipFile(zip_path, \"w\") as zipf:\n        for file in files:\n            zipf.write(file, arcname=os.path.basename(file))\n\n    return zip_path", "raw_solution": "import os\nimport glob\nimport zipfile\n\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n\n    files = glob.glob(os.path.join(directory, \"*\"))\n    files = [file for file in files if os.path.isfile(file)]\n\n    if not files:\n        return None\n\n    zip_path = os.path.join(directory, \"files.zip\")\n    with zipfile.ZipFile(zip_path, \"w\") as zipf:\n        for file in files:\n            zipf.write(file, arcname=os.path.basename(file))\n\n    return zip_path"}
{"task_id": "BigCodeBench/20", "solution": "import ast\nimport pandas as pd\nimport seaborn as sns\ndef task_func(csv_file):\n    df = pd.read_csv(csv_file)\n    df['dict_column'] = df['dict_column'].apply(ast.literal_eval)\n    df = pd.concat([df.drop(['dict_column'], axis=1), df['dict_column'].apply(pd.Series)], axis=1)\n    ax = sns.pairplot(df)\n    return df, ax", "raw_solution": "import ast\nimport pandas as pd\nimport seaborn as sns\n\ndef task_func(csv_file):\n    df = pd.read_csv(csv_file)\n    df['dict_column'] = df['dict_column'].apply(ast.literal_eval)\n    df = pd.concat([df.drop(['dict_column'], axis=1), df['dict_column'].apply(pd.Series)], axis=1)\n    ax = sns.pairplot(df)\n    return df, ax\n```"}
{"task_id": "BigCodeBench/21", "solution": "import psutil\nimport platform\ndef task_func():\n    # Get system details\n    os_name = platform.system()\n    architecture = platform.architecture()[0]\n\n    # Get memory details\n    total_memory = psutil.virtual_memory().total / (1024.0 ** 3)\n    used_memory = psutil.virtual_memory().used / (1024.0 ** 3)\n    memory_usage = (used_memory / total_memory) * 100\n\n    # Return system details in dictionary format\n    return {\n        'OS': os_name,\n        'Architecture': architecture,\n        'Memory Usage': f'{memory_usage:.2f}%'\n    }", "raw_solution": "import psutil\nimport platform\n\ndef task_func():\n    # Get system details\n    os_name = platform.system()\n    architecture = platform.architecture()[0]\n\n    # Get memory details\n    total_memory = psutil.virtual_memory().total / (1024.0 ** 3)\n    used_memory = psutil.virtual_memory().used / (1024.0 ** 3)\n    memory_usage = (used_memory / total_memory) * 100\n\n    # Return system details in dictionary format\n    return {\n        'OS': os_name,\n        'Architecture': architecture,\n        'Memory Usage': f'{memory_usage:.2f}%'\n    }\n```"}
{"task_id": "BigCodeBench/22", "solution": "import collections\nfrom itertools import zip_longest\nfrom random import choices\ndef task_func(l1, l2, K=10):\n    combined = [item for sublist in zip_longest(l1, l2) for item in sublist if item is not None]\n    sample = choices(combined, k=K)\n    return collections.Counter(sample)", "raw_solution": "import collections\nfrom itertools import zip_longest\nfrom random import choices\n\ndef task_func(l1, l2, K=10):\n    combined = [item for sublist in zip_longest(l1, l2) for item in sublist if item is not None]\n    sample = choices(combined, k=K)\n    return collections.Counter(sample)\n```"}
{"task_id": "BigCodeBench/23", "solution": "import numpy as np\nfrom itertools import zip_longest\ndef task_func(l1, l2, THRESHOLD=0.5):\n    l1 = [i for i in l1 if isinstance(i, (int, float))]\n    l2 = [i for i in l2 if isinstance(i, (int, float))]\n    l1, l2 = list(l1), list(l2)\n    l1.reverse()\n    l2.reverse()\n    combined = [i for sublist in zip_longest(l1, l2, fillvalue=None) for i in sublist if i is not None]\n    closest = min(combined, key=lambda x: abs(x - THRESHOLD))\n    return closest", "raw_solution": "import numpy as np\nfrom itertools import zip_longest\n\ndef task_func(l1, l2, THRESHOLD=0.5):\n    l1 = [i for i in l1 if isinstance(i, (int, float))]\n    l2 = [i for i in l2 if isinstance(i, (int, float))]\n    l1, l2 = list(l1), list(l2)\n    l1.reverse()\n    l2.reverse()\n    combined = [i for sublist in zip_longest(l1, l2, fillvalue=None) for i in sublist if i is not None]\n    closest = min(combined, key=lambda x: abs(x - THRESHOLD))\n    return closest\n```"}
{"task_id": "BigCodeBench/24", "solution": "import base64\nimport hashlib\nimport os\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\nfrom cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding", "raw_solution": "import base64\nimport hashlib\nimport os\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\nfrom cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\n"}
{"task_id": "BigCodeBench/25", "solution": "import base64\nimport json\nimport zlib\ndef task_func(data_dict):\n    json_str = json.dumps(data_dict)\n    compressed_data = zlib.compress(json_str.encode())\n    encoded_data = base64.b64encode(compressed_data)\n    return encoded_data.decode()", "raw_solution": "import base64\nimport json\nimport zlib\n\ndef task_func(data_dict):\n    json_str = json.dumps(data_dict)\n    compressed_data = zlib.compress(json_str.encode())\n    encoded_data = base64.b64encode(compressed_data)\n    return encoded_data.decode()\n```"}
{"task_id": "BigCodeBench/26", "solution": "import base64\nfrom cryptography.fernet import Fernet\ndef task_func(message, encryption_key):\n    cipher_suite = Fernet(encryption_key)\n    cipher_text = cipher_suite.encrypt(message.encode())\n    return base64.b64encode(cipher_text).decode()", "raw_solution": "import base64\nfrom cryptography.fernet import Fernet\n\ndef task_func(message, encryption_key):\n    cipher_suite = Fernet(encryption_key)\n    cipher_text = cipher_suite.encrypt(message.encode())\n    return base64.b64encode(cipher_text).decode()\n```"}
{"task_id": "BigCodeBench/27", "solution": "import json\nimport base64\nfrom datetime import datetime\ndef task_func(data: dict, DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\") -> str:\n    data['timestamp'] = datetime.now().strftime(DATE_FORMAT)\n    json_str = json.dumps(data)\n    return base64.b64encode(json_str.encode('ascii')).decode('ascii')", "raw_solution": "import json\nimport base64\nfrom datetime import datetime\n\ndef task_func(data: dict, DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\") -> str:\n    data['timestamp'] = datetime.now().strftime(DATE_FORMAT)\n    json_str = json.dumps(data)\n    return base64.b64encode(json_str.encode('ascii')).decode('ascii')\n```"}
{"task_id": "BigCodeBench/28", "solution": "import requests\nimport json\nimport base64\ndef task_func(data, url=\"http://your-api-url.com\"):\n    # Convert the dictionary to a JSON-formatted string\n    json_data = json.dumps(data)\n\n    # Encode the JSON-formatted string in base64 format\n    encoded_data = base64.b64encode(json_data.encode()).decode()\n\n    # Send the encoded data as a 'payload' in a POST request to the API endpoint\n    response = requests.post(url, data=encoded_data)\n\n    return response", "raw_solution": "import requests\nimport json\nimport base64\n\ndef task_func(data, url=\"http://your-api-url.com\"):\n    # Convert the dictionary to a JSON-formatted string\n    json_data = json.dumps(data)\n\n    # Encode the JSON-formatted string in base64 format\n    encoded_data = base64.b64encode(json_data.encode()).decode()\n\n    # Send the encoded data as a 'payload' in a POST request to the API endpoint\n    response = requests.post(url, data=encoded_data)\n\n    return response\n```"}
{"task_id": "BigCodeBench/29", "solution": "from sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport base64\ndef task_func(data):\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data)\n    encoded_data = base64.b64encode(standardized_data.astype(np.float64))\n    return encoded_data.decode('utf-8')", "raw_solution": "from sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport base64\n\ndef task_func(data):\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data)\n    encoded_data = base64.b64encode(standardized_data.astype(np.float64))\n    return encoded_data.decode('utf-8')\n```"}
{"task_id": "BigCodeBench/30", "solution": "import json\nimport os\nimport re\ndef task_func(\n    file_path,\n    attribute,\n    INPUT_JSON={\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\"type\": str},  \n            \"age\": {\"type\": int},   \n            \"email\": {\"type\": str}  \n        },\n        \"required\": [\"name\", \"age\", \"email\"]\n    },\n    EMAIL_REGEX=r\"^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$\"):\n    if not os.path.exists(file_path):\n        raise ValueError(\"File does not exist\")\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n    if not set(INPUT_JSON['required']).issubset(data.keys()):\n        raise ValueError(\"Required attributes are missing\")\n    for key, value in data.items():\n        if key in INPUT_JSON['properties']:\n            if type(value) != INPUT_JSON['properties'][key]['type']:\n                raise ValueError(\"Types do not match\")\n            if key == 'email' and not re.match(EMAIL_REGEX, value):\n                raise ValueError(\"Invalid email format\")\n    if attribute not in data:\n        raise ValueError(\"Attribute not found\")\n    return data[attribute]", "raw_solution": "import json\nimport os\nimport re\n\ndef task_func(\n    file_path,\n    attribute,\n    INPUT_JSON={\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\"type\": str},  \n            \"age\": {\"type\": int},   \n            \"email\": {\"type\": str}  \n        },\n        \"required\": [\"name\", \"age\", \"email\"]\n    },\n    EMAIL_REGEX=r\"^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$\"):\n    if not os.path.exists(file_path):\n        raise ValueError(\"File does not exist\")\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n    if not set(INPUT_JSON['required']).issubset(data.keys()):\n        raise ValueError(\"Required attributes are missing\")\n    for key, value in data.items():\n        if key in INPUT_JSON['properties']:\n            if type(value) != INPUT_JSON['properties'][key]['type']:\n                raise ValueError(\"Types do not match\")\n            if key == 'email' and not re.match(EMAIL_REGEX, value):\n                raise ValueError(\"Invalid email format\")\n    if attribute not in data:\n        raise ValueError(\"Attribute not found\")\n    return data[attribute]\n```"}
{"task_id": "BigCodeBench/31", "solution": "import nltk\nfrom string import punctuation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nPUNCTUATION = set(punctuation)\ndef task_func(text):\n    words = nltk.word_tokenize(text)\n    words = [word for word in words if word.startswith('$') and not all(char in PUNCTUATION for char in word[1:])]\n    if not words:\n        return None\n    freq_dist = nltk.FreqDist(words)\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=list(freq_dist.keys()), y=list(freq_dist.values()))\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of Words Starting with $')\n    return plt.gca()", "raw_solution": "import nltk\nfrom string import punctuation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Constants\nPUNCTUATION = set(punctuation)\ndef task_func(text):\n    words = nltk.word_tokenize(text)\n    words = [word for word in words if word.startswith('$') and not all(char in PUNCTUATION for char in word[1:])]\n    if not words:\n        return None\n    freq_dist = nltk.FreqDist(words)\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=list(freq_dist.keys()), y=list(freq_dist.values()))\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of Words Starting with $')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/32", "solution": "import requests\nfrom bs4 import BeautifulSoup\ndef task_func(url, tag):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    element = soup.find(tag)\n    if element:\n        return element.text\n    else:\n        return None", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\n\ndef task_func(url, tag):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    element = soup.find(tag)\n    if element:\n        return element.text\n    else:\n        return None\n```"}
{"task_id": "BigCodeBench/33", "solution": "import numpy as np\nfrom functools import reduce\ndef task_func(list_of_pairs):\n    product = reduce(lambda x, y: x * y, [pair[1] for pair in list_of_pairs])\n    return np.array([product])", "raw_solution": "import numpy as np\nfrom functools import reduce\n\ndef task_func(list_of_pairs):\n    product = reduce(lambda x, y: x * y, [pair[1] for pair in list_of_pairs])\n    return np.array([product])\n```"}
{"task_id": "BigCodeBench/34", "solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n\n    # Split the text into words\n    words = text.split()\n\n    # If there are no words available to generate a word cloud, raise an exception\n    if not words:\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n\n    # Generate a word cloud from the words\n    wordcloud = WordCloud(width=480, height=480, max_words=150, background_color=\"white\").generate(text)\n\n    # Plot the word cloud\n    plt.figure(figsize=(10, 7))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n\n    return wordcloud", "raw_solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n\n    # Split the text into words\n    words = text.split()\n\n    # If there are no words available to generate a word cloud, raise an exception\n    if not words:\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n\n    # Generate a word cloud from the words\n    wordcloud = WordCloud(width=480, height=480, max_words=150, background_color=\"white\").generate(text)\n\n    # Plot the word cloud\n    plt.figure(figsize=(10, 7))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n\n    return wordcloud\n```"}
{"task_id": "BigCodeBench/35", "solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df, target_values=[1, 3, 4]):\n    for col in df.columns:\n        df[col] = df[col].apply(lambda x: x if x in target_values else 0)\n    return df", "raw_solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, target_values=[1, 3, 4]):\n    for col in df.columns:\n        df[col] = df[col].apply(lambda x: x if x in target_values else 0)\n    return df\n```"}
{"task_id": "BigCodeBench/36", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport pandas as pd\nTARGET_VALUES = np.array([1, 3, 4])\ndef task_func(df):\n    # Replace all elements in DataFrame columns that do not exist in the TARGET_VALUES array with zeros\n    df = df.replace(set(df.columns) - set(TARGET_VALUES), 0)\n\n    # Perform a Box-Cox transformation on each column (if data is not constant, add 1 to account for zeros)\n    for col in df.columns:\n        if np.all(df[col] == 0):\n            df[col] = 0\n        else:\n            df[col] = stats.boxcox(df[col] + 1)[0]\n\n    # Create a figure and display the KDE plots of the transformed columns\n    fig, ax = plt.subplots(figsize=(10, 6))\n    df.plot(kind='kde', ax=ax)\n    plt.title('KDE Plots of Transformed Columns')\n    plt.xlabel('Values')\n    plt.ylabel('Density')\n\n    return df, fig", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nTARGET_VALUES = np.array([1, 3, 4])\n\ndef task_func(df):\n    # Replace all elements in DataFrame columns that do not exist in the TARGET_VALUES array with zeros\n    df = df.replace(set(df.columns) - set(TARGET_VALUES), 0)\n\n    # Perform a Box-Cox transformation on each column (if data is not constant, add 1 to account for zeros)\n    for col in df.columns:\n        if np.all(df[col] == 0):\n            df[col] = 0\n        else:\n            df[col] = stats.boxcox(df[col] + 1)[0]\n\n    # Create a figure and display the KDE plots of the transformed columns\n    fig, ax = plt.subplots(figsize=(10, 6))\n    df.plot(kind='kde', ax=ax)\n    plt.title('KDE Plots of Transformed Columns')\n    plt.xlabel('Values')\n    plt.ylabel('Density')\n\n    return df, fig\n```"}
{"task_id": "BigCodeBench/37", "solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, target_column):\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    # Train the Random Forest Classifier\n    clf = RandomForestClassifier(random_state=42)\n    clf.fit(X, y)\n\n    # Get feature importances\n    importances = clf.feature_importances_\n\n    # Create a dataframe for feature importances\n    df_importances = pd.DataFrame({\n        'Feature': X.columns,\n        'Importance': importances\n    })\n\n    # Sort the dataframe by importance\n    df_importances = df_importances.sort_values('Importance', ascending=False)\n\n    # Create the bar plot\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=df_importances)\n    plt.xlabel('Feature Importance Score')\n    plt.ylabel('Features')\n    plt.title('Visualizing Important Features')\n    plt.tight_layout()\n\n    return clf, plt.gca()", "raw_solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_column):\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    # Train the Random Forest Classifier\n    clf = RandomForestClassifier(random_state=42)\n    clf.fit(X, y)\n\n    # Get feature importances\n    importances = clf.feature_importances_\n\n    # Create a dataframe for feature importances\n    df_importances = pd.DataFrame({\n        'Feature': X.columns,\n        'Importance': importances\n    })\n\n    # Sort the dataframe by importance\n    df_importances = df_importances.sort_values('Importance', ascending=False)\n\n    # Create the bar plot\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=df_importances)\n    plt.xlabel('Feature Importance Score')\n    plt.ylabel('Features')\n    plt.title('Visualizing Important Features')\n    plt.tight_layout()\n\n    return clf, plt.gca()\n```"}
{"task_id": "BigCodeBench/38", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nFEATURE_NAMES = [\"Feature 1\", \"Feature 2\", \"Feature 3\", \"Feature 4\", \"Feature 5\"]\ndef task_func(data_matrix):\n    # Standardize the data\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data_matrix)\n\n    # Calculate the mean of each row\n    means = standardized_data.mean(axis=1)\n\n    # Create a DataFrame\n    df = pd.DataFrame(standardized_data, columns=FEATURE_NAMES)\n    df['Mean'] = means\n\n    # Create the histogram plot\n    fig, ax = plt.subplots()\n    ax.hist(means, bins=10, edgecolor='black')\n    ax.set_title('Distribution of Means')\n    ax.set_xlabel('Mean')\n    ax.set_ylabel('Frequency')\n\n    return df, ax", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Constants\nFEATURE_NAMES = [\"Feature 1\", \"Feature 2\", \"Feature 3\", \"Feature 4\", \"Feature 5\"]\n\ndef task_func(data_matrix):\n    # Standardize the data\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data_matrix)\n\n    # Calculate the mean of each row\n    means = standardized_data.mean(axis=1)\n\n    # Create a DataFrame\n    df = pd.DataFrame(standardized_data, columns=FEATURE_NAMES)\n    df['Mean'] = means\n\n    # Create the histogram plot\n    fig, ax = plt.subplots()\n    ax.hist(means, bins=10, edgecolor='black')\n    ax.set_title('Distribution of Means')\n    ax.set_xlabel('Mean')\n    ax.set_ylabel('Frequency')\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/39", "solution": "import numpy as np\nfrom scipy.stats import ttest_1samp\nimport matplotlib.pyplot as plt\nALPHA = 0.05\ndef task_func(data_matrix):\n    # Calculate the mean value of each row in the data matrix\n    row_means = np.mean(data_matrix, axis=1)\n    # Calculate the population mean\n    population_mean = np.mean(data_matrix)\n    # Run a t-test from a sample against the population value\n    t_stat, p_val = ttest_1samp(data_matrix, population_mean)\n    # Record the mean values that differ significantly\n    significant_indices = [i for i, p in enumerate(p_val) if p < ALPHA]\n    # Create the plot\n    fig, ax = plt.subplots()\n    ax.plot(row_means, color='red', label='Means')\n    ax.plot(significant_indices, [row_means[i] for i in significant_indices], color='blue', label='Significant Means')\n    ax.axhline(population_mean, color='green', label='Population Mean')\n    ax.legend()\n    plt.show()\n    return significant_indices, ax", "raw_solution": "import numpy as np\nfrom scipy.stats import ttest_1samp\nimport matplotlib.pyplot as plt\n# Constants\nALPHA = 0.05\ndef task_func(data_matrix):\n    # Calculate the mean value of each row in the data matrix\n    row_means = np.mean(data_matrix, axis=1)\n    # Calculate the population mean\n    population_mean = np.mean(data_matrix)\n    # Run a t-test from a sample against the population value\n    t_stat, p_val = ttest_1samp(data_matrix, population_mean)\n    # Record the mean values that differ significantly\n    significant_indices = [i for i, p in enumerate(p_val) if p < ALPHA]\n    # Create the plot\n    fig, ax = plt.subplots()\n    ax.plot(row_means, color='red', label='Means')\n    ax.plot(significant_indices, [row_means[i] for i in significant_indices], color='blue', label='Significant Means')\n    ax.axhline(population_mean, color='green', label='Population Mean')\n    ax.legend()\n    plt.show()\n    return significant_indices, ax\n```"}
{"task_id": "BigCodeBench/40", "solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy.stats import zscore\ndef task_func(data_matrix):\n    # Calculate the Z-values of a 2D data matrix\n    z_scores = pd.DataFrame(zscore(data_matrix, axis=1), columns=data_matrix.columns)\n    # Calculate the mean value of each row\n    z_scores['Mean'] = z_scores.mean(axis=1)\n    # Visualize the correlation matrix of the Z-values with a heatmap\n    heatmap = sns.heatmap(z_scores.corr(), annot=True, cmap='coolwarm')\n    return z_scores, heatmap.axes", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy.stats import zscore\n\ndef task_func(data_matrix):\n    # Calculate the Z-values of a 2D data matrix\n    z_scores = pd.DataFrame(zscore(data_matrix, axis=1), columns=data_matrix.columns)\n    # Calculate the mean value of each row\n    z_scores['Mean'] = z_scores.mean(axis=1)\n    # Visualize the correlation matrix of the Z-values with a heatmap\n    heatmap = sns.heatmap(z_scores.corr(), annot=True, cmap='coolwarm')\n    return z_scores, heatmap.axes\n```"}
{"task_id": "BigCodeBench/41", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\ndef task_func(data_matrix):\n    df = pd.DataFrame(data_matrix)\n    df['Skewness'] = df.apply(lambda row: skew(row), axis=1)\n    ax = df['Skewness'].plot(kind='hist', bins=20, edgecolor='black')\n    ax.set_xlabel('Skewness')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution of Skewness')\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\n\ndef task_func(data_matrix):\n    df = pd.DataFrame(data_matrix)\n    df['Skewness'] = df.apply(lambda row: skew(row), axis=1)\n    ax = df['Skewness'].plot(kind='hist', bins=20, edgecolor='black')\n    ax.set_xlabel('Skewness')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution of Skewness')\n    return df, ax\n```"}
{"task_id": "BigCodeBench/42", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(data_matrix, n_components=2):\n    pca = PCA(n_components=n_components)\n    pca_result = pca.fit_transform(data_matrix)\n    df = pd.DataFrame(pca_result, columns=[f'Component {i+1}' for i in range(n_components)])\n    df['Mean'] = df.mean(axis=1)\n    explained_variance_ratio = pca.explained_variance_ratio_\n    cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio)\n    fig, ax = plt.subplots()\n    ax.plot(range(1, n_components + 1), cumulative_explained_variance_ratio)\n    ax.set_xlabel('Number of Components')\n    ax.set_ylabel('Cumulative Explained Variance')\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(data_matrix, n_components=2):\n    pca = PCA(n_components=n_components)\n    pca_result = pca.fit_transform(data_matrix)\n    df = pd.DataFrame(pca_result, columns=[f'Component {i+1}' for i in range(n_components)])\n    df['Mean'] = df.mean(axis=1)\n    explained_variance_ratio = pca.explained_variance_ratio_\n    cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio)\n    fig, ax = plt.subplots()\n    ax.plot(range(1, n_components + 1), cumulative_explained_variance_ratio)\n    ax.set_xlabel('Number of Components')\n    ax.set_ylabel('Cumulative Explained Variance')\n    return df, ax\n```"}
{"task_id": "BigCodeBench/43", "solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df):\n    # Replace NaN values with the average of the column\n    df.fillna(df.mean(), inplace=True)\n\n    # Describe the dataframe\n    df_stats = df.describe()\n\n    # Create a list to store the distribution plots\n    axes = []\n\n    # Iterate over each numeric column\n    for col in df.select_dtypes(include=[np.number]).columns:\n        # Create a distribution plot for the column\n        ax = sns.histplot(df[col], bins=10)\n        ax.set_title(f\"Distribution of {col}\")\n        axes.append(ax)\n\n    return df_stats, axes", "raw_solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df):\n    # Replace NaN values with the average of the column\n    df.fillna(df.mean(), inplace=True)\n\n    # Describe the dataframe\n    df_stats = df.describe()\n\n    # Create a list to store the distribution plots\n    axes = []\n\n    # Iterate over each numeric column\n    for col in df.select_dtypes(include=[np.number]).columns:\n        # Create a distribution plot for the column\n        ax = sns.histplot(df[col], bins=10)\n        ax.set_title(f\"Distribution of {col}\")\n        axes.append(ax)\n\n    return df_stats, axes\n```"}
{"task_id": "BigCodeBench/44", "solution": "from sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df):\n    # Normalize numeric columns in a DataFrame and draw a box plot for each column.\n    # Missing values are replaced by column's average.\n    scaler = MinMaxScaler()\n    df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    fig, axes = plt.subplots(nrows=1, ncols=len(df.columns), figsize=(10, 5))\n    for i, column in enumerate(df.columns):\n        df_normalized[column].plot(kind='box', ax=axes[i])\n        axes[i].set_title(column)\n\n    plt.tight_layout()\n    plt.show()\n\n    return df_normalized, axes", "raw_solution": "from sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df):\n    # Normalize numeric columns in a DataFrame and draw a box plot for each column.\n    # Missing values are replaced by column's average.\n    scaler = MinMaxScaler()\n    df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    fig, axes = plt.subplots(nrows=1, ncols=len(df.columns), figsize=(10, 5))\n    for i, column in enumerate(df.columns):\n        df_normalized[column].plot(kind='box', ax=axes[i])\n        axes[i].set_title(column)\n\n    plt.tight_layout()\n    plt.show()\n\n    return df_normalized, axes\n```"}
{"task_id": "BigCodeBench/45", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame):\n    # Replace missing values with column's average\n    df.fillna(df.mean(), inplace=True)\n\n    # Perform PCA\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(df)\n\n    # Create DataFrame with principal components\n    principalDf = pd.DataFrame(data=principalComponents, columns=['principal component 1', 'principal component 2'])\n\n    # Create scatter plot\n    fig, ax = plt.subplots()\n    sns.scatterplot(x='principal component 1', y='principal component 2', data=principalDf, ax=ax)\n    ax.set_xlabel('principal component 1')\n    ax.set_ylabel('principal component 2')\n\n    return principalDf, ax", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame):\n    # Replace missing values with column's average\n    df.fillna(df.mean(), inplace=True)\n\n    # Perform PCA\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(df)\n\n    # Create DataFrame with principal components\n    principalDf = pd.DataFrame(data=principalComponents, columns=['principal component 1', 'principal component 2'])\n\n    # Create scatter plot\n    fig, ax = plt.subplots()\n    sns.scatterplot(x='principal component 1', y='principal component 2', data=principalDf, ax=ax)\n    ax.set_xlabel('principal component 1')\n    ax.set_ylabel('principal component 2')\n\n    return principalDf, ax\n```"}
{"task_id": "BigCodeBench/46", "solution": "    # Calculate Z-scores for numeric columns in a DataFrame and draw a histogram for each column.\n    # Missing values are replaced by the column's average.\n    # The histograms are plotted with 10 bins.\n    # The function should output with:\n    # tuple:\n    # 1. pandas.DataFrame: A DataFrame with computed z-scores.\n    # 2. list: A list of Axes objects representing the histograms of the numeric columns.\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore", "raw_solution": "from scipy.stats import zscore\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df):\n    # Calculate Z-scores for numeric columns in a DataFrame and draw a histogram for each column.\n    # Missing values are replaced by the column's average.\n    # The histograms are plotted with 10 bins.\n    # The function should output with:\n    # tuple:\n    # 1. pandas.DataFrame: A DataFrame with computed z-scores.\n    # 2. list: A list of Axes objects representing the histograms of the numeric columns.\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n    # import matplotlib.pyplot as plt\n    # import pandas as pd\n    # def task_func(df):\n    # ```\n    # The function should be written as:\n    # ```\n    # from scipy.stats import zscore\n   "}
{"task_id": "BigCodeBench/47", "solution": "from sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\ndef task_func(df):\n    # Standardize numeric columns in the DataFrame\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    df[numeric_cols] = StandardScaler().fit_transform(df[numeric_cols])\n\n    # Replace missing values with the column's average\n    df.fillna(df.mean(), inplace=True)\n\n    # Calculate the correlation matrix\n    corr_matrix = df.corr()\n\n    # Plot the heatmap of the correlation matrix\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n    plt.title('Correlation Matrix Heatmap')\n    plt.show()\n\n    return df, plt.gca()", "raw_solution": "from sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef task_func(df):\n    # Standardize numeric columns in the DataFrame\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    df[numeric_cols] = StandardScaler().fit_transform(df[numeric_cols])\n\n    # Replace missing values with the column's average\n    df.fillna(df.mean(), inplace=True)\n\n    # Calculate the correlation matrix\n    corr_matrix = df.corr()\n\n    # Plot the heatmap of the correlation matrix\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n    plt.title('Correlation Matrix Heatmap')\n    plt.show()\n\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/48", "solution": "import time\nfrom datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\ndef task_func(n, output_path=None):\n    timestamps = [time.time() for _ in range(n)]\n    formatted_timestamps = [datetime.utcfromtimestamp(timestamp).strftime(DATE_FORMAT) for timestamp in timestamps]\n\n    if output_path:\n        plt.hist(timestamps, bins=10)\n        plt.xlabel('Unix Timestamp')\n        plt.ylabel('Frequency')\n        plt.title('Histogram of Unix Timestamps')\n        plt.savefig(output_path)\n    else:\n        plt.hist(timestamps, bins=10)\n        plt.xlabel('Unix Timestamp')\n        plt.ylabel('Frequency')\n        plt.title('Histogram of Unix Timestamps')\n        plt.show()\n\n    return formatted_timestamps", "raw_solution": "import time\nfrom datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\n\n# Constants\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n\ndef task_func(n, output_path=None):\n    timestamps = [time.time() for _ in range(n)]\n    formatted_timestamps = [datetime.utcfromtimestamp(timestamp).strftime(DATE_FORMAT) for timestamp in timestamps]\n\n    if output_path:\n        plt.hist(timestamps, bins=10)\n        plt.xlabel('Unix Timestamp')\n        plt.ylabel('Frequency')\n        plt.title('Histogram of Unix Timestamps')\n        plt.savefig(output_path)\n    else:\n        plt.hist(timestamps, bins=10)\n        plt.xlabel('Unix Timestamp')\n        plt.ylabel('Frequency')\n        plt.title('Histogram of Unix Timestamps')\n        plt.show()\n\n    return formatted_timestamps\n```"}
{"task_id": "BigCodeBench/49", "solution": "from datetime import datetime\nimport pandas as pd\nimport matplotlib.pyplot as plt\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\ndef task_func(timestamps):\n    if not timestamps:\n        raise ValueError(\"Input list of timestamps is empty.\")\n    df = pd.DataFrame(timestamps, columns=['Timestamp'])\n    df['Datetime'] = df['Timestamp'].apply(lambda x: datetime.fromtimestamp(x).strftime(DATE_FORMAT))\n    df['Datetime'] = pd.to_datetime(df['Datetime'])\n    ax = df['Datetime'].hist(bins=10)\n    plt.xlabel('Datetime')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Datetime')\n    return df, ax", "raw_solution": "from datetime import datetime\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n\ndef task_func(timestamps):\n    if not timestamps:\n        raise ValueError(\"Input list of timestamps is empty.\")\n    df = pd.DataFrame(timestamps, columns=['Timestamp'])\n    df['Datetime'] = df['Timestamp'].apply(lambda x: datetime.fromtimestamp(x).strftime(DATE_FORMAT))\n    df['Datetime'] = pd.to_datetime(df['Datetime'])\n    ax = df['Datetime'].hist(bins=10)\n    plt.xlabel('Datetime')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Datetime')\n    return df, ax\n```"}
{"task_id": "BigCodeBench/50", "solution": "from datetime import datetime\nimport pandas as pd\nimport pytz\nimport matplotlib.pyplot as plt\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\nTIMEZONES = [\n    \"America/New_York\",\n    \"Europe/London\",\n    \"Asia/Shanghai\",\n    \"Asia/Tokyo\",\n    \"Australia/Sydney\",\n]\ndef task_func(timestamp):\n    # Convert Unix timestamp to datetime objects in different time zones\n    datetime_objects = [datetime.fromtimestamp(timestamp, tz=pytz.timezone(tz)) for tz in TIMEZONES]\n\n    # Create a DataFrame\n    df = pd.DataFrame({\n        \"Timezone\": TIMEZONES,\n        \"Datetime\": [dt.strftime(DATE_FORMAT) for dt in datetime_objects]\n    })\n\n    # Draw a bar chart\n    fig, ax = plt.subplots()\n    df.plot(x=\"Timezone\", y=\"Datetime\", kind=\"bar\", ax=ax)\n    ax.set_xlabel(\"Timezone\")\n    ax.set_ylabel(\"Datetime\")\n    ax.set_title(\"Datetime = f(Timezone)\")\n\n    return df, ax", "raw_solution": "from datetime import datetime\nimport pandas as pd\nimport pytz\nimport matplotlib.pyplot as plt\n\n# Constants\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\nTIMEZONES = [\n    \"America/New_York\",\n    \"Europe/London\",\n    \"Asia/Shanghai\",\n    \"Asia/Tokyo\",\n    \"Australia/Sydney\",\n]\n\ndef task_func(timestamp):\n    # Convert Unix timestamp to datetime objects in different time zones\n    datetime_objects = [datetime.fromtimestamp(timestamp, tz=pytz.timezone(tz)) for tz in TIMEZONES]\n\n    # Create a DataFrame\n    df = pd.DataFrame({\n        \"Timezone\": TIMEZONES,\n        \"Datetime\": [dt.strftime(DATE_FORMAT) for dt in datetime_objects]\n    })\n\n    # Draw a bar chart\n    fig, ax = plt.subplots()\n    df.plot(x=\"Timezone\", y=\"Datetime\", kind=\"bar\", ax=ax)\n    ax.set_xlabel(\"Timezone\")\n    ax.set_ylabel(\"Datetime\")\n    ax.set_title(\"Datetime = f(Timezone)\")\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/51", "solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df, age: int, height: int):\n    df = df[df['Age'] >= age]\n    df = df[df['Height'] >= height]\n    if len(df.columns) < 3:\n        df['Cluster'] = 0\n        return df, None\n    else:\n        kmeans = KMeans(n_clusters=3)\n        kmeans.fit(df[['Age', 'Height']])\n        df['Cluster'] = kmeans.labels_\n        plt.scatter(df['Age'], df['Height'], c=df['Cluster'])\n        plt.xlabel('Age')\n        plt.ylabel('Height')\n        plt.title('KMeans Clustering based on Age and Height')\n        return df, plt.gca()", "raw_solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, age: int, height: int):\n    df = df[df['Age'] >= age]\n    df = df[df['Height'] >= height]\n    if len(df.columns) < 3:\n        df['Cluster'] = 0\n        return df, None\n    else:\n        kmeans = KMeans(n_clusters=3)\n        kmeans.fit(df[['Age', 'Height']])\n        df['Cluster'] = kmeans.labels_\n        plt.scatter(df['Age'], df['Height'], c=df['Cluster'])\n        plt.xlabel('Age')\n        plt.ylabel('Height')\n        plt.title('KMeans Clustering based on Age and Height')\n        return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/52", "solution": "import pandas as pd\nimport regex as re\nSTOPWORDS = [\"a\", \"an\", \"the\", \"in\", \"is\", \"are\"]\ndef task_func(text):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Split the text into words\n    words = text.split()\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n    # Count the frequency of each word\n    word_counts = pd.Series(words).value_counts()\n    return word_counts", "raw_solution": "import pandas as pd\nimport regex as re\n# Constants\nSTOPWORDS = [\"a\", \"an\", \"the\", \"in\", \"is\", \"are\"]\ndef task_func(text):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Split the text into words\n    words = text.split()\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n    # Count the frequency of each word\n    word_counts = pd.Series(words).value_counts()\n    return word_counts\n```"}
{"task_id": "BigCodeBench/53", "solution": "import pandas as pd\nimport regex as re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nCOLUMN_NAMES = [\"Name\", \"Email\", \"Age\", \"Country\"]\ndef task_func(text):\n    pattern = r\"Name: (.*?), Email: (.*?), Age: (.*?), Country: (.*?)($|\\n)\"\n    matches = re.findall(pattern, text)\n    df = pd.DataFrame(matches, columns=COLUMN_NAMES)\n    df['Age'] = df['Age'].astype(int)\n    sns.histplot(data=df, x='Age', kde=True, color='blue')\n    plt.show()\n    return df", "raw_solution": "import pandas as pd\nimport regex as re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nCOLUMN_NAMES = [\"Name\", \"Email\", \"Age\", \"Country\"]\ndef task_func(text):\n    pattern = r\"Name: (.*?), Email: (.*?), Age: (.*?), Country: (.*?)($|\\n)\"\n    matches = re.findall(pattern, text)\n    df = pd.DataFrame(matches, columns=COLUMN_NAMES)\n    df['Age'] = df['Age'].astype(int)\n    sns.histplot(data=df, x='Age', kde=True, color='blue')\n    plt.show()\n    return df\n```"}
{"task_id": "BigCodeBench/54", "solution": "import pandas as pd\nimport regex as re\nfrom sklearn.feature_extraction.text import CountVectorizer\ndef task_func(text):\n    # Split the text into sentences\n    sentences = re.split(r'[.!?]', text)\n    # Remove empty sentences\n    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n\n    # Create a CountVectorizer\n    vectorizer = CountVectorizer()\n    # Fit and transform the sentences\n    X = vectorizer.fit_transform(sentences)\n\n    # Create a DataFrame from the document-term matrix\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n\n    return df", "raw_solution": "import pandas as pd\nimport regex as re\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef task_func(text):\n    # Split the text into sentences\n    sentences = re.split(r'[.!?]', text)\n    # Remove empty sentences\n    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n\n    # Create a CountVectorizer\n    vectorizer = CountVectorizer()\n    # Fit and transform the sentences\n    X = vectorizer.fit_transform(sentences)\n\n    # Create a DataFrame from the document-term matrix\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n\n    return df\n```"}
{"task_id": "BigCodeBench/55", "solution": "import re\nimport pandas as pd\nSTOPWORDS = [\"Those\", \"are\", \"the\", \"words\", \"to\", \"ignore\"]\ndef task_func(text):\n    sentences = re.split('(?<=[.!?]) +', text)\n    sentence_dict = {}\n    for i, sentence in enumerate(sentences, 1):\n        words = re.findall(r'\\b\\w+\\b', sentence)\n        words = [word for word in words if word not in STOPWORDS]\n        sentence_dict[f\"Sentence {i}\"] = len(words)\n    return pd.Series(sentence_dict)", "raw_solution": "import re\nimport pandas as pd\nSTOPWORDS = [\"Those\", \"are\", \"the\", \"words\", \"to\", \"ignore\"]\ndef task_func(text):\n    sentences = re.split('(?<=[.!?]) +', text)\n    sentence_dict = {}\n    for i, sentence in enumerate(sentences, 1):\n        words = re.findall(r'\\b\\w+\\b', sentence)\n        words = [word for word in words if word not in STOPWORDS]\n        sentence_dict[f\"Sentence {i}\"] = len(words)\n    return pd.Series(sentence_dict)\n```"}
{"task_id": "BigCodeBench/56", "solution": "import pandas as pd\nimport regex as re\ndef task_func(text):\n    lines = text.split('\\n')\n    data = []\n    for line in lines:\n        match = re.match(r'Score: (\\d+), Category: (\\w+)', line)\n        if match:\n            score, category = match.groups()\n            data.append({'Score': int(score), 'Category': category})\n    return pd.DataFrame(data)", "raw_solution": "import pandas as pd\nimport regex as re\n\ndef task_func(text):\n    lines = text.split('\\n')\n    data = []\n    for line in lines:\n        match = re.match(r'Score: (\\d+), Category: (\\w+)', line)\n        if match:\n            score, category = match.groups()\n            data.append({'Score': int(score), 'Category': category})\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/57", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(csv_file_path: str, title: str):\n    df = pd.read_csv(csv_file_path)\n    corr = df.corr().round(2)\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, ax=ax)\n    ax.set_title(title)\n    return corr, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(csv_file_path: str, title: str):\n    df = pd.read_csv(csv_file_path)\n    corr = df.corr().round(2)\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, ax=ax)\n    ax.set_title(title)\n    return corr, ax\n```"}
{"task_id": "BigCodeBench/58", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(mu, sigma, num_samples):\n    # Generate a normal distribution\n    x = np.random.normal(mu, sigma, num_samples)\n\n    # Create the plot\n    fig, ax = plt.subplots()\n\n    # Plot the histogram\n    ax.hist(x, bins=30, density=True, color='blue', alpha=0.5)\n\n    # Plot the normal distribution\n    x_range = np.linspace(min(x), max(x), 100)\n    ax.plot(x_range, stats.norm.pdf(x_range, mu, sigma), color='red')\n\n    # Set the plot title\n    ax.set_title('Normal Distribution')\n\n    # Return the figure\n    return fig", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(mu, sigma, num_samples):\n    # Generate a normal distribution\n    x = np.random.normal(mu, sigma, num_samples)\n\n    # Create the plot\n    fig, ax = plt.subplots()\n\n    # Plot the histogram\n    ax.hist(x, bins=30, density=True, color='blue', alpha=0.5)\n\n    # Plot the normal distribution\n    x_range = np.linspace(min(x), max(x), 100)\n    ax.plot(x_range, stats.norm.pdf(x_range, mu, sigma), color='red')\n\n    # Set the plot title\n    ax.set_title('Normal Distribution')\n\n    # Return the figure\n    return fig\n```"}
{"task_id": "BigCodeBench/59", "solution": "import wikipedia\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ndef task_func(page_title):\n    try:\n        page = wikipedia.page(page_title)\n        text = page.content\n        wordcloud = WordCloud().generate(text)\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis(\"off\")\n        return plt.gca()\n    except wikipedia.exceptions.PageError:\n        return None", "raw_solution": "import wikipedia\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(page_title):\n    try:\n        page = wikipedia.page(page_title)\n        text = page.content\n        wordcloud = WordCloud().generate(text)\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis(\"off\")\n        return plt.gca()\n    except wikipedia.exceptions.PageError:\n        return None\n```"}
{"task_id": "BigCodeBench/60", "solution": "import json\nimport pandas as pd\ndef task_func(result, csv_file_path=\"test.csv\", json_file_path=\"test.json\"):\n    df = pd.DataFrame(result)\n    df.to_csv(csv_file_path, index=False)\n    with open(json_file_path, 'w') as f:\n        json.dump(result, f)", "raw_solution": "import json\nimport pandas as pd\n\ndef task_func(result, csv_file_path=\"test.csv\", json_file_path=\"test.json\"):\n    df = pd.DataFrame(result)\n    df.to_csv(csv_file_path, index=False)\n    with open(json_file_path, 'w') as f:\n        json.dump(result, f)\n```"}
{"task_id": "BigCodeBench/61", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nPLOT_TITLE = 'Square root plot'\nX_LABEL = 'x'\nY_LABEL = 'sqrt(x)'\nTIME_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(result):\n    # Extract the 'from_user' values from the input list of dictionaries\n    x_values = [d['from_user'] for d in result]\n\n    # Calculate the square root of each value\n    y_values = np.sqrt(x_values)\n\n    # Create the plot\n    plt.figure(figsize=(10, 6))\n    plt.plot(x_values, y_values, marker='o')\n    plt.title(PLOT_TITLE)\n    plt.xlabel(X_LABEL)\n    plt.ylabel(Y_LABEL)\n\n    # Annotate the plot with the current date and time\n    current_time = datetime.now().strftime(TIME_FORMAT)\n    plt.annotate(current_time, xy=(1, 1), xycoords='axes fraction', xytext=(5, -5), textcoords='offset points', ha='right', va='top')\n\n    plt.tight_layout()\n    plt.show()\n\n    return y_values", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n# Constants\nPLOT_TITLE = 'Square root plot'\nX_LABEL = 'x'\nY_LABEL = 'sqrt(x)'\nTIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(result):\n    # Extract the 'from_user' values from the input list of dictionaries\n    x_values = [d['from_user'] for d in result]\n\n    # Calculate the square root of each value\n    y_values = np.sqrt(x_values)\n\n    # Create the plot\n    plt.figure(figsize=(10, 6))\n    plt.plot(x_values, y_values, marker='o')\n    plt.title(PLOT_TITLE)\n    plt.xlabel(X_LABEL)\n    plt.ylabel(Y_LABEL)\n\n    # Annotate the plot with the current date and time\n    current_time = datetime.now().strftime(TIME_FORMAT)\n    plt.annotate(current_time, xy=(1, 1), xycoords='axes fraction', xytext=(5, -5), textcoords='offset points', ha='right', va='top')\n\n    plt.tight_layout()\n    plt.show()\n\n    return y_values\n```"}
{"task_id": "BigCodeBench/62", "solution": "import random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(result, colors=['b', 'g', 'r', 'c', 'm', 'y', 'k']):\n    from_user_values = result[result['from_user'] != '']\n    from_user_values = from_user_values['from_user'].value_counts()\n    plt.figure(figsize=(10, 6))\n    sns.barplot(from_user_values.index, from_user_values.values, palette=random.choices(colors, k=len(from_user_values.index)))\n    plt.xlabel('From User')\n    plt.ylabel('Count')\n    plt.title('Histogram of From User Values')\n    plt.show()", "raw_solution": "import random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(result, colors=['b', 'g', 'r', 'c', 'm', 'y', 'k']):\n    from_user_values = result[result['from_user'] != '']\n    from_user_values = from_user_values['from_user'].value_counts()\n    plt.figure(figsize=(10, 6))\n    sns.barplot(from_user_values.index, from_user_values.values, palette=random.choices(colors, k=len(from_user_values.index)))\n    plt.xlabel('From User')\n    plt.ylabel('Count')\n    plt.title('Histogram of From User Values')\n    plt.show()\n```"}
{"task_id": "BigCodeBench/63", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(car_dict):\n    df = pd.DataFrame(list(car_dict.items()), columns=['Car', 'Color'])\n    df.plot(kind='bar', x='Car', y='Color', legend=False)\n    plt.title('Distribution of Vehicle Colors')\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(car_dict):\n    df = pd.DataFrame(list(car_dict.items()), columns=['Car', 'Color'])\n    df.plot(kind='bar', x='Car', y='Color', legend=False)\n    plt.title('Distribution of Vehicle Colors')\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/64", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nCOLUMNS = ['col1', 'col2', 'col3']\ndef task_func(data):\n    df = pd.DataFrame(data, columns=COLUMNS)\n    pivot_table = df.pivot_table(values='col3', index='col1', columns='col2', aggfunc='count')\n    heatmap = sns.heatmap(pivot_table, cmap=\"YlGnBu\")\n    return df, heatmap.get_figure()", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['col1', 'col2', 'col3']\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=COLUMNS)\n    pivot_table = df.pivot_table(values='col3', index='col1', columns='col2', aggfunc='count')\n    heatmap = sns.heatmap(pivot_table, cmap=\"YlGnBu\")\n    return df, heatmap.get_figure()\n```"}
{"task_id": "BigCodeBench/65", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nCOLUMNS = ['col1', 'col2', 'col3']\ndef task_func(data):\n    df = pd.DataFrame(data, columns=COLUMNS)\n    df = df.groupby(COLUMNS[:-1]).last().reset_index()\n    df.columns = [\"-\".join(COLUMNS[:-1]), COLUMNS[-1]]\n    ax = df.plot(x=\"-\".join(COLUMNS[:-1]), y=COLUMNS[-1], kind='line')\n    plt.xlabel(\"-\".join(COLUMNS[:-1]))\n    plt.ylabel(COLUMNS[-1])\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\nCOLUMNS = ['col1', 'col2', 'col3']\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=COLUMNS)\n    df = df.groupby(COLUMNS[:-1]).last().reset_index()\n    df.columns = [\"-\".join(COLUMNS[:-1]), COLUMNS[-1]]\n    ax = df.plot(x=\"-\".join(COLUMNS[:-1]), y=COLUMNS[-1], kind='line')\n    plt.xlabel(\"-\".join(COLUMNS[:-1]))\n    plt.ylabel(COLUMNS[-1])\n    return df, ax\n```"}
{"task_id": "BigCodeBench/66", "solution": "import pandas as pd\nimport seaborn as sns\nCOLUMNS = ['col1', 'col2', 'col3']\ndef task_func(data):\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=COLUMNS)\n\n    # Group by 'col1' and 'col2' and reset index\n    grouped_df = df.groupby(['col1', 'col2']).mean().reset_index()\n\n    # Create distribution plot\n    plot = sns.distplot(grouped_df['col3'])\n    plot.set_xlabel('col3')\n\n    return grouped_df, plot.figure", "raw_solution": "import pandas as pd\nimport seaborn as sns\n\n# Constants\nCOLUMNS = ['col1', 'col2', 'col3']\n\ndef task_func(data):\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=COLUMNS)\n\n    # Group by 'col1' and 'col2' and reset index\n    grouped_df = df.groupby(['col1', 'col2']).mean().reset_index()\n\n    # Create distribution plot\n    plot = sns.distplot(grouped_df['col3'])\n    plot.set_xlabel('col3')\n\n    return grouped_df, plot.figure\n```"}
{"task_id": "BigCodeBench/67", "solution": "import pandas as pd\nimport re\nimport os\ndef task_func(dir_path: str, pattern: str = '^EMP'):\n    files = [f for f in os.listdir(dir_path) if re.match(pattern, f)]\n    sizes = [os.path.getsize(os.path.join(dir_path, f)) for f in files]\n    df = pd.DataFrame({'File': files, 'Size': sizes})\n    return df", "raw_solution": "import pandas as pd\nimport re\nimport os\n\ndef task_func(dir_path: str, pattern: str = '^EMP'):\n    files = [f for f in os.listdir(dir_path) if re.match(pattern, f)]\n    sizes = [os.path.getsize(os.path.join(dir_path, f)) for f in files]\n    df = pd.DataFrame({'File': files, 'Size': sizes})\n    return df\n```"}
{"task_id": "BigCodeBench/68", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(data='/path/to/data.csv', emp_prefix='EMP'):\n    df = pd.read_csv(data)\n    filtered_df = df[df['Employee ID'].str.startswith(emp_prefix)]\n    sns.histplot(data=filtered_df, x='Age', kde=True, color='blue')\n    plt.title('Histogram of Age')\n    plt.xlabel('Age')\n    plt.ylabel('Frequency')\n    plt.show()\n    return filtered_df", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data='/path/to/data.csv', emp_prefix='EMP'):\n    df = pd.read_csv(data)\n    filtered_df = df[df['Employee ID'].str.startswith(emp_prefix)]\n    sns.histplot(data=filtered_df, x='Age', kde=True, color='blue')\n    plt.title('Histogram of Age')\n    plt.xlabel('Age')\n    plt.ylabel('Frequency')\n    plt.show()\n    return filtered_df\n```"}
{"task_id": "BigCodeBench/69", "solution": "import random\nimport matplotlib.pyplot as plt\nSALARY_RANGE = (20000, 100000)\ndef task_func(dict1):\n    # Get the number of employees in the department\n    num_employees = len(dict1)\n\n    # Generate random salaries for each employee\n    salaries = [random.randint(SALARY_RANGE[0], SALARY_RANGE[1]) for _ in range(num_employees)]\n\n    # Create a histogram\n    plt.hist(salaries, bins=10, edgecolor='black')\n\n    # Set the title and labels\n    plt.title('Salary Distribution in EMPXX Department')\n    plt.xlabel('Salary')\n    plt.ylabel('Number of Employees')\n\n    return plt.gca()", "raw_solution": "import random\nimport matplotlib.pyplot as plt\n\n# Constants\nSALARY_RANGE = (20000, 100000)\n\ndef task_func(dict1):\n    # Get the number of employees in the department\n    num_employees = len(dict1)\n\n    # Generate random salaries for each employee\n    salaries = [random.randint(SALARY_RANGE[0], SALARY_RANGE[1]) for _ in range(num_employees)]\n\n    # Create a histogram\n    plt.hist(salaries, bins=10, edgecolor='black')\n\n    # Set the title and labels\n    plt.title('Salary Distribution in EMPXX Department')\n    plt.xlabel('Salary')\n    plt.ylabel('Number of Employees')\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/70", "solution": "import pandas as pd\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nCOLUMNS = ['email', 'list']\ndef task_func(json_file):\n    try:\n        with open(json_file, 'r') as file:\n            data = json.load(file)\n    except FileNotFoundError:\n        return pd.DataFrame(columns=COLUMNS), None\n\n    df = pd.DataFrame(data)\n    df = df[COLUMNS]\n\n    if df.empty:\n        return df, None\n\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n\n    fig, ax = plt.subplots()\n    df.plot(x='email', y=['sum', 'mean'], kind='bar', ax=ax)\n    ax.set_xlabel('Email')\n    ax.set_ylabel('Value')\n    ax.legend(['Sum', 'Mean'])\n\n    return df, ax.figure", "raw_solution": "import pandas as pd\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['email', 'list']\n\ndef task_func(json_file):\n    try:\n        with open(json_file, 'r') as file:\n            data = json.load(file)\n    except FileNotFoundError:\n        return pd.DataFrame(columns=COLUMNS), None\n\n    df = pd.DataFrame(data)\n    df = df[COLUMNS]\n\n    if df.empty:\n        return df, None\n\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n\n    fig, ax = plt.subplots()\n    df.plot(x='email', y=['sum', 'mean'], kind='bar', ax=ax)\n    ax.set_xlabel('Email')\n    ax.set_ylabel('Value')\n    ax.legend(['Sum', 'Mean'])\n\n    return df, ax.figure\n```"}
{"task_id": "BigCodeBench/71", "solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport ast\ndef task_func(csv_file):\n    df = pd.read_csv(csv_file)\n    df['list'] = df['list'].apply(ast.literal_eval)\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(lambda x: np.mean(x))\n    df['std'] = df['list'].apply(lambda x: np.std(x))\n    plot = sns.histplot(df['mean'], kde=False)\n    return df, plot", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport ast\n\ndef task_func(csv_file):\n    df = pd.read_csv(csv_file)\n    df['list'] = df['list'].apply(ast.literal_eval)\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(lambda x: np.mean(x))\n    df['std'] = df['list'].apply(lambda x: np.std(x))\n    plot = sns.histplot(df['mean'], kde=False)\n    return df, plot\n```"}
{"task_id": "BigCodeBench/72", "solution": "import pandas as pd\nimport os\nimport numpy as np\nimport ast\nimport matplotlib.pyplot as plt\ndef task_func(directory):\n    # Initialize variables\n    max_len = 0\n    max_file = None\n    # Traverse directory for CSV files\n    for file in os.listdir(directory):\n        if file.endswith('.csv'):\n            if len(file) > max_len:\n                max_len = len(file)\n                max_file = file\n    # If no CSV file found, return empty dataframe\n    if max_file is None:\n        return pd.DataFrame(columns=['email', 'list', 'sum', 'mean', 'median'])\n    # Load CSV file\n    df = pd.read_csv(os.path.join(directory, max_file))\n    # Convert 'list' column to list\n    df['list'] = df['list'].apply(ast.literal_eval)\n    # Calculate sum, mean and median\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(lambda x: np.mean(x))\n    df['median'] = df['list'].apply(lambda x: np.median(x))\n    # Draw histogram of median\n    plt.figure(figsize=(10, 6))\n    plt.hist(df['median'], bins=10, color='skyblue', edgecolor='black')\n    plt.xlabel('Median')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Median')\n    plt.grid(True)\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nimport os\nimport numpy as np\nimport ast\nimport matplotlib.pyplot as plt\n\ndef task_func(directory):\n    # Initialize variables\n    max_len = 0\n    max_file = None\n    # Traverse directory for CSV files\n    for file in os.listdir(directory):\n        if file.endswith('.csv'):\n            if len(file) > max_len:\n                max_len = len(file)\n                max_file = file\n    # If no CSV file found, return empty dataframe\n    if max_file is None:\n        return pd.DataFrame(columns=['email', 'list', 'sum', 'mean', 'median'])\n    # Load CSV file\n    df = pd.read_csv(os.path.join(directory, max_file))\n    # Convert 'list' column to list\n    df['list'] = df['list'].apply(ast.literal_eval)\n    # Calculate sum, mean and median\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(lambda x: np.mean(x))\n    df['median'] = df['list'].apply(lambda x: np.median(x))\n    # Draw histogram of median\n    plt.figure(figsize=(10, 6))\n    plt.hist(df['median'], bins=10, color='skyblue', edgecolor='black')\n    plt.xlabel('Median')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Median')\n    plt.grid(True)\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/73", "solution": "import pandas as pd\nimport sqlite3\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ast\ndef task_func(db_file):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_file)\n\n    # Query the database to get the email data\n    query = \"SELECT email, list FROM EmailData\"\n    df = pd.read_sql_query(query, conn)\n\n    # Convert the 'list' column to a list of integers\n    df['list'] = df['list'].apply(ast.literal_eval)\n\n    # Calculate the sum, mean, and variance for each email\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['var'] = df['list'].apply(np.var)\n\n    # Plot the sum, mean, and variance\n    fig, ax = plt.subplots()\n    df.plot(x='email', y=['sum', 'mean', 'var'], kind='bar', ax=ax)\n    ax.set_xlabel('Email')\n    ax.set_ylabel('Value')\n    ax.legend(loc='upper left')\n\n    # Close the database connection\n    conn.close()\n\n    return df, ax", "raw_solution": "import pandas as pd\nimport sqlite3\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ast\n\ndef task_func(db_file):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_file)\n\n    # Query the database to get the email data\n    query = \"SELECT email, list FROM EmailData\"\n    df = pd.read_sql_query(query, conn)\n\n    # Convert the 'list' column to a list of integers\n    df['list'] = df['list'].apply(ast.literal_eval)\n\n    # Calculate the sum, mean, and variance for each email\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['var'] = df['list'].apply(np.var)\n\n    # Plot the sum, mean, and variance\n    fig, ax = plt.subplots()\n    df.plot(x='email', y=['sum', 'mean', 'var'], kind='bar', ax=ax)\n    ax.set_xlabel('Email')\n    ax.set_ylabel('Value')\n    ax.legend(loc='upper left')\n\n    # Close the database connection\n    conn.close()\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/74", "solution": "import socket\nimport requests\ndef task_func(host):\n    if host is None or host == '':\n        raise ValueError(\"Host cannot be None or an empty string\")\n    try:\n        ip_address = socket.gethostbyname(host)\n    except socket.gaierror:\n        raise ConnectionError(\"Failed to resolve hostname\")\n    try:\n        response = requests.get(f\"https://ipinfo.io/{ip_address}\")\n        response.raise_for_status()\n    except requests.exceptions.RequestException:\n        raise ConnectionError(\"Failed to connect to geolocation service\")\n    return response.json()", "raw_solution": "import socket\nimport requests\n\ndef task_func(host):\n    if host is None or host == '':\n        raise ValueError(\"Host cannot be None or an empty string\")\n    try:\n        ip_address = socket.gethostbyname(host)\n    except socket.gaierror:\n        raise ConnectionError(\"Failed to resolve hostname\")\n    try:\n        response = requests.get(f\"https://ipinfo.io/{ip_address}\")\n        response.raise_for_status()\n    except requests.exceptions.RequestException:\n        raise ConnectionError(\"Failed to connect to geolocation service\")\n    return response.json()\n```"}
{"task_id": "BigCodeBench/75", "solution": "import pandas as pd\nimport numpy as np\nimport itertools\nfrom datetime import datetime, timedelta\nimport seaborn as sns\ndef task_func(df, fruits=None, days=None, seed=None, sales_lower_bound=1, sales_upper_bound=50):\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"'df' must be a pandas DataFrame\")\n    if not df.empty:\n        raise ValueError(\"'df' must be empty\")\n    if not fruits:\n        raise ValueError(\"'fruits' must be specified\")\n    if not days:\n        raise ValueError(\"'days' must be specified\")\n    if not seed:\n        raise ValueError(\"'seed' must be specified\")\n    if not isinstance(sales_lower_bound, int) or not isinstance(sales_upper_bound, int):\n        raise ValueError(\"'sales_lower_bound' and 'sales_upper_bound' must be integers\")\n    if sales_lower_bound >= sales_upper_bound:\n        raise ValueError(\"'sales_lower_bound' must be less than 'sales_upper_bound'\")\n\n    np.random.seed(seed)\n    dates = pd.date_range(start=datetime.now(), periods=days)\n    df = pd.DataFrame(dates, columns=['Date'])\n    df['Fruit'] = np.random.choice(fruits, size=days)\n    df['Sales'] = np.random.randint(sales_lower_bound, sales_upper_bound, size=days)\n\n    g = sns.boxplot(x=\"Fruit\", y=\"Sales\", data=df)\n    return df, g", "raw_solution": "import pandas as pd\nimport numpy as np\nimport itertools\nfrom datetime import datetime, timedelta\nimport seaborn as sns\n\ndef task_func(df, fruits=None, days=None, seed=None, sales_lower_bound=1, sales_upper_bound=50):\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"'df' must be a pandas DataFrame\")\n    if not df.empty:\n        raise ValueError(\"'df' must be empty\")\n    if not fruits:\n        raise ValueError(\"'fruits' must be specified\")\n    if not days:\n        raise ValueError(\"'days' must be specified\")\n    if not seed:\n        raise ValueError(\"'seed' must be specified\")\n    if not isinstance(sales_lower_bound, int) or not isinstance(sales_upper_bound, int):\n        raise ValueError(\"'sales_lower_bound' and 'sales_upper_bound' must be integers\")\n    if sales_lower_bound >= sales_upper_bound:\n        raise ValueError(\"'sales_lower_bound' must be less than 'sales_upper_bound'\")\n\n    np.random.seed(seed)\n    dates = pd.date_range(start=datetime.now(), periods=days)\n    df = pd.DataFrame(dates, columns=['Date'])\n    df['Fruit'] = np.random.choice(fruits, size=days)\n    df['Sales'] = np.random.randint(sales_lower_bound, sales_upper_bound, size=days)\n\n    g = sns.boxplot(x=\"Fruit\", y=\"Sales\", data=df)\n    return df, g\n```"}
{"task_id": "BigCodeBench/76", "solution": "import random\nimport string\nfrom django.http import HttpResponse\ndef task_func(request, session_expire_time):\n    if not session_expire_time:\n        raise ValueError(\"Session expire time is not provided\")\n\n    session_key = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(20))\n    response = HttpResponse(\"Session key generated successfully.\")\n    response.set_cookie('session_key', session_key, max_age=session_expire_time)\n    return response", "raw_solution": "import random\nimport string\nfrom django.http import HttpResponse\n\ndef task_func(request, session_expire_time):\n    if not session_expire_time:\n        raise ValueError(\"Session expire time is not provided\")\n\n    session_key = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(20))\n    response = HttpResponse(\"Session key generated successfully.\")\n    response.set_cookie('session_key', session_key, max_age=session_expire_time)\n    return response\n```"}
{"task_id": "BigCodeBench/77", "solution": "import hashlib\nimport base64\nimport binascii\nfrom django.http import HttpResponseBadRequest, HttpResponse\ndef task_func(data):\n    try:\n        username = data['username']\n        password = base64.b64decode(data['password'])\n    except KeyError:\n        return HttpResponseBadRequest('Bad Request.')\n    except (UnicodeDecodeError, binascii.Error, ValueError):\n        return HttpResponseBadRequest('Bad Request.')\n\n    if username == 'admin' and hashlib.sha256(password).hexdigest() == '5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8':\n        return HttpResponse(content='Login successful.', status=400)\n    else:\n        return HttpResponse(content='Login failed.', status=401)", "raw_solution": "import hashlib\nimport base64\nimport binascii\nfrom django.http import HttpResponseBadRequest, HttpResponse\n\ndef task_func(data):\n    try:\n        username = data['username']\n        password = base64.b64decode(data['password'])\n    except KeyError:\n        return HttpResponseBadRequest('Bad Request.')\n    except (UnicodeDecodeError, binascii.Error, ValueError):\n        return HttpResponseBadRequest('Bad Request.')\n\n    if username == 'admin' and hashlib.sha256(password).hexdigest() == '5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8':\n        return HttpResponse(content='Login successful.', status=400)\n    else:\n        return HttpResponse(content='Login failed.', status=401)"}
{"task_id": "BigCodeBench/78", "solution": "import csv\nimport io\nfrom django.http import HttpRequest, FileResponse\ndef task_func(request, header, csv_data):\n    response = HttpResponse(content_type='text/csv')\n    response['Content-Disposition'] = 'attachment; filename=\"file.csv\"'\n    writer = csv.writer(response)\n    writer.writerow(header)\n    for row in csv_data:\n        writer.writerow(row)\n    return response", "raw_solution": "import csv\nimport io\nfrom django.http import HttpRequest, FileResponse\n\ndef task_func(request, header, csv_data):\n    response = HttpResponse(content_type='text/csv')\n    response['Content-Disposition'] = 'attachment; filename=\"file.csv\"'\n    writer = csv.writer(response)\n    writer.writerow(header)\n    for row in csv_data:\n        writer.writerow(row)\n    return response\n```"}
{"task_id": "BigCodeBench/79", "solution": "import zipfile\nimport io\nfrom django.http import FileResponse, HttpRequest\nfrom django.conf import settings\ndef task_func(request, file_paths):\n    \"\"\"\n    Generates a ZIP file response for a Django HttpRequest, zipping the specified files.\n    This function is useful for scenarios where multiple file downloads are required in response to a web request.\n    The actual HttpRequest is not utilized within the function but is required for compatibility with Django view structures.\n    \"\"\"\n    # Create a BytesIO object to write the ZIP file to\n    zip_buffer = io.BytesIO()\n\n    # Create a ZIP file object\n    with zipfile.ZipFile(zip_buffer, \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n        # Loop through the file paths\n        for file_path in file_paths:\n            # Open the file and add it to the ZIP file\n            with open(file_path, \"rb\") as file:\n                zip_file.writestr(file_path, file.read())\n\n    # Reset the buffer position to the start\n    zip_buffer.seek(0)\n\n    # Create a FileResponse object with the ZIP file as the content\n    response = FileResponse(zip_buffer, content_type='application/zip')\n    response['Content-Disposition'] = 'attachment; filename=\"files.zip\"'\n\n    return response", "raw_solution": "import zipfile\nimport io\nfrom django.http import FileResponse, HttpRequest\nfrom django.conf import settings\n\ndef task_func(request, file_paths):\n    \"\"\"\n    Generates a ZIP file response for a Django HttpRequest, zipping the specified files.\n    This function is useful for scenarios where multiple file downloads are required in response to a web request.\n    The actual HttpRequest is not utilized within the function but is required for compatibility with Django view structures.\n    \"\"\"\n    # Create a BytesIO object to write the ZIP file to\n    zip_buffer = io.BytesIO()\n\n    # Create a ZIP file object\n    with zipfile.ZipFile(zip_buffer, \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n        # Loop through the file paths\n        for file_path in file_paths:\n            # Open the file and add it to the ZIP file\n            with open(file_path, \"rb\") as file:\n                zip_file.writestr(file_path, file.read())\n\n    # Reset the buffer position to the start\n    zip_buffer.seek(0)\n\n    # Create a FileResponse object with the ZIP file as the content\n    response = FileResponse(zip_buffer, content_type='application/zip')\n    response['Content-Disposition'] = 'attachment; filename=\"files.zip\"'\n\n    return response\n```"}
{"task_id": "BigCodeBench/80", "solution": "from flask import Flask, render_template, request\nimport json\nimport logging\ndef task_func(template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n\n    @app.route('/', methods=['POST'])\n    def root():\n        data = request.get_json()\n        logging.info(json.dumps(data))\n        return render_template('index.html', data=data)\n\n    return app", "raw_solution": "from flask import Flask, render_template, request\nimport json\nimport logging\nlogging.basicConfig(filename=\"out.log\", level=logging.INFO)\n\ndef task_func(template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n\n    @app.route('/', methods=['POST'])\n    def root():\n        data = request.get_json()\n        logging.info(json.dumps(data))\n        return render_template('index.html', data=data)\n\n    return app\n```"}
{"task_id": "BigCodeBench/81", "solution": "from flask import Flask\nfrom flask_restful import Resource, Api\nimport requests\ndef task_func(api_url, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    api = Api(app)\n\n    class ExternalApi(Resource):\n        def get(self):\n            response = requests.get(api_url)\n            return response.json()\n\n    api.add_resource(ExternalApi, '/api')\n\n    return app", "raw_solution": "from flask import Flask\nfrom flask_restful import Resource, Api\nimport requests\n\ndef task_func(api_url, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    api = Api(app)\n\n    class ExternalApi(Resource):\n        def get(self):\n            response = requests.get(api_url)\n            return response.json()\n\n    api.add_resource(ExternalApi, '/api')\n\n    return app\n```"}
{"task_id": "BigCodeBench/82", "solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\nclass LoginForm(FlaskForm):\n    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n    password = PasswordField('Password', validators=[DataRequired(), Length(min=8, max=80)])\n    submit = SubmitField('Log In')\nlogin_manager = LoginManager()\nclass User(UserMixin):\n    def __init__(self, username, password):\n        self.username = username\n        self.password = generate_password_hash(password)\n\n    def check_password(self, password):\n        return check_password_hash(self.password, password)\ndef create_app(secret_key, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    app.config['SECRET_KEY'] = secret_key\n    login_manager.init_app(app)\n    return app\ndef task_func(secret_key, template_folder):\n    app = create_app(secret_key, template_folder)\n\n    users = [User('admin', 'password')]\n\n    @app.route('/login', methods=['GET', 'POST'])\n    def login():\n        form = LoginForm()\n        if form.validate_on_submit():\n            user = load_user(form.username.data)\n            if user and user.check_password(form.password.data):\n                login_user(user)\n                return redirect(url_for('protected'))\n        return render_template('login.html', form=form)\n\n    @app.route('/logout')\n    @login_required\n    def logout():\n        logout_user()\n        return redirect(url_for('login'))\n\n    @app.route('/protected')\n    @login_required\n    def protected():\n        return render_template('protected.html')\n\n    return app", "raw_solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\n\nclass LoginForm(FlaskForm):\n    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n    password = PasswordField('Password', validators=[DataRequired(), Length(min=8, max=80)])\n    submit = SubmitField('Log In')\n\nlogin_manager = LoginManager()\n\nclass User(UserMixin):\n    def __init__(self, username, password):\n        self.username = username\n        self.password = generate_password_hash(password)\n\n    def check_password(self, password):\n        return check_password_hash(self.password, password)\n\n@login_manager.user_loader\ndef load_user(user_id):\n    for user in users:\n        if user.username == user_id:\n            return user\n    return None\n\ndef create_app(secret_key, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    app.config['SECRET_KEY'] = secret_key\n    login_manager.init_app(app)\n    return app\n\ndef task_func(secret_key, template_folder):\n    app = create_app(secret_key, template_folder)\n\n    users = [User('admin', 'password')]\n\n    @app.route('/login', methods=['GET', 'POST'])\n    def login():\n        form = LoginForm()\n        if form.validate_on_submit():\n            user = load_user(form.username.data)\n            if user and user.check_password(form.password.data):\n                login_user(user)\n                return redirect(url_for('protected'))\n        return render_template('login.html', form=form)\n\n    @app.route('/logout')\n    @login_required\n    def logout():\n        logout_user()\n        return redirect(url_for('login'))\n\n    @app.route('/protected')\n    @login_required\n    def protected():\n        return render_template('protected.html')\n\n    return app\n```"}
{"task_id": "BigCodeBench/83", "solution": "from flask import Flask\nfrom flask_mail import Mail, Message\ndef task_func(smtp_server, smtp_port, smtp_user, smtp_password, template_folder):\n    app = Flask(__name__)\n    app.config['MAIL_SERVER'] = smtp_server\n    app.config['MAIL_PORT'] = smtp_port\n    app.config['MAIL_USERNAME'] = smtp_user\n    app.config['MAIL_PASSWORD'] = smtp_password\n    app.config['MAIL_DEFAULT_SENDER'] = smtp_user\n    app.config['MAIL_USE_TLS'] = True\n    app.config['MAIL_USE_SSL'] = False\n    mail = Mail(app)\n\n    @app.route('/send_email')\n    def send_email():\n        msg = Message(\"Test Email\", recipients=[\"test@example.com\"])\n        msg.body = \"This is a test email.\"\n        mail.send(msg)\n        return \"Email sent successfully.\"\n\n    return app", "raw_solution": "from flask import Flask\nfrom flask_mail import Mail, Message\n\ndef task_func(smtp_server, smtp_port, smtp_user, smtp_password, template_folder):\n    app = Flask(__name__)\n    app.config['MAIL_SERVER'] = smtp_server\n    app.config['MAIL_PORT'] = smtp_port\n    app.config['MAIL_USERNAME'] = smtp_user\n    app.config['MAIL_PASSWORD'] = smtp_password\n    app.config['MAIL_DEFAULT_SENDER'] = smtp_user\n    app.config['MAIL_USE_TLS'] = True\n    app.config['MAIL_USE_SSL'] = False\n    mail = Mail(app)\n\n    @app.route('/send_email')\n    def send_email():\n        msg = Message(\"Test Email\", recipients=[\"test@example.com\"])\n        msg.body = \"This is a test email.\"\n        mail.send(msg)\n        return \"Email sent successfully.\"\n\n    return app\n```"}
{"task_id": "BigCodeBench/84", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(products, n_samples=100, sales_lower=50, sales_upper=200, profit_margin_min=0.1, profit_margin_max=0.5, random_seed=42):\n    if not isinstance(products, list) or not all(isinstance(product, str) for product in products):\n        raise TypeError(\"Products must be a list of strings\")\n    if not isinstance(n_samples, int) or n_samples <= 0:\n        raise ValueError(\"n_samples must be a positive integer\")\n    if not isinstance(sales_lower, (int, float)) or not isinstance(sales_upper, (int, float)) or sales_lower > sales_upper:\n        raise TypeError(\"sales_lower and sales_upper must be numeric and sales_lower must be less than or equal to sales_upper\")\n    if not isinstance(profit_margin_min, (int, float)) or not isinstance(profit_margin_max, (int, float)) or profit_margin_min > profit_margin_max:\n        raise TypeError(\"profit_margin_min and profit_margin_max must be numeric and profit_margin_min must be less than or equal to profit_margin_max\")\n\n    np.random.seed(random_seed)\n    sales = np.random.uniform(sales_lower, sales_upper, n_samples)\n    profit_margins = np.random.uniform(profit_margin_min, profit_margin_max, n_samples)\n    profits = sales * profit_margins\n\n    df = pd.DataFrame({\n        \"Product\": np.random.choice(products, n_samples),\n        \"Sales\": sales,\n        \"Profit Margin\": profit_margins,\n        \"Profit\": profits\n    })\n\n    df = df.groupby(\"Product\").sum().sort_values(\"Profit\", ascending=False)\n\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(products, n_samples=100, sales_lower=50, sales_upper=200, profit_margin_min=0.1, profit_margin_max=0.5, random_seed=42):\n    if not isinstance(products, list) or not all(isinstance(product, str) for product in products):\n        raise TypeError(\"Products must be a list of strings\")\n    if not isinstance(n_samples, int) or n_samples <= 0:\n        raise ValueError(\"n_samples must be a positive integer\")\n    if not isinstance(sales_lower, (int, float)) or not isinstance(sales_upper, (int, float)) or sales_lower > sales_upper:\n        raise TypeError(\"sales_lower and sales_upper must be numeric and sales_lower must be less than or equal to sales_upper\")\n    if not isinstance(profit_margin_min, (int, float)) or not isinstance(profit_margin_max, (int, float)) or profit_margin_min > profit_margin_max:\n        raise TypeError(\"profit_margin_min and profit_margin_max must be numeric and profit_margin_min must be less than or equal to profit_margin_max\")\n\n    np.random.seed(random_seed)\n    sales = np.random.uniform(sales_lower, sales_upper, n_samples)\n    profit_margins = np.random.uniform(profit_margin_min, profit_margin_max, n_samples)\n    profits = sales * profit_margins\n\n    df = pd.DataFrame({\n        \"Product\": np.random.choice(products, n_samples),\n        \"Sales\": sales,\n        \"Profit Margin\": profit_margins,\n        \"Profit\": profits\n    })\n\n    df = df.groupby(\"Product\").sum().sort_values(\"Profit\", ascending=False)\n\n    return df\n```"}
{"task_id": "BigCodeBench/85", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import timedelta\nimport matplotlib.pyplot as plt\ndef task_func(start_date, end_date, random_seed=42):\n    if end_date < start_date:\n        raise ValueError(\"Invalid date range\")\n\n    np.random.seed(random_seed)\n    date_range = pd.date_range(start=start_date, end=end_date)\n\n    temperature = np.random.uniform(-10, 40, size=len(date_range))\n    humidity = np.random.uniform(20, 100, size=len(date_range))\n    wind_speed = np.random.uniform(0, 20, size=len(date_range))\n\n    df = pd.DataFrame({\n        'Date': date_range,\n        'Temperature': temperature,\n        'Humidity': humidity,\n        'Wind Speed': wind_speed\n    })\n\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.plot(df['Date'], df['Temperature'], label='Temperature')\n    ax.plot(df['Date'], df['Humidity'], label='Humidity')\n    ax.plot(df['Date'], df['Wind Speed'], label='Wind Speed')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    return df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import timedelta\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date, end_date, random_seed=42):\n    if end_date < start_date:\n        raise ValueError(\"Invalid date range\")\n\n    np.random.seed(random_seed)\n    date_range = pd.date_range(start=start_date, end=end_date)\n\n    temperature = np.random.uniform(-10, 40, size=len(date_range))\n    humidity = np.random.uniform(20, 100, size=len(date_range))\n    wind_speed = np.random.uniform(0, 20, size=len(date_range))\n\n    df = pd.DataFrame({\n        'Date': date_range,\n        'Temperature': temperature,\n        'Humidity': humidity,\n        'Wind Speed': wind_speed\n    })\n\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.plot(df['Date'], df['Temperature'], label='Temperature')\n    ax.plot(df['Date'], df['Humidity'], label='Humidity')\n    ax.plot(df['Date'], df['Wind Speed'], label='Wind Speed')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/86", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(students=[\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"], seed=42):\n    np.random.seed(seed)\n    scores = np.random.randint(0, 100, len(students))\n    df = pd.DataFrame({\"Student\": students, \"Score\": scores})\n    df = df.sort_values(\"Score\")\n    ax = df.plot(x=\"Student\", y=\"Score\", kind=\"bar\", legend=False)\n    ax.set_xlabel(\"Student\")\n    ax.set_ylabel(\"Score\")\n    return df, ax.figure", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(students=[\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"], seed=42):\n    np.random.seed(seed)\n    scores = np.random.randint(0, 100, len(students))\n    df = pd.DataFrame({\"Student\": students, \"Score\": scores})\n    df = df.sort_values(\"Score\")\n    ax = df.plot(x=\"Student\", y=\"Score\", kind=\"bar\", legend=False)\n    ax.set_xlabel(\"Student\")\n    ax.set_ylabel(\"Score\")\n    return df, ax.figure\n```"}
{"task_id": "BigCodeBench/87", "solution": "import pandas as pd\nfrom random import choices, seed\ndef task_func(products, ratings, weights, random_seed=42):\n    seed(random_seed)\n    df = pd.DataFrame({'Product': products, 'Rating': choices(ratings, weights=weights, k=len(products))})\n    df.sort_values(by='Rating', ascending=False, inplace=True)\n    return df", "raw_solution": "import pandas as pd\nfrom random import choices, seed\n\ndef task_func(products, ratings, weights, random_seed=42):\n    seed(random_seed)\n    df = pd.DataFrame({'Product': products, 'Rating': choices(ratings, weights=weights, k=len(products))})\n    df.sort_values(by='Rating', ascending=False, inplace=True)\n    return df\n```"}
{"task_id": "BigCodeBench/88", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\ndef task_func(start_date, end_date, seed=42):\n    np.random.seed(seed)\n    date_range = pd.date_range(start=start_date, end=end_date)\n    sales_data = pd.DataFrame({\n        'Date': date_range,\n        'Sales': np.random.randint(0, 501, len(date_range))\n    })\n    fig, ax = plt.subplots()\n    sales_data.plot(x='Date', y='Sales', ax=ax)\n    ax.set_title('Sales Over Time')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    return sales_data, ax.figure", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date, end_date, seed=42):\n    np.random.seed(seed)\n    date_range = pd.date_range(start=start_date, end=end_date)\n    sales_data = pd.DataFrame({\n        'Date': date_range,\n        'Sales': np.random.randint(0, 501, len(date_range))\n    })\n    fig, ax = plt.subplots()\n    sales_data.plot(x='Date', y='Sales', ax=ax)\n    ax.set_title('Sales Over Time')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    return sales_data, ax.figure\n```"}
{"task_id": "BigCodeBench/89", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data, column, outlier_z_score):\n    # Standardize the column\n    scaler = StandardScaler()\n    data[column] = scaler.fit_transform(data[column].values.reshape(-1, 1))\n\n    # Calculate Z-scores\n    z_scores = np.abs(stats.zscore(data[column]))\n\n    # Identify outliers\n    outliers = np.where(z_scores > outlier_z_score)[0]\n\n    # Remove outliers\n    data_without_outliers = data.drop(outliers)\n\n    # Visualize data before and after outlier removal\n    plt.figure(figsize=(12, 6))\n\n    plt.subplot(1, 2, 1)\n    plt.scatter(range(len(data[column])), data[column])\n    plt.title('Data with Outliers')\n\n    plt.subplot(1, 2, 2)\n    plt.scatter(range(len(data_without_outliers[column])), data_without_outliers[column])\n    plt.title('Data without Outliers')\n\n    plt.tight_layout()\n    plt.show()\n\n    return (data, data_without_outliers, outliers)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data, column, outlier_z_score):\n    # Standardize the column\n    scaler = StandardScaler()\n    data[column] = scaler.fit_transform(data[column].values.reshape(-1, 1))\n\n    # Calculate Z-scores\n    z_scores = np.abs(stats.zscore(data[column]))\n\n    # Identify outliers\n    outliers = np.where(z_scores > outlier_z_score)[0]\n\n    # Remove outliers\n    data_without_outliers = data.drop(outliers)\n\n    # Visualize data before and after outlier removal\n    plt.figure(figsize=(12, 6))\n\n    plt.subplot(1, 2, 1)\n    plt.scatter(range(len(data[column])), data[column])\n    plt.title('Data with Outliers')\n\n    plt.subplot(1, 2, 2)\n    plt.scatter(range(len(data_without_outliers[column])), data_without_outliers[column])\n    plt.title('Data without Outliers')\n\n    plt.tight_layout()\n    plt.show()\n\n    return (data, data_without_outliers, outliers)\n```"}
{"task_id": "BigCodeBench/90", "solution": "import numpy as np\nimport math\ndef task_func(data, target, k):\n    if not isinstance(k, int) or k < 0:\n        raise ValueError(\"'k' must be a non-negative integer\")\n\n    def haversine_distance(lat1, lon1, lat2, lon2):\n        lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n        dlat = lat2 - lat1\n        dlon = lon2 - lon1\n        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n        distance = 6371 * c\n        return distance\n\n    distances = [haversine_distance(target[0], target[1], lat, lon) for lat, lon in data]\n    nearest_neighbors = sorted(range(len(distances)), key=lambda i: distances[i])[:k]\n    return [data[i] for i in nearest_neighbors]", "raw_solution": "import numpy as np\nimport math\n\ndef task_func(data, target, k):\n    if not isinstance(k, int) or k < 0:\n        raise ValueError(\"'k' must be a non-negative integer\")\n\n    def haversine_distance(lat1, lon1, lat2, lon2):\n        lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n        dlat = lat2 - lat1\n        dlon = lon2 - lon1\n        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n        distance = 6371 * c\n        return distance\n\n    distances = [haversine_distance(target[0], target[1], lat, lon) for lat, lon in data]\n    nearest_neighbors = sorted(range(len(distances)), key=lambda i: distances[i])[:k]\n    return [data[i] for i in nearest_neighbors]"}
{"task_id": "BigCodeBench/91", "solution": "from scipy.stats import linregress\nimport matplotlib.pyplot as plt\ndef task_func(data, column1, column2):\n    if column1 not in data.columns or column2 not in data.columns:\n        raise ValueError(\"Specified columns do not exist in the DataFrame\")\n\n    slope, intercept, r_value, p_value, std_err = linregress(data[column1], data[column2])\n\n    fig, ax = plt.subplots()\n    ax.scatter(data[column1], data[column2])\n    ax.plot(data[column1], intercept + slope * data[column1], color='red')\n    ax.set_xlabel(column1)\n    ax.set_ylabel(column2)\n    ax.set_title(f'Linear Regression: {column1} vs {column2}')\n\n    return (slope, intercept, r_value, p_value, std_err), ax", "raw_solution": "from scipy.stats import linregress\nimport matplotlib.pyplot as plt\n\ndef task_func(data, column1, column2):\n    if column1 not in data.columns or column2 not in data.columns:\n        raise ValueError(\"Specified columns do not exist in the DataFrame\")\n\n    slope, intercept, r_value, p_value, std_err = linregress(data[column1], data[column2])\n\n    fig, ax = plt.subplots()\n    ax.scatter(data[column1], data[column2])\n    ax.plot(data[column1], intercept + slope * data[column1], color='red')\n    ax.set_xlabel(column1)\n    ax.set_ylabel(column2)\n    ax.set_title(f'Linear Regression: {column1} vs {column2}')\n\n    return (slope, intercept, r_value, p_value, std_err), ax\n```"}
{"task_id": "BigCodeBench/92", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.collections import PathCollection\ndef task_func(data, n_clusters=3):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' must be a pandas DataFrame\")\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"'n_clusters' must be an integer greater than 1\")\n\n    kmeans = KMeans(n_clusters=n_clusters)\n    kmeans.fit(data)\n\n    labels = kmeans.labels_\n\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels)\n    ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n\n    return labels, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.collections import PathCollection\n\ndef task_func(data, n_clusters=3):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' must be a pandas DataFrame\")\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"'n_clusters' must be an integer greater than 1\")\n\n    kmeans = KMeans(n_clusters=n_clusters)\n    kmeans.fit(data)\n\n    labels = kmeans.labels_\n\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels)\n    ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n\n    return labels, ax\n```"}
{"task_id": "BigCodeBench/93", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(data, n_components=2):\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError(\"n_components must be a positive integer\")\n\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n\n    transformed_df = pd.DataFrame(transformed_data, columns=[f\"PC{i+1}\" for i in range(n_components)])\n\n    fig, ax = plt.subplots()\n    ax.scatter(transformed_df.iloc[:, 0], transformed_df.iloc[:, 1])\n    ax.set_xlabel(f\"PC1\")\n    ax.set_ylabel(f\"PC2\")\n    ax.set_title(f\"PCA Scatter Plot\")\n\n    return transformed_df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError(\"n_components must be a positive integer\")\n\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n\n    transformed_df = pd.DataFrame(transformed_data, columns=[f\"PC{i+1}\" for i in range(n_components)])\n\n    fig, ax = plt.subplots()\n    ax.scatter(transformed_df.iloc[:, 0], transformed_df.iloc[:, 1])\n    ax.set_xlabel(f\"PC1\")\n    ax.set_ylabel(f\"PC2\")\n    ax.set_title(f\"PCA Scatter Plot\")\n\n    return transformed_df, ax\n```"}
{"task_id": "BigCodeBench/94", "solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(mean, std_dev, num_samples):\n    np.random.seed(0)\n    samples = np.random.normal(mean, std_dev, num_samples)\n\n    fig, ax = plt.subplots()\n    ax.hist(samples, bins=30, density=True, color='skyblue', edgecolor='black')\n\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mean, std_dev)\n    ax.plot(x, p, 'k', linewidth=2)\n\n    title = \"Fit results: mean = %.2f, std = %.2f\" % (mean, std_dev)\n    plt.title(title)\n\n    return fig, samples", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(mean, std_dev, num_samples):\n    np.random.seed(0)\n    samples = np.random.normal(mean, std_dev, num_samples)\n\n    fig, ax = plt.subplots()\n    ax.hist(samples, bins=30, density=True, color='skyblue', edgecolor='black')\n\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mean, std_dev)\n    ax.plot(x, p, 'k', linewidth=2)\n\n    title = \"Fit results: mean = %.2f, std = %.2f\" % (mean, std_dev)\n    plt.title(title)\n\n    return fig, samples\n```"}
{"task_id": "BigCodeBench/95", "solution": "import pandas as pd\nfrom random import randint, uniform, seed\ndef task_func(categories=None, months=None, random_seed=42):\n    if not categories or not months:\n        raise ValueError(\"Both 'categories' and 'months' must be provided as lists.\")\n    if not categories or not months:\n        raise ValueError(\"Both 'categories' and 'months' must not be empty lists.\")\n    seed(random_seed)\n    data = []\n    for category in categories:\n        for month in months:\n            sales = randint(100, 500) + uniform(0, 1)\n            data.append([month, category, sales])\n    df = pd.DataFrame(data, columns=['Month', 'Category', 'Sales'])\n    return df", "raw_solution": "import pandas as pd\nfrom random import randint, uniform, seed\n\ndef task_func(categories=None, months=None, random_seed=42):\n    if not categories or not months:\n        raise ValueError(\"Both 'categories' and 'months' must be provided as lists.\")\n    if not categories or not months:\n        raise ValueError(\"Both 'categories' and 'months' must not be empty lists.\")\n    seed(random_seed)\n    data = []\n    for category in categories:\n        for month in months:\n            sales = randint(100, 500) + uniform(0, 1)\n            data.append([month, category, sales])\n    df = pd.DataFrame(data, columns=['Month', 'Category', 'Sales'])\n    return df\n```"}
{"task_id": "BigCodeBench/96", "solution": "import csv\nfrom collections import Counter\nimport operator\ndef task_func(csv_file, csv_delimiter):\n    with open(csv_file, 'r') as file:\n        reader = csv.reader(file, delimiter=csv_delimiter)\n        words = [word for row in reader for word in row]\n    word_count = Counter(words)\n    return sorted(word_count.items(), key=operator.itemgetter(1), reverse=True)", "raw_solution": "import csv\nfrom collections import Counter\nimport operator\n\ndef task_func(csv_file, csv_delimiter):\n    with open(csv_file, 'r') as file:\n        reader = csv.reader(file, delimiter=csv_delimiter)\n        words = [word for row in reader for word in row]\n    word_count = Counter(words)\n    return sorted(word_count.items(), key=operator.itemgetter(1), reverse=True)\n```"}
{"task_id": "BigCodeBench/97", "solution": "import math\nimport itertools\nfrom functools import reduce\ndef task_func(numbers):\n    result = 0\n    for r in range(1, len(numbers) + 1):\n        for combination in itertools.combinations(numbers, r):\n            product = reduce(lambda x, y: x * y, combination)\n            result += math.log(product)\n    return result", "raw_solution": "import math\nimport itertools\nfrom functools import reduce\n\ndef task_func(numbers):\n    result = 0\n    for r in range(1, len(numbers) + 1):\n        for combination in itertools.combinations(numbers, r):\n            product = reduce(lambda x, y: x * y, combination)\n            result += math.log(product)\n    return result\n```"}
{"task_id": "BigCodeBench/98", "solution": "import random\nimport string\nfrom collections import Counter\ndef task_func(num_strings, string_length):\n    random_strings = [''.join(random.choices(string.ascii_lowercase, k=string_length)) for _ in range(num_strings)]\n    char_freq = Counter(''.join(random_strings))\n    return sorted(char_freq.items(), key=lambda x: x[1], reverse=True)", "raw_solution": "import random\nimport string\nfrom collections import Counter\n\ndef task_func(num_strings, string_length):\n    random_strings = [''.join(random.choices(string.ascii_lowercase, k=string_length)) for _ in range(num_strings)]\n    char_freq = Counter(''.join(random_strings))\n    return sorted(char_freq.items(), key=lambda x: x[1], reverse=True)\n```"}
{"task_id": "BigCodeBench/99", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\ndef task_func():\n    iris = load_iris()\n    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    df['species'] = iris.target\n    sns.set(font='Arial')\n    g = sns.pairplot(df, hue='species', diag_kind='kde', plot_kws={'alpha': 0.6, 's': 80, 'edgecolor': 'k'})\n    g.fig.suptitle(\"Iris Dataset Pair Plot\", y=1.03)\n    return g.fig", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\n\ndef task_func():\n    iris = load_iris()\n    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    df['species'] = iris.target\n    sns.set(font='Arial')\n    g = sns.pairplot(df, hue='species', diag_kind='kde', plot_kws={'alpha': 0.6, 's': 80, 'edgecolor': 'k'})\n    g.fig.suptitle(\"Iris Dataset Pair Plot\", y=1.03)\n    return g.fig\n```"}
{"task_id": "BigCodeBench/100", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\ndef task_func(seed=42):\n    try:\n        random.seed(seed)\n        dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(30)]\n        values = [random.randint(1, 100) for _ in range(30)]\n        df = pd.DataFrame({'Date': dates, 'Value': values})\n        df['Date'] = pd.to_datetime(df['Date'])\n        df.set_index('Date', inplace=True)\n        plt.figure(figsize=(10, 5))\n        plt.plot(df.index, df['Value'])\n        plt.xlabel('Date')\n        plt.ylabel('Value')\n        plt.title('Random Time Series Data')\n        plt.xticks(rotation=45)\n        plt.grid(True)\n        plt.tight_layout()\n        plt.style.use('seaborn-whitegrid')\n        plt.rcParams['font.family'] = 'Arial'\n        return plt.gca()\n    except Exception as e:\n        raise ValueError(f\"Error generating data or plot: {e}\")", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\n\ndef task_func(seed=42):\n    try:\n        random.seed(seed)\n        dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(30)]\n        values = [random.randint(1, 100) for _ in range(30)]\n        df = pd.DataFrame({'Date': dates, 'Value': values})\n        df['Date'] = pd.to_datetime(df['Date'])\n        df.set_index('Date', inplace=True)\n        plt.figure(figsize=(10, 5))\n        plt.plot(df.index, df['Value'])\n        plt.xlabel('Date')\n        plt.ylabel('Value')\n        plt.title('Random Time Series Data')\n        plt.xticks(rotation=45)\n        plt.grid(True)\n        plt.tight_layout()\n        plt.style.use('seaborn-whitegrid')\n        plt.rcParams['font.family'] = 'Arial'\n        return plt.gca()\n    except Exception as e:\n        raise ValueError(f\"Error generating data or plot: {e}\")\n```"}
{"task_id": "BigCodeBench/101", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n    np.random.seed(seed)\n    try:\n        data = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n        data.columns = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n        correlation_matrix = data.corr()\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n        plt.title(\"Correlation Heatmap of Boston Housing Dataset\")\n        plt.show()\n    except Exception as e:\n        raise ValueError(f\"Error in generating or saving the plot: {e}\")", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n    np.random.seed(seed)\n    try:\n        data = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n        data.columns = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n        correlation_matrix = data.corr()\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n        plt.title(\"Correlation Heatmap of Boston Housing Dataset\")\n        plt.show()\n    except Exception as e:\n        raise ValueError(f\"Error in generating or saving the plot: {e}\")\n```"}
{"task_id": "BigCodeBench/102", "solution": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.datasets import load_diabetes\ndef task_func():\n    # Load the diabetes dataset\n    diabetes = load_diabetes()\n    df = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)\n    df['target'] = diabetes.target\n\n    # Set the font to Arial\n    plt.rcParams['font.family'] = 'Arial'\n\n    # Create a pairplot\n    pairplot = sns.pairplot(df)\n\n    return pairplot, df", "raw_solution": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.datasets import load_diabetes\n\ndef task_func():\n    # Load the diabetes dataset\n    diabetes = load_diabetes()\n    df = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)\n    df['target'] = diabetes.target\n\n    # Set the font to Arial\n    plt.rcParams['font.family'] = 'Arial'\n\n    # Create a pairplot\n    pairplot = sns.pairplot(df)\n\n    return pairplot, df\n```"}
{"task_id": "BigCodeBench/103", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(temperatures):\n    if not isinstance(temperatures, pd.DataFrame):\n        raise ValueError(\"Input DataFrame is not in the expected format.\")\n    if temperatures.empty:\n        raise ValueError(\"Input DataFrame is empty.\")\n    if 'Date' not in temperatures.columns or 'Temperature' not in temperatures.columns:\n        raise ValueError(\"Input DataFrame does not contain the expected columns.\")\n    temperatures['Date'] = pd.to_datetime(temperatures['Date'])\n    temperatures.set_index('Date', inplace=True)\n    plt.figure(figsize=(10, 6))\n    plt.plot(temperatures['Temperature'])\n    plt.xlabel('Date', fontsize=14, fontname='Arial')\n    plt.ylabel('Temperature (\u00b0C)', fontsize=14, fontname='Arial')\n    plt.title('Daily Temperatures in New York', fontsize=16, fontname='Arial')\n    plt.grid(True)\n    return plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(temperatures):\n    if not isinstance(temperatures, pd.DataFrame):\n        raise ValueError(\"Input DataFrame is not in the expected format.\")\n    if temperatures.empty:\n        raise ValueError(\"Input DataFrame is empty.\")\n    if 'Date' not in temperatures.columns or 'Temperature' not in temperatures.columns:\n        raise ValueError(\"Input DataFrame does not contain the expected columns.\")\n    temperatures['Date'] = pd.to_datetime(temperatures['Date'])\n    temperatures.set_index('Date', inplace=True)\n    plt.figure(figsize=(10, 6))\n    plt.plot(temperatures['Temperature'])\n    plt.xlabel('Date', fontsize=14, fontname='Arial')\n    plt.ylabel('Temperature (\u00b0C)', fontsize=14, fontname='Arial')\n    plt.title('Daily Temperatures in New York', fontsize=16, fontname='Arial')\n    plt.grid(True)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/104", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\ndef task_func(df, groups=['A', 'B', 'C', 'D', 'E']):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' must be a pandas DataFrame\")\n    if 'Date' not in df.columns or 'Value' not in df.columns or 'Group' not in df.columns:\n        raise ValueError(\"'df' must contain columns 'Date', 'Value', and 'Group'\")\n    if not set(df['Group']).issubset(set(groups)):\n        raise ValueError(\"'df' contains unknown groups\")\n\n    colors = cycle('rgbcmyk')\n    fig, ax = plt.subplots()\n    for group, color in zip(groups, colors):\n        df_group = df[df['Group'] == group]\n        ax.scatter(df_group['Date'], df_group['Value'], color=color, label=group)\n\n    ax.set_title('Scatterplot of Values for Each Group Over Time')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\n\ndef task_func(df, groups=['A', 'B', 'C', 'D', 'E']):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' must be a pandas DataFrame\")\n    if 'Date' not in df.columns or 'Value' not in df.columns or 'Group' not in df.columns:\n        raise ValueError(\"'df' must contain columns 'Date', 'Value', and 'Group'\")\n    if not set(df['Group']).issubset(set(groups)):\n        raise ValueError(\"'df' contains unknown groups\")\n\n    colors = cycle('rgbcmyk')\n    fig, ax = plt.subplots()\n    for group, color in zip(groups, colors):\n        df_group = df[df['Group'] == group]\n        ax.scatter(df_group['Date'], df_group['Value'], color=color, label=group)\n\n    ax.set_title('Scatterplot of Values for Each Group Over Time')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    return ax\n```"}
{"task_id": "BigCodeBench/105", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"Dataframe is empty\")\n    if 'date' not in df.columns:\n        raise ValueError(\"'date' column is missing\")\n    try:\n        df['date'] = pd.to_datetime(df['date'])\n    except ValueError:\n        raise ValueError(\"'date' column is not in datetime format\")\n    df['date'] = df['date'].map(datetime.datetime.toordinal)\n    correlation_matrix = df.corr()\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n    plt.title('Correlation Matrix')\n    plt.show()\n    pair_grid = sns.pairplot(df)\n    return pair_grid", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"Dataframe is empty\")\n    if 'date' not in df.columns:\n        raise ValueError(\"'date' column is missing\")\n    try:\n        df['date'] = pd.to_datetime(df['date'])\n    except ValueError:\n        raise ValueError(\"'date' column is not in datetime format\")\n    df['date'] = df['date'].map(datetime.datetime.toordinal)\n    correlation_matrix = df.corr()\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n    plt.title('Correlation Matrix')\n    plt.show()\n    pair_grid = sns.pairplot(df)\n    return pair_grid\n```"}
{"task_id": "BigCodeBench/106", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a valid DataFrame\")\n    if 'date' not in df.columns or 'value' not in df.columns:\n        raise ValueError(\"DataFrame lacks the required columns\")\n    if df['date'].dtype != 'datetime64[ns]':\n        raise ValueError(\"'date' column is not in datetime format\")\n\n    df['date'] = df['date'].map(dt.datetime.toordinal)\n\n    X = df['date'].values.reshape(-1, 1)\n    y = df['value'].values.reshape(-1, 1)\n\n    model = LinearRegression()\n    model.fit(X, y)\n\n    predictions = model.predict(X)\n\n    fig, ax = plt.subplots()\n    ax.scatter(X, y, color='blue')\n    ax.plot(X, predictions, color='red')\n    ax.set_title('Value vs Date (Linear Regression Prediction)')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n\n    return model, predictions, ax", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a valid DataFrame\")\n    if 'date' not in df.columns or 'value' not in df.columns:\n        raise ValueError(\"DataFrame lacks the required columns\")\n    if df['date'].dtype != 'datetime64[ns]':\n        raise ValueError(\"'date' column is not in datetime format\")\n\n    df['date'] = df['date'].map(dt.datetime.toordinal)\n\n    X = df['date'].values.reshape(-1, 1)\n    y = df['value'].values.reshape(-1, 1)\n\n    model = LinearRegression()\n    model.fit(X, y)\n\n    predictions = model.predict(X)\n\n    fig, ax = plt.subplots()\n    ax.scatter(X, y, color='blue')\n    ax.plot(X, predictions, color='red')\n    ax.set_title('Value vs Date (Linear Regression Prediction)')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n\n    return model, predictions, ax\n```"}
{"task_id": "BigCodeBench/107", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(df, n_clusters=3, random_state=0):\n    if df.empty or 'date' not in df.columns or 'value' not in df.columns:\n        raise ValueError(\"DataFrame is empty or lacks required columns\")\n\n    df['date'] = df['date'].map(dt.datetime.toordinal)\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(df[['date', 'value']])\n\n    plt.scatter(df['date'], df['value'], c=kmeans.labels_)\n    plt.xlabel('Date (ordinal)')\n    plt.ylabel('Value')\n    plt.title('KMeans Clustering of Value vs Date')\n    plt.show()\n\n    return plt.gca()", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(df, n_clusters=3, random_state=0):\n    if df.empty or 'date' not in df.columns or 'value' not in df.columns:\n        raise ValueError(\"DataFrame is empty or lacks required columns\")\n\n    df['date'] = df['date'].map(dt.datetime.toordinal)\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(df[['date', 'value']])\n\n    plt.scatter(df['date'], df['value'], c=kmeans.labels_)\n    plt.xlabel('Date (ordinal)')\n    plt.ylabel('Value')\n    plt.title('KMeans Clustering of Value vs Date')\n    plt.show()\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/108", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' must be a pandas DataFrame\")\n    if 'value' not in df.columns:\n        raise ValueError(\"'df' must contain a 'value' column\")\n    if not isinstance(freq, str):\n        raise ValueError(\"'freq' must be a string\")\n    if decomposition_model not in ['additive', 'multiplicative']:\n        raise ValueError(\"'decomposition_model' must be 'additive' or 'multiplicative'\")\n    if not df['value'].apply(lambda x: isinstance(x, (int, float))).all():\n        raise ValueError(\"'value' column must contain numeric data\")\n\n    result = seasonal_decompose(df['value'], model=decomposition_model, freq=freq)\n\n    fig, ax = plt.subplots(4, 1, figsize=(10, 10))\n    result.trend.plot(ax=ax[0])\n    ax[0].set_title('Trend')\n    result.seasonal.plot(ax=ax[1])\n    ax[1].set_title('Seasonality')\n    result.resid.plot(ax=ax[2])\n    ax[2].set_title('Residuals')\n    plt.tight_layout()\n\n    return (result, ax)", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' must be a pandas DataFrame\")\n    if 'value' not in df.columns:\n        raise ValueError(\"'df' must contain a 'value' column\")\n    if not isinstance(freq, str):\n        raise ValueError(\"'freq' must be a string\")\n    if decomposition_model not in ['additive', 'multiplicative']:\n        raise ValueError(\"'decomposition_model' must be 'additive' or 'multiplicative'\")\n    if not df['value'].apply(lambda x: isinstance(x, (int, float))).all():\n        raise ValueError(\"'value' column must contain numeric data\")\n\n    result = seasonal_decompose(df['value'], model=decomposition_model, freq=freq)\n\n    fig, ax = plt.subplots(4, 1, figsize=(10, 10))\n    result.trend.plot(ax=ax[0])\n    ax[0].set_title('Trend')\n    result.seasonal.plot(ax=ax[1])\n    ax[1].set_title('Seasonality')\n    result.resid.plot(ax=ax[2])\n    ax[2].set_title('Residuals')\n    plt.tight_layout()\n\n    return (result, ax)\n```"}
{"task_id": "BigCodeBench/109", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, items=None, locations=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' must be a pandas DataFrame\")\n    if 'Item' not in df.columns or 'Location' not in df.columns:\n        raise ValueError(\"'df' must contain 'Item' and 'Location' columns\")\n\n    if items is not None:\n        df = df[df['Item'].isin(items)]\n    if locations is not None:\n        df = df[df['Location'].isin(locations)]\n\n    item_counts = df['Item'].value_counts()\n    location_counts = df['Location'].value_counts()\n\n    fig, ax = plt.subplots()\n    ax.bar(item_counts.index, item_counts.values, label='Items')\n    ax.bar(location_counts.index, location_counts.values, label='Locations')\n    ax.legend()\n    plt.show()\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, items=None, locations=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' must be a pandas DataFrame\")\n    if 'Item' not in df.columns or 'Location' not in df.columns:\n        raise ValueError(\"'df' must contain 'Item' and 'Location' columns\")\n\n    if items is not None:\n        df = df[df['Item'].isin(items)]\n    if locations is not None:\n        df = df[df['Location'].isin(locations)]\n\n    item_counts = df['Item'].value_counts()\n    location_counts = df['Location'].value_counts()\n\n    fig, ax = plt.subplots()\n    ax.bar(item_counts.index, item_counts.values, label='Items')\n    ax.bar(location_counts.index, location_counts.values, label='Locations')\n    ax.legend()\n    plt.show()\n    return ax\n```"}
{"task_id": "BigCodeBench/110", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n    if 'Date' not in df.columns or 'Sales' not in df.columns:\n        raise ValueError(\"'df' lacks 'Date' or 'Sales' columns\")\n    if df.empty:\n        raise ValueError(\"'df' has no data to plot\")\n\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n\n    ax = df['Sales'].plot(kind='line', title='Daily Turnover')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n    if 'Date' not in df.columns or 'Sales' not in df.columns:\n        raise ValueError(\"'df' lacks 'Date' or 'Sales' columns\")\n    if df.empty:\n        raise ValueError(\"'df' has no data to plot\")\n\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n\n    ax = df['Sales'].plot(kind='line', title='Daily Turnover')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/111", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n    if not all(col in df.columns for col in ['Date', 'Time', 'Temperature']):\n        raise ValueError(\"'df' lacks 'Date', 'Time', or 'Temperature' columns\")\n\n    df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n    df.set_index('DateTime', inplace=True)\n    df.drop(['Date', 'Time'], axis=1, inplace=True)\n\n    df = df.resample('1H').mean()\n\n    plt.figure(figsize=(10, 6))\n    heatmap = sns.heatmap(df, cmap='coolwarm')\n    plt.title('Temperature Heatmap')\n    plt.xlabel('Time')\n    plt.ylabel('Date')\n    plt.show()\n\n    return heatmap", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n    if not all(col in df.columns for col in ['Date', 'Time', 'Temperature']):\n        raise ValueError(\"'df' lacks 'Date', 'Time', or 'Temperature' columns\")\n\n    df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n    df.set_index('DateTime', inplace=True)\n    df.drop(['Date', 'Time'], axis=1, inplace=True)\n\n    df = df.resample('1H').mean()\n\n    plt.figure(figsize=(10, 6))\n    heatmap = sns.heatmap(df, cmap='coolwarm')\n    plt.title('Temperature Heatmap')\n    plt.xlabel('Time')\n    plt.ylabel('Date')\n    plt.show()\n\n    return heatmap\n```"}
{"task_id": "BigCodeBench/112", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a pandas DataFrame\")\n    if 'Status' not in df.columns:\n        raise ValueError(\"DataFrame does not contain the 'Status' column\")\n\n    status_counts = df['Status'].value_counts()\n    fig, ax = plt.subplots()\n    ax.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', startangle=140)\n    ax.axis('equal')\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a pandas DataFrame\")\n    if 'Status' not in df.columns:\n        raise ValueError(\"DataFrame does not contain the 'Status' column\")\n\n    status_counts = df['Status'].value_counts()\n    fig, ax = plt.subplots()\n    ax.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', startangle=140)\n    ax.axis('equal')\n    return ax\n```"}
{"task_id": "BigCodeBench/113", "solution": "import json\nfrom collections import Counter\nimport random\nimport os\ndef task_func(my_dict, keys):\n    if len(set(keys)) != 10:\n        raise ValueError(\"'keys' must contain exactly 10 unique elements\")\n\n    for key in keys:\n        if key in my_dict:\n            my_dict[key] += 1\n        else:\n            my_dict[key] = 1\n\n    with open('updated_dictionary.json', 'w') as json_file:\n        json.dump(my_dict, json_file)\n\n    with open('key_frequencies.txt', 'w') as txt_file:\n        for key, count in my_dict.items():\n            txt_file.write(f\"{key}: {count}\\n\")\n\n    return (my_dict, 'updated_dictionary.json', 'key_frequencies.txt')", "raw_solution": "import json\nfrom collections import Counter\nimport random\nimport os\n\ndef task_func(my_dict, keys):\n    if len(set(keys)) != 10:\n        raise ValueError(\"'keys' must contain exactly 10 unique elements\")\n\n    for key in keys:\n        if key in my_dict:\n            my_dict[key] += 1\n        else:\n            my_dict[key] = 1\n\n    with open('updated_dictionary.json', 'w') as json_file:\n        json.dump(my_dict, json_file)\n\n    with open('key_frequencies.txt', 'w') as txt_file:\n        for key, count in my_dict.items():\n            txt_file.write(f\"{key}: {count}\\n\")\n\n    return (my_dict, 'updated_dictionary.json', 'key_frequencies.txt')\n```"}
{"task_id": "BigCodeBench/114", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(my_dict):\n    if 'array' not in my_dict:\n        raise KeyError(\"The 'array' key is not found in the dictionary.\")\n    if not isinstance(my_dict['array'], np.ndarray):\n        raise TypeError(\"The value of the 'array' key is not a numpy array.\")\n    array = my_dict['array']\n    scaler = MinMaxScaler()\n    normalized_array = scaler.fit_transform(array.reshape(-1, 1))\n    my_dict['normalized_array'] = normalized_array.flatten()\n    return my_dict", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(my_dict):\n    if 'array' not in my_dict:\n        raise KeyError(\"The 'array' key is not found in the dictionary.\")\n    if not isinstance(my_dict['array'], np.ndarray):\n        raise TypeError(\"The value of the 'array' key is not a numpy array.\")\n    array = my_dict['array']\n    scaler = MinMaxScaler()\n    normalized_array = scaler.fit_transform(array.reshape(-1, 1))\n    my_dict['normalized_array'] = normalized_array.flatten()\n    return my_dict\n```"}
{"task_id": "BigCodeBench/115", "solution": "import numpy as np\nfrom scipy.stats import mode\nfrom scipy.stats import entropy\ndef task_func(numbers):\n    if not numbers:\n        raise ValueError(\"Input list cannot be empty\")\n    arr = np.array(numbers)\n    result = {}\n    result['mode'] = mode(arr)[0][0]\n    result['entropy'] = entropy(arr, base=2)\n    return result", "raw_solution": "import numpy as np\nfrom scipy.stats import mode\nfrom scipy.stats import entropy\n\ndef task_func(numbers):\n    if not numbers:\n        raise ValueError(\"Input list cannot be empty\")\n    arr = np.array(numbers)\n    result = {}\n    result['mode'] = mode(arr)[0][0]\n    result['entropy'] = entropy(arr, base=2)\n    return result\n```"}
{"task_id": "BigCodeBench/116", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(mu, sigma, sample_size):\n    samples = np.random.normal(mu, sigma, sample_size)\n    plt.hist(samples, bins=30, alpha=0.75, color='blue')\n    plt.xlabel(\"Sample values\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Histogram of Generated Samples\")\n    plt.show()\n    return samples", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(mu, sigma, sample_size):\n    samples = np.random.normal(mu, sigma, sample_size)\n    plt.hist(samples, bins=30, alpha=0.75, color='blue')\n    plt.xlabel(\"Sample values\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Histogram of Generated Samples\")\n    plt.show()\n    return samples\n```"}
{"task_id": "BigCodeBench/117", "solution": "import pandas as pd\nimport numpy as np\nfrom random import choice, seed as set_seed\ndef task_func(num_of_students, seed=42, name_list=None, gender_list=None, age_range=(15, 20), score_range=(50, 100)):\n    if num_of_students <= 0:\n        raise ValueError(\"num_of_students must be positive\")\n    if name_list is None:\n        name_list = [\"John\", \"Jane\", \"Mary\", \"James\", \"Jennifer\", \"Maria\", \"Michael\", \"Emily\", \"Jessica\", \"Sophia\"]\n    if gender_list is None:\n        gender_list = [\"Male\", \"Female\"]\n\n    set_seed(seed)\n    data = {\n        \"Name\": [choice(name_list) for _ in range(num_of_students)],\n        \"Age\": [np.random.randint(age_range[0], age_range[1] + 1) for _ in range(num_of_students)],\n        \"Gender\": [choice(gender_list) for _ in range(num_of_students)],\n        \"Score\": [np.random.randint(score_range[0], score_range[1] + 1) for _ in range(num_of_students)]\n    }\n    return pd.DataFrame(data)", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom random import choice, seed as set_seed\n\ndef task_func(num_of_students, seed=42, name_list=None, gender_list=None, age_range=(15, 20), score_range=(50, 100)):\n    if num_of_students <= 0:\n        raise ValueError(\"num_of_students must be positive\")\n    if name_list is None:\n        name_list = [\"John\", \"Jane\", \"Mary\", \"James\", \"Jennifer\", \"Maria\", \"Michael\", \"Emily\", \"Jessica\", \"Sophia\"]\n    if gender_list is None:\n        gender_list = [\"Male\", \"Female\"]\n\n    set_seed(seed)\n    data = {\n        \"Name\": [choice(name_list) for _ in range(num_of_students)],\n        \"Age\": [np.random.randint(age_range[0], age_range[1] + 1) for _ in range(num_of_students)],\n        \"Gender\": [choice(gender_list) for _ in range(num_of_students)],\n        \"Score\": [np.random.randint(score_range[0], score_range[1] + 1) for _ in range(num_of_students)]\n    }\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/118", "solution": "import os\nimport shutil\ndef task_func(directory, backup_directory):\n    if not os.path.exists(backup_directory):\n        os.makedirs(backup_directory)\n\n    copied_files = []\n    for filename in os.listdir(directory):\n        if filename.endswith(\".json\"):\n            source_path = os.path.join(directory, filename)\n            backup_path = os.path.join(backup_directory, filename)\n            shutil.copy(source_path, backup_path)\n            copied_files.append(backup_path)\n\n    return copied_files", "raw_solution": "import os\nimport shutil\n\ndef task_func(directory, backup_directory):\n    if not os.path.exists(backup_directory):\n        os.makedirs(backup_directory)\n\n    copied_files = []\n    for filename in os.listdir(directory):\n        if filename.endswith(\".json\"):\n            source_path = os.path.join(directory, filename)\n            backup_path = os.path.join(backup_directory, filename)\n            shutil.copy(source_path, backup_path)\n            copied_files.append(backup_path)\n\n    return copied_files\n```"}
{"task_id": "BigCodeBench/119", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func():\n    x = np.linspace(-10, 10, 400)\n    y = x**2\n\n    plt.plot(x, y)\n    plt.title('y = x^2')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.grid(True)\n    plt.show()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    x = np.linspace(-10, 10, 400)\n    y = x**2\n\n    plt.plot(x, y)\n    plt.title('y = x^2')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.grid(True)\n    plt.show()\n```"}
{"task_id": "BigCodeBench/120", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"'start_date' and 'end_date' must be datetime.datetime instances\")\n    if start_date > end_date:\n        raise ValueError(\"'start_date' must be earlier than 'end_date'\")\n    random_seed(seed)\n    total_days = (end_date - start_date).days + 1\n    random_days = [randint(0, total_days - 1) for _ in range(total_days)]\n    dates = [start_date + timedelta(days=day) for day in random_days]\n    return pd.Series(dates)", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"'start_date' and 'end_date' must be datetime.datetime instances\")\n    if start_date > end_date:\n        raise ValueError(\"'start_date' must be earlier than 'end_date'\")\n    random_seed(seed)\n    total_days = (end_date - start_date).days + 1\n    random_days = [randint(0, total_days - 1) for _ in range(total_days)]\n    dates = [start_date + timedelta(days=day) for day in random_days]\n    return pd.Series(dates)"}
{"task_id": "BigCodeBench/121", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(my_list, seed=42):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' must be a list\")\n    np.random.seed(seed)\n    categories = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n    sales_data = pd.DataFrame(np.random.randint(100, 500, size=(10, len(categories))), columns=categories)\n    sales_data.loc[10] = my_list\n    fig, ax = plt.subplots()\n    sales_data.plot(kind='bar', ax=ax)\n    plt.title('Sales Data')\n    plt.xlabel('Categories')\n    plt.ylabel('Sales')\n    plt.tight_layout()\n    return (sales_data, ax)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, seed=42):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' must be a list\")\n    np.random.seed(seed)\n    categories = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n    sales_data = pd.DataFrame(np.random.randint(100, 500, size=(10, len(categories))), columns=categories)\n    sales_data.loc[10] = my_list\n    fig, ax = plt.subplots()\n    sales_data.plot(kind='bar', ax=ax)\n    plt.title('Sales Data')\n    plt.xlabel('Categories')\n    plt.ylabel('Sales')\n    plt.tight_layout()\n    return (sales_data, ax)\n```"}
{"task_id": "BigCodeBench/122", "solution": "import numpy as np\nimport random\ndef task_func(my_list):\n    my_list.append(random.randint(0, 100))\n    return np.random.rand(sum(my_list))", "raw_solution": "import numpy as np\nimport random\n\ndef task_func(my_list):\n    my_list.append(random.randint(0, 100))\n    return np.random.rand(sum(my_list))\n```"}
{"task_id": "BigCodeBench/123", "solution": "import pandas as pd\nimport os\nimport glob\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' must be a list\")\n    if not os.path.exists(file_dir):\n        raise FileNotFoundError(\"No files found in the specified directory\")\n\n    my_list.append('12')\n    file_list = glob.glob(file_dir + '*' + file_ext)\n    if not file_list:\n        raise FileNotFoundError(\"No files found in the specified directory\")\n\n    df = pd.DataFrame()\n    for file in file_list[:sum(my_list)]:\n        df = df.append(pd.read_csv(file))\n    return df", "raw_solution": "import pandas as pd\nimport os\nimport glob\n\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' must be a list\")\n    if not os.path.exists(file_dir):\n        raise FileNotFoundError(\"No files found in the specified directory\")\n\n    my_list.append('12')\n    file_list = glob.glob(file_dir + '*' + file_ext)\n    if not file_list:\n        raise FileNotFoundError(\"No files found in the specified directory\")\n\n    df = pd.DataFrame()\n    for file in file_list[:sum(my_list)]:\n        df = df.append(pd.read_csv(file))\n    return df\n```"}
{"task_id": "BigCodeBench/124", "solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' must be a list\")\n    if not all(isinstance(x, (int, float)) for x in my_list):\n        raise ValueError(\"All elements in 'my_list' must be numeric (int or float)\")\n\n    random_seed(seed)\n    my_list.append(12)\n    sum_list = sum(my_list)\n    if sum_list > size:\n        raise ValueError(\"Sum of elements in 'my_list' exceeds 'size'\")\n\n    start_time = time.time()\n    random_list = [randint(1, 100) for _ in range(sum_list)]\n    end_time = time.time()\n\n    fig, ax = plt.subplots()\n    ax.hist(random_list, bins=range(1, 101), edgecolor='black')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n    plt.show()\n\n    return (end_time - start_time, ax)", "raw_solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' must be a list\")\n    if not all(isinstance(x, (int, float)) for x in my_list):\n        raise ValueError(\"All elements in 'my_list' must be numeric (int or float)\")\n\n    random_seed(seed)\n    my_list.append(12)\n    sum_list = sum(my_list)\n    if sum_list > size:\n        raise ValueError(\"Sum of elements in 'my_list' exceeds 'size'\")\n\n    start_time = time.time()\n    random_list = [randint(1, 100) for _ in range(sum_list)]\n    end_time = time.time()\n\n    fig, ax = plt.subplots()\n    ax.hist(random_list, bins=range(1, 101), edgecolor='black')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n    plt.show()\n\n    return (end_time - start_time, ax)\n```"}
{"task_id": "BigCodeBench/125", "solution": "from collections import defaultdict\nimport itertools\nimport json\nimport random\ndef task_func(LETTERS, n):\n    # Generate all possible combinations of a given set of letters of length 'n'\n    combinations = [''.join(x) for x in itertools.product(LETTERS, repeat=n)]\n\n    # Count the occurrences of each letter in these combinations\n    letter_counts = defaultdict(int)\n    for combination in combinations:\n        for letter in combination:\n            letter_counts[letter] += 1\n\n    # Save the results in a JSON file\n    file_name = f\"prefix_{random.randint(0, 100)}.json\"\n    with open(file_name, 'w') as file:\n        json.dump(letter_counts, file)\n\n    return file_name", "raw_solution": "from collections import defaultdict\nimport itertools\nimport json\nimport random\n\ndef task_func(LETTERS, n):\n    # Generate all possible combinations of a given set of letters of length 'n'\n    combinations = [''.join(x) for x in itertools.product(LETTERS, repeat=n)]\n\n    # Count the occurrences of each letter in these combinations\n    letter_counts = defaultdict(int)\n    for combination in combinations:\n        for letter in combination:\n            letter_counts[letter] += 1\n\n    # Save the results in a JSON file\n    file_name = f\"prefix_{random.randint(0, 100)}.json\"\n    with open(file_name, 'w') as file:\n        json.dump(letter_counts, file)\n\n    return file_name\n```"}
{"task_id": "BigCodeBench/126", "solution": "import pandas as pd\nfrom random import randint, seed as random_seed\nimport statistics\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(animals=None, seed=42):\n    if animals is None:\n        animals = ['Lion', 'Tiger', 'Bear', 'Elephant', 'Monkey', 'Gorilla', 'Hippo', 'Rhino', 'Otter', 'Fox']\n    random_seed(seed)\n    animal_counts = {animal: [randint(1, 100) for _ in range(10)] for animal in animals}\n    df = pd.DataFrame(animal_counts)\n    df['Mean'] = df.mean(axis=1)\n    df['Median'] = df.median(axis=1)\n    df['Standard Deviation'] = df.std(axis=1)\n    df.set_index('Animal', inplace=True)\n    df.plot(kind='bar')\n    plt.ylabel('Count')\n    plt.show()\n    return df", "raw_solution": "import pandas as pd\nfrom random import randint, seed as random_seed\nimport statistics\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(animals=None, seed=42):\n    if animals is None:\n        animals = ['Lion', 'Tiger', 'Bear', 'Elephant', 'Monkey', 'Gorilla', 'Hippo', 'Rhino', 'Otter', 'Fox']\n    random_seed(seed)\n    animal_counts = {animal: [randint(1, 100) for _ in range(10)] for animal in animals}\n    df = pd.DataFrame(animal_counts)\n    df['Mean'] = df.mean(axis=1)\n    df['Median'] = df.median(axis=1)\n    df['Standard Deviation'] = df.std(axis=1)\n    df.set_index('Animal', inplace=True)\n    df.plot(kind='bar')\n    plt.ylabel('Count')\n    plt.show()\n    return df\n```"}
{"task_id": "BigCodeBench/127", "solution": "import os\nimport shutil\nimport glob\nimport hashlib\ndef task_func(ROOT_DIR, DEST_DIR, SPECIFIC_HASH):\n    if not os.path.exists(DEST_DIR):\n        os.makedirs(DEST_DIR)\n\n    count = 0\n    for file in glob.glob(ROOT_DIR + '/*'):\n        if os.path.isfile(file):\n            with open(file, 'rb') as f:\n                data = f.read()\n                md5 = hashlib.md5(data).hexdigest()\n                if md5 == SPECIFIC_HASH:\n                    shutil.move(file, DEST_DIR)\n                    count += 1\n    return count", "raw_solution": "import os\nimport shutil\nimport glob\nimport hashlib\n\ndef task_func(ROOT_DIR, DEST_DIR, SPECIFIC_HASH):\n    if not os.path.exists(DEST_DIR):\n        os.makedirs(DEST_DIR)\n\n    count = 0\n    for file in glob.glob(ROOT_DIR + '/*'):\n        if os.path.isfile(file):\n            with open(file, 'rb') as f:\n                data = f.read()\n                md5 = hashlib.md5(data).hexdigest()\n                if md5 == SPECIFIC_HASH:\n                    shutil.move(file, DEST_DIR)\n                    count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/128", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randint\nimport math\ndef task_func(POINTS=100):\n    x = [0]\n    y = [0]\n    for i in range(POINTS):\n        direction = randint(0, 3)\n        if direction == 0:\n            x.append(x[-1] + 1)\n            y.append(y[-1])\n        elif direction == 1:\n            x.append(x[-1] - 1)\n            y.append(y[-1])\n        elif direction == 2:\n            x.append(x[-1])\n            y.append(y[-1] + 1)\n        else:\n            x.append(x[-1])\n            y.append(y[-1] - 1)\n    plt.plot(x, y)\n    plt.show()\n    return plt.gcf()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randint\nimport math\n\ndef task_func(POINTS=100):\n    x = [0]\n    y = [0]\n    for i in range(POINTS):\n        direction = randint(0, 3)\n        if direction == 0:\n            x.append(x[-1] + 1)\n            y.append(y[-1])\n        elif direction == 1:\n            x.append(x[-1] - 1)\n            y.append(y[-1])\n        elif direction == 2:\n            x.append(x[-1])\n            y.append(y[-1] + 1)\n        else:\n            x.append(x[-1])\n            y.append(y[-1] - 1)\n    plt.plot(x, y)\n    plt.show()\n    return plt.gcf()\n```"}
{"task_id": "BigCodeBench/129", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef scrape_table(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise ValueError(\"Failed to connect to the URL\") from e\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    table = soup.find('table')\n\n    if table is None:\n        raise ValueError(\"No table data found on the page\")\n\n    rows = table.find_all('tr')\n    header = [th.text for th in rows[0].find_all('th')]\n    data = [[td.text for td in row.find_all('td')] for row in rows[1:]]\n\n    return pd.DataFrame(data, columns=header)"}
{"task_id": "BigCodeBench/130", "solution": "import base64\nimport binascii\nimport os\nimport hashlib\ndef task_func(hex_str, salt_size):\n    # Convert hex string to bytes\n    byte_str = binascii.unhexlify(hex_str)\n\n    # Generate a random salt of the specified size\n    salt = os.urandom(salt_size)\n\n    # Append the salt to the byte representation of the hex string\n    salted_data = byte_str + salt\n\n    # Compute the SHA256 hash of the salted data\n    hash_obj = hashlib.sha256()\n    hash_obj.update(salted_data)\n    hash_value = hash_obj.digest()\n\n    # Return the salt and hash as a tuple\n    return (base64.b64encode(salt).decode(), base64.b64encode(hash_value).decode())", "raw_solution": "import base64\nimport binascii\nimport os\nimport hashlib\n\ndef task_func(hex_str, salt_size):\n    # Convert hex string to bytes\n    byte_str = binascii.unhexlify(hex_str)\n\n    # Generate a random salt of the specified size\n    salt = os.urandom(salt_size)\n\n    # Append the salt to the byte representation of the hex string\n    salted_data = byte_str + salt\n\n    # Compute the SHA256 hash of the salted data\n    hash_obj = hashlib.sha256()\n    hash_obj.update(salted_data)\n    hash_value = hash_obj.digest()\n\n    # Return the salt and hash as a tuple\n    return (base64.b64encode(salt).decode(), base64.b64encode(hash_value).decode())\n```"}
{"task_id": "BigCodeBench/131", "solution": "import base64\nimport binascii\nimport os\nimport hashlib\ndef task_func(hex_str, salt_size):\n    # Convert hex string to bytes\n    byte_str = binascii.unhexlify(hex_str)\n\n    # Generate a random salt of the given size\n    salt = os.urandom(salt_size)\n\n    # Append the salt to the byte representation of the hex string\n    salted_data = byte_str + salt\n\n    # Compute the SHA256 hash of the salted data\n    hash_obj = hashlib.sha256()\n    hash_obj.update(salted_data)\n    hash_value = hash_obj.digest()\n\n    # Return the salt and hash as a tuple\n    return (base64.b64encode(salt).decode(), base64.b64encode(hash_value).decode())", "raw_solution": "import base64\nimport binascii\nimport os\nimport hashlib\n\ndef task_func(hex_str, salt_size):\n    # Convert hex string to bytes\n    byte_str = binascii.unhexlify(hex_str)\n\n    # Generate a random salt of the given size\n    salt = os.urandom(salt_size)\n\n    # Append the salt to the byte representation of the hex string\n    salted_data = byte_str + salt\n\n    # Compute the SHA256 hash of the salted data\n    hash_obj = hashlib.sha256()\n    hash_obj.update(salted_data)\n    hash_value = hash_obj.digest()\n\n    # Return the salt and hash as a tuple\n    return (base64.b64encode(salt).decode(), base64.b64encode(hash_value).decode())\n```"}
{"task_id": "BigCodeBench/132", "solution": "import binascii\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(hex_str):\n    if not isinstance(hex_str, str):\n        raise ValueError(\"Input must be a string\")\n    if not hex_str.startswith('\\\\x'):\n        hex_str = '\\\\x' + hex_str\n    try:\n        bytes_obj = binascii.unhexlify(hex_str)\n    except binascii.Error:\n        raise ValueError(\"Invalid hex string\")\n    byte_freq = np.bincount(bytes_obj)\n    df = pd.DataFrame({'Byte Value': range(256), 'Frequency': byte_freq})\n    fig, ax = plt.subplots()\n    ax.bar(df['Byte Value'], df['Frequency'])\n    ax.set_xlabel('Byte Value')\n    ax.set_ylabel('Frequency')\n    return (df, ax)", "raw_solution": "import binascii\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(hex_str):\n    if not isinstance(hex_str, str):\n        raise ValueError(\"Input must be a string\")\n    if not hex_str.startswith('\\\\x'):\n        hex_str = '\\\\x' + hex_str\n    try:\n        bytes_obj = binascii.unhexlify(hex_str)\n    except binascii.Error:\n        raise ValueError(\"Invalid hex string\")\n    byte_freq = np.bincount(bytes_obj)\n    df = pd.DataFrame({'Byte Value': range(256), 'Frequency': byte_freq})\n    fig, ax = plt.subplots()\n    ax.bar(df['Byte Value'], df['Frequency'])\n    ax.set_xlabel('Byte Value')\n    ax.set_ylabel('Frequency')\n    return (df, ax)\n```"}
{"task_id": "BigCodeBench/133", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input must be a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame cannot be empty\")\n    if df.columns.size < 1:\n        raise ValueError(\"DataFrame must have at least one column\")\n\n    scaler = MinMaxScaler()\n    df[df.columns[-1]] = scaler.fit_transform(df[[df.columns[-1]]])\n\n    fig, ax = plt.subplots()\n    ax.plot(df[df.columns[-1]])\n    ax.set_title(f'Normalized Data of {df.columns[-1]}')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Normalized Value')\n\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input must be a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame cannot be empty\")\n    if df.columns.size < 1:\n        raise ValueError(\"DataFrame must have at least one column\")\n\n    scaler = MinMaxScaler()\n    df[df.columns[-1]] = scaler.fit_transform(df[[df.columns[-1]]])\n\n    fig, ax = plt.subplots()\n    ax.plot(df[df.columns[-1]])\n    ax.set_title(f'Normalized Data of {df.columns[-1]}')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Normalized Value')\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/134", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, bins=20):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    last_column = df.columns[-1]\n    plt.hist(df[last_column], bins=bins)\n    plt.title(f'Histogram of {last_column}')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, bins=20):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    last_column = df.columns[-1]\n    plt.hist(df[last_column], bins=bins)\n    plt.title(f'Histogram of {last_column}')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/135", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.shape[1] == 0:\n        raise ValueError(\"Input should be a DataFrame with at least one column\")\n\n    imputer = SimpleImputer(strategy='mean')\n    df.iloc[:, -1] = imputer.fit_transform(df.iloc[:, -1].values.reshape(-1, 1))\n\n    fig, ax = plt.subplots()\n    sns.boxplot(data=df.iloc[:, -1], ax=ax)\n    ax.set_title('Boxplot of last column')\n\n    return df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.shape[1] == 0:\n        raise ValueError(\"Input should be a DataFrame with at least one column\")\n\n    imputer = SimpleImputer(strategy='mean')\n    df.iloc[:, -1] = imputer.fit_transform(df.iloc[:, -1].values.reshape(-1, 1))\n\n    fig, ax = plt.subplots()\n    sns.boxplot(data=df.iloc[:, -1], ax=ax)\n    ax.set_title('Boxplot of last column')\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/136", "solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input must be a pandas DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame cannot be empty\")\n\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(df)\n    principalDf = pd.DataFrame(data = principalComponents, columns = ['Principal Component 1', 'Principal Component 2'])\n\n    fig = plt.figure(figsize = (8,8))\n    ax = fig.add_subplot(1,1,1)\n    ax.set_xlabel('Principal Component 1', fontsize = 15)\n    ax.set_ylabel('Principal Component 2', fontsize = 15)\n    ax.set_title('2 Component PCA', fontsize = 20)\n    ax.scatter(principalDf['Principal Component 1'], principalDf['Principal Component 2'])\n\n    return principalDf, ax", "raw_solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input must be a pandas DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame cannot be empty\")\n\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(df)\n    principalDf = pd.DataFrame(data = principalComponents, columns = ['Principal Component 1', 'Principal Component 2'])\n\n    fig = plt.figure(figsize = (8,8))\n    ax = fig.add_subplot(1,1,1)\n    ax.set_xlabel('Principal Component 1', fontsize = 15)\n    ax.set_ylabel('Principal Component 2', fontsize = 15)\n    ax.set_title('2 Component PCA', fontsize = 20)\n    ax.scatter(principalDf['Principal Component 1'], principalDf['Principal Component 2'])\n\n    return principalDf, ax\n```"}
{"task_id": "BigCodeBench/137", "solution": "import pandas as pd\nfrom scipy.stats import skew\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.shape[1] == 0:\n        raise ValueError(\"DataFrame has no columns\")\n    return skew(df.iloc[:, -1])", "raw_solution": "import pandas as pd\nfrom scipy.stats import skew\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.shape[1] == 0:\n        raise ValueError(\"DataFrame has no columns\")\n    return skew(df.iloc[:, -1])\n```"}
{"task_id": "BigCodeBench/138", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, letters=list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' must be a DataFrame\")\n    if 'Letters' not in df.columns:\n        raise ValueError(\"'df' must contain the 'Letters' column\")\n    df = df[df['Letters'].isin(letters)]\n    df['Letters'].value_counts().sort_index().plot(kind='bar', title='Letter Frequency')\n    plt.xlabel('Letters')\n    plt.ylabel('Frequency')\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, letters=list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' must be a DataFrame\")\n    if 'Letters' not in df.columns:\n        raise ValueError(\"'df' must contain the 'Letters' column\")\n    df = df[df['Letters'].isin(letters)]\n    df['Letters'].value_counts().sort_index().plot(kind='bar', title='Letter Frequency')\n    plt.xlabel('Letters')\n    plt.ylabel('Frequency')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/139", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"Input should be a non-empty DataFrame\")\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if not numeric_cols.any():\n        raise ValueError(\"There are no numeric columns in the DataFrame\")\n    plots = []\n    for col in numeric_cols:\n        plt.figure()\n        plt.hist(df[col], bins='auto', color='blue', edgecolor='black')\n        plt.title(col)\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plots.append(plt.gca())\n    return plots", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"Input should be a non-empty DataFrame\")\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if not numeric_cols.any():\n        raise ValueError(\"There are no numeric columns in the DataFrame\")\n    plots = []\n    for col in numeric_cols:\n        plt.figure()\n        plt.hist(df[col], bins='auto', color='blue', edgecolor='black')\n        plt.title(col)\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plots.append(plt.gca())\n    return plots\n```"}
{"task_id": "BigCodeBench/140", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, cols):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' should be a DataFrame\")\n    if not isinstance(cols, list):\n        raise ValueError(\"'cols' should be a list\")\n    for col in cols:\n        if col not in df.columns:\n            raise ValueError(f\"Column '{col}' does not exist in 'df'\")\n    scaler = StandardScaler()\n    df[cols] = scaler.fit_transform(df[cols])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, cols):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' should be a DataFrame\")\n    if not isinstance(cols, list):\n        raise ValueError(\"'cols' should be a list\")\n    for col in cols:\n        if col not in df.columns:\n            raise ValueError(f\"Column '{col}' does not exist in 'df'\")\n    scaler = StandardScaler()\n    df[cols] = scaler.fit_transform(df[cols])\n    return df\n```"}
{"task_id": "BigCodeBench/141", "solution": "import numpy as np\nimport pandas as pd\nimport statistics\ndef task_func(rows, columns=['A', 'B', 'C', 'D', 'E', 'F'], seed=42):\n    if rows <= 0 or not isinstance(rows, int):\n        raise ValueError(\"'rows' must be a positive integer greater than 0.\")\n    np.random.seed(seed)\n    data = np.random.randint(1, 101, size=(rows, len(columns)))\n    df = pd.DataFrame(data, columns=columns)\n    result = {}\n    for col in columns:\n        mean = df[col].mean()\n        median = df[col].median()\n        result[col] = {'mean': mean, 'median': median}\n    return df, result", "raw_solution": "import numpy as np\nimport pandas as pd\nimport statistics\n\ndef task_func(rows, columns=['A', 'B', 'C', 'D', 'E', 'F'], seed=42):\n    if rows <= 0 or not isinstance(rows, int):\n        raise ValueError(\"'rows' must be a positive integer greater than 0.\")\n    np.random.seed(seed)\n    data = np.random.randint(1, 101, size=(rows, len(columns)))\n    df = pd.DataFrame(data, columns=columns)\n    result = {}\n    for col in columns:\n        mean = df[col].mean()\n        median = df[col].median()\n        result[col] = {'mean': mean, 'median': median}\n    return df, result\n```"}
{"task_id": "BigCodeBench/142", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func():\n    x = np.linspace(0, 2*np.pi, 1000)\n    y_sin = np.sin(x)\n    y_cos = np.cos(x)\n\n    fig, axs = plt.subplots(2)\n    fig.set_size_inches(10, 10)\n\n    axs[0].plot(x, y_sin, label='Sine function')\n    axs[0].set_xlabel('x')\n    axs[0].set_ylabel('sin(x)')\n    axs[0].legend()\n\n    axs[1].plot(x, y_cos, label='Cosine function')\n    axs[1].set_xlabel('x')\n    axs[1].set_ylabel('cos(x)')\n    axs[1].legend()\n\n    plt.tight_layout()\n    return fig, axs", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    x = np.linspace(0, 2*np.pi, 1000)\n    y_sin = np.sin(x)\n    y_cos = np.cos(x)\n\n    fig, axs = plt.subplots(2)\n    fig.set_size_inches(10, 10)\n\n    axs[0].plot(x, y_sin, label='Sine function')\n    axs[0].set_xlabel('x')\n    axs[0].set_ylabel('sin(x)')\n    axs[0].legend()\n\n    axs[1].plot(x, y_cos, label='Cosine function')\n    axs[1].set_xlabel('x')\n    axs[1].set_ylabel('cos(x)')\n    axs[1].legend()\n\n    plt.tight_layout()\n    return fig, axs\n```"}
{"task_id": "BigCodeBench/143", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func():\n    x = np.linspace(-10, 10, 100)\n    y = 2*x + 1\n\n    plt.figure(figsize=(8, 6))\n    plt.plot(x, y, label='y=2x+1', color='red')\n    plt.scatter([2], [5], color='green', label='Solution at x=2, y=5')\n    plt.title('Solution of the equation y=2x+1 at x=2')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    x = np.linspace(-10, 10, 100)\n    y = 2*x + 1\n\n    plt.figure(figsize=(8, 6))\n    plt.plot(x, y, label='y=2x+1', color='red')\n    plt.scatter([2], [5], color='green', label='Solution at x=2, y=5')\n    plt.title('Solution of the equation y=2x+1 at x=2')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/144", "solution": "import ipaddress\nimport requests\ndef task_func(ip_range, timeout):\n    try:\n        network = ipaddress.IPv4Network(ip_range)\n    except ValueError:\n        raise ValueError(\"Invalid IP range\")\n\n    active_ips = []\n    for ip in network.hosts():\n        try:\n            response = requests.get(f\"http://{ip}\", timeout=timeout)\n            if response.status_code == 200:\n                active_ips.append(str(ip))\n        except requests.exceptions.RequestException:\n            continue\n\n    return active_ips", "raw_solution": "import ipaddress\nimport requests\n\ndef task_func(ip_range, timeout):\n    try:\n        network = ipaddress.IPv4Network(ip_range)\n    except ValueError:\n        raise ValueError(\"Invalid IP range\")\n\n    active_ips = []\n    for ip in network.hosts():\n        try:\n            response = requests.get(f\"http://{ip}\", timeout=timeout)\n            if response.status_code == 200:\n                active_ips.append(str(ip))\n        except requests.exceptions.RequestException:\n            continue\n\n    return active_ips\n```"}
{"task_id": "BigCodeBench/145", "solution": "import csv\nfrom ipaddress import IPv4Network\ndef task_func(ip_range, csv_path):\n    network = IPv4Network(ip_range)\n    with open(csv_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        for ip in network.hosts():\n            writer.writerow([str(ip)])\n    return csv_path", "raw_solution": "import csv\nfrom ipaddress import IPv4Network\n\ndef task_func(ip_range, csv_path):\n    network = IPv4Network(ip_range)\n    with open(csv_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        for ip in network.hosts():\n            writer.writerow([str(ip)])\n    return csv_path\n```"}
{"task_id": "BigCodeBench/146", "solution": "import subprocess\nfrom ipaddress import IPv4Network\ndef task_func(ip_range):\n    result = {}\n    for ip in IPv4Network(ip_range):\n        try:\n            subprocess.check_output([\"ping\", \"-c\", \"1\", str(ip)], stderr=subprocess.STDOUT)\n            result[str(ip)] = True\n        except subprocess.CalledProcessError:\n            result[str(ip)] = False\n    return result", "raw_solution": "import subprocess\nfrom ipaddress import IPv4Network\n\ndef task_func(ip_range):\n    result = {}\n    for ip in IPv4Network(ip_range):\n        try:\n            subprocess.check_output([\"ping\", \"-c\", \"1\", str(ip)], stderr=subprocess.STDOUT)\n            result[str(ip)] = True\n        except subprocess.CalledProcessError:\n            result[str(ip)] = False\n    return result\n```"}
{"task_id": "BigCodeBench/147", "solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\ndef task_func(ip_range, port):\n    def check_port(ip, port):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1)\n        result = sock.connect_ex((ip, port))\n        sock.close()\n        return result == 0\n\n    def worker(ip):\n        return {ip: check_port(ip, port)}\n\n    threads = []\n    results = {}\n\n    for ip in IPv4Network(ip_range):\n        t = Thread(target=worker, args=(str(ip),))\n        threads.append(t)\n        t.start()\n\n    for t in threads:\n        t.join()\n\n    for t in threads:\n        results.update(t.result)\n\n    return results", "raw_solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\n\ndef task_func(ip_range, port):\n    def check_port(ip, port):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1)\n        result = sock.connect_ex((ip, port))\n        sock.close()\n        return result == 0\n\n    def worker(ip):\n        return {ip: check_port(ip, port)}\n\n    threads = []\n    results = {}\n\n    for ip in IPv4Network(ip_range):\n        t = Thread(target=worker, args=(str(ip),))\n        threads.append(t)\n        t.start()\n\n    for t in threads:\n        t.join()\n\n    for t in threads:\n        results.update(t.result)\n\n    return results\n```"}
{"task_id": "BigCodeBench/148", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n    le = LabelEncoder()\n    df[column_name] = le.fit_transform(df[column_name])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n    le = LabelEncoder()\n    df[column_name] = le.fit_transform(df[column_name])\n    return df\n```"}
{"task_id": "BigCodeBench/149", "solution": "import pandas as pd\nimport numpy as np\nDEFAULT_COLUMNS = ['Element', 'Count']\ndef task_func(elements, include_index=False):\n    if include_index:\n        DEFAULT_COLUMNS.insert(0, 'Index')\n    df = pd.DataFrame(elements, columns=DEFAULT_COLUMNS[1:])\n    df[DEFAULT_COLUMNS[1]] = df[DEFAULT_COLUMNS[0]].apply(len)\n    if include_index:\n        df.insert(0, DEFAULT_COLUMNS[0], range(1, len(df) + 1))\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nDEFAULT_COLUMNS = ['Element', 'Count']\ndef task_func(elements, include_index=False):\n    if include_index:\n        DEFAULT_COLUMNS.insert(0, 'Index')\n    df = pd.DataFrame(elements, columns=DEFAULT_COLUMNS[1:])\n    df[DEFAULT_COLUMNS[1]] = df[DEFAULT_COLUMNS[0]].apply(len)\n    if include_index:\n        df.insert(0, DEFAULT_COLUMNS[0], range(1, len(df) + 1))\n    return df\n```"}
{"task_id": "BigCodeBench/150", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(product_dict, product_keys):\n    if not product_dict or not product_keys:\n        return None, None\n\n    data = []\n    for key in product_keys:\n        if key in product_dict:\n            data.append([key] + list(product_dict[key].values()))\n\n    df = pd.DataFrame(data, columns=['Product', 'Quantity', 'Price', 'Profit'])\n    df['Average Price'] = df['Price'] / df['Quantity']\n    df['Average Profit'] = df['Profit'] / df['Quantity']\n\n    fig, ax = plt.subplots()\n    df.plot(x='Product', y='Profit', kind='bar', ax=ax)\n    ax.set_xlabel('Product')\n    ax.set_ylabel('Profit')\n    plt.tight_layout()\n\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(product_dict, product_keys):\n    if not product_dict or not product_keys:\n        return None, None\n\n    data = []\n    for key in product_keys:\n        if key in product_dict:\n            data.append([key] + list(product_dict[key].values()))\n\n    df = pd.DataFrame(data, columns=['Product', 'Quantity', 'Price', 'Profit'])\n    df['Average Price'] = df['Price'] / df['Quantity']\n    df['Average Profit'] = df['Profit'] / df['Quantity']\n\n    fig, ax = plt.subplots()\n    df.plot(x='Product', y='Profit', kind='bar', ax=ax)\n    ax.set_xlabel('Product')\n    ax.set_ylabel('Profit')\n    plt.tight_layout()\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/151", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(data_dict, data_keys):\n    if not any(key in data_dict for key in data_keys):\n        raise ValueError(\"No keys in data_keys are found in data_dict\")\n\n    data = pd.DataFrame(data_dict)\n    data = data[data_keys]\n\n    scaler = MinMaxScaler()\n    normalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n    fig, ax = plt.subplots()\n    normalized_data.plot(kind='line', ax=ax)\n    ax.set_title('Normalized Data')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n\n    return normalized_data, ax.figure", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict, data_keys):\n    if not any(key in data_dict for key in data_keys):\n        raise ValueError(\"No keys in data_keys are found in data_dict\")\n\n    data = pd.DataFrame(data_dict)\n    data = data[data_keys]\n\n    scaler = MinMaxScaler()\n    normalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n    fig, ax = plt.subplots()\n    normalized_data.plot(kind='line', ax=ax)\n    ax.set_title('Normalized Data')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n\n    return normalized_data, ax.figure\n```"}
{"task_id": "BigCodeBench/152", "solution": "import pandas as pd\nimport numpy as np\nfrom random import randint\nSTUDENTS = ['Joe', 'Amy', 'Mark', 'Sara', 'John', 'Emily', 'Zoe', 'Matt']\nCOURSES = ['Math', 'Physics', 'Chemistry', 'Biology', 'English', 'History', 'Geography', 'Computer Science']\ndef task_func():\n    # Create a DataFrame with random grades for each student in each course\n    df = pd.DataFrame(np.random.uniform(0, 100, size=(len(STUDENTS), len(COURSES))), index=STUDENTS, columns=COURSES)\n\n    # Add a column for the average grade\n    df['Average'] = df.mean(axis=1)\n\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom random import randint\n\n# Constants\nSTUDENTS = ['Joe', 'Amy', 'Mark', 'Sara', 'John', 'Emily', 'Zoe', 'Matt']\nCOURSES = ['Math', 'Physics', 'Chemistry', 'Biology', 'English', 'History', 'Geography', 'Computer Science']\n\ndef task_func():\n    # Create a DataFrame with random grades for each student in each course\n    df = pd.DataFrame(np.random.uniform(0, 100, size=(len(STUDENTS), len(COURSES))), index=STUDENTS, columns=COURSES)\n\n    # Add a column for the average grade\n    df['Average'] = df.mean(axis=1)\n\n    return df\n```"}
{"task_id": "BigCodeBench/153", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(data):\n    le = LabelEncoder()\n    data_encoded = le.fit_transform(data)\n    df = pd.DataFrame({'Category': data, 'Encoded': data_encoded})\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(data):\n    le = LabelEncoder()\n    data_encoded = le.fit_transform(data)\n    df = pd.DataFrame({'Category': data, 'Encoded': data_encoded})\n    return df\n```"}
{"task_id": "BigCodeBench/154", "solution": "import re\nimport os\nimport glob\nimport mimetypes\ndef task_func(directory, file_pattern, suffix):\n    file_dict = {}\n    for file in glob.glob(os.path.join(directory, file_pattern + suffix)):\n        file_name = os.path.basename(file)\n        file_type = mimetypes.guess_type(file_name)[0]\n        file_dict[file_name] = file_type\n    return file_dict", "raw_solution": "import re\nimport os\nimport glob\nimport mimetypes\n\ndef task_func(directory, file_pattern, suffix):\n    file_dict = {}\n    for file in glob.glob(os.path.join(directory, file_pattern + suffix)):\n        file_name = os.path.basename(file)\n        file_type = mimetypes.guess_type(file_name)[0]\n        file_dict[file_name] = file_type\n    return file_dict\n```"}
{"task_id": "BigCodeBench/155", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    df = pd.DataFrame(data, columns=COLUMN_NAMES)\n    df['Average'] = df.mean(axis=1)\n    fig, ax = plt.subplots()\n    ax.plot(df['Average'])\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=COLUMN_NAMES)\n    df['Average'] = df.mean(axis=1)\n    fig, ax = plt.subplots()\n    ax.plot(df['Average'])\n    return df, ax\n```"}
{"task_id": "BigCodeBench/156", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    scaler = MinMaxScaler()\n    data_scaled = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n    data_scaled['Average'] = data_scaled.mean(axis=1)\n    fig, ax = plt.subplots()\n    data_scaled['Average'].plot(kind='bar', ax=ax)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Average')\n    plt.tight_layout()\n    return data_scaled, ax", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    scaler = MinMaxScaler()\n    data_scaled = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n    data_scaled['Average'] = data_scaled.mean(axis=1)\n    fig, ax = plt.subplots()\n    data_scaled['Average'].plot(kind='bar', ax=ax)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Average')\n    plt.tight_layout()\n    return data_scaled, ax\n```"}
{"task_id": "BigCodeBench/157", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data must be a pandas DataFrame\")\n    if not np.issubdtype(data.dtypes.values[0], np.number):\n        raise ValueError(\"DataFrame must contain only numeric data\")\n    data['Average'] = data.mean(axis=1)\n    correlation_matrix = data.corr()\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n    return data, ax", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data must be a pandas DataFrame\")\n    if not np.issubdtype(data.dtypes.values[0], np.number):\n        raise ValueError(\"DataFrame must contain only numeric data\")\n    data['Average'] = data.mean(axis=1)\n    correlation_matrix = data.corr()\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n    return data, ax\n```"}
{"task_id": "BigCodeBench/158", "solution": "import json\nimport urllib.request\nimport urllib.parse\nimport gzip\nimport os\ndef task_func(url_str, file_path):\n    # Fetch JSON data from the URL\n    with urllib.request.urlopen(url_str) as url:\n        data = url.read()\n\n    # Decode the JSON data\n    json_data = json.loads(data)\n\n    # Compress the JSON data into a gzip file\n    with gzip.open(file_path, 'wb') as f:\n        f.write(json.dumps(json_data).encode())\n\n    return file_path", "raw_solution": "import json\nimport urllib.request\nimport urllib.parse\nimport gzip\nimport os\n\ndef task_func(url_str, file_path):\n    # Fetch JSON data from the URL\n    with urllib.request.urlopen(url_str) as url:\n        data = url.read()\n\n    # Decode the JSON data\n    json_data = json.loads(data)\n\n    # Compress the JSON data into a gzip file\n    with gzip.open(file_path, 'wb') as f:\n        f.write(json.dumps(json_data).encode())\n\n    return file_path\n```"}
{"task_id": "BigCodeBench/159", "solution": "import struct\nimport io\nimport gzip", "raw_solution": "import struct\nimport io\nimport gzip\n\ndef compress_numpy_array(newArray):\n    \"\"\"\n    Compresses a given NumPy array using gzip compression and returns the compressed data.\n    \"\"\"\n    # Convert the array to bytes\n    byte_array = newArray.tobytes()\n\n    # Compress the byte array using gzip\n    compressed_data = gzip.compress(byte_array)\n\n    return compressed_data\n```"}
{"task_id": "BigCodeBench/160", "solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nCOLUMN_NAMES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\ndef task_func(data):\n    if data.shape[1] != 8:\n        raise ValueError(\"The input data does not have exactly eight columns.\")\n\n    data['Average'] = data[COLUMN_NAMES].mean(axis=1)\n    plot = sns.distplot(data['Average'])\n\n    p_value = None\n    if data.shape[0] >= 20:\n        _, p_value = stats.normaltest(data['Average'])\n\n    return data, plot, p_value", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy import stats\n\n# Constants\nCOLUMN_NAMES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n\ndef task_func(data):\n    if data.shape[1] != 8:\n        raise ValueError(\"The input data does not have exactly eight columns.\")\n\n    data['Average'] = data[COLUMN_NAMES].mean(axis=1)\n    plot = sns.distplot(data['Average'])\n\n    p_value = None\n    if data.shape[0] >= 20:\n        _, p_value = stats.normaltest(data['Average'])\n\n    return data, plot, p_value\n```"}
{"task_id": "BigCodeBench/161", "solution": "import re\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(log_file):\n    # Define the regular expression pattern for log entries\n    pattern = r'^(\\w+): \\[(.*)\\] - (.*)$'\n\n    # Initialize an empty list to store the log entries\n    log_entries = []\n\n    # Open the log file and read each line\n    with open(log_file, 'r') as file:\n        for line in file:\n            # Use the regular expression to match the log entry pattern\n            match = re.match(pattern, line.strip())\n\n            # If a match is found, extract the message type, timestamp, and message\n            if match:\n                message_type, timestamp, message = match.groups()\n\n                # Convert the timestamp to a datetime object\n                try:\n                    timestamp = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n                except ValueError:\n                    raise ValueError('Invalid timestamp in log entry: {}'.format(line.strip()))\n\n                # Append the log entry to the list\n                log_entries.append({\n                    'message_type': message_type,\n                    'timestamp': timestamp,\n                    'message': message\n                })\n\n    # If no valid log entries are found, raise an exception\n    if not log_entries:\n        raise ValueError('No valid log entries found in file: {}'.format(log_file))\n\n    # Convert the log entries list to a pandas DataFrame\n    df = pd.DataFrame(log_entries)\n\n    # Save the DataFrame to a CSV file\n    csv_file = '{}_structured.csv'.format(log_file)\n    df.to_csv(csv_file, index=False)\n\n    return csv_file", "raw_solution": "import re\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(log_file):\n    # Define the regular expression pattern for log entries\n    pattern = r'^(\\w+): \\[(.*)\\] - (.*)$'\n\n    # Initialize an empty list to store the log entries\n    log_entries = []\n\n    # Open the log file and read each line\n    with open(log_file, 'r') as file:\n        for line in file:\n            # Use the regular expression to match the log entry pattern\n            match = re.match(pattern, line.strip())\n\n            # If a match is found, extract the message type, timestamp, and message\n            if match:\n                message_type, timestamp, message = match.groups()\n\n                # Convert the timestamp to a datetime object\n                try:\n                    timestamp = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n                except ValueError:\n                    raise ValueError('Invalid timestamp in log entry: {}'.format(line.strip()))\n\n                # Append the log entry to the list\n                log_entries.append({\n                    'message_type': message_type,\n                    'timestamp': timestamp,\n                    'message': message\n                })\n\n    # If no valid log entries are found, raise an exception\n    if not log_entries:\n        raise ValueError('No valid log entries found in file: {}'.format(log_file))\n\n    # Convert the log entries list to a pandas DataFrame\n    df = pd.DataFrame(log_entries)\n\n    # Save the DataFrame to a CSV file\n    csv_file = '{}_structured.csv'.format(log_file)\n    df.to_csv(csv_file, index=False)\n\n    return csv_file\n```"}
{"task_id": "BigCodeBench/162", "solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(text, rwidth=0.8):\n    words = re.findall(r'\\b\\w+\\b', text)\n    lengths = [len(word) for word in words]\n    bins = np.arange(min(lengths), max(lengths) + 2, 1)\n    hist, bins = np.histogram(lengths, bins=bins)\n    ax = plt.subplot()\n    ax.bar(bins[:-1], hist, align='edge', width=rwidth)\n    ax.set_xlabel('Word Length')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Word Length Distribution')\n    return ax", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(text, rwidth=0.8):\n    words = re.findall(r'\\b\\w+\\b', text)\n    lengths = [len(word) for word in words]\n    bins = np.arange(min(lengths), max(lengths) + 2, 1)\n    hist, bins = np.histogram(lengths, bins=bins)\n    ax = plt.subplot()\n    ax.bar(bins[:-1], hist, align='edge', width=rwidth)\n    ax.set_xlabel('Word Length')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Word Length Distribution')\n    return ax\n```"}
{"task_id": "BigCodeBench/163", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(rows=5, cols=5):\n    if cols > rows:\n        raise ValueError(\"Number of columns cannot exceed the number of rows.\")\n    data = np.random.randint(1, 10, size=(rows, cols))\n    df = pd.DataFrame(data, columns=[f\"Category {i+1}\" for i in range(cols)])\n    df.plot(kind='bar', stacked=True)\n    plt.title(\"Stacked Bar Chart\")\n    plt.xlabel(\"Categories\")\n    plt.ylabel(\"Values\")\n    return plt.gca()", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(rows=5, cols=5):\n    if cols > rows:\n        raise ValueError(\"Number of columns cannot exceed the number of rows.\")\n    data = np.random.randint(1, 10, size=(rows, cols))\n    df = pd.DataFrame(data, columns=[f\"Category {i+1}\" for i in range(cols)])\n    df.plot(kind='bar', stacked=True)\n    plt.title(\"Stacked Bar Chart\")\n    plt.xlabel(\"Categories\")\n    plt.ylabel(\"Values\")\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/164", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(num_labels=5, data_range=(0, 1)):\n    labels = np.arange(num_labels)\n    data = np.random.randint(data_range[0], data_range[1], size=(num_labels, num_labels))\n    df = pd.DataFrame(data, columns=labels, index=labels)\n\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', stacked=True, ax=ax)\n    ax.set_xlabel('Labels')\n    ax.set_ylabel('Values')\n    ax.set_title('Stacked Bar Chart')\n\n    return fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(num_labels=5, data_range=(0, 1)):\n    labels = np.arange(num_labels)\n    data = np.random.randint(data_range[0], data_range[1], size=(num_labels, num_labels))\n    df = pd.DataFrame(data, columns=labels, index=labels)\n\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', stacked=True, ax=ax)\n    ax.set_xlabel('Labels')\n    ax.set_ylabel('Values')\n    ax.set_title('Stacked Bar Chart')\n\n    return fig\n```"}
{"task_id": "BigCodeBench/165", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\ndef task_func(num_rows=5, rand_range=(0, 100)):\n    # Create a DataFrame with random integer values within the specified range\n    df = pd.DataFrame({\n        'A': [randint(*rand_range) for _ in range(num_rows)],\n        'B': [randint(*rand_range) for _ in range(num_rows)],\n        'C': [randint(*rand_range) for _ in range(num_rows)],\n        'D': [randint(*rand_range) for _ in range(num_rows)],\n        'E': [randint(*rand_range) for _ in range(num_rows)]\n    })\n\n    # Create a stacked bar chart of the DataFrame\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', stacked=True, ax=ax)\n\n    # Set the chart title and labels\n    ax.set_title('Stacked Bar Chart')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n\n    return fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\n\ndef task_func(num_rows=5, rand_range=(0, 100)):\n    # Create a DataFrame with random integer values within the specified range\n    df = pd.DataFrame({\n        'A': [randint(*rand_range) for _ in range(num_rows)],\n        'B': [randint(*rand_range) for _ in range(num_rows)],\n        'C': [randint(*rand_range) for _ in range(num_rows)],\n        'D': [randint(*rand_range) for _ in range(num_rows)],\n        'E': [randint(*rand_range) for _ in range(num_rows)]\n    })\n\n    # Create a stacked bar chart of the DataFrame\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', stacked=True, ax=ax)\n\n    # Set the chart title and labels\n    ax.set_title('Stacked Bar Chart')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n\n    return fig\n```"}
{"task_id": "BigCodeBench/166", "solution": "import pandas as pd\nfrom datetime import datetime\nimport holidays\ndef task_func(start_date=datetime(2023, 1, 1), end_date=datetime(2023, 12, 31), country='US'):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"Both start_date and end_date must be datetime objects.\")\n    if start_date > end_date:\n        raise ValueError(\"Start date must be before end date.\")\n    if end_date < start_date:\n        raise ValueError(\"End date must be after start date.\")\n\n    country_holidays = holidays.CountryHoliday(country)\n    business_days = pd.date_range(start=start_date, end=end_date, freq='B')\n    business_days = business_days[~business_days.isin(country_holidays)]\n\n    return business_days.tolist()", "raw_solution": "import pandas as pd\nfrom datetime import datetime\nimport holidays\n\ndef task_func(start_date=datetime(2023, 1, 1), end_date=datetime(2023, 12, 31), country='US'):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"Both start_date and end_date must be datetime objects.\")\n    if start_date > end_date:\n        raise ValueError(\"Start date must be before end date.\")\n    if end_date < start_date:\n        raise ValueError(\"End date must be after start date.\")\n\n    country_holidays = holidays.CountryHoliday(country)\n    business_days = pd.date_range(start=start_date, end=end_date, freq='B')\n    business_days = business_days[~business_days.isin(country_holidays)]\n\n    return business_days.tolist()"}
{"task_id": "BigCodeBench/167", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\ndef task_func(num_types=5, integer_range=(0, 100)):\n    # Generate a DataFrame with random integer values across specified number of categories\n    df = pd.DataFrame({\n        'Category': [f'Category {i+1}' for i in range(num_types)],\n        'Value': [randint(*integer_range) for _ in range(num_types)]\n    })\n\n    # Create a horizontal stacked bar chart\n    fig, ax = plt.subplots()\n    ax.barh(df['Category'], df['Value'], left=0, color='skyblue')\n\n    # Set plot title and labels\n    ax.set_title('Horizontal Stacked Bar Chart')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Category')\n\n    return fig, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\n\ndef task_func(num_types=5, integer_range=(0, 100)):\n    # Generate a DataFrame with random integer values across specified number of categories\n    df = pd.DataFrame({\n        'Category': [f'Category {i+1}' for i in range(num_types)],\n        'Value': [randint(*integer_range) for _ in range(num_types)]\n    })\n\n    # Create a horizontal stacked bar chart\n    fig, ax = plt.subplots()\n    ax.barh(df['Category'], df['Value'], left=0, color='skyblue')\n\n    # Set plot title and labels\n    ax.set_title('Horizontal Stacked Bar Chart')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Category')\n\n    return fig, ax\n```"}
{"task_id": "BigCodeBench/168", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(num_groups=5, data_size=5, labels=None):\n    if labels is None:\n        labels = ['Group ' + str(i) for i in range(1, num_groups + 1)]\n    data = pd.DataFrame(np.random.randint(0, 100, size=(data_size, num_groups)), columns=labels)\n    data.plot(kind='bar', stacked=True)\n    plt.savefig('test_plot.png')\n    return (plt.gcf(), data, 'test_plot.png')", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(num_groups=5, data_size=5, labels=None):\n    if labels is None:\n        labels = ['Group ' + str(i) for i in range(1, num_groups + 1)]\n    data = pd.DataFrame(np.random.randint(0, 100, size=(data_size, num_groups)), columns=labels)\n    data.plot(kind='bar', stacked=True)\n    plt.savefig('test_plot.png')\n    return (plt.gcf(), data, 'test_plot.png')\n```"}
{"task_id": "BigCodeBench/169", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import gaussian_filter\ndef task_func(image, sigma=2):\n    if not isinstance(image, np.ndarray):\n        raise TypeError(\"Input image must be a numpy array.\")\n    if sigma <= 0:\n        raise ValueError(\"Sigma must be a positive number.\")\n    filtered_image = gaussian_filter(image, sigma)\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n    ax[0].imshow(image, cmap='gray')\n    ax[0].set_title('Original')\n    ax[1].imshow(filtered_image, cmap='gray')\n    ax[1].set_title('Filtered')\n    plt.tight_layout()\n    plt.show()\n    return ax, filtered_image", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import gaussian_filter\n\ndef task_func(image, sigma=2):\n    if not isinstance(image, np.ndarray):\n        raise TypeError(\"Input image must be a numpy array.\")\n    if sigma <= 0:\n        raise ValueError(\"Sigma must be a positive number.\")\n    filtered_image = gaussian_filter(image, sigma)\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n    ax[0].imshow(image, cmap='gray')\n    ax[0].set_title('Original')\n    ax[1].imshow(filtered_image, cmap='gray')\n    ax[1].set_title('Filtered')\n    plt.tight_layout()\n    plt.show()\n    return ax, filtered_image\n```"}
{"task_id": "BigCodeBench/170", "solution": "import pandas as pd\nimport requests\nfrom io import StringIO\ndef task_func(csv_url, sort_by_column=\"title\"):\n    response = requests.get(csv_url)\n    if response.status_code != 200:\n        raise Exception(\"Response status code is not 200\")\n    data = StringIO(response.text)\n    df = pd.read_csv(data)\n    return df.sort_values(by=[sort_by_column])", "raw_solution": "import pandas as pd\nimport requests\nfrom io import StringIO\n\ndef task_func(csv_url, sort_by_column=\"title\"):\n    response = requests.get(csv_url)\n    if response.status_code != 200:\n        raise Exception(\"Response status code is not 200\")\n    data = StringIO(response.text)\n    df = pd.read_csv(data)\n    return df.sort_values(by=[sort_by_column])\n```"}
{"task_id": "BigCodeBench/171", "solution": "import random\nimport pandas as pd\nimport collections\ndef task_func(vegetable_dict, seed=0):\n    random.seed(seed)\n    # Reverse the dictionary to map vegetables to people\n    reversed_dict = {v: k for k, v in vegetable_dict.items()}\n    # Assign random counts to these vegetables\n    for vegetable in reversed_dict:\n        reversed_dict[vegetable] = random.randint(1, 10)\n    # Calculate the total counts\n    total_counts = sum(reversed_dict.values())\n    # Calculate the percentage occurrence of each vegetable\n    for vegetable in reversed_dict:\n        reversed_dict[vegetable] = (reversed_dict[vegetable] / total_counts) * 100\n    # Create a DataFrame from the dictionary\n    df = pd.DataFrame(list(reversed_dict.items()), columns=['Vegetable', 'Percentage'])\n    return df", "raw_solution": "import random\nimport pandas as pd\nimport collections\n# Constants\nVEGETABLES = ['Carrot', 'Potato', 'Tomato', 'Cabbage', 'Spinach']\ndef task_func(vegetable_dict, seed=0):\n    random.seed(seed)\n    # Reverse the dictionary to map vegetables to people\n    reversed_dict = {v: k for k, v in vegetable_dict.items()}\n    # Assign random counts to these vegetables\n    for vegetable in reversed_dict:\n        reversed_dict[vegetable] = random.randint(1, 10)\n    # Calculate the total counts\n    total_counts = sum(reversed_dict.values())\n    # Calculate the percentage occurrence of each vegetable\n    for vegetable in reversed_dict:\n        reversed_dict[vegetable] = (reversed_dict[vegetable] / total_counts) * 100\n    # Create a DataFrame from the dictionary\n    df = pd.DataFrame(list(reversed_dict.items()), columns=['Vegetable', 'Percentage'])\n    return df\n```"}
{"task_id": "BigCodeBench/172", "solution": "import json\nfrom datetime import datetime\ndef task_func(json_data):\n    utc_datetime = datetime.strptime(json_data['utc_datetime'], '%Y-%m-%d %H:%M:%S')\n    return utc_datetime.weekday() > 4", "raw_solution": "import json\nfrom datetime import datetime\n\ndef task_func(json_data):\n    utc_datetime = datetime.strptime(json_data['utc_datetime'], '%Y-%m-%d %H:%M:%S')\n    return utc_datetime.weekday() > 4\n```"}
{"task_id": "BigCodeBench/173", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(country_dict):\n    gdp_values = np.random.randint(1000000000, 100000000000, size=len(country_dict))\n    df = pd.DataFrame(gdp_values, index=country_dict.keys(), columns=['GDP'])\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(country_dict):\n    gdp_values = np.random.randint(1000000000, 100000000000, size=len(country_dict))\n    df = pd.DataFrame(gdp_values, index=country_dict.keys(), columns=['GDP'])\n    return df\n```"}
{"task_id": "BigCodeBench/174", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(data, key, min_value, max_value):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data should be a pandas DataFrame\")\n    data[key] = np.random.randint(min_value, max_value, data.shape[0])\n    return data", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(data, key, min_value, max_value):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data should be a pandas DataFrame\")\n    data[key] = np.random.randint(min_value, max_value, data.shape[0])\n    return data\n```"}
{"task_id": "BigCodeBench/175", "solution": "import re\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if 'Title' not in df.columns or 'Views' not in df.columns or 'Likes' not in df.columns:\n        return plt.subplot(111)\n    df = df[df['Title'].str.contains(r'(how|what)', case=False)]\n    if df.empty:\n        return plt.subplot(111)\n    df['Like Ratio'] = df['Likes'] / df['Views']\n    ax = df.plot(x='Title', y='Like Ratio', kind='bar', legend=False)\n    ax.set_xlabel('Video Title')\n    ax.set_ylabel('Like Ratio')\n    return ax", "raw_solution": "import re\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if 'Title' not in df.columns or 'Views' not in df.columns or 'Likes' not in df.columns:\n        return plt.subplot(111)\n    df = df[df['Title'].str.contains(r'(how|what)', case=False)]\n    if df.empty:\n        return plt.subplot(111)\n    df['Like Ratio'] = df['Likes'] / df['Views']\n    ax = df.plot(x='Title', y='Like Ratio', kind='bar', legend=False)\n    ax.set_xlabel('Video Title')\n    ax.set_ylabel('Like Ratio')\n    return ax\n```"}
{"task_id": "BigCodeBench/176", "solution": "import re\nimport socket\ndef task_func(ip_addresses: list) -> dict:\n    result = {}\n    for ip in ip_addresses:\n        try:\n            result[ip] = socket.gethostbyaddr(ip)[0]\n        except socket.herror:\n            result[ip] = None\n    return result", "raw_solution": "import re\nimport socket\ndef task_func(ip_addresses: list) -> dict:\n    result = {}\n    for ip in ip_addresses:\n        try:\n            result[ip] = socket.gethostbyaddr(ip)[0]\n        except socket.herror:\n            result[ip] = None\n    return result\n```"}
{"task_id": "BigCodeBench/177", "solution": "import re\nimport nltk\nfrom string import punctuation\ndef task_func(df):\n    if df.empty or 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError(\"DataFrame is empty or does not contain the necessary columns 'Title' and 'Content'\")\n\n    df = df[df['Title'].str.contains(r'(?i)like|what')]\n    df['Content'] = df['Content'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n\n    words = nltk.word_tokenize(' '.join(df['Content']))\n    words = [word.lower() for word in words if word.isalpha()]\n\n    word_freq = {}\n    for word in words:\n        if word in word_freq:\n            word_freq[word] += 1\n        else:\n            word_freq[word] = 1\n\n    return word_freq", "raw_solution": "import re\nimport nltk\nfrom string import punctuation\n\ndef task_func(df):\n    if df.empty or 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError(\"DataFrame is empty or does not contain the necessary columns 'Title' and 'Content'\")\n\n    df = df[df['Title'].str.contains(r'(?i)like|what')]\n    df['Content'] = df['Content'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n\n    words = nltk.word_tokenize(' '.join(df['Content']))\n    words = [word.lower() for word in words if word.isalpha()]\n\n    word_freq = {}\n    for word in words:\n        if word in word_freq:\n            word_freq[word] += 1\n        else:\n            word_freq[word] = 1\n\n    return word_freq\n```"}
{"task_id": "BigCodeBench/178", "solution": "import re\nimport json\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\ndef task_func(ip_address):\n    if re.match(IP_REGEX, ip_address):\n        return ip_address\n    else:\n        return 'Invalid IP address received'", "raw_solution": "import re\nimport json\n# Constants\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\ndef task_func(ip_address):\n    if re.match(IP_REGEX, ip_address):\n        return ip_address\n    else:\n        return 'Invalid IP address received'\n```"}
{"task_id": "BigCodeBench/179", "solution": "import re\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\ndef task_func(df):\n    if 'Title' not in df.columns or 'Content' not in df.columns:\n        return plt.figure()\n    df = df[df['Title'].str.contains('how|what', case=False)]\n    if df.empty:\n        return plt.figure()\n    vectorizer = TfidfVectorizer(stop_words='english')\n    tfidf_matrix = vectorizer.fit_transform(df['Content'])\n    feature_names = vectorizer.get_feature_names_out()\n    tfidf_scores = tfidf_matrix.toarray().sum(axis=0)\n    fig, ax = plt.subplots()\n    ax.bar(feature_names, tfidf_scores)\n    ax.set_ylabel('TF-IDF Score')\n    plt.xticks(rotation=90)\n    return fig", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\ndef task_func(df):\n    if 'Title' not in df.columns or 'Content' not in df.columns:\n        return plt.figure()\n    df = df[df['Title'].str.contains('how|what', case=False)]\n    if df.empty:\n        return plt.figure()\n    vectorizer = TfidfVectorizer(stop_words='english')\n    tfidf_matrix = vectorizer.fit_transform(df['Content'])\n    feature_names = vectorizer.get_feature_names_out()\n    tfidf_scores = tfidf_matrix.toarray().sum(axis=0)\n    fig, ax = plt.subplots()\n    ax.bar(feature_names, tfidf_scores)\n    ax.set_ylabel('TF-IDF Score')\n    plt.xticks(rotation=90)\n    return fig\n```"}
{"task_id": "BigCodeBench/180", "solution": "from PIL import Image\nimport numpy as np\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(img_path, scale_factors=[0.5, 0.75, 1.5, 2.0]):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"Image file not found\")\n\n    img = Image.open(img_path)\n    img_array = np.array(img)\n\n    result = []\n    for scale in scale_factors:\n        scaled_img = resize(img_array, (int(img_array.shape[0] * scale), int(img_array.shape[1] * scale)))\n        fig, ax = plt.subplots()\n        ax.imshow(scaled_img)\n        result.append((ax, scaled_img))\n\n    return result", "raw_solution": "from PIL import Image\nimport numpy as np\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(img_path, scale_factors=[0.5, 0.75, 1.5, 2.0]):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"Image file not found\")\n\n    img = Image.open(img_path)\n    img_array = np.array(img)\n\n    result = []\n    for scale in scale_factors:\n        scaled_img = resize(img_array, (int(img_array.shape[0] * scale), int(img_array.shape[1] * scale)))\n        fig, ax = plt.subplots()\n        ax.imshow(scaled_img)\n        result.append((ax, scaled_img))\n\n    return result\n```"}
{"task_id": "BigCodeBench/181", "solution": "from django.http import HttpResponse\nfrom django.conf import settings\nimport random\nimport time\ndef task_func(data, min_delay, max_delay):\n    delay = random.randint(min_delay, max_delay)\n    time.sleep(delay)\n    return HttpResponse(data, content_type='application/json')", "raw_solution": "from django.http import HttpResponse\nfrom django.conf import settings\nimport random\nimport time\n\ndef task_func(data, min_delay, max_delay):\n    delay = random.randint(min_delay, max_delay)\n    time.sleep(delay)\n    return HttpResponse(data, content_type='application/json')\n```"}
{"task_id": "BigCodeBench/182", "solution": "import re\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import CountVectorizer\ndef task_func(df):\n    # Filter articles that start with \"how\" or \"what\"\n    filtered_df = df[df['title'].str.lower().str.startswith('how') | df['title'].str.lower().str.startswith('what')]\n\n    # Vectorize the content using CountVectorizer\n    vectorizer = CountVectorizer(stop_words='english')\n    X = vectorizer.fit_transform(filtered_df['content'])\n\n    # Group articles into clusters using KMeans clustering\n    kmeans = KMeans(n_clusters=3)\n    kmeans.fit(X)\n\n    # Return the cluster labels for the filtered articles\n    return kmeans.labels_", "raw_solution": "import re\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef task_func(df):\n    # Filter articles that start with \"how\" or \"what\"\n    filtered_df = df[df['title'].str.lower().str.startswith('how') | df['title'].str.lower().str.startswith('what')]\n\n    # Vectorize the content using CountVectorizer\n    vectorizer = CountVectorizer(stop_words='english')\n    X = vectorizer.fit_transform(filtered_df['content'])\n\n    # Group articles into clusters using KMeans clustering\n    kmeans = KMeans(n_clusters=3)\n    kmeans.fit(X)\n\n    # Return the cluster labels for the filtered articles\n    return kmeans.labels_\n```"}
{"task_id": "BigCodeBench/183", "solution": "from django.http import HttpResponse\nimport uuid\nimport json\ndef task_func(data):\n    response = HttpResponse(json.dumps(data), content_type='application/json')\n    response['UUID'] = str(uuid.uuid4())\n    return response", "raw_solution": "from django.http import HttpResponse\nimport uuid\nimport json\n\ndef task_func(data):\n    response = HttpResponse(json.dumps(data), content_type='application/json')\n    response['UUID'] = str(uuid.uuid4())\n    return response\n```"}
{"task_id": "BigCodeBench/184", "solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\ndef task_func(dataframe, text_column):\n    # Preprocessing\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: ' '.join([word for word in x.split() if word not in STOPWORDS]))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: ' '.join([word for word in x.split() if not word.isnumeric()]))\n    # Vectorization\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(dataframe[text_column])\n    # Create DataFrame\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n    return df", "raw_solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\n# Constants\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\ndef task_func(dataframe, text_column):\n    # Preprocessing\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: ' '.join([word for word in x.split() if word not in STOPWORDS]))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: ' '.join([word for word in x.split() if not word.isnumeric()]))\n    # Vectorization\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(dataframe[text_column])\n    # Create DataFrame\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n    return df\n```"}
{"task_id": "BigCodeBench/185", "solution": "import pandas as pd\nimport numpy as np\nimport folium\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"'Lon' and 'Lat' keys are required in the dictionary.\")\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples.\")\n    if len(dic['Lon']) != 2 or len(dic['Lat']) != 2:\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples of length 2.\")\n\n    df = pd.DataFrame(cities, columns=['City'])\n    df['Longitude'] = np.random.uniform(low=dic['Lon'][0], high=dic['Lon'][1], size=len(cities))\n    df['Latitude'] = np.random.uniform(low=dic['Lat'][0], high=dic['Lat'][1], size=len(cities))\n\n    m = folium.Map(location=[np.mean(df['Latitude']), np.mean(df['Longitude'])], zoom_start=2)\n    for i in range(0,len(df)):\n        folium.Marker([df.iloc[i]['Latitude'], df.iloc[i]['Longitude']], popup=df.iloc[i]['City']).add_to(m)\n\n    return (m, df)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport folium\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"'Lon' and 'Lat' keys are required in the dictionary.\")\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples.\")\n    if len(dic['Lon']) != 2 or len(dic['Lat']) != 2:\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples of length 2.\")\n\n    df = pd.DataFrame(cities, columns=['City'])\n    df['Longitude'] = np.random.uniform(low=dic['Lon'][0], high=dic['Lon'][1], size=len(cities))\n    df['Latitude'] = np.random.uniform(low=dic['Lat'][0], high=dic['Lat'][1], size=len(cities))\n\n    m = folium.Map(location=[np.mean(df['Latitude']), np.mean(df['Longitude'])], zoom_start=2)\n    for i in range(0,len(df)):\n        folium.Marker([df.iloc[i]['Latitude'], df.iloc[i]['Longitude']], popup=df.iloc[i]['City']).add_to(m)\n\n    return (m, df)\n```"}
{"task_id": "BigCodeBench/186", "solution": "from geopy.distance import geodesic\nimport folium\ndef task_func(dic):\n    if not dic:\n        raise ValueError(\"Input dictionary is empty\")\n    locations = list(dic.keys())\n    distances = {}\n    m = folium.Map(location=[45.5236, -122.6750])\n    for i in range(len(locations)):\n        for j in range(i+1, len(locations)):\n            lat1, lon1 = dic[locations[i]]\n            lat2, lon2 = dic[locations[j]]\n            distance = geodesic((lat1, lon1), (lat2, lon2)).km\n            distances[f\"{locations[i]}-{locations[j]}\"] = distance\n            folium.Marker([lat1, lon1], popup=locations[i]).add_to(m)\n            folium.Marker([lat2, lon2], popup=locations[j]).add_to(m)\n    return m, distances", "raw_solution": "from geopy.distance import geodesic\nimport folium\n\ndef task_func(dic):\n    if not dic:\n        raise ValueError(\"Input dictionary is empty\")\n    locations = list(dic.keys())\n    distances = {}\n    m = folium.Map(location=[45.5236, -122.6750])\n    for i in range(len(locations)):\n        for j in range(i+1, len(locations)):\n            lat1, lon1 = dic[locations[i]]\n            lat2, lon2 = dic[locations[j]]\n            distance = geodesic((lat1, lon1), (lat2, lon2)).km\n            distances[f\"{locations[i]}-{locations[j]}\"] = distance\n            folium.Marker([lat1, lon1], popup=locations[i]).add_to(m)\n            folium.Marker([lat2, lon2], popup=locations[j]).add_to(m)\n    return m, distances\n```"}
{"task_id": "BigCodeBench/187", "solution": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"'Lon' and 'Lat' keys are required in the dictionary.\")\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples.\")\n    if len(cities) != len(set(cities)):\n        raise ValueError(\"Cities should be unique.\")\n    lon_range, lat_range = dic['Lon'], dic['Lat']\n    coordinates = [(np.random.uniform(lon_range[0], lon_range[1]), np.random.uniform(lat_range[0], lat_range[1])) for _ in range(len(cities))]\n    geometry = [Point(coord) for coord in coordinates]\n    df = gpd.GeoDataFrame(cities, geometry=geometry)\n    df.columns = ['City', 'Coordinates']\n    return df", "raw_solution": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"'Lon' and 'Lat' keys are required in the dictionary.\")\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples.\")\n    if len(cities) != len(set(cities)):\n        raise ValueError(\"Cities should be unique.\")\n    lon_range, lat_range = dic['Lon'], dic['Lat']\n    coordinates = [(np.random.uniform(lon_range[0], lon_range[1]), np.random.uniform(lat_range[0], lat_range[1])) for _ in range(len(cities))]\n    geometry = [Point(coord) for coord in coordinates]\n    df = gpd.GeoDataFrame(cities, geometry=geometry)\n    df.columns = ['City', 'Coordinates']\n    return df\n```"}
{"task_id": "BigCodeBench/188", "solution": "import pandas as pd\nimport folium\nfrom geopy.geocoders import Photon\ndef task_func(dic):\n    geolocator = Photon(user_agent=\"geoapiExercises\")\n    df = pd.DataFrame(dic)\n    df['coordinates'] = df['location'].apply(lambda x: geolocator.geocode(x).raw['geometry']['coordinates'] if isinstance(x, str) else x)\n    m = folium.Map(location=[df['coordinates'].mean()[0], df['coordinates'].mean()[1]], zoom_start=13)\n    for i in range(0,len(df)):\n        folium.Marker(location=[df.iloc[i]['coordinates'][1], df.iloc[i]['coordinates'][0]], popup=df.iloc[i]['location']).add_to(m)\n    return m", "raw_solution": "import pandas as pd\nimport folium\nfrom geopy.geocoders import Photon\n\ndef task_func(dic):\n    geolocator = Photon(user_agent=\"geoapiExercises\")\n    df = pd.DataFrame(dic)\n    df['coordinates'] = df['location'].apply(lambda x: geolocator.geocode(x).raw['geometry']['coordinates'] if isinstance(x, str) else x)\n    m = folium.Map(location=[df['coordinates'].mean()[0], df['coordinates'].mean()[1]], zoom_start=13)\n    for i in range(0,len(df)):\n        folium.Marker(location=[df.iloc[i]['coordinates'][1], df.iloc[i]['coordinates'][0]], popup=df.iloc[i]['location']).add_to(m)\n    return m\n```"}
{"task_id": "BigCodeBench/189", "solution": "import re\nimport json\nimport requests\ndef task_func(data_url: str) -> list:\n    try:\n        response = requests.get(data_url)\n        data = json.loads(response.text)\n        names = re.findall(r'\\\"name\\\":\\\"(.*?)\\\"', str(data))\n        return names\n    except:\n        return \"Invalid url input\"", "raw_solution": "import re\nimport json\nimport requests\n\ndef task_func(data_url: str) -> list:\n    try:\n        response = requests.get(data_url)\n        data = json.loads(response.text)\n        names = re.findall(r'\\\"name\\\":\\\"(.*?)\\\"', str(data))\n        return names\n    except:\n        return \"Invalid url input\"\n```"}
{"task_id": "BigCodeBench/190", "solution": "import sqlite3\nimport pandas as pd\nimport csv\nfrom io import StringIO\nDATABASE_NAME = 'test.db'\nTABLE_NAME = 'test_table'\ndef task_func(csv_input):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(DATABASE_NAME)\n    cursor = conn.cursor()\n\n    # Create a new table or replace an existing one\n    cursor.execute(f'DROP TABLE IF EXISTS {TABLE_NAME}')\n    cursor.execute(f'CREATE TABLE {TABLE_NAME} (id INTEGER PRIMARY KEY, name TEXT, age INTEGER)')\n\n    # Insert data into the table\n    if isinstance(csv_input, str):\n        with open(csv_input, 'r') as file:\n            reader = csv.reader(file)\n            next(reader)  # Skip the header row\n            cursor.executemany(f'INSERT INTO {TABLE_NAME} (name, age) VALUES (?, ?)', reader)\n    elif isinstance(csv_input, StringIO):\n        reader = csv.reader(csv_input)\n        next(reader)  # Skip the header row\n        cursor.executemany(f'INSERT INTO {TABLE_NAME} (name, age) VALUES (?, ?)', reader)\n\n    # Commit the changes and close the connection\n    conn.commit()\n    conn.close()\n\n    # Query the table and return the data as a DataFrame\n    conn = sqlite3.connect(DATABASE_NAME)\n    df = pd.read_sql_query(f'SELECT * FROM {TABLE_NAME}', conn)\n    conn.close()\n\n    return df", "raw_solution": "import sqlite3\nimport pandas as pd\nimport csv\nfrom io import StringIO\n\n# Constants\nDATABASE_NAME = 'test.db'\nTABLE_NAME = 'test_table'\n\ndef task_func(csv_input):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(DATABASE_NAME)\n    cursor = conn.cursor()\n\n    # Create a new table or replace an existing one\n    cursor.execute(f'DROP TABLE IF EXISTS {TABLE_NAME}')\n    cursor.execute(f'CREATE TABLE {TABLE_NAME} (id INTEGER PRIMARY KEY, name TEXT, age INTEGER)')\n\n    # Insert data into the table\n    if isinstance(csv_input, str):\n        with open(csv_input, 'r') as file:\n            reader = csv.reader(file)\n            next(reader)  # Skip the header row\n            cursor.executemany(f'INSERT INTO {TABLE_NAME} (name, age) VALUES (?, ?)', reader)\n    elif isinstance(csv_input, StringIO):\n        reader = csv.reader(csv_input)\n        next(reader)  # Skip the header row\n        cursor.executemany(f'INSERT INTO {TABLE_NAME} (name, age) VALUES (?, ?)', reader)\n\n    # Commit the changes and close the connection\n    conn.commit()\n    conn.close()\n\n    # Query the table and return the data as a DataFrame\n    conn = sqlite3.connect(DATABASE_NAME)\n    df = pd.read_sql_query(f'SELECT * FROM {TABLE_NAME}', conn)\n    conn.close()\n\n    return df\n```"}
{"task_id": "BigCodeBench/191", "solution": "import random\nfrom scipy import stats\ndef task_func(animals, mean):\n    # Generate the number of customers based on a Poisson distribution\n    num_customers = stats.poisson.rvs(mean)\n    sales = {animal: 0 for animal in animals}\n\n    for _ in range(num_customers):\n        # Randomly select an animal for the customer to buy\n        animal = random.choice(animals)\n        sales[animal] += 1\n\n    return sales", "raw_solution": "import random\nfrom scipy import stats\n\ndef task_func(animals, mean):\n    # Generate the number of customers based on a Poisson distribution\n    num_customers = stats.poisson.rvs(mean)\n    sales = {animal: 0 for animal in animals}\n\n    for _ in range(num_customers):\n        # Randomly select an animal for the customer to buy\n        animal = random.choice(animals)\n        sales[animal] += 1\n\n    return sales\n```"}
{"task_id": "BigCodeBench/192", "solution": "import re\nimport smtplib\nTEXT = \"Josie Smith [3996 COLLEGE AVENUE, SOMETOWN, MD 21003]Mugsy Dog Smith [2560 OAK ST, GLENMEADE, WI 14098]\"\nRECEPIENT_ADDRESS = \"names@gmail.com\"\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\ndef task_func(text=TEXT, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, recepient_address=RECEPIENT_ADDRESS, smtp=None):\n    # Extract names from the text\n    names = re.findall(r'\\[.*?\\]|(?<=\\s)[A-Z][a-z]*', text)\n    names = [name.strip() for name in names]\n\n    # Send the names in an email\n    if smtp is None:\n        smtp = smtplib.SMTP(smtp_server, smtp_port)\n        smtp.starttls()\n        smtp.login(email_address, email_password)\n\n    message = \"Subject: Extracted Names\\n\\n\" + \"\\n\".join(names)\n    smtp.sendmail(email_address, recepient_address, message)\n\n    smtp.quit()\n\n    return names", "raw_solution": "import re\nimport smtplib\n\n# Constants\nTEXT = \"Josie Smith [3996 COLLEGE AVENUE, SOMETOWN, MD 21003]Mugsy Dog Smith [2560 OAK ST, GLENMEADE, WI 14098]\"\nRECEPIENT_ADDRESS = \"names@gmail.com\"\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\n\ndef task_func(text=TEXT, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, recepient_address=RECEPIENT_ADDRESS, smtp=None):\n    # Extract names from the text\n    names = re.findall(r'\\[.*?\\]|(?<=\\s)[A-Z][a-z]*', text)\n    names = [name.strip() for name in names]\n\n    # Send the names in an email\n    if smtp is None:\n        smtp = smtplib.SMTP(smtp_server, smtp_port)\n        smtp.starttls()\n        smtp.login(email_address, email_password)\n\n    message = \"Subject: Extracted Names\\n\\n\" + \"\\n\".join(names)\n    smtp.sendmail(email_address, recepient_address, message)\n\n    smtp.quit()\n\n    return names\n```"}
{"task_id": "BigCodeBench/193", "solution": "import pandas as pd\nimport numpy as np\nfrom random import choice, randint, sample\nDATA_TYPES = [str, int, float, list, tuple, dict, set]\ndef task_func(rows, columns):\n    data = {}\n    for i in range(columns):\n        data[f'col{i}'] = [choice(DATA_TYPES)() for _ in range(rows)]\n    return pd.DataFrame(data)", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom random import choice, randint, sample\n\n# Constants\nDATA_TYPES = [str, int, float, list, tuple, dict, set]\n\ndef task_func(rows, columns):\n    data = {}\n    for i in range(columns):\n        data[f'col{i}'] = [choice(DATA_TYPES)() for _ in range(rows)]\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/194", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nBAR_COLOR = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black']\ndef task_func(data_size):\n    # Generate random data\n    data = np.random.rand(data_size)\n    # Select a random color for the histogram bars\n    bar_color = np.random.choice(BAR_COLOR)\n    # Plot the histogram\n    plt.hist(data, color=bar_color)\n    plt.show()\n    return data, bar_color", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nBAR_COLOR = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black']\ndef task_func(data_size):\n    # Generate random data\n    data = np.random.rand(data_size)\n    # Select a random color for the histogram bars\n    bar_color = np.random.choice(BAR_COLOR)\n    # Plot the histogram\n    plt.hist(data, color=bar_color)\n    plt.show()\n    return data, bar_color\n```"}
{"task_id": "BigCodeBench/195", "solution": "import subprocess\nimport platform\nimport time\ndef task_func(url):\n    if platform.system() == \"Windows\":\n        command = [\"start\", url]\n    else:\n        command = [\"xdg-open\", url]\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    time.sleep(1)\n    return process.returncode", "raw_solution": "import subprocess\nimport platform\nimport time\n\ndef task_func(url):\n    if platform.system() == \"Windows\":\n        command = [\"start\", url]\n    else:\n        command = [\"xdg-open\", url]\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    time.sleep(1)\n    return process.returncode\n```"}
{"task_id": "BigCodeBench/196", "solution": "import random\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib import pyplot as plt\ndef task_func(length, range_limit=100, seed=0):\n    if range_limit <= 1:\n        raise ValueError(\"range_limit should be greater than 1\")\n    random.seed(seed)\n    numbers = [random.randint(0, range_limit) for _ in range(length)]\n    numbers.sort()\n    ax = sns.histplot(numbers, bins=range_limit)\n    plt.show()\n    return ax, numbers", "raw_solution": "import random\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\ndef task_func(length, range_limit=100, seed=0):\n    if range_limit <= 1:\n        raise ValueError(\"range_limit should be greater than 1\")\n    random.seed(seed)\n    numbers = [random.randint(0, range_limit) for _ in range(length)]\n    numbers.sort()\n    ax = sns.histplot(numbers, bins=range_limit)\n    plt.show()\n    return ax, numbers\n```"}
{"task_id": "BigCodeBench/197", "solution": "import heapq\nimport math\nimport matplotlib.pyplot as plt\ndef task_func(l1, l2, N=10):\n    diffs = [(abs(a - b))**0.5 for a, b in zip(l1, l2)]\n    top_diffs = heapq.nlargest(N, diffs)\n    plt.plot(top_diffs)\n    return plt.gca()", "raw_solution": "import heapq\nimport math\nimport matplotlib.pyplot as plt\n\ndef task_func(l1, l2, N=10):\n    diffs = [(abs(a - b))**0.5 for a, b in zip(l1, l2)]\n    top_diffs = heapq.nlargest(N, diffs)\n    plt.plot(top_diffs)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/198", "solution": "import numpy as np\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\ndef task_func(data, value):\n    if not data:\n        return np.array([]), 0\n    avg = statistics.mean(data)\n    data = [x for x in data if x > avg]\n    count = bisect.bisect_right(data, value)\n    plt.hist(data, bins=10)\n    plt.show()\n    return np.array(data), count", "raw_solution": "import numpy as np\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\n\ndef task_func(data, value):\n    if not data:\n        return np.array([]), 0\n    avg = statistics.mean(data)\n    data = [x for x in data if x > avg]\n    count = bisect.bisect_right(data, value)\n    plt.hist(data, bins=10)\n    plt.show()\n    return np.array(data), count\n```"}
{"task_id": "BigCodeBench/199", "solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime must be a datetime object\")\n    if not all(isinstance(city, str) for city in cities):\n        raise ValueError(\"All cities must be strings\")\n    if not all(isinstance(condition, str) for condition in weather_conditions):\n        raise ValueError(\"All weather conditions must be strings\")\n    if not all(isinstance(tz, str) for tz in timezones.values()):\n        raise ValueError(\"All timezones must be strings\")\n    if not isinstance(seed, int):\n        raise ValueError(\"Seed must be an integer\")\n\n    set_seed(seed)\n\n    data = []\n    for city in cities:\n        local_time = utc_datetime.astimezone(pytz.timezone(timezones[city]))\n        data.append({\n            'City': city,\n            'Local Time': local_time.strftime('%Y-%m-%d %H:%M:%S %Z'),\n            'Weather Condition': weather_conditions[randint(0, len(weather_conditions) - 1)]\n        })\n\n    return pd.DataFrame(data)", "raw_solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\n\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime must be a datetime object\")\n    if not all(isinstance(city, str) for city in cities):\n        raise ValueError(\"All cities must be strings\")\n    if not all(isinstance(condition, str) for condition in weather_conditions):\n        raise ValueError(\"All weather conditions must be strings\")\n    if not all(isinstance(tz, str) for tz in timezones.values()):\n        raise ValueError(\"All timezones must be strings\")\n    if not isinstance(seed, int):\n        raise ValueError(\"Seed must be an integer\")\n\n    set_seed(seed)\n\n    data = []\n    for city in cities:\n        local_time = utc_datetime.astimezone(pytz.timezone(timezones[city]))\n        data.append({\n            'City': city,\n            'Local Time': local_time.strftime('%Y-%m-%d %H:%M:%S %Z'),\n            'Weather Condition': weather_conditions[randint(0, len(weather_conditions) - 1)]\n        })\n\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/200", "solution": "import random\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\ndef task_func(n, value):\n    # Generate 'n' random numbers between 0 and 1\n    numbers = [random.random() for _ in range(n)]\n    # Calculate the average of the generated numbers\n    avg = statistics.mean(numbers)\n    # Find numbers greater than the average\n    numbers_greater_avg = [num for num in numbers if num > avg]\n    # Count numbers greater than or equal to the specified value\n    count = bisect.bisect_right(numbers_greater_avg, value)\n    # Sort the numbers\n    numbers_greater_avg.sort()\n    # Plot the sorted numbers\n    plt.plot(numbers_greater_avg)\n    plt.show()\n    return numbers_greater_avg, count", "raw_solution": "import random\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\n\ndef task_func(n, value):\n    # Generate 'n' random numbers between 0 and 1\n    numbers = [random.random() for _ in range(n)]\n    # Calculate the average of the generated numbers\n    avg = statistics.mean(numbers)\n    # Find numbers greater than the average\n    numbers_greater_avg = [num for num in numbers if num > avg]\n    # Count numbers greater than or equal to the specified value\n    count = bisect.bisect_right(numbers_greater_avg, value)\n    # Sort the numbers\n    numbers_greater_avg.sort()\n    # Plot the sorted numbers\n    plt.plot(numbers_greater_avg)\n    plt.show()\n    return numbers_greater_avg, count\n```"}
{"task_id": "BigCodeBench/201", "solution": "import bisect\nimport statistics\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(df, column, value):\n    if column not in df.columns:\n        raise ValueError(\"Column does not exist in the DataFrame\")\n    if not isinstance(value, (int, float)):\n        raise ValueError(\"Value is not a number\")\n\n    column_data = df[column].dropna().values\n    avg = statistics.mean(column_data)\n    values_greater_avg = column_data[column_data > avg]\n    count_greater_value = bisect.bisect_right(values_greater_avg, value)\n\n    fig, ax = plt.subplots()\n    ax.hist(values_greater_avg, bins='auto', color='blue')\n    ax.set_title(f\"Histogram of values greater than average ({avg})\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n\n    return values_greater_avg, count_greater_value, ax", "raw_solution": "import bisect\nimport statistics\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df, column, value):\n    if column not in df.columns:\n        raise ValueError(\"Column does not exist in the DataFrame\")\n    if not isinstance(value, (int, float)):\n        raise ValueError(\"Value is not a number\")\n\n    column_data = df[column].dropna().values\n    avg = statistics.mean(column_data)\n    values_greater_avg = column_data[column_data > avg]\n    count_greater_value = bisect.bisect_right(values_greater_avg, value)\n\n    fig, ax = plt.subplots()\n    ax.hist(values_greater_avg, bins='auto', color='blue')\n    ax.set_title(f\"Histogram of values greater than average ({avg})\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n\n    return values_greater_avg, count_greater_value, ax"}
{"task_id": "BigCodeBench/202", "solution": "import re\nimport json\nfrom collections import Counter\ndef task_func(json_str, top_n=10):\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    urls = re.findall(url_pattern, json_str)\n    url_counts = Counter(urls)\n    return dict(url_counts.most_common(top_n))", "raw_solution": "import re\nimport json\nfrom collections import Counter\n\ndef task_func(json_str, top_n=10):\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    urls = re.findall(url_pattern, json_str)\n    url_counts = Counter(urls)\n    return dict(url_counts.most_common(top_n))\n```"}
{"task_id": "BigCodeBench/203", "solution": "import json\nimport smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\ndef task_func(input_data=None, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, smtp=None):\n    if smtp is None:\n        smtp = smtplib.SMTP(smtp_server, smtp_port)\n        smtp.starttls()\n        smtp.login(email_address, email_password)\n\n    data = json.loads(input_data)\n    names = [item['name'] for item in data['data']]\n\n    message = MIMEMultipart()\n    message['From'] = email_address\n    message['To'] = data['recepient']\n    message['Subject'] = 'Extracted Names'\n    message.attach(MIMEText('\\n'.join(names)))\n\n    smtp.send_message(message)\n    smtp.quit()\n\n    return names", "raw_solution": "import json\nimport smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\n\n# Constants\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\n\ndef task_func(input_data=None, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, smtp=None):\n    if smtp is None:\n        smtp = smtplib.SMTP(smtp_server, smtp_port)\n        smtp.starttls()\n        smtp.login(email_address, email_password)\n\n    data = json.loads(input_data)\n    names = [item['name'] for item in data['data']]\n\n    message = MIMEMultipart()\n    message['From'] = email_address\n    message['To'] = data['recepient']\n    message['Subject'] = 'Extracted Names'\n    message.attach(MIMEText('\\n'.join(names)))\n\n    smtp.send_message(message)\n    smtp.quit()\n\n    return names\n```"}
{"task_id": "BigCodeBench/204", "solution": "import numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(L):\n    mean = np.mean(L)\n    median = np.median(L)\n    mode = Counter(L).most_common(1)[0][0]\n    std_dev = np.std(L)\n\n    fig, ax = plt.subplots()\n    ax.hist(L, bins=10, edgecolor='black')\n    ax.set_title('Histogram of L')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return {'mean': mean, 'median': median, 'mode': mode, 'std_dev': std_dev, 'plot': ax}", "raw_solution": "import numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    mean = np.mean(L)\n    median = np.median(L)\n    mode = Counter(L).most_common(1)[0][0]\n    std_dev = np.std(L)\n\n    fig, ax = plt.subplots()\n    ax.hist(L, bins=10, edgecolor='black')\n    ax.set_title('Histogram of L')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return {'mean': mean, 'median': median, 'mode': mode, 'std_dev': std_dev, 'plot': ax}\n```"}
{"task_id": "BigCodeBench/205", "solution": "import subprocess\nfrom multiprocessing import Pool\ndef execute_command(command):\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    output, _ = process.communicate()\n    return output\ndef task_func(commands):\n    if not commands:\n        return []\n    with Pool(len(commands)) as p:\n        return p.map(execute_command, commands)", "raw_solution": "import subprocess\nfrom multiprocessing import Pool\n\ndef execute_command(command):\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    output, _ = process.communicate()\n    return output\n\ndef task_func(commands):\n    if not commands:\n        return []\n    with Pool(len(commands)) as p:\n        return p.map(execute_command, commands)\n```"}
{"task_id": "BigCodeBench/206", "solution": "import csv\nimport json\nimport os\ndef task_func(file_name):\n    try:\n        with open(file_name, 'r') as csv_file:\n            csv_reader = csv.DictReader(csv_file)\n            json_data = [row for row in csv_reader]\n\n        json_file_name = os.path.splitext(file_name)[0] + '.json'\n        with open(json_file_name, 'w') as json_file:\n            json.dump(json_data, json_file)\n\n        return json_file_name\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"The file {file_name} does not exist.\")", "raw_solution": "import csv\nimport json\nimport os\n\ndef task_func(file_name):\n    try:\n        with open(file_name, 'r') as csv_file:\n            csv_reader = csv.DictReader(csv_file)\n            json_data = [row for row in csv_reader]\n\n        json_file_name = os.path.splitext(file_name)[0] + '.json'\n        with open(json_file_name, 'w') as json_file:\n            json.dump(json_data, json_file)\n\n        return json_file_name\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"The file {file_name} does not exist.\")\n```"}
{"task_id": "BigCodeBench/207", "solution": "import re\nimport requests\ndef task_func(input):\n    # Extract the API endpoint from the input string\n    endpoint = re.search(r'https?://[^\\s]+', input).group(0)\n\n    # Send a GET request to the endpoint\n    response = requests.get(endpoint)\n\n    # Return the response data in JSON format\n    return response.json()", "raw_solution": "import re\nimport requests\n\ndef task_func(input):\n    # Extract the API endpoint from the input string\n    endpoint = re.search(r'https?://[^\\s]+', input).group(0)\n\n    # Send a GET request to the endpoint\n    response = requests.get(endpoint)\n\n    # Return the response data in JSON format\n    return response.json()\n```"}
{"task_id": "BigCodeBench/208", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError(\"elements must be a positive integer\")\n    np.random.seed(seed)\n    random_walk = np.random.choice([-1, 1], size=elements)\n    random_walk_cumulative = np.cumsum(random_walk)\n    stats = pd.Series(random_walk_cumulative).describe()\n    fig, ax = plt.subplots()\n    ax.plot(random_walk_cumulative)\n    ax.set_xlabel('Steps')\n    ax.set_ylabel('Cumulative Sum')\n    ax.set_title('Random Walk')\n    return stats, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError(\"elements must be a positive integer\")\n    np.random.seed(seed)\n    random_walk = np.random.choice([-1, 1], size=elements)\n    random_walk_cumulative = np.cumsum(random_walk)\n    stats = pd.Series(random_walk_cumulative).describe()\n    fig, ax = plt.subplots()\n    ax.plot(random_walk_cumulative)\n    ax.set_xlabel('Steps')\n    ax.set_ylabel('Cumulative Sum')\n    ax.set_title('Random Walk')\n    return stats, ax\n```"}
{"task_id": "BigCodeBench/209", "solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Find the tuple with the maximum value at index 1\n    max_tuple = max(data, key=itemgetter(1))\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(*zip(*data))\n\n    # Highlight the tuple with the maximum value at index 1\n    ax.scatter(*max_tuple, color='red', label='Max Tuple')\n\n    # Set the title and labels\n    ax.set_title('Max Tuple Highlighted')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n\n    # Add a legend\n    ax.legend()\n\n    return ax", "raw_solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Find the tuple with the maximum value at index 1\n    max_tuple = max(data, key=itemgetter(1))\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(*zip(*data))\n\n    # Highlight the tuple with the maximum value at index 1\n    ax.scatter(*max_tuple, color='red', label='Max Tuple')\n\n    # Set the title and labels\n    ax.set_title('Max Tuple Highlighted')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n\n    # Add a legend\n    ax.legend()\n\n    return ax\n```"}
{"task_id": "BigCodeBench/210", "solution": "import collections\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Count the frequency of each letter in the data\n    letter_counts = collections.Counter(data)\n\n    # Find the letter with the maximum count\n    max_letter = max(letter_counts.items(), key=itemgetter(1))[0]\n\n    # Create a bar plot of the letter counts\n    fig, ax = plt.subplots()\n    ax.bar(letter_counts.keys(), letter_counts.values())\n\n    # Highlight the letter with the maximum count\n    ax.bar(max_letter, letter_counts[max_letter], color='r')\n\n    # Set the plot labels and title\n    ax.set_xlabel('Letter')\n    ax.set_ylabel('Count')\n    ax.set_title('Letter Counts with Max Value Letter Highlighted')\n    ax.legend(['Letter Counts', 'Max Value Letter'])\n\n    return ax", "raw_solution": "import collections\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Count the frequency of each letter in the data\n    letter_counts = collections.Counter(data)\n\n    # Find the letter with the maximum count\n    max_letter = max(letter_counts.items(), key=itemgetter(1))[0]\n\n    # Create a bar plot of the letter counts\n    fig, ax = plt.subplots()\n    ax.bar(letter_counts.keys(), letter_counts.values())\n\n    # Highlight the letter with the maximum count\n    ax.bar(max_letter, letter_counts[max_letter], color='r')\n\n    # Set the plot labels and title\n    ax.set_xlabel('Letter')\n    ax.set_ylabel('Count')\n    ax.set_title('Letter Counts with Max Value Letter Highlighted')\n    ax.legend(['Letter Counts', 'Max Value Letter'])\n\n    return ax\n```"}
{"task_id": "BigCodeBench/211", "solution": "import requests\nimport os\nimport zipfile\ndef task_func(url, destination_directory, headers=None):\n    response = requests.get(url, headers=headers)\n    with open('temp.zip', 'wb') as f:\n        f.write(response.content)\n    with zipfile.ZipFile('temp.zip', 'r') as zip_ref:\n        zip_ref.extractall(destination_directory)\n    os.remove('temp.zip')\n    return [file for file in os.listdir(destination_directory) if os.path.isfile(os.path.join(destination_directory, file))]", "raw_solution": "import requests\nimport os\nimport zipfile\n\ndef task_func(url, destination_directory, headers=None):\n    response = requests.get(url, headers=headers)\n    with open('temp.zip', 'wb') as f:\n        f.write(response.content)\n    with zipfile.ZipFile('temp.zip', 'r') as zip_ref:\n        zip_ref.extractall(destination_directory)\n    os.remove('temp.zip')\n    return [file for file in os.listdir(destination_directory) if os.path.isfile(os.path.join(destination_directory, file))]\n```"}
{"task_id": "BigCodeBench/212", "solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(data[:, 0], data[:, 1])\n\n    # Label the axes\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n\n    # Set the title\n    ax.set_title('Points with Max Y Point Highlighted')\n\n    # Find the point with the maximum y-value\n    max_y_point = max(data, key=itemgetter(1))\n\n    # Mark the point with the maximum y-value\n    ax.scatter(max_y_point[0], max_y_point[1], color='red')\n\n    return ax, max_y_point", "raw_solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(data[:, 0], data[:, 1])\n\n    # Label the axes\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n\n    # Set the title\n    ax.set_title('Points with Max Y Point Highlighted')\n\n    # Find the point with the maximum y-value\n    max_y_point = max(data, key=itemgetter(1))\n\n    # Mark the point with the maximum y-value\n    ax.scatter(max_y_point[0], max_y_point[1], color='red')\n\n    return ax, max_y_point\n```"}
{"task_id": "BigCodeBench/213", "solution": "import time\nimport random\nimport matplotlib.pyplot as plt\nfrom scipy.stats import kurtosis\ndef task_func(intervals=100, seed=0):\n    random.seed(seed)\n    numbers = []\n    for i in range(intervals):\n        numbers.append(random.random())\n        time.sleep(1)\n\n    fig, ax = plt.subplots()\n    ax.plot(range(intervals), numbers)\n    ax.set_xlabel('Elapsed Time (s)')\n    ax.set_ylabel('Random Number')\n    ax.set_title('Random Number Generation Over Time')\n    plt.show()\n\n    kurt = kurtosis(numbers)\n    return ax, kurt", "raw_solution": "import time\nimport random\nimport matplotlib.pyplot as plt\nfrom scipy.stats import kurtosis\n\ndef task_func(intervals=100, seed=0):\n    random.seed(seed)\n    numbers = []\n    for i in range(intervals):\n        numbers.append(random.random())\n        time.sleep(1)\n\n    fig, ax = plt.subplots()\n    ax.plot(range(intervals), numbers)\n    ax.set_xlabel('Elapsed Time (s)')\n    ax.set_ylabel('Random Number')\n    ax.set_title('Random Number Generation Over Time')\n    plt.show()\n\n    kurt = kurtosis(numbers)\n    return ax, kurt\n```"}
{"task_id": "BigCodeBench/214", "solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low >= range_high:\n        raise ValueError(\"range_low must be less than range_high\")\n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, size=image_size)\n    plt.imshow(image)\n    plt.show()\n    return image", "raw_solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low >= range_high:\n        raise ValueError(\"range_low must be less than range_high\")\n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, size=image_size)\n    plt.imshow(image)\n    plt.show()\n    return image\n```"}
{"task_id": "BigCodeBench/215", "solution": "import requests\nimport json\nimport pandas as pd\nimport seaborn as sns\nHEADERS = {\n    'accept': 'application/json'\n}\ndef task_func(url, parameters):\n    try:\n        response = requests.get(url, headers=HEADERS, params=parameters)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise Exception(f\"Error: {e}\")\n\n    data = response.json()\n    if not data:\n        raise Exception(\"Empty data\")\n\n    df = pd.DataFrame(data)\n    if df.empty:\n        raise Exception(\"Invalid data\")\n\n    corr = df.corr()\n    mask = np.triu(np.ones_like(corr, dtype=bool))\n    fig, ax = plt.subplots(figsize=(11, 9))\n    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n    plt.show()\n    return df, ax", "raw_solution": "import requests\nimport json\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nHEADERS = {\n    'accept': 'application/json'\n}\n\ndef task_func(url, parameters):\n    try:\n        response = requests.get(url, headers=HEADERS, params=parameters)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise Exception(f\"Error: {e}\")\n\n    data = response.json()\n    if not data:\n        raise Exception(\"Empty data\")\n\n    df = pd.DataFrame(data)\n    if df.empty:\n        raise Exception(\"Invalid data\")\n\n    corr = df.corr()\n    mask = np.triu(np.ones_like(corr, dtype=bool))\n    fig, ax = plt.subplots(figsize=(11, 9))\n    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n    plt.show()\n    return df, ax\n```"}
{"task_id": "BigCodeBench/216", "solution": "import pandas as pd\nimport os\nimport json\nfrom collections import Counter\ndef task_func(json_dir_path, word_count):\n    # Initialize an empty list to store the text content from all JSON files\n    text_content = []\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(json_dir_path):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the file and load its content\n            with open(os.path.join(json_dir_path, filename), 'r') as file:\n                data = json.load(file)\n\n            # Extract the text content from the file and append it to the list\n            text_content.append(data['text'])\n\n    # Join all the text content into a single string\n    all_text = ' '.join(text_content)\n\n    # Split the text into words\n    words = all_text.split()\n\n    # Count the frequency of each word\n    word_freq = Counter(words)\n\n    # Return the most common words and their counts\n    return word_freq.most_common(word_count)", "raw_solution": "import pandas as pd\nimport os\nimport json\nfrom collections import Counter\n\ndef task_func(json_dir_path, word_count):\n    # Initialize an empty list to store the text content from all JSON files\n    text_content = []\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(json_dir_path):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the file and load its content\n            with open(os.path.join(json_dir_path, filename), 'r') as file:\n                data = json.load(file)\n\n            # Extract the text content from the file and append it to the list\n            text_content.append(data['text'])\n\n    # Join all the text content into a single string\n    all_text = ' '.join(text_content)\n\n    # Split the text into words\n    words = all_text.split()\n\n    # Count the frequency of each word\n    word_freq = Counter(words)\n\n    # Return the most common words and their counts\n    return word_freq.most_common(word_count)\n```"}
{"task_id": "BigCodeBench/217", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(mu=0, sigma=1, sample_size=1000, seed=0):\n    np.random.seed(seed)\n    sample = np.random.normal(mu, sigma, sample_size)\n    x = np.linspace(sample.min(), sample.max(), 100)\n    y = stats.norm.pdf(x, mu, sigma)\n\n    fig, ax = plt.subplots()\n    ax.hist(sample, bins=30, density=True, alpha=0.6, color='g', label='Histogram')\n    ax.plot(x, y, 'k', label='Normal PDF')\n    ax.set_title(f'Normal Distribution with $\\\\mu = {mu:.2f}, \\\\sigma = {sigma:.2f}$')\n    ax.legend()\n\n    empirical_mean = np.mean(sample)\n    empirical_std_dev = np.std(sample)\n\n    return ax, empirical_mean, empirical_std_dev", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(mu=0, sigma=1, sample_size=1000, seed=0):\n    np.random.seed(seed)\n    sample = np.random.normal(mu, sigma, sample_size)\n    x = np.linspace(sample.min(), sample.max(), 100)\n    y = stats.norm.pdf(x, mu, sigma)\n\n    fig, ax = plt.subplots()\n    ax.hist(sample, bins=30, density=True, alpha=0.6, color='g', label='Histogram')\n    ax.plot(x, y, 'k', label='Normal PDF')\n    ax.set_title(f'Normal Distribution with $\\\\mu = {mu:.2f}, \\\\sigma = {sigma:.2f}$')\n    ax.legend()\n\n    empirical_mean = np.mean(sample)\n    empirical_std_dev = np.std(sample)\n\n    return ax, empirical_mean, empirical_std_dev\n```"}
{"task_id": "BigCodeBench/218", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\nTARGET = 'target'\ndef task_func(df, dict_mapping, plot_histogram=False):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    if TARGET not in df.columns or any(feature not in df.columns for feature in FEATURES):\n        raise ValueError(\"FEATURES and TARGET columns not in the input DataFrame\")\n\n    df = df.replace(dict_mapping)\n\n    scaler = StandardScaler()\n    df[FEATURES] = scaler.fit_transform(df[FEATURES])\n\n    if plot_histogram:\n        import matplotlib.pyplot as plt\n        plt.hist(df[TARGET], bins=10)\n        plt.title('Histogram of Target Variable')\n        plt.xlabel('Target')\n        plt.ylabel('Frequency')\n        return plt.gca()\n    else:\n        return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\n# Constants\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\nTARGET = 'target'\n\ndef task_func(df, dict_mapping, plot_histogram=False):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    if TARGET not in df.columns or any(feature not in df.columns for feature in FEATURES):\n        raise ValueError(\"FEATURES and TARGET columns not in the input DataFrame\")\n\n    df = df.replace(dict_mapping)\n\n    scaler = StandardScaler()\n    df[FEATURES] = scaler.fit_transform(df[FEATURES])\n\n    if plot_histogram:\n        import matplotlib.pyplot as plt\n        plt.hist(df[TARGET], bins=10)\n        plt.title('Histogram of Target Variable')\n        plt.xlabel('Target')\n        plt.ylabel('Frequency')\n        return plt.gca()\n    else:\n        return df\n```"}
{"task_id": "BigCodeBench/219", "solution": "import math\nimport statistics\nimport numpy as np\nfrom scipy.signal import fftconvolve\ndef task_func(input_list):\n    # Sort the input list based on the degree value of its elements\n    input_list.sort(key=lambda x: x[1])\n\n    # Calculate the mean, median, and mode of the sorted list\n    degrees = [x[1] for x in input_list]\n    mean_degree = round(statistics.mean(degrees), 2)\n    median_degree = round(statistics.median(degrees), 2)\n    mode_degree = round(statistics.mode(degrees), 2)\n\n    # Calculate the mean, median, and mode of the magnitude of the fast fourier transform of the degree values\n    fft_degrees = np.abs(np.fft.fft(degrees)).tolist()\n    fft_mean_degree = round(statistics.mean(fft_degrees), 2)\n    fft_median_degree = round(statistics.median(fft_degrees), 2)\n    fft_mode_degree = round(statistics.mode(fft_degrees), 2)\n\n    return (mean_degree, median_degree, mode_degree, fft_mean_degree, fft_median_degree, fft_mode_degree)", "raw_solution": "import math\nimport statistics\nimport numpy as np\nfrom scipy.signal import fftconvolve\n\ndef task_func(input_list):\n    # Sort the input list based on the degree value of its elements\n    input_list.sort(key=lambda x: x[1])\n\n    # Calculate the mean, median, and mode of the sorted list\n    degrees = [x[1] for x in input_list]\n    mean_degree = round(statistics.mean(degrees), 2)\n    median_degree = round(statistics.median(degrees), 2)\n    mode_degree = round(statistics.mode(degrees), 2)\n\n    # Calculate the mean, median, and mode of the magnitude of the fast fourier transform of the degree values\n    fft_degrees = np.abs(np.fft.fft(degrees)).tolist()\n    fft_mean_degree = round(statistics.mean(fft_degrees), 2)\n    fft_median_degree = round(statistics.median(fft_degrees), 2)\n    fft_mode_degree = round(statistics.mode(fft_degrees), 2)\n\n    return (mean_degree, median_degree, mode_degree, fft_mean_degree, fft_median_degree, fft_mode_degree)\n```"}
{"task_id": "BigCodeBench/220", "solution": "from random import choice\nimport turtle\nimport time\ndef task_func(colors):\n    t = turtle.Turtle()\n    t.speed(1)\n    turtle.bgcolor(\"black\")\n    t.color(\"white\")\n    t.shape(\"turtle\")\n    for i in range(5):\n        t.color(choice(colors))\n        t.begin_fill()\n        for _ in range(4):\n            t.forward(100)\n            t.right(90)\n        t.end_fill()\n        t.penup()\n        t.goto(0, 0)\n        t.pendown()\n        time.sleep(1)\n    turtle.done()", "raw_solution": "from random import choice\nimport turtle\nimport time\n\ndef task_func(colors):\n    t = turtle.Turtle()\n    t.speed(1)\n    turtle.bgcolor(\"black\")\n    t.color(\"white\")\n    t.shape(\"turtle\")\n    for i in range(5):\n        t.color(choice(colors))\n        t.begin_fill()\n        for _ in range(4):\n            t.forward(100)\n            t.right(90)\n        t.end_fill()\n        t.penup()\n        t.goto(0, 0)\n        t.pendown()\n        time.sleep(1)\n    turtle.done()\n```"}
{"task_id": "BigCodeBench/221", "solution": "import numpy as np\nfrom scipy import stats\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\ndef task_func(df, dct):\n    if not all(feature in df.columns for feature in FEATURES):\n        return \"Invalid input\"\n    for key, value in dct.items():\n        df[key] = df[key].replace(value)\n    result = {}\n    for feature in FEATURES:\n        try:\n            mean = df[feature].mean()\n            median = df[feature].median()\n            mode = stats.mode(df[feature])[0][0]\n            variance = df[feature].var()\n            result[feature] = {'mean': mean, 'median': median, 'mode': mode, 'variance': variance}\n        except Exception as e:\n            return \"Invalid input\"\n    return result", "raw_solution": "import numpy as np\nfrom scipy import stats\n# Constants\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\ndef task_func(df, dct):\n    if not all(feature in df.columns for feature in FEATURES):\n        return \"Invalid input\"\n    for key, value in dct.items():\n        df[key] = df[key].replace(value)\n    result = {}\n    for feature in FEATURES:\n        try:\n            mean = df[feature].mean()\n            median = df[feature].median()\n            mode = stats.mode(df[feature])[0][0]\n            variance = df[feature].var()\n            result[feature] = {'mean': mean, 'median': median, 'mode': mode, 'variance': variance}\n        except Exception as e:\n            return \"Invalid input\"\n    return result\n```"}
{"task_id": "BigCodeBench/222", "solution": "import math\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(list_input):\n    # Sort the list based on the degree value of its elements\n    sorted_list = sorted(list_input, key=lambda x: abs(x))\n\n    # Calculate the cumulative sum of the sorted list\n    cumulative_sum = np.cumsum(sorted_list)\n\n    # Plot the line chart of the cumulative sum\n    fig, ax = plt.subplots()\n    ax.plot(cumulative_sum)\n\n    return cumulative_sum, ax", "raw_solution": "import math\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(list_input):\n    # Sort the list based on the degree value of its elements\n    sorted_list = sorted(list_input, key=lambda x: abs(x))\n\n    # Calculate the cumulative sum of the sorted list\n    cumulative_sum = np.cumsum(sorted_list)\n\n    # Plot the line chart of the cumulative sum\n    fig, ax = plt.subplots()\n    ax.plot(cumulative_sum)\n\n    return cumulative_sum, ax\n```"}
{"task_id": "BigCodeBench/223", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(df, dct, columns=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    if columns is not None:\n        df = df[columns]\n    for col in df.columns:\n        if df[col].dtype == object:\n            le = LabelEncoder()\n            df[col] = le.fit_transform(df[col])\n        elif col in dct:\n            df[col] = df[col].replace(dct[col])\n    for col in df.columns:\n        if df[col].dtype != object:\n            df[col] = (df[col] - df[col].mean()) / df[col].std()\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(df, dct, columns=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    if columns is not None:\n        df = df[columns]\n    for col in df.columns:\n        if df[col].dtype == object:\n            le = LabelEncoder()\n            df[col] = le.fit_transform(df[col])\n        elif col in dct:\n            df[col] = df[col].replace(dct[col])\n    for col in df.columns:\n        if df[col].dtype != object:\n            df[col] = (df[col] - df[col].mean()) / df[col].std()\n    return df\n```"}
{"task_id": "BigCodeBench/224", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\ndef task_func(range_start=-10, range_end=10, step=0.1):\n    def generator():\n        for x in np.arange(range_start, range_end, step):\n            yield (x, np.sin(x), np.cos(x), np.abs(np.sin(x) - np.cos(x)))\n\n    x_values, sin_values, cos_values, abs_diff_values = zip(*generator())\n\n    fig, ax = plt.subplots()\n    ax.plot(x_values, sin_values, label='sin(x)')\n    ax.plot(x_values, cos_values, label='cos(x)')\n    ax.plot(x_values, abs_diff_values, label='abs(sin(x) - cos(x))')\n    ax.legend()\n    plt.show()\n\n    fft_abs_diff = np.abs(fft(abs_diff_values))\n    mean_fft_abs_diff = np.mean(fft_abs_diff)\n    median_fft_abs_diff = np.median(fft_abs_diff)\n\n    return mean_fft_abs_diff, median_fft_abs_diff", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\n\ndef task_func(range_start=-10, range_end=10, step=0.1):\n    def generator():\n        for x in np.arange(range_start, range_end, step):\n            yield (x, np.sin(x), np.cos(x), np.abs(np.sin(x) - np.cos(x)))\n\n    x_values, sin_values, cos_values, abs_diff_values = zip(*generator())\n\n    fig, ax = plt.subplots()\n    ax.plot(x_values, sin_values, label='sin(x)')\n    ax.plot(x_values, cos_values, label='cos(x)')\n    ax.plot(x_values, abs_diff_values, label='abs(sin(x) - cos(x))')\n    ax.legend()\n    plt.show()\n\n    fft_abs_diff = np.abs(fft(abs_diff_values))\n    mean_fft_abs_diff = np.mean(fft_abs_diff)\n    median_fft_abs_diff = np.median(fft_abs_diff)\n\n    return mean_fft_abs_diff, median_fft_abs_diff\n```"}
{"task_id": "BigCodeBench/225", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, dct, columns=None, plot_histograms=False):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    df = df.copy()\n    for col, value in dct.items():\n        if columns is None or col in columns:\n            df[col] = df[col].replace(value)\n    if plot_histograms:\n        for col in columns:\n            plt.figure(figsize=(10, 6))\n            df[col].hist(bins=10)\n            plt.title(f\"Histogram of {col}\")\n            plt.show()\n    return df", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, dct, columns=None, plot_histograms=False):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    df = df.copy()\n    for col, value in dct.items():\n        if columns is None or col in columns:\n            df[col] = df[col].replace(value)\n    if plot_histograms:\n        for col in columns:\n            plt.figure(figsize=(10, 6))\n            df[col].hist(bins=10)\n            plt.title(f\"Histogram of {col}\")\n            plt.show()\n    return df\n```"}
{"task_id": "BigCodeBench/226", "solution": "import numpy as np\nimport math\nimport matplotlib.pyplot as plt\ndef task_func(range_start=0, range_end=10, step=0.1):\n    def exp_generator(start, end, step):\n        for x in np.arange(start, end, step):\n            yield (x, math.exp(x))\n\n    x_values, y_values = zip(*exp_generator(range_start, range_end, step))\n\n    fig, ax = plt.subplots()\n    ax.plot(x_values, y_values)\n    ax.set_xlabel('x')\n    ax.set_ylabel('e^x')\n    ax.set_title('Exponential Function')\n\n    return exp_generator(range_start, range_end, step), ax", "raw_solution": "import numpy as np\nimport math\nimport matplotlib.pyplot as plt\n\ndef task_func(range_start=0, range_end=10, step=0.1):\n    def exp_generator(start, end, step):\n        for x in np.arange(start, end, step):\n            yield (x, math.exp(x))\n\n    x_values, y_values = zip(*exp_generator(range_start, range_end, step))\n\n    fig, ax = plt.subplots()\n    ax.plot(x_values, y_values)\n    ax.set_xlabel('x')\n    ax.set_ylabel('e^x')\n    ax.set_title('Exponential Function')\n\n    return exp_generator(range_start, range_end, step), ax\n```"}
{"task_id": "BigCodeBench/227", "solution": "import numpy as np\nimport os\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\ndef task_func(L, M, N, audio_file):\n    if not os.path.exists(audio_file):\n        raise FileNotFoundError(\"The specified audio file does not exist.\")\n\n    data, sample_rate = librosa.load(audio_file)\n    SPL = 20 * np.log10(np.sqrt(np.mean(data**2)))\n\n    matrix = np.array(L).reshape(M, N)\n    normalized_matrix = matrix / np.max(matrix) * SPL\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(normalized_matrix, shading='gouraud')\n    ax.set_yscale('log')\n    ax.set_xscale('linear')\n    ax.set_title('Spectrogram')\n    ax.set_ylabel('Frequency [Hz]')\n    ax.set_xlabel('Time [s]')\n\n    return normalized_matrix, fig", "raw_solution": "import numpy as np\nimport os\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\n\ndef task_func(L, M, N, audio_file):\n    if not os.path.exists(audio_file):\n        raise FileNotFoundError(\"The specified audio file does not exist.\")\n\n    data, sample_rate = librosa.load(audio_file)\n    SPL = 20 * np.log10(np.sqrt(np.mean(data**2)))\n\n    matrix = np.array(L).reshape(M, N)\n    normalized_matrix = matrix / np.max(matrix) * SPL\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(normalized_matrix, shading='gouraud')\n    ax.set_yscale('log')\n    ax.set_xscale('linear')\n    ax.set_title('Spectrogram')\n    ax.set_ylabel('Frequency [Hz]')\n    ax.set_xlabel('Time [s]')\n\n    return normalized_matrix, fig\n```"}
{"task_id": "BigCodeBench/228", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(df, dct):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    df = df.replace(dct)\n    return df.corr(method='pearson')", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(df, dct):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    df = df.replace(dct)\n    return df.corr(method='pearson')\n```"}
{"task_id": "BigCodeBench/229", "solution": "import json\nimport random\nfrom datetime import datetime, timedelta\nUSERS = ['Alice', 'Bob', 'Charlie', 'Dave', 'Eve']\nACTIONS = ['login', 'logout', 'view', 'edit', 'delete']\ndef task_func(file_path, num_entries, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    log_entries = []\n    for _ in range(num_entries):\n        user = random.choice(USERS)\n        action = random.choice(ACTIONS)\n        timestamp = (datetime.now() - timedelta(minutes=random.randint(1, 1440))).isoformat()\n        log_entries.append({'user': user, 'action': action, 'timestamp': timestamp})\n\n    with open(file_path, 'w') as file:\n        json.dump(log_entries, file)\n\n    return file_path", "raw_solution": "import json\nimport random\nfrom datetime import datetime, timedelta\n\n# Constants\nUSERS = ['Alice', 'Bob', 'Charlie', 'Dave', 'Eve']\nACTIONS = ['login', 'logout', 'view', 'edit', 'delete']\n\ndef task_func(file_path, num_entries, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    log_entries = []\n    for _ in range(num_entries):\n        user = random.choice(USERS)\n        action = random.choice(ACTIONS)\n        timestamp = (datetime.now() - timedelta(minutes=random.randint(1, 1440))).isoformat()\n        log_entries.append({'user': user, 'action': action, 'timestamp': timestamp})\n\n    with open(file_path, 'w') as file:\n        json.dump(log_entries, file)\n\n    return file_path\n```"}
{"task_id": "BigCodeBench/230", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nCOLUMNS = ['Name', 'Age', 'Country', 'Score']\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        return \"Invalid input\"\n    if not all(col in df.columns for col in COLUMNS):\n        return \"Invalid input\"\n\n    # Generate histogram of scores\n    plt.figure(figsize=(10, 6))\n    plt.hist(df['Score'], bins=10, color='skyblue', edgecolor='black', alpha=0.7)\n    plt.title('Histogram of Scores')\n    plt.xlabel('Score')\n    plt.ylabel('Frequency')\n    plt.grid(True)\n\n    # Generate boxplot of scores by country\n    plt.figure(figsize=(10, 6))\n    sns.boxplot(x='Country', y='Score', data=df, palette='Set3')\n    plt.title('Boxplot of Scores by Country')\n    plt.xlabel('Country')\n    plt.ylabel('Score')\n    plt.grid(True)\n\n    return plt.gcf()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nCOLUMNS = ['Name', 'Age', 'Country', 'Score']\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        return \"Invalid input\"\n    if not all(col in df.columns for col in COLUMNS):\n        return \"Invalid input\"\n\n    # Generate histogram of scores\n    plt.figure(figsize=(10, 6))\n    plt.hist(df['Score'], bins=10, color='skyblue', edgecolor='black', alpha=0.7)\n    plt.title('Histogram of Scores')\n    plt.xlabel('Score')\n    plt.ylabel('Frequency')\n    plt.grid(True)\n\n    # Generate boxplot of scores by country\n    plt.figure(figsize=(10, 6))\n    sns.boxplot(x='Country', y='Score', data=df, palette='Set3')\n    plt.title('Boxplot of Scores by Country')\n    plt.xlabel('Country')\n    plt.ylabel('Score')\n    plt.grid(True)\n\n    return plt.gcf()\n```"}
{"task_id": "BigCodeBench/231", "solution": "import numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport random\nfrom matplotlib.axes import Axes\ndef task_func(obj_list) -> Axes:\n    values = [obj.value for obj in obj_list]\n    mean = np.mean(values)\n    std_dev = np.std(values)\n    x = np.linspace(mean - 3*std_dev, mean + 3*std_dev, 100)\n    plt.plot(x, stats.norm.pdf(x, mean, std_dev))\n    plt.hist(values, bins=10, density=True)\n    return plt.gca()", "raw_solution": "import numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport random\nfrom matplotlib.axes import Axes\nclass ValueObject:\n    value = 0\n    def __init__(self, mu=0, std=1, seed=77):\n        random.seed(seed)\n        self.value = random.gauss(mu, std)\ndef task_func(obj_list) -> Axes:\n    values = [obj.value for obj in obj_list]\n    mean = np.mean(values)\n    std_dev = np.std(values)\n    x = np.linspace(mean - 3*std_dev, mean + 3*std_dev, 100)\n    plt.plot(x, stats.norm.pdf(x, mean, std_dev))\n    plt.hist(values, bins=10, density=True)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/232", "solution": "import pandas as pd\nimport collections\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    df = df.drop_duplicates(subset=['Customer Name'])\n    total_sales = df['Sales'].sum()\n    most_popular_category = df['Category'].mode()[0]\n\n    return {'Total Sales': total_sales, 'Most Popular Category': most_popular_category}", "raw_solution": "import pandas as pd\nimport collections\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    df = df.drop_duplicates(subset=['Customer Name'])\n    total_sales = df['Sales'].sum()\n    most_popular_category = df['Category'].mode()[0]\n\n    return {'Total Sales': total_sales, 'Most Popular Category': most_popular_category}\n```"}
{"task_id": "BigCodeBench/233", "solution": "import random\nimport matplotlib.pyplot as plt\ndef task_func(obj_list, attr, num_bins=30, seed=0):\n    random.seed(seed)\n    values = [getattr(obj, attr) for obj in obj_list]\n    plt.hist(values, bins=num_bins)\n    plt.title('Histogram of attribute values')\n    plt.xlabel('Attribute Value')\n    plt.ylabel('Count')\n    return plt.gca()", "raw_solution": "import random\nimport matplotlib.pyplot as plt\n\nclass Object:\n    value = 0\n    def __init__(self, value=None):\n        if value is None:\n            self.value = random.gauss(0, 1)\n        else:\n            self.value = value\n\ndef task_func(obj_list, attr, num_bins=30, seed=0):\n    random.seed(seed)\n    values = [getattr(obj, attr) for obj in obj_list]\n    plt.hist(values, bins=num_bins)\n    plt.title('Histogram of attribute values')\n    plt.xlabel('Attribute Value')\n    plt.ylabel('Count')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/234", "solution": "import pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    df = df.drop_duplicates(subset='name')\n    slope, intercept, r_value, p_value, std_err = stats.linregress(df['age'],df['score'])\n    plt.scatter(df['age'],df['score'])\n    plt.plot(df['age'],intercept + slope*df['age'],'r')\n    plt.title('Linear Regression')\n    plt.xlabel('Age')\n    plt.ylabel('Score')\n    return plt, plt.gca()", "raw_solution": "import pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    df = df.drop_duplicates(subset='name')\n    slope, intercept, r_value, p_value, std_err = stats.linregress(df['age'],df['score'])\n    plt.scatter(df['age'],df['score'])\n    plt.plot(df['age'],intercept + slope*df['age'],'r')\n    plt.title('Linear Regression')\n    plt.xlabel('Age')\n    plt.ylabel('Score')\n    return plt, plt.gca()\n```"}
{"task_id": "BigCodeBench/235", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom statsmodels.formula.api import ols\ndef task_func(mu, sigma, seed=0, num_samples=1000, num_bins=30):\n    np.random.seed(seed)\n    data = np.random.normal(mu, sigma, num_samples)\n\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=num_bins, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n\n    x = np.linspace(min(data), max(data), 100)\n    pdf = (1/(sigma * np.sqrt(2 * np.pi))) * np.exp(- (x - mu)**2 / (2 * sigma**2))\n    ax.plot(x, pdf, color='red', label='PDF')\n\n    model = ols('y ~ x + I(x**2)', data={'x': data, 'y': data}).fit()\n    y_ols = model.predict(data)\n    ax.plot(data, y_ols, color='green', label='OLS')\n\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.legend()\n\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom statsmodels.formula.api import ols\n\ndef task_func(mu, sigma, seed=0, num_samples=1000, num_bins=30):\n    np.random.seed(seed)\n    data = np.random.normal(mu, sigma, num_samples)\n\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=num_bins, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n\n    x = np.linspace(min(data), max(data), 100)\n    pdf = (1/(sigma * np.sqrt(2 * np.pi))) * np.exp(- (x - mu)**2 / (2 * sigma**2))\n    ax.plot(x, pdf, color='red', label='PDF')\n\n    model = ols('y ~ x + I(x**2)', data={'x': data, 'y': data}).fit()\n    y_ols = model.predict(data)\n    ax.plot(data, y_ols, color='green', label='OLS')\n\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.legend()\n\n    return ax\n```"}
{"task_id": "BigCodeBench/236", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\ndef task_func(df, test_size=0.2, random_state=42):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    df = df.drop_duplicates(subset='Name')\n    X = df[['Age', 'Score']]\n    y = df['Category']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    clf = RandomForestClassifier(random_state=random_state)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    return accuracy", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\ndef task_func(df, test_size=0.2, random_state=42):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    df = df.drop_duplicates(subset='Name')\n    X = df[['Age', 'Score']]\n    y = df['Category']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    clf = RandomForestClassifier(random_state=random_state)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    return accuracy\n```"}
{"task_id": "BigCodeBench/237", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(data, save_plot=False, plot_path=None):\n    if save_plot and plot_path is None:\n        raise ValueError(\"If save_plot is True, plot_path must be provided.\")\n\n    # Unzip the data\n    objects, coordinates = zip(*data)\n    coordinates = np.array(coordinates)\n\n    # Apply PCA to reduce the dimensionality to 2D\n    pca = PCA(n_components=2)\n    coordinates_2d = pca.fit_transform(coordinates)\n\n    if save_plot:\n        # Plot the 2D coordinates\n        fig, ax = plt.subplots()\n        ax.scatter(coordinates_2d[:, 0], coordinates_2d[:, 1])\n        ax.set_xlabel('PC1')\n        ax.set_ylabel('PC2')\n        ax.set_title('PCA of 3D coordinates')\n        plt.savefig(plot_path)\n        plt.close(fig)\n        return coordinates_2d, ax\n    else:\n        return coordinates_2d", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(data, save_plot=False, plot_path=None):\n    if save_plot and plot_path is None:\n        raise ValueError(\"If save_plot is True, plot_path must be provided.\")\n\n    # Unzip the data\n    objects, coordinates = zip(*data)\n    coordinates = np.array(coordinates)\n\n    # Apply PCA to reduce the dimensionality to 2D\n    pca = PCA(n_components=2)\n    coordinates_2d = pca.fit_transform(coordinates)\n\n    if save_plot:\n        # Plot the 2D coordinates\n        fig, ax = plt.subplots()\n        ax.scatter(coordinates_2d[:, 0], coordinates_2d[:, 1])\n        ax.set_xlabel('PC1')\n        ax.set_ylabel('PC2')\n        ax.set_title('PCA of 3D coordinates')\n        plt.savefig(plot_path)\n        plt.close(fig)\n        return coordinates_2d, ax\n    else:\n        return coordinates_2d\n```"}
{"task_id": "BigCodeBench/238", "solution": "import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    # Standardize 'Age' and 'Score' columns\n    scaler = StandardScaler()\n    df[['Age', 'Score']] = scaler.fit_transform(df[['Age', 'Score']])\n\n    # Remove duplicate entries based on 'Name'\n    df = df.drop_duplicates(subset='Name')\n\n    # Plot a scatter plot of standardized values\n    plt.figure(figsize=(8, 6))\n    plt.scatter(df['Age'], df['Score'])\n    plt.title('Scatter Plot of Standardized Age and Score')\n    plt.xlabel('Age (standardized)')\n    plt.ylabel('Score (standardized)')\n    plt.tight_layout()\n\n    return df, plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    # Standardize 'Age' and 'Score' columns\n    scaler = StandardScaler()\n    df[['Age', 'Score']] = scaler.fit_transform(df[['Age', 'Score']])\n\n    # Remove duplicate entries based on 'Name'\n    df = df.drop_duplicates(subset='Name')\n\n    # Plot a scatter plot of standardized values\n    plt.figure(figsize=(8, 6))\n    plt.scatter(df['Age'], df['Score'])\n    plt.title('Scatter Plot of Standardized Age and Score')\n    plt.xlabel('Age (standardized)')\n    plt.ylabel('Score (standardized)')\n    plt.tight_layout()\n\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/239", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(original):\n    # Extract numeric values\n    numeric_values = [x[0] for x in original]\n    numeric_values = np.array(numeric_values)\n\n    # Compute basic statistics\n    stats_dict = {\n        'mean': np.mean(numeric_values),\n        'std_dev': np.std(numeric_values),\n        'min': np.min(numeric_values),\n        'max': np.max(numeric_values)\n    }\n\n    # Generate histogram with overlaid PDF\n    fig, ax = plt.subplots()\n    ax.hist(numeric_values, density=True, alpha=0.6, bins='auto')\n    xmin, xmax = ax.get_xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = stats.norm.pdf(x, stats_dict['mean'], stats_dict['std_dev'])\n    ax.plot(x, p, 'k', linewidth=2)\n    title = \"Histogram with Overlaid PDF\\nMean: {:.2f}, Std Dev: {:.2f}, Min: {:.2f}, Max: {:.2f}\".format(\n        stats_dict['mean'], stats_dict['std_dev'], stats_dict['min'], stats_dict['max'])\n    ax.set_title(title)\n\n    return numeric_values, stats_dict, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(original):\n    # Extract numeric values\n    numeric_values = [x[0] for x in original]\n    numeric_values = np.array(numeric_values)\n\n    # Compute basic statistics\n    stats_dict = {\n        'mean': np.mean(numeric_values),\n        'std_dev': np.std(numeric_values),\n        'min': np.min(numeric_values),\n        'max': np.max(numeric_values)\n    }\n\n    # Generate histogram with overlaid PDF\n    fig, ax = plt.subplots()\n    ax.hist(numeric_values, density=True, alpha=0.6, bins='auto')\n    xmin, xmax = ax.get_xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = stats.norm.pdf(x, stats_dict['mean'], stats_dict['std_dev'])\n    ax.plot(x, p, 'k', linewidth=2)\n    title = \"Histogram with Overlaid PDF\\nMean: {:.2f}, Std Dev: {:.2f}, Min: {:.2f}, Max: {:.2f}\".format(\n        stats_dict['mean'], stats_dict['std_dev'], stats_dict['min'], stats_dict['max'])\n    ax.set_title(title)\n\n    return numeric_values, stats_dict, ax\n```"}
{"task_id": "BigCodeBench/240", "solution": "import pandas as pd\nfrom random import uniform\ndef task_func(n_data_points=1000, min_value=0.0, max_value=10.0, column_name='Value'):\n    data = [round(uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n    df = pd.DataFrame(data, columns=[column_name])\n    return df", "raw_solution": "import pandas as pd\nfrom random import uniform\n\ndef task_func(n_data_points=1000, min_value=0.0, max_value=10.0, column_name='Value'):\n    data = [round(uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n    df = pd.DataFrame(data, columns=[column_name])\n    return df\n```"}
{"task_id": "BigCodeBench/241", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\ndef task_func(original):\n    # Convert the original list to a numpy array\n    original_array = np.array(original)\n\n    # Normalize the array\n    normalized_array = preprocessing.normalize([original_array], norm='l2')[0]\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot the original and normalized arrays\n    ax.plot(original_array, label='Original')\n    ax.plot(normalized_array, label='Normalized')\n\n    # Set the title and labels\n    ax.set_title('Original vs. Normalized Data')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n\n    # Add a legend\n    ax.legend()\n\n    # Return the numpy arrays and the axes object\n    return original_array, normalized_array, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\n\ndef task_func(original):\n    # Convert the original list to a numpy array\n    original_array = np.array(original)\n\n    # Normalize the array\n    normalized_array = preprocessing.normalize([original_array], norm='l2')[0]\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot the original and normalized arrays\n    ax.plot(original_array, label='Original')\n    ax.plot(normalized_array, label='Normalized')\n\n    # Set the title and labels\n    ax.set_title('Original vs. Normalized Data')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n\n    # Add a legend\n    ax.legend()\n\n    # Return the numpy arrays and the axes object\n    return original_array, normalized_array, ax\n```"}
{"task_id": "BigCodeBench/242", "solution": "import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(image_path, kernel_size):\n    if not isinstance(kernel_size, int) or kernel_size <= 0:\n        raise ValueError(\"Kernel size must be a positive integer\")\n    try:\n        image = cv2.imread(image_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(\"Image file not found\")\n    blurred = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n    axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    axs[0].set_title('Original Image')\n    axs[1].imshow(cv2.cvtColor(blurred, cv2.COLOR_BGR2RGB))\n    axs[1].set_title('Blurred Image')\n    for ax in axs:\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n    return blurred, axs", "raw_solution": "import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(image_path, kernel_size):\n    if not isinstance(kernel_size, int) or kernel_size <= 0:\n        raise ValueError(\"Kernel size must be a positive integer\")\n    try:\n        image = cv2.imread(image_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(\"Image file not found\")\n    blurred = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n    axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    axs[0].set_title('Original Image')\n    axs[1].imshow(cv2.cvtColor(blurred, cv2.COLOR_BGR2RGB))\n    axs[1].set_title('Blurred Image')\n    for ax in axs:\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n    return blurred, axs\n```"}
{"task_id": "BigCodeBench/243", "solution": "import pandas as pd\nimport random\nN_DATA_POINTS = 10000\nMIN_VALUE = 0.0\nMAX_VALUE = 10.0\ndef task_func(n_data_points=N_DATA_POINTS):\n    if n_data_points == 0:\n        return pd.DataFrame(columns=['Value'])\n    data = [round(random.uniform(MIN_VALUE, MAX_VALUE), 3) for _ in range(n_data_points)]\n    return pd.DataFrame(data, columns=['Value'])", "raw_solution": "import pandas as pd\nimport random\n\n# Constants\nN_DATA_POINTS = 10000\nMIN_VALUE = 0.0\nMAX_VALUE = 10.0\n\ndef task_func(n_data_points=N_DATA_POINTS):\n    if n_data_points == 0:\n        return pd.DataFrame(columns=['Value'])\n    data = [round(random.uniform(MIN_VALUE, MAX_VALUE), 3) for _ in range(n_data_points)]\n    return pd.DataFrame(data, columns=['Value'])\n```"}
{"task_id": "BigCodeBench/244", "solution": "import numpy as np\nfrom scipy.fft import fft\nfrom matplotlib import pyplot as plt\ndef task_func(original):\n    if not original:\n        return np.array([]), np.array([]), None\n    original_array = np.array(original)\n    fft_data = fft(original_array)\n    axes = plt.hist(np.abs(fft_data), bins=10, color='blue', edgecolor='black')\n    plt.title('FFT Magnitude Histogram')\n    plt.xlabel('Magnitude')\n    plt.ylabel('Frequency')\n    plt.grid(True)\n    return original_array, fft_data, axes", "raw_solution": "import numpy as np\nfrom scipy.fft import fft\nfrom matplotlib import pyplot as plt\n\ndef task_func(original):\n    if not original:\n        return np.array([]), np.array([]), None\n    original_array = np.array(original)\n    fft_data = fft(original_array)\n    axes = plt.hist(np.abs(fft_data), bins=10, color='blue', edgecolor='black')\n    plt.title('FFT Magnitude Histogram')\n    plt.xlabel('Magnitude')\n    plt.ylabel('Frequency')\n    plt.grid(True)\n    return original_array, fft_data, axes\n```"}
{"task_id": "BigCodeBench/245", "solution": "import pandas as pd\nimport random\nfrom scipy import stats\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    data = [round(random.uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n    mean = round(sum(data) / len(data), 3)\n    median = round(stats.median(data), 3)\n    mode = round(stats.mode(data)[0][0], 3)\n    return {'mean': mean, 'median': median, 'mode': mode}", "raw_solution": "import pandas as pd\nimport random\nfrom scipy import stats\n\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    data = [round(random.uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n    mean = round(sum(data) / len(data), 3)\n    median = round(stats.median(data), 3)\n    mode = round(stats.mode(data)[0][0], 3)\n    return {'mean': mean, 'median': median, 'mode': mode}\n```"}
{"task_id": "BigCodeBench/246", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\nANGLES = np.arange(0, 2*np.pi, 0.01)\ndef task_func(n_waves, seed=0):\n    if n_waves < 1:\n        return [], [], None\n    np.random.seed(seed)\n    freqs = np.random.uniform(0, 1, n_waves)\n    phases = np.random.uniform(0, 2*np.pi, n_waves)\n    y_values = np.sin(np.outer(freqs, ANGLES) + phases)\n    fft_data = fft(y_values)\n    axes = plt.hist(np.abs(fft_data), bins=30, color='blue', edgecolor='black')\n    plt.title('FFT Magnitude Histogram')\n    plt.xlabel('Magnitude')\n    plt.ylabel('Frequency')\n    return y_values, fft_data, axes", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\nANGLES = np.arange(0, 2*np.pi, 0.01)\n\ndef task_func(n_waves, seed=0):\n    if n_waves < 1:\n        return [], [], None\n    np.random.seed(seed)\n    freqs = np.random.uniform(0, 1, n_waves)\n    phases = np.random.uniform(0, 2*np.pi, n_waves)\n    y_values = np.sin(np.outer(freqs, ANGLES) + phases)\n    fft_data = fft(y_values)\n    axes = plt.hist(np.abs(fft_data), bins=30, color='blue', edgecolor='black')\n    plt.title('FFT Magnitude Histogram')\n    plt.xlabel('Magnitude')\n    plt.ylabel('Frequency')\n    return y_values, fft_data, axes\n```"}
{"task_id": "BigCodeBench/247", "solution": "import pandas as pd\nimport random\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    if max_value < min_value:\n        raise ValueError(\"max_value must be greater than min_value\")\n    data = [round(random.uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n    scaler = StandardScaler()\n    df = pd.DataFrame(data, columns=[\"Normalized Value\"])\n    df[\"Normalized Value\"] = scaler.fit_transform(df[[\"Normalized Value\"]])\n    return df", "raw_solution": "import pandas as pd\nimport random\nfrom sklearn.preprocessing import StandardScaler\n\n# Constants\nN_DATA_POINTS = 5000\nMIN_VALUE = 0.0\nMAX_VALUE = 10.0\n\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    if max_value < min_value:\n        raise ValueError(\"max_value must be greater than min_value\")\n    data = [round(random.uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n    scaler = StandardScaler()\n    df = pd.DataFrame(data, columns=[\"Normalized Value\"])\n    df[\"Normalized Value\"] = scaler.fit_transform(df[[\"Normalized Value\"]])\n    return df\n```"}
{"task_id": "BigCodeBench/248", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"The data_list is empty.\")\n    unzipped_data = list(itertools.chain(*data_list))\n    plt.plot(unzipped_data)\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"The data_list is empty.\")\n    unzipped_data = list(itertools.chain(*data_list))\n    plt.plot(unzipped_data)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/249", "solution": "import pandas as pd\nimport random\nfrom sklearn.model_selection import train_test_split\ndef task_func(n_data_points=10000, min_value=0.0, max_value=10.0, test_size=0.2):\n    data = [round(random.uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n    df = pd.DataFrame(data, columns=[\"Value\"])\n    train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)\n    return (train_df, test_df)", "raw_solution": "import pandas as pd\nimport random\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(n_data_points=10000, min_value=0.0, max_value=10.0, test_size=0.2):\n    data = [round(random.uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n    df = pd.DataFrame(data, columns=[\"Value\"])\n    train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)\n    return (train_df, test_df)\n```"}
{"task_id": "BigCodeBench/250", "solution": "import numpy as np\nimport itertools\nimport json\ndef task_func(data_list, json_file_name=\"mean_values.json\"):\n    mean_values = {}\n    for i in range(len(data_list[0])):\n        column = [row[i] for row in data_list]\n        mean_values[f'Position {i}'] = np.mean(column)\n    if json_file_name:\n        with open(json_file_name, 'w') as f:\n            json.dump(mean_values, f)\n    return mean_values", "raw_solution": "import numpy as np\nimport itertools\nimport json\n\ndef task_func(data_list, json_file_name=\"mean_values.json\"):\n    mean_values = {}\n    for i in range(len(data_list[0])):\n        column = [row[i] for row in data_list]\n        mean_values[f'Position {i}'] = np.mean(column)\n    if json_file_name:\n        with open(json_file_name, 'w') as f:\n            json.dump(mean_values, f)\n    return mean_values\n```"}
{"task_id": "BigCodeBench/251", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data must be a DataFrame\")\n    if 'Job' not in data.columns:\n        raise ValueError(\"DataFrame must contain a 'Job' column\")\n    job_counts = data['Job'].value_counts()\n    fig, ax = plt.subplots()\n    ax.pie(job_counts, labels=job_counts.index, autopct='%1.1f%%', startangle=140)\n    ax.axis('equal')\n    return fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data must be a DataFrame\")\n    if 'Job' not in data.columns:\n        raise ValueError(\"DataFrame must contain a 'Job' column\")\n    job_counts = data['Job'].value_counts()\n    fig, ax = plt.subplots()\n    ax.pie(job_counts, labels=job_counts.index, autopct='%1.1f%%', startangle=140)\n    ax.axis('equal')\n    return fig\n```"}
{"task_id": "BigCodeBench/252", "solution": "import matplotlib.pyplot as plt\nfrom itertools import cycle\ndef task_func(data, labels):\n    colors = cycle(COLORS)\n    ax = plt.gca()\n    for d, l, c in zip_longest(data, labels, colors):\n        if d is not None:\n            ax.plot(d, label=l, color=c)\n    ax.legend()\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom itertools import cycle\n\ndef task_func(data, labels):\n    colors = cycle(COLORS)\n    ax = plt.gca()\n    for d, l, c in zip_longest(data, labels, colors):\n        if d is not None:\n            ax.plot(d, label=l, color=c)\n    ax.legend()\n    return ax\n```"}
{"task_id": "BigCodeBench/253", "solution": "import numpy as np\nimport random\nCOLORS = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\ndef task_func(ax):\n    # Generate random parameters\n    amplitude = random.uniform(0.1, 1.0)\n    frequency = random.uniform(0.1, 10.0)\n    phase = random.uniform(0, np.pi)\n    color = random.choice(COLORS)\n    # Generate the sine wave\n    theta = np.linspace(0, 2*np.pi, 100)\n    r = amplitude * np.sin(frequency * theta + phase)\n    # Plot the sine wave\n    ax.plot(theta, r, color=color)\n    # Set the radial labels\n    radial_label_position = random.uniform(0, 1)\n    ax.set_rlabel_position(radial_label_position)\n    # Return the color code\n    return color", "raw_solution": "import numpy as np\nimport random\n# Constants\nCOLORS = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\ndef task_func(ax):\n    # Generate random parameters\n    amplitude = random.uniform(0.1, 1.0)\n    frequency = random.uniform(0.1, 10.0)\n    phase = random.uniform(0, np.pi)\n    color = random.choice(COLORS)\n    # Generate the sine wave\n    theta = np.linspace(0, 2*np.pi, 100)\n    r = amplitude * np.sin(frequency * theta + phase)\n    # Plot the sine wave\n    ax.plot(theta, r, color=color)\n    # Set the radial labels\n    radial_label_position = random.uniform(0, 1)\n    ax.set_rlabel_position(radial_label_position)\n    # Return the color code\n    return color\n```"}
{"task_id": "BigCodeBench/254", "solution": "import json\nimport math\ndef task_func(decimal_value, precision=2):\n    sqrt_value = round(math.sqrt(decimal_value), precision)\n    json_string = json.dumps({\"sqrt_value\": sqrt_value})\n    return json_string", "raw_solution": "import json\nimport math\ndef task_func(decimal_value, precision=2):\n    sqrt_value = round(math.sqrt(decimal_value), precision)\n    json_string = json.dumps({\"sqrt_value\": sqrt_value})\n    return json_string\n```"}
{"task_id": "BigCodeBench/255", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(ax, func_index):\n    if not isinstance(ax, plt.Axes):\n        raise ValueError(\"Input ax must be a matplotlib.axes._axes.Axes instance\")\n    if func_index < 0 or func_index >= len(FUNCTIONS):\n        raise ValueError(\"Invalid function index\")\n    func = FUNCTIONS[func_index]\n    theta = np.linspace(0, 2 * np.pi, 1000)\n    r = func(theta)\n    ax.plot(theta, r)\n    ax.set_theta_zero_location(\"W\")\n    ax.set_theta_direction(-1)\n    ax.set_rticks([0.5, 1, 1.5, 2])\n    ax.set_rlabel_position(180)\n    ax.grid(True)\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(ax, func_index):\n    if not isinstance(ax, plt.Axes):\n        raise ValueError(\"Input ax must be a matplotlib.axes._axes.Axes instance\")\n    if func_index < 0 or func_index >= len(FUNCTIONS):\n        raise ValueError(\"Invalid function index\")\n    func = FUNCTIONS[func_index]\n    theta = np.linspace(0, 2 * np.pi, 1000)\n    r = func(theta)\n    ax.plot(theta, r)\n    ax.set_theta_zero_location(\"W\")\n    ax.set_theta_direction(-1)\n    ax.set_rticks([0.5, 1, 1.5, 2])\n    ax.set_rlabel_position(180)\n    ax.grid(True)\n    return ax\n```"}
{"task_id": "BigCodeBench/256", "solution": "import json\nimport random\nimport hashlib\nfrom datetime import datetime\ndef task_func(utc_datetime, salt='salt', password_length=10, seed=0):\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime must be a datetime object\")\n    if not isinstance(salt, str):\n        raise ValueError(\"salt must be a string\")\n    random.seed(seed)\n    password = ''.join(random.choice('abcdefghijklmnopqrstuvwxyz0123456789') for _ in range(password_length))\n    hashed_password = hashlib.sha256((salt + str(utc_datetime)).encode()).hexdigest()\n    return json.dumps({\"hashed_password\": hashed_password})", "raw_solution": "import json\nimport random\nimport hashlib\nfrom datetime import datetime\n\ndef task_func(utc_datetime, salt='salt', password_length=10, seed=0):\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime must be a datetime object\")\n    if not isinstance(salt, str):\n        raise ValueError(\"salt must be a string\")\n    random.seed(seed)\n    password = ''.join(random.choice('abcdefghijklmnopqrstuvwxyz0123456789') for _ in range(password_length))\n    hashed_password = hashlib.sha256((salt + str(utc_datetime)).encode()).hexdigest()\n    return json.dumps({\"hashed_password\": hashed_password})\n```"}
{"task_id": "BigCodeBench/257", "solution": "import numpy as np\nimport matplotlib.pyplot as plt", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef draw_spiral(ax, num_turns):\n    theta = np.linspace(0, 2*np.pi*num_turns, 1000)\n    r = theta\n    x = r * np.cos(theta)\n    y = r * np.sin(theta)\n    ax.plot(x, y)\n    ax.set_aspect('equal')\n    ax.set_xlim(-1.1, 1.1)\n    ax.set_ylim(-1.1, 1.1)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    return ax\n```"}
{"task_id": "BigCodeBench/258", "solution": "import json\nimport random\nfrom datetime import datetime\nDATA = [\n    {'name': 'John', 'age': 30, 'city': 'New York'},\n    {'name': 'Peter', 'age': 35, 'city': 'London'},\n    {'name': 'Susan', 'age': 25, 'city': 'Sydney'},\n    {'name': 'Alice', 'age': 28, 'city': 'Paris'},\n    {'name': 'Bob', 'age': 40, 'city': 'Tokyo'},\n    {'name': 'Charlie', 'age': 22, 'city': 'Beijing'},\n    {'name': 'David', 'age': 33, 'city': 'Mumbai'},\n    {'name': 'Eve', 'age': 27, 'city': 'Berlin'},\n    {'name': 'Frank', 'age': 32, 'city': 'Moscow'},\n    {'name': 'Grace', 'age': 29, 'city': 'Rome'}\n]\ndef task_func(utc_datetime, seed=0):\n    random.seed(seed)\n    person = random.choice(DATA)\n    person['timestamp'] = utc_datetime.strftime('%Y-%m-%dT%H:%M:%SZ')\n    return json.dumps(person)", "raw_solution": "import json\nimport random\nfrom datetime import datetime\n\n# Constants\nDATA = [\n    {'name': 'John', 'age': 30, 'city': 'New York'},\n    {'name': 'Peter', 'age': 35, 'city': 'London'},\n    {'name': 'Susan', 'age': 25, 'city': 'Sydney'},\n    {'name': 'Alice', 'age': 28, 'city': 'Paris'},\n    {'name': 'Bob', 'age': 40, 'city': 'Tokyo'},\n    {'name': 'Charlie', 'age': 22, 'city': 'Beijing'},\n    {'name': 'David', 'age': 33, 'city': 'Mumbai'},\n    {'name': 'Eve', 'age': 27, 'city': 'Berlin'},\n    {'name': 'Frank', 'age': 32, 'city': 'Moscow'},\n    {'name': 'Grace', 'age': 29, 'city': 'Rome'}\n]\n\ndef task_func(utc_datetime, seed=0):\n    random.seed(seed)\n    person = random.choice(DATA)\n    person['timestamp'] = utc_datetime.strftime('%Y-%m-%dT%H:%M:%SZ')\n    return json.dumps(person)\n```"}
{"task_id": "BigCodeBench/259", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(ax, num_points):\n    if not isinstance(ax, plt.Axes):\n        raise ValueError(\"Input ax is not an Axes object.\")\n    if num_points < 0:\n        raise ValueError(\"Number of points cannot be negative.\")\n    if num_points == 0:\n        return ax\n\n    theta = np.linspace(0, 2 * np.pi, num_points)\n    radii = np.random.rand(num_points)\n\n    ax.plot(theta, radii, 'o')\n    ax.set_rticks(np.arange(0, 1, 0.1))\n\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(ax, num_points):\n    if not isinstance(ax, plt.Axes):\n        raise ValueError(\"Input ax is not an Axes object.\")\n    if num_points < 0:\n        raise ValueError(\"Number of points cannot be negative.\")\n    if num_points == 0:\n        return ax\n\n    theta = np.linspace(0, 2 * np.pi, num_points)\n    radii = np.random.rand(num_points)\n\n    ax.plot(theta, radii, 'o')\n    ax.set_rticks(np.arange(0, 1, 0.1))\n\n    return ax\n```"}
{"task_id": "BigCodeBench/260", "solution": "import json\nimport os\nimport glob\nKEY = 'mynewkey'\nVALUE = 'mynewvalue'\ndef task_func(directory):\n    count = 0\n    for file in glob.glob(os.path.join(directory, '*.json')):\n        with open(file, 'r+') as f:\n            data = json.load(f)\n            if KEY not in data:\n                data[KEY] = VALUE\n                f.seek(0)\n                json.dump(data, f, indent=4)\n                f.truncate()\n                count += 1\n    return count", "raw_solution": "import json\nimport os\nimport glob\n\n# Constants\nKEY = 'mynewkey'\nVALUE = 'mynewvalue'\n\ndef task_func(directory):\n    count = 0\n    for file in glob.glob(os.path.join(directory, '*.json')):\n        with open(file, 'r+') as f:\n            data = json.load(f)\n            if KEY not in data:\n                data[KEY] = VALUE\n                f.seek(0)\n                json.dump(data, f, indent=4)\n                f.truncate()\n                count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/261", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(ax, radius):\n    if not isinstance(ax, plt.Axes):\n        raise TypeError(\"'ax' must be a matplotlib.axes._axes.Axes object\")\n    if radius < 0:\n        raise ValueError(\"Radius cannot be negative\")\n    theta = np.linspace(0, 2*np.pi, 1000)\n    x = radius * np.cos(theta)\n    y = radius * np.sin(theta)\n    ax.plot(x, y, color='blue')\n    ax.set_rticks([0.5, 1, 1.5, 2])\n    ax.grid(True)\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(ax, radius):\n    if not isinstance(ax, plt.Axes):\n        raise TypeError(\"'ax' must be a matplotlib.axes._axes.Axes object\")\n    if radius < 0:\n        raise ValueError(\"Radius cannot be negative\")\n    theta = np.linspace(0, 2*np.pi, 1000)\n    x = radius * np.cos(theta)\n    y = radius * np.sin(theta)\n    ax.plot(x, y, color='blue')\n    ax.set_rticks([0.5, 1, 1.5, 2])\n    ax.grid(True)\n    return ax\n```"}
{"task_id": "BigCodeBench/262", "solution": "import collections\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(dictionary, new_key, new_value):\n    dictionary[new_key] = new_value\n    counter = collections.Counter(dictionary.values())\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Values')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution of Values')\n    return dictionary, ax", "raw_solution": "import collections\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(dictionary, new_key, new_value):\n    dictionary[new_key] = new_value\n    counter = collections.Counter(dictionary.values())\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Values')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution of Values')\n    return dictionary, ax\n```"}
{"task_id": "BigCodeBench/263", "solution": "import os\nimport glob\nimport shutil\nimport time\nFILE_EXTENSIONS = ['.txt', '.csv', '.xlsx', '.docx', '.pdf']\ndef task_func(my_path: str, days_old: int) -> str:\n    # Get the current time\n    current_time = time.time()\n\n    # Create the archive directory if it doesn't exist\n    archive_path = os.path.join(my_path, 'archive')\n    if not os.path.exists(archive_path):\n        os.makedirs(archive_path)\n\n    # Get a list of files with the specified extensions\n    files = []\n    for extension in FILE_EXTENSIONS:\n        files.extend(glob.glob(os.path.join(my_path, '*' + extension)))\n\n    # Move files older than 'days_old' to the archive directory\n    for file in files:\n        file_time = os.path.getmtime(file)\n        if current_time - file_time >= days_old * 24 * 60 * 60:\n            shutil.move(file, archive_path)\n\n    return archive_path", "raw_solution": "import os\nimport glob\nimport shutil\nimport time\n\n# Constants\nFILE_EXTENSIONS = ['.txt', '.csv', '.xlsx', '.docx', '.pdf']\n\ndef task_func(my_path: str, days_old: int) -> str:\n    # Get the current time\n    current_time = time.time()\n\n    # Create the archive directory if it doesn't exist\n    archive_path = os.path.join(my_path, 'archive')\n    if not os.path.exists(archive_path):\n        os.makedirs(archive_path)\n\n    # Get a list of files with the specified extensions\n    files = []\n    for extension in FILE_EXTENSIONS:\n        files.extend(glob.glob(os.path.join(my_path, '*' + extension)))\n\n    # Move files older than 'days_old' to the archive directory\n    for file in files:\n        file_time = os.path.getmtime(file)\n        if current_time - file_time >= days_old * 24 * 60 * 60:\n            shutil.move(file, archive_path)\n\n    return archive_path\n```"}
{"task_id": "BigCodeBench/264", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(dictionary, key, value, n=100, bins=30, seed=0):\n    if not isinstance(value, (int, float)):\n        raise ValueError(\"The provided value is not a number.\")\n    dictionary[key] = value\n    np.random.seed(seed)\n    data = np.random.normal(value, 1, n)\n    series = pd.Series(data)\n    plt.hist(series, bins=bins)\n    plt.title(f\"Histogram of Normal Distribution with Mean={value} and Std=1\")\n    plt.xlabel(\"Value\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n    return dictionary, series", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(dictionary, key, value, n=100, bins=30, seed=0):\n    if not isinstance(value, (int, float)):\n        raise ValueError(\"The provided value is not a number.\")\n    dictionary[key] = value\n    np.random.seed(seed)\n    data = np.random.normal(value, 1, n)\n    series = pd.Series(data)\n    plt.hist(series, bins=bins)\n    plt.title(f\"Histogram of Normal Distribution with Mean={value} and Std=1\")\n    plt.xlabel(\"Value\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n    return dictionary, series\n```"}
{"task_id": "BigCodeBench/265", "solution": "import collections\nimport json\nimport os\ndef task_func(data, json_file_name='data.json'):\n    data['a'] = 1\n    freq = collections.Counter(data.values())\n    data_dict = {'data': data, 'freq': dict(freq)}\n    with open(json_file_name, 'w') as json_file:\n        json.dump(data_dict, json_file)\n    return os.path.abspath(json_file_name)", "raw_solution": "import collections\nimport json\nimport os\n\ndef task_func(data, json_file_name='data.json'):\n    data['a'] = 1\n    freq = collections.Counter(data.values())\n    data_dict = {'data': data, 'freq': dict(freq)}\n    with open(json_file_name, 'w') as json_file:\n        json.dump(data_dict, json_file)\n    return os.path.abspath(json_file_name)\n```"}
{"task_id": "BigCodeBench/266", "solution": "import os\nimport os.path\nimport csv\nimport collections\nFILE_NAME = 'file_sizes.csv'\ndef task_func(my_path):\n    file_sizes = collections.defaultdict(int)\n    for root, dirs, files in os.walk(my_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            file_size = os.path.getsize(file_path)\n            file_sizes[file_path] = file_size\n\n    with open(FILE_NAME, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow([\"File Path\", \"File Size\"])\n        for file_path, file_size in file_sizes.items():\n            writer.writerow([file_path, file_size])\n    return FILE_NAME", "raw_solution": "import os\nimport os.path\nimport csv\nimport collections\n# Constants\nFILE_NAME = 'file_sizes.csv'\ndef task_func(my_path):\n    file_sizes = collections.defaultdict(int)\n    for root, dirs, files in os.walk(my_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            file_size = os.path.getsize(file_path)\n            file_sizes[file_path] = file_size\n\n    with open(FILE_NAME, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow([\"File Path\", \"File Size\"])\n        for file_path, file_size in file_sizes.items():\n            writer.writerow([file_path, file_size])\n    return FILE_NAME\n```"}
{"task_id": "BigCodeBench/267", "solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\ndef task_func(data, sample_rate=8000):\n    # Add a new key \"a\" with the value 1 to the dictionary\n    data[\"a\"] = 1\n\n    # Generate a signal based on the values in \"data\"\n    signal = np.array(list(data.values()))\n\n    # Run a Fast Fourier Transform (FFT) on the signal\n    fft_signal = fftpack.fft(signal)\n\n    # Plot and return the FFT of the signal with a title of 'FFT of the signal'\n    plt.figure(figsize=(10, 4))\n    plt.plot(np.abs(fft_signal))\n    plt.title('FFT of the signal')\n    plt.xlabel('Frequency')\n    plt.ylabel('Amplitude')\n    plt.grid(True)\n\n    return fft_signal, plt.gca()", "raw_solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\n\ndef task_func(data, sample_rate=8000):\n    # Add a new key \"a\" with the value 1 to the dictionary\n    data[\"a\"] = 1\n\n    # Generate a signal based on the values in \"data\"\n    signal = np.array(list(data.values()))\n\n    # Run a Fast Fourier Transform (FFT) on the signal\n    fft_signal = fftpack.fft(signal)\n\n    # Plot and return the FFT of the signal with a title of 'FFT of the signal'\n    plt.figure(figsize=(10, 4))\n    plt.plot(np.abs(fft_signal))\n    plt.title('FFT of the signal')\n    plt.xlabel('Frequency')\n    plt.ylabel('Amplitude')\n    plt.grid(True)\n\n    return fft_signal, plt.gca()\n```"}
{"task_id": "BigCodeBench/268", "solution": "import collections\nimport random\nLETTERS = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\ndef task_func(n_keys, n_values):\n    result = collections.defaultdict(list)\n    for i in range(n_keys):\n        key = random.choice(LETTERS)\n        result[key] = list(range(1, n_values + 1))\n    return dict(result)", "raw_solution": "import collections\nimport random\n# Constants\nLETTERS = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\ndef task_func(n_keys, n_values):\n    result = collections.defaultdict(list)\n    for i in range(n_keys):\n        key = random.choice(LETTERS)\n        result[key] = list(range(1, n_values + 1))\n    return dict(result)\n```"}
{"task_id": "BigCodeBench/269", "solution": "import numpy as np\nfrom scipy import stats\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(data_dict):\n    # Add key \"a\" with value 1\n    data_dict[\"a\"] = 1\n\n    # Conduct statistical analysis on values\n    values = list(data_dict.values())\n    mean = round(np.mean(values), 2)\n    median = np.median(values)\n    mode = stats.mode(values)[0][0]\n    stats_dict = {\"mean\": mean, \"median\": median, \"mode\": mode}\n\n    # Normalize values using MinMaxScaler\n    scaler = MinMaxScaler()\n    normalized_values = scaler.fit_transform(np.array(values).reshape(-1, 1))\n\n    # Plot histogram of normalized values\n    plt.hist(normalized_values, bins='auto', color='#0504aa', alpha=0.7, rwidth=0.85)\n    plt.grid(axis='y', alpha=0.75)\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Normalized Values')\n    hist_plot = plt.gca()\n\n    return data_dict, stats_dict, hist_plot", "raw_solution": "import numpy as np\nfrom scipy import stats\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict):\n    # Add key \"a\" with value 1\n    data_dict[\"a\"] = 1\n\n    # Conduct statistical analysis on values\n    values = list(data_dict.values())\n    mean = round(np.mean(values), 2)\n    median = np.median(values)\n    mode = stats.mode(values)[0][0]\n    stats_dict = {\"mean\": mean, \"median\": median, \"mode\": mode}\n\n    # Normalize values using MinMaxScaler\n    scaler = MinMaxScaler()\n    normalized_values = scaler.fit_transform(np.array(values).reshape(-1, 1))\n\n    # Plot histogram of normalized values\n    plt.hist(normalized_values, bins='auto', color='#0504aa', alpha=0.7, rwidth=0.85)\n    plt.grid(axis='y', alpha=0.75)\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Normalized Values')\n    hist_plot = plt.gca()\n\n    return data_dict, stats_dict, hist_plot\n```"}
{"task_id": "BigCodeBench/270", "solution": "import re\nfrom collections import Counter\ndef task_func(sentence):\n    words = re.findall(r'\\b\\w+\\b', sentence)\n    return dict(Counter(words))", "raw_solution": "import re\nfrom collections import Counter\n\ndef task_func(sentence):\n    words = re.findall(r'\\b\\w+\\b', sentence)\n    return dict(Counter(words))\n```"}
{"task_id": "BigCodeBench/271", "solution": "import random\nimport string\nimport hashlib\nimport time\ndef task_func(data_dict: dict, seed=0) -> dict:\n    random.seed(seed)\n    salt = ''.join(random.choices(string.ascii_lowercase, k=5))\n    data_dict['a'] = 1\n    for key, value in data_dict.items():\n        hashed_value = hashlib.sha256((value + salt).encode()).hexdigest()\n        data_dict[key] = hashed_value\n    data_dict['timestamp'] = int(time.time())\n    return data_dict", "raw_solution": "import random\nimport string\nimport hashlib\nimport time\n\ndef task_func(data_dict: dict, seed=0) -> dict:\n    random.seed(seed)\n    salt = ''.join(random.choices(string.ascii_lowercase, k=5))\n    data_dict['a'] = 1\n    for key, value in data_dict.items():\n        hashed_value = hashlib.sha256((value + salt).encode()).hexdigest()\n        data_dict[key] = hashed_value\n    data_dict['timestamp'] = int(time.time())\n    return data_dict\n```"}
{"task_id": "BigCodeBench/272", "solution": "import cgi\nimport http.server\nimport json", "raw_solution": "import cgi\nimport http.server\nimport json\n\nclass PostHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        data = json.loads(post_data)\n\n        if self.headers['Content-Type'] != 'application/json':\n            self.send_response(400)\n            self.end_headers()\n            self.wfile.write(json.dumps({\"status\": \"error\", \"message\": \"Content-Type header is not application/json\"}).encode())\n            return\n\n        if 'data' not in data:\n            self.send_response(400)\n            self.end_headers()\n            self.wfile.write(json.dumps({\"status\": \"error\", \"message\": \"No data received\"}).encode())\n            return\n\n        self.send_response(200)\n        self.end_headers()\n        self.wfile.write(json.dumps({\"status\": \"success\", \"message\": \"Data received successfully.\"}).encode())"}
{"task_id": "BigCodeBench/273", "solution": "import cgi\nimport http.server\nimport json", "raw_solution": "import cgi\nimport http.server\nimport json\n\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\n\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\n\nclass DataHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers.get('content-length', 0))\n        content_type = self.headers.get('content-type', '')\n\n        if content_type != 'application/json':\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({\n                'status': 'error',\n                'message': 'Content-Type header is not application/json'\n            }).encode())\n            return\n\n        post_data = self.rfile.read(content_length)\n\n        try:\n            data = json.loads(post_data)\n        except json.JSONDecodeError:\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({\n                'status': 'error',\n                'message': 'Invalid JSON'\n            }).encode())\n            return\n\n        if 'data' not in data:\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({\n                'status': 'error',\n                'message': 'No data key in request'\n            }).encode())\n            return\n\n        self.send_response(200)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        self.wfile.write(json.dumps(SUCCESS_RESPONSE).encode())\n```"}
{"task_id": "BigCodeBench/274", "solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class EmailHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            try:\n                content_length = int(self.headers['Content-Length'])\n                post_data = self.rfile.read(content_length)\n                email_data = json.loads(post_data)\n\n                if 'subject' not in email_data or 'message' not in email_data or 'to' not in email_data:\n                    raise ValueError(\"Missing required keys in email data\")\n\n                msg = MIMEText(email_data['message'])\n                msg['Subject'] = email_data['subject']\n                msg['From'] = smtp_username\n                msg['To'] = email_data['to']\n\n                server = smtplib.SMTP(smtp_server, smtp_port)\n                server.starttls()\n                server.login(smtp_username, smtp_password)\n                server.send_message(msg)\n                server.quit()\n\n                self.send_response(200)\n                self.end_headers()\n                self.wfile.write(b'Email sent successfully')\n\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Invalid JSON')\n\n            except ValueError as e:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(str(e).encode())\n\n            except smtplib.SMTPAuthenticationError:\n                self.send_response(535)\n                self.end_headers()\n                self.wfile.write(b'Authentication Failed')\n\n    return EmailHandler", "raw_solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\n\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class EmailHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            try:\n                content_length = int(self.headers['Content-Length'])\n                post_data = self.rfile.read(content_length)\n                email_data = json.loads(post_data)\n\n                if 'subject' not in email_data or 'message' not in email_data or 'to' not in email_data:\n                    raise ValueError(\"Missing required keys in email data\")\n\n                msg = MIMEText(email_data['message'])\n                msg['Subject'] = email_data['subject']\n                msg['From'] = smtp_username\n                msg['To'] = email_data['to']\n\n                server = smtplib.SMTP(smtp_server, smtp_port)\n                server.starttls()\n                server.login(smtp_username, smtp_password)\n                server.send_message(msg)\n                server.quit()\n\n                self.send_response(200)\n                self.end_headers()\n                self.wfile.write(b'Email sent successfully')\n\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Invalid JSON')\n\n            except ValueError as e:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(str(e).encode())\n\n            except smtplib.SMTPAuthenticationError:\n                self.send_response(535)\n                self.end_headers()\n                self.wfile.write(b'Authentication Failed')\n\n    return EmailHandler\n```"}
{"task_id": "BigCodeBench/275", "solution": "import numpy as np\nfrom itertools import combinations\ndef task_func(n):\n    if n < 1:\n        raise ValueError(\"Input n should be greater than 0\")\n    return list(combinations(range(1, n+1), 2))", "raw_solution": "import numpy as np\nfrom itertools import combinations\ndef task_func(n):\n    if n < 1:\n        raise ValueError(\"Input n should be greater than 0\")\n    return list(combinations(range(1, n+1), 2))\n```"}
{"task_id": "BigCodeBench/276", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(matrix):\n    # Calculate the maximum values of each row in the matrix\n    max_values = np.max(matrix, axis=1)\n\n    # Calculate the histogram and the estimate of the core density of the distribution\n    hist, bins = np.histogram(max_values, bins=10, density=True)\n\n    # Calculate the skewness and kurtosis of the distribution\n    skewness = stats.skew(max_values)\n    kurtosis = stats.kurtosis(max_values)\n\n    # Plot the histogram\n    fig, ax = plt.subplots()\n    ax.bar(bins[:-1], hist, width=np.diff(bins), edgecolor='black')\n    ax.set_xlabel('Max Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Max Values')\n\n    return skewness, kurtosis, ax", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(matrix):\n    # Calculate the maximum values of each row in the matrix\n    max_values = np.max(matrix, axis=1)\n\n    # Calculate the histogram and the estimate of the core density of the distribution\n    hist, bins = np.histogram(max_values, bins=10, density=True)\n\n    # Calculate the skewness and kurtosis of the distribution\n    skewness = stats.skew(max_values)\n    kurtosis = stats.kurtosis(max_values)\n\n    # Plot the histogram\n    fig, ax = plt.subplots()\n    ax.bar(bins[:-1], hist, width=np.diff(bins), edgecolor='black')\n    ax.set_xlabel('Max Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Max Values')\n\n    return skewness, kurtosis, ax\n```"}
{"task_id": "BigCodeBench/277", "solution": "import random\nfrom itertools import combinations\nimport math\ndef task_func(n):\n    if n < 2:\n        return None\n    dots = [(random.random(), random.random()) for _ in range(n)]\n    min_distance = float('inf')\n    closest_pair = None\n    for pair in combinations(dots, 2):\n        distance = math.sqrt((pair[0][0] - pair[1][0])**2 + (pair[0][1] - pair[1][1])**2)\n        if distance < min_distance:\n            min_distance = distance\n            closest_pair = pair\n    return closest_pair", "raw_solution": "import random\nfrom itertools import combinations\nimport math\n\ndef task_func(n):\n    if n < 2:\n        return None\n    dots = [(random.random(), random.random()) for _ in range(n)]\n    min_distance = float('inf')\n    closest_pair = None\n    for pair in combinations(dots, 2):\n        distance = math.sqrt((pair[0][0] - pair[1][0])**2 + (pair[0][1] - pair[1][1])**2)\n        if distance < min_distance:\n            min_distance = distance\n            closest_pair = pair\n    return closest_pair\n```"}
{"task_id": "BigCodeBench/278", "solution": "import numpy as np\nfrom sympy import symbols, solve\ndef task_func(precision=2, seed=0):\n    np.random.seed(seed)\n    a, b, c = np.random.uniform(-10, 10, 3)\n    x = symbols('x')\n    solutions = solve(a*x**2 + b*x + c, x)\n    solutions = [complex(round(s.evalf(precision), precision)) for s in solutions]\n    return tuple(solutions)", "raw_solution": "import numpy as np\nfrom sympy import symbols, solve\n\ndef task_func(precision=2, seed=0):\n    np.random.seed(seed)\n    a, b, c = np.random.uniform(-10, 10, 3)\n    x = symbols('x')\n    solutions = solve(a*x**2 + b*x + c, x)\n    solutions = [complex(round(s.evalf(precision), precision)) for s in solutions]\n    return tuple(solutions)\n```"}
{"task_id": "BigCodeBench/279", "solution": "import random\nfrom collections import Counter\nCARDS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\ndef task_func(x=1):\n    def draw_hand():\n        return random.sample(CARDS, 5)\n\n    hands = [draw_hand() for _ in range(x)]\n    drawn_cards = Counter()\n    for hand in hands:\n        drawn_cards.update(hand)\n\n    return (hands, drawn_cards)", "raw_solution": "import random\nfrom collections import Counter\n# Constants\nCARDS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\ndef task_func(x=1):\n    def draw_hand():\n        return random.sample(CARDS, 5)\n\n    hands = [draw_hand() for _ in range(x)]\n    drawn_cards = Counter()\n    for hand in hands:\n        drawn_cards.update(hand)\n\n    return (hands, drawn_cards)\n```"}
{"task_id": "BigCodeBench/280", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\ndef task_func(signal, precision=2, seed=777):\n    np.random.seed(seed)\n    transformed_signal = fft(signal)\n    transformed_signal = np.round(transformed_signal, precision)\n\n    fig, axs = plt.subplots(2, 1)\n    axs[0].plot(signal)\n    axs[0].set_title('Original Signal')\n    axs[1].plot(np.abs(transformed_signal))\n    axs[1].set_title('Transformed Signal')\n\n    return transformed_signal, axs", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\n\ndef task_func(signal, precision=2, seed=777):\n    np.random.seed(seed)\n    transformed_signal = fft(signal)\n    transformed_signal = np.round(transformed_signal, precision)\n\n    fig, axs = plt.subplots(2, 1)\n    axs[0].plot(signal)\n    axs[0].set_title('Original Signal')\n    axs[1].plot(np.abs(transformed_signal))\n    axs[1].set_title('Transformed Signal')\n\n    return transformed_signal, axs\n```"}
{"task_id": "BigCodeBench/281", "solution": "import re\nimport os\nfrom collections import Counter\ndef task_func(folder_path: str) -> dict:\n    ip_pattern = r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b'\n    ip_counter = Counter()\n\n    for filename in os.listdir(folder_path):\n        if filename.endswith('.log'):\n            with open(os.path.join(folder_path, filename), 'r') as file:\n                for line in file:\n                    ip_matches = re.findall(ip_pattern, line)\n                    ip_counter.update(ip_matches)\n\n    return dict(ip_counter)", "raw_solution": "import re\nimport os\nfrom collections import Counter\n\ndef task_func(folder_path: str) -> dict:\n    ip_pattern = r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b'\n    ip_counter = Counter()\n\n    for filename in os.listdir(folder_path):\n        if filename.endswith('.log'):\n            with open(os.path.join(folder_path, filename), 'r') as file:\n                for line in file:\n                    ip_matches = re.findall(ip_pattern, line)\n                    ip_counter.update(ip_matches)\n\n    return dict(ip_counter)\n```"}
{"task_id": "BigCodeBench/282", "solution": "import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport cv2\nimport os\ndef task_func(file_path, onpick):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"Image file does not exist\")\n\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.reshape((-1, 3))\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(img[:, 0], img[:, 1], img[:, 2], picker=True)\n\n    def on_pick(event):\n        if event.ind:\n            onpick(event.ind)\n\n    fig.canvas.mpl_connect('pick_event', on_pick)\n\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport cv2\nimport os\n\ndef task_func(file_path, onpick):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"Image file does not exist\")\n\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.reshape((-1, 3))\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(img[:, 0], img[:, 1], img[:, 2], picker=True)\n\n    def on_pick(event):\n        if event.ind:\n            onpick(event.ind)\n\n    fig.canvas.mpl_connect('pick_event', on_pick)\n\n    return ax\n```"}
{"task_id": "BigCodeBench/283", "solution": "import os\nimport json\nfrom collections import Counter\ndef task_func(json_files_path='./json_files/', key='name'):\n    key_counts = Counter()\n    for filename in os.listdir(json_files_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(json_files_path, filename), 'r') as file:\n                data = json.load(file)\n                if isinstance(data, list):\n                    for item in data:\n                        if key in item:\n                            key_counts[item[key]] += 1\n                elif isinstance(data, dict):\n                    if key in data:\n                        key_counts[data[key]] += 1\n    return dict(key_counts)", "raw_solution": "import os\nimport json\nfrom collections import Counter\n\ndef task_func(json_files_path='./json_files/', key='name'):\n    key_counts = Counter()\n    for filename in os.listdir(json_files_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(json_files_path, filename), 'r') as file:\n                data = json.load(file)\n                if isinstance(data, list):\n                    for item in data:\n                        if key in item:\n                            key_counts[item[key]] += 1\n                elif isinstance(data, dict):\n                    if key in data:\n                        key_counts[data[key]] += 1\n    return dict(key_counts)\n```"}
{"task_id": "BigCodeBench/284", "solution": "import mechanize\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\ndef task_func(url):\n    br = mechanize.Browser()\n    br.set_handle_robots(False)\n    br.open(url)\n    html = br.response().read()\n    soup = BeautifulSoup(html, 'html.parser')\n    base_url = url\n    links = []\n    for link in soup.find_all('a'):\n        href = link.get('href')\n        if href and not href.startswith('#'):\n            absolute_url = urljoin(base_url, href)\n            links.append(absolute_url)\n    return links", "raw_solution": "import mechanize\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\n\ndef task_func(url):\n    br = mechanize.Browser()\n    br.set_handle_robots(False)\n    br.open(url)\n    html = br.response().read()\n    soup = BeautifulSoup(html, 'html.parser')\n    base_url = url\n    links = []\n    for link in soup.find_all('a'):\n        href = link.get('href')\n        if href and not href.startswith('#'):\n            absolute_url = urljoin(base_url, href)\n            links.append(absolute_url)\n    return links\n```"}
{"task_id": "BigCodeBench/285", "solution": "import mechanize\nfrom bs4 import BeautifulSoup\ndef task_func(url, form_id, data):\n    browser = mechanize.Browser()\n    browser.open(url)\n    browser.select_form(nr=form_id)\n    for key, value in data.items():\n        browser.form[key] = value\n    response = browser.submit()\n    soup = BeautifulSoup(response.read(), 'html.parser')\n    title = soup.title\n    if title is not None:\n        return title.text\n    else:\n        return 'No Title'", "raw_solution": "import mechanize\nfrom bs4 import BeautifulSoup\n\ndef task_func(url, form_id, data):\n    browser = mechanize.Browser()\n    browser.open(url)\n    browser.select_form(nr=form_id)\n    for key, value in data.items():\n        browser.form[key] = value\n    response = browser.submit()\n    soup = BeautifulSoup(response.read(), 'html.parser')\n    title = soup.title\n    if title is not None:\n        return title.text\n    else:\n        return 'No Title'\n```"}
{"task_id": "BigCodeBench/286", "solution": "from collections import Counter\nimport os\nimport csv\ndef task_func(output_file, test_directory):\n    try:\n        if not os.path.exists(test_directory):\n            return 0\n        word_counts = Counter()\n        for filename in os.listdir(test_directory):\n            if filename.endswith('.txt'):\n                with open(os.path.join(test_directory, filename), 'r') as file:\n                    words = file.read().split()\n                    word_counts.update(words)\n        with open(output_file, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            writer.writerow(['Word', 'Count'])\n            for word, count in word_counts.items():\n                writer.writerow([word, count])\n        return sum(word_counts.values())\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return 0", "raw_solution": "from collections import Counter\nimport os\nimport csv\n\n# Constants\nFILE_DIR = './yourdictfiles/'\n\ndef task_func(output_file, test_directory):\n    try:\n        if not os.path.exists(test_directory):\n            return 0\n        word_counts = Counter()\n        for filename in os.listdir(test_directory):\n            if filename.endswith('.txt'):\n                with open(os.path.join(test_directory, filename), 'r') as file:\n                    words = file.read().split()\n                    word_counts.update(words)\n        with open(output_file, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            writer.writerow(['Word', 'Count'])\n            for word, count in word_counts.items():\n                writer.writerow([word, count])\n        return sum(word_counts.values())\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return 0\n```"}
{"task_id": "BigCodeBench/287", "solution": "from collections import Counter\nimport os\nimport json\ndef task_func(filename, directory):\n    word_counts = Counter()\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith('.txt'):\n                with open(os.path.join(root, file), 'r') as f:\n                    words = f.read().split()\n                    word_counts.update(words)\n    with open(filename, 'w') as f:\n        json.dump(word_counts, f)\n    return sum(word_counts.values())", "raw_solution": "from collections import Counter\nimport os\nimport json\n\ndef task_func(filename, directory):\n    word_counts = Counter()\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith('.txt'):\n                with open(os.path.join(root, file), 'r') as f:\n                    words = f.read().split()\n                    word_counts.update(words)\n    with open(filename, 'w') as f:\n        json.dump(word_counts, f)\n    return sum(word_counts.values())\n```"}
{"task_id": "BigCodeBench/288", "solution": "import collections\nimport json\nimport os\ndef task_func(directory_path: str) -> dict:\n    result = collections.defaultdict(int)\n    for filename in os.listdir(directory_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(directory_path, filename), 'r') as file:\n                data = json.load(file)\n                for key in data.keys():\n                    result[key] += 1\n    return dict(result)", "raw_solution": "import collections\nimport json\nimport os\n\ndef task_func(directory_path: str) -> dict:\n    result = collections.defaultdict(int)\n    for filename in os.listdir(directory_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(directory_path, filename), 'r') as file:\n                data = json.load(file)\n                for key in data.keys():\n                    result[key] += 1\n    return dict(result)\n```"}
{"task_id": "BigCodeBench/289", "solution": "import tensorflow as tf\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(X, y, n_splits, batch_size, epochs):\n    # Normalize the input data\n    scaler = MinMaxScaler()\n    X = scaler.fit_transform(X)\n\n    # Define the model\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Dense(20, activation='relu', input_shape=(X.shape[1],)),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n\n    # Compile the model\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Initialize KFold\n    kf = KFold(n_splits=n_splits)\n\n    # Initialize history list\n    history_list = []\n\n    # Perform k-fold cross-validation\n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n\n        # Train the model\n        history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n\n        # Append the history to the list\n        history_list.append(history)\n\n    return history_list", "raw_solution": "import tensorflow as tf\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(X, y, n_splits, batch_size, epochs):\n    # Normalize the input data\n    scaler = MinMaxScaler()\n    X = scaler.fit_transform(X)\n\n    # Define the model\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Dense(20, activation='relu', input_shape=(X.shape[1],)),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n\n    # Compile the model\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Initialize KFold\n    kf = KFold(n_splits=n_splits)\n\n    # Initialize history list\n    history_list = []\n\n    # Perform k-fold cross-validation\n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n\n        # Train the model\n        history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n\n        # Append the history to the list\n        history_list.append(history)\n\n    return history_list\n```"}
{"task_id": "BigCodeBench/290", "solution": "import nltk\nfrom collections import Counter\nimport os\nfrom nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(directory_path):\n    # Initialize a counter to count unique non-stop words\n    word_counter = Counter()\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory_path):\n        if filename.endswith('.txt'):\n            # Read the file\n            with open(os.path.join(directory_path, filename), 'r') as file:\n                # Tokenize the file content\n                words = nltk.word_tokenize(file.read())\n                # Filter out stop words and count the remaining words\n                word_counter.update(word for word in words if word.lower() not in STOPWORDS)\n    # Return the total count of unique non-stop words\n    return sum(word_counter.values())", "raw_solution": "import nltk\nnltk.download('stopwords')\nfrom collections import Counter\nimport os\nfrom nltk.corpus import stopwords\n# Constants\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(directory_path):\n    # Initialize a counter to count unique non-stop words\n    word_counter = Counter()\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory_path):\n        if filename.endswith('.txt'):\n            # Read the file\n            with open(os.path.join(directory_path, filename), 'r') as file:\n                # Tokenize the file content\n                words = nltk.word_tokenize(file.read())\n                # Filter out stop words and count the remaining words\n                word_counter.update(word for word in words if word.lower() not in STOPWORDS)\n    # Return the total count of unique non-stop words\n    return sum(word_counter.values())\n```"}
{"task_id": "BigCodeBench/291", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\ndef task_func(mu, sigma, seed=0):\n    np.random.seed(seed)\n    data = np.random.normal(mu, sigma, 1000)\n    ax = sns.histplot(data, kde=True, color=\"skyblue\", linewidth=0)\n    ax.set_title(f\"Normal Distribution with Mean {mu} and Standard Deviation {sigma}\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\ndef task_func(mu, sigma, seed=0):\n    np.random.seed(seed)\n    data = np.random.normal(mu, sigma, 1000)\n    ax = sns.histplot(data, kde=True, color=\"skyblue\", linewidth=0)\n    ax.set_title(f\"Normal Distribution with Mean {mu} and Standard Deviation {sigma}\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n    return ax\n```"}
{"task_id": "BigCodeBench/292", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    scaler = MinMaxScaler()\n    df[['Age', 'Income']] = scaler.fit_transform(df[['Age', 'Income']])\n    hist_data = df['Income'].values\n    return (df, hist_data)", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    scaler = MinMaxScaler()\n    df[['Age', 'Income']] = scaler.fit_transform(df[['Age', 'Income']])\n    hist_data = df['Income'].values\n    return (df, hist_data)\n```"}
{"task_id": "BigCodeBench/293", "solution": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n    histogram = plt.hist(sums, bins='auto')\n    return histogram, subsets, sums", "raw_solution": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n    histogram = plt.hist(sums, bins='auto')\n    return histogram, subsets, sums\n```"}
{"task_id": "BigCodeBench/294", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    if not all(col in df.columns for col in ['id', 'age', 'income']):\n        raise ValueError(\"DataFrame does not have the 'id', 'age', and 'income' columns\")\n\n    df_grouped = df.groupby('id')\n    df_standardized = df_grouped.apply(lambda x: (x - x.mean()) / x.std())\n\n    return df_standardized", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    if not all(col in df.columns for col in ['id', 'age', 'income']):\n        raise ValueError(\"DataFrame does not have the 'id', 'age', and 'income' columns\")\n\n    df_grouped = df.groupby('id')\n    df_standardized = df_grouped.apply(lambda x: (x - x.mean()) / x.std())\n\n    return df_standardized\n```"}
{"task_id": "BigCodeBench/295", "solution": "import itertools\nimport statistics\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n    mean = statistics.mean(sums)\n    median = statistics.median(sums)\n    mode = statistics.mode(sums)\n    return {'mean': mean, 'median': median, 'mode': mode}", "raw_solution": "import itertools\nimport statistics\n\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n    mean = statistics.mean(sums)\n    median = statistics.median(sums)\n    mode = statistics.mode(sums)\n    return {'mean': mean, 'median': median, 'mode': mode}\n```"}
{"task_id": "BigCodeBench/296", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    if df.empty:\n        return plt.gca()\n    value_counts = df['value'].value_counts()\n    ax = value_counts.plot(kind='bar')\n    ax.set_title(\"Value Distribution\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Count\")\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    if df.empty:\n        return plt.gca()\n    value_counts = df['value'].value_counts()\n    ax = value_counts.plot(kind='bar')\n    ax.set_title(\"Value Distribution\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Count\")\n    return ax\n```"}
{"task_id": "BigCodeBench/297", "solution": "import itertools\nimport collections\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n    return dict(collections.Counter(sums))", "raw_solution": "import itertools\nimport collections\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n    return dict(collections.Counter(sums))\n```"}
{"task_id": "BigCodeBench/298", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\ndef task_func(df, plot=False):\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise KeyError(\"DataFrame does not have the 'Date' and 'Value' columns\")\n\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n\n    scaler = StandardScaler()\n    scaled_values = scaler.fit_transform(df['Value'].values.reshape(-1, 1))\n\n    df = df.drop(columns=['Value'])\n    for i, col in enumerate(df.columns):\n        df[f'Scaled_{col}'] = scaled_values[:, i]\n\n    if plot:\n        ax = df.plot(kind='bar', figsize=(10, 6))\n        ax.set_title('Scaled Values Over Time')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Scaled Value')\n        plt.tight_layout()\n        return df, ax\n    else:\n        return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(df, plot=False):\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise KeyError(\"DataFrame does not have the 'Date' and 'Value' columns\")\n\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n\n    scaler = StandardScaler()\n    scaled_values = scaler.fit_transform(df['Value'].values.reshape(-1, 1))\n\n    df = df.drop(columns=['Value'])\n    for i, col in enumerate(df.columns):\n        df[f'Scaled_{col}'] = scaled_values[:, i]\n\n    if plot:\n        ax = df.plot(kind='bar', figsize=(10, 6))\n        ax.set_title('Scaled Values Over Time')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Scaled Value')\n        plt.tight_layout()\n        return df, ax\n    else:\n        return df"}
{"task_id": "BigCodeBench/299", "solution": "import itertools\nimport math\nfrom pandas import Series\ndef task_func(elements, subset_size, top_n=2):\n    if subset_size > len(elements):\n        return 1\n    if subset_size == 0:\n        return 1\n    subsets = list(itertools.combinations(elements, subset_size))\n    subset_sums = [sum(subset) for subset in subsets]\n    subset_sums.sort(reverse=True)\n    top_n_sums = subset_sums[:top_n]\n    product_of_sums = math.prod(subset_sums)\n    return product_of_sums, Series(top_n_sums)", "raw_solution": "import itertools\nimport math\nfrom pandas import Series\n\ndef task_func(elements, subset_size, top_n=2):\n    if subset_size > len(elements):\n        return 1\n    if subset_size == 0:\n        return 1\n    subsets = list(itertools.combinations(elements, subset_size))\n    subset_sums = [sum(subset) for subset in subsets]\n    subset_sums.sort(reverse=True)\n    top_n_sums = subset_sums[:top_n]\n    product_of_sums = math.prod(subset_sums)\n    return product_of_sums, Series(top_n_sums)\n```"}
{"task_id": "BigCodeBench/300", "solution": "import pandas as pd\nfrom scipy.stats import zscore\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise KeyError(\"DataFrame does not have the 'Date' and 'Value' columns\")\n\n    df['Date'] = pd.to_datetime(df['Date'])\n    df = df.explode('Value')\n    df['Value'] = df['Value'].astype(float)\n    df = df.groupby('Date')['Value'].apply(list).reset_index()\n    df = df.set_index('Date')\n\n    z_scores = df.apply(zscore)\n\n    fig, ax = plt.subplots()\n    z_scores.boxplot(ax=ax)\n    ax.set_title(\"Z-Scores Over Time\")\n    ax.set_xlabel(\"Date\")\n    ax.set_ylabel(\"Z-Score\")\n\n    return df, fig", "raw_solution": "import pandas as pd\nfrom scipy.stats import zscore\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise KeyError(\"DataFrame does not have the 'Date' and 'Value' columns\")\n\n    df['Date'] = pd.to_datetime(df['Date'])\n    df = df.explode('Value')\n    df['Value'] = df['Value'].astype(float)\n    df = df.groupby('Date')['Value'].apply(list).reset_index()\n    df = df.set_index('Date')\n\n    z_scores = df.apply(zscore)\n\n    fig, ax = plt.subplots()\n    z_scores.boxplot(ax=ax)\n    ax.set_title(\"Z-Scores Over Time\")\n    ax.set_xlabel(\"Date\")\n    ax.set_ylabel(\"Z-Score\")\n\n    return df, fig\n```"}
{"task_id": "BigCodeBench/301", "solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\nSOLAR_CYCLE_YEARS = np.array([1986, 1996, 2008, 2019])\ndef task_func(date_str, from_tz, to_tz):\n    date = parse(date_str)\n    date = date.replace(tzinfo=pytz.timezone(from_tz))\n    date = date.astimezone(pytz.timezone(to_tz))\n    year = date.year\n    closest_year = SOLAR_CYCLE_YEARS[np.argmin(np.abs(SOLAR_CYCLE_YEARS - year))]\n    solar_activity = (math.cos((year - closest_year) * 2 * math.pi / 11) + 1) / 2\n    return solar_activity", "raw_solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\nSOLAR_CYCLE_YEARS = np.array([1986, 1996, 2008, 2019])\ndef task_func(date_str, from_tz, to_tz):\n    date = parse(date_str)\n    date = date.replace(tzinfo=pytz.timezone(from_tz))\n    date = date.astimezone(pytz.timezone(to_tz))\n    year = date.year\n    closest_year = SOLAR_CYCLE_YEARS[np.argmin(np.abs(SOLAR_CYCLE_YEARS - year))]\n    solar_activity = (math.cos((year - closest_year) * 2 * math.pi / 11) + 1) / 2\n    return solar_activity\n```"}
{"task_id": "BigCodeBench/302", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df, plot=False):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if 'Value' not in df.columns:\n        raise ValueError(\"'Value' column not found in DataFrame\")\n    if not all(isinstance(x, list) for x in df['Value']):\n        raise ValueError(\"'Value' column contains non-list values\")\n\n    # Split lists in the 'Value' column into separate columns\n    df = df['Value'].apply(pd.Series)\n    df.columns = [f'Value_{i}' for i in range(1, len(df.columns) + 1)]\n\n    # Calculate the Pearson correlation coefficient\n    corr = df.corr()\n\n    if plot:\n        # Visualize the correlation matrix using a heatmap\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(corr, annot=True, cmap='coolwarm')\n        plt.title(\"Correlation Heatmap\")\n        plt.show()\n\n    return corr", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df, plot=False):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if 'Value' not in df.columns:\n        raise ValueError(\"'Value' column not found in DataFrame\")\n    if not all(isinstance(x, list) for x in df['Value']):\n        raise ValueError(\"'Value' column contains non-list values\")\n\n    # Split lists in the 'Value' column into separate columns\n    df = df['Value'].apply(pd.Series)\n    df.columns = [f'Value_{i}' for i in range(1, len(df.columns) + 1)]\n\n    # Calculate the Pearson correlation coefficient\n    corr = df.corr()\n\n    if plot:\n        # Visualize the correlation matrix using a heatmap\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(corr, annot=True, cmap='coolwarm')\n        plt.title(\"Correlation Heatmap\")\n        plt.show()\n\n    return corr"}
{"task_id": "BigCodeBench/303", "solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\ndef task_func(date_str, from_tz, to_tz):\n    date = parse(date_str)\n    date = date.replace(tzinfo=pytz.timezone(from_tz))\n    date = date.astimezone(pytz.timezone(to_tz))\n    year = date.year\n    month = date.month\n    day = date.day\n    if month < 3:\n        year -= 1\n        month += 12\n    c = year // 100\n    m = month + 1\n    k = year % 100\n    f = k + k // 4 + 5 * c + c // 4 + 13 * (m + 1) // 5 + day - 1\n    f = f % 7\n    return f / 7", "raw_solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\n\nMOON_PHASES_YEARS = np.array([1987, 1994, 2001, 2008, 2015, 2022])\n\ndef task_func(date_str, from_tz, to_tz):\n    date = parse(date_str)\n    date = date.replace(tzinfo=pytz.timezone(from_tz))\n    date = date.astimezone(pytz.timezone(to_tz))\n    year = date.year\n    month = date.month\n    day = date.day\n    if month < 3:\n        year -= 1\n        month += 12\n    c = year // 100\n    m = month + 1\n    k = year % 100\n    f = k + k // 4 + 5 * c + c // 4 + 13 * (m + 1) // 5 + day - 1\n    f = f % 7\n    return f / 7\n```"}
{"task_id": "BigCodeBench/304", "solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if df.empty:\n        return (0.0, 0.0)\n    pca = PCA(n_components=df.shape[1])\n    pca.fit(df)\n    explained_variance_ratio = pca.explained_variance_ratio_\n    fig, ax = plt.subplots()\n    ax.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio)\n    ax.set_title(\"Explained Variance Ratio of Principal Components\")\n    ax.set_xlabel(\"Principal Component\")\n    ax.set_ylabel(\"Explained Variance Ratio\")\n    return (explained_variance_ratio, ax)", "raw_solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if df.empty:\n        return (0.0, 0.0)\n    pca = PCA(n_components=df.shape[1])\n    pca.fit(df)\n    explained_variance_ratio = pca.explained_variance_ratio_\n    fig, ax = plt.subplots()\n    ax.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio)\n    ax.set_title(\"Explained Variance Ratio of Principal Components\")\n    ax.set_xlabel(\"Principal Component\")\n    ax.set_ylabel(\"Explained Variance Ratio\")\n    return (explained_variance_ratio, ax)\n```"}
{"task_id": "BigCodeBench/305", "solution": "from collections import Counter\nimport itertools\nimport random\nALPHABET = 'abcdefghijklmnopqrstuvwxyz'\ndef task_func(list_of_lists, seed=0):\n    random.seed(seed)\n    if not list_of_lists:\n        list_of_lists = [random.choice(ALPHABET) for _ in range(10)]\n    flat_list = list(itertools.chain.from_iterable(list_of_lists))\n    return Counter(flat_list)", "raw_solution": "from collections import Counter\nimport itertools\nimport random\n# Constants\nALPHABET = 'abcdefghijklmnopqrstuvwxyz'\ndef task_func(list_of_lists, seed=0):\n    random.seed(seed)\n    if not list_of_lists:\n        list_of_lists = [random.choice(ALPHABET) for _ in range(10)]\n    flat_list = list(itertools.chain.from_iterable(list_of_lists))\n    return Counter(flat_list)\n```"}
{"task_id": "BigCodeBench/306", "solution": "import os\nimport logging\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(f\"Directory {directory} does not exist\")\n\n    removed_files = []\n    count = 0\n    for filename in os.listdir(directory):\n        if 'jquery' in filename:\n            file_path = os.path.join(directory, filename)\n            os.remove(file_path)\n            removed_files.append(filename)\n            count += 1\n\n    with open('jquery_removal.log', 'w') as log_file:\n        for filename in removed_files:\n            log_file.write(f\"Removed: {filename}\\n\")\n\n    return count, removed_files", "raw_solution": "import os\nimport logging\n\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(f\"Directory {directory} does not exist\")\n\n    removed_files = []\n    count = 0\n    for filename in os.listdir(directory):\n        if 'jquery' in filename:\n            file_path = os.path.join(directory, filename)\n            os.remove(file_path)\n            removed_files.append(filename)\n            count += 1\n\n    with open('jquery_removal.log', 'w') as log_file:\n        for filename in removed_files:\n            log_file.write(f\"Removed: {filename}\\n\")\n\n    return count, removed_files\n```"}
{"task_id": "BigCodeBench/307", "solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\ndef task_func(list_of_lists, seed=0):\n    random.seed(seed)\n    combined_data = []\n    for sublist in list_of_lists:\n        if not sublist:\n            sublist = [random.randint(0, 100) for _ in range(5)]\n        combined_data.extend(sublist)\n\n    plt.figure(figsize=(10, 6))\n    sns.histplot(combined_data, bins=10, color=\"skyblue\", kde=False)\n    plt.title(\"Histogram of Combined Data\")\n    plt.xlabel(\"Value\")\n    plt.ylabel(\"Frequency\")\n    return plt.gca()", "raw_solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n\ndef task_func(list_of_lists, seed=0):\n    random.seed(seed)\n    combined_data = []\n    for sublist in list_of_lists:\n        if not sublist:\n            sublist = [random.randint(0, 100) for _ in range(5)]\n        combined_data.extend(sublist)\n\n    plt.figure(figsize=(10, 6))\n    sns.histplot(combined_data, bins=10, color=\"skyblue\", kde=False)\n    plt.title(\"Histogram of Combined Data\")\n    plt.xlabel(\"Value\")\n    plt.ylabel(\"Frequency\")\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/308", "solution": "import pandas as pd\nfrom statistics import mean\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\ndef task_func(additional_fields = []):\n    # Generate random grades for each student in each subject\n    data = {student: {field: random.randint(0, 100) for field in FIELDS} for student in STUDENTS}\n\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Calculate the average grade for each student\n    df['Average'] = df.mean(axis=1)\n\n    # Calculate the average grade for each subject\n    df.loc['Average Grade'] = df.mean()\n\n    return df", "raw_solution": "import pandas as pd\nfrom statistics import mean\nimport random\n\n# Constants for generating the report data\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\n\ndef task_func(additional_fields = []):\n    # Generate random grades for each student in each subject\n    data = {student: {field: random.randint(0, 100) for field in FIELDS} for student in STUDENTS}\n\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Calculate the average grade for each student\n    df['Average'] = df.mean(axis=1)\n\n    # Calculate the average grade for each subject\n    df.loc['Average Grade'] = df.mean()\n\n    return df\n```"}
{"task_id": "BigCodeBench/309", "solution": "import numpy as np\nimport random\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(list_of_lists, seed=42):\n    random.seed(seed)\n    for i in range(len(list_of_lists)):\n        if not list_of_lists[i]:\n            list_of_lists[i] = [random.randint(0, 100) for _ in range(5)]\n    scaler = MinMaxScaler()\n    return scaler.fit_transform(list_of_lists).tolist()", "raw_solution": "import numpy as np\nimport random\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(list_of_lists, seed=42):\n    random.seed(seed)\n    for i in range(len(list_of_lists)):\n        if not list_of_lists[i]:\n            list_of_lists[i] = [random.randint(0, 100) for _ in range(5)]\n    scaler = MinMaxScaler()\n    return scaler.fit_transform(list_of_lists).tolist()\n```"}
{"task_id": "BigCodeBench/310", "solution": "import os\nimport csv\nimport random\nfrom statistics import mean\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\ndef task_func(filename):\n    # Generate data\n    data = []\n    for i in range(PEOPLE_COUNT):\n        name = f'Person{i+1}'\n        age = random.randint(18, 60)\n        height = round(random.uniform(1.50, 2.00), 2)\n        weight = round(random.uniform(50, 150), 2)\n        data.append([name, age, height, weight])\n\n    # Calculate averages\n    avg_age = round(mean([row[1] for row in data]), 2)\n    avg_height = round(mean([row[2] for row in data]), 2)\n    avg_weight = round(mean([row[3] for row in data]), 2)\n\n    # Append averages to data\n    data.append([f'Average', avg_age, avg_height, avg_weight])\n\n    # Write to CSV file\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(COLUMNS)\n        writer.writerows(data)\n\n    return filename", "raw_solution": "import os\nimport csv\nimport random\nfrom statistics import mean\n\n# Constants\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\n\ndef task_func(filename):\n    # Generate data\n    data = []\n    for i in range(PEOPLE_COUNT):\n        name = f'Person{i+1}'\n        age = random.randint(18, 60)\n        height = round(random.uniform(1.50, 2.00), 2)\n        weight = round(random.uniform(50, 150), 2)\n        data.append([name, age, height, weight])\n\n    # Calculate averages\n    avg_age = round(mean([row[1] for row in data]), 2)\n    avg_height = round(mean([row[2] for row in data]), 2)\n    avg_weight = round(mean([row[3] for row in data]), 2)\n\n    # Append averages to data\n    data.append([f'Average', avg_age, avg_height, avg_weight])\n\n    # Write to CSV file\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(COLUMNS)\n        writer.writerows(data)\n\n    return filename\n```"}
{"task_id": "BigCodeBench/311", "solution": "import numpy as np\nimport random\nfrom scipy import stats\ndef task_func(list_of_lists, size=5, seed=0):\n    if not list_of_lists:\n        random.seed(seed)\n        list_of_lists = [[random.randint(0, 100) for _ in range(size)] for _ in range(size)]\n    flattened_list = [item for sublist in list_of_lists for item in sublist]\n    mean = np.mean(flattened_list)\n    median = np.median(flattened_list)\n    mode = stats.mode(flattened_list)\n    return {'mean': mean, 'median': median, 'mode': mode.mode[0]}", "raw_solution": "import numpy as np\nimport random\nfrom scipy import stats\n\ndef task_func(list_of_lists, size=5, seed=0):\n    if not list_of_lists:\n        random.seed(seed)\n        list_of_lists = [[random.randint(0, 100) for _ in range(size)] for _ in range(size)]\n    flattened_list = [item for sublist in list_of_lists for item in sublist]\n    mean = np.mean(flattened_list)\n    median = np.median(flattened_list)\n    mode = stats.mode(flattened_list)\n    return {'mean': mean, 'median': median, 'mode': mode.mode[0]}\n```"}
{"task_id": "BigCodeBench/312", "solution": "import random\nimport matplotlib.pyplot as plt\nDISTRIBUTION_SIZE = 1000\ndef task_func(bins=30):\n    # Generate a Gaussian distribution\n    distribution = [random.gauss(0, 1) for _ in range(DISTRIBUTION_SIZE)]\n\n    # Create a histogram plot\n    fig, ax = plt.subplots()\n    ax.hist(distribution, bins=bins)\n\n    return distribution, ax", "raw_solution": "import random\nimport matplotlib.pyplot as plt\n# Constants\nDISTRIBUTION_SIZE = 1000\ndef task_func(bins=30):\n    # Generate a Gaussian distribution\n    distribution = [random.gauss(0, 1) for _ in range(DISTRIBUTION_SIZE)]\n\n    # Create a histogram plot\n    fig, ax = plt.subplots()\n    ax.hist(distribution, bins=bins)\n\n    return distribution, ax\n```"}
{"task_id": "BigCodeBench/313", "solution": "import re\nimport os\nimport shutil\nfrom datetime import datetime\ndef task_func(directory):\n    # Initialize the dictionary to store the subdirectories and their corresponding files\n    subdir_files = {}\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the file is a regular file\n        if os.path.isfile(os.path.join(directory, filename)):\n            # Extract the text that is not enclosed in square brackets\n            match = re.search(r'\\[(.*?)\\]', filename)\n            if match:\n                text = match.group(1)\n            else:\n                continue\n\n            # Create the subdirectory if it doesn't exist\n            subdir = os.path.join(directory, text)\n            if not os.path.exists(subdir):\n                os.makedirs(subdir)\n\n            # Move the file to the subdirectory\n            shutil.move(os.path.join(directory, filename), subdir)\n\n            # Add the file to the list of files in the subdirectory\n            if text in subdir_files:\n                subdir_files[text].append(filename)\n            else:\n                subdir_files[text] = [filename]\n\n    # Return the directory path and the dictionary of subdirectories and their files\n    return directory, subdir_files", "raw_solution": "import re\nimport os\nimport shutil\nfrom datetime import datetime\n\ndef task_func(directory):\n    # Initialize the dictionary to store the subdirectories and their corresponding files\n    subdir_files = {}\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the file is a regular file\n        if os.path.isfile(os.path.join(directory, filename)):\n            # Extract the text that is not enclosed in square brackets\n            match = re.search(r'\\[(.*?)\\]', filename)\n            if match:\n                text = match.group(1)\n            else:\n                continue\n\n            # Create the subdirectory if it doesn't exist\n            subdir = os.path.join(directory, text)\n            if not os.path.exists(subdir):\n                os.makedirs(subdir)\n\n            # Move the file to the subdirectory\n            shutil.move(os.path.join(directory, filename), subdir)\n\n            # Add the file to the list of files in the subdirectory\n            if text in subdir_files:\n                subdir_files[text].append(filename)\n            else:\n                subdir_files[text] = [filename]\n\n    # Return the directory path and the dictionary of subdirectories and their files\n    return directory, subdir_files\n```"}
{"task_id": "BigCodeBench/314", "solution": "import socket\nimport ssl\nimport http.client\ndef task_func(SERVER_NAME, SERVER_PORT, path):\n    context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n    context.verify_mode = ssl.CERT_REQUIRED\n    context.check_hostname = True\n    context.load_default_certs()\n\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.settimeout(5)\n\n    try:\n        sock = context.wrap_socket(sock, server_hostname=SERVER_NAME)\n        sock.connect((SERVER_NAME, SERVER_PORT))\n    except ssl.SSLError as e:\n        raise e\n\n    request = f\"GET {path} HTTP/1.1\\r\\nHost: {SERVER_NAME}\\r\\n\\r\\n\"\n    sock.send(request.encode())\n\n    response = b\"\"\n    while True:\n        chunk = sock.recv(4096)\n        if chunk:\n            response += chunk\n        else:\n            break\n\n    sock.close()\n\n    return response.decode()", "raw_solution": "import socket\nimport ssl\nimport http.client\n\ndef task_func(SERVER_NAME, SERVER_PORT, path):\n    context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n    context.verify_mode = ssl.CERT_REQUIRED\n    context.check_hostname = True\n    context.load_default_certs()\n\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.settimeout(5)\n\n    try:\n        sock = context.wrap_socket(sock, server_hostname=SERVER_NAME)\n        sock.connect((SERVER_NAME, SERVER_PORT))\n    except ssl.SSLError as e:\n        raise e\n\n    request = f\"GET {path} HTTP/1.1\\r\\nHost: {SERVER_NAME}\\r\\n\\r\\n\"\n    sock.send(request.encode())\n\n    response = b\"\"\n    while True:\n        chunk = sock.recv(4096)\n        if chunk:\n            response += chunk\n        else:\n            break\n\n    sock.close()\n\n    return response.decode()\n```"}
{"task_id": "BigCodeBench/315", "solution": "import os\nfrom sendgrid import SendGridAPIClient\nfrom sendgrid.helpers.mail import Mail\nfrom python_http_client.exceptions import HTTPError\ndef task_func(dir, api_key, recipient_email):\n    try:\n        files = os.listdir(dir)\n    except FileNotFoundError:\n        return False\n\n    message = Mail(\n        from_email='from_email@example.com',\n        to_emails=recipient_email,\n        subject='List of Files',\n        plain_text_content='Here is the list of files: ' + ', '.join(files))\n\n    try:\n        sg = SendGridAPIClient(api_key)\n        response = sg.send(message)\n        return response.status_code // 100 == 2\n    except HTTPError as e:\n        raise e\n    except Exception as e:\n        raise e", "raw_solution": "import os\nfrom sendgrid import SendGridAPIClient\nfrom sendgrid.helpers.mail import Mail\nfrom python_http_client.exceptions import HTTPError\n\ndef task_func(dir, api_key, recipient_email):\n    try:\n        files = os.listdir(dir)\n    except FileNotFoundError:\n        return False\n\n    message = Mail(\n        from_email='from_email@example.com',\n        to_emails=recipient_email,\n        subject='List of Files',\n        plain_text_content='Here is the list of files: ' + ', '.join(files))\n\n    try:\n        sg = SendGridAPIClient(api_key)\n        response = sg.send(message)\n        return response.status_code // 100 == 2\n    except HTTPError as e:\n        raise e\n    except Exception as e:\n        raise e\n```"}
{"task_id": "BigCodeBench/316", "solution": "import pandas as pd\nimport random\nCATEGORIES = ['A', 'B', 'C', 'D', 'E']\ndef task_func(value_range=(0, 100)):\n    # Generate random values within the specified range\n    values = [random.randint(value_range[0], value_range[1]) for _ in range(100)]\n\n    # Map the values to categories\n    categories = [CATEGORIES[i % len(CATEGORIES)] for i in values]\n\n    # Count the occurrences of each category\n    counts = {category: categories.count(category) for category in CATEGORIES}\n\n    # Create a DataFrame from the counts\n    df = pd.DataFrame(list(counts.items()), columns=['Category', 'Count'])\n\n    return df", "raw_solution": "import pandas as pd\nimport random\n\n# Constants\nCATEGORIES = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(value_range=(0, 100)):\n    # Generate random values within the specified range\n    values = [random.randint(value_range[0], value_range[1]) for _ in range(100)]\n\n    # Map the values to categories\n    categories = [CATEGORIES[i % len(CATEGORIES)] for i in values]\n\n    # Count the occurrences of each category\n    counts = {category: categories.count(category) for category in CATEGORIES}\n\n    # Create a DataFrame from the counts\n    df = pd.DataFrame(list(counts.items()), columns=['Category', 'Count'])\n\n    return df\n```"}
{"task_id": "BigCodeBench/317", "solution": "import numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport re\ndef task_func(example_str):\n    # Extract all texts not enclosed in square brackets\n    text = re.sub(r'\\[.*?\\]', '', example_str)\n\n    # Calculate TF-IDF values\n    vectorizer = TfidfVectorizer()\n    tfidf_matrix = vectorizer.fit_transform([text])\n    tfidf_scores = np.asarray(tfidf_matrix.sum(axis=0)).ravel().tolist()[0]\n\n    # Return TF-IDF scores as a dictionary\n    return dict(zip(vectorizer.get_feature_names_out(), tfidf_scores))", "raw_solution": "import numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport re\n\ndef task_func(example_str):\n    # Extract all texts not enclosed in square brackets\n    text = re.sub(r'\\[.*?\\]', '', example_str)\n\n    # Calculate TF-IDF values\n    vectorizer = TfidfVectorizer()\n    tfidf_matrix = vectorizer.fit_transform([text])\n    tfidf_scores = np.asarray(tfidf_matrix.sum(axis=0)).ravel().tolist()[0]\n\n    # Return TF-IDF scores as a dictionary\n    return dict(zip(vectorizer.get_feature_names_out(), tfidf_scores))\n```"}
{"task_id": "BigCodeBench/318", "solution": "import random\nimport math\nimport matplotlib.pyplot as plt\ndef task_func(points_count=1000, radius=1):\n    x_coords = [random.uniform(-radius, radius) for _ in range(points_count)]\n    y_coords = [random.uniform(-radius, radius) for _ in range(points_count)]\n\n    fig, ax = plt.subplots()\n    ax.scatter(x_coords, y_coords)\n    ax.set_aspect('equal')\n    plt.show()\n    return ax", "raw_solution": "import random\nimport math\nimport matplotlib.pyplot as plt\n\ndef task_func(points_count=1000, radius=1):\n    x_coords = [random.uniform(-radius, radius) for _ in range(points_count)]\n    y_coords = [random.uniform(-radius, radius) for _ in range(points_count)]\n\n    fig, ax = plt.subplots()\n    ax.scatter(x_coords, y_coords)\n    ax.set_aspect('equal')\n    plt.show()\n    return ax\n```"}
{"task_id": "BigCodeBench/319", "solution": "import re\nimport matplotlib.pyplot as plt\nfrom nltk.probability import FreqDist\nfrom nltk.tokenize import word_tokenize\ndef task_func(example_str, top_n=30):\n    # Extract words not enclosed in square brackets\n    words = re.findall(r'\\[.*?\\]|\\b\\w+\\b', example_str)\n    words = [word.strip('[]') for word in words]\n\n    # Tokenize words and calculate frequency distribution\n    fdist = FreqDist(word_tokenize(words))\n\n    # Plot frequency distribution\n    fdist.plot(top_n)\n\n    # Get top_n most common words\n    top_words = fdist.most_common(top_n)\n    top_words_dict = {word[0]: word[1] for word in top_words}\n\n    return plt.gca(), top_words_dict", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nfrom nltk.probability import FreqDist\nfrom nltk.tokenize import word_tokenize\n\ndef task_func(example_str, top_n=30):\n    # Extract words not enclosed in square brackets\n    words = re.findall(r'\\[.*?\\]|\\b\\w+\\b', example_str)\n    words = [word.strip('[]') for word in words]\n\n    # Tokenize words and calculate frequency distribution\n    fdist = FreqDist(word_tokenize(words))\n\n    # Plot frequency distribution\n    fdist.plot(top_n)\n\n    # Get top_n most common words\n    top_words = fdist.most_common(top_n)\n    top_words_dict = {word[0]: word[1] for word in top_words}\n\n    return plt.gca(), top_words_dict\n```"}
{"task_id": "BigCodeBench/320", "solution": "import subprocess\nimport os\nimport random\ndef task_func(directory, file_list):\n    if not file_list:\n        return None\n    file_path = os.path.join(directory, random.choice(file_list))\n    process = subprocess.Popen(['python', file_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    return process.returncode", "raw_solution": "import subprocess\nimport os\nimport random\n\ndef task_func(directory, file_list):\n    if not file_list:\n        return None\n    file_path = os.path.join(directory, random.choice(file_list))\n    process = subprocess.Popen(['python', file_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    return process.returncode\n```"}
{"task_id": "BigCodeBench/321", "solution": "import pandas as pd\nimport re\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Extract names not surrounded by square brackets\n    names = re.findall(r'\\[(.*?)\\]', text)\n    names = [name for name in names if not re.match(r'^\\[.*\\]$', name)]\n\n    # Count the frequency of each name\n    name_freq = pd.Series(names).value_counts()\n\n    # Create a bar chart of the name frequencies\n    fig, ax = plt.subplots()\n    name_freq.plot(kind='bar', ax=ax)\n    ax.set_title('Name Frequencies')\n    ax.set_xlabel('Name')\n    ax.set_ylabel('Frequency')\n\n    # Calculate skewness and kurtosis\n    skewness = stats.skew(name_freq)\n    kurtosis = stats.kurtosis(name_freq)\n\n    return name_freq, ax, skewness, kurtosis", "raw_solution": "import pandas as pd\nimport re\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Extract names not surrounded by square brackets\n    names = re.findall(r'\\[(.*?)\\]', text)\n    names = [name for name in names if not re.match(r'^\\[.*\\]$', name)]\n\n    # Count the frequency of each name\n    name_freq = pd.Series(names).value_counts()\n\n    # Create a bar chart of the name frequencies\n    fig, ax = plt.subplots()\n    name_freq.plot(kind='bar', ax=ax)\n    ax.set_title('Name Frequencies')\n    ax.set_xlabel('Name')\n    ax.set_ylabel('Frequency')\n\n    # Calculate skewness and kurtosis\n    skewness = stats.skew(name_freq)\n    kurtosis = stats.kurtosis(name_freq)\n\n    return name_freq, ax, skewness, kurtosis\n```"}
{"task_id": "BigCodeBench/322", "solution": "import subprocess\nimport os\nimport shutil\nimport sys\nDIRECTORY = 'c:\\Program Files\\VMware\\VMware Server'\nBACKUP_DIRECTORY = 'c:\\Program Files\\VMware\\VMware Server\\Backup'\ndef task_func(filename):\n    # Check if the backup directory exists, if not, create it\n    if not os.path.exists(BACKUP_DIRECTORY):\n        os.makedirs(BACKUP_DIRECTORY)\n\n    # Backup the file\n    backup_file = os.path.join(BACKUP_DIRECTORY, filename)\n    try:\n        shutil.copy(os.path.join(DIRECTORY, filename), backup_file)\n    except Exception as e:\n        print(f\"Backup failed: {str(e)}\")\n        return -1\n\n    # Execute the file as a subprocess\n    try:\n        result = subprocess.run([backup_file], capture_output=True, text=True, check=True)\n        return result.returncode\n    except subprocess.CalledProcessError as e:\n        print(f\"Execution failed: {str(e)}\")\n        return -1", "raw_solution": "import subprocess\nimport os\nimport shutil\nimport sys\n\n# Constants\nDIRECTORY = 'c:\\Program Files\\VMware\\VMware Server'\nBACKUP_DIRECTORY = 'c:\\Program Files\\VMware\\VMware Server\\Backup'\n\ndef task_func(filename):\n    # Check if the backup directory exists, if not, create it\n    if not os.path.exists(BACKUP_DIRECTORY):\n        os.makedirs(BACKUP_DIRECTORY)\n\n    # Backup the file\n    backup_file = os.path.join(BACKUP_DIRECTORY, filename)\n    try:\n        shutil.copy(os.path.join(DIRECTORY, filename), backup_file)\n    except Exception as e:\n        print(f\"Backup failed: {str(e)}\")\n        return -1\n\n    # Execute the file as a subprocess\n    try:\n        result = subprocess.run([backup_file], capture_output=True, text=True, check=True)\n        return result.returncode\n    except subprocess.CalledProcessError as e:\n        print(f\"Execution failed: {str(e)}\")\n        return -1\n```"}
{"task_id": "BigCodeBench/323", "solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.mixture import GaussianMixture\ndef task_func(text, num_gaussians=1, seed=42):\n    if num_gaussians <= 0:\n        raise ValueError(\"num_gaussians must be greater than 0\")\n    words = re.findall(r'\\[[^\\]]*\\]|\\b\\w+\\b', text)\n    words = [word.strip('[]') for word in words]\n    word_counts = Counter(words)\n    gm = GaussianMixture(n_components=num_gaussians, random_state=seed)\n    gm.fit(np.array(list(word_counts.values())).reshape(-1, 1))\n    means = gm.means_.flatten()\n    variances = gm.covariances_.flatten()\n    return dict(zip(word_counts.keys(), means))", "raw_solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.mixture import GaussianMixture\n\ndef task_func(text, num_gaussians=1, seed=42):\n    if num_gaussians <= 0:\n        raise ValueError(\"num_gaussians must be greater than 0\")\n    words = re.findall(r'\\[[^\\]]*\\]|\\b\\w+\\b', text)\n    words = [word.strip('[]') for word in words]\n    word_counts = Counter(words)\n    gm = GaussianMixture(n_components=num_gaussians, random_state=seed)\n    gm.fit(np.array(list(word_counts.values())).reshape(-1, 1))\n    means = gm.means_.flatten()\n    variances = gm.covariances_.flatten()\n    return dict(zip(word_counts.keys(), means))\n```"}
{"task_id": "BigCodeBench/324", "solution": "import subprocess\nimport time\nimport threading\ndef task_func(file_list):\n    exit_codes = []\n    threads = []\n\n    def run_file(file):\n        try:\n            result = subprocess.run([file], capture_output=True, text=True, check=True)\n            exit_codes.append(result.returncode)\n        except subprocess.CalledProcessError as e:\n            exit_codes.append(e.returncode)\n\n    for file in file_list:\n        thread = threading.Thread(target=run_file, args=(file,))\n        threads.append(thread)\n        thread.start()\n\n    for thread in threads:\n        thread.join()\n\n    return exit_codes", "raw_solution": "import subprocess\nimport time\nimport threading\n\ndef task_func(file_list):\n    exit_codes = []\n    threads = []\n\n    def run_file(file):\n        try:\n            result = subprocess.run([file], capture_output=True, text=True, check=True)\n            exit_codes.append(result.returncode)\n        except subprocess.CalledProcessError as e:\n            exit_codes.append(e.returncode)\n\n    for file in file_list:\n        thread = threading.Thread(target=run_file, args=(file,))\n        threads.append(thread)\n        thread.start()\n\n    for thread in threads:\n        thread.join()\n\n    return exit_codes\n```"}
{"task_id": "BigCodeBench/325", "solution": "import re\nimport os\nfrom pathlib import Path\nimport glob\ndef task_func(directory_path: str, regex_pattern: str = r'\\\\(.+?\\\\)|\\\\w') -> dict:\n    result = {}\n    for file in glob.glob(os.path.join(directory_path, '*.txt')):\n        with open(file, 'r') as f:\n            content = f.read()\n            matches = re.findall(regex_pattern, content)\n            result[Path(file).name] = [match[0] for match in matches if match]\n    return result", "raw_solution": "import re\nimport os\nfrom pathlib import Path\nimport glob\n\ndef task_func(directory_path: str, regex_pattern: str = r'\\\\(.+?\\\\)|\\\\w') -> dict:\n    result = {}\n    for file in glob.glob(os.path.join(directory_path, '*.txt')):\n        with open(file, 'r') as f:\n            content = f.read()\n            matches = re.findall(regex_pattern, content)\n            result[Path(file).name] = [match[0] for match in matches if match]\n    return result\n```"}
{"task_id": "BigCodeBench/326", "solution": "import subprocess\nimport os\nimport sys\nimport glob\ndef task_func(directory_path):\n    result = []\n    for file in glob.glob(os.path.join(directory_path, \"*.bat\")):\n        try:\n            exit_code = subprocess.call(file, shell=True)\n            result.append((file, exit_code))\n        except Exception as e:\n            result.append((file, None))\n    return result", "raw_solution": "import subprocess\nimport os\nimport sys\nimport glob\n\ndef task_func(directory_path):\n    result = []\n    for file in glob.glob(os.path.join(directory_path, \"*.bat\")):\n        try:\n            exit_code = subprocess.call(file, shell=True)\n            result.append((file, exit_code))\n        except Exception as e:\n            result.append((file, None))\n    return result\n```"}
{"task_id": "BigCodeBench/327", "solution": "import csv\nimport re\nfrom collections import Counter\ndef task_func(file_path, regex_pattern=r'\\(.+?\\)|\\w+|[\\W_]+'):\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = [row[0] for row in reader]\n\n    matches = []\n    for line in data:\n        matches.extend(re.findall(regex_pattern, line))\n\n    return dict(Counter(matches))", "raw_solution": "import csv\nimport re\nfrom collections import Counter\n\ndef task_func(file_path, regex_pattern=r'\\(.+?\\)|\\w+|[\\W_]+'):\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = [row[0] for row in reader]\n\n    matches = []\n    for line in data:\n        matches.extend(re.findall(regex_pattern, line))\n\n    return dict(Counter(matches))\n```"}
{"task_id": "BigCodeBench/328", "solution": "import collections\nimport random\nfrom queue import PriorityQueue\ndef task_func(number_teams=5):\n    teams = collections.OrderedDict()\n    for i in range(1, number_teams + 1):\n        teams[f\"Team {i}\"] = random.randint(1, 100)\n    sorted_teams = sorted(teams.items(), key=lambda x: x[1], reverse=True)\n    return collections.OrderedDict(sorted_teams)", "raw_solution": "import collections\nimport random\nfrom queue import PriorityQueue\ndef task_func(number_teams=5):\n    teams = collections.OrderedDict()\n    for i in range(1, number_teams + 1):\n        teams[f\"Team {i}\"] = random.randint(1, 100)\n    sorted_teams = sorted(teams.items(), key=lambda x: x[1], reverse=True)\n    return collections.OrderedDict(sorted_teams)\n```"}
{"task_id": "BigCodeBench/329", "solution": "import re\nimport json\nimport os\ndef task_func(file_path: str, regex_pattern=r'\\(.+?\\)|\\w') -> dict:\n    result = {}\n    for filename in os.listdir(file_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(file_path, filename), 'r') as file:\n                data = json.load(file)\n                matches = re.findall(regex_pattern, str(data))\n                result[filename] = matches\n    return result", "raw_solution": "import re\nimport json\nimport os\n\ndef task_func(file_path: str, regex_pattern=r'\\(.+?\\)|\\w') -> dict:\n    result = {}\n    for filename in os.listdir(file_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(file_path, filename), 'r') as file:\n                data = json.load(file)\n                matches = re.findall(regex_pattern, str(data))\n                result[filename] = matches\n    return result\n```"}
{"task_id": "BigCodeBench/330", "solution": "import heapq\nimport random\ndef task_func(list_length:int, k:int):\n    # Generate a list of random integers\n    random_list = [random.randint(1, 100) for _ in range(list_length)]\n\n    # Use heapq to find the k largest numbers\n    k_largest = heapq.nlargest(k, random_list)\n\n    return (random_list, k_largest)", "raw_solution": "import heapq\nimport random\n\ndef task_func(list_length:int, k:int):\n    # Generate a list of random integers\n    random_list = [random.randint(1, 100) for _ in range(list_length)]\n\n    # Use heapq to find the k largest numbers\n    k_largest = heapq.nlargest(k, random_list)\n\n    return (random_list, k_largest)\n```"}
{"task_id": "BigCodeBench/331", "solution": "import bisect\nimport random\ndef task_func(num, list_length = 5, min_value = 0, max_value = 0):\n    if max_value == 0:\n        max_value = min_value + list_length\n    random_list = random.sample(range(min_value, max_value), list_length)\n    random_list.sort()\n    bisect.insort(random_list, num)\n    return (random_list, random_list)", "raw_solution": "import bisect\nimport random\n\ndef task_func(num, list_length = 5, min_value = 0, max_value = 0):\n    if max_value == 0:\n        max_value = min_value + list_length\n    random_list = random.sample(range(min_value, max_value), list_length)\n    random_list.sort()\n    bisect.insort(random_list, num)\n    return (random_list, random_list)\n```"}
{"task_id": "BigCodeBench/332", "solution": "import re\nfrom collections import Counter\nfrom nltk.corpus import stopwords\ndef task_func(text: str) -> dict:\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n\n    # Split the text into words\n    words = text.split()\n\n    # Remove stop words\n    words = [word for word in words if word not in stopwords.words('english')]\n\n    # Count the occurrences of each word\n    word_counts = Counter(words)\n\n    return word_counts", "raw_solution": "import re\nfrom collections import Counter\nfrom nltk.corpus import stopwords\n\ndef task_func(text: str) -> dict:\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n\n    # Split the text into words\n    words = text.split()\n\n    # Remove stop words\n    words = [word for word in words if word not in stopwords.words('english')]\n\n    # Count the occurrences of each word\n    word_counts = Counter(words)\n\n    return word_counts\n```"}
{"task_id": "BigCodeBench/333", "solution": "import heapq\nimport random\ndef task_func(k, list_length = 5, min_value = 0, max_value = 100):\n    # Generate a list of random integers\n    random_list = [random.randint(min_value, max_value) for _ in range(list_length)]\n\n    # Use heapq to find the k smallest numbers\n    k_smallest = heapq.nsmallest(k, random_list)\n\n    return (random_list, k_smallest)", "raw_solution": "import heapq\nimport random\n\ndef task_func(k, list_length = 5, min_value = 0, max_value = 100):\n    # Generate a list of random integers\n    random_list = [random.randint(min_value, max_value) for _ in range(list_length)]\n\n    # Use heapq to find the k smallest numbers\n    k_smallest = heapq.nsmallest(k, random_list)\n\n    return (random_list, k_smallest)\n```"}
{"task_id": "BigCodeBench/334", "solution": "from nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\ndef task_func(documents):\n    vectorizer = TfidfVectorizer(tokenizer=word_tokenize)\n    tfidf_matrix = vectorizer.fit_transform(documents)\n    df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names())\n    return df", "raw_solution": "from nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\n\ndef task_func(documents):\n    vectorizer = TfidfVectorizer(tokenizer=word_tokenize)\n    tfidf_matrix = vectorizer.fit_transform(documents)\n    df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names())\n    return df\n```"}
{"task_id": "BigCodeBench/335", "solution": "import collections\nfrom queue import PriorityQueue\nimport random\nLETTERS = ['a', 'b', 'c', 'd', 'e']\ndef task_func(string_length=100):\n    # Generate a random string of a given length from the predefined list of letters\n    random_string = ''.join(random.choice(LETTERS) for _ in range(string_length))\n\n    # Count the frequency of each letter in the generated string\n    letter_freq = collections.Counter(random_string)\n\n    # Create an ordered dictionary with the frequencies of each letter\n    ordered_dict = collections.OrderedDict(sorted(letter_freq.items(), key=lambda x: x[1], reverse=True))\n\n    return ordered_dict", "raw_solution": "import collections\nfrom queue import PriorityQueue\nimport random\n# Constants\nLETTERS = ['a', 'b', 'c', 'd', 'e']\ndef task_func(string_length=100):\n    # Generate a random string of a given length from the predefined list of letters\n    random_string = ''.join(random.choice(LETTERS) for _ in range(string_length))\n\n    # Count the frequency of each letter in the generated string\n    letter_freq = collections.Counter(random_string)\n\n    # Create an ordered dictionary with the frequencies of each letter\n    ordered_dict = collections.OrderedDict(sorted(letter_freq.items(), key=lambda x: x[1], reverse=True))\n\n    return ordered_dict\n```"}
{"task_id": "BigCodeBench/336", "solution": "import re\nimport os\nimport glob\nfrom pathlib import Path\ndef task_func(pattern, directory, extensions):\n    regex = re.compile(pattern, re.IGNORECASE)\n    files = []\n    for ext in extensions:\n        files.extend(glob.glob(os.path.join(directory, f'**/*.{ext}'), recursive=True))\n    matching_files = []\n    for file in files:\n        with open(file, 'r') as f:\n            if regex.search(f.read()):\n                matching_files.append(os.path.abspath(file))\n    return matching_files", "raw_solution": "import re\nimport os\nimport glob\nfrom pathlib import Path\n\ndef task_func(pattern, directory, extensions):\n    regex = re.compile(pattern, re.IGNORECASE)\n    files = []\n    for ext in extensions:\n        files.extend(glob.glob(os.path.join(directory, f'**/*.{ext}'), recursive=True))\n    matching_files = []\n    for file in files:\n        with open(file, 'r') as f:\n            if regex.search(f.read()):\n                matching_files.append(os.path.abspath(file))\n    return matching_files\n```"}
{"task_id": "BigCodeBench/337", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nCOLORS = ['r', 'g', 'b']\ndef task_func(df, group_col, value_col):\n    if not np.issubdtype(df[value_col].dtype, np.number):\n        raise TypeError(\"The 'Value' has non-numeric values.\")\n    group_values = df[group_col].unique()\n    group_colors = [COLORS[i % len(COLORS)] for i in range(len(group_values))]\n    group_means = df.groupby(group_col)[value_col].mean()\n    group_errors = df.groupby(group_col)[value_col].sem()\n    fig, ax = plt.subplots()\n    ax.bar(group_values, group_means, yerr=group_errors, color=group_colors)\n    ax.set_title(f\"Bar chart of {value_col} by {group_col}\")\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nCOLORS = ['r', 'g', 'b']\ndef task_func(df, group_col, value_col):\n    if not np.issubdtype(df[value_col].dtype, np.number):\n        raise TypeError(\"The 'Value' has non-numeric values.\")\n    group_values = df[group_col].unique()\n    group_colors = [COLORS[i % len(COLORS)] for i in range(len(group_values))]\n    group_means = df.groupby(group_col)[value_col].mean()\n    group_errors = df.groupby(group_col)[value_col].sem()\n    fig, ax = plt.subplots()\n    ax.bar(group_values, group_means, yerr=group_errors, color=group_colors)\n    ax.set_title(f\"Bar chart of {value_col} by {group_col}\")\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n    return ax\n```"}
{"task_id": "BigCodeBench/338", "solution": "import random\nimport string\nfrom matplotlib import pyplot as plt\ndef task_func(elements, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    char_count = {}\n    for element in elements:\n        pattern = \"% \" + \"\".join(random.choices(string.ascii_letters + string.digits, k=5)) + \"%\"\n        formatted_element = pattern.format(element)\n        formatted_elements.append(formatted_element)\n        for char in formatted_element:\n            if char in char_count:\n                char_count[char] += 1\n            else:\n                char_count[char] = 1\n\n    # Plot histogram\n    ax = plt.figure().gca()\n    ax.hist(list(char_count.values()), bins=range(min(char_count.values()), max(char_count.values())+1), edgecolor='black')\n    plt.xlabel('Character Count')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Character Counts')\n\n    return formatted_elements, ax, char_count", "raw_solution": "import random\nimport string\nfrom matplotlib import pyplot as plt\n\ndef task_func(elements, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    char_count = {}\n    for element in elements:\n        pattern = \"% \" + \"\".join(random.choices(string.ascii_letters + string.digits, k=5)) + \"%\"\n        formatted_element = pattern.format(element)\n        formatted_elements.append(formatted_element)\n        for char in formatted_element:\n            if char in char_count:\n                char_count[char] += 1\n            else:\n                char_count[char] = 1\n\n    # Plot histogram\n    ax = plt.figure().gca()\n    ax.hist(list(char_count.values()), bins=range(min(char_count.values()), max(char_count.values())+1), edgecolor='black')\n    plt.xlabel('Character Count')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Character Counts')\n\n    return formatted_elements, ax, char_count\n```"}
{"task_id": "BigCodeBench/339", "solution": "import json\nimport urllib.parse\nimport hmac\nimport hashlib\ndef task_func(req_data, secret_key):\n    if not isinstance(req_data, dict):\n        raise TypeError(\"req_data must be a dictionary\")\n    json_data = json.dumps(req_data, sort_keys=True)\n    signature = hmac.new(secret_key.encode(), json_data.encode(), hashlib.sha256).hexdigest()\n    url_encoded_signature = urllib.parse.quote(signature)\n    return url_encoded_signature.replace('+', '%20')", "raw_solution": "import json\nimport urllib.parse\nimport hmac\nimport hashlib\n\ndef task_func(req_data, secret_key):\n    if not isinstance(req_data, dict):\n        raise TypeError(\"req_data must be a dictionary\")\n    json_data = json.dumps(req_data, sort_keys=True)\n    signature = hmac.new(secret_key.encode(), json_data.encode(), hashlib.sha256).hexdigest()\n    url_encoded_signature = urllib.parse.quote(signature)\n    return url_encoded_signature.replace('+', '%20')\n```"}
{"task_id": "BigCodeBench/340", "solution": "import json\nimport hashlib\nimport blake3\ndef task_func(req_data):\n    # Convert the request data to a JSON string\n    json_str = json.dumps(req_data)\n\n    # Hash the JSON string with BLAKE3\n    blake3_hash = blake3.hash(json_str.encode())\n\n    # Convert the BLAKE3 hash to a hexadecimal string\n    blake3_hex = blake3_hash.hexdigest()\n\n    # Generate an MD5 hash of the BLAKE3 hexadecimal representation\n    md5_hash = hashlib.md5(blake3_hex.encode())\n\n    # Return the BLAKE3 hexadecimal hash and the MD5 hash\n    return (blake3_hex, md5_hash.hexdigest())", "raw_solution": "import json\nimport hashlib\nimport blake3\n\ndef task_func(req_data):\n    # Convert the request data to a JSON string\n    json_str = json.dumps(req_data)\n\n    # Hash the JSON string with BLAKE3\n    blake3_hash = blake3.hash(json_str.encode())\n\n    # Convert the BLAKE3 hash to a hexadecimal string\n    blake3_hex = blake3_hash.hexdigest()\n\n    # Generate an MD5 hash of the BLAKE3 hexadecimal representation\n    md5_hash = hashlib.md5(blake3_hex.encode())\n\n    # Return the BLAKE3 hexadecimal hash and the MD5 hash\n    return (blake3_hex, md5_hash.hexdigest())\n```"}
{"task_id": "BigCodeBench/341", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"The input df must contain the specified column\")\n\n    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n\n    if df[col].dtype in ['int64', 'float64']:\n        sns.histplot(df[col], kde=True, ax=axes[0])\n    else:\n        sns.countplot(df[col], ax=axes[0])\n\n    sns.boxplot(df[col], ax=axes[1])\n\n    plt.tight_layout()\n\n    return fig", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"The input df must contain the specified column\")\n\n    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n\n    if df[col].dtype in ['int64', 'float64']:\n        sns.histplot(df[col], kde=True, ax=axes[0])\n    else:\n        sns.countplot(df[col], ax=axes[0])\n\n    sns.boxplot(df[col], ax=axes[1])\n\n    plt.tight_layout()\n\n    return fig\n```"}
{"task_id": "BigCodeBench/342", "solution": "import string\nimport random\nimport re\ndef task_func(elements, pattern, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    for element in elements:\n        replaced_element = \"\".join(random.choice(string.ascii_letters) for _ in range(len(element)))\n        formatted_element = \"%{}%\".format(replaced_element)\n        formatted_elements.append(formatted_element)\n    search_result = bool(re.search(pattern, \"\".join(formatted_elements)))\n    return formatted_elements, search_result", "raw_solution": "import string\nimport random\nimport re\n\ndef task_func(elements, pattern, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    for element in elements:\n        replaced_element = \"\".join(random.choice(string.ascii_letters) for _ in range(len(element)))\n        formatted_element = \"%{}%\".format(replaced_element)\n        formatted_elements.append(formatted_element)\n    search_result = bool(re.search(pattern, \"\".join(formatted_elements)))\n    return formatted_elements, search_result\n```"}
{"task_id": "BigCodeBench/343", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nCOLORS = ['r', 'g', 'b', 'y', 'm']\ndef task_func(df, col, title=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(f\"The input df must contain the column {col}\")\n\n    values = df[col].unique()\n    counts = [(df[col] == value).sum() for value in values]\n\n    fig, ax = plt.subplots()\n    ax.pie(counts, labels=values, colors=COLORS[:len(values)], autopct='%1.1f%%', startangle=90)\n    ax.axis('equal')\n    if title:\n        ax.set_title(title)\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants for pie chart colors\nCOLORS = ['r', 'g', 'b', 'y', 'm']\n\ndef task_func(df, col, title=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(f\"The input df must contain the column {col}\")\n\n    values = df[col].unique()\n    counts = [(df[col] == value).sum() for value in values]\n\n    fig, ax = plt.subplots()\n    ax.pie(counts, labels=values, colors=COLORS[:len(values)], autopct='%1.1f%%', startangle=90)\n    ax.axis('equal')\n    if title:\n        ax.set_title(title)\n    return ax\n```"}
{"task_id": "BigCodeBench/344", "solution": "import os\nimport shutil\ndef task_func(src_folder, backup_dir):\n    if not os.path.exists(src_folder):\n        raise ValueError(\"Source folder does not exist\")\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n    try:\n        shutil.make_archive(os.path.join(backup_dir, os.path.basename(src_folder)), 'zip', src_folder)\n        os.rmdir(src_folder)\n    except Exception as e:\n        raise Exception(\"An error occurred while deleting the source folder\") from e\n    return True", "raw_solution": "import os\nimport shutil\n\ndef task_func(src_folder, backup_dir):\n    if not os.path.exists(src_folder):\n        raise ValueError(\"Source folder does not exist\")\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n    try:\n        shutil.make_archive(os.path.join(backup_dir, os.path.basename(src_folder)), 'zip', src_folder)\n        os.rmdir(src_folder)\n    except Exception as e:\n        raise Exception(\"An error occurred while deleting the source folder\") from e\n    return True\n```"}
{"task_id": "BigCodeBench/345", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(df, col1, col2):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"Input df is empty\")\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"Input df does not contain the specified columns\")\n    if not pd.api.types.is_numeric_dtype(df[col1]) or not pd.api.types.is_numeric_dtype(df[col2]):\n        raise TypeError(\"Input df uses non-numeric data\")\n\n    ax = sns.scatterplot(data=df, x=col1, y=col2)\n    sns.regplot(data=df, x=col1, y=col2, scatter=False, ax=ax)\n\n    return ax", "raw_solution": "import pandas as pd\nimport seaborn as sns\n\ndef task_func(df, col1, col2):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"Input df is empty\")\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"Input df does not contain the specified columns\")\n    if not pd.api.types.is_numeric_dtype(df[col1]) or not pd.api.types.is_numeric_dtype(df[col2]):\n        raise TypeError(\"Input df uses non-numeric data\")\n\n    ax = sns.scatterplot(data=df, x=col1, y=col2)\n    sns.regplot(data=df, x=col1, y=col2, scatter=False, ax=ax)\n\n    return ax\n```"}
{"task_id": "BigCodeBench/346", "solution": "import subprocess\nimport os\nimport sys\nimport time\ndef task_func(script_path, wait=True, *args):\n    if not os.path.exists(script_path):\n        raise ValueError(\"Script does not exist\")\n    try:\n        if wait:\n            return subprocess.run([sys.executable, script_path] + list(args), check=True, capture_output=True).returncode\n        else:\n            subprocess.Popen([sys.executable, script_path] + list(args))\n            return None\n    except subprocess.CalledProcessError as e:\n        raise subprocess.CalledProcessError(e.returncode, e.cmd, e.output)", "raw_solution": "import subprocess\nimport os\nimport sys\nimport time\n\ndef task_func(script_path, wait=True, *args):\n    if not os.path.exists(script_path):\n        raise ValueError(\"Script does not exist\")\n    try:\n        if wait:\n            return subprocess.run([sys.executable, script_path] + list(args), check=True, capture_output=True).returncode\n        else:\n            subprocess.Popen([sys.executable, script_path] + list(args))\n            return None\n    except subprocess.CalledProcessError as e:\n        raise subprocess.CalledProcessError(e.returncode, e.cmd, e.output)\n```"}
{"task_id": "BigCodeBench/347", "solution": "import pandas as pd\nimport re\nimport numpy as np\nPATTERN = r\"([a-fA-F\\d]{32})\"\ndef task_func(df, column):\n    if column not in df.columns:\n        raise KeyError(f\"Column '{column}' does not exist in the DataFrame.\")\n    df[column] = df[column].apply(lambda x: re.findall(PATTERN, str(x)))\n    df = df.explode(column)\n    return df[column].value_counts()", "raw_solution": "import pandas as pd\nimport re\nimport numpy as np\n# Constants\nPATTERN = r\"([a-fA-F\\d]{32})\"\ndef task_func(df, column):\n    if column not in df.columns:\n        raise KeyError(f\"Column '{column}' does not exist in the DataFrame.\")\n    df[column] = df[column].apply(lambda x: re.findall(PATTERN, str(x)))\n    df = df.explode(column)\n    return df[column].value_counts()\n```"}
{"task_id": "BigCodeBench/348", "solution": "import subprocess\nimport os\nimport signal\nimport time\ndef task_func(process_name: str) -> int:\n    count = 0\n    for line in subprocess.check_output([\"ps\", \"aux\"]).splitlines():\n        if process_name in line.decode():\n            pid = int(line.split()[1])\n            os.kill(pid, signal.SIGTERM)\n            time.sleep(1)\n            count += 1\n    return count", "raw_solution": "import subprocess\nimport os\nimport signal\nimport time\n\ndef task_func(process_name: str) -> int:\n    count = 0\n    for line in subprocess.check_output([\"ps\", \"aux\"]).splitlines():\n        if process_name in line.decode():\n            pid = int(line.split()[1])\n            os.kill(pid, signal.SIGTERM)\n            time.sleep(1)\n            count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/349", "solution": "import pandas as pd\nimport random\ndef task_func(product_list, categories):\n    data = []\n    for i in range(len(product_list)):\n        quantity_sold = random.randint(1, 100)\n        revenue = quantity_sold * random.randint(10, 100)\n        data.append([product_list[i], categories[i], quantity_sold, revenue])\n    df = pd.DataFrame(data, columns=['Product', 'Category', 'Quantity Sold', 'Revenue'])\n    return df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(product_list, categories):\n    data = []\n    for i in range(len(product_list)):\n        quantity_sold = random.randint(1, 100)\n        revenue = quantity_sold * random.randint(10, 100)\n        data.append([product_list[i], categories[i], quantity_sold, revenue])\n    df = pd.DataFrame(data, columns=['Product', 'Category', 'Quantity Sold', 'Revenue'])\n    return df\n```"}
{"task_id": "BigCodeBench/350", "solution": "import subprocess\nimport os\nimport shutil\nfrom glob import glob\ndef task_func(src_folder, dst_folder):\n    if not os.path.exists(src_folder):\n        return {'success': False, 'message': f'Source folder {src_folder} does not exist.', 'failed_files': []}\n    if not os.path.exists(dst_folder):\n        return {'success': False, 'message': f'Destination folder {dst_folder} does not exist.', 'failed_files': []}\n\n    failed_files = []\n    for file in glob(os.path.join(src_folder, '*')):\n        if os.path.isfile(file):\n            try:\n                subprocess.run(['gzip', file], check=True)\n                shutil.move(file + '.gz', dst_folder)\n            except subprocess.CalledProcessError:\n                failed_files.append(file)\n\n    if failed_files:\n        return {'success': False, 'message': f'Failed to compress and move {len(failed_files)} files.', 'failed_files': failed_files}\n    else:\n        return {'success': True, 'message': 'All files were compressed and moved successfully.', 'failed_files': []}", "raw_solution": "import subprocess\nimport os\nimport shutil\nfrom glob import glob\n\ndef task_func(src_folder, dst_folder):\n    if not os.path.exists(src_folder):\n        return {'success': False, 'message': f'Source folder {src_folder} does not exist.', 'failed_files': []}\n    if not os.path.exists(dst_folder):\n        return {'success': False, 'message': f'Destination folder {dst_folder} does not exist.', 'failed_files': []}\n\n    failed_files = []\n    for file in glob(os.path.join(src_folder, '*')):\n        if os.path.isfile(file):\n            try:\n                subprocess.run(['gzip', file], check=True)\n                shutil.move(file + '.gz', dst_folder)\n            except subprocess.CalledProcessError:\n                failed_files.append(file)\n\n    if failed_files:\n        return {'success': False, 'message': f'Failed to compress and move {len(failed_files)} files.', 'failed_files': failed_files}\n    else:\n        return {'success': True, 'message': 'All files were compressed and moved successfully.', 'failed_files': []}"}
{"task_id": "BigCodeBench/351", "solution": "import pandas as pd\nimport random\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    data = []\n    for product in product_list:\n        for category in categories:\n            quantity_sold = random.randint(min_value, max_value)\n            revenue = quantity_sold * random.uniform(min_value, max_value)\n            data.append([product, category, quantity_sold, revenue])\n    df = pd.DataFrame(data, columns=['Product', 'Category', 'Quantity Sold', 'Revenue'])\n    return df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    data = []\n    for product in product_list:\n        for category in categories:\n            quantity_sold = random.randint(min_value, max_value)\n            revenue = quantity_sold * random.uniform(min_value, max_value)\n            data.append([product, category, quantity_sold, revenue])\n    df = pd.DataFrame(data, columns=['Product', 'Category', 'Quantity Sold', 'Revenue'])\n    return df\n```"}
{"task_id": "BigCodeBench/352", "solution": "import pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(text_dict, word_keys, top_k=2):\n    if top_k < 0:\n        raise ValueError(\"top_k cannot be a negative integer\")\n    word_freq = Counter(text_dict)\n    top_words = word_freq.most_common(top_k)\n    top_words_dict = {word: freq for word, freq in top_words}\n    df = pd.DataFrame(list(top_words_dict.items()), columns=[\"Word\", \"Frequency\"])\n    ax = df.plot(kind='bar', x='Word', y='Frequency', legend=False)\n    plt.xlabel(\"Words\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Frequency of Top {} Words\".format(top_k))\n    return ax, top_words_dict", "raw_solution": "import pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(text_dict, word_keys, top_k=2):\n    if top_k < 0:\n        raise ValueError(\"top_k cannot be a negative integer\")\n    word_freq = Counter(text_dict)\n    top_words = word_freq.most_common(top_k)\n    top_words_dict = {word: freq for word, freq in top_words}\n    df = pd.DataFrame(list(top_words_dict.items()), columns=[\"Word\", \"Frequency\"])\n    ax = df.plot(kind='bar', x='Word', y='Frequency', legend=False)\n    plt.xlabel(\"Words\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Frequency of Top {} Words\".format(top_k))\n    return ax, top_words_dict\n```"}
{"task_id": "BigCodeBench/353", "solution": "import pandas as pd\nimport random\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    data = []\n    for product in product_list:\n        for category in categories:\n            quantity_sold = random.randint(min_value, max_value)\n            revenue = random.uniform(min_value, max_value)\n            total_revenue = quantity_sold * revenue\n            data.append([product, category, quantity_sold, revenue, total_revenue])\n    df = pd.DataFrame(data, columns=['Product', 'Category', 'Quantity Sold', 'Revenue', 'Total Revenue'])\n    return df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    data = []\n    for product in product_list:\n        for category in categories:\n            quantity_sold = random.randint(min_value, max_value)\n            revenue = random.uniform(min_value, max_value)\n            total_revenue = quantity_sold * revenue\n            data.append([product, category, quantity_sold, revenue, total_revenue])\n    df = pd.DataFrame(data, columns=['Product', 'Category', 'Quantity Sold', 'Revenue', 'Total Revenue'])\n    return df\n```"}
{"task_id": "BigCodeBench/354", "solution": "import collections\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(sentences_dict, word_keys):\n    word_counts = collections.defaultdict(int)\n    for sentence in sentences_dict.values():\n        for word in sentence.split():\n            if word in word_keys:\n                word_counts[word] += 1\n    df = pd.DataFrame(list(word_counts.items()), columns=['Word', 'Count'])\n    df.plot(x='Word', y='Count', kind='bar', legend=False)\n    plt.xlabel('Word')\n    plt.ylabel('Count')\n    plt.title('Word Frequencies')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    return plt.gca()", "raw_solution": "import collections\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nWORDS = ['the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have', 'I']\n\ndef task_func(sentences_dict, word_keys):\n    word_counts = collections.defaultdict(int)\n    for sentence in sentences_dict.values():\n        for word in sentence.split():\n            if word in word_keys:\n                word_counts[word] += 1\n    df = pd.DataFrame(list(word_counts.items()), columns=['Word', 'Count'])\n    df.plot(x='Word', y='Count', kind='bar', legend=False)\n    plt.xlabel('Word')\n    plt.ylabel('Count')\n    plt.title('Word Frequencies')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/355", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import get_window", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import get_window\n\ndef complex_wave_with_hann(amplitude, frequency, time):\n    # Generate the complex wave\n    wave = amplitude * np.exp(2j * np.pi * frequency * time)\n\n    # Apply the Hann window\n    window = get_window('hann', len(time))\n    wave *= window\n\n    # Plot the wave\n    fig, ax = plt.subplots()\n    ax.plot(time, wave.real, label='Real')\n    ax.plot(time, wave.imag, label='Imaginary')\n    ax.set_title('Complex Wave with Hann Window')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n    ax.legend()\n\n    return wave, fig, ax\n```"}
{"task_id": "BigCodeBench/356", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport cmath\ndef task_func(x, y):\n    if not isinstance(x, np.ndarray) or not isinstance(y, np.ndarray):\n        raise TypeError(\"Both x and y must be numpy.ndarray\")\n    if len(x) != len(y):\n        raise ValueError(\"x and y must have the same length\")\n\n    phase = np.angle(x + y * 1j)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y, phase)\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_zlabel('Phase')\n    ax.set_title('Phase of a complex function')\n\n    return ax, phase", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport cmath\n\ndef task_func(x, y):\n    if not isinstance(x, np.ndarray) or not isinstance(y, np.ndarray):\n        raise TypeError(\"Both x and y must be numpy.ndarray\")\n    if len(x) != len(y):\n        raise ValueError(\"x and y must have the same length\")\n\n    phase = np.angle(x + y * 1j)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y, phase)\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_zlabel('Phase')\n    ax.set_title('Phase of a complex function')\n\n    return ax, phase\n```"}
{"task_id": "BigCodeBench/357", "solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(x):\n    if not isinstance(x, np.ndarray):\n        raise TypeError(\"x must be a numpy.ndarray\")\n    real_part = norm.rvs(loc=0, scale=1, size=x.shape[0])\n    imag_part = norm.rvs(loc=2, scale=2, size=x.shape[0])\n    return real_part + 1j * imag_part", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(x):\n    if not isinstance(x, np.ndarray):\n        raise TypeError(\"x must be a numpy.ndarray\")\n    real_part = norm.rvs(loc=0, scale=1, size=x.shape[0])\n    imag_part = norm.rvs(loc=2, scale=2, size=x.shape[0])\n    return real_part + 1j * imag_part\n```"}
{"task_id": "BigCodeBench/358", "solution": "import itertools\nimport json\ndef task_func(json_list, r):\n    try:\n        data = json.loads(json_list)\n        if 'number_list' not in data:\n            raise Exception(\"Invalid JSON: 'number_list' key not found\")\n        number_list = data['number_list']\n        if not number_list:\n            raise Exception(\"Invalid JSON: 'number_list' is empty\")\n        return list(itertools.combinations(number_list, r))\n    except json.JSONDecodeError:\n        raise Exception(\"Invalid JSON\")", "raw_solution": "import itertools\nimport json\n\ndef task_func(json_list, r):\n    try:\n        data = json.loads(json_list)\n        if 'number_list' not in data:\n            raise Exception(\"Invalid JSON: 'number_list' key not found\")\n        number_list = data['number_list']\n        if not number_list:\n            raise Exception(\"Invalid JSON: 'number_list' is empty\")\n        return list(itertools.combinations(number_list, r))\n    except json.JSONDecodeError:\n        raise Exception(\"Invalid JSON\")\n```"}
{"task_id": "BigCodeBench/359", "solution": "from scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(data_dict, data_keys):\n    x = data_dict[data_keys[0]]\n    y = data_dict[data_keys[1]]\n    correlation, _ = stats.pearsonr(x, y)\n    fig, ax = plt.subplots()\n    ax.scatter(x, y)\n    ax.set_xlabel(data_keys[0])\n    ax.set_ylabel(data_keys[1])\n    ax.set_title(f'Scatter plot of {data_keys[0]} and {data_keys[1]}')\n    return correlation, ax", "raw_solution": "from scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict, data_keys):\n    x = data_dict[data_keys[0]]\n    y = data_dict[data_keys[1]]\n    correlation, _ = stats.pearsonr(x, y)\n    fig, ax = plt.subplots()\n    ax.scatter(x, y)\n    ax.set_xlabel(data_keys[0])\n    ax.set_ylabel(data_keys[1])\n    ax.set_title(f'Scatter plot of {data_keys[0]} and {data_keys[1]}')\n    return correlation, ax\n```"}
{"task_id": "BigCodeBench/360", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(file_location, sheet_name):\n    if not os.path.exists(file_location):\n        raise FileNotFoundError(\"File does not exist at the specified path.\")\n    if not pd.ExcelFile(file_location).sheet_names.count(sheet_name):\n        raise ValueError(\"Specified sheet does not exist in the workbook.\")\n    df = pd.read_excel(file_location, sheet_name=sheet_name)\n    stats = df.describe().T.to_dict()\n    fig, ax = plt.subplots()\n    ax.bar(stats.keys(), [stat['mean'] for stat in stats.values()], color='b', label='Mean')\n    ax.bar(stats.keys(), [stat['std'] for stat in stats.values()], color='r', label='Standard Deviation')\n    ax.set_title('Mean and Standard Deviation')\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Values')\n    ax.legend()\n    return stats, fig", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(file_location, sheet_name):\n    if not os.path.exists(file_location):\n        raise FileNotFoundError(\"File does not exist at the specified path.\")\n    if not pd.ExcelFile(file_location).sheet_names.count(sheet_name):\n        raise ValueError(\"Specified sheet does not exist in the workbook.\")\n    df = pd.read_excel(file_location, sheet_name=sheet_name)\n    stats = df.describe().T.to_dict()\n    fig, ax = plt.subplots()\n    ax.bar(stats.keys(), [stat['mean'] for stat in stats.values()], color='b', label='Mean')\n    ax.bar(stats.keys(), [stat['std'] for stat in stats.values()], color='r', label='Standard Deviation')\n    ax.set_title('Mean and Standard Deviation')\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Values')\n    ax.legend()\n    return stats, fig\n```"}
{"task_id": "BigCodeBench/361", "solution": "import pandas as pd\nimport logging\nimport os\ndef task_func(sheet_name, excel_file_location=\"test.xlsx\", csv_file_location=\"test.csv\"):\n    try:\n        # Check if the Excel file exists\n        if not os.path.isfile(excel_file_location):\n            raise FileNotFoundError(f\"The file {excel_file_location} does not exist.\")\n\n        # Read data from Excel file\n        df = pd.read_excel(excel_file_location, sheet_name=sheet_name)\n\n        # Convert data to CSV file\n        df.to_csv(csv_file_location, index=False)\n\n        # Calculate the sum of each column\n        column_sums = df.sum().to_dict()\n\n        return column_sums\n\n    except ValueError:\n        raise ValueError(f\"The sheet {sheet_name} does not exist in the Excel file.\")", "raw_solution": "import pandas as pd\nimport logging\nimport os\n\n# Set up basic configuration for logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\ndef task_func(sheet_name, excel_file_location=\"test.xlsx\", csv_file_location=\"test.csv\"):\n    try:\n        # Check if the Excel file exists\n        if not os.path.isfile(excel_file_location):\n            raise FileNotFoundError(f\"The file {excel_file_location} does not exist.\")\n\n        # Read data from Excel file\n        df = pd.read_excel(excel_file_location, sheet_name=sheet_name)\n\n        # Convert data to CSV file\n        df.to_csv(csv_file_location, index=False)\n\n        # Calculate the sum of each column\n        column_sums = df.sum().to_dict()\n\n        return column_sums\n\n    except ValueError:\n        raise ValueError(f\"The sheet {sheet_name} does not exist in the Excel file.\")\n```"}
{"task_id": "BigCodeBench/362", "solution": "import pandas as pd\nimport os\ndef task_func(original_file_location=\"test.xlsx\", new_file_location=\"new_test.xlsx\", sheet_name=\"Sheet1\"):\n    if not os.path.exists(original_file_location):\n        raise FileNotFoundError(\"The original Excel file does not exist at the specified path.\")\n    if not os.path.exists(new_file_location):\n        raise FileNotFoundError(\"The new Excel file does not exist at the specified path.\")\n    try:\n        df = pd.read_excel(original_file_location, sheet_name=sheet_name)\n    except KeyError:\n        raise ValueError(\"The specified sheet does not exist in the workbook.\")\n    df.to_excel(new_file_location, index=False)\n    return pd.read_excel(new_file_location)", "raw_solution": "import pandas as pd\nimport os\n\ndef task_func(original_file_location=\"test.xlsx\", new_file_location=\"new_test.xlsx\", sheet_name=\"Sheet1\"):\n    if not os.path.exists(original_file_location):\n        raise FileNotFoundError(\"The original Excel file does not exist at the specified path.\")\n    if not os.path.exists(new_file_location):\n        raise FileNotFoundError(\"The new Excel file does not exist at the specified path.\")\n    try:\n        df = pd.read_excel(original_file_location, sheet_name=sheet_name)\n    except KeyError:\n        raise ValueError(\"The specified sheet does not exist in the workbook.\")\n    df.to_excel(new_file_location, index=False)\n    return pd.read_excel(new_file_location)\n```"}
{"task_id": "BigCodeBench/363", "solution": "from multiprocessing import Pool\nimport math\ndef calculate_factorial(number: int) -> tuple:\n    return number, math.factorial(number)\ndef task_func(numbers: list) -> dict:\n    if not all(isinstance(i, int) and i >= 0 for i in numbers):\n        raise ValueError(\"All elements in the list must be non-negative integers.\")\n    with Pool(processes=4) as pool:\n        result = pool.map(calculate_factorial, numbers)\n    return dict(result)", "raw_solution": "from multiprocessing import Pool\nimport math\n\ndef calculate_factorial(number: int) -> tuple:\n    return number, math.factorial(number)\n\ndef task_func(numbers: list) -> dict:\n    if not all(isinstance(i, int) and i >= 0 for i in numbers):\n        raise ValueError(\"All elements in the list must be non-negative integers.\")\n    with Pool(processes=4) as pool:\n        result = pool.map(calculate_factorial, numbers)\n    return dict(result)\n```"}
{"task_id": "BigCodeBench/364", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nFEATURES = ['feature '+str(i) for i in range(1, 11)]\nTARGET = 'target'\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    X = df[FEATURES]\n    y = df[TARGET]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# Constants\nFEATURES = ['feature '+str(i) for i in range(1, 11)]\nTARGET = 'target'\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    X = df[FEATURES]\n    y = df[TARGET]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model\n```"}
{"task_id": "BigCodeBench/365", "solution": "from collections import Counter\nimport json\nimport random\nWORDS = ['apple', 'banana', 'cherry', 'date', 'elderberry', 'fig', 'grape', 'honeydew']\ndef task_func(n, file_name, seed=77):\n    random.seed(seed)\n    selected_words = random.sample(WORDS, n)\n    with open(file_name, 'w') as f:\n        json.dump(selected_words, f)\n    return file_name", "raw_solution": "from collections import Counter\nimport json\nimport random\n# Constants\nWORDS = ['apple', 'banana', 'cherry', 'date', 'elderberry', 'fig', 'grape', 'honeydew']\ndef task_func(n, file_name, seed=77):\n    random.seed(seed)\n    selected_words = random.sample(WORDS, n)\n    with open(file_name, 'w') as f:\n        json.dump(selected_words, f)\n    return file_name\n```"}
{"task_id": "BigCodeBench/366", "solution": "import matplotlib.pyplot as plt\nimport random\nCOLORS = ['#00bfbf', '#000000', '#0000ff']\ndef task_func(number_list, bins):\n    # Create a histogram subplot\n    fig, ax = plt.subplots()\n    ax.hist(number_list, bins=bins, color=random.choice(COLORS))\n    ax.set_title('Histogram')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport random\n# Constants\nCOLORS = ['#00bfbf', '#000000', '#0000ff']\ndef task_func(number_list, bins):\n    # Create a histogram subplot\n    fig, ax = plt.subplots()\n    ax.hist(number_list, bins=bins, color=random.choice(COLORS))\n    ax.set_title('Histogram')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n    return ax\n```"}
{"task_id": "BigCodeBench/367", "solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\ndef task_func(activities):\n    if not all(isinstance(activity, datetime) for activity in activities):\n        raise TypeError(\"Activities must be datetime objects\")\n\n    activity_counts = defaultdict(int)\n    for activity in activities:\n        activity_counts[activity.strftime('%A')] += 1\n\n    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    counts = [activity_counts[day] for day in days_of_week]\n\n    plt.bar(days_of_week, counts)\n    plt.xlabel('Day of the Week')\n    plt.ylabel('Number of Activities')\n    plt.title('Weekly Activity')\n    plt.show()\n\n    return plt.gca()", "raw_solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef task_func(activities):\n    if not all(isinstance(activity, datetime) for activity in activities):\n        raise TypeError(\"Activities must be datetime objects\")\n\n    activity_counts = defaultdict(int)\n    for activity in activities:\n        activity_counts[activity.strftime('%A')] += 1\n\n    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    counts = [activity_counts[day] for day in days_of_week]\n\n    plt.bar(days_of_week, counts)\n    plt.xlabel('Day of the Week')\n    plt.ylabel('Number of Activities')\n    plt.title('Weekly Activity')\n    plt.show()\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/368", "solution": "import os\nimport shutil\nimport random\ndef task_func(src_dir: str, dest_dir: str, seed:int = 100) -> str:\n    random.seed(seed)\n    files = os.listdir(src_dir)\n    if not files:\n        raise ValueError(\"Source directory is empty\")\n    file_to_move = random.choice(files)\n    shutil.move(os.path.join(src_dir, file_to_move), dest_dir)\n    return file_to_move", "raw_solution": "import os\nimport shutil\nimport random\n\ndef task_func(src_dir: str, dest_dir: str, seed:int = 100) -> str:\n    random.seed(seed)\n    files = os.listdir(src_dir)\n    if not files:\n        raise ValueError(\"Source directory is empty\")\n    file_to_move = random.choice(files)\n    shutil.move(os.path.join(src_dir, file_to_move), dest_dir)\n    return file_to_move\n```"}
{"task_id": "BigCodeBench/369", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(l):\n    # Convert list to numpy array\n    arr = np.array(l)\n\n    # Calculate mean and standard deviation\n    mean, std = stats.norm.fit(arr)\n\n    # Create histogram\n    plt.hist(arr, bins=10, density=True)\n\n    # Generate x values for the Gaussian fit\n    x = np.linspace(min(arr), max(arr), 100)\n\n    # Plot Gaussian fit\n    plt.plot(x, stats.norm.pdf(x, mean, std))\n\n    # Set plot title\n    plt.title(f\"Fit results: mu = {mean:.2f},  std = {std:.2f}\")\n\n    return plt.gca()", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(l):\n    # Convert list to numpy array\n    arr = np.array(l)\n\n    # Calculate mean and standard deviation\n    mean, std = stats.norm.fit(arr)\n\n    # Create histogram\n    plt.hist(arr, bins=10, density=True)\n\n    # Generate x values for the Gaussian fit\n    x = np.linspace(min(arr), max(arr), 100)\n\n    # Plot Gaussian fit\n    plt.plot(x, stats.norm.pdf(x, mean, std))\n\n    # Set plot title\n    plt.title(f\"Fit results: mu = {mean:.2f},  std = {std:.2f}\")\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/370", "solution": "import os\nimport re\nimport json\nimport glob\ndef task_func(directory_path: str) -> list:\n    if not os.path.exists(directory_path):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n\n    json_files = glob.glob(os.path.join(directory_path, \"*.json\"))\n    processed_files = []\n\n    for file in json_files:\n        with open(file, \"r\") as f:\n            content = f.read()\n            content = re.sub(r'(\")', r'\\\\\"', content)\n\n        with open(file, \"w\") as f:\n            f.write(content)\n\n        processed_files.append(file)\n\n    return processed_files", "raw_solution": "import os\nimport re\nimport json\nimport glob\n\ndef task_func(directory_path: str) -> list:\n    if not os.path.exists(directory_path):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n\n    json_files = glob.glob(os.path.join(directory_path, \"*.json\"))\n    processed_files = []\n\n    for file in json_files:\n        with open(file, \"r\") as f:\n            content = f.read()\n            content = re.sub(r'(\")', r'\\\\\"', content)\n\n        with open(file, \"w\") as f:\n            f.write(content)\n\n        processed_files.append(file)\n\n    return processed_files\n```"}
{"task_id": "BigCodeBench/371", "solution": "from sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\ndef task_func(l):\n    scaler = MinMaxScaler()\n    df = pd.DataFrame(l, columns=['Values'])\n    df['Scaled Values'] = scaler.fit_transform(df[['Values']])\n    return df", "raw_solution": "from sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndef task_func(l):\n    scaler = MinMaxScaler()\n    df = pd.DataFrame(l, columns=['Values'])\n    df['Scaled Values'] = scaler.fit_transform(df[['Values']])\n    return df\n```"}
{"task_id": "BigCodeBench/372", "solution": "import re\nimport glob\nfrom docx import Document\ndef task_func(directory_path: str) -> int:\n    count = 0\n    for file in glob.glob(directory_path + \"/*.docx\"):\n        doc = Document(file)\n        for para in doc.paragraphs:\n            if '\"' in para.text:\n                para.text = re.sub(r'(?<=\")', r'\\\\\"', para.text)\n        doc.save(file)\n        count += 1\n    return count", "raw_solution": "import re\nimport glob\nfrom docx import Document\n\ndef task_func(directory_path: str) -> int:\n    count = 0\n    for file in glob.glob(directory_path + \"/*.docx\"):\n        doc = Document(file)\n        for para in doc.paragraphs:\n            if '\"' in para.text:\n                para.text = re.sub(r'(?<=\")', r'\\\\\"', para.text)\n        doc.save(file)\n        count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/373", "solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(l, x_data, plot=False):\n    def func(x, a, b, c):\n        return a * x**2 + b * x + c\n\n    popt, _ = curve_fit(func, x_data, l)\n    fitted_values = func(x_data, *popt)\n\n    if plot:\n        plt.scatter(x_data, l, color='red', label='Original Data')\n        plt.plot(x_data, fitted_values, color='blue', label='Fitted Curve')\n        plt.legend()\n        plt.show()\n\n    return popt, fitted_values", "raw_solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(l, x_data, plot=False):\n    def func(x, a, b, c):\n        return a * x**2 + b * x + c\n\n    popt, _ = curve_fit(func, x_data, l)\n    fitted_values = func(x_data, *popt)\n\n    if plot:\n        plt.scatter(x_data, l, color='red', label='Original Data')\n        plt.plot(x_data, fitted_values, color='blue', label='Fitted Curve')\n        plt.legend()\n        plt.show()\n\n    return popt, fitted_values\n```"}
{"task_id": "BigCodeBench/374", "solution": "import regex as re\nimport glob\nimport os\nfrom openpyxl import load_workbook\ndef task_func(directory_path='./xlsx_files/'):\n    count = 0\n    for file in glob.glob(os.path.join(directory_path, '*.xlsx')):\n        wb = load_workbook(filename=file, read_only=True)\n        for sheet in wb:\n            for row in sheet.iter_rows():\n                for cell in row:\n                    if cell.value is not None:\n                        cell.value = re.sub(r'(?<=[^\\\\])(?=\")', '\\\\', str(cell.value))\n        wb.save(file)\n        count += 1\n    return count", "raw_solution": "import regex as re\nimport glob\nimport os\nfrom openpyxl import load_workbook\n\ndef task_func(directory_path='./xlsx_files/'):\n    count = 0\n    for file in glob.glob(os.path.join(directory_path, '*.xlsx')):\n        wb = load_workbook(filename=file, read_only=True)\n        for sheet in wb:\n            for row in sheet.iter_rows():\n                for cell in row:\n                    if cell.value is not None:\n                        cell.value = re.sub(r'(?<=[^\\\\])(?=\")', '\\\\', str(cell.value))\n        wb.save(file)\n        count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/375", "solution": "from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(l):\n    pca = PCA(n_components=2)\n    pca.fit(l)\n    x_pca = pca.transform(l)\n\n    fig, ax = plt.subplots()\n    ax.scatter(x_pca[:, 0], x_pca[:, 1])\n    ax.set_xlabel('First Principal Component')\n    ax.set_ylabel('Second Principal Component')\n    ax.set_title('PCA Result')\n    return ax", "raw_solution": "from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(l):\n    pca = PCA(n_components=2)\n    pca.fit(l)\n    x_pca = pca.transform(l)\n\n    fig, ax = plt.subplots()\n    ax.scatter(x_pca[:, 0], x_pca[:, 1])\n    ax.set_xlabel('First Principal Component')\n    ax.set_ylabel('Second Principal Component')\n    ax.set_title('PCA Result')\n    return ax\n```"}
{"task_id": "BigCodeBench/376", "solution": "import nltk\nimport re\nfrom collections import Counter\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(text):\n    # Split the text into words, convert to lowercase, remove punctuation and common stopwords\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    words = [word for word in words if word not in STOPWORDS]\n    # Calculate the frequency of each word\n    word_freq = Counter(words)\n    return word_freq", "raw_solution": "import nltk\nimport re\nfrom collections import Counter\n# Constants\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(text):\n    # Split the text into words, convert to lowercase, remove punctuation and common stopwords\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    words = [word for word in words if word not in STOPWORDS]\n    # Calculate the frequency of each word\n    word_freq = Counter(words)\n    return word_freq\n```"}
{"task_id": "BigCodeBench/377", "solution": "from texttable import Texttable\nimport os\nimport psutil\ndef task_func():\n    t = Texttable()\n    t.add_rows([[\"Item\", \"Value\"],\n                [\"CPU Usage (%)\", psutil.cpu_percent()],\n                [\"Memory Usage (%)\", psutil.virtual_memory().percent],\n                [\"Disk Usage (%)\", psutil.disk_usage('/').percent]])\n    return t.draw()", "raw_solution": "from texttable import Texttable\nimport os\nimport psutil\n\ndef task_func():\n    t = Texttable()\n    t.add_rows([[\"Item\", \"Value\"],\n                [\"CPU Usage (%)\", psutil.cpu_percent()],\n                [\"Memory Usage (%)\", psutil.virtual_memory().percent],\n                [\"Disk Usage (%)\", psutil.disk_usage('/').percent]])\n    return t.draw()\n```"}
{"task_id": "BigCodeBench/378", "solution": "import pandas as pd\nfrom texttable import Texttable\nimport os\nimport glob\ndef task_func(data_dir='./data/'):\n    if not os.path.exists(data_dir):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    csv_files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n    if not csv_files:\n        raise ValueError(\"There are no CSV files in the specified directory.\")\n    t = Texttable()\n    t.add_rows([[\"File Name\", \"Number of Rows\", \"Number of Columns\"]] +\n               [[(os.path.basename(file), *pd.read_csv(file).shape)] for file in csv_files])\n    return t.draw()", "raw_solution": "import pandas as pd\nfrom texttable import Texttable\nimport os\nimport glob\n\ndef task_func(data_dir='./data/'):\n    if not os.path.exists(data_dir):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    csv_files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n    if not csv_files:\n        raise ValueError(\"There are no CSV files in the specified directory.\")\n    t = Texttable()\n    t.add_rows([[\"File Name\", \"Number of Rows\", \"Number of Columns\"]] +\n               [[(os.path.basename(file), *pd.read_csv(file).shape)] for file in csv_files])\n    return t.draw()\n```"}
{"task_id": "BigCodeBench/379", "solution": "import pandas as pd\nimport numpy as np\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(length):\n    df = pd.DataFrame(np.random.randint(0,100,size=(length, len(COLUMNS))), columns=COLUMNS)\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(length):\n    df = pd.DataFrame(np.random.randint(0,100,size=(length, len(COLUMNS))), columns=COLUMNS)\n    return df\n```"}
{"task_id": "BigCodeBench/380", "solution": "import re\nimport os\nimport shutil\ndef task_func(directory):\n    for filename in os.listdir(directory):\n        if os.path.isfile(os.path.join(directory, filename)):\n            extension = os.path.splitext(filename)[1]\n            if not os.path.exists(os.path.join(directory, extension)):\n                os.mkdir(os.path.join(directory, extension))\n            shutil.move(os.path.join(directory, filename), os.path.join(directory, extension, filename))", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(directory):\n    for filename in os.listdir(directory):\n        if os.path.isfile(os.path.join(directory, filename)):\n            extension = os.path.splitext(filename)[1]\n            if not os.path.exists(os.path.join(directory, extension)):\n                os.mkdir(os.path.join(directory, extension))\n            shutil.move(os.path.join(directory, filename), os.path.join(directory, extension, filename))\n```"}
{"task_id": "BigCodeBench/381", "solution": "import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(file_path='arena.csv', target_column='Index', seed=42):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"File {file_path} not found\")\n    df = pd.read_csv(file_path)\n    if target_column not in df.columns:\n        raise ValueError(f\"Column {target_column} not found in data\")\n    df = df.dropna()\n    if df.isin([np.inf, -np.inf]).any().any() or df.abs().max().max() > 3.4028234663852886e+38:\n        raise ValueError(\"Data contains NaN, infinity or a value too large for dtype('float32')\")\n    y = df[target_column]\n    X = df.drop(columns=[target_column])\n    clf = RandomForestClassifier(random_state=seed)\n    clf.fit(X, y)\n    importances = clf.feature_importances_\n    fig, ax = plt.subplots()\n    sns.barplot(x=X.columns, y=importances, ax=ax)\n    ax.set_title('Feature Importances')\n    ax.set_xlabel('Features')\n    ax.set_ylabel('Importance')\n    return ax, importances", "raw_solution": "import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(file_path='arena.csv', target_column='Index', seed=42):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"File {file_path} not found\")\n    df = pd.read_csv(file_path)\n    if target_column not in df.columns:\n        raise ValueError(f\"Column {target_column} not found in data\")\n    df = df.dropna()\n    if df.isin([np.inf, -np.inf]).any().any() or df.abs().max().max() > 3.4028234663852886e+38:\n        raise ValueError(\"Data contains NaN, infinity or a value too large for dtype('float32')\")\n    y = df[target_column]\n    X = df.drop(columns=[target_column])\n    clf = RandomForestClassifier(random_state=seed)\n    clf.fit(X, y)\n    importances = clf.feature_importances_\n    fig, ax = plt.subplots()\n    sns.barplot(x=X.columns, y=importances, ax=ax)\n    ax.set_title('Feature Importances')\n    ax.set_xlabel('Features')\n    ax.set_ylabel('Importance')\n    return ax, importances\n```"}
{"task_id": "BigCodeBench/382", "solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(length):\n    mu, sigma = 0, 1\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, length)\n    plt.figure(figsize=(10, 6))\n    plt.plot(x, norm.pdf(x, mu, sigma), label='Probability Density Function')\n    plt.hist(x, bins=30, density=True, alpha=0.6, color='g', label='Histogram')\n    plt.legend()\n    plt.grid(True)\n    plt.title('Normal Distribution with Mean 0 and Standard Deviation 1')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.tight_layout()\n    return x, plt.gca()", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(length):\n    mu, sigma = 0, 1\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, length)\n    plt.figure(figsize=(10, 6))\n    plt.plot(x, norm.pdf(x, mu, sigma), label='Probability Density Function')\n    plt.hist(x, bins=30, density=True, alpha=0.6, color='g', label='Histogram')\n    plt.legend()\n    plt.grid(True)\n    plt.title('Normal Distribution with Mean 0 and Standard Deviation 1')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.tight_layout()\n    return x, plt.gca()\n```"}
{"task_id": "BigCodeBench/383", "solution": "import pandas as pd\nimport seaborn as sns\nfrom collections import Counter\nfrom textblob import TextBlob\nfrom matplotlib import pyplot as plt\ndef task_func(text, n, top_k):\n    blob = TextBlob(text)\n    ngrams = blob.ngrams(n)\n    counter = Counter(ngrams)\n    top_n_grams = counter.most_common(top_k)\n    df = pd.DataFrame(top_n_grams, columns=['n-gram', 'Frequency'])\n    sns.barplot(x='Frequency', y='n-gram', data=df, color='skyblue')\n    plt.show()", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom collections import Counter\nfrom textblob import TextBlob\nfrom matplotlib import pyplot as plt\n\ndef task_func(text, n, top_k):\n    blob = TextBlob(text)\n    ngrams = blob.ngrams(n)\n    counter = Counter(ngrams)\n    top_n_grams = counter.most_common(top_k)\n    df = pd.DataFrame(top_n_grams, columns=['n-gram', 'Frequency'])\n    sns.barplot(x='Frequency', y='n-gram', data=df, color='skyblue')\n    plt.show()\n```"}
{"task_id": "BigCodeBench/384", "solution": "import collections\nimport random\nimport itertools\nANIMALS = ['Cat', 'Dog', 'Elephant', 'Lion', 'Tiger', 'Bear', 'Giraffe', 'Horse', 'Rabbit', 'Snake', 'Zebra']\ndef task_func(animal_dict, max_count=10, seed=0):\n    random.seed(seed)\n    reversed_dict = collections.defaultdict(list)\n    for key, value in animal_dict.items():\n        reversed_dict[value].append(key)\n    counter = collections.Counter(itertools.chain.from_iterable(animal_dict.values()))\n    for animal in ANIMALS:\n        if animal in counter:\n            counter[animal] = random.randint(1, max_count)\n    return reversed_dict, counter", "raw_solution": "import collections\nimport random\nimport itertools\n\nANIMALS = ['Cat', 'Dog', 'Elephant', 'Lion', 'Tiger', 'Bear', 'Giraffe', 'Horse', 'Rabbit', 'Snake', 'Zebra']\n\ndef task_func(animal_dict, max_count=10, seed=0):\n    random.seed(seed)\n    reversed_dict = collections.defaultdict(list)\n    for key, value in animal_dict.items():\n        reversed_dict[value].append(key)\n    counter = collections.Counter(itertools.chain.from_iterable(animal_dict.values()))\n    for animal in ANIMALS:\n        if animal in counter:\n            counter[animal] = random.randint(1, max_count)\n    return reversed_dict, counter\n```"}
{"task_id": "BigCodeBench/385", "solution": "import matplotlib.pyplot as plt\nfrom collections import Counter\ndef task_func(fruit_dict):\n    # Combine all the fruits into one list\n    all_fruits = [fruit for name in fruit_dict.values() for fruit in name]\n\n    # Count the frequency of each fruit\n    fruit_counts = Counter(all_fruits)\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(fruit_counts.keys(), fruit_counts.values())\n    ax.set_xlabel('Fruit')\n    ax.set_ylabel('Count')\n    ax.set_title('Fruit Counts')\n\n    return fruit_counts, ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom collections import Counter\n\nFRUITS = ['Apple', 'Banana', 'Cherry', 'Date', 'Elderberry', 'Fig', 'Grape', 'Honeydew', 'Indian Prune', 'Jackfruit']\n\ndef task_func(fruit_dict):\n    # Combine all the fruits into one list\n    all_fruits = [fruit for name in fruit_dict.values() for fruit in name]\n\n    # Count the frequency of each fruit\n    fruit_counts = Counter(all_fruits)\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(fruit_counts.keys(), fruit_counts.values())\n    ax.set_xlabel('Fruit')\n    ax.set_ylabel('Count')\n    ax.set_title('Fruit Counts')\n\n    return fruit_counts, ax\n```"}
{"task_id": "BigCodeBench/386", "solution": "import numpy as np\nimport pandas as pd\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(length, min_value = 0, max_value = 100):\n    # Generate a DataFrame with random values\n    df = pd.DataFrame(np.random.randint(min_value, max_value, size=(length, len(COLUMNS))), columns=COLUMNS)\n\n    # Calculate the cumulative distribution function (CDF)\n    cdf = df.apply(lambda x: x.sort_values().values)\n\n    return cdf", "raw_solution": "import numpy as np\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(length, min_value = 0, max_value = 100):\n    # Generate a DataFrame with random values\n    df = pd.DataFrame(np.random.randint(min_value, max_value, size=(length, len(COLUMNS))), columns=COLUMNS)\n\n    # Calculate the cumulative distribution function (CDF)\n    cdf = df.apply(lambda x: x.sort_values().values)\n\n    return cdf\n```"}
{"task_id": "BigCodeBench/387", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nCITIES = ['New York', 'London', 'Beijing', 'Tokyo', 'Sydney', 'Paris', 'Berlin', 'Moscow', 'Madrid', 'Rome']\ndef task_func(city_dict, max_range=1000000, seed=0):\n    np.random.seed(seed)\n    city_pop = {}\n    for city in CITIES:\n        if city in city_dict.values():\n            city_pop[city] = np.random.randint(1, max_range)\n        else:\n            city_pop[city] = -1\n    fig, ax = plt.subplots()\n    ax.bar(city_pop.keys(), city_pop.values())\n    ax.set_xlabel('City')\n    ax.set_ylabel('Population')\n    ax.set_title('City Population')\n    return city_pop, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nCITIES = ['New York', 'London', 'Beijing', 'Tokyo', 'Sydney', 'Paris', 'Berlin', 'Moscow', 'Madrid', 'Rome']\n\ndef task_func(city_dict, max_range=1000000, seed=0):\n    np.random.seed(seed)\n    city_pop = {}\n    for city in CITIES:\n        if city in city_dict.values():\n            city_pop[city] = np.random.randint(1, max_range)\n        else:\n            city_pop[city] = -1\n    fig, ax = plt.subplots()\n    ax.bar(city_pop.keys(), city_pop.values())\n    ax.set_xlabel('City')\n    ax.set_ylabel('Population')\n    ax.set_title('City Population')\n    return city_pop, ax\n```"}
{"task_id": "BigCodeBench/388", "solution": "import collections\nimport pandas as pd\ndef task_func(my_tuple, path_csv_files):\n    result = {}\n    for file in path_csv_files:\n        df = pd.read_csv(file)\n        for column in my_tuple:\n            if column in df.columns:\n                result[column] = dict(collections.Counter(df[column]))\n    return result", "raw_solution": "import collections\nimport pandas as pd\n\ndef task_func(my_tuple, path_csv_files):\n    result = {}\n    for file in path_csv_files:\n        df = pd.read_csv(file)\n        for column in my_tuple:\n            if column in df.columns:\n                result[column] = dict(collections.Counter(df[column]))\n    return result\n```"}
{"task_id": "BigCodeBench/389", "solution": "import re\nimport os\nimport shutil\ndef task_func(directory):\n    interesting_files = []\n    for filename in os.listdir(directory):\n        if re.search(r'like|what', filename):\n            interesting_files.append(filename)\n            if not os.path.exists(os.path.join(directory, 'Interesting Files')):\n                os.makedirs(os.path.join(directory, 'Interesting Files'))\n            shutil.move(os.path.join(directory, filename), os.path.join(directory, 'Interesting Files', filename))\n    return interesting_files", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(directory):\n    interesting_files = []\n    for filename in os.listdir(directory):\n        if re.search(r'like|what', filename):\n            interesting_files.append(filename)\n            if not os.path.exists(os.path.join(directory, 'Interesting Files')):\n                os.makedirs(os.path.join(directory, 'Interesting Files'))\n            shutil.move(os.path.join(directory, filename), os.path.join(directory, 'Interesting Files', filename))\n    return interesting_files\n```"}
{"task_id": "BigCodeBench/390", "solution": "import pandas as pd\nimport requests\nfrom io import StringIO\ndef task_func(csv_url_dict, sort_by_column=\"title\"):\n    if not csv_url_dict or \"URL\" not in csv_url_dict:\n        raise ValueError(\"Invalid input. The dictionary should contain a CSV URL.\")\n\n    csv_url = csv_url_dict[\"URL\"]\n    response = requests.get(csv_url)\n    data = response.text\n    df = pd.read_csv(StringIO(data))\n\n    return df.sort_values(by=[sort_by_column])", "raw_solution": "import pandas as pd\nimport requests\nfrom io import StringIO\n\ndef task_func(csv_url_dict, sort_by_column=\"title\"):\n    if not csv_url_dict or \"URL\" not in csv_url_dict:\n        raise ValueError(\"Invalid input. The dictionary should contain a CSV URL.\")\n\n    csv_url = csv_url_dict[\"URL\"]\n    response = requests.get(csv_url)\n    data = response.text\n    df = pd.read_csv(StringIO(data))\n\n    return df.sort_values(by=[sort_by_column])\n```"}
{"task_id": "BigCodeBench/391", "solution": "import os\nimport glob\nimport shutil\ndef task_func(directory, archive_dir='archive'):\n    if not os.path.exists(directory):\n        return False, [f\"Directory {directory} does not exist\"]\n    if not os.path.exists(archive_dir):\n        os.makedirs(archive_dir)\n    json_files = glob.glob(os.path.join(directory, '*.json'))\n    error_messages = []\n    for file in json_files:\n        try:\n            shutil.move(file, archive_dir)\n        except Exception as e:\n            error_messages.append(f\"Failed to move file {file} to archive directory: {str(e)}\")\n    return not error_messages, error_messages", "raw_solution": "import os\nimport glob\nimport shutil\n\ndef task_func(directory, archive_dir='archive'):\n    if not os.path.exists(directory):\n        return False, [f\"Directory {directory} does not exist\"]\n    if not os.path.exists(archive_dir):\n        os.makedirs(archive_dir)\n    json_files = glob.glob(os.path.join(directory, '*.json'))\n    error_messages = []\n    for file in json_files:\n        try:\n            shutil.move(file, archive_dir)\n        except Exception as e:\n            error_messages.append(f\"Failed to move file {file} to archive directory: {str(e)}\")\n    return not error_messages, error_messages\n```"}
{"task_id": "BigCodeBench/392", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nCOLORS = ['r', 'g', 'b']\ndef task_func(df, group_col, value_col, group_name):\n    if group_name not in df[group_col].unique():\n        raise ValueError(f\"Group name {group_name} does not exist in the dataframe.\")\n    group_data = df[df[group_col] == group_name][value_col]\n    ax = group_data.plot(kind='bar', color=COLORS[0])\n    ax.set_title(f'Bar chart of {value_col} for {group_name}')\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nCOLORS = ['r', 'g', 'b']\ndef task_func(df, group_col, value_col, group_name):\n    if group_name not in df[group_col].unique():\n        raise ValueError(f\"Group name {group_name} does not exist in the dataframe.\")\n    group_data = df[df[group_col] == group_name][value_col]\n    ax = group_data.plot(kind='bar', color=COLORS[0])\n    ax.set_title(f'Bar chart of {value_col} for {group_name}')\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n    return ax\n```"}
{"task_id": "BigCodeBench/393", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(mu, sigma, num_samples=1000, seed=77):\n    np.random.seed(seed)\n    samples = np.random.normal(mu, sigma, num_samples)\n\n    fig, ax = plt.subplots(2, 1, figsize=(10, 10))\n\n    ax[0].hist(samples, bins=30, density=True)\n    ax[0].set_title('Histogram')\n\n    stats.probplot(samples, plot=ax[1])\n    ax[1].set_title('Q-Q Plot')\n\n    plt.tight_layout()\n\n    return fig", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(mu, sigma, num_samples=1000, seed=77):\n    np.random.seed(seed)\n    samples = np.random.normal(mu, sigma, num_samples)\n\n    fig, ax = plt.subplots(2, 1, figsize=(10, 10))\n\n    ax[0].hist(samples, bins=30, density=True)\n    ax[0].set_title('Histogram')\n\n    stats.probplot(samples, plot=ax[1])\n    ax[1].set_title('Q-Q Plot')\n\n    plt.tight_layout()\n\n    return fig\n```"}
{"task_id": "BigCodeBench/394", "solution": "import collections\nimport string\nimport random\ndef task_func(length, seed=0):\n    random.seed(seed)\n    random_string = ''.join(random.choices(string.ascii_letters, k=length))\n    frequency = collections.Counter(random_string)\n    return dict(frequency)", "raw_solution": "import collections\nimport string\nimport random\n\ndef task_func(length, seed=0):\n    random.seed(seed)\n    random_string = ''.join(random.choices(string.ascii_letters, k=length))\n    frequency = collections.Counter(random_string)\n    return dict(frequency)\n```"}
{"task_id": "BigCodeBench/395", "solution": "import re\nimport os\nimport glob\nimport natsort\nimport pandas as pd\ndef task_func(directory='./', file_pattern='*.txt', regex=r'([0-9]+)'):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    files = natsort.natsorted(glob.glob(os.path.join(directory, file_pattern)))\n    if not files:\n        raise ValueError(\"No files matching the pattern were found.\")\n    data = []\n    for file in files:\n        with open(file, 'r') as f:\n            content = f.read()\n            numeric_data = re.findall(regex, content)\n            if numeric_data:\n                data.append({'Filename': file, 'Numeric Data': numeric_data})\n    return pd.DataFrame(data)", "raw_solution": "import re\nimport os\nimport glob\nimport natsort\nimport pandas as pd\n\ndef task_func(directory='./', file_pattern='*.txt', regex=r'([0-9]+)'):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    files = natsort.natsorted(glob.glob(os.path.join(directory, file_pattern)))\n    if not files:\n        raise ValueError(\"No files matching the pattern were found.\")\n    data = []\n    for file in files:\n        with open(file, 'r') as f:\n            content = f.read()\n            numeric_data = re.findall(regex, content)\n            if numeric_data:\n                data.append({'Filename': file, 'Numeric Data': numeric_data})\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/396", "solution": "import matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(mu, sigma, sample_size, seed=0):\n    np.random.seed(seed)\n    sample = np.random.normal(mu, sigma, sample_size)\n    density = stats.gaussian_kde(sample)\n    x = np.linspace(min(sample), max(sample), 100)\n    plt.plot(x, density(x))\n    plt.title(f'Gaussian Kernel Density Estimate (Mean: {mu}, Std Dev: {sigma}, Sample Size: {sample_size})')\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    return plt.gca()", "raw_solution": "import matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(mu, sigma, sample_size, seed=0):\n    np.random.seed(seed)\n    sample = np.random.normal(mu, sigma, sample_size)\n    density = stats.gaussian_kde(sample)\n    x = np.linspace(min(sample), max(sample), 100)\n    plt.plot(x, density(x))\n    plt.title(f'Gaussian Kernel Density Estimate (Mean: {mu}, Std Dev: {sigma}, Sample Size: {sample_size})')\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/397", "solution": "import re\nimport urllib.request\nimport json\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\ndef task_func(API_URL):\n    try:\n        response = urllib.request.urlopen(API_URL)\n        data = response.read()\n        json_data = json.loads(data)\n        ip_address = json_data['ip']\n        if re.match(IP_REGEX, ip_address):\n            return ip_address\n        else:\n            raise ValueError(\"Invalid IP address\")\n    except urllib.error.URLError as e:\n        return str(e)", "raw_solution": "import re\nimport urllib.request\nimport json\n# Constants\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\ndef task_func(API_URL):\n    try:\n        response = urllib.request.urlopen(API_URL)\n        data = response.read()\n        json_data = json.loads(data)\n        ip_address = json_data['ip']\n        if re.match(IP_REGEX, ip_address):\n            return ip_address\n        else:\n            raise ValueError(\"Invalid IP address\")\n    except urllib.error.URLError as e:\n        return str(e)\n```"}
{"task_id": "BigCodeBench/398", "solution": "import json\nimport os\ndef task_func(file_path):\n    if not os.path.exists(file_path):\n        return False\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n    if not isinstance(data, list):\n        return False\n    for item in data:\n        if not isinstance(item, dict):\n            return False\n    return True", "raw_solution": "import json\nimport os\n\ndef task_func(file_path):\n    if not os.path.exists(file_path):\n        return False\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n    if not isinstance(data, list):\n        return False\n    for item in data:\n        if not isinstance(item, dict):\n            return False\n    return True\n```"}
{"task_id": "BigCodeBench/399", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency cannot be negative\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be positive\")\n\n    x = np.linspace(0, 1, sample_size)\n    y_sin = np.sin(2 * np.pi * frequency * x)\n    y_cos = np.cos(2 * np.pi * frequency * x)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y_sin, label='Sine')\n    ax.plot(x, y_cos, label='Cosine')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n    ax.legend()\n    return fig, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency cannot be negative\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be positive\")\n\n    x = np.linspace(0, 1, sample_size)\n    y_sin = np.sin(2 * np.pi * frequency * x)\n    y_cos = np.cos(2 * np.pi * frequency * x)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y_sin, label='Sine')\n    ax.plot(x, y_cos, label='Cosine')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n    ax.legend()\n    return fig, ax\n```"}
{"task_id": "BigCodeBench/400", "solution": "import json\nfrom glob import glob\ndef task_func(directory, string):\n    file_paths = []\n    for file_path in glob(directory + '/**/*.json', recursive=True):\n        with open(file_path, 'r') as file:\n            data = json.load(file)\n            if string in str(data):\n                file_paths.append(file_path)\n    return file_paths", "raw_solution": "import json\nfrom glob import glob\n\ndef task_func(directory, string):\n    file_paths = []\n    for file_path in glob(directory + '/**/*.json', recursive=True):\n        with open(file_path, 'r') as file:\n            data = json.load(file)\n            if string in str(data):\n                file_paths.append(file_path)\n    return file_paths\n```"}
{"task_id": "BigCodeBench/401", "solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\ndef task_func(app_name):\n    app = Flask(app_name)\n    mail = Mail(app)\n\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'localhost')\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', 25))\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'False').lower() in ['true', '1']\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', None)\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', None)\n\n    return mail, app.config", "raw_solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\n\ndef task_func(app_name):\n    app = Flask(app_name)\n    mail = Mail(app)\n\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'localhost')\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', 25))\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'False').lower() in ['true', '1']\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', None)\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', None)\n\n    return mail, app.config\n```"}
{"task_id": "BigCodeBench/402", "solution": "import re\nimport requests\nimport json\nimport csv\nimport os\nAPI_URL = 'https://api.example.com/data'\ndef task_func(pattern):\n    # Make a GET request to the API\n    response = requests.get(API_URL)\n    # Extract the data from the JSON response\n    data = json.loads(response.text)['data']\n    # Find the data that matches the RegEx pattern\n    matched_data = [d for d in data if re.search(pattern, d)]\n    # Write the matched data to a CSV file\n    csv_file_path = os.path.join(os.getcwd(), 'matched_data.csv')\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        for row in matched_data:\n            writer.writerow([row])\n    return csv_file_path", "raw_solution": "import re\nimport requests\nimport json\nimport csv\nimport os  \n\n# Constants\nAPI_URL = 'https://api.example.com/data'\n\ndef task_func(pattern):\n    # Make a GET request to the API\n    response = requests.get(API_URL)\n    # Extract the data from the JSON response\n    data = json.loads(response.text)['data']\n    # Find the data that matches the RegEx pattern\n    matched_data = [d for d in data if re.search(pattern, d)]\n    # Write the matched data to a CSV file\n    csv_file_path = os.path.join(os.getcwd(), 'matched_data.csv')\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        for row in matched_data:\n            writer.writerow([row])\n    return csv_file_path\n```"}
{"task_id": "BigCodeBench/403", "solution": "from PIL import Image, ImageFilter\nimport cv2\nimport numpy as np\nimport os\ndef task_func(img_path, blur_radius=5):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n\n    # Open the image\n    img = Image.open(img_path)\n\n    # Apply a blur filter\n    blurred_img = img.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n\n    # Convert the image to grayscale\n    grayscale_img = blurred_img.convert('L')\n\n    # Convert the images to numpy arrays\n    original_img_array = np.array(img)\n    processed_img_array = np.array(grayscale_img)\n\n    # Display the original and processed images side by side\n    cv2.imshow('Original Image', original_img_array)\n    cv2.imshow('Processed Image', processed_img_array)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n\n    return original_img_array, processed_img_array", "raw_solution": "from PIL import Image, ImageFilter\nimport cv2\nimport numpy as np\nimport os\n\ndef task_func(img_path, blur_radius=5):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n\n    # Open the image\n    img = Image.open(img_path)\n\n    # Apply a blur filter\n    blurred_img = img.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n\n    # Convert the image to grayscale\n    grayscale_img = blurred_img.convert('L')\n\n    # Convert the images to numpy arrays\n    original_img_array = np.array(img)\n    processed_img_array = np.array(grayscale_img)\n\n    # Display the original and processed images side by side\n    cv2.imshow('Original Image', original_img_array)\n    cv2.imshow('Processed Image', processed_img_array)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n\n    return original_img_array, processed_img_array\n```"}
{"task_id": "BigCodeBench/404", "solution": "import cv2\nimport numpy as np\nimport os\ndef task_func(img_path):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n\n    # Load the image\n    image = cv2.imread(img_path)\n\n    # Convert the image to grayscale\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Find contours in the image\n    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    return image, contours", "raw_solution": "import cv2\nimport numpy as np\nimport os\n\ndef task_func(img_path):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n\n    # Load the image\n    image = cv2.imread(img_path)\n\n    # Convert the image to grayscale\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Find contours in the image\n    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    return image, contours\n```"}
{"task_id": "BigCodeBench/405", "solution": "import random\nimport matplotlib.pyplot as plt\ndef task_func(points: int):\n    random_numbers = [random.randint(1, 100) for _ in range(points)]\n    fig, ax = plt.subplots()\n    ax.plot(range(points), random_numbers)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Random Number')\n    ax.set_title('Random Number Generation')\n    return random_numbers, ax", "raw_solution": "import random\nimport matplotlib.pyplot as plt\n\ndef task_func(points: int):\n    random_numbers = [random.randint(1, 100) for _ in range(points)]\n    fig, ax = plt.subplots()\n    ax.plot(range(points), random_numbers)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Random Number')\n    ax.set_title('Random Number Generation')\n    return random_numbers, ax\n```"}
{"task_id": "BigCodeBench/406", "solution": "from PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\ndef task_func(img_path, angle):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n\n    img = Image.open(img_path)\n    rotated_img = img.rotate(angle, expand=True)\n\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n    axs[0].imshow(img)\n    axs[0].set_title('Original Image')\n    axs[1].imshow(rotated_img)\n    axs[1].set_title('Rotated Image')\n    plt.show()\n\n    return np.array(img), np.array(rotated_img)", "raw_solution": "from PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\ndef task_func(img_path, angle):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n\n    img = Image.open(img_path)\n    rotated_img = img.rotate(angle, expand=True)\n\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n    axs[0].imshow(img)\n    axs[0].set_title('Original Image')\n    axs[1].imshow(rotated_img)\n    axs[1].set_title('Rotated Image')\n    plt.show()\n\n    return np.array(img), np.array(rotated_img)\n```"}
{"task_id": "BigCodeBench/407", "solution": "import os\nimport csv\nfrom openpyxl import load_workbook\ndef task_func(file_name, excel_file_path, csv_file_path) -> str:\n    # Load the workbook\n    workbook = load_workbook(filename=os.path.join(excel_file_path, file_name))\n\n    # Get the active sheet\n    sheet = workbook.active\n\n    # Create the CSV file path\n    csv_file_path = os.path.join(csv_file_path, file_name.replace('.xlsx', '.csv'))\n\n    # Open the CSV file for writing\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n\n        # Write the header row\n        writer.writerow([cell.value for cell in sheet[1]])\n\n        # Write the data rows\n        for row in sheet.iter_rows(min_row=2):\n            writer.writerow([cell.value for cell in row])\n\n    return csv_file_path", "raw_solution": "import os\nimport csv\nfrom openpyxl import load_workbook\n\ndef task_func(file_name, excel_file_path, csv_file_path) -> str:\n    # Load the workbook\n    workbook = load_workbook(filename=os.path.join(excel_file_path, file_name))\n\n    # Get the active sheet\n    sheet = workbook.active\n\n    # Create the CSV file path\n    csv_file_path = os.path.join(csv_file_path, file_name.replace('.xlsx', '.csv'))\n\n    # Open the CSV file for writing\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n\n        # Write the header row\n        writer.writerow([cell.value for cell in sheet[1]])\n\n        # Write the data rows\n        for row in sheet.iter_rows(min_row=2):\n            writer.writerow([cell.value for cell in row])\n\n    return csv_file_path\n```"}
{"task_id": "BigCodeBench/408", "solution": "import sqlite3\nimport pandas as pd\ndef task_func(db_file: str, query: str) -> pd.DataFrame:\n    conn = sqlite3.connect(db_file)\n    df = pd.read_sql_query(query, conn)\n    conn.close()\n    return df", "raw_solution": "import sqlite3\nimport pandas as pd\n\ndef task_func(db_file: str, query: str) -> pd.DataFrame:\n    conn = sqlite3.connect(db_file)\n    df = pd.read_sql_query(query, conn)\n    conn.close()\n    return df\n```"}
{"task_id": "BigCodeBench/409", "solution": "import os\nimport pandas as pd\nimport numpy as np\ndef task_func(excel_file_path, file_name, column_name):\n    if not os.path.exists(excel_file_path):\n        raise FileNotFoundError(\"The specified Excel file does not exist.\")\n    if not os.path.exists(os.path.join(excel_file_path, file_name)):\n        raise ValueError(\"The specified file does not exist in the specified directory.\")\n    df = pd.read_excel(os.path.join(excel_file_path, file_name))\n    if column_name not in df.columns:\n        raise ValueError(\"The specified column does not exist in the file.\")\n    mean = df[column_name].mean()\n    median = df[column_name].median()\n    std_dev = df[column_name].std()\n    return {\"mean\": mean, \"median\": median, \"std_dev\": std_dev}", "raw_solution": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(excel_file_path, file_name, column_name):\n    if not os.path.exists(excel_file_path):\n        raise FileNotFoundError(\"The specified Excel file does not exist.\")\n    if not os.path.exists(os.path.join(excel_file_path, file_name)):\n        raise ValueError(\"The specified file does not exist in the specified directory.\")\n    df = pd.read_excel(os.path.join(excel_file_path, file_name))\n    if column_name not in df.columns:\n        raise ValueError(\"The specified column does not exist in the file.\")\n    mean = df[column_name].mean()\n    median = df[column_name].median()\n    std_dev = df[column_name].std()\n    return {\"mean\": mean, \"median\": median, \"std_dev\": std_dev}\n```"}
{"task_id": "BigCodeBench/410", "solution": "import os\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(excel_directory: str, file_name: str, column_name: str, start_date: str, end_date: str) -> pd.DataFrame:\n    try:\n        if not os.path.exists(os.path.join(excel_directory, file_name)):\n            raise FileNotFoundError(f\"The file {file_name} does not exist in the directory {excel_directory}\")\n        df = pd.read_excel(os.path.join(excel_directory, file_name))\n        if column_name not in df.columns:\n            raise ValueError(f\"The column {column_name} does not exist in the DataFrame\")\n        df[column_name] = pd.to_datetime(df[column_name])\n        start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n        end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n        filtered_df = df[(df[column_name] >= start_date) & (df[column_name] <= end_date)]\n        return filtered_df\n    except ValueError as e:\n        raise ValueError(f\"Incorrect date format: {e}\")", "raw_solution": "import os\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(excel_directory: str, file_name: str, column_name: str, start_date: str, end_date: str) -> pd.DataFrame:\n    try:\n        if not os.path.exists(os.path.join(excel_directory, file_name)):\n            raise FileNotFoundError(f\"The file {file_name} does not exist in the directory {excel_directory}\")\n        df = pd.read_excel(os.path.join(excel_directory, file_name))\n        if column_name not in df.columns:\n            raise ValueError(f\"The column {column_name} does not exist in the DataFrame\")\n        df[column_name] = pd.to_datetime(df[column_name])\n        start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n        end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n        filtered_df = df[(df[column_name] >= start_date) & (df[column_name] <= end_date)]\n        return filtered_df\n    except ValueError as e:\n        raise ValueError(f\"Incorrect date format: {e}\")"}
{"task_id": "BigCodeBench/411", "solution": "import pandas as pd\nimport json\ndef task_func(data: dict, output_path: str = \"./default_data_output.json\") -> str:\n    df = pd.DataFrame(data)\n    if 'c' in df.columns:\n        df = df.drop(columns=['c'])\n    df.to_json(output_path, orient='records')\n    return output_path", "raw_solution": "import pandas as pd\nimport json\n\ndef task_func(data: dict, output_path: str = \"./default_data_output.json\") -> str:\n    df = pd.DataFrame(data)\n    if 'c' in df.columns:\n        df = df.drop(columns=['c'])\n    df.to_json(output_path, orient='records')\n    return output_path\n```"}
{"task_id": "BigCodeBench/412", "solution": "import json\nimport base64\nimport unicodedata\ndef task_func(json_file: str) -> dict:\n    with open(json_file, 'r') as file:\n        data = json.load(file)\n\n    decoded_data = {key: base64.b64decode(value).decode('utf-8') for key, value in data.items()}\n    normalized_data = {key: unicodedata.normalize('NFC', value) for key, value in decoded_data.items()}\n\n    return normalized_data", "raw_solution": "import json\nimport base64\nimport unicodedata\n\ndef task_func(json_file: str) -> dict:\n    with open(json_file, 'r') as file:\n        data = json.load(file)\n\n    decoded_data = {key: base64.b64decode(value).decode('utf-8') for key, value in data.items()}\n    normalized_data = {key: unicodedata.normalize('NFC', value) for key, value in decoded_data.items()}\n\n    return normalized_data\n```"}
{"task_id": "BigCodeBench/413", "solution": "import os\nfrom flask_mail import Mail\ndef task_func(app):\n    mail = Mail(app)\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'smtp.example.com')\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', '587'))\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', 'username')\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', 'password')\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'True').lower() in ('true', '1')\n    app.config['MAIL_USE_SSL'] = os.getenv('MAIL_USE_SSL', 'False').lower() in ('true', '1')\n    return mail, app.config", "raw_solution": "import os\nfrom flask_mail import Mail\n\ndef task_func(app):\n    mail = Mail(app)\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'smtp.example.com')\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', '587'))\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', 'username')\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', 'password')\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'True').lower() in ('true', '1')\n    app.config['MAIL_USE_SSL'] = os.getenv('MAIL_USE_SSL', 'False').lower() in ('true', '1')\n    return mail, app.config\n```"}
{"task_id": "BigCodeBench/414", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data, column=\"c\"):\n    if column in data.columns:\n        data = data.drop(columns=column)\n    if data.select_dtypes(include=[np.number]).empty:\n        return data, None\n    else:\n        fig, ax = plt.subplots()\n        data.plot(ax=ax)\n        return data, ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data, column=\"c\"):\n    if column in data.columns:\n        data = data.drop(columns=column)\n    if data.select_dtypes(include=[np.number]).empty:\n        return data, None\n    else:\n        fig, ax = plt.subplots()\n        data.plot(ax=ax)\n        return data, ax\n```"}
{"task_id": "BigCodeBench/415", "solution": "import pandas as pd\nimport codecs\ndef task_func(dataframe: pd.DataFrame) -> pd.DataFrame:\n    if not isinstance(dataframe, pd.DataFrame):\n        raise TypeError(\"Input should be a pandas DataFrame\")\n    if \"UnicodeString\" not in dataframe.columns:\n        raise KeyError(\"Column 'UnicodeString' does not exist in the DataFrame\")\n    dataframe[\"UnicodeString\"] = dataframe[\"UnicodeString\"].apply(lambda x: codecs.decode(x, 'unicode_escape'))\n    return dataframe", "raw_solution": "import pandas as pd\nimport codecs\n\ndef task_func(dataframe: pd.DataFrame) -> pd.DataFrame:\n    if not isinstance(dataframe, pd.DataFrame):\n        raise TypeError(\"Input should be a pandas DataFrame\")\n    if \"UnicodeString\" not in dataframe.columns:\n        raise KeyError(\"Column 'UnicodeString' does not exist in the DataFrame\")\n    dataframe[\"UnicodeString\"] = dataframe[\"UnicodeString\"].apply(lambda x: codecs.decode(x, 'unicode_escape'))\n    return dataframe\n```"}
{"task_id": "BigCodeBench/416", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(data, column=\"c\"):\n    if not data or not any(isinstance(col, (int, float)) for col in data.columns):\n        return None\n    data = data.drop(columns=column)\n    corr = data.corr()\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, cmap='coolwarm')\n    plt.title('Correlation Matrix Heatmap')\n    plt.show()\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data, column=\"c\"):\n    if not data or not any(isinstance(col, (int, float)) for col in data.columns):\n        return None\n    data = data.drop(columns=column)\n    corr = data.corr()\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, cmap='coolwarm')\n    plt.title('Correlation Matrix Heatmap')\n    plt.show()\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/417", "solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\ndef task_func(X, Y, learning_rate=0.01):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n\n    # Construct the model\n    model = Sequential()\n    model.add(Dense(1, input_dim=2, activation='sigmoid'))\n\n    # Compile the model\n    sgd = SGD(lr=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\n    # Train the model\n    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=0)\n\n    # Plot the training and validation loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    return model, plt.gca()", "raw_solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\n\ndef task_func(X, Y, learning_rate=0.01):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n\n    # Construct the model\n    model = Sequential()\n    model.add(Dense(1, input_dim=2, activation='sigmoid'))\n\n    # Compile the model\n    sgd = SGD(lr=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\n    # Train the model\n    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=0)\n\n    # Plot the training and validation loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    return model, plt.gca()\n```"}
{"task_id": "BigCodeBench/418", "solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\ndef task_func(X, Y):\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    model = keras.Sequential([\n        keras.layers.Dense(1, input_shape=(X_train.shape[1],), activation='sigmoid')\n    ])\n\n    model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\n    history = model.fit(X_train, y_train, epochs=100, verbose=0)\n\n    y_pred = model.predict(X_test)\n    fpr, tpr, _ = roc_curve(y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return model, plt.gca()", "raw_solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\ndef task_func(X, Y):\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    model = keras.Sequential([\n        keras.layers.Dense(1, input_shape=(X_train.shape[1],), activation='sigmoid')\n    ])\n\n    model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\n    history = model.fit(X_train, y_train, epochs=100, verbose=0)\n\n    y_pred = model.predict(X_test)\n    fpr, tpr, _ = roc_curve(y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return model, plt.gca()\n```"}
{"task_id": "BigCodeBench/419", "solution": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\ndef task_func(X, Y):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    # Construct the model\n    model = keras.Sequential([\n        keras.layers.Dense(1, input_dim=X.shape[1], activation='sigmoid')\n    ])\n\n    # Compile the model\n    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n\n    # Fit the model\n    model.fit(X_train, Y_train, epochs=100, verbose=0)\n\n    # Predict probabilities\n    Y_pred_prob = model.predict(X_test)\n\n    # Calculate precision and recall\n    precision, recall, _ = precision_recall_curve(Y_test, Y_pred_prob)\n\n    # Plot the Precision-Recall curve\n    plt.plot(recall, precision)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    ax = plt.gca()\n\n    return model, ax", "raw_solution": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n\ndef task_func(X, Y):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    # Construct the model\n    model = keras.Sequential([\n        keras.layers.Dense(1, input_dim=X.shape[1], activation='sigmoid')\n    ])\n\n    # Compile the model\n    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n\n    # Fit the model\n    model.fit(X_train, Y_train, epochs=100, verbose=0)\n\n    # Predict probabilities\n    Y_pred_prob = model.predict(X_test)\n\n    # Calculate precision and recall\n    precision, recall, _ = precision_recall_curve(Y_test, Y_pred_prob)\n\n    # Plot the Precision-Recall curve\n    plt.plot(recall, precision)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    ax = plt.gca()\n\n    return model, ax\n```"}
{"task_id": "BigCodeBench/420", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data):\n    scaler = StandardScaler()\n    for col in data.columns:\n        if pd.api.types.is_numeric_dtype(data[col]):\n            try:\n                data[col] = scaler.fit_transform(data[col].values.reshape(-1, 1))\n            except ValueError:\n                pass\n    return data", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data):\n    scaler = StandardScaler()\n    for col in data.columns:\n        if pd.api.types.is_numeric_dtype(data[col]):\n            try:\n                data[col] = scaler.fit_transform(data[col].values.reshape(-1, 1))\n            except ValueError:\n                pass\n    return data\n```"}
{"task_id": "BigCodeBench/421", "solution": "import requests\nimport os\nimport json\nimport time\nHEADERS = {\n    'accept': 'text/json',\n    'Content-Type': 'application/json'\n}\ndef task_func(url, directory, metadata):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"Directory does not exist\")\n    if not url.startswith(\"http\"):\n        raise TypeError(\"Invalid URL\")\n    status_codes = []\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        with open(file_path, 'r') as file:\n            file_data = file.read()\n        response = requests.post(url, headers=HEADERS, data=json.dumps({\"metadata\": metadata, \"file\": file_data}))\n        status_codes.append(response.status_code)\n        time.sleep(1)\n    return status_codes", "raw_solution": "import requests\nimport os\nimport json\nimport time\n\nHEADERS = {\n    'accept': 'text/json',\n    'Content-Type': 'application/json'\n}\n\ndef task_func(url, directory, metadata):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"Directory does not exist\")\n    if not url.startswith(\"http\"):\n        raise TypeError(\"Invalid URL\")\n    status_codes = []\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        with open(file_path, 'r') as file:\n            file_data = file.read()\n        response = requests.post(url, headers=HEADERS, data=json.dumps({\"metadata\": metadata, \"file\": file_data}))\n        status_codes.append(response.status_code)\n        time.sleep(1)\n    return status_codes\n```"}
{"task_id": "BigCodeBench/422", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\ndef task_func(df, target_column, column_to_remove=\"c\", test_size=0.2):\n    if column_to_remove in df.columns:\n        df = df.drop(columns=column_to_remove)\n    X = df.drop(columns=target_column)\n    y = df[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n    return X_train, X_test, y_train, y_test", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(df, target_column, column_to_remove=\"c\", test_size=0.2):\n    if column_to_remove in df.columns:\n        df = df.drop(columns=column_to_remove)\n    X = df.drop(columns=target_column)\n    y = df[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n    return X_train, X_test, y_train, y_test\n```"}
{"task_id": "BigCodeBench/423", "solution": "import numpy as np\nimport cv2\nimport os\ndef task_func(image_path='image.jpg', threshold=128):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n    if not isinstance(threshold, int) or threshold < 0 or threshold > 255:\n        raise ValueError(\"Threshold should be an integer in the range 0-255.\")\n\n    # Read the image\n    image = cv2.imread(image_path)\n\n    # Convert the image to grayscale\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Binarize the image using the given threshold\n    _, binary_image = cv2.threshold(gray_image, threshold, 255, cv2.THRESH_BINARY)\n\n    return gray_image, binary_image", "raw_solution": "import numpy as np\nimport cv2\nimport os\n\ndef task_func(image_path='image.jpg', threshold=128):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n    if not isinstance(threshold, int) or threshold < 0 or threshold > 255:\n        raise ValueError(\"Threshold should be an integer in the range 0-255.\")\n\n    # Read the image\n    image = cv2.imread(image_path)\n\n    # Convert the image to grayscale\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Binarize the image using the given threshold\n    _, binary_image = cv2.threshold(gray_image, threshold, 255, cv2.THRESH_BINARY)\n\n    return gray_image, binary_image\n```"}
{"task_id": "BigCodeBench/424", "solution": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n    if n_clusters <= 0 or not isinstance(n_clusters, int):\n        raise ValueError(\"'n_clusters' must be a positive integer.\")\n\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = image.reshape((image.shape[0] * image.shape[1], 3))\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(image)\n\n    segmented_image = kmeans.cluster_centers_[kmeans.labels_]\n    segmented_image = segmented_image.reshape(image.shape[0], 1, 3)\n\n    return image, segmented_image", "raw_solution": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n    if n_clusters <= 0 or not isinstance(n_clusters, int):\n        raise ValueError(\"'n_clusters' must be a positive integer.\")\n\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = image.reshape((image.shape[0] * image.shape[1], 3))\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(image)\n\n    segmented_image = kmeans.cluster_centers_[kmeans.labels_]\n    segmented_image = segmented_image.reshape(image.shape[0], 1, 3)\n\n    return image, segmented_image\n```"}
{"task_id": "BigCodeBench/425", "solution": "import cv2\nimport os\nfrom matplotlib import pyplot as plt\ndef task_func(image_path='image.jpg', histogram_path='histogram.png'):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n\n    image = cv2.imread(image_path, 0)\n    histogram = cv2.calcHist([image], [0], None, [256], [0, 256])\n\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1), plt.imshow(image, cmap='gray')\n    plt.title('Image'), plt.xticks([]), plt.yticks([])\n    plt.subplot(1, 2, 2), plt.plot(histogram)\n    plt.title('Histogram'), plt.xticks([]), plt.yticks([])\n    plt.savefig(histogram_path)\n\n    return plt.gca()", "raw_solution": "import cv2\nimport os\nfrom matplotlib import pyplot as plt\n\ndef task_func(image_path='image.jpg', histogram_path='histogram.png'):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n\n    image = cv2.imread(image_path, 0)\n    histogram = cv2.calcHist([image], [0], None, [256], [0, 256])\n\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1), plt.imshow(image, cmap='gray')\n    plt.title('Image'), plt.xticks([]), plt.yticks([])\n    plt.subplot(1, 2, 2), plt.plot(histogram)\n    plt.title('Histogram'), plt.xticks([]), plt.yticks([])\n    plt.savefig(histogram_path)\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/426", "solution": "import numpy as np\nimport cv2\nimport os\ndef task_func(image_path='image.jpg', threshold=128):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n    if not isinstance(threshold, int) or threshold < 0 or threshold > 255:\n        raise ValueError(\"Threshold value must be an integer in the range 0-255.\")\n\n    # Read the image\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n\n    # Binarize the image\n    _, binary_image = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n\n    # Save the binary image\n    cv2.imwrite('binary_image.jpg', binary_image)\n\n    return image, binary_image", "raw_solution": "import numpy as np\nimport cv2\nimport os\n\ndef task_func(image_path='image.jpg', threshold=128):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n    if not isinstance(threshold, int) or threshold < 0 or threshold > 255:\n        raise ValueError(\"Threshold value must be an integer in the range 0-255.\")\n\n    # Read the image\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n\n    # Binarize the image\n    _, binary_image = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n\n    # Save the binary image\n    cv2.imwrite('binary_image.jpg', binary_image)\n\n    return image, binary_image\n```"}
{"task_id": "BigCodeBench/427", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\ndef task_func(df1, df2, features=[\"feature1\", \"feature2\", \"feature3\"], target=\"target\"):\n    # Merge the two dataframes based on 'id' column\n    df = pd.merge(df1, df2, on='id')\n\n    # Perform linear regression using specified features to predict the target\n    X = df[features]\n    y = df[target]\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Get the regression coefficients and intercept\n    coefficients = model.coef_.tolist()\n    intercept = model.intercept_\n\n    # Predict the target values\n    y_pred = model.predict(X)\n\n    # Calculate the residuals\n    residuals = y - y_pred\n\n    # Plot the residuals\n    plt.figure(figsize=(8, 6))\n    plt.scatter(y_pred, residuals)\n    plt.hlines(y=0, xmin=y_pred.min(), xmax=y_pred.max(), colors='black')\n    plt.title('Residuals Plot')\n    plt.xlabel('Predicted Values')\n    plt.ylabel('Residuals')\n    residuals_plot = plt.gca()\n\n    # Return the results\n    return {\n        'coefficients': coefficients,\n        'intercept': intercept,\n        'residuals_plot': residuals_plot\n    }", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\ndef task_func(df1, df2, features=[\"feature1\", \"feature2\", \"feature3\"], target=\"target\"):\n    # Merge the two dataframes based on 'id' column\n    df = pd.merge(df1, df2, on='id')\n\n    # Perform linear regression using specified features to predict the target\n    X = df[features]\n    y = df[target]\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Get the regression coefficients and intercept\n    coefficients = model.coef_.tolist()\n    intercept = model.intercept_\n\n    # Predict the target values\n    y_pred = model.predict(X)\n\n    # Calculate the residuals\n    residuals = y - y_pred\n\n    # Plot the residuals\n    plt.figure(figsize=(8, 6))\n    plt.scatter(y_pred, residuals)\n    plt.hlines(y=0, xmin=y_pred.min(), xmax=y_pred.max(), colors='black')\n    plt.title('Residuals Plot')\n    plt.xlabel('Predicted Values')\n    plt.ylabel('Residuals')\n    residuals_plot = plt.gca()\n\n    # Return the results\n    return {\n        'coefficients': coefficients,\n        'intercept': intercept,\n        'residuals_plot': residuals_plot\n    }\n```"}
{"task_id": "BigCodeBench/428", "solution": "import pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df1, df2):\n    # Merge the two dataframes on the 'id' column\n    merged_df = pd.merge(df1, df2, on='id', how='outer')\n\n    # Scale the numeric features\n    scaler = StandardScaler()\n    merged_df[merged_df.select_dtypes(include=['float64', 'int']).columns] = scaler.fit_transform(merged_df[merged_df.select_dtypes(include=['float64', 'int']).columns])\n\n    # Create a pair plot of the scaled features\n    pair_plot = sns.pairplot(merged_df, diag_kind='kde')\n\n    return merged_df, pair_plot", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df1, df2):\n    # Merge the two dataframes on the 'id' column\n    merged_df = pd.merge(df1, df2, on='id', how='outer')\n\n    # Scale the numeric features\n    scaler = StandardScaler()\n    merged_df[merged_df.select_dtypes(include=['float64', 'int']).columns] = scaler.fit_transform(merged_df[merged_df.select_dtypes(include=['float64', 'int']).columns])\n\n    # Create a pair plot of the scaled features\n    pair_plot = sns.pairplot(merged_df, diag_kind='kde')\n\n    return merged_df, pair_plot\n```"}
{"task_id": "BigCodeBench/429", "solution": "import pandas as pd\nfrom sklearn.feature_selection import SelectKBest, f_classif\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df1, df2):\n    # Perform feature selection\n    X = df1.drop('target', axis=1)\n    y = df1['target']\n    selector = SelectKBest(score_func=f_classif, k=2)\n    selector.fit(X, y)\n    selected_features = X.columns[selector.get_support()]\n\n    # Create a correlation matrix\n    corr_matrix = df2[selected_features].corr()\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n    plt.title('Correlation Heatmap of Selected Features')\n    plt.show()\n\n    return list(selected_features), plt.gca()", "raw_solution": "import pandas as pd\nfrom sklearn.feature_selection import SelectKBest, f_classif\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df1, df2):\n    # Perform feature selection\n    X = df1.drop('target', axis=1)\n    y = df1['target']\n    selector = SelectKBest(score_func=f_classif, k=2)\n    selector.fit(X, y)\n    selected_features = X.columns[selector.get_support()]\n\n    # Create a correlation matrix\n    corr_matrix = df2[selected_features].corr()\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n    plt.title('Correlation Heatmap of Selected Features')\n    plt.show()\n\n    return list(selected_features), plt.gca()\n```"}
{"task_id": "BigCodeBench/430", "solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    # Merge datasets\n    df = pd.merge(df1, df2, on='id', suffixes=('_df1', '_df2'))\n\n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=2, n_init=10)\n    kmeans.fit(df[[column1, column2]])\n\n    # Get cluster labels\n    labels = kmeans.labels_\n\n    # Create scatterplot\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(df[column1], df[column2], c=labels)\n\n    return labels, ax", "raw_solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    # Merge datasets\n    df = pd.merge(df1, df2, on='id', suffixes=('_df1', '_df2'))\n\n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=2, n_init=10)\n    kmeans.fit(df[[column1, column2]])\n\n    # Get cluster labels\n    labels = kmeans.labels_\n\n    # Create scatterplot\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(df[column1], df[column2], c=labels)\n\n    return labels, ax\n```"}
{"task_id": "BigCodeBench/431", "solution": "import cv2\nimport os\nimport numpy as np\ndef task_func(image_file: str) -> np.ndarray:\n    if not os.path.exists(image_file):\n        raise FileNotFoundError(f\"Image file {image_file} does not exist.\")\n    try:\n        img = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n    except cv2.error:\n        raise ValueError(f\"Image file {image_file} is not a valid image.\")\n    hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n    return hist.flatten()", "raw_solution": "import cv2\nimport os\nimport numpy as np\n\ndef task_func(image_file: str) -> np.ndarray:\n    if not os.path.exists(image_file):\n        raise FileNotFoundError(f\"Image file {image_file} does not exist.\")\n    try:\n        img = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n    except cv2.error:\n        raise ValueError(f\"Image file {image_file} is not a valid image.\")\n    hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n    return hist.flatten()\n```"}
{"task_id": "BigCodeBench/432", "solution": "import seaborn as sns\nfrom scipy.stats import chi2_contingency\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    # Merge the dataframes based on the 'id' column\n    df = pd.merge(df1, df2, on='id', how='inner')\n\n    # Create a contingency table\n    contingency_table = pd.crosstab(df[column1], df[column2])\n\n    # Perform the chi-square test\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n\n    # Create a heatmap of the contingency table\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(contingency_table, annot=True, cmap='YlGnBu')\n    plt.title('Chi-Square Independence Test')\n    plt.xlabel(column2)\n    plt.ylabel(column1)\n    plt.show()\n\n    return p, plt.gca()", "raw_solution": "import seaborn as sns\nfrom scipy.stats import chi2_contingency\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    # Merge the dataframes based on the 'id' column\n    df = pd.merge(df1, df2, on='id', how='inner')\n\n    # Create a contingency table\n    contingency_table = pd.crosstab(df[column1], df[column2])\n\n    # Perform the chi-square test\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n\n    # Create a heatmap of the contingency table\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(contingency_table, annot=True, cmap='YlGnBu')\n    plt.title('Chi-Square Independence Test')\n    plt.xlabel(column2)\n    plt.ylabel(column1)\n    plt.show()\n\n    return p, plt.gca()\n```"}
{"task_id": "BigCodeBench/433", "solution": "import base64\nimport hashlib\nimport hmac\nimport binascii\ndef task_func(s, signature, secret_key):\n    decoded_message = base64.b64decode(s)\n    secret_key_bytes = bytes(secret_key, 'utf-8')\n    signature_bytes = base64.b64decode(signature)\n    computed_signature = hmac.new(secret_key_bytes, decoded_message, hashlib.sha1).digest()\n    return hmac.compare_digest(computed_signature, signature_bytes)", "raw_solution": "import base64\nimport hashlib\nimport hmac\nimport binascii\n\ndef task_func(s, signature, secret_key):\n    decoded_message = base64.b64decode(s)\n    secret_key_bytes = bytes(secret_key, 'utf-8')\n    signature_bytes = base64.b64decode(signature)\n    computed_signature = hmac.new(secret_key_bytes, decoded_message, hashlib.sha1).digest()\n    return hmac.compare_digest(computed_signature, signature_bytes)\n```"}
{"task_id": "BigCodeBench/434", "solution": "import pandas as pd\nimport re\nimport random\ndef task_func(s: str, seed: int = 0) -> pd.DataFrame:\n    random.seed(seed)\n    product_names = ['Apple', 'Banana', 'Orange', 'Pear', 'Grape']\n    product_dict = {}\n    data_list = []\n    for line in s.split('\\n'):\n        id, quantity, code, price, *description = line.split()\n        description = ' '.join(description)\n        if code not in product_dict:\n            product_dict[code] = random.choice(product_names)\n        data_list.append([id, quantity, code, price, product_dict[code], description])\n    data_df = pd.DataFrame(data_list, columns=['ID', 'Quantity', 'Code', 'Price', 'Product', 'Description'])\n    data_df['Quantity'] = data_df['Quantity'].astype(int)\n    data_df['Price'] = data_df['Price'].astype(int)\n    return data_df", "raw_solution": "import pandas as pd\nimport re\nimport random\n\ndef task_func(s: str, seed: int = 0) -> pd.DataFrame:\n    random.seed(seed)\n    product_names = ['Apple', 'Banana', 'Orange', 'Pear', 'Grape']\n    product_dict = {}\n    data_list = []\n    for line in s.split('\\n'):\n        id, quantity, code, price, *description = line.split()\n        description = ' '.join(description)\n        if code not in product_dict:\n            product_dict[code] = random.choice(product_names)\n        data_list.append([id, quantity, code, price, product_dict[code], description])\n    data_df = pd.DataFrame(data_list, columns=['ID', 'Quantity', 'Code', 'Price', 'Product', 'Description'])\n    data_df['Quantity'] = data_df['Quantity'].astype(int)\n    data_df['Price'] = data_df['Price'].astype(int)\n    return data_df\n```"}
{"task_id": "BigCodeBench/435", "solution": "import pandas as pd\nfrom random import randint\ndef task_func(name: str, age: int, code: str, salary: float, bio: str) -> pd.DataFrame:\n    job_titles = ['Engineer', 'Manager', 'Analyst', 'Developer', 'Tester']\n    job_title = job_titles[randint(0, len(job_titles)-1)]\n    data = {'Name': name, 'Age': age, 'Code': code, 'Salary': salary, 'Bio': bio, 'Job Title': job_title}\n    return pd.DataFrame(data, index=[0])", "raw_solution": "import pandas as pd\nfrom random import randint\n\ndef task_func(name: str, age: int, code: str, salary: float, bio: str) -> pd.DataFrame:\n    job_titles = ['Engineer', 'Manager', 'Analyst', 'Developer', 'Tester']\n    job_title = job_titles[randint(0, len(job_titles)-1)]\n    data = {'Name': name, 'Age': age, 'Code': code, 'Salary': salary, 'Bio': bio, 'Job Title': job_title}\n    return pd.DataFrame(data, index=[0])\n```"}
{"task_id": "BigCodeBench/436", "solution": "import string\nimport matplotlib.pyplot as plt\ndef task_func(s):\n    if not isinstance(s, str):\n        raise ValueError(\"Input must be a string\")\n    s = s.lower()\n    freq = {}\n    for char in s:\n        if char in string.ascii_lowercase:\n            if char in freq:\n                freq[char] += 1\n            else:\n                freq[char] = 1\n    fig, ax = plt.subplots()\n    ax.bar(freq.keys(), freq.values())\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Letter Frequencies')\n    plt.show()\n    return (freq, ax)", "raw_solution": "import string\nimport matplotlib.pyplot as plt\n\ndef task_func(s):\n    if not isinstance(s, str):\n        raise ValueError(\"Input must be a string\")\n    s = s.lower()\n    freq = {}\n    for char in s:\n        if char in string.ascii_lowercase:\n            if char in freq:\n                freq[char] += 1\n            else:\n                freq[char] = 1\n    fig, ax = plt.subplots()\n    ax.bar(freq.keys(), freq.values())\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Letter Frequencies')\n    plt.show()\n    return (freq, ax)\n```"}
{"task_id": "BigCodeBench/437", "solution": "import pickle\nimport os\ndef task_func(df, file_name=\"save.pkl\"):\n    # Save the DataFrame to a pickle file\n    with open(file_name, 'wb') as f:\n        pickle.dump(df, f)\n\n    # Read the DataFrame from the pickle file\n    with open(file_name, 'rb') as f:\n        loaded_df = pickle.load(f)\n\n    # Delete the intermediate file\n    os.remove(file_name)\n\n    return loaded_df", "raw_solution": "import pickle\nimport os\ndef task_func(df, file_name=\"save.pkl\"):\n    # Save the DataFrame to a pickle file\n    with open(file_name, 'wb') as f:\n        pickle.dump(df, f)\n\n    # Read the DataFrame from the pickle file\n    with open(file_name, 'rb') as f:\n        loaded_df = pickle.load(f)\n\n    # Delete the intermediate file\n    os.remove(file_name)\n\n    return loaded_df\n```"}
{"task_id": "BigCodeBench/438", "solution": "import pickle\nimport os\nimport matplotlib.pyplot as plt\ndef task_func(numbers, file_path=\"save.pkl\"):\n    if not isinstance(numbers, list) or not all(isinstance(i, (int, float)) for i in numbers):\n        raise TypeError(\"Input should be a list of numbers\")\n\n    fig, ax = plt.subplots()\n    ax.plot(numbers)\n    fig.savefig(file_path)\n\n    with open(file_path, 'rb') as file:\n        loaded_fig = pickle.load(file)\n\n    os.remove(file_path)\n\n    return loaded_fig", "raw_solution": "import pickle\nimport os\nimport matplotlib.pyplot as plt\n\ndef task_func(numbers, file_path=\"save.pkl\"):\n    if not isinstance(numbers, list) or not all(isinstance(i, (int, float)) for i in numbers):\n        raise TypeError(\"Input should be a list of numbers\")\n\n    fig, ax = plt.subplots()\n    ax.plot(numbers)\n    fig.savefig(file_path)\n\n    with open(file_path, 'rb') as file:\n        loaded_fig = pickle.load(file)\n\n    os.remove(file_path)\n\n    return loaded_fig\n```"}
{"task_id": "BigCodeBench/439", "solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(P, T):\n    # Calculate the product of P and T\n    result = np.dot(P, T)\n\n    # Create a heatmap of the result\n    ax = sns.heatmap(result, cmap=\"YlGnBu\")\n\n    return result, ax", "raw_solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(P, T):\n    # Calculate the product of P and T\n    result = np.dot(P, T)\n\n    # Create a heatmap of the result\n    ax = sns.heatmap(result, cmap=\"YlGnBu\")\n\n    return result, ax\n```"}
{"task_id": "BigCodeBench/440", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(P, T):\n    if P.shape[1] != T.shape[0]:\n        raise ValueError(\"The shapes of P and T are not compatible for multiplication.\")\n\n    result = np.dot(P, T.reshape(-1, T.shape[-1]))\n\n    scaler = StandardScaler()\n    result = scaler.fit_transform(result)\n\n    df = pd.DataFrame(result, columns=[f\"feature_{i}\" for i in range(result.shape[1])])\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(P, T):\n    if P.shape[1] != T.shape[0]:\n        raise ValueError(\"The shapes of P and T are not compatible for multiplication.\")\n\n    result = np.dot(P, T.reshape(-1, T.shape[-1]))\n\n    scaler = StandardScaler()\n    result = scaler.fit_transform(result)\n\n    df = pd.DataFrame(result, columns=[f\"feature_{i}\" for i in range(result.shape[1])])\n    return df\n```"}
{"task_id": "BigCodeBench/441", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\ndef task_func(P, T):\n    result = np.einsum('ij,ajk->ai', P, T)\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(result[:,0], result[:,1], result[:,2])\n    return result, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef task_func(P, T):\n    result = np.einsum('ij,ajk->ai', P, T)\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(result[:,0], result[:,1], result[:,2])\n    return result, ax\n```"}
{"task_id": "BigCodeBench/442", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(P, T, tensor_shape=(3, 3, 3)):\n    # Calculate the product of a matrix \"P\" and a 3D tensor \"T\"\n    result = np.dot(P, T.reshape(-1, tensor_shape[0]*tensor_shape[1]*tensor_shape[2]))\n\n    # Apply PCA to reduce the dimensionality of the result\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(result)\n\n    # Visualize the PCA result\n    fig, ax = plt.subplots()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1])\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    ax.set_title('PCA Result Visualization')\n\n    return pca_result, ax", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(P, T, tensor_shape=(3, 3, 3)):\n    # Calculate the product of a matrix \"P\" and a 3D tensor \"T\"\n    result = np.dot(P, T.reshape(-1, tensor_shape[0]*tensor_shape[1]*tensor_shape[2]))\n\n    # Apply PCA to reduce the dimensionality of the result\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(result)\n\n    # Visualize the PCA result\n    fig, ax = plt.subplots()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1])\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    ax.set_title('PCA Result Visualization')\n\n    return pca_result, ax\n```"}
{"task_id": "BigCodeBench/443", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    # Calculate the product of a matrix 'P' and a 3D tensor 'T'\n    result = np.dot(P, T)\n    # Flatten the result\n    flattened_result = result.flatten()\n    # Apply KMeans clustering to the flattened data\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    kmeans.fit(flattened_result.reshape(-1, 1))\n    # Visualize it\n    fig, ax = plt.subplots()\n    ax.scatter(flattened_result, np.zeros_like(flattened_result), c=kmeans.labels_)\n    ax.set_title('KMeans Clustering Visualization')\n    return kmeans.labels_, ax", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    # Calculate the product of a matrix 'P' and a 3D tensor 'T'\n    result = np.dot(P, T)\n    # Flatten the result\n    flattened_result = result.flatten()\n    # Apply KMeans clustering to the flattened data\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    kmeans.fit(flattened_result.reshape(-1, 1))\n    # Visualize it\n    fig, ax = plt.subplots()\n    ax.scatter(flattened_result, np.zeros_like(flattened_result), c=kmeans.labels_)\n    ax.set_title('KMeans Clustering Visualization')\n    return kmeans.labels_, ax\n```"}
{"task_id": "BigCodeBench/444", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\ndef task_func(n_points=100, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    points = np.random.rand(n_points, 3)\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n    return points, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef task_func(n_points=100, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    points = np.random.rand(n_points, 3)\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n    return points, ax\n```"}
{"task_id": "BigCodeBench/445", "solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\ndef task_func(points, seed=0):\n    np.random.seed(seed)\n    points = np.array(points)\n    if not isinstance(points, np.ndarray):\n        raise TypeError(\"Input points must be a numpy array\")\n    if points.shape[1] != 2:\n        raise ValueError(\"Input points must be a 2D array\")\n    vor = Voronoi(points)\n    fig, ax = plt.subplots()\n    voronoi_plot_2d(vor, ax=ax)\n    ax.scatter(points[:, 0], points[:, 1], color='red')\n    ax.set_xlim(vor.min_bound[0] - 1, vor.max_bound[0] + 1)\n    ax.set_ylim(vor.min_bound[1] - 1, vor.max_bound[1] + 1)\n    plt.show()\n    return vor, ax", "raw_solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\n\ndef task_func(points, seed=0):\n    np.random.seed(seed)\n    points = np.array(points)\n    if not isinstance(points, np.ndarray):\n        raise TypeError(\"Input points must be a numpy array\")\n    if points.shape[1] != 2:\n        raise ValueError(\"Input points must be a 2D array\")\n    vor = Voronoi(points)\n    fig, ax = plt.subplots()\n    voronoi_plot_2d(vor, ax=ax)\n    ax.scatter(points[:, 0], points[:, 1], color='red')\n    ax.set_xlim(vor.min_bound[0] - 1, vor.max_bound[0] + 1)\n    ax.set_ylim(vor.min_bound[1] - 1, vor.max_bound[1] + 1)\n    plt.show()\n    return vor, ax\n```"}
{"task_id": "BigCodeBench/446", "solution": "import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\ndef task_func(n_samples=100, centers=3, n_features=2, random_seed=42):\n    X, y = make_blobs(n_samples=n_samples, centers=centers, n_features=n_features, random_state=random_seed)\n    fig, ax = plt.subplots()\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='viridis')\n    return X, y, ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\n\ndef task_func(n_samples=100, centers=3, n_features=2, random_seed=42):\n    X, y = make_blobs(n_samples=n_samples, centers=centers, n_features=n_features, random_state=random_seed)\n    fig, ax = plt.subplots()\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='viridis')\n    return X, y, ax\n```"}
{"task_id": "BigCodeBench/447", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(data, n_components=2, random_state=None):\n    pca = PCA(n_components=n_components, random_state=random_state)\n    transformed_data = pca.fit_transform(data)\n\n    fig, ax = plt.subplots()\n    if n_components == 1:\n        ax.scatter(transformed_data, np.zeros_like(transformed_data))\n    else:\n        ax.scatter(transformed_data[:, 0], transformed_data[:, 1])\n\n    return {\"transformed_data\": transformed_data, \"ax\": ax}", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(data, n_components=2, random_state=None):\n    pca = PCA(n_components=n_components, random_state=random_state)\n    transformed_data = pca.fit_transform(data)\n\n    fig, ax = plt.subplots()\n    if n_components == 1:\n        ax.scatter(transformed_data, np.zeros_like(transformed_data))\n    else:\n        ax.scatter(transformed_data[:, 0], transformed_data[:, 1])\n\n    return {\"transformed_data\": transformed_data, \"ax\": ax}\n```"}
{"task_id": "BigCodeBench/448", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(mu=0, sigma=1):\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = norm.pdf(x, mu, sigma)\n    plt.plot(x, y)\n    plt.title(f'Normal Distribution with Mean {mu} and Standard Deviation {sigma}')\n    plt.xlabel('x')\n    plt.ylabel('Probability Density')\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(mu=0, sigma=1):\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = norm.pdf(x, mu, sigma)\n    plt.plot(x, y)\n    plt.title(f'Normal Distribution with Mean {mu} and Standard Deviation {sigma}')\n    plt.xlabel('x')\n    plt.ylabel('Probability Density')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/449", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, list):\n    scaler = StandardScaler()\n    standardized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n    fig, axes_list = plt.subplots(nrows=1, ncols=len(data.columns), figsize=(20, 5))\n    for i, ax in enumerate(axes_list):\n        ax.hist(standardized_data.iloc[:, i], bins=20, color='blue', edgecolor='black')\n        ax.set_title(data.columns[i])\n        ax.set_xlabel('Value')\n        ax.set_ylabel('Frequency')\n\n    plt.tight_layout()\n    plt.show()\n\n    return standardized_data, axes_list", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, list):\n    scaler = StandardScaler()\n    standardized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n    fig, axes_list = plt.subplots(nrows=1, ncols=len(data.columns), figsize=(20, 5))\n    for i, ax in enumerate(axes_list):\n        ax.hist(standardized_data.iloc[:, i], bins=20, color='blue', edgecolor='black')\n        ax.set_title(data.columns[i])\n        ax.set_xlabel('Value')\n        ax.set_ylabel('Frequency')\n\n    plt.tight_layout()\n    plt.show()\n\n    return standardized_data, axes_list\n```"}
{"task_id": "BigCodeBench/450", "solution": "from scipy.spatial.distance import cdist\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(n_samples=200, centers=4, plot_path=None, random_seed=None):\n    np.random.seed(random_seed)\n    X, y = make_blobs(n_samples=n_samples, centers=centers, random_state=random_seed)\n    dist_matrix = cdist(X, X)\n\n    if plot_path is not None:\n        plt.scatter(X[:, 0], X[:, 1], c=y)\n        plt.savefig(plot_path)\n        plt.close()\n        return None\n    else:\n        return dist_matrix, plt.gca()", "raw_solution": "from scipy.spatial.distance import cdist\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(n_samples=200, centers=4, plot_path=None, random_seed=None):\n    np.random.seed(random_seed)\n    X, y = make_blobs(n_samples=n_samples, centers=centers, random_state=random_seed)\n    dist_matrix = cdist(X, X)\n\n    if plot_path is not None:\n        plt.scatter(X[:, 0], X[:, 1], c=y)\n        plt.savefig(plot_path)\n        plt.close()\n        return None\n    else:\n        return dist_matrix, plt.gca()\n```"}
{"task_id": "BigCodeBench/451", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(n_components=2, N_SAMPLES=500, N_FEATURES=50, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    X = np.random.randn(N_SAMPLES, N_FEATURES)\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(X)\n    if n_components == 1:\n        return transformed_data, None\n    cov_matrix = np.cov(transformed_data, rowvar=False)\n    fig, ax = plt.subplots(figsize=(6, 6))\n    sns.heatmap(cov_matrix, annot=True, cmap='coolwarm', ax=ax)\n    return transformed_data, ax", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(n_components=2, N_SAMPLES=500, N_FEATURES=50, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    X = np.random.randn(N_SAMPLES, N_FEATURES)\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(X)\n    if n_components == 1:\n        return transformed_data, None\n    cov_matrix = np.cov(transformed_data, rowvar=False)\n    fig, ax = plt.subplots(figsize=(6, 6))\n    sns.heatmap(cov_matrix, annot=True, cmap='coolwarm', ax=ax)\n    return transformed_data, ax\n```"}
{"task_id": "BigCodeBench/452", "solution": "import numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\ndef task_func(n_samples=100, n_features=10, random_seed=None):\n    # Generate synthetic data\n    X, y = datasets.make_regression(n_samples=n_samples, n_features=n_features, random_state=random_seed)\n\n    # Split the data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n\n    # Fit a linear regression model to the data\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    # Predict the values of the test set\n    predictions = model.predict(X_test)\n\n    # Get the coefficients and intercept of the model\n    coefficients = model.coef_\n    intercept = model.intercept_\n\n    # Calculate the mean squared error of the model predictions\n    mse = mean_squared_error(y_test, predictions)\n\n    return predictions, coefficients, intercept, mse", "raw_solution": "import numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\ndef task_func(n_samples=100, n_features=10, random_seed=None):\n    # Generate synthetic data\n    X, y = datasets.make_regression(n_samples=n_samples, n_features=n_features, random_state=random_seed)\n\n    # Split the data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n\n    # Fit a linear regression model to the data\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    # Predict the values of the test set\n    predictions = model.predict(X_test)\n\n    # Get the coefficients and intercept of the model\n    coefficients = model.coef_\n    intercept = model.intercept_\n\n    # Calculate the mean squared error of the model predictions\n    mse = mean_squared_error(y_test, predictions)\n\n    return predictions, coefficients, intercept, mse\n```"}
{"task_id": "BigCodeBench/453", "solution": "import re\nimport string\nfrom random import choice\ndef task_func(n, pattern):\n    while True:\n        random_string = ''.join(choice(string.ascii_letters) for _ in range(n))\n        if re.match(pattern, random_string):\n            return random_string", "raw_solution": "import re\nimport string\nfrom random import choice\n\ndef task_func(n, pattern):\n    while True:\n        random_string = ''.join(choice(string.ascii_letters) for _ in range(n))\n        if re.match(pattern, random_string):\n            return random_string\n```"}
{"task_id": "BigCodeBench/454", "solution": "import os\nimport shutil\nimport glob\ndef task_func(src_dir, dest_dir, ext):\n    if not os.path.exists(src_dir) or not os.path.exists(dest_dir):\n        raise FileNotFoundError(\"Source or Destination directory does not exist\")\n\n    moved_files = []\n    for file in glob.glob(os.path.join(src_dir, f\"*.{ext}\")):\n        filename = os.path.basename(file)\n        dest_file = os.path.join(dest_dir, filename)\n        if not os.path.exists(dest_file):\n            shutil.move(file, dest_dir)\n            moved_files.append(dest_file)\n\n    return moved_files", "raw_solution": "import os\nimport shutil\nimport glob\n\ndef task_func(src_dir, dest_dir, ext):\n    if not os.path.exists(src_dir) or not os.path.exists(dest_dir):\n        raise FileNotFoundError(\"Source or Destination directory does not exist\")\n\n    moved_files = []\n    for file in glob.glob(os.path.join(src_dir, f\"*.{ext}\")):\n        filename = os.path.basename(file)\n        dest_file = os.path.join(dest_dir, filename)\n        if not os.path.exists(dest_file):\n            shutil.move(file, dest_dir)\n            moved_files.append(dest_file)\n\n    return moved_files\n```"}
{"task_id": "BigCodeBench/455", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(mean, std_dev, n):\n    samples = np.random.normal(mean, std_dev, n)\n    x = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 100)\n    plt.hist(samples, bins=30, density=True)\n    plt.plot(x, stats.norm.pdf(x, mean, std_dev))\n    plt.show()\n    return samples", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(mean, std_dev, n):\n    samples = np.random.normal(mean, std_dev, n)\n    x = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 100)\n    plt.hist(samples, bins=30, density=True)\n    plt.plot(x, stats.norm.pdf(x, mean, std_dev))\n    plt.show()\n    return samples\n```"}
{"task_id": "BigCodeBench/456", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, plt.Axes):\n    scaler = MinMaxScaler()\n    normalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n    plt.figure(figsize=(10, 8))\n    heatmap = sns.heatmap(normalized_data, cmap=\"YlGnBu\", cbar_kws={\"label\": \"Normalized Value\"})\n\n    return normalized_data, heatmap.figure", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, plt.Axes):\n    scaler = MinMaxScaler()\n    normalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n    plt.figure(figsize=(10, 8))\n    heatmap = sns.heatmap(normalized_data, cmap=\"YlGnBu\", cbar_kws={\"label\": \"Normalized Value\"})\n\n    return normalized_data, heatmap.figure\n```"}
{"task_id": "BigCodeBench/457", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(L):\n    if not isinstance(L, list):\n        raise TypeError(\"Input should be a list of list of integers\")\n    for sublist in L:\n        if not isinstance(sublist, list):\n            raise TypeError(\"Input should be a list of list of integers\")\n        for element in sublist:\n            if not isinstance(element, int):\n                raise TypeError(\"Input should be a list of list of integers\")\n    flat_list = [item for sublist in L for item in sublist if sublist]\n    df = pd.DataFrame(flat_list, columns=['Value'])\n    ax = df.hist(bins=df['Value'].nunique(), rwidth=0.8)\n    return ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    if not isinstance(L, list):\n        raise TypeError(\"Input should be a list of list of integers\")\n    for sublist in L:\n        if not isinstance(sublist, list):\n            raise TypeError(\"Input should be a list of list of integers\")\n        for element in sublist:\n            if not isinstance(element, int):\n                raise TypeError(\"Input should be a list of list of integers\")\n    flat_list = [item for sublist in L for item in sublist if sublist]\n    df = pd.DataFrame(flat_list, columns=['Value'])\n    ax = df.hist(bins=df['Value'].nunique(), rwidth=0.8)\n    return ax\n```"}
{"task_id": "BigCodeBench/458", "solution": "import json\nimport re\nimport pandas as pd\ndef task_func(json_str):\n    if not json_str:\n        return pd.DataFrame()\n    data = json.loads(json_str)\n    for key, value in data.items():\n        if isinstance(value, list):\n            for i, item in enumerate(value):\n                if isinstance(item, str) and re.match(r'^-?\\d+(?:\\.\\d+)?$', item):\n                    value[i] = float(item) * 2\n                elif isinstance(item, (int, float)):\n                    value[i] = item * 2\n        elif isinstance(value, str) and re.match(r'^-?\\d+(?:\\.\\d+)?$', value):\n            data[key] = float(value) * 2\n        elif isinstance(value, (int, float)):\n            data[key] = value * 2\n    return pd.DataFrame(data)", "raw_solution": "import json\nimport re\nimport pandas as pd\n\ndef task_func(json_str):\n    if not json_str:\n        return pd.DataFrame()\n    data = json.loads(json_str)\n    for key, value in data.items():\n        if isinstance(value, list):\n            for i, item in enumerate(value):\n                if isinstance(item, str) and re.match(r'^-?\\d+(?:\\.\\d+)?$', item):\n                    value[i] = float(item) * 2\n                elif isinstance(item, (int, float)):\n                    value[i] = item * 2\n        elif isinstance(value, str) and re.match(r'^-?\\d+(?:\\.\\d+)?$', value):\n            data[key] = float(value) * 2\n        elif isinstance(value, (int, float)):\n            data[key] = value * 2\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/459", "solution": "import subprocess\nimport os\nimport time\nfrom datetime import datetime\ndef task_func(script_dir, scripts, delay):\n    if delay < 0:\n        raise ValueError(\"Delay cannot be negative\")\n    if not scripts:\n        raise ValueError(\"No scripts provided\")\n\n    timestamps = []\n    for script in scripts:\n        script_path = os.path.join(script_dir, script)\n        if not os.path.exists(script_path):\n            raise ValueError(f\"Script {script} not found in directory {script_dir}\")\n\n        timestamps.append(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n        subprocess.run([\"bash\", script_path])\n\n        if delay > 0:\n            time.sleep(delay)\n\n    return timestamps", "raw_solution": "import subprocess\nimport os\nimport time\nfrom datetime import datetime\n\ndef task_func(script_dir, scripts, delay):\n    if delay < 0:\n        raise ValueError(\"Delay cannot be negative\")\n    if not scripts:\n        raise ValueError(\"No scripts provided\")\n\n    timestamps = []\n    for script in scripts:\n        script_path = os.path.join(script_dir, script)\n        if not os.path.exists(script_path):\n            raise ValueError(f\"Script {script} not found in directory {script_dir}\")\n\n        timestamps.append(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n        subprocess.run([\"bash\", script_path])\n\n        if delay > 0:\n            time.sleep(delay)\n\n    return timestamps\n```"}
{"task_id": "BigCodeBench/460", "solution": "import subprocess\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(script_path, output_file_path):\n    try:\n        subprocess.run([\"python\", script_path, output_file_path], check=True)\n    except subprocess.CalledProcessError:\n        raise ValueError(\"Script execution failed\")\n\n    try:\n        df = pd.read_csv(output_file_path)\n    except pd.errors.ParserError:\n        raise ValueError(\"Invalid CSV file\")\n\n    if df.shape[1] != 2:\n        raise ValueError(\"CSV must have exactly 2 columns\")\n\n    fig, ax = plt.subplots()\n    ax.bar(df.iloc[:, 0], df.iloc[:, 1])\n    plt.tight_layout()\n\n    return df, ax", "raw_solution": "import subprocess\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(script_path, output_file_path):\n    try:\n        subprocess.run([\"python\", script_path, output_file_path], check=True)\n    except subprocess.CalledProcessError:\n        raise ValueError(\"Script execution failed\")\n\n    try:\n        df = pd.read_csv(output_file_path)\n    except pd.errors.ParserError:\n        raise ValueError(\"Invalid CSV file\")\n\n    if df.shape[1] != 2:\n        raise ValueError(\"CSV must have exactly 2 columns\")\n\n    fig, ax = plt.subplots()\n    ax.bar(df.iloc[:, 0], df.iloc[:, 1])\n    plt.tight_layout()\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/461", "solution": "import subprocess\nimport psutil\nimport time\nimport os\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.exists(script_path):\n        raise FileNotFoundError(f\"Script path {script_path} does not exist.\")\n\n    start_time = time.time()\n    process = subprocess.Popen(['python', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    cpu_usage = 0\n    memory_usage = 0\n\n    while time.time() - start_time <= timeout:\n        if process.poll() is not None:\n            break\n\n        for proc in psutil.process_iter(['pid', 'cpu_percent', 'memory_info']):\n            if proc.info['pid'] == process.pid:\n                cpu_usage += proc.info['cpu_percent']\n                memory_usage += proc.info['memory_info'].rss\n                break\n\n        time.sleep(0.1)\n\n    process.terminate()\n\n    return {'CPU Usage': cpu_usage, 'Memory Usage': memory_usage}", "raw_solution": "import subprocess\nimport psutil\nimport time\nimport os\n\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.exists(script_path):\n        raise FileNotFoundError(f\"Script path {script_path} does not exist.\")\n\n    start_time = time.time()\n    process = subprocess.Popen(['python', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    cpu_usage = 0\n    memory_usage = 0\n\n    while time.time() - start_time <= timeout:\n        if process.poll() is not None:\n            break\n\n        for proc in psutil.process_iter(['pid', 'cpu_percent', 'memory_info']):\n            if proc.info['pid'] == process.pid:\n                cpu_usage += proc.info['cpu_percent']\n                memory_usage += proc.info['memory_info'].rss\n                break\n\n        time.sleep(0.1)\n\n    process.terminate()\n\n    return {'CPU Usage': cpu_usage, 'Memory Usage': memory_usage}"}
{"task_id": "BigCodeBench/462", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport random\ndef task_func(num_rows=100, categories=[\"a\", \"b\", \"c\", \"d\", \"e\"], random_seed=42):\n    if num_rows < 1:\n        raise ValueError(\"num_rows must be greater than 0\")\n    random.seed(random_seed)\n    df = pd.DataFrame({\n        \"Category\": [random.choice(categories) for _ in range(num_rows)],\n        \"Value\": [random.randint(1, 100) for _ in range(num_rows)]\n    })\n    counts = df[\"Category\"].value_counts()\n    fig, ax = plt.subplots()\n    counts.plot(kind=\"bar\", ax=ax)\n    ax.set_title(\"Category Counts\")\n    return df, ax.figure", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport random\n\ndef task_func(num_rows=100, categories=[\"a\", \"b\", \"c\", \"d\", \"e\"], random_seed=42):\n    if num_rows < 1:\n        raise ValueError(\"num_rows must be greater than 0\")\n    random.seed(random_seed)\n    df = pd.DataFrame({\n        \"Category\": [random.choice(categories) for _ in range(num_rows)],\n        \"Value\": [random.randint(1, 100) for _ in range(num_rows)]\n    })\n    counts = df[\"Category\"].value_counts()\n    fig, ax = plt.subplots()\n    counts.plot(kind=\"bar\", ax=ax)\n    ax.set_title(\"Category Counts\")\n    return df, ax.figure\n```"}
{"task_id": "BigCodeBench/463", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data_str, separator=\",\", bins=20):\n    if not data_str:\n        raise ValueError(\"Data is empty\")\n    try:\n        data = pd.Series(data_str.split(separator)).astype(int)\n    except ValueError:\n        raise ValueError(\"Failed to convert data\")\n\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=bins, grid=True, rwidth=0.9, color='#607c8e')\n    plt.show()\n\n    return data, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data_str, separator=\",\", bins=20):\n    if not data_str:\n        raise ValueError(\"Data is empty\")\n    try:\n        data = pd.Series(data_str.split(separator)).astype(int)\n    except ValueError:\n        raise ValueError(\"Failed to convert data\")\n\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=bins, grid=True, rwidth=0.9, color='#607c8e')\n    plt.show()\n\n    return data, ax\n```"}
{"task_id": "BigCodeBench/464", "solution": "import json\nfrom datetime import datetime\nfrom decimal import Decimal\nclass CustomEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        elif isinstance(obj, Decimal):\n            return str(obj)\n        return super().default(obj)\ndef task_func(my_obj):\n    return json.dumps(my_obj, cls=CustomEncoder)", "raw_solution": "import json\nfrom datetime import datetime\nfrom decimal import Decimal\n\nclass CustomEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        elif isinstance(obj, Decimal):\n            return str(obj)\n        return super().default(obj)\n\ndef task_func(my_obj):\n    return json.dumps(my_obj, cls=CustomEncoder)\n```"}
{"task_id": "BigCodeBench/465", "solution": "import json\nfrom datetime import datetime\nimport numpy as np\nfrom decimal import Decimal\nclass CustomEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        elif isinstance(obj, Decimal):\n            return str(obj)\n        else:\n            raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\ndef task_func(my_obj):\n    return json.dumps(my_obj, cls=CustomEncoder)", "raw_solution": "import json\nfrom datetime import datetime\nimport numpy as np\nfrom decimal import Decimal\n\nclass CustomEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        elif isinstance(obj, Decimal):\n            return str(obj)\n        else:\n            raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n\ndef task_func(my_obj):\n    return json.dumps(my_obj, cls=CustomEncoder)\n```"}
{"task_id": "BigCodeBench/466", "solution": "import json\nfrom enum import Enum\ndef task_func(my_obj):\n    class EnumEncoder(json.JSONEncoder):\n        def default(self, obj):\n            if isinstance(obj, Enum):\n                return obj.name\n            return super().default(obj)\n\n    return json.dumps(my_obj, cls=EnumEncoder)", "raw_solution": "import json\nfrom enum import Enum\n\nclass Color(Enum):\n    RED = 1\n    GREEN = 2\n    BLUE = 3\n\ndef task_func(my_obj):\n    class EnumEncoder(json.JSONEncoder):\n        def default(self, obj):\n            if isinstance(obj, Enum):\n                return obj.name\n            return super().default(obj)\n\n    return json.dumps(my_obj, cls=EnumEncoder)\n```"}
{"task_id": "BigCodeBench/467", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(n, seed=0):\n    np.random.seed(seed)\n    points = [(np.random.rand(), np.random.rand()) for _ in range(n)]\n    fig, ax = plt.subplots()\n    ax.scatter([x for x, y in points], [y for x, y in points])\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_title('Scatter plot of random points')\n    return fig, points", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(n, seed=0):\n    np.random.seed(seed)\n    points = [(np.random.rand(), np.random.rand()) for _ in range(n)]\n    fig, ax = plt.subplots()\n    ax.scatter([x for x, y in points], [y for x, y in points])\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_title('Scatter plot of random points')\n    return fig, points\n```"}
{"task_id": "BigCodeBench/468", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(file_path=\"data.csv\", columns=[\"A\", \"B\", \"C\"]):\n    df = pd.read_csv(file_path)\n    df = df[columns]\n    df = df.astype(float)\n    ax = df.plot(kind='line')\n    cube_root = np.cbrt(df)\n    return df, ax, cube_root", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(file_path=\"data.csv\", columns=[\"A\", \"B\", \"C\"]):\n    df = pd.read_csv(file_path)\n    df = df[columns]\n    df = df.astype(float)\n    ax = df.plot(kind='line')\n    cube_root = np.cbrt(df)\n    return df, ax, cube_root\n```"}
{"task_id": "BigCodeBench/469", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\ndef task_func(student_grades, possible_grades=[\"A\", \"B\", \"C\", \"D\", \"F\"]):\n    # Convert grades to uppercase and remove whitespace\n    student_grades = [grade.strip().upper() for grade in student_grades]\n\n    # Filter grades that are in possible grades\n    student_grades = [grade for grade in student_grades if grade in possible_grades]\n\n    # Count the frequency of each grade\n    grade_counts = Counter(student_grades)\n\n    # Create a DataFrame with the grade counts\n    df = pd.DataFrame(list(grade_counts.items()), columns=[\"Grade\", \"Count\"])\n    df.set_index(\"Grade\", inplace=True)\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    df.plot(kind=\"bar\", ax=ax)\n    ax.set_xlabel(\"Grade\")\n    ax.set_ylabel(\"Number of Students\")\n    ax.set_title(\"Grade Distribution\")\n\n    return df, ax.figure", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\ndef task_func(student_grades, possible_grades=[\"A\", \"B\", \"C\", \"D\", \"F\"]):\n    # Convert grades to uppercase and remove whitespace\n    student_grades = [grade.strip().upper() for grade in student_grades]\n\n    # Filter grades that are in possible grades\n    student_grades = [grade for grade in student_grades if grade in possible_grades]\n\n    # Count the frequency of each grade\n    grade_counts = Counter(student_grades)\n\n    # Create a DataFrame with the grade counts\n    df = pd.DataFrame(list(grade_counts.items()), columns=[\"Grade\", \"Count\"])\n    df.set_index(\"Grade\", inplace=True)\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    df.plot(kind=\"bar\", ax=ax)\n    ax.set_xlabel(\"Grade\")\n    ax.set_ylabel(\"Number of Students\")\n    ax.set_title(\"Grade Distribution\")\n\n    return df, ax.figure"}
{"task_id": "BigCodeBench/470", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(myList):\n    # Create a histogram of the values in myList\n    fig, ax = plt.subplots()\n    ax.hist(myList, bins=np.arange(min(myList), max(myList) + 2), edgecolor='black')\n\n    # Set the labels and title\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Values')\n\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(myList):\n    # Create a histogram of the values in myList\n    fig, ax = plt.subplots()\n    ax.hist(myList, bins=np.arange(min(myList), max(myList) + 2), edgecolor='black')\n\n    # Set the labels and title\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Values')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/471", "solution": "from collections import Counter\nimport pandas as pd\ndef task_func(myList):\n    word_counts = Counter(myList)\n    df = pd.DataFrame(list(word_counts.items()), columns=['Word', 'Count'])\n    return df", "raw_solution": "from collections import Counter\nimport pandas as pd\ndef task_func(myList):\n    word_counts = Counter(myList)\n    df = pd.DataFrame(list(word_counts.items()), columns=['Word', 'Count'])\n    return df\n```"}
{"task_id": "BigCodeBench/472", "solution": "import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\ndef task_func(myList, n_clusters):\n    if not isinstance(myList, list) or not all(isinstance(i, list) and len(i) == 2 for i in myList):\n        raise ValueError(\"Invalid input: myList should be a list of 2D points\")\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"Invalid input: n_clusters should be a positive integer\")\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n    kmeans.fit(myList)\n\n    plt.scatter([i[0] for i in myList], [i[1] for i in myList], c=kmeans.labels_)\n    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='x', color='red')\n    plt.show()\n\n    return plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\ndef task_func(myList, n_clusters):\n    if not isinstance(myList, list) or not all(isinstance(i, list) and len(i) == 2 for i in myList):\n        raise ValueError(\"Invalid input: myList should be a list of 2D points\")\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"Invalid input: n_clusters should be a positive integer\")\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n    kmeans.fit(myList)\n\n    plt.scatter([i[0] for i in myList], [i[1] for i in myList], c=kmeans.labels_)\n    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='x', color='red')\n    plt.show()\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/473", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\ndef task_func(n_walks, n_steps, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    steps = np.random.choice([-1, 1], size=(n_walks, n_steps))\n    positions = steps.cumsum(axis=1)\n    colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n    fig, ax = plt.subplots()\n    for walk, color in zip(positions, colors):\n        ax.plot(walk, color=color)\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef task_func(n_walks, n_steps, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    steps = np.random.choice([-1, 1], size=(n_walks, n_steps))\n    positions = steps.cumsum(axis=1)\n    colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n    fig, ax = plt.subplots()\n    for walk, color in zip(positions, colors):\n        ax.plot(walk, color=color)\n    return ax\n```"}
{"task_id": "BigCodeBench/474", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(n_samples=1000, mu=0, sigma=1, random_seed=0):\n    np.random.seed(random_seed)\n    samples = np.random.normal(mu, sigma, n_samples)\n\n    fig, ax = plt.subplots(figsize=(10, 6))\n\n    ax.hist(samples, bins=30, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n\n    x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)\n    ax.plot(x, norm.pdf(x, mu, sigma), color='red', linewidth=2)\n\n    ax.set_title(f'Histogram and PDF of Normal Distribution (mu={mu}, sigma={sigma})')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return ax, samples", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(n_samples=1000, mu=0, sigma=1, random_seed=0):\n    np.random.seed(random_seed)\n    samples = np.random.normal(mu, sigma, n_samples)\n\n    fig, ax = plt.subplots(figsize=(10, 6))\n\n    ax.hist(samples, bins=30, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n\n    x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)\n    ax.plot(x, norm.pdf(x, mu, sigma), color='red', linewidth=2)\n\n    ax.set_title(f'Histogram and PDF of Normal Distribution (mu={mu}, sigma={sigma})')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return ax, samples\n```"}
{"task_id": "BigCodeBench/475", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\ndef task_func(data, date_format, country, country_codes=None):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' must be a pandas DataFrame\")\n    if not isinstance(date_format, str):\n        raise ValueError(\"'date_format' must be a string\")\n    if country not in country_codes:\n        raise ValueError(\"'country' must be in 'country_codes'\")\n    if not isinstance(country_codes, dict):\n        raise ValueError(\"'country_codes' must be a dictionary\")\n\n    data['date'] = pd.to_datetime(data['date'], format=date_format)\n    data = data[data['country'] == country]\n\n    ax = data['date'].hist(bins=30)\n    ax.set_title('Date Distribution')\n    ax.set_ylabel('Frequency')\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\ndef task_func(data, date_format, country, country_codes=None):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' must be a pandas DataFrame\")\n    if not isinstance(date_format, str):\n        raise ValueError(\"'date_format' must be a string\")\n    if country not in country_codes:\n        raise ValueError(\"'country' must be in 'country_codes'\")\n    if not isinstance(country_codes, dict):\n        raise ValueError(\"'country_codes' must be a dictionary\")\n\n    data['date'] = pd.to_datetime(data['date'], format=date_format)\n    data = data[data['country'] == country]\n\n    ax = data['date'].hist(bins=30)\n    ax.set_title('Date Distribution')\n    ax.set_ylabel('Frequency')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/476", "solution": "import matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\ndef task_func(X, Y):\n    def quad_func(x, a, b, c):\n        return a * x**2 + b * x + c\n\n    popt, _ = curve_fit(quad_func, X, Y)\n\n    fig, ax = plt.subplots()\n    ax.scatter(X, Y, color='red')\n    ax.plot(X, quad_func(X, *popt), color='blue')\n\n    return popt, ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n\ndef task_func(X, Y):\n    def quad_func(x, a, b, c):\n        return a * x**2 + b * x + c\n\n    popt, _ = curve_fit(quad_func, X, Y)\n\n    fig, ax = plt.subplots()\n    ax.scatter(X, Y, color='red')\n    ax.plot(X, quad_func(X, *popt), color='blue')\n\n    return popt, ax\n```"}
{"task_id": "BigCodeBench/477", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n    df = pd.DataFrame({\n        \"x\": np.random.rand(N),\n        \"y\": np.random.rand(N),\n        \"category\": np.random.choice(CATEGORIES, N, replace=True if N >= len(CATEGORIES) else False)\n    })\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(df[\"x\"], df[\"y\"], c=df[\"category\"])\n    plt.show()\n    return df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n    df = pd.DataFrame({\n        \"x\": np.random.rand(N),\n        \"y\": np.random.rand(N),\n        \"category\": np.random.choice(CATEGORIES, N, replace=True if N >= len(CATEGORIES) else False)\n    })\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(df[\"x\"], df[\"y\"], c=df[\"category\"])\n    plt.show()\n    return df, ax\n```"}
{"task_id": "BigCodeBench/478", "solution": "import pandas as pd\nimport re\nimport random\ndef task_func(data_list, seed=None):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        if ',' in data:\n            substring = random.choice(data.split(','))\n            modified_data = data.replace(substring, '')\n            result.append({'Original String': data, 'Modified String': modified_data})\n        else:\n            result.append({'Original String': data, 'Modified String': data})\n    return pd.DataFrame(result)", "raw_solution": "import pandas as pd\nimport re\nimport random\n\ndef task_func(data_list, seed=None):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        if ',' in data:\n            substring = random.choice(data.split(','))\n            modified_data = data.replace(substring, '')\n            result.append({'Original String': data, 'Modified String': modified_data})\n        else:\n            result.append({'Original String': data, 'Modified String': data})\n    return pd.DataFrame(result)\n```"}
{"task_id": "BigCodeBench/479", "solution": "import random\nimport string\nimport pandas as pd\ndef task_func(data_list, seed=0):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        if len(data) == 0:\n            result.append((data, data))\n            continue\n        start = random.randint(0, len(data) - 1)\n        end = random.randint(start, len(data))\n        substring = data[start:end]\n        replacement = ''.join(random.choices(string.ascii_lowercase, k=len(substring)))\n        modified_data = data[:start] + replacement + data[end:]\n        result.append((data, modified_data))\n    df = pd.DataFrame(result, columns=['Original String', 'Modified String'])\n    return df", "raw_solution": "import random\nimport string\nimport pandas as pd\n\ndef task_func(data_list, seed=0):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        if len(data) == 0:\n            result.append((data, data))\n            continue\n        start = random.randint(0, len(data) - 1)\n        end = random.randint(start, len(data))\n        substring = data[start:end]\n        replacement = ''.join(random.choices(string.ascii_lowercase, k=len(substring)))\n        modified_data = data[:start] + replacement + data[end:]\n        result.append((data, modified_data))\n    df = pd.DataFrame(result, columns=['Original String', 'Modified String'])\n    return df\n```"}
{"task_id": "BigCodeBench/480", "solution": "import re\nimport random\nimport pandas as pd\ndef task_func(data_list, seed=None):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        words = re.split(',', data)\n        words = [word.strip() for word in words]\n        random.shuffle(words)\n        result.append((data, ','.join(words)))\n    return pd.DataFrame(result, columns=['Original String', 'Shuffled String'])", "raw_solution": "import re\nimport random\nimport pandas as pd\n\ndef task_func(data_list, seed=None):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        words = re.split(',', data)\n        words = [word.strip() for word in words]\n        random.shuffle(words)\n        result.append((data, ','.join(words)))\n    return pd.DataFrame(result, columns=['Original String', 'Shuffled String'])\n```"}
{"task_id": "BigCodeBench/481", "solution": "import pandas as pd\nimport random\nimport re\ndef task_func(data_list, seed=42):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        words = data.split(',')\n        random.shuffle(words)\n        randomized_data = ' '.join(words).strip()\n        result.append({'Original String': data, 'Randomized String': randomized_data})\n    return pd.DataFrame(result)", "raw_solution": "import pandas as pd\nimport random\nimport re\n\ndef task_func(data_list, seed=42):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        words = data.split(',')\n        random.shuffle(words)\n        randomized_data = ' '.join(words).strip()\n        result.append({'Original String': data, 'Randomized String': randomized_data})\n    return pd.DataFrame(result)\n```"}
{"task_id": "BigCodeBench/482", "solution": "import pandas as pd\nimport random\nimport re\ndef task_func(data_list, seed=None):\n    random.seed(seed)\n    operations = ['remove', 'replace', 'shuffle', 'randomize']\n    df = pd.DataFrame(data_list, columns=['Original String'])\n    df['Modified String'] = df['Original String'].apply(lambda x: x.strip())\n    df['Modified String'] = df['Modified String'].apply(lambda x: x.split(','))\n    df['Modified String'] = df['Modified String'].apply(lambda x: [i.strip() for i in x])\n    df['Operation'] = df['Modified String'].apply(lambda x: random.choice(operations) if len(x) > 1 else '')\n    df['Substring'] = df['Modified String'].apply(lambda x: random.choice(x) if len(x) > 1 else '')\n    df['Modified String'] = df.apply(lambda row: row['Modified String'] if row['Operation'] == '' else modify_string(row['Modified String'], row['Operation'], row['Substring']), axis=1)\n    df['Modified String'] = df['Modified String'].apply(lambda x: ','.join(x))\n    return df\ndef modify_string(string_list, operation, substring):\n    if operation == 'remove':\n        string_list.remove(substring)\n    elif operation == 'replace':\n        index = string_list.index(substring)\n        string_list[index] = 'random_string'\n    elif operation == 'shuffle':\n        random.shuffle(string_list)\n    elif operation == 'randomize':\n        random.shuffle(string_list)\n    return string_list", "raw_solution": "import pandas as pd\nimport random\nimport re\n\ndef task_func(data_list, seed=None):\n    random.seed(seed)\n    operations = ['remove', 'replace', 'shuffle', 'randomize']\n    df = pd.DataFrame(data_list, columns=['Original String'])\n    df['Modified String'] = df['Original String'].apply(lambda x: x.strip())\n    df['Modified String'] = df['Modified String'].apply(lambda x: x.split(','))\n    df['Modified String'] = df['Modified String'].apply(lambda x: [i.strip() for i in x])\n    df['Operation'] = df['Modified String'].apply(lambda x: random.choice(operations) if len(x) > 1 else '')\n    df['Substring'] = df['Modified String'].apply(lambda x: random.choice(x) if len(x) > 1 else '')\n    df['Modified String'] = df.apply(lambda row: row['Modified String'] if row['Operation'] == '' else modify_string(row['Modified String'], row['Operation'], row['Substring']), axis=1)\n    df['Modified String'] = df['Modified String'].apply(lambda x: ','.join(x))\n    return df\n\ndef modify_string(string_list, operation, substring):\n    if operation == 'remove':\n        string_list.remove(substring)\n    elif operation == 'replace':\n        index = string_list.index(substring)\n        string_list[index] = 'random_string'\n    elif operation == 'shuffle':\n        random.shuffle(string_list)\n    elif operation == 'randomize':\n        random.shuffle(string_list)\n    return string_list\n```"}
{"task_id": "BigCodeBench/483", "solution": "import re\nimport pandas as pd\ndef task_func(df: pd.DataFrame, column_name: str, pattern: str) -> pd.DataFrame:\n    if pattern == \"\":\n        return df.copy()\n    def reverse_words(word_list):\n        matched_words = [word for word in word_list if re.match(pattern, word)]\n        matched_words.reverse()\n        for i, word in enumerate(word_list):\n            if not re.match(pattern, word):\n                matched_words.insert(i, word)\n        return matched_words\n    df[column_name] = df[column_name].apply(lambda x: reverse_words(x.split()))\n    return df", "raw_solution": "import re\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame, column_name: str, pattern: str) -> pd.DataFrame:\n    if pattern == \"\":\n        return df.copy()\n    def reverse_words(word_list):\n        matched_words = [word for word in word_list if re.match(pattern, word)]\n        matched_words.reverse()\n        for i, word in enumerate(word_list):\n            if not re.match(pattern, word):\n                matched_words.insert(i, word)\n        return matched_words\n    df[column_name] = df[column_name].apply(lambda x: reverse_words(x.split()))\n    return df\n```"}
{"task_id": "BigCodeBench/484", "solution": "import math\nimport numpy as np\nfrom datetime import datetime\nimport pandas as pd\ndef task_func(\n    start_time,\n    end_time,\n    step,\n    columns=[\"Timestamp\", \"Sensor1\", \"Sensor2\", \"Sensor3\", \"SensorStatus\"],\n    sensor_statuses=[\"OK\", \"MAINTENANCE_REQUIRED\", \"ERROR\"],\n    random_seed=42,\n):\n    np.random.seed(random_seed)\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    timestamps = pd.date_range(start=start_time, end=end_time, freq=step)\n    data = {\n        columns[0]: timestamps,\n        columns[1]: np.sin(timestamps.view(int) / 1000) + np.random.normal(0, 0.1, len(timestamps)),\n        columns[2]: np.cos(timestamps.view(int) / 1000) + np.random.normal(0, 0.1, len(timestamps)),\n        columns[3]: np.tan(timestamps.view(int) / 1000) + np.random.normal(0, 0.1, len(timestamps)),\n        columns[4]: np.random.choice(sensor_statuses, len(timestamps)),\n    }\n    return pd.DataFrame(data)", "raw_solution": "import math\nimport numpy as np\nfrom datetime import datetime\nimport pandas as pd\n\ndef task_func(\n    start_time,\n    end_time,\n    step,\n    columns=[\"Timestamp\", \"Sensor1\", \"Sensor2\", \"Sensor3\", \"SensorStatus\"],\n    sensor_statuses=[\"OK\", \"MAINTENANCE_REQUIRED\", \"ERROR\"],\n    random_seed=42,\n):\n    np.random.seed(random_seed)\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    timestamps = pd.date_range(start=start_time, end=end_time, freq=step)\n    data = {\n        columns[0]: timestamps,\n        columns[1]: np.sin(timestamps.view(int) / 1000) + np.random.normal(0, 0.1, len(timestamps)),\n        columns[2]: np.cos(timestamps.view(int) / 1000) + np.random.normal(0, 0.1, len(timestamps)),\n        columns[3]: np.tan(timestamps.view(int) / 1000) + np.random.normal(0, 0.1, len(timestamps)),\n        columns[4]: np.random.choice(sensor_statuses, len(timestamps)),\n    }\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/485", "solution": "from datetime import datetime, timedelta\nimport pytz\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_time, end_time):\n    # Define the time zones\n    time_zones = [\"UTC\", \"America/Los_Angeles\", \"Europe/Paris\", \"Asia/Kolkata\", \"Australia/Sydney\"]\n    colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\n\n    # Convert the start and end times to datetime objects\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d\")\n\n    # Calculate the number of days between the start and end times\n    num_days = (end_time - start_time).days + 1\n\n    # Create a list to store the time differences for each day\n    time_diffs = []\n\n    # Loop through each day in the date range\n    for i in range(num_days):\n        # Calculate the current date\n        current_date = start_time + timedelta(days=i)\n\n        # Calculate the time difference for each time zone\n        time_diff = []\n        for time_zone in time_zones:\n            tz = pytz.timezone(time_zone)\n            current_time = current_date.replace(tzinfo=pytz.utc)\n            time_diff.append(current_time.astimezone(tz).hour - current_time.hour)\n        time_diffs.append(time_diff)\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot the time differences for each day\n    for i, time_diff in enumerate(time_diffs):\n        ax.plot(time_diff, color=colors[i % len(colors)], label=f\"Day {i+1}\")\n\n    # Set the x-axis label and tick labels\n    ax.set_xlabel(\"Time Zone\")\n    ax.set_xticks(np.arange(len(time_zones)))\n    ax.set_xticklabels(time_zones)\n\n    # Set the y-axis label\n    ax.set_ylabel(\"Time Difference (hours)\")\n\n    # Set the title\n    ax.set_title(\"Time Difference Between UTC and Other Time Zones\")\n\n    # Show the legend\n    ax.legend()\n\n    return ax", "raw_solution": "from datetime import datetime, timedelta\nimport pytz\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_time, end_time):\n    # Define the time zones\n    time_zones = [\"UTC\", \"America/Los_Angeles\", \"Europe/Paris\", \"Asia/Kolkata\", \"Australia/Sydney\"]\n    colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\n\n    # Convert the start and end times to datetime objects\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d\")\n\n    # Calculate the number of days between the start and end times\n    num_days = (end_time - start_time).days + 1\n\n    # Create a list to store the time differences for each day\n    time_diffs = []\n\n    # Loop through each day in the date range\n    for i in range(num_days):\n        # Calculate the current date\n        current_date = start_time + timedelta(days=i)\n\n        # Calculate the time difference for each time zone\n        time_diff = []\n        for time_zone in time_zones:\n            tz = pytz.timezone(time_zone)\n            current_time = current_date.replace(tzinfo=pytz.utc)\n            time_diff.append(current_time.astimezone(tz).hour - current_time.hour)\n        time_diffs.append(time_diff)\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot the time differences for each day\n    for i, time_diff in enumerate(time_diffs):\n        ax.plot(time_diff, color=colors[i % len(colors)], label=f\"Day {i+1}\")\n\n    # Set the x-axis label and tick labels\n    ax.set_xlabel(\"Time Zone\")\n    ax.set_xticks(np.arange(len(time_zones)))\n    ax.set_xticklabels(time_zones)\n\n    # Set the y-axis label\n    ax.set_ylabel(\"Time Difference (hours)\")\n\n    # Set the title\n    ax.set_title(\"Time Difference Between UTC and Other Time Zones\")\n\n    # Show the legend\n    ax.legend()\n\n    return ax\n```"}
{"task_id": "BigCodeBench/486", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    time_range = pd.date_range(start=start_time, end=end_time, freq=step)\n    values = np.random.normal(0, 1, len(time_range)) + trend * np.arange(len(time_range))\n    df = pd.DataFrame({'Time': time_range, 'Value': values})\n    fig, ax = plt.subplots()\n    ax.plot(df['Time'], df['Value'])\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n    return ax", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    time_range = pd.date_range(start=start_time, end=end_time, freq=step)\n    values = np.random.normal(0, 1, len(time_range)) + trend * np.arange(len(time_range))\n    df = pd.DataFrame({'Time': time_range, 'Value': values})\n    fig, ax = plt.subplots()\n    ax.plot(df['Time'], df['Value'])\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n    return ax\n```"}
{"task_id": "BigCodeBench/487", "solution": "import os\nimport pandas as pd\nimport re\ndef task_func(file_path: str) -> pd.DataFrame:\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n\n    pattern = r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{6}) - (\\w+) - (.+)\"\n    data = []\n\n    with open(file_path, \"r\") as file:\n        for line in file:\n            match = re.match(pattern, line.strip())\n            if match:\n                data.append({\n                    \"Timestamp\": match.group(1),\n                    \"Level\": match.group(2),\n                    \"Message\": match.group(3)\n                })\n\n    if not data:\n        return pd.DataFrame(columns=[\"Timestamp\", \"Level\", \"Message\"])\n\n    return pd.DataFrame(data)", "raw_solution": "import os\nimport pandas as pd\nimport re\n\ndef task_func(file_path: str) -> pd.DataFrame:\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n\n    pattern = r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{6}) - (\\w+) - (.+)\"\n    data = []\n\n    with open(file_path, \"r\") as file:\n        for line in file:\n            match = re.match(pattern, line.strip())\n            if match:\n                data.append({\n                    \"Timestamp\": match.group(1),\n                    \"Level\": match.group(2),\n                    \"Message\": match.group(3)\n                })\n\n    if not data:\n        return pd.DataFrame(columns=[\"Timestamp\", \"Level\", \"Message\"])\n\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/488", "solution": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_time, end_time, step, amplitude, period, seed=0):\n    np.random.seed(seed)\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    dates = pd.date_range(start=start_time, end=end_time, freq=step)\n    values = amplitude * np.sin(2 * np.pi * (dates - start_time).total_seconds() / period)\n    df = pd.DataFrame({\"Timestamp\": dates, \"Value\": values})\n    ax = df.plot(x=\"Timestamp\", y=\"Value\", kind=\"line\")\n    plt.title(\"Time Series with Seasonality\")\n    plt.xlabel(\"Timestamp\")\n    plt.ylabel(\"Value\")\n    return ax", "raw_solution": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_time, end_time, step, amplitude, period, seed=0):\n    np.random.seed(seed)\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    dates = pd.date_range(start=start_time, end=end_time, freq=step)\n    values = amplitude * np.sin(2 * np.pi * (dates - start_time).total_seconds() / period)\n    df = pd.DataFrame({\"Timestamp\": dates, \"Value\": values})\n    ax = df.plot(x=\"Timestamp\", y=\"Value\", kind=\"line\")\n    plt.title(\"Time Series with Seasonality\")\n    plt.xlabel(\"Timestamp\")\n    plt.ylabel(\"Value\")\n    return ax\n```"}
{"task_id": "BigCodeBench/489", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\ndef task_func(epoch_milliseconds, seed=0):\n    random.seed(seed)\n    users = ['user1', 'user2', 'user3', 'user4', 'user5']\n    activities = ['login', 'logout', 'browse', 'search', 'purchase']\n    current_time = datetime.now()\n    start_time = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    if start_time > current_time:\n        raise ValueError(\"Start time is after the current system time.\")\n    logs = []\n    current_time = start_time\n    while current_time <= datetime.now():\n        user = random.choice(users)\n        activity = random.choice(activities)\n        time = current_time.strftime('%Y-%m-%d %H:%M:%S')\n        logs.append({'User': user, 'Activity': activity, 'Time': time})\n        current_time += timedelta(seconds=random.randint(1, 10))\n    return pd.DataFrame(logs)", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\n\ndef task_func(epoch_milliseconds, seed=0):\n    random.seed(seed)\n    users = ['user1', 'user2', 'user3', 'user4', 'user5']\n    activities = ['login', 'logout', 'browse', 'search', 'purchase']\n    current_time = datetime.now()\n    start_time = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    if start_time > current_time:\n        raise ValueError(\"Start time is after the current system time.\")\n    logs = []\n    current_time = start_time\n    while current_time <= datetime.now():\n        user = random.choice(users)\n        activity = random.choice(activities)\n        time = current_time.strftime('%Y-%m-%d %H:%M:%S')\n        logs.append({'User': user, 'Activity': activity, 'Time': time})\n        current_time += timedelta(seconds=random.randint(1, 10))\n    return pd.DataFrame(logs)\n```"}
{"task_id": "BigCodeBench/490", "solution": "import xmltodict\nimport json\ndef task_func(s, file_path):\n    dict = xmltodict.parse(s)\n    with open(file_path, 'w') as f:\n        json.dump(dict, f)\n    return dict", "raw_solution": "import xmltodict\nimport json\n\ndef task_func(s, file_path):\n    dict = xmltodict.parse(s)\n    with open(file_path, 'w') as f:\n        json.dump(dict, f)\n    return dict\n```"}
{"task_id": "BigCodeBench/491", "solution": "import random\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\ndef task_func(epoch_milliseconds, seed=None):\n    if epoch_milliseconds < 0 or epoch_milliseconds > int(datetime.now().timestamp() * 1000):\n        raise ValueError(\"Invalid start time\")\n\n    random.seed(seed)\n\n    start_time = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    end_time = datetime.now()\n\n    days = (end_time - start_time).days\n    sales_data = {}\n\n    for day in range(days):\n        date = start_time + timedelta(days=day)\n        sales_data[date.strftime(\"%Y-%m-%d\")] = {\n            \"Electronics\": random.randint(10, 50),\n            \"Clothing\": random.randint(10, 50),\n            \"Home\": random.randint(10, 50),\n            \"Books\": random.randint(10, 50),\n            \"Sports\": random.randint(10, 50),\n        }\n\n    fig, ax = plt.subplots()\n\n    for category in sales_data[list(sales_data.keys())[0]].keys():\n        ax.plot([date.strftime(\"%Y-%m-%d\") for date in sales_data.keys()], [data[category] for data in sales_data.values()], label=category)\n\n    ax.set_xlabel(\"Days since start date\")\n    ax.set_ylabel(\"Sales units\")\n    ax.legend()\n\n    return sales_data, ax", "raw_solution": "import random\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\n\ndef task_func(epoch_milliseconds, seed=None):\n    if epoch_milliseconds < 0 or epoch_milliseconds > int(datetime.now().timestamp() * 1000):\n        raise ValueError(\"Invalid start time\")\n\n    random.seed(seed)\n\n    start_time = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    end_time = datetime.now()\n\n    days = (end_time - start_time).days\n    sales_data = {}\n\n    for day in range(days):\n        date = start_time + timedelta(days=day)\n        sales_data[date.strftime(\"%Y-%m-%d\")] = {\n            \"Electronics\": random.randint(10, 50),\n            \"Clothing\": random.randint(10, 50),\n            \"Home\": random.randint(10, 50),\n            \"Books\": random.randint(10, 50),\n            \"Sports\": random.randint(10, 50),\n        }\n\n    fig, ax = plt.subplots()\n\n    for category in sales_data[list(sales_data.keys())[0]].keys():\n        ax.plot([date.strftime(\"%Y-%m-%d\") for date in sales_data.keys()], [data[category] for data in sales_data.values()], label=category)\n\n    ax.set_xlabel(\"Days since start date\")\n    ax.set_ylabel(\"Sales units\")\n    ax.legend()\n\n    return sales_data, ax\n```"}
{"task_id": "BigCodeBench/492", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    if not isinstance(epoch_milliseconds, int) or not isinstance(random_seed, int) or not isinstance(products, list):\n        raise ValueError(\"Invalid input type\")\n    if len(products) != 5:\n        raise ValueError(\"Invalid number of products\")\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    end_date = datetime.now()\n    date_range = (end_date - start_date).days\n    data = []\n    for i in range(date_range):\n        date = start_date + timedelta(days=i)\n        for product in products:\n            sales = random.randint(10, 50)\n            data.append([product, date, sales])\n    df = pd.DataFrame(data, columns=[\"Product\", \"Date\", \"Sales\"])\n    return df", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\n\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    if not isinstance(epoch_milliseconds, int) or not isinstance(random_seed, int) or not isinstance(products, list):\n        raise ValueError(\"Invalid input type\")\n    if len(products) != 5:\n        raise ValueError(\"Invalid number of products\")\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    end_date = datetime.now()\n    date_range = (end_date - start_date).days\n    data = []\n    for i in range(date_range):\n        date = start_date + timedelta(days=i)\n        for product in products:\n            sales = random.randint(10, 50)\n            data.append([product, date, sales])\n    df = pd.DataFrame(data, columns=[\"Product\", \"Date\", \"Sales\"])\n    return df\n```"}
{"task_id": "BigCodeBench/493", "solution": "from datetime import datetime, timedelta\nimport random\nimport matplotlib.pyplot as plt\ndef task_func(\n    epoch_milliseconds,\n    teams=[\"Team1\", \"Team2\", \"Team3\", \"Team4\", \"Team5\"],\n    random_seed=0,\n):\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    current_date = datetime.now()\n    days = (current_date - start_date).days\n    performance_data = {}\n    for team in teams:\n        performance_data[team] = [random.uniform(0.1, 1) for _ in range(days)]\n    fig, ax = plt.subplots()\n    for team, performance in performance_data.items():\n        ax.plot(range(days), performance, label=team)\n    ax.set_xlabel('Days')\n    ax.set_ylabel('Performance')\n    ax.legend()\n    return performance_data, fig", "raw_solution": "from datetime import datetime, timedelta\nimport random\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    epoch_milliseconds,\n    teams=[\"Team1\", \"Team2\", \"Team3\", \"Team4\", \"Team5\"],\n    random_seed=0,\n):\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    current_date = datetime.now()\n    days = (current_date - start_date).days\n    performance_data = {}\n    for team in teams:\n        performance_data[team] = [random.uniform(0.1, 1) for _ in range(days)]\n    fig, ax = plt.subplots()\n    for team, performance in performance_data.items():\n        ax.plot(range(days), performance, label=team)\n    ax.set_xlabel('Days')\n    ax.set_ylabel('Performance')\n    ax.legend()\n    return performance_data, fig\n```"}
{"task_id": "BigCodeBench/494", "solution": "from datetime import datetime\nimport pytz\nimport re\nfrom faker import Faker\ndef task_func(epoch_milliseconds, seed=0, timezones=[\"UTC\"]):\n    faker = Faker()\n    faker.seed(seed)\n    event_schedule = {}\n    valid_timezones = pytz.all_timezones\n    valid_timezone_regex = re.compile(r'^UTC[+-]\\d{2}:\\d{2}$')\n    valid_timezones = [tz for tz in valid_timezones if valid_timezone_regex.match(tz)]\n    if not valid_timezones:\n        valid_timezones = [\"UTC\"]\n    for epoch in epoch_milliseconds:\n        event_time = datetime.fromtimestamp(epoch / 1000.0)\n        event_name = faker.word()\n        event_timezone = faker.random_element(valid_timezones)\n        event_schedule[event_name] = [{'date': event_time.date(), 'time': event_time.time(), 'timezone': event_timezone}]\n    return event_schedule", "raw_solution": "from datetime import datetime\nimport pytz\nimport re\nfrom faker import Faker\n\ndef task_func(epoch_milliseconds, seed=0, timezones=[\"UTC\"]):\n    faker = Faker()\n    faker.seed(seed)\n    event_schedule = {}\n    valid_timezones = pytz.all_timezones\n    valid_timezone_regex = re.compile(r'^UTC[+-]\\d{2}:\\d{2}$')\n    valid_timezones = [tz for tz in valid_timezones if valid_timezone_regex.match(tz)]\n    if not valid_timezones:\n        valid_timezones = [\"UTC\"]\n    for epoch in epoch_milliseconds:\n        event_time = datetime.fromtimestamp(epoch / 1000.0)\n        event_name = faker.word()\n        event_timezone = faker.random_element(valid_timezones)\n        event_schedule[event_name] = [{'date': event_time.date(), 'time': event_time.time(), 'timezone': event_timezone}]\n    return event_schedule\n```"}
{"task_id": "BigCodeBench/495", "solution": "import pandas as pd\nimport numpy as np", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef generate_spending_report(days, random_seed=0):\n    np.random.seed(random_seed)\n    date_range = pd.date_range(start='2023-01-01', periods=days)\n    data = {\n        'Groceries': np.random.randint(0, 101, size=days),\n        'Entertainment': np.random.randint(0, 101, size=days),\n        'Rent': np.random.randint(0, 101, size=days),\n        'Utilities': np.random.randint(0, 101, size=days),\n        'Miscellaneous': np.random.randint(0, 101, size=days)\n    }\n    df = pd.DataFrame(data, index=date_range)\n    return df\n```"}
{"task_id": "BigCodeBench/496", "solution": "from datetime import datetime, timedelta\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(days_in_past=7, random_seed=0):\n    if days_in_past < 1:\n        raise ValueError(\"days_in_past must be greater than 0\")\n    np.random.seed(random_seed)\n    temperatures = np.random.randint(15, 35, days_in_past)\n    dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days_in_past)]\n    fig, ax = plt.subplots()\n    ax.plot(dates, temperatures)\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Temperature (\u00b0C)')\n    ax.set_title('Temperature Trend')\n    return ax", "raw_solution": "from datetime import datetime, timedelta\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(days_in_past=7, random_seed=0):\n    if days_in_past < 1:\n        raise ValueError(\"days_in_past must be greater than 0\")\n    np.random.seed(random_seed)\n    temperatures = np.random.randint(15, 35, days_in_past)\n    dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days_in_past)]\n    fig, ax = plt.subplots()\n    ax.plot(dates, temperatures)\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Temperature (\u00b0C)')\n    ax.set_title('Temperature Trend')\n    return ax\n```"}
{"task_id": "BigCodeBench/497", "solution": "from datetime import datetime, timedelta\nimport pytz\nimport calendar\ndef task_func(days_in_past=7):\n    if days_in_past < 0:\n        raise ValueError(\"'days_in_past' cannot be negative\")\n    target_date = datetime.now(pytz.utc) - timedelta(days=days_in_past)\n    weekday = calendar.day_name[target_date.weekday()]\n    return weekday", "raw_solution": "from datetime import datetime, timedelta\nimport pytz\nimport calendar\n\ndef task_func(days_in_past=7):\n    if days_in_past < 0:\n        raise ValueError(\"'days_in_past' cannot be negative\")\n    target_date = datetime.now(pytz.utc) - timedelta(days=days_in_past)\n    weekday = calendar.day_name[target_date.weekday()]\n    return weekday\n```"}
{"task_id": "BigCodeBench/498", "solution": "import xmltodict\nimport json\ndef task_func(s, save_json=False, json_file_path=None):\n    if not s.strip():\n        raise ValueError(\"Input XML string is empty or contains only whitespace.\")\n    result = xmltodict.parse(s)\n    if save_json:\n        with open(json_file_path, 'w') as f:\n            json.dump(result, f)\n    return result", "raw_solution": "import xmltodict\nimport json\n\ndef task_func(s, save_json=False, json_file_path=None):\n    if not s.strip():\n        raise ValueError(\"Input XML string is empty or contains only whitespace.\")\n    result = xmltodict.parse(s)\n    if save_json:\n        with open(json_file_path, 'w') as f:\n            json.dump(result, f)\n    return result\n```"}
{"task_id": "BigCodeBench/499", "solution": "import xlwt\nimport os\nimport io\nimport csv\ndef task_func(csv_content, filename):\n    # Create a new workbook\n    workbook = xlwt.Workbook()\n    # Add a new sheet to the workbook\n    sheet = workbook.add_sheet('Sheet1')\n    # Write the CSV content into the first cell of the sheet\n    sheet.write(0, 0, csv_content)\n    # Save the workbook as an Excel file\n    workbook.save(filename)\n    # Return the absolute path of the created Excel file\n    return os.path.abspath(filename)", "raw_solution": "import xlwt\nimport os\nimport io\nimport csv\n\ndef task_func(csv_content, filename):\n    # Create a new workbook\n    workbook = xlwt.Workbook()\n    # Add a new sheet to the workbook\n    sheet = workbook.add_sheet('Sheet1')\n    # Write the CSV content into the first cell of the sheet\n    sheet.write(0, 0, csv_content)\n    # Save the workbook as an Excel file\n    workbook.save(filename)\n    # Return the absolute path of the created Excel file\n    return os.path.abspath(filename)\n```"}
{"task_id": "BigCodeBench/500", "solution": "import xlwt\nimport os\nFIELDS = ['ID', 'Name', 'Age']\ndef task_func(values, filename):\n    wb = xlwt.Workbook()\n    ws = wb.add_sheet('Sheet1')\n    for i, field in enumerate(FIELDS):\n        ws.write(0, i, field)\n    for i, value in enumerate(values, start=1):\n        for j, field in enumerate(FIELDS):\n            ws.write(i, j, value.get(field, ''))\n    wb.save(filename)\n    return os.path.abspath(filename)", "raw_solution": "import xlwt\nimport os\n# Constants\nFIELDS = ['ID', 'Name', 'Age']\ndef task_func(values, filename):\n    wb = xlwt.Workbook()\n    ws = wb.add_sheet('Sheet1')\n    for i, field in enumerate(FIELDS):\n        ws.write(0, i, field)\n    for i, value in enumerate(values, start=1):\n        for j, field in enumerate(FIELDS):\n            ws.write(i, j, value.get(field, ''))\n    wb.save(filename)\n    return os.path.abspath(filename)\n```"}
{"task_id": "BigCodeBench/501", "solution": "import xlwt\nimport os\nimport pandas as pd\nimport json\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    if not isinstance(json_str, (str, bytes, bytearray)):\n        raise TypeError(\"json_str must be a string, bytes, or bytearray\")\n    try:\n        data = json.loads(json_str)\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON\")\n    if not isinstance(data, list):\n        raise ValueError(\"JSON must be a list\")\n    if not isinstance(filename, str):\n        raise TypeError(\"filename must be a string\")\n    if not isinstance(sheet_name, str):\n        raise TypeError(\"sheet_name must be a string\")\n    if not data:\n        wb = xlwt.Workbook()\n        wb.save(filename)\n        return os.path.abspath(filename)\n    df = pd.DataFrame(data)\n    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n    df.to_excel(writer, sheet_name=sheet_name, index=False)\n    writer.save()\n    return os.path.abspath(filename)", "raw_solution": "import xlwt\nimport os\nimport pandas as pd\nimport json\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    if not isinstance(json_str, (str, bytes, bytearray)):\n        raise TypeError(\"json_str must be a string, bytes, or bytearray\")\n    try:\n        data = json.loads(json_str)\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON\")\n    if not isinstance(data, list):\n        raise ValueError(\"JSON must be a list\")\n    if not isinstance(filename, str):\n        raise TypeError(\"filename must be a string\")\n    if not isinstance(sheet_name, str):\n        raise TypeError(\"sheet_name must be a string\")\n    if not data:\n        wb = xlwt.Workbook()\n        wb.save(filename)\n        return os.path.abspath(filename)\n    df = pd.DataFrame(data)\n    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n    df.to_excel(writer, sheet_name=sheet_name, index=False)\n    writer.save()\n    return os.path.abspath(filename)\n```"}
{"task_id": "BigCodeBench/502", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\ndef task_func(days_in_past=7, random_seed=0):\n    random.seed(random_seed)\n    activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n    df = pd.DataFrame(columns=[\"Date\", \"Activity\", \"Duration\"])\n    for i in range(days_in_past):\n        date = datetime.now() - timedelta(days=i)\n        for activity in activities:\n            duration = random.randint(0, 120)\n            df = df.append({\"Date\": date, \"Activity\": activity, \"Duration\": duration}, ignore_index=True)\n    df[\"Date\"] = df[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n    g = sns.lineplot(data=df, x=\"Date\", y=\"Duration\", hue=\"Activity\", palette=\"deep\")\n    return (g, df)", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\n\ndef task_func(days_in_past=7, random_seed=0):\n    random.seed(random_seed)\n    activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n    df = pd.DataFrame(columns=[\"Date\", \"Activity\", \"Duration\"])\n    for i in range(days_in_past):\n        date = datetime.now() - timedelta(days=i)\n        for activity in activities:\n            duration = random.randint(0, 120)\n            df = df.append({\"Date\": date, \"Activity\": activity, \"Duration\": duration}, ignore_index=True)\n    df[\"Date\"] = df[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n    g = sns.lineplot(data=df, x=\"Date\", y=\"Duration\", hue=\"Activity\", palette=\"deep\")\n    return (g, df)\n```"}
{"task_id": "BigCodeBench/503", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0\n):\n    np.random.seed(random_seed)\n    dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days_in_past)]\n    prices = np.random.rand(days_in_past, len(stock_names))\n    df = pd.DataFrame(prices, index=dates, columns=stock_names)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0\n):\n    np.random.seed(random_seed)\n    dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days_in_past)]\n    prices = np.random.rand(days_in_past, len(stock_names))\n    df = pd.DataFrame(prices, index=dates, columns=stock_names)\n    return df\n```"}
{"task_id": "BigCodeBench/504", "solution": "import hashlib\nimport rsa\nimport base64\ndef task_func(file_path):\n    with open(file_path, 'rb') as file:\n        data = file.read()\n    hash_obj = hashlib.sha256(data)\n    hash_digest = hash_obj.digest()\n    with open('private.pem', 'rb') as key_file:\n        private_key = rsa.PrivateKey.load_pkcs1(key_file.read())\n    signature = rsa.sign_hash(hash_digest, private_key, 'SHA-256')\n    return base64.b64encode(signature).decode()", "raw_solution": "import hashlib\nimport rsa\nimport base64\n\ndef task_func(file_path):\n    with open(file_path, 'rb') as file:\n        data = file.read()\n    hash_obj = hashlib.sha256(data)\n    hash_digest = hash_obj.digest()\n    with open('private.pem', 'rb') as key_file:\n        private_key = rsa.PrivateKey.load_pkcs1(key_file.read())\n    signature = rsa.sign_hash(hash_digest, private_key, 'SHA-256')\n    return base64.b64encode(signature).decode()\n```"}
{"task_id": "BigCodeBench/505", "solution": "import hashlib\nimport hmac\ndef task_func(secret, message):\n    secret = secret.encode()\n    message = message.encode()\n    h = hmac.new(secret, message, hashlib.sha256)\n    return h.hexdigest()", "raw_solution": "import hashlib\nimport hmac\n\ndef task_func(secret, message):\n    secret = secret.encode()\n    message = message.encode()\n    h = hmac.new(secret, message, hashlib.sha256)\n    return h.hexdigest()\n```"}
{"task_id": "BigCodeBench/506", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    df = pd.DataFrame(data, columns=['date', 'temperature', 'humidity', 'wind_speed', 'precipitation'])\n    if df.empty:\n        return {'sum': np.nan, 'mean': np.nan, 'min': np.inf, 'max': -np.inf, 'plot': None}\n    else:\n        result = {\n            'sum': df[column].sum(),\n            'mean': df[column].mean(),\n            'min': df[column].min(),\n            'max': df[column].max(),\n            'plot': None\n        }\n        fig, ax = plt.subplots()\n        ax.hist(df[column], bins=10, edgecolor='black')\n        ax.set_title(f'Histogram of {column}')\n        ax.set_xlabel(column)\n        ax.set_ylabel('Frequency')\n        result['plot'] = ax\n        return result", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    df = pd.DataFrame(data, columns=['date', 'temperature', 'humidity', 'wind_speed', 'precipitation'])\n    if df.empty:\n        return {'sum': np.nan, 'mean': np.nan, 'min': np.inf, 'max': -np.inf, 'plot': None}\n    else:\n        result = {\n            'sum': df[column].sum(),\n            'mean': df[column].mean(),\n            'min': df[column].min(),\n            'max': df[column].max(),\n            'plot': None\n        }\n        fig, ax = plt.subplots()\n        ax.hist(df[column], bins=10, edgecolor='black')\n        ax.set_title(f'Histogram of {column}')\n        ax.set_xlabel(column)\n        ax.set_ylabel('Frequency')\n        result['plot'] = ax\n        return result\n```"}
{"task_id": "BigCodeBench/507", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(column, data):\n    if column not in data.columns:\n        raise ValueError(\"Invalid column name\")\n    if data.empty:\n        return {'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}\n    return {\n        'sum': data[column].sum(),\n        'mean': data[column].mean(),\n        'min': data[column].min(),\n        'max': data[column].max()\n    }", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(column, data):\n    if column not in data.columns:\n        raise ValueError(\"Invalid column name\")\n    if data.empty:\n        return {'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}\n    return {\n        'sum': data[column].sum(),\n        'mean': data[column].mean(),\n        'min': data[column].min(),\n        'max': data[column].max()\n    }\n```"}
{"task_id": "BigCodeBench/508", "solution": "import hashlib\nimport io\nimport os\ndef task_func(file_path1, file_path2):\n    if not os.path.exists(file_path1) or not os.path.exists(file_path2):\n        raise FileNotFoundError(\"One or both files do not exist\")\n\n    with io.open(file_path1, 'rb') as f1, io.open(file_path2, 'rb') as f2:\n        hash1 = hashlib.md5(f1.read()).hexdigest()\n        hash2 = hashlib.md5(f2.read()).hexdigest()\n\n    return hash1 == hash2", "raw_solution": "import hashlib\nimport io\nimport os\n\ndef task_func(file_path1, file_path2):\n    if not os.path.exists(file_path1) or not os.path.exists(file_path2):\n        raise FileNotFoundError(\"One or both files do not exist\")\n\n    with io.open(file_path1, 'rb') as f1, io.open(file_path2, 'rb') as f2:\n        hash1 = hashlib.md5(f1.read()).hexdigest()\n        hash2 = hashlib.md5(f2.read()).hexdigest()\n\n    return hash1 == hash2\n```"}
{"task_id": "BigCodeBench/509", "solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    try:\n        with open(file_path1, 'r') as file1, open(file_path2, 'r') as file2:\n            reader1 = csv.reader(file1, delimiter=delimiter, quotechar=quotechar)\n            reader2 = csv.reader(file2, delimiter=delimiter, quotechar=quotechar)\n            lines1 = list(reader1)\n            lines2 = list(reader2)\n\n            if not lines1 or not lines2:\n                raise ValueError(\"One or both of the files are empty.\")\n\n            diff_lines = []\n            for line1, line2 in zip(lines1, lines2):\n                if line1 != line2:\n                    diff_lines.append(line1)\n                    diff_lines.append(line2)\n\n            if len(lines1) > len(lines2):\n                diff_lines.extend(lines1[len(lines2):])\n            elif len(lines2) > len(lines1):\n                diff_lines.extend(lines2[len(lines1):])\n\n            diff_report = []\n            for i, line in enumerate(diff_lines, start=1):\n                if i % 2 == 1:\n                    status = '-'\n                else:\n                    status = '+'\n                diff_report.append([i, status, line])\n\n            df = pd.DataFrame(diff_report, columns=['Line Number', 'Status', 'Content'])\n            return df\n\n    except FileNotFoundError:\n        raise FileNotFoundError(\"One or both of the files cannot be found.\")\n    except Exception as e:\n        raise Exception(\"An error occurred: \" + str(e))", "raw_solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    try:\n        with open(file_path1, 'r') as file1, open(file_path2, 'r') as file2:\n            reader1 = csv.reader(file1, delimiter=delimiter, quotechar=quotechar)\n            reader2 = csv.reader(file2, delimiter=delimiter, quotechar=quotechar)\n            lines1 = list(reader1)\n            lines2 = list(reader2)\n\n            if not lines1 or not lines2:\n                raise ValueError(\"One or both of the files are empty.\")\n\n            diff_lines = []\n            for line1, line2 in zip(lines1, lines2):\n                if line1 != line2:\n                    diff_lines.append(line1)\n                    diff_lines.append(line2)\n\n            if len(lines1) > len(lines2):\n                diff_lines.extend(lines1[len(lines2):])\n            elif len(lines2) > len(lines1):\n                diff_lines.extend(lines2[len(lines1):])\n\n            diff_report = []\n            for i, line in enumerate(diff_lines, start=1):\n                if i % 2 == 1:\n                    status = '-'\n                else:\n                    status = '+'\n                diff_report.append([i, status, line])\n\n            df = pd.DataFrame(diff_report, columns=['Line Number', 'Status', 'Content'])\n            return df\n\n    except FileNotFoundError:\n        raise FileNotFoundError(\"One or both of the files cannot be found.\")\n    except Exception as e:\n        raise Exception(\"An error occurred: \" + str(e))"}
{"task_id": "BigCodeBench/510", "solution": "import difflib\nimport gzip\ndef task_func(file_path1, file_path2):\n    with gzip.open(file_path1, 'rt') as f1, gzip.open(file_path2, 'rt') as f2:\n        diff = difflib.Differ()\n        diff_result = diff.compare(f1.readlines(), f2.readlines())\n        diff_str = ''.join(diff_result)\n        return diff_str", "raw_solution": "import difflib\nimport gzip\n\ndef task_func(file_path1, file_path2):\n    with gzip.open(file_path1, 'rt') as f1, gzip.open(file_path2, 'rt') as f2:\n        diff = difflib.Differ()\n        diff_result = diff.compare(f1.readlines(), f2.readlines())\n        diff_str = ''.join(diff_result)\n        return diff_str\n```"}
{"task_id": "BigCodeBench/511", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if data.empty:\n        return ({'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}, None)\n    else:\n        stats = {\n            'sum': data[column].sum(),\n            'mean': data[column].mean(),\n            'min': data[column].min(),\n            'max': data[column].max()\n        }\n        fig, ax = plt.subplots()\n        ax.pie(data[column], labels=data['Age'], autopct='%1.1f%%')\n        ax.axis('equal')\n        return (stats, ax)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if data.empty:\n        return ({'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}, None)\n    else:\n        stats = {\n            'sum': data[column].sum(),\n            'mean': data[column].mean(),\n            'min': data[column].min(),\n            'max': data[column].max()\n        }\n        fig, ax = plt.subplots()\n        ax.pie(data[column], labels=data['Age'], autopct='%1.1f%%')\n        ax.axis('equal')\n        return (stats, ax)\n```"}
{"task_id": "BigCodeBench/512", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if not isinstance(column, str):\n        raise ValueError(\"Column name must be a string\")\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data must be a pandas DataFrame\")\n    if column not in data.columns:\n        raise ValueError(\"Column name not found in data\")\n    if (data[column] < 0).any():\n        raise ValueError(\"Quantity sold or total sales cannot be negative\")\n    stats = {\n        'sum': data[column].sum(),\n        'mean': data[column].mean(),\n        'min': data[column].min(),\n        'max': data[column].max()\n    }\n    fig, ax = plt.subplots()\n    ax.bar(data['Product'], data[column])\n    ax.set_xlabel('Product')\n    ax.set_ylabel(column)\n    ax.set_title('Bar Chart of ' + column)\n    return stats, ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if not isinstance(column, str):\n        raise ValueError(\"Column name must be a string\")\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data must be a pandas DataFrame\")\n    if column not in data.columns:\n        raise ValueError(\"Column name not found in data\")\n    if (data[column] < 0).any():\n        raise ValueError(\"Quantity sold or total sales cannot be negative\")\n    stats = {\n        'sum': data[column].sum(),\n        'mean': data[column].mean(),\n        'min': data[column].min(),\n        'max': data[column].max()\n    }\n    fig, ax = plt.subplots()\n    ax.bar(data['Product'], data[column])\n    ax.set_xlabel('Product')\n    ax.set_ylabel(column)\n    ax.set_title('Bar Chart of ' + column)\n    return stats, ax\n```"}
{"task_id": "BigCodeBench/513", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if not data:\n        raise ValueError(\"Data list is empty\")\n    df = pd.DataFrame(data)\n    if column not in df.columns:\n        raise KeyError(\"Invalid column\")\n    if (df[column] < 0).any():\n        raise ValueError(\"Negative values are not allowed\")\n    summary = {\n        \"sum\": df[column].sum(),\n        \"mean\": df[column].mean(),\n        \"min\": df[column].min(),\n        \"max\": df[column].max()\n    }\n    ax = df.plot(x='Date', y=column, kind='line', title=f'Line Chart of {column}')\n    plt.show()\n    return summary, ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if not data:\n        raise ValueError(\"Data list is empty\")\n    df = pd.DataFrame(data)\n    if column not in df.columns:\n        raise KeyError(\"Invalid column\")\n    if (df[column] < 0).any():\n        raise ValueError(\"Negative values are not allowed\")\n    summary = {\n        \"sum\": df[column].sum(),\n        \"mean\": df[column].mean(),\n        \"min\": df[column].min(),\n        \"max\": df[column].max()\n    }\n    ax = df.plot(x='Date', y=column, kind='line', title=f'Line Chart of {column}')\n    plt.show()\n    return summary, ax\n```"}
{"task_id": "BigCodeBench/514", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(array):\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'E'])\n    df.plot(kind='bar', stacked=True)\n    plt.title('Sum of each column')\n    plt.xlabel('Index')\n    plt.ylabel('Sum')\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(array):\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'E'])\n    df.plot(kind='bar', stacked=True)\n    plt.title('Sum of each column')\n    plt.xlabel('Index')\n    plt.ylabel('Sum')\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/515", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(array):\n    if not array:\n        raise ValueError(\"Input array is empty\")\n    for sublist in array:\n        if len(sublist) != 5:\n            raise ValueError(\"Sublists must be of length 5\")\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'E'])\n    correlation_matrix = df.corr()\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n    plt.show()\n    return df, correlation_matrix", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(array):\n    if not array:\n        raise ValueError(\"Input array is empty\")\n    for sublist in array:\n        if len(sublist) != 5:\n            raise ValueError(\"Sublists must be of length 5\")\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'E'])\n    correlation_matrix = df.corr()\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n    plt.show()\n    return df, correlation_matrix\n```"}
{"task_id": "BigCodeBench/516", "solution": "import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\ndef task_func(\n    array: list, random_seed: int = 0\n) -> (pd.DataFrame, sm.regression.linear_model.RegressionResultsWrapper):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'Response'])\n    X = df[['A', 'B', 'C', 'D']]\n    y = df['Response']\n    X = sm.add_constant(X)\n    model = sm.OLS(y, X)\n    results = model.fit()\n    return df, results", "raw_solution": "import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\ndef task_func(\n    array: list, random_seed: int = 0\n) -> (pd.DataFrame, sm.regression.linear_model.RegressionResultsWrapper):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'Response'])\n    X = df[['A', 'B', 'C', 'D']]\n    y = df['Response']\n    X = sm.add_constant(X)\n    model = sm.OLS(y, X)\n    results = model.fit()\n    return df, results\n```"}
{"task_id": "BigCodeBench/517", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\ndef task_func(array: list, random_seed: int = 42) -> (pd.DataFrame, np.ndarray):\n    df = pd.DataFrame(array)\n    pca = PCA(n_components=2, random_state=random_seed)\n    pca_data = pca.fit_transform(df)\n    return df, pca_data", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\n\ndef task_func(array: list, random_seed: int = 42) -> (pd.DataFrame, np.ndarray):\n    df = pd.DataFrame(array)\n    pca = PCA(n_components=2, random_state=random_seed)\n    pca_data = pca.fit_transform(df)\n    return df, pca_data\n```"}
{"task_id": "BigCodeBench/518", "solution": "import pandas as pd\nfrom scipy.spatial.distance import pdist, squareform\ndef task_func(array):\n    df = pd.DataFrame(array)\n    df.columns = [chr(65 + i) for i in range(df.shape[1])]\n    distance_matrix = pd.DataFrame(squareform(pdist(df.values, 'euclidean')), index=df.index, columns=df.index)\n    return df, distance_matrix", "raw_solution": "import pandas as pd\nfrom scipy.spatial.distance import pdist, squareform\n\ndef task_func(array):\n    df = pd.DataFrame(array)\n    df.columns = [chr(65 + i) for i in range(df.shape[1])]\n    distance_matrix = pd.DataFrame(squareform(pdist(df.values, 'euclidean')), index=df.index, columns=df.index)\n    return df, distance_matrix\n```"}
{"task_id": "BigCodeBench/519", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    df = pd.DataFrame(data)\n    df = df.fillna(0)\n    df.plot(kind='line', x='Time', y='Sales Quantity', title='Fruit Sales over Time')\n    plt.xlabel('Time')\n    plt.ylabel('Sales Quantity')\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    df = pd.DataFrame(data)\n    df = df.fillna(0)\n    df.plot(kind='line', x='Time', y='Sales Quantity', title='Fruit Sales over Time')\n    plt.xlabel('Time')\n    plt.ylabel('Sales Quantity')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/520", "solution": "import collections\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not data:\n        return None, None\n    if not all(isinstance(i, dict) for i in data):\n        raise ValueError(\"All elements in data must be dictionaries.\")\n    if not all(i.keys() == data[0].keys() for i in data):\n        raise ValueError(\"All dictionaries must have the same keys.\")\n    if not all(isinstance(v, int) and v >= 0 for d in data for v in d.values()):\n        raise ValueError(\"Sales quantity must not be negative.\")\n\n    total_sales = collections.defaultdict(int)\n    for d in data:\n        for fruit, sales in d.items():\n            total_sales[fruit] += sales\n\n    colors = ['red', 'yellow', 'green', 'blue', 'purple']\n    ax = plt.bar(total_sales.keys(), total_sales.values(), color=colors)\n\n    return total_sales, ax", "raw_solution": "import collections\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not data:\n        return None, None\n    if not all(isinstance(i, dict) for i in data):\n        raise ValueError(\"All elements in data must be dictionaries.\")\n    if not all(i.keys() == data[0].keys() for i in data):\n        raise ValueError(\"All dictionaries must have the same keys.\")\n    if not all(isinstance(v, int) and v >= 0 for d in data for v in d.values()):\n        raise ValueError(\"Sales quantity must not be negative.\")\n\n    total_sales = collections.defaultdict(int)\n    for d in data:\n        for fruit, sales in d.items():\n            total_sales[fruit] += sales\n\n    colors = ['red', 'yellow', 'green', 'blue', 'purple']\n    ax = plt.bar(total_sales.keys(), total_sales.values(), color=colors)\n\n    return total_sales, ax\n```"}
{"task_id": "BigCodeBench/521", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data_list):\n    df = pd.DataFrame(data_list)\n    df = df.set_index('Test')\n    df = df.T\n    df.plot(kind='line', ax=plt.gca())\n    plt.xlabel('Test Number')\n    plt.ylabel('Score')\n    plt.title('Student Scores Over Tests')\n    plt.legend(title='Students')\n    plt.grid(True)\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data_list):\n    df = pd.DataFrame(data_list)\n    df = df.set_index('Test')\n    df = df.T\n    df.plot(kind='line', ax=plt.gca())\n    plt.xlabel('Test Number')\n    plt.ylabel('Score')\n    plt.title('Student Scores Over Tests')\n    plt.legend(title='Students')\n    plt.grid(True)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/522", "solution": "import collections\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not data:\n        return None\n\n    # Combine dictionaries with differing keys\n    combined_data = collections.defaultdict(list)\n    for d in data:\n        for key, value in d.items():\n            combined_data[key].append(value)\n\n    # Calculate average score for each student\n    averages = {}\n    for key, values in combined_data.items():\n        values = [v for v in values if v is not None]\n        if not values:\n            continue\n        if any(v < 0 for v in values):\n            raise ValueError(\"Negative scores are not allowed\")\n        averages[key] = sum(values) / len(values)\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    ax.bar(averages.keys(), averages.values(), color='blue')\n    ax.set_xlabel('Student')\n    ax.set_ylabel('Average Score')\n    ax.set_title('Average Student Scores')\n\n    return ax", "raw_solution": "import collections\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not data:\n        return None\n\n    # Combine dictionaries with differing keys\n    combined_data = collections.defaultdict(list)\n    for d in data:\n        for key, value in d.items():\n            combined_data[key].append(value)\n\n    # Calculate average score for each student\n    averages = {}\n    for key, values in combined_data.items():\n        values = [v for v in values if v is not None]\n        if not values:\n            continue\n        if any(v < 0 for v in values):\n            raise ValueError(\"Negative scores are not allowed\")\n        averages[key] = sum(values) / len(values)\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    ax.bar(averages.keys(), averages.values(), color='blue')\n    ax.set_xlabel('Student')\n    ax.set_ylabel('Average Score')\n    ax.set_title('Average Student Scores')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/523", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not data:\n        return None\n    combined_data = {}\n    for d in data:\n        for key, value in d.items():\n            if key in combined_data:\n                combined_data[key].append(value)\n            else:\n                combined_data[key] = [value]\n    df = pd.DataFrame(combined_data)\n    ax = df.plot(kind='line')\n    plt.xlabel('Time')\n    plt.ylabel('Data Points')\n    plt.title('Data over Time')\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not data:\n        return None\n    combined_data = {}\n    for d in data:\n        for key, value in d.items():\n            if key in combined_data:\n                combined_data[key].append(value)\n            else:\n                combined_data[key] = [value]\n    df = pd.DataFrame(combined_data)\n    ax = df.plot(kind='line')\n    plt.xlabel('Time')\n    plt.ylabel('Data Points')\n    plt.title('Data over Time')\n    return ax\n```"}
{"task_id": "BigCodeBench/524", "solution": "from collections import defaultdict\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not isinstance(data, list):\n        raise TypeError(\"Input data should be a list of dictionaries.\")\n    if not data:\n        raise ValueError(\"Input data should not be empty.\")\n    for item in data:\n        if not isinstance(item, dict):\n            raise TypeError(\"All items in the list should be dictionaries.\")\n        for key, value in item.items():\n            if not isinstance(value, (int, float)):\n                raise TypeError(\"All values in the dictionaries should be numeric.\")\n\n    stats = defaultdict(list)\n    for item in data:\n        for key, value in item.items():\n            stats[key].append(value)\n\n    mean_std_dict = {}\n    axes_list = []\n    for key, values in stats.items():\n        mean = np.mean(values)\n        std_dev = np.std(values)\n        mean_std_dict[key] = (mean, std_dev)\n\n        fig, ax = plt.subplots()\n        ax.bar([\"Mean\", \"Std Dev\"], [mean, std_dev], color=[\"blue\", \"orange\"])\n        ax.set_title(f\"{key} Mean and Standard Deviation\")\n        ax.set_ylabel(\"Value\")\n        ax.set_xlabel(\"Statistic\")\n        axes_list.append(ax)\n\n    return mean_std_dict, axes_list", "raw_solution": "from collections import defaultdict\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not isinstance(data, list):\n        raise TypeError(\"Input data should be a list of dictionaries.\")\n    if not data:\n        raise ValueError(\"Input data should not be empty.\")\n    for item in data:\n        if not isinstance(item, dict):\n            raise TypeError(\"All items in the list should be dictionaries.\")\n        for key, value in item.items():\n            if not isinstance(value, (int, float)):\n                raise TypeError(\"All values in the dictionaries should be numeric.\")\n\n    stats = defaultdict(list)\n    for item in data:\n        for key, value in item.items():\n            stats[key].append(value)\n\n    mean_std_dict = {}\n    axes_list = []\n    for key, values in stats.items():\n        mean = np.mean(values)\n        std_dev = np.std(values)\n        mean_std_dict[key] = (mean, std_dev)\n\n        fig, ax = plt.subplots()\n        ax.bar([\"Mean\", \"Std Dev\"], [mean, std_dev], color=[\"blue\", \"orange\"])\n        ax.set_title(f\"{key} Mean and Standard Deviation\")\n        ax.set_ylabel(\"Value\")\n        ax.set_xlabel(\"Statistic\")\n        axes_list.append(ax)\n\n    return mean_std_dict, axes_list\n```"}
{"task_id": "BigCodeBench/525", "solution": "import json\nimport numpy as np\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\ndef task_func(input_file):\n    with open(input_file, 'r') as file:\n        data = json.load(file)\n\n    result = defaultdict(dict)\n    plots = []\n\n    for key in data[0].keys():\n        values = [d[key] for d in data if key in d]\n        mean = np.mean(values)\n        median = np.median(values)\n        result[key]['mean'] = mean\n        result[key]['median'] = median\n\n        fig, ax = plt.subplots()\n        ax.bar(['Mean', 'Median'], [mean, median], color=['blue', 'orange'])\n        ax.set_title(f'{key} Mean and Median')\n        ax.set_ylabel('Value')\n        ax.set_xlabel('Statistic')\n        plots.append(ax)\n\n    return result, plots", "raw_solution": "import json\nimport numpy as np\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef task_func(input_file):\n    with open(input_file, 'r') as file:\n        data = json.load(file)\n\n    result = defaultdict(dict)\n    plots = []\n\n    for key in data[0].keys():\n        values = [d[key] for d in data if key in d]\n        mean = np.mean(values)\n        median = np.median(values)\n        result[key]['mean'] = mean\n        result[key]['median'] = median\n\n        fig, ax = plt.subplots()\n        ax.bar(['Mean', 'Median'], [mean, median], color=['blue', 'orange'])\n        ax.set_title(f'{key} Mean and Median')\n        ax.set_ylabel('Value')\n        ax.set_xlabel('Statistic')\n        plots.append(ax)\n\n    return result, plots\n```"}
{"task_id": "BigCodeBench/526", "solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\ndef task_func(input_file=\"data.json\"):\n    with open(input_file, 'r') as file:\n        data = json.load(file)\n\n    stats = defaultdict(list)\n    for item in data:\n        for key, value in item.items():\n            if isinstance(value, (int, float)):\n                stats[key].append(value)\n\n    df = pd.DataFrame(stats)\n    df = df.apply(pd.to_numeric, errors='coerce')\n    df = df.dropna(axis=1, how='all')\n    df = df.dropna(axis=0, how='any')\n\n    df['mean'] = df.mean(axis=0)\n    df['median'] = df.median(axis=0)\n\n    df = df.sort_index()\n\n    return df", "raw_solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\ndef task_func(input_file=\"data.json\"):\n    with open(input_file, 'r') as file:\n        data = json.load(file)\n\n    stats = defaultdict(list)\n    for item in data:\n        for key, value in item.items():\n            if isinstance(value, (int, float)):\n                stats[key].append(value)\n\n    df = pd.DataFrame(stats)\n    df = df.apply(pd.to_numeric, errors='coerce')\n    df = df.dropna(axis=1, how='all')\n    df = df.dropna(axis=0, how='any')\n\n    df['mean'] = df.mean(axis=0)\n    df['median'] = df.median(axis=0)\n\n    df = df.sort_index()\n\n    return df\n```"}
{"task_id": "BigCodeBench/527", "solution": "import json\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\ndef task_func(input_file: str) -> plt.Axes:\n    with open(input_file, 'r') as file:\n        data = json.load(file)\n\n    results = defaultdict(dict)\n    for key in data[0].keys():\n        values = [item[key] for item in data]\n        results[key]['mean'] = np.mean(values)\n        results[key]['median'] = np.median(values)\n\n    df = pd.DataFrame(data)\n    ax = sns.boxplot(x=\"X\", y=\"Y\", data=df)\n\n    return results, ax", "raw_solution": "import json\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\ndef task_func(input_file: str) -> plt.Axes:\n    with open(input_file, 'r') as file:\n        data = json.load(file)\n\n    results = defaultdict(dict)\n    for key in data[0].keys():\n        values = [item[key] for item in data]\n        results[key]['mean'] = np.mean(values)\n        results[key]['median'] = np.median(values)\n\n    df = pd.DataFrame(data)\n    ax = sns.boxplot(x=\"X\", y=\"Y\", data=df)\n\n    return results, ax\n```"}
{"task_id": "BigCodeBench/528", "solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(file_path):\n    if not file_path.endswith('.csv'):\n        raise ValueError(\"File must be a CSV file\")\n\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        rows = list(reader)\n\n    duplicates = [row for row in rows if rows.count(row) > 1]\n    duplicate_counts = Counter(tuple(sorted(row)) for row in duplicates)\n\n    df = pd.DataFrame(list(duplicate_counts.items()), columns=['Duplicates', 'Count'])\n    df.set_index('Duplicates', inplace=True)\n\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Duplicates')\n    ax.set_ylabel('Count')\n    ax.set_title('Duplicate Rows in CSV File')\n\n    return duplicate_counts, ax", "raw_solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path):\n    if not file_path.endswith('.csv'):\n        raise ValueError(\"File must be a CSV file\")\n\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        rows = list(reader)\n\n    duplicates = [row for row in rows if rows.count(row) > 1]\n    duplicate_counts = Counter(tuple(sorted(row)) for row in duplicates)\n\n    df = pd.DataFrame(list(duplicate_counts.items()), columns=['Duplicates', 'Count'])\n    df.set_index('Duplicates', inplace=True)\n\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Duplicates')\n    ax.set_ylabel('Count')\n    ax.set_title('Duplicate Rows in CSV File')\n\n    return duplicate_counts, ax"}
{"task_id": "BigCodeBench/529", "solution": "from collections import Counter\nimport random\nimport matplotlib.pyplot as plt\ndef task_func(num_rolls, num_dice, plot_path=None, random_seed=0):\n    random.seed(random_seed)\n    roll_sums = [sum(random.randint(1, 6) for _ in range(num_dice)) for _ in range(num_rolls)]\n    counter = Counter(roll_sums)\n\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Sum of Dice Roll')\n    ax.set_ylabel('Count')\n    ax.set_title(f'Distribution of Dice Roll Sums ({num_rolls} rolls, {num_dice} dice)')\n\n    if plot_path is not None:\n        plt.savefig(plot_path)\n\n    return counter, ax", "raw_solution": "from collections import Counter\nimport random\nimport matplotlib.pyplot as plt\n\ndef task_func(num_rolls, num_dice, plot_path=None, random_seed=0):\n    random.seed(random_seed)\n    roll_sums = [sum(random.randint(1, 6) for _ in range(num_dice)) for _ in range(num_rolls)]\n    counter = Counter(roll_sums)\n\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Sum of Dice Roll')\n    ax.set_ylabel('Count')\n    ax.set_title(f'Distribution of Dice Roll Sums ({num_rolls} rolls, {num_dice} dice)')\n\n    if plot_path is not None:\n        plt.savefig(plot_path)\n\n    return counter, ax\n```"}
{"task_id": "BigCodeBench/530", "solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if (df['age'] < 0).any():\n        raise ValueError(\"Age cannot be negative\")\n    df['age'] = df['age'].apply(lambda x: int(x) if x == int(x) else int(x) + 1)\n    duplicates = df[df.duplicated(subset='name', keep=False)]\n    if duplicates.empty:\n        return Counter(), None\n    age_distribution = Counter(duplicates['age'])\n    min_age, max_age = min(age_distribution.keys()), max(age_distribution.keys())\n    bins = np.arange(min_age, max_age + 1) - 0.5\n    plt.figure(figsize=(10, 6))\n    sns.histplot(duplicates['age'], bins=bins, kde=False, color='skyblue')\n    plt.xlabel('Age')\n    plt.ylabel('Count')\n    plt.title('Age Distribution for Duplicate Names')\n    plt.grid(True)\n    return age_distribution, plt.gca()", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if (df['age'] < 0).any():\n        raise ValueError(\"Age cannot be negative\")\n    df['age'] = df['age'].apply(lambda x: int(x) if x == int(x) else int(x) + 1)\n    duplicates = df[df.duplicated(subset='name', keep=False)]\n    if duplicates.empty:\n        return Counter(), None\n    age_distribution = Counter(duplicates['age'])\n    min_age, max_age = min(age_distribution.keys()), max(age_distribution.keys())\n    bins = np.arange(min_age, max_age + 1) - 0.5\n    plt.figure(figsize=(10, 6))\n    sns.histplot(duplicates['age'], bins=bins, kde=False, color='skyblue')\n    plt.xlabel('Age')\n    plt.ylabel('Count')\n    plt.title('Age Distribution for Duplicate Names')\n    plt.grid(True)\n    return age_distribution, plt.gca()\n```"}
{"task_id": "BigCodeBench/531", "solution": "from collections import Counter\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df, n_clusters=3, random_state=None, n_init=10):\n    # Identify duplicate points\n    duplicate_points = df[df.duplicated(subset=None, keep=False)]\n    duplicate_count = Counter(duplicate_points.index)\n\n    # Perform KMeans clustering on unique points\n    unique_points = df.drop_duplicates()\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    kmeans.fit(unique_points)\n\n    # Record the clusters\n    unique_points['cluster'] = kmeans.labels_\n\n    # Plot the clustered data\n    plt.scatter(unique_points['x'], unique_points['y'], c=unique_points['cluster'])\n    plt.show()\n\n    return duplicate_count, unique_points, plt.gca()", "raw_solution": "from collections import Counter\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, n_clusters=3, random_state=None, n_init=10):\n    # Identify duplicate points\n    duplicate_points = df[df.duplicated(subset=None, keep=False)]\n    duplicate_count = Counter(duplicate_points.index)\n\n    # Perform KMeans clustering on unique points\n    unique_points = df.drop_duplicates()\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    kmeans.fit(unique_points)\n\n    # Record the clusters\n    unique_points['cluster'] = kmeans.labels_\n\n    # Plot the clustered data\n    plt.scatter(unique_points['x'], unique_points['y'], c=unique_points['cluster'])\n    plt.show()\n\n    return duplicate_count, unique_points, plt.gca()\n```"}
{"task_id": "BigCodeBench/532", "solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(df, bins=4):\n    # Identify and count duplicate values in the 'value' column\n    value_counts = df['value'].value_counts()\n    duplicate_counts = value_counts[value_counts > 1]\n\n    # Plot histogram with normal distribution curve\n    fig, ax = plt.subplots()\n    ax.hist(df['value'], bins=bins, color='green', alpha=0.6, edgecolor='black')\n    ax.set_title(\"Distribution\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n\n    # Fit a normal distribution to the data\n    mu, sigma = norm.fit(df['value'])\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, sigma)\n    ax.plot(x, p, 'k', linewidth=2)\n\n    return duplicate_counts, ax", "raw_solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(df, bins=4):\n    # Identify and count duplicate values in the 'value' column\n    value_counts = df['value'].value_counts()\n    duplicate_counts = value_counts[value_counts > 1]\n\n    # Plot histogram with normal distribution curve\n    fig, ax = plt.subplots()\n    ax.hist(df['value'], bins=bins, color='green', alpha=0.6, edgecolor='black')\n    ax.set_title(\"Distribution\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n\n    # Fit a normal distribution to the data\n    mu, sigma = norm.fit(df['value'])\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, sigma)\n    ax.plot(x, p, 'k', linewidth=2)\n\n    return duplicate_counts, ax\n```"}
{"task_id": "BigCodeBench/533", "solution": "import numpy as np\nimport secrets\nimport hashlib\nimport base64\ndef task_func(num, from_base, to_base, alphabet):\n    if from_base < 2 or to_base < 2:\n        raise ValueError(\"Invalid base for conversion\")\n    if not set(num).issubset(set(alphabet)):\n        raise ValueError(\"Invalid number format for conversion\")\n    salt = secrets.token_hex(16)\n    num_dec = int(num, from_base)\n    num_hex = hex(num_dec)[2:]\n    hash_obj = hashlib.sha256(salt.encode() + num_hex.encode())\n    hash_hex = hash_obj.hexdigest()\n    hash_b64 = base64.b64encode(bytes.fromhex(hash_hex)).decode()\n    return hash_b64, salt", "raw_solution": "import numpy as np\nimport secrets\nimport hashlib\nimport base64\n\ndef task_func(num, from_base, to_base, alphabet):\n    if from_base < 2 or to_base < 2:\n        raise ValueError(\"Invalid base for conversion\")\n    if not set(num).issubset(set(alphabet)):\n        raise ValueError(\"Invalid number format for conversion\")\n    salt = secrets.token_hex(16)\n    num_dec = int(num, from_base)\n    num_hex = hex(num_dec)[2:]\n    hash_obj = hashlib.sha256(salt.encode() + num_hex.encode())\n    hash_hex = hash_obj.hexdigest()\n    hash_b64 = base64.b64encode(bytes.fromhex(hash_hex)).decode()\n    return hash_b64, salt\n```"}
{"task_id": "BigCodeBench/534", "solution": "from cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives.asymmetric import rsa\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nimport base64\ndef task_func(num, from_base, to_base, private_key, alphabet):\n    # Convert number from source base to target base\n    num = int(str(num), from_base)\n    num = int(str(num), 10)\n    # Sign the number with RSA private key\n    signature = private_key.sign(\n        num.to_bytes(num.bit_length() // 8 + 1, 'big'),\n        padding.PSS(\n            mgf=padding.MGF1(hashes.SHA256()),\n            salt_length=padding.PSS.MAX_LENGTH\n        ),\n        hashes.SHA256()\n    )\n    # Encode the signed number in base64 with custom alphabet\n    encoded = base64.b64encode(signature).decode('utf-8')\n    return encoded", "raw_solution": "from cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives.asymmetric import rsa\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nimport base64\n\ndef task_func(num, from_base, to_base, private_key, alphabet):\n    # Convert number from source base to target base\n    num = int(str(num), from_base)\n    num = int(str(num), 10)\n    # Sign the number with RSA private key\n    signature = private_key.sign(\n        num.to_bytes(num.bit_length() // 8 + 1, 'big'),\n        padding.PSS(\n            mgf=padding.MGF1(hashes.SHA256()),\n            salt_length=padding.PSS.MAX_LENGTH\n        ),\n        hashes.SHA256()\n    )\n    # Encode the signed number in base64 with custom alphabet\n    encoded = base64.b64encode(signature).decode('utf-8')\n    return encoded\n```"}
{"task_id": "BigCodeBench/535", "solution": "import sqlite3\nimport numpy as np\nfrom random import choice, seed\ndef task_func(db_path, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries cannot be negative\")\n\n    NAMES = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    AGES = np.random.randint(18, 65, num_entries)\n    HEIGHTS = np.random.randint(150, 200, num_entries)\n\n    if random_seed is not None:\n        seed(random_seed)\n\n    conn = sqlite3.connect(db_path)\n    c = conn.cursor()\n\n    c.execute(f'''CREATE TABLE IF NOT EXISTS {table_name}\n                  (name TEXT, age INTEGER, height INTEGER)''')\n\n    for i in range(num_entries):\n        c.execute(f'''INSERT INTO {table_name} VALUES\n                      (?, ?, ?)''', (choice(NAMES), AGES[i], HEIGHTS[i]))\n\n    conn.commit()\n    conn.close()\n\n    return num_entries", "raw_solution": "import sqlite3\nimport numpy as np\nfrom random import choice, seed\n\ndef task_func(db_path, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries cannot be negative\")\n\n    NAMES = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    AGES = np.random.randint(18, 65, num_entries)\n    HEIGHTS = np.random.randint(150, 200, num_entries)\n\n    if random_seed is not None:\n        seed(random_seed)\n\n    conn = sqlite3.connect(db_path)\n    c = conn.cursor()\n\n    c.execute(f'''CREATE TABLE IF NOT EXISTS {table_name}\n                  (name TEXT, age INTEGER, height INTEGER)''')\n\n    for i in range(num_entries):\n        c.execute(f'''INSERT INTO {table_name} VALUES\n                      (?, ?, ?)''', (choice(NAMES), AGES[i], HEIGHTS[i]))\n\n    conn.commit()\n    conn.close()\n\n    return num_entries"}
{"task_id": "BigCodeBench/536", "solution": "import sqlite3\nimport pandas as pd\nimport os\ndef task_func(db_name, table_name, csv_path=\"data.csv\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n\n    # Read the table from the database\n    df = pd.read_sql_query(f\"SELECT * from {table_name}\", conn)\n\n    # Export the DataFrame to a CSV file\n    df.to_csv(csv_path, index=False)\n\n    # Return the absolute path of the exported CSV file\n    return os.path.abspath(csv_path)", "raw_solution": "import sqlite3\nimport pandas as pd\nimport os\n\ndef task_func(db_name, table_name, csv_path=\"data.csv\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n\n    # Read the table from the database\n    df = pd.read_sql_query(f\"SELECT * from {table_name}\", conn)\n\n    # Export the DataFrame to a CSV file\n    df.to_csv(csv_path, index=False)\n\n    # Return the absolute path of the exported CSV file\n    return os.path.abspath(csv_path)\n```"}
{"task_id": "BigCodeBench/537", "solution": "import sqlite3\nimport pandas as pd\nimport seaborn as sns\ndef task_func(db_name=\"test.db\", table_name=\"People\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n\n    # Execute a SELECT query to fetch the data from the table\n    query = f\"SELECT age FROM {table_name}\"\n    data = pd.read_sql_query(query, conn)\n\n    # Check for negative age values\n    if (data['age'] < 0).any():\n        raise ValueError(\"The data contains negative age values.\")\n\n    # Plot the age distribution\n    plot = sns.histplot(data=data, x='age', bins=30, kde=True)\n\n    # Close the connection to the database\n    conn.close()\n\n    return plot", "raw_solution": "import sqlite3\nimport pandas as pd\nimport seaborn as sns\n\ndef task_func(db_name=\"test.db\", table_name=\"People\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n\n    # Execute a SELECT query to fetch the data from the table\n    query = f\"SELECT age FROM {table_name}\"\n    data = pd.read_sql_query(query, conn)\n\n    # Check for negative age values\n    if (data['age'] < 0).any():\n        raise ValueError(\"The data contains negative age values.\")\n\n    # Plot the age distribution\n    plot = sns.histplot(data=data, x='age', bins=30, kde=True)\n\n    # Close the connection to the database\n    conn.close()\n\n    return plot\n```"}
{"task_id": "BigCodeBench/538", "solution": "import sqlite3\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(db_name, table_name):\n    conn = sqlite3.connect(db_name)\n    df = pd.read_sql_query(f\"SELECT * from {table_name}\", conn)\n    conn.close()\n\n    df = df.select_dtypes(include=['int', 'float'])\n    if df.shape[1] < 2:\n        raise ValueError(\"The table has less than two numerical columns.\")\n\n    fig, ax = plt.subplots()\n    ax.scatter(df.columns[0], df.columns[1])\n    ax.set_xlabel(df.columns[0])\n    ax.set_ylabel(df.columns[1])\n    ax.set_title(f\"{df.columns[0]} vs {df.columns[1]}\")\n    return ax", "raw_solution": "import sqlite3\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(db_name, table_name):\n    conn = sqlite3.connect(db_name)\n    df = pd.read_sql_query(f\"SELECT * from {table_name}\", conn)\n    conn.close()\n\n    df = df.select_dtypes(include=['int', 'float'])\n    if df.shape[1] < 2:\n        raise ValueError(\"The table has less than two numerical columns.\")\n\n    fig, ax = plt.subplots()\n    ax.scatter(df.columns[0], df.columns[1])\n    ax.set_xlabel(df.columns[0])\n    ax.set_ylabel(df.columns[1])\n    ax.set_title(f\"{df.columns[0]} vs {df.columns[1]}\")\n    return ax\n```"}
{"task_id": "BigCodeBench/539", "solution": "import sqlite3\nfrom random import choice, seed\nimport os\ndef task_func(db_name, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries cannot be negative\")\n\n    NAMES = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    AGES = range(18, 66)\n    HEIGHTS = range(150, 201)\n\n    if random_seed is not None:\n        seed(random_seed)\n\n    conn = sqlite3.connect(db_name)\n    cursor = conn.cursor()\n\n    cursor.execute(f'''CREATE TABLE IF NOT EXISTS {table_name}\n                    (name TEXT, age INTEGER, height INTEGER)''')\n\n    for _ in range(num_entries):\n        name = choice(NAMES)\n        age = choice(AGES)\n        height = choice(HEIGHTS)\n        cursor.execute(f'''INSERT INTO {table_name} (name, age, height)\n                        VALUES (?, ?, ?)''', (name, age, height))\n\n    conn.commit()\n    conn.close()\n\n    return os.path.abspath(db_name)", "raw_solution": "import sqlite3\nfrom random import choice, seed\nimport os\n\ndef task_func(db_name, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries cannot be negative\")\n\n    NAMES = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    AGES = range(18, 66)\n    HEIGHTS = range(150, 201)\n\n    if random_seed is not None:\n        seed(random_seed)\n\n    conn = sqlite3.connect(db_name)\n    cursor = conn.cursor()\n\n    cursor.execute(f'''CREATE TABLE IF NOT EXISTS {table_name}\n                    (name TEXT, age INTEGER, height INTEGER)''')\n\n    for _ in range(num_entries):\n        name = choice(NAMES)\n        age = choice(AGES)\n        height = choice(HEIGHTS)\n        cursor.execute(f'''INSERT INTO {table_name} (name, age, height)\n                        VALUES (?, ?, ?)''', (name, age, height))\n\n    conn.commit()\n    conn.close()\n\n    return os.path.abspath(db_name)\n```"}
{"task_id": "BigCodeBench/540", "solution": "from collections import Counter\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\ndef task_func(list_of_menuitems, title=\"Menu Distribution\", color=\"blue\", width=1.0):\n    flat_list = list(itertools.chain(*list_of_menuitems))\n    count_dict = dict(Counter(flat_list))\n    labels = list(count_dict.keys())\n    values = list(count_dict.values())\n\n    fig, ax = plt.subplots()\n    ax.bar(labels, values, color=color, width=width)\n    ax.set_xlabel(\"Menu Items\")\n    ax.set_ylabel(\"Frequency\")\n    ax.set_title(title)\n    plt.xticks(rotation=90)\n    return ax", "raw_solution": "from collections import Counter\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef task_func(list_of_menuitems, title=\"Menu Distribution\", color=\"blue\", width=1.0):\n    flat_list = list(itertools.chain(*list_of_menuitems))\n    count_dict = dict(Counter(flat_list))\n    labels = list(count_dict.keys())\n    values = list(count_dict.values())\n\n    fig, ax = plt.subplots()\n    ax.bar(labels, values, color=color, width=width)\n    ax.set_xlabel(\"Menu Items\")\n    ax.set_ylabel(\"Frequency\")\n    ax.set_title(title)\n    plt.xticks(rotation=90)\n    return ax\n```"}
{"task_id": "BigCodeBench/541", "solution": "import os\nimport sys\nimport importlib\nfrom pkgutil import iter_modules\ndef task_func(package_name):\n    try:\n        package = importlib.import_module(package_name)\n    except ImportError:\n        raise ImportError(f\"Package '{package_name}' is not installed or cannot be found. Please install it using: pip install {package_name}\")\n\n    package_path = os.path.dirname(package.__file__)\n    sys.path.append(package_path)\n\n    modules = [name for _, name, _ in iter_modules([package_path])]\n    return modules", "raw_solution": "import os\nimport sys\nimport importlib\nfrom pkgutil import iter_modules\n\ndef task_func(package_name):\n    try:\n        package = importlib.import_module(package_name)\n    except ImportError:\n        raise ImportError(f\"Package '{package_name}' is not installed or cannot be found. Please install it using: pip install {package_name}\")\n\n    package_path = os.path.dirname(package.__file__)\n    sys.path.append(package_path)\n\n    modules = [name for _, name, _ in iter_modules([package_path])]\n    return modules"}
{"task_id": "BigCodeBench/542", "solution": "import hashlib\nimport random\nimport struct\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_keys=KEYS, seed=42):\n    random.seed(seed)\n    hex_key = random.choice(hex_keys)\n    try:\n        float_key = struct.unpack('f', bytes.fromhex(hex_key))[0]\n    except ValueError:\n        raise ValueError(\"Invalid hexadecimal string\")\n    md5_hash = hashlib.md5(struct.pack('f', float_key)).hexdigest()\n    return md5_hash", "raw_solution": "import hashlib\nimport random\nimport struct\n\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\n\ndef task_func(hex_keys=KEYS, seed=42):\n    random.seed(seed)\n    hex_key = random.choice(hex_keys)\n    try:\n        float_key = struct.unpack('f', bytes.fromhex(hex_key))[0]\n    except ValueError:\n        raise ValueError(\"Invalid hexadecimal string\")\n    md5_hash = hashlib.md5(struct.pack('f', float_key)).hexdigest()\n    return md5_hash\n```"}
{"task_id": "BigCodeBench/543", "solution": "import base64\nimport os\ndef task_func():\n    # Generate a random float number\n    random_float = os.urandom(8)\n    # Convert the float to a hexadecimal string\n    hex_string = random_float.hex()\n    # Encode the hexadecimal representation in base64\n    base64_encoded = base64.b64encode(bytes.fromhex(hex_string))\n    # Return the base64 encoded string\n    return base64_encoded.decode()", "raw_solution": "import base64\nimport os\n\ndef task_func():\n    # Generate a random float number\n    random_float = os.urandom(8)\n    # Convert the float to a hexadecimal string\n    hex_string = random_float.hex()\n    # Encode the hexadecimal representation in base64\n    base64_encoded = base64.b64encode(bytes.fromhex(hex_string))\n    # Return the base64 encoded string\n    return base64_encoded.decode()\n```"}
{"task_id": "BigCodeBench/544", "solution": "import struct\nimport zlib\nKEY = '470FC614'\ndef task_func(hex_string=KEY):\n    # Convert hex string to float\n    float_number = struct.unpack('f', bytes.fromhex(hex_string))[0]\n\n    # Compress the float number\n    compressed_float = zlib.compress(struct.pack('f', float_number))\n\n    return compressed_float", "raw_solution": "import struct\nimport zlib\n\n# Constants\nKEY = '470FC614'\n\ndef task_func(hex_string=KEY):\n    # Convert hex string to float\n    float_number = struct.unpack('f', bytes.fromhex(hex_string))[0]\n\n    # Compress the float number\n    compressed_float = zlib.compress(struct.pack('f', float_number))\n\n    return compressed_float\n```"}
{"task_id": "BigCodeBench/545", "solution": "import codecs\nimport random\nimport struct\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_keys=KEYS):\n    # Convert hex strings to float\n    float_keys = [float(int(key, 16)) for key in hex_keys]\n\n    # Generate a random float number from the list\n    random_float = random.choice(float_keys)\n\n    # Encode the float number in utf-8\n    encoded_float = codecs.encode(struct.pack('>f', random_float), 'utf-8')\n\n    return encoded_float", "raw_solution": "import codecs\nimport random\nimport struct\n\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\n\ndef task_func(hex_keys=KEYS):\n    # Convert hex strings to float\n    float_keys = [float(int(key, 16)) for key in hex_keys]\n\n    # Generate a random float number from the list\n    random_float = random.choice(float_keys)\n\n    # Encode the float number in utf-8\n    encoded_float = codecs.encode(struct.pack('>f', random_float), 'utf-8')\n\n    return encoded_float\n```"}
{"task_id": "BigCodeBench/546", "solution": "from collections import OrderedDict\nfrom prettytable import PrettyTable\ndef task_func(my_dict):\n    sorted_dict = OrderedDict(sorted(my_dict.items()))\n    pt = PrettyTable()\n    pt.field_names = [\"Key\", \"Value\"]\n    for key, value in sorted_dict.items():\n        pt.add_row([key, value])\n    return pt", "raw_solution": "from collections import OrderedDict\nfrom prettytable import PrettyTable\n\ndef task_func(my_dict):\n    sorted_dict = OrderedDict(sorted(my_dict.items()))\n    pt = PrettyTable()\n    pt.field_names = [\"Key\", \"Value\"]\n    for key, value in sorted_dict.items():\n        pt.add_row([key, value])\n    return pt\n```"}
{"task_id": "BigCodeBench/547", "solution": "import hashlib\nimport os\nimport base64\ndef task_func(password: str, salt_length: int = 8) -> str:\n    salt = os.urandom(salt_length)\n    password_salt = (password + salt.decode()).encode()\n    hashed_password = hashlib.sha256(password_salt).digest()\n    return base64.b64encode(hashed_password).decode()", "raw_solution": "import hashlib\nimport os\nimport base64\n\ndef task_func(password: str, salt_length: int = 8) -> str:\n    salt = os.urandom(salt_length)\n    password_salt = (password + salt.decode()).encode()\n    hashed_password = hashlib.sha256(password_salt).digest()\n    return base64.b64encode(hashed_password).decode()\n```"}
{"task_id": "BigCodeBench/548", "solution": "import random\nimport string\nimport base64\nimport zlib\ndef task_func(string_length=100):\n    random_string = ''.join(random.choices(string.ascii_uppercase + string.digits, k=string_length))\n    compressed_string = zlib.compress(random_string.encode())\n    base64_string = base64.b64encode(compressed_string).decode()\n    return base64_string", "raw_solution": "import random\nimport string\nimport base64\nimport zlib\n\ndef task_func(string_length=100):\n    random_string = ''.join(random.choices(string.ascii_uppercase + string.digits, k=string_length))\n    compressed_string = zlib.compress(random_string.encode())\n    base64_string = base64.b64encode(compressed_string).decode()\n    return base64_string\n```"}
{"task_id": "BigCodeBench/549", "solution": "import base64\nimport pandas as pd\ndef task_func(df):\n    df = pd.DataFrame(df)\n    csv_data = df.to_csv(index=False)\n    bytes_data = csv_data.encode('utf-8')\n    base64_data = base64.b64encode(bytes_data)\n    return base64_data.decode('utf-8')", "raw_solution": "import base64\nimport pandas as pd\n\ndef task_func(df):\n    df = pd.DataFrame(df)\n    csv_data = df.to_csv(index=False)\n    bytes_data = csv_data.encode('utf-8')\n    base64_data = base64.b64encode(bytes_data)\n    return base64_data.decode('utf-8')\n```"}
{"task_id": "BigCodeBench/550", "solution": "from collections import Counter\nimport pandas as pd\ndef task_func(list_of_menuitems):\n    flat_list = [item for sublist in list_of_menuitems for item in sublist]\n    count_dict = dict(Counter(flat_list))\n    df = pd.DataFrame(list(count_dict.items()), columns=['MenuItem', 'Count'])\n    df.set_index('MenuItem', inplace=True)\n    return df", "raw_solution": "from collections import Counter\nimport pandas as pd\n\ndef task_func(list_of_menuitems):\n    flat_list = [item for sublist in list_of_menuitems for item in sublist]\n    count_dict = dict(Counter(flat_list))\n    df = pd.DataFrame(list(count_dict.items()), columns=['MenuItem', 'Count'])\n    df.set_index('MenuItem', inplace=True)\n    return df\n```"}
{"task_id": "BigCodeBench/551", "solution": "from collections import Counter\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\ndef task_func(list_of_menuitems):\n    flat_list = [item for sublist in list_of_menuitems for item in sublist]\n    counter = Counter(flat_list)\n    df = pd.DataFrame(list(counter.items()), columns=['Menu Item', 'Frequency'])\n    ax = sns.barplot(x='Menu Item', y='Frequency', data=df)\n    return ax", "raw_solution": "from collections import Counter\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\ndef task_func(list_of_menuitems):\n    flat_list = [item for sublist in list_of_menuitems for item in sublist]\n    counter = Counter(flat_list)\n    df = pd.DataFrame(list(counter.items()), columns=['Menu Item', 'Frequency'])\n    ax = sns.barplot(x='Menu Item', y='Frequency', data=df)\n    return ax\n```"}
{"task_id": "BigCodeBench/552", "solution": "import collections\nimport itertools\nimport matplotlib.pyplot as plt\nITEMS = ['apple', 'banana']\ndef task_func(a, b, items=ITEMS):\n    # Combine the two lists\n    combined = list(itertools.chain(a, b))\n    # Count the frequency of each item in the combined list\n    counter = collections.Counter(combined)\n    # Create a bar chart showing the frequency of each item\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Items')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of Items in Combined List')\n    return ax", "raw_solution": "import collections\nimport itertools\nimport matplotlib.pyplot as plt\n# Constants\nITEMS = ['apple', 'banana']\ndef task_func(a, b, items=ITEMS):\n    # Combine the two lists\n    combined = list(itertools.chain(a, b))\n    # Count the frequency of each item in the combined list\n    counter = collections.Counter(combined)\n    # Create a bar chart showing the frequency of each item\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Items')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of Items in Combined List')\n    return ax\n```"}
{"task_id": "BigCodeBench/553", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(a, b):\n    df = pd.DataFrame(np.random.randint(0,100,size=(len(a), len(b))), index=a, columns=COLUMNS[:len(b)])\n    ax = df.plot(kind='bar', figsize=(10,5))\n    plt.title('Bar Chart')\n    plt.xlabel('Index')\n    plt.ylabel('Value')\n    return ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(a, b):\n    df = pd.DataFrame(np.random.randint(0,100,size=(len(a), len(b))), index=a, columns=COLUMNS[:len(b)])\n    ax = df.plot(kind='bar', figsize=(10,5))\n    plt.title('Bar Chart')\n    plt.xlabel('Index')\n    plt.ylabel('Value')\n    return ax\n```"}
{"task_id": "BigCodeBench/554", "solution": "import numpy as np\nimport random\ndef task_func(MIN_WORDS, MAX_WORDS, WORDS_POOL):\n    num_words = random.randint(MIN_WORDS, MAX_WORDS)\n    sentence = ' '.join(random.choice(WORDS_POOL) for _ in range(num_words))\n    return sentence + ' ' + sentence[::-1]", "raw_solution": "import numpy as np\nimport random\n\ndef task_func(MIN_WORDS, MAX_WORDS, WORDS_POOL):\n    num_words = random.randint(MIN_WORDS, MAX_WORDS)\n    sentence = ' '.join(random.choice(WORDS_POOL) for _ in range(num_words))\n    return sentence + ' ' + sentence[::-1]\n```"}
{"task_id": "BigCodeBench/555", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\ndef task_func(a, b):\n    # Calculate Pearson correlation coefficient\n    correlation, _ = stats.pearsonr(a, b)\n\n    # Create DataFrame from lists\n    df = pd.DataFrame({'a': a, 'b': b})\n\n    # Create scatter plot with regression line\n    fig, ax = plt.subplots()\n    ax.scatter(df['a'], df['b'])\n    m, b = np.polyfit(df['a'], df['b'], 1)\n    ax.plot(df['a'], m*df['a'] + b, color='red')\n\n    return correlation, ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndef task_func(a, b):\n    # Calculate Pearson correlation coefficient\n    correlation, _ = stats.pearsonr(a, b)\n\n    # Create DataFrame from lists\n    df = pd.DataFrame({'a': a, 'b': b})\n\n    # Create scatter plot with regression line\n    fig, ax = plt.subplots()\n    ax.scatter(df['a'], df['b'])\n    m, b = np.polyfit(df['a'], df['b'], 1)\n    ax.plot(df['a'], m*df['a'] + b, color='red')\n\n    return correlation, ax\n```"}
{"task_id": "BigCodeBench/556", "solution": "import numpy as np\nimport random\nfrom difflib import SequenceMatcher\ndef task_func(s, min_length, max_length, letters):\n    length = random.randint(min_length, max_length)\n    random_string = ''.join(random.choice(letters) for _ in range(length))\n    similarity = SequenceMatcher(None, s, random_string).ratio()\n    return (random_string, similarity >= 0.5)", "raw_solution": "import numpy as np\nimport random\nfrom difflib import SequenceMatcher\n\ndef task_func(s, min_length, max_length, letters):\n    length = random.randint(min_length, max_length)\n    random_string = ''.join(random.choice(letters) for _ in range(length))\n    similarity = SequenceMatcher(None, s, random_string).ratio()\n    return (random_string, similarity >= 0.5)\n```"}
{"task_id": "BigCodeBench/557", "solution": "import numpy as np\nfrom difflib import SequenceMatcher\nimport matplotlib.pyplot as plt\ndef task_func(s_list, plot_path=None):\n    if not isinstance(s_list, list):\n        raise ValueError(\"s_list must be a list of strings\")\n    if not all(isinstance(s, str) for s in s_list):\n        raise ValueError(\"s_list must be a list of strings\")\n    if len(s_list) == 1:\n        return np.nan\n    scores = []\n    for i in range(len(s_list)):\n        score = sum(SequenceMatcher(None, s_list[i], s_list[j]).ratio() for j in range(len(s_list))) / len(s_list)\n        scores.append(score)\n    if plot_path:\n        plt.plot(scores)\n        plt.savefig(plot_path)\n    return scores", "raw_solution": "import numpy as np\nfrom difflib import SequenceMatcher\nimport matplotlib.pyplot as plt\n\ndef task_func(s_list, plot_path=None):\n    if not isinstance(s_list, list):\n        raise ValueError(\"s_list must be a list of strings\")\n    if not all(isinstance(s, str) for s in s_list):\n        raise ValueError(\"s_list must be a list of strings\")\n    if len(s_list) == 1:\n        return np.nan\n    scores = []\n    for i in range(len(s_list)):\n        score = sum(SequenceMatcher(None, s_list[i], s_list[j]).ratio() for j in range(len(s_list))) / len(s_list)\n        scores.append(score)\n    if plot_path:\n        plt.plot(scores)\n        plt.savefig(plot_path)\n    return scores\n```"}
{"task_id": "BigCodeBench/558", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(a, b, columns=['A', 'B']):\n    # Standardize the values\n    scaler = StandardScaler()\n    data = pd.DataFrame(scaler.fit_transform(pd.DataFrame({columns[0]: a, columns[1]: b})), columns=columns)\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    data.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Standardized Value')\n    ax.set_title('Standardized Values')\n\n    return data, ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(a, b, columns=['A', 'B']):\n    # Standardize the values\n    scaler = StandardScaler()\n    data = pd.DataFrame(scaler.fit_transform(pd.DataFrame({columns[0]: a, columns[1]: b})), columns=columns)\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    data.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Standardized Value')\n    ax.set_title('Standardized Values')\n\n    return data, ax\n```"}
{"task_id": "BigCodeBench/559", "solution": "import pandas as pd\nfrom scipy.spatial import distance\nimport matplotlib.pyplot as plt\ndef task_func(a, b):\n    euclidean_distance = distance.euclidean(a, b)\n    df = pd.DataFrame({'A': a, 'B': b}, index=['A', 'B', 'C', 'D', 'E'])\n    fig, ax = plt.subplots()\n    ax.plot(df)\n    return euclidean_distance, df, ax", "raw_solution": "import pandas as pd\nfrom scipy.spatial import distance\nimport matplotlib.pyplot as plt\n\ndef task_func(a, b):\n    euclidean_distance = distance.euclidean(a, b)\n    df = pd.DataFrame({'A': a, 'B': b}, index=['A', 'B', 'C', 'D', 'E'])\n    fig, ax = plt.subplots()\n    ax.plot(df)\n    return euclidean_distance, df, ax\n```"}
{"task_id": "BigCodeBench/560", "solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(data):\n    # Convert the 'date' column to datetime format\n    data['date'] = pd.to_datetime(data['date'])\n\n    # Extract the year from the 'date' column\n    year = data['date'].dt.year.iloc[0]\n\n    # Set the 'date' column as the index\n    data.set_index('date', inplace=True)\n\n    # Group the data by month and calculate the mean value for each month\n    monthly_data = data.groupby(data.index.month).mean()\n\n    # Create a bar chart\n    ax = monthly_data.plot(kind='bar', legend=False)\n\n    # Set the title and labels\n    ax.set_title(f'Monthly Data for {year}')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n\n    return ax", "raw_solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(data):\n    # Convert the 'date' column to datetime format\n    data['date'] = pd.to_datetime(data['date'])\n\n    # Extract the year from the 'date' column\n    year = data['date'].dt.year.iloc[0]\n\n    # Set the 'date' column as the index\n    data.set_index('date', inplace=True)\n\n    # Group the data by month and calculate the mean value for each month\n    monthly_data = data.groupby(data.index.month).mean()\n\n    # Create a bar chart\n    ax = monthly_data.plot(kind='bar', legend=False)\n\n    # Set the title and labels\n    ax.set_title(f'Monthly Data for {year}')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/561", "solution": "import pytz\nfrom dateutil import parser\ndef task_func(date_str, from_tz, to_tz):\n    date = parser.parse(date_str)\n    from_tz = pytz.timezone(from_tz)\n    to_tz = pytz.timezone(to_tz)\n    date = from_tz.localize(date)\n    date = date.astimezone(to_tz)\n    return date.strftime('%Y-%m-%d %H:%M:%S')", "raw_solution": "import pytz\nfrom dateutil import parser\n\ndef task_func(date_str, from_tz, to_tz):\n    date = parser.parse(date_str)\n    from_tz = pytz.timezone(from_tz)\n    to_tz = pytz.timezone(to_tz)\n    date = from_tz.localize(date)\n    date = date.astimezone(to_tz)\n    return date.strftime('%Y-%m-%d %H:%M:%S')\n```"}
{"task_id": "BigCodeBench/562", "solution": "import os\nimport ctypes\nimport sys\nimport subprocess\ndef task_func(filepath):\n    if not isinstance(filepath, str):\n        raise TypeError(\"Input filepath must be a string\")\n    if not filepath:\n        raise OSError(\"Input filepath is invalid or empty\")\n\n    # Load the DLL file\n    ctypes.CDLL(filepath)\n\n    # Retrieve system information\n    system_name = os.uname().sysname\n    node_name = os.uname().nodename\n    release = os.uname().release\n    version = os.uname().version\n    machine = os.uname().machine\n    python_version = sys.version.split()[0]\n    pip_version = subprocess.getoutput(\"pip --version\").split()[1]\n\n    # Print the system information\n    print(f\"System: {system_name} Node Name: {node_name} Release: {release} Version: {version} Machine: {machine} Python Version: {python_version} PIP Version: {pip_version}\")\n\n    return os.path.basename(filepath)", "raw_solution": "import os\nimport ctypes\nimport sys\nimport subprocess\n\ndef task_func(filepath):\n    if not isinstance(filepath, str):\n        raise TypeError(\"Input filepath must be a string\")\n    if not filepath:\n        raise OSError(\"Input filepath is invalid or empty\")\n\n    # Load the DLL file\n    ctypes.CDLL(filepath)\n\n    # Retrieve system information\n    system_name = os.uname().sysname\n    node_name = os.uname().nodename\n    release = os.uname().release\n    version = os.uname().version\n    machine = os.uname().machine\n    python_version = sys.version.split()[0]\n    pip_version = subprocess.getoutput(\"pip --version\").split()[1]\n\n    # Print the system information\n    print(f\"System: {system_name} Node Name: {node_name} Release: {release} Version: {version} Machine: {machine} Python Version: {python_version} PIP Version: {pip_version}\")\n\n    return os.path.basename(filepath)\n```"}
{"task_id": "BigCodeBench/563", "solution": "import ctypes\nimport os\nimport shutil\nimport glob\ndef task_func(filepath, destination_dir):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Get the name of the loaded DLL file\n    dll_name = os.path.basename(filepath)\n\n    # Move all DLL files in the same directory to the specified destination directory\n    for dll_file in glob.glob(os.path.join(os.path.dirname(filepath), \"*.dll\")):\n        shutil.move(dll_file, destination_dir)\n\n    return dll_name", "raw_solution": "import ctypes\nimport os\nimport shutil\nimport glob\n\ndef task_func(filepath, destination_dir):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Get the name of the loaded DLL file\n    dll_name = os.path.basename(filepath)\n\n    # Move all DLL files in the same directory to the specified destination directory\n    for dll_file in glob.glob(os.path.join(os.path.dirname(filepath), \"*.dll\")):\n        shutil.move(dll_file, destination_dir)\n\n    return dll_name\n```"}
{"task_id": "BigCodeBench/564", "solution": "import os\nimport ctypes\nfrom datetime import datetime\nimport pytz\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Get the file metadata\n    creation_time = os.path.getctime(filepath)\n    modification_time = os.path.getmtime(filepath)\n    file_size = os.path.getsize(filepath)\n\n    # Convert the times to UTC format\n    creation_time = datetime.fromtimestamp(creation_time, pytz.utc)\n    modification_time = datetime.fromtimestamp(modification_time, pytz.utc)\n\n    # Create the metadata dictionary\n    metadata = {\n        'Creation Time': creation_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Modification Time': modification_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Size': file_size\n    }\n\n    # Return the DLL file name and metadata\n    return os.path.basename(filepath), metadata", "raw_solution": "import os\nimport ctypes\nfrom datetime import datetime\nimport pytz\n\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Get the file metadata\n    creation_time = os.path.getctime(filepath)\n    modification_time = os.path.getmtime(filepath)\n    file_size = os.path.getsize(filepath)\n\n    # Convert the times to UTC format\n    creation_time = datetime.fromtimestamp(creation_time, pytz.utc)\n    modification_time = datetime.fromtimestamp(modification_time, pytz.utc)\n\n    # Create the metadata dictionary\n    metadata = {\n        'Creation Time': creation_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Modification Time': modification_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Size': file_size\n    }\n\n    # Return the DLL file name and metadata\n    return os.path.basename(filepath), metadata\n```"}
{"task_id": "BigCodeBench/565", "solution": "import ctypes\nimport hashlib\nimport binascii\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Calculate the MD5 and SHA256 hashes\n    with open(filepath, 'rb') as f:\n        data = f.read()\n        md5_hash = hashlib.md5(data).digest()\n        sha256_hash = hashlib.sha256(data).digest()\n\n    # Convert the hashes to hexadecimal format\n    md5_hex = binascii.hexlify(md5_hash).decode()\n    sha256_hex = binascii.hexlify(sha256_hash).decode()\n\n    # Print the hashes\n    print(f\"MD5: {md5_hex}\")\n    print(f\"SHA256: {sha256_hex}\")\n\n    # Return the actual name of the loaded DLL file\n    return dll._name", "raw_solution": "import ctypes\nimport hashlib\nimport binascii\n\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Calculate the MD5 and SHA256 hashes\n    with open(filepath, 'rb') as f:\n        data = f.read()\n        md5_hash = hashlib.md5(data).digest()\n        sha256_hash = hashlib.sha256(data).digest()\n\n    # Convert the hashes to hexadecimal format\n    md5_hex = binascii.hexlify(md5_hash).decode()\n    sha256_hex = binascii.hexlify(sha256_hash).decode()\n\n    # Print the hashes\n    print(f\"MD5: {md5_hex}\")\n    print(f\"SHA256: {sha256_hex}\")\n\n    # Return the actual name of the loaded DLL file\n    return dll._name\n```"}
{"task_id": "BigCodeBench/566", "solution": "import inspect\nimport types\ndef task_func(f):\n    if inspect.isfunction(f):\n        if isinstance(f, types.LambdaType):\n            is_lambda = True\n        else:\n            is_lambda = False\n        args = list(inspect.signature(f).parameters.keys())\n        defaults = [v.default for v in inspect.signature(f).parameters.values() if v.default is not inspect.Parameter.empty]\n        annotations = [v.annotation for v in inspect.signature(f).parameters.values() if v.annotation is not inspect.Parameter.empty]\n        return {\n            'name': f.__name__,\n            'is_lambda': is_lambda,\n            'arguments': args,\n            'defaults': defaults,\n            'annotations': annotations\n        }\n    else:\n        raise ValueError(\"Input must be a function\")", "raw_solution": "import inspect\nimport types\n\ndef task_func(f):\n    if inspect.isfunction(f):\n        if isinstance(f, types.LambdaType):\n            is_lambda = True\n        else:\n            is_lambda = False\n        args = list(inspect.signature(f).parameters.keys())\n        defaults = [v.default for v in inspect.signature(f).parameters.values() if v.default is not inspect.Parameter.empty]\n        annotations = [v.annotation for v in inspect.signature(f).parameters.values() if v.annotation is not inspect.Parameter.empty]\n        return {\n            'name': f.__name__,\n            'is_lambda': is_lambda,\n            'arguments': args,\n            'defaults': defaults,\n            'annotations': annotations\n        }\n    else:\n        raise ValueError(\"Input must be a function\")"}
{"task_id": "BigCodeBench/567", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Convert the string data to a numeric array\n    data = np.array([float(x) for x in data.split(',')])\n\n    # Calculate the bins\n    bins = np.arange(data.min(), data.max()+2) - 0.5\n\n    # Create the histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=bins, edgecolor='black')\n\n    # Set the title and labels\n    ax.set_title('Histogram of Values')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Convert the string data to a numeric array\n    data = np.array([float(x) for x in data.split(',')])\n\n    # Calculate the bins\n    bins = np.arange(data.min(), data.max()+2) - 0.5\n\n    # Create the histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=bins, edgecolor='black')\n\n    # Set the title and labels\n    ax.set_title('Histogram of Values')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/568", "solution": "import inspect\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(f_list):\n    if not all(inspect.isfunction(f) for f in f_list):\n        raise ValueError(\"All elements in the list must be functions\")\n    if any(inspect.islambda(f) for f in f_list):\n        raise ValueError(\"Lambda functions are not allowed\")\n    data = [(f.__name__, len(inspect.signature(f).parameters)) for f in f_list]\n    df = pd.DataFrame(data, columns=[\"Function\", \"Arguments\"])\n    df.plot(x=\"Function\", y=\"Arguments\", kind=\"bar\")\n    plt.show()\n    return df", "raw_solution": "import inspect\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(f_list):\n    if not all(inspect.isfunction(f) for f in f_list):\n        raise ValueError(\"All elements in the list must be functions\")\n    if any(inspect.islambda(f) for f in f_list):\n        raise ValueError(\"Lambda functions are not allowed\")\n    data = [(f.__name__, len(inspect.signature(f).parameters)) for f in f_list]\n    df = pd.DataFrame(data, columns=[\"Function\", \"Arguments\"])\n    df.plot(x=\"Function\", y=\"Arguments\", kind=\"bar\")\n    plt.show()\n    return df\n```"}
{"task_id": "BigCodeBench/569", "solution": "import inspect\nimport types\nimport math\ndef task_func(f):\n    sig = inspect.signature(f)\n    num_args = len(sig.parameters)\n    lambda_count = 0\n    for param in sig.parameters.values():\n        if isinstance(param.default, types.LambdaType):\n            lambda_count += 1\n    return {\n        \"name\": f.__name__,\n        \"sqrt_args\": math.sqrt(num_args),\n        \"lambda_count\": lambda_count\n    }", "raw_solution": "import inspect\nimport types\nimport math\n\ndef task_func(f):\n    sig = inspect.signature(f)\n    num_args = len(sig.parameters)\n    lambda_count = 0\n    for param in sig.parameters.values():\n        if isinstance(param.default, types.LambdaType):\n            lambda_count += 1\n    return {\n        \"name\": f.__name__,\n        \"sqrt_args\": math.sqrt(num_args),\n        \"lambda_count\": lambda_count\n    }\n```"}
{"task_id": "BigCodeBench/570", "solution": "import inspect\nimport types\nimport json\ndef task_func(f):\n    if inspect.isfunction(f):\n        if isinstance(f, types.LambdaType):\n            is_lambda = True\n        else:\n            is_lambda = False\n        arg_spec = inspect.getfullargspec(f)\n        annotations = inspect.get_annotations(f)\n        return json.dumps({\n            \"name\": f.__name__,\n            \"args\": arg_spec.args,\n            \"defaults\": arg_spec.defaults,\n            \"annotations\": annotations,\n            \"is_lambda\": is_lambda\n        })\n    else:\n        raise ValueError(\"Input must be a function\")", "raw_solution": "import inspect\nimport types\nimport json\n\ndef task_func(f):\n    if inspect.isfunction(f):\n        if isinstance(f, types.LambdaType):\n            is_lambda = True\n        else:\n            is_lambda = False\n        arg_spec = inspect.getfullargspec(f)\n        annotations = inspect.get_annotations(f)\n        return json.dumps({\n            \"name\": f.__name__,\n            \"args\": arg_spec.args,\n            \"defaults\": arg_spec.defaults,\n            \"annotations\": annotations,\n            \"is_lambda\": is_lambda\n        })\n    else:\n        raise ValueError(\"Input must be a function\")\n```"}
{"task_id": "BigCodeBench/571", "solution": "import inspect\nimport pandas as pd\ndef task_func(f_list, file_path):\n    if not isinstance(f_list, list) or not all(inspect.isfunction(f) for f in f_list):\n        raise ValueError(\"'f_list' must be a list of functions\")\n    if not f_list:\n        raise ValueError(\"'f_list' cannot be empty\")\n    if not isinstance(file_path, str):\n        raise ValueError(\"'file_path' must be a string\")\n    try:\n        with open(file_path, 'w') as file:\n            file.write('Function Name,Number of Arguments,Defaults,Annotations,Is Lambda\\n')\n            for f in f_list:\n                code = inspect.getsource(f)\n                if 'lambda' in code:\n                    is_lambda = True\n                else:\n                    is_lambda = False\n                arg_spec = inspect.getfullargspec(f)\n                defaults = arg_spec.defaults if arg_spec.defaults else []\n                annotations = f.__annotations__ if f.__annotations__ else {}\n                file.write(f\"{f.__name__},{len(arg_spec.args)},{defaults},{annotations},{is_lambda}\\n\")\n    except IOError:\n        raise IOError(\"Error in writing to the specified file path\")", "raw_solution": "import inspect\nimport pandas as pd\n\ndef task_func(f_list, file_path):\n    if not isinstance(f_list, list) or not all(inspect.isfunction(f) for f in f_list):\n        raise ValueError(\"'f_list' must be a list of functions\")\n    if not f_list:\n        raise ValueError(\"'f_list' cannot be empty\")\n    if not isinstance(file_path, str):\n        raise ValueError(\"'file_path' must be a string\")\n    try:\n        with open(file_path, 'w') as file:\n            file.write('Function Name,Number of Arguments,Defaults,Annotations,Is Lambda\\n')\n            for f in f_list:\n                code = inspect.getsource(f)\n                if 'lambda' in code:\n                    is_lambda = True\n                else:\n                    is_lambda = False\n                arg_spec = inspect.getfullargspec(f)\n                defaults = arg_spec.defaults if arg_spec.defaults else []\n                annotations = f.__annotations__ if f.__annotations__ else {}\n                file.write(f\"{f.__name__},{len(arg_spec.args)},{defaults},{annotations},{is_lambda}\\n\")\n    except IOError:\n        raise IOError(\"Error in writing to the specified file path\")\n```"}
{"task_id": "BigCodeBench/572", "solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array_length=100):\n    array1 = [randint(1, 100) for _ in range(array_length)]\n    array2 = [randint(1, 100) for _ in range(array_length)]\n\n    max_values = [max(array1[i], array2[i]) for i in range(array_length)]\n\n    plt.plot(max_values)\n    plt.ylabel('Maximum Values')\n    plt.show()\n\n    return plt.gca()", "raw_solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(array_length=100):\n    array1 = [randint(1, 100) for _ in range(array_length)]\n    array2 = [randint(1, 100) for _ in range(array_length)]\n\n    max_values = [max(array1[i], array2[i]) for i in range(array_length)]\n\n    plt.plot(max_values)\n    plt.ylabel('Maximum Values')\n    plt.show()\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/573", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(array_length=100):\n    np.random.seed(0)\n    array1 = np.random.randint(0, 100, array_length)\n    array2 = np.random.randint(0, 100, array_length)\n\n    mean1, mean2 = np.mean(array1), np.mean(array2)\n    median1, median2 = np.median(array1), np.median(array2)\n    std1, std2 = np.std(array1), np.std(array2)\n\n    statistics = pd.DataFrame({\n        'Array1': [mean1, median1, std1],\n        'Array2': [mean2, median2, std2]\n    }, index=['Mean', 'Median', 'Standard Deviation'])\n\n    ax = statistics.plot(kind='bar', figsize=(10, 5))\n    ax.set_xlabel('Statistics')\n    ax.set_ylabel('Value')\n    ax.legend(loc='upper right')\n\n    return statistics, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(array_length=100):\n    np.random.seed(0)\n    array1 = np.random.randint(0, 100, array_length)\n    array2 = np.random.randint(0, 100, array_length)\n\n    mean1, mean2 = np.mean(array1), np.mean(array2)\n    median1, median2 = np.median(array1), np.median(array2)\n    std1, std2 = np.std(array1), np.std(array2)\n\n    statistics = pd.DataFrame({\n        'Array1': [mean1, median1, std1],\n        'Array2': [mean2, median2, std2]\n    }, index=['Mean', 'Median', 'Standard Deviation'])\n\n    ax = statistics.plot(kind='bar', figsize=(10, 5))\n    ax.set_xlabel('Statistics')\n    ax.set_ylabel('Value')\n    ax.legend(loc='upper right')\n\n    return statistics, ax\n```"}
{"task_id": "BigCodeBench/574", "solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array_length=100, noise_level=0.2):\n    def sine_func(x, a, b, c):\n        return a * np.sin(b * x) + c\n\n    x = np.linspace(0, 1, array_length)\n    y = np.sin(2 * np.pi * x) + np.random.normal(0, noise_level, array_length)\n\n    popt, _ = curve_fit(sine_func, x, y)\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(x, y, 'o', label='Noisy Sine Wave')\n    plt.plot(x, sine_func(x, *popt), '-', label='Adjusted Curve')\n    plt.legend()\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title('Sine Wave with Noise and Adjusted Curve')\n    plt.grid(True)\n    return plt.gca()", "raw_solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(array_length=100, noise_level=0.2):\n    def sine_func(x, a, b, c):\n        return a * np.sin(b * x) + c\n\n    x = np.linspace(0, 1, array_length)\n    y = np.sin(2 * np.pi * x) + np.random.normal(0, noise_level, array_length)\n\n    popt, _ = curve_fit(sine_func, x, y)\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(x, y, 'o', label='Noisy Sine Wave')\n    plt.plot(x, sine_func(x, *popt), '-', label='Adjusted Curve')\n    plt.legend()\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title('Sine Wave with Noise and Adjusted Curve')\n    plt.grid(True)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/575", "solution": "from random import shuffle\nimport pandas as pd\nimport numpy as np\ndef task_func(l, n_groups = 5):\n    shuffle(l)\n    df = pd.DataFrame(l)\n    for i in range(n_groups):\n        df.loc[i] = df.loc[i].shift(n_groups)\n    return df", "raw_solution": "from random import shuffle\nimport pandas as pd\nimport numpy as np\n\ndef task_func(l, n_groups = 5):\n    shuffle(l)\n    df = pd.DataFrame(l)\n    for i in range(n_groups):\n        df.loc[i] = df.loc[i].shift(n_groups)\n    return df\n```"}
{"task_id": "BigCodeBench/576", "solution": "from random import shuffle, randint\nimport pandas as pd\ndef task_func(l, n_groups = 5):\n    shuffle(l)\n    series = pd.Series(l)\n    for i in range(len(series)):\n        n = randint(1, n_groups)\n        series[i] = series[i][n:] + series[i][:n]\n    return series", "raw_solution": "from random import shuffle, randint\nimport pandas as pd\n\ndef task_func(l, n_groups = 5):\n    shuffle(l)\n    series = pd.Series(l)\n    for i in range(len(series)):\n        n = randint(1, n_groups)\n        series[i] = series[i][n:] + series[i][:n]\n    return series\n```"}
{"task_id": "BigCodeBench/577", "solution": "import os\nimport pathlib\nfrom hashlib import md5\nimport unicodedata\ndef task_func(directory):\n    result = {}\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            normalized_name = unicodedata.normalize('NFKD', filename).encode('ascii', 'ignore').decode()\n            with open(file_path, 'rb') as file:\n                file_data = file.read()\n                file_size = os.path.getsize(file_path)\n                file_hash = md5(file_data).hexdigest()\n            result[normalized_name] = {'Size': file_size, 'MD5 Hash': file_hash}\n    return result", "raw_solution": "import os\nimport pathlib\nfrom hashlib import md5\nimport unicodedata\n\ndef task_func(directory):\n    result = {}\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            normalized_name = unicodedata.normalize('NFKD', filename).encode('ascii', 'ignore').decode()\n            with open(file_path, 'rb') as file:\n                file_data = file.read()\n                file_size = os.path.getsize(file_path)\n                file_hash = md5(file_data).hexdigest()\n            result[normalized_name] = {'Size': file_size, 'MD5 Hash': file_hash}\n    return result\n```"}
{"task_id": "BigCodeBench/578", "solution": "import unicodedata\nimport requests\nURL = 'https://api.github.com/users/'\ndef task_func(username):\n    try:\n        response = requests.get(URL + username)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as err:\n        raise SystemExit(err)\n\n    user_data = response.json()\n    normalized_data = {}\n\n    for key, value in user_data.items():\n        if isinstance(value, str):\n            normalized_data[key] = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode()\n        else:\n            normalized_data[key] = value\n\n    return normalized_data", "raw_solution": "import unicodedata\nimport requests\n\nURL = 'https://api.github.com/users/'\n\ndef task_func(username):\n    try:\n        response = requests.get(URL + username)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as err:\n        raise SystemExit(err)\n\n    user_data = response.json()\n    normalized_data = {}\n\n    for key, value in user_data.items():\n        if isinstance(value, str):\n            normalized_data[key] = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode()\n        else:\n            normalized_data[key] = value\n\n    return normalized_data\n```"}
{"task_id": "BigCodeBench/579", "solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r') as file:\n            reader = csv.reader(file)\n            data = list(reader)\n    except FileNotFoundError:\n        raise FileNotFoundError(\"File not found\")\n    except IOError:\n        raise IOError(\"Error in reading file\")\n\n    text = ' '.join(str(row) for row in data)\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode()\n    words = text.split()\n    word_count = Counter(words)\n    most_common_words = word_count.most_common(10)\n\n    words, frequencies = zip(*most_common_words)\n\n    fig, ax = plt.subplots()\n    ax.bar(words, frequencies)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('Most Common Words')\n\n    return (ax, most_common_words)", "raw_solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r') as file:\n            reader = csv.reader(file)\n            data = list(reader)\n    except FileNotFoundError:\n        raise FileNotFoundError(\"File not found\")\n    except IOError:\n        raise IOError(\"Error in reading file\")\n\n    text = ' '.join(str(row) for row in data)\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode()\n    words = text.split()\n    word_count = Counter(words)\n    most_common_words = word_count.most_common(10)\n\n    words, frequencies = zip(*most_common_words)\n\n    fig, ax = plt.subplots()\n    ax.bar(words, frequencies)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('Most Common Words')\n\n    return (ax, most_common_words)\n```"}
{"task_id": "BigCodeBench/580", "solution": "import pandas as pd\nimport random\nimport statistics\nimport matplotlib.pyplot as plt\nimport numpy as np\nRANGE = 10000\nSIZE = 1000\nBIN_WIDTH = 100\ndef task_func():\n    # Generate random numbers\n    random_numbers = [random.randint(0, RANGE) for _ in range(SIZE)]\n\n    # Calculate moving average\n    moving_average = [statistics.mean(random_numbers[max(0, i-5):i+1]) for i in range(SIZE)]\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        \"Random Numbers\": random_numbers,\n        \"Moving Average\": moving_average\n    })\n\n    # Plot histogram\n    plt.hist(df[\"Random Numbers\"], bins=np.arange(0, RANGE, BIN_WIDTH))\n    plt.xlabel(\"Random Numbers\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Histogram of Random Numbers\")\n    plt.show()\n\n    return df", "raw_solution": "import pandas as pd\nimport random\nimport statistics\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Constants\nRANGE = 10000  # The range within which random numbers are generated\nSIZE = 1000  # The number of random numbers to generate\nBIN_WIDTH = 100  # The width of bins for the histogram\n\ndef task_func():\n    # Generate random numbers\n    random_numbers = [random.randint(0, RANGE) for _ in range(SIZE)]\n\n    # Calculate moving average\n    moving_average = [statistics.mean(random_numbers[max(0, i-5):i+1]) for i in range(SIZE)]\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        \"Random Numbers\": random_numbers,\n        \"Moving Average\": moving_average\n    })\n\n    # Plot histogram\n    plt.hist(df[\"Random Numbers\"], bins=np.arange(0, RANGE, BIN_WIDTH))\n    plt.xlabel(\"Random Numbers\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Histogram of Random Numbers\")\n    plt.show()\n\n    return df\n```"}
{"task_id": "BigCodeBench/581", "solution": "import math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nSIZE = 1000\nPI = np.pi\ndef task_func(size=SIZE, frequency=1):\n    x = np.linspace(0, 2*PI, size)\n    y = np.sin(frequency * x)\n    plt.plot(x, y)\n    plt.xlabel('x')\n    plt.ylabel('sin(x)')\n    plt.title('Sinusoidal Wave')\n    plt.grid(True)\n    return plt.gca()", "raw_solution": "import math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\n# Constants\nRANGE = 10000\nSIZE = 1000\nPI = np.pi\ndef task_func(size=SIZE, frequency=1):\n    x = np.linspace(0, 2*PI, size)\n    y = np.sin(frequency * x)\n    plt.plot(x, y)\n    plt.xlabel('x')\n    plt.ylabel('sin(x)')\n    plt.title('Sinusoidal Wave')\n    plt.grid(True)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/582", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(size=1000):\n    # Generate normally distributed random numbers\n    data = np.random.normal(0, 1, size)\n\n    # Create a figure and axis\n    fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n\n    # Plot histogram\n    ax[0].hist(data, bins=30, density=True, color='skyblue', edgecolor='black')\n    ax[0].set_title('Histogram')\n    ax[0].set_xlabel('Value')\n    ax[0].set_ylabel('Frequency')\n\n    # Plot PDF\n    x = np.linspace(-4, 4, 100)\n    y = stats.norm.pdf(x, 0, 1)\n    ax[1].plot(x, y, color='red')\n    ax[1].set_title('Probability Density Function')\n    ax[1].set_xlabel('Value')\n    ax[1].set_ylabel('Probability')\n\n    # Adjust layout and spacing\n    plt.tight_layout()\n    plt.subplots_adjust(hspace=0.4)\n\n    return fig", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(size=1000):\n    # Generate normally distributed random numbers\n    data = np.random.normal(0, 1, size)\n\n    # Create a figure and axis\n    fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n\n    # Plot histogram\n    ax[0].hist(data, bins=30, density=True, color='skyblue', edgecolor='black')\n    ax[0].set_title('Histogram')\n    ax[0].set_xlabel('Value')\n    ax[0].set_ylabel('Frequency')\n\n    # Plot PDF\n    x = np.linspace(-4, 4, 100)\n    y = stats.norm.pdf(x, 0, 1)\n    ax[1].plot(x, y, color='red')\n    ax[1].set_title('Probability Density Function')\n    ax[1].set_xlabel('Value')\n    ax[1].set_ylabel('Probability')\n\n    # Adjust layout and spacing\n    plt.tight_layout()\n    plt.subplots_adjust(hspace=0.4)\n\n    return fig\n```"}
{"task_id": "BigCodeBench/583", "solution": "import rsa\nimport os\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES\nfrom base64 import b64encode, b64decode\ndef task_func():\n    # Generate RSA key pair\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Generate AES key and nonce\n    aes_key = get_random_bytes(16)\n    aes_nonce = get_random_bytes(16)\n\n    # Encrypt the private key with AES\n    cipher_aes = AES.new(aes_key, AES.MODE_EAX)\n    cipher_aes.nonce = aes_nonce\n    encrypted_private_key = cipher_aes.encrypt(rsa.key.exportKey('PEM'))\n\n    # Generate filename\n    random_bytes = get_random_bytes(8)\n    filename = f\"private_key_{random_bytes.hex()}.txt\"\n\n    # Save encrypted private key to file\n    with open(filename, 'wb') as file:\n        file.write(b64encode(encrypted_private_key))\n\n    return pubkey, filename, aes_key, aes_nonce", "raw_solution": "import rsa\nimport os\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES\nfrom base64 import b64encode, b64decode\n\ndef task_func():\n    # Generate RSA key pair\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Generate AES key and nonce\n    aes_key = get_random_bytes(16)\n    aes_nonce = get_random_bytes(16)\n\n    # Encrypt the private key with AES\n    cipher_aes = AES.new(aes_key, AES.MODE_EAX)\n    cipher_aes.nonce = aes_nonce\n    encrypted_private_key = cipher_aes.encrypt(rsa.key.exportKey('PEM'))\n\n    # Generate filename\n    random_bytes = get_random_bytes(8)\n    filename = f\"private_key_{random_bytes.hex()}.txt\"\n\n    # Save encrypted private key to file\n    with open(filename, 'wb') as file:\n        file.write(b64encode(encrypted_private_key))\n\n    return pubkey, filename, aes_key, aes_nonce\n```"}
{"task_id": "BigCodeBench/584", "solution": "import rsa\nimport urllib.request\nfrom hashlib import sha256\ndef task_func(url):\n    try:\n        # Generate RSA public and private keys\n        (pubkey, privkey) = rsa.newkeys(512)\n\n        # Retrieve the content from the specified URL\n        response = urllib.request.urlopen(url)\n        content = response.read()\n\n        # Calculate the SHA256 hash of the URL content\n        hash_content = sha256(content).digest()\n\n        # Sign the hash with the private key\n        signature = rsa.sign_hash(hash_content, privkey, 'SHA-256')\n\n        # Convert the signature to a hexadecimal string\n        signature_hex = signature.hex()\n\n        return pubkey, signature_hex, hash_content\n\n    except urllib.error.URLError as e:\n        raise ValueError(f\"Error reaching the server: {e}\")\n    except rsa.pkcs1.VerificationError as e:\n        raise rsa.pkcs1.VerificationError(f\"Error signing the hash: {e}\")", "raw_solution": "import rsa\nimport urllib.request\nfrom hashlib import sha256\n\ndef task_func(url):\n    try:\n        # Generate RSA public and private keys\n        (pubkey, privkey) = rsa.newkeys(512)\n\n        # Retrieve the content from the specified URL\n        response = urllib.request.urlopen(url)\n        content = response.read()\n\n        # Calculate the SHA256 hash of the URL content\n        hash_content = sha256(content).digest()\n\n        # Sign the hash with the private key\n        signature = rsa.sign_hash(hash_content, privkey, 'SHA-256')\n\n        # Convert the signature to a hexadecimal string\n        signature_hex = signature.hex()\n\n        return pubkey, signature_hex, hash_content\n\n    except urllib.error.URLError as e:\n        raise ValueError(f\"Error reaching the server: {e}\")\n    except rsa.pkcs1.VerificationError as e:\n        raise rsa.pkcs1.VerificationError(f\"Error signing the hash: {e}\")\n```"}
{"task_id": "BigCodeBench/585", "solution": "import rsa\nimport os\nimport zipfile\nfrom base64 import b64encode\ndef task_func(directory):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Create a zip file\n    zip_filename = \"encrypted_files.zip\"\n    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n        # Iterate over all files in the directory\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            # Read the file data\n            with open(file_path, 'rb') as f:\n                file_data = f.read()\n            # Encrypt the file data\n            encrypted_data = rsa.encrypt(file_data, pubkey)\n            # Add the encrypted data to the zip file\n            zipf.writestr(filename, b64encode(encrypted_data).decode())\n\n    return pubkey, zip_filename", "raw_solution": "import rsa\nimport os\nimport zipfile\nfrom base64 import b64encode\n\ndef task_func(directory):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Create a zip file\n    zip_filename = \"encrypted_files.zip\"\n    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n        # Iterate over all files in the directory\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            # Read the file data\n            with open(file_path, 'rb') as f:\n                file_data = f.read()\n            # Encrypt the file data\n            encrypted_data = rsa.encrypt(file_data, pubkey)\n            # Add the encrypted data to the zip file\n            zipf.writestr(filename, b64encode(encrypted_data).decode())\n\n    return pubkey, zip_filename\n```"}
{"task_id": "BigCodeBench/586", "solution": "import rsa\nfrom cryptography.fernet import Fernet\nfrom base64 import b64encode\nimport os\ndef task_func(file_path):\n    # Generate RSA keys\n    (public_key, private_key) = rsa.newkeys(512)\n\n    # Read file contents\n    with open(file_path, 'rb') as file:\n        file_contents = file.read()\n\n    # Encrypt file contents with Fernet\n    fernet_key = Fernet.generate_key()\n    cipher_suite = Fernet(fernet_key)\n    encrypted_file_contents = cipher_suite.encrypt(file_contents)\n\n    # Encrypt Fernet key with RSA\n    encrypted_fernet_key = rsa.encrypt(fernet_key, public_key)\n\n    # Save encrypted file contents and encrypted Fernet key\n    encrypted_file_path = os.path.splitext(file_path)[0] + \"_encrypted\" + os.path.splitext(file_path)[1]\n    encrypted_key_path = os.path.splitext(file_path)[0] + \"_key_encrypted.key\"\n\n    with open(encrypted_file_path, 'wb') as encrypted_file:\n        encrypted_file.write(encrypted_file_contents)\n\n    with open(encrypted_key_path, 'wb') as encrypted_key:\n        encrypted_key.write(b64encode(encrypted_fernet_key))\n\n    return public_key, encrypted_file_path, encrypted_key_path", "raw_solution": "import rsa\nfrom cryptography.fernet import Fernet\nfrom base64 import b64encode\nimport os\n\ndef task_func(file_path):\n    # Generate RSA keys\n    (public_key, private_key) = rsa.newkeys(512)\n\n    # Read file contents\n    with open(file_path, 'rb') as file:\n        file_contents = file.read()\n\n    # Encrypt file contents with Fernet\n    fernet_key = Fernet.generate_key()\n    cipher_suite = Fernet(fernet_key)\n    encrypted_file_contents = cipher_suite.encrypt(file_contents)\n\n    # Encrypt Fernet key with RSA\n    encrypted_fernet_key = rsa.encrypt(fernet_key, public_key)\n\n    # Save encrypted file contents and encrypted Fernet key\n    encrypted_file_path = os.path.splitext(file_path)[0] + \"_encrypted\" + os.path.splitext(file_path)[1]\n    encrypted_key_path = os.path.splitext(file_path)[0] + \"_key_encrypted.key\"\n\n    with open(encrypted_file_path, 'wb') as encrypted_file:\n        encrypted_file.write(encrypted_file_contents)\n\n    with open(encrypted_key_path, 'wb') as encrypted_key:\n        encrypted_key.write(b64encode(encrypted_fernet_key))\n\n    return public_key, encrypted_file_path, encrypted_key_path\n```"}
{"task_id": "BigCodeBench/587", "solution": "import rsa\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\nfrom base64 import b64encode\ndef task_func(file_path):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # AES Encryption\n    aes_key = os.urandom(32)\n    cipher = Cipher(algorithms.AES(aes_key), modes.CBC())\n    encryptor = cipher.encryptor()\n\n    with open(file_path, 'rb') as file:\n        plaintext = file.read()\n\n    padder = padding.PKCS7(128).padder()\n    padded_data = padder.update(plaintext) + padder.finalize()\n\n    cipher_text = encryptor.update(padded_data) + encryptor.finalize()\n\n    # Save encrypted file\n    encrypted_file_name = \"encrypted_file.bin\"\n    with open(encrypted_file_name, 'wb') as file:\n        file.write(cipher_text)\n\n    # Encrypt AES key with RSA\n    encrypted_aes_key = rsa.encrypt(aes_key, pubkey)\n\n    # Save encrypted AES key\n    encrypted_aes_key_file_name = \"encrypted_aes_key.bin\"\n    with open(encrypted_aes_key_file_name, 'wb') as file:\n        file.write(encrypted_aes_key)\n\n    return pubkey, encrypted_file_name, encrypted_aes_key_file_name", "raw_solution": "import rsa\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\nfrom base64 import b64encode\n\ndef task_func(file_path):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # AES Encryption\n    aes_key = os.urandom(32)\n    cipher = Cipher(algorithms.AES(aes_key), modes.CBC())\n    encryptor = cipher.encryptor()\n\n    with open(file_path, 'rb') as file:\n        plaintext = file.read()\n\n    padder = padding.PKCS7(128).padder()\n    padded_data = padder.update(plaintext) + padder.finalize()\n\n    cipher_text = encryptor.update(padded_data) + encryptor.finalize()\n\n    # Save encrypted file\n    encrypted_file_name = \"encrypted_file.bin\"\n    with open(encrypted_file_name, 'wb') as file:\n        file.write(cipher_text)\n\n    # Encrypt AES key with RSA\n    encrypted_aes_key = rsa.encrypt(aes_key, pubkey)\n\n    # Save encrypted AES key\n    encrypted_aes_key_file_name = \"encrypted_aes_key.bin\"\n    with open(encrypted_aes_key_file_name, 'wb') as file:\n        file.write(encrypted_aes_key)\n\n    return pubkey, encrypted_file_name, encrypted_aes_key_file_name\n```"}
{"task_id": "BigCodeBench/588", "solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nRANGE = 100\nSIZE = 1000\ndef task_func():\n    # Generate a DataFrame with 'X' and 'Y' columns filled with random integers within the specified range\n    df = pd.DataFrame({\n        'X': np.random.randint(0, RANGE, SIZE),\n        'Y': np.random.randint(0, RANGE, SIZE)\n    })\n\n    # Plot the points using a scatter plot\n    sns.scatterplot(x='X', y='Y', data=df)\n    plt.show()\n\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Constants defining the range of random integers and the size of the DataFrame\nRANGE = 100\nSIZE = 1000\n\ndef task_func():\n    # Generate a DataFrame with 'X' and 'Y' columns filled with random integers within the specified range\n    df = pd.DataFrame({\n        'X': np.random.randint(0, RANGE, SIZE),\n        'Y': np.random.randint(0, RANGE, SIZE)\n    })\n\n    # Plot the points using a scatter plot\n    sns.scatterplot(x='X', y='Y', data=df)\n    plt.show()\n\n    return df\n```"}
{"task_id": "BigCodeBench/589", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.cluster import KMeans\nRANGE = 100\nSIZE = 1000\nCLUSTERS = 5\ndef task_func():\n    # Generate random data points\n    data = np.random.rand(SIZE, 2) * RANGE\n\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=CLUSTERS, random_state=0).fit(data)\n\n    # Plot the clustered points\n    plt.scatter(data[:, 0], data[:, 1], c=kmeans.labels_)\n    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='X', color='red')\n    plt.show()\n\n    return data, kmeans", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\n# Constants for configuration\nRANGE = 100\nSIZE = 1000\nCLUSTERS = 5\n\ndef task_func():\n    # Generate random data points\n    data = np.random.rand(SIZE, 2) * RANGE\n\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=CLUSTERS, random_state=0).fit(data)\n\n    # Plot the clustered points\n    plt.scatter(data[:, 0], data[:, 1], c=kmeans.labels_)\n    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='X', color='red')\n    plt.show()\n\n    return data, kmeans\n```"}
{"task_id": "BigCodeBench/590", "solution": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\ndef task_func(url):\n    if not url:\n        raise ValueError(\"URL is invalid or empty\")\n    try:\n        response = urllib.request.urlopen(url)\n    except urllib.error.URLError as e:\n        raise urllib.error.URLError(\"Network connectivity or server issue\") from e\n    html = response.read().decode('utf-8')\n    doc = pq(html)\n    data = []\n    for tag in doc('a'):\n        text = tag.text\n        href = tag.attrib['href']\n        data.append({'text': text, 'href': href, 'fetch_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n    return pd.DataFrame(data)", "raw_solution": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\n\ndef task_func(url):\n    if not url:\n        raise ValueError(\"URL is invalid or empty\")\n    try:\n        response = urllib.request.urlopen(url)\n    except urllib.error.URLError as e:\n        raise urllib.error.URLError(\"Network connectivity or server issue\") from e\n    html = response.read().decode('utf-8')\n    doc = pq(html)\n    data = []\n    for tag in doc('a'):\n        text = tag.text\n        href = tag.attrib['href']\n        data.append({'text': text, 'href': href, 'fetch_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/591", "solution": "from datetime import datetime, timedelta\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nTEMP_CATEGORIES = ['Cold', 'Normal', 'Hot']\nFILE_PATH = 'custom_data.csv'\ndef task_func(hours, file_path=FILE_PATH):\n    data = []\n    for i in range(hours):\n        temp = randint(0, 100)\n        category = TEMP_CATEGORIES[0] if temp < 30 else TEMP_CATEGORIES[1] if temp < 70 else TEMP_CATEGORIES[2]\n        data.append({'Time': (datetime.now() + timedelta(hours=i)).strftime('%Y-%m-%d %H:%M:%S'), 'Temperature': temp, 'Category': category})\n\n    df = pd.DataFrame(data)\n    df.to_csv(file_path, index=False)\n\n    fig, ax = plt.subplots()\n    ax.plot(df['Time'], df['Temperature'])\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Temperature')\n    ax.set_title('Temperature over Time')\n\n    return file_path, ax", "raw_solution": "from datetime import datetime, timedelta\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nTEMP_CATEGORIES = ['Cold', 'Normal', 'Hot']\nFILE_PATH = 'custom_data.csv'\n\ndef task_func(hours, file_path=FILE_PATH):\n    data = []\n    for i in range(hours):\n        temp = randint(0, 100)\n        category = TEMP_CATEGORIES[0] if temp < 30 else TEMP_CATEGORIES[1] if temp < 70 else TEMP_CATEGORIES[2]\n        data.append({'Time': (datetime.now() + timedelta(hours=i)).strftime('%Y-%m-%d %H:%M:%S'), 'Temperature': temp, 'Category': category})\n\n    df = pd.DataFrame(data)\n    df.to_csv(file_path, index=False)\n\n    fig, ax = plt.subplots()\n    ax.plot(df['Time'], df['Temperature'])\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Temperature')\n    ax.set_title('Temperature over Time')\n\n    return file_path, ax\n```"}
{"task_id": "BigCodeBench/592", "solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    file_path = os.path.join(output_dir, 'sensor_data.csv')\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Time', 'Temperature', 'Humidity', 'Pressure'])\n\n        start_time = datetime.now()\n        for _ in range(hours):\n            for sensor in SENSORS:\n                data = [start_time.strftime('%Y-%m-%d %H:%M:%S'), randint(10, 30), randint(20, 80), randint(900, 1100)]\n                writer.writerow(data)\n            start_time += timedelta(hours=1)", "raw_solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\n\n# Constants\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    file_path = os.path.join(output_dir, 'sensor_data.csv')\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Time', 'Temperature', 'Humidity', 'Pressure'])\n\n        start_time = datetime.now()\n        for _ in range(hours):\n            for sensor in SENSORS:\n                data = [start_time.strftime('%Y-%m-%d %H:%M:%S'), randint(10, 30), randint(20, 80), randint(900, 1100)]\n                writer.writerow(data)\n            start_time += timedelta(hours=1)\n```"}
{"task_id": "BigCodeBench/593", "solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Generate traffic data\n    traffic_data = []\n    for i in range(hours):\n        traffic_count = {vehicle_type: randint(1, 100) for vehicle_type in VEHICLE_TYPES}\n        traffic_data.append({'Time': datetime.now() + timedelta(hours=i), **traffic_count})\n\n    # Save traffic data to CSV file\n    csv_file_path = os.path.join(output_dir, 'traffic_data.csv')\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        csv_writer = csv.DictWriter(csv_file, fieldnames=['Time', *VEHICLE_TYPES])\n        csv_writer.writeheader()\n        for data in traffic_data:\n            csv_writer.writerow(data)\n\n    # Load traffic data from CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Plot traffic data\n    fig, ax = plt.subplots()\n    for vehicle_type in VEHICLE_TYPES:\n        ax.plot(df['Time'], df[vehicle_type], label=vehicle_type)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Vehicle Count')\n    ax.legend()\n\n    return csv_file_path, ax", "raw_solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Generate traffic data\n    traffic_data = []\n    for i in range(hours):\n        traffic_count = {vehicle_type: randint(1, 100) for vehicle_type in VEHICLE_TYPES}\n        traffic_data.append({'Time': datetime.now() + timedelta(hours=i), **traffic_count})\n\n    # Save traffic data to CSV file\n    csv_file_path = os.path.join(output_dir, 'traffic_data.csv')\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        csv_writer = csv.DictWriter(csv_file, fieldnames=['Time', *VEHICLE_TYPES])\n        csv_writer.writeheader()\n        for data in traffic_data:\n            csv_writer.writerow(data)\n\n    # Load traffic data from CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Plot traffic data\n    fig, ax = plt.subplots()\n    for vehicle_type in VEHICLE_TYPES:\n        ax.plot(df['Time'], df[vehicle_type], label=vehicle_type)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Vehicle Count')\n    ax.legend()\n\n    return csv_file_path, ax\n```"}
{"task_id": "BigCodeBench/594", "solution": "import csv\nimport os\nimport shutil\nfrom datetime import datetime, timedelta\nfrom random import randint\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Generate weather data\n    weather_data = []\n    current_time = datetime.now()\n    for i in range(hours):\n        time = current_time + timedelta(hours=i)\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS)-1)]\n        weather_data.append([time.strftime('%Y-%m-%d %H:%M:%S'), condition])\n\n    # Save weather data to CSV file\n    csv_file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow(['Time', 'Condition'])\n        writer.writerows(weather_data)\n\n    # Back up the CSV file to a backup directory\n    backup_dir = os.path.join(output_dir, 'backup')\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n    backup_file_path = os.path.join(backup_dir, 'weather_data.csv')\n    shutil.copy(csv_file_path, backup_file_path)\n\n    return csv_file_path", "raw_solution": "import csv\nimport os\nimport shutil\nfrom datetime import datetime, timedelta\nfrom random import randint\n\n# Constants\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Generate weather data\n    weather_data = []\n    current_time = datetime.now()\n    for i in range(hours):\n        time = current_time + timedelta(hours=i)\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS)-1)]\n        weather_data.append([time.strftime('%Y-%m-%d %H:%M:%S'), condition])\n\n    # Save weather data to CSV file\n    csv_file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow(['Time', 'Condition'])\n        writer.writerows(weather_data)\n\n    # Back up the CSV file to a backup directory\n    backup_dir = os.path.join(output_dir, 'backup')\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n    backup_file_path = os.path.join(backup_dir, 'weather_data.csv')\n    shutil.copy(csv_file_path, backup_file_path)\n\n    return csv_file_path\n```"}
{"task_id": "BigCodeBench/595", "solution": "import random\nimport bisect\nfrom array import array\ndef task_func(n=10, total=100):\n    while True:\n        numbers = [random.randint(1, total) for _ in range(n-1)]\n        numbers.sort()\n        insert_position = bisect.bisect(numbers, random.randint(1, total))\n        if sum(numbers[:insert_position]) + sum(numbers[insert_position:]) == total:\n            return (numbers, insert_position)", "raw_solution": "import random\nimport bisect\nfrom array import array\n\ndef task_func(n=10, total=100):\n    while True:\n        numbers = [random.randint(1, total) for _ in range(n-1)]\n        numbers.sort()\n        insert_position = bisect.bisect(numbers, random.randint(1, total))\n        if sum(numbers[:insert_position]) + sum(numbers[insert_position:]) == total:\n            return (numbers, insert_position)\n```"}
{"task_id": "BigCodeBench/596", "solution": "import time\nfrom datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\ndef task_func(duration):\n    timestamps = []\n    values = []\n    start_time = time.time()\n    while time.time() - start_time < duration:\n        timestamp = datetime.now().strftime('%H:%M:%S.%f')\n        value = randint(1, 100)\n        timestamps.append(timestamp)\n        values.append(value)\n        time.sleep(0.1)\n    return (timestamps, values)", "raw_solution": "import time\nfrom datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\n\ndef task_func(duration):\n    timestamps = []\n    values = []\n    start_time = time.time()\n    while time.time() - start_time < duration:\n        timestamp = datetime.now().strftime('%H:%M:%S.%f')\n        value = randint(1, 100)\n        timestamps.append(timestamp)\n        values.append(value)\n        time.sleep(0.1)\n    return (timestamps, values)\n```"}
{"task_id": "BigCodeBench/597", "solution": "import pandas as pd\nimport time\ndef task_func(data, letter):\n    df = pd.DataFrame(data)\n    filtered_df = df[df['Name'].str.startswith(letter)]\n    return filtered_df['Name']", "raw_solution": "import pandas as pd\nimport time\n# Constants\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\ndef task_func(data, letter):\n    df = pd.DataFrame(data)\n    filtered_df = df[df['Name'].str.startswith(letter)]\n    return filtered_df['Name']\n```"}
{"task_id": "BigCodeBench/598", "solution": "import pandas as pd\nimport time\ndef task_func(df, letter):\n    df = pd.DataFrame(df)\n    df = df[df['Word'].str.startswith(letter)]\n    word_lengths = df['Word'].str.len()\n    word_length_counts = word_lengths.value_counts().to_dict()\n    return word_length_counts", "raw_solution": "import pandas as pd\nimport time\ndef task_func(df, letter):\n    df = pd.DataFrame(df)\n    df = df[df['Word'].str.startswith(letter)]\n    word_lengths = df['Word'].str.len()\n    word_length_counts = word_lengths.value_counts().to_dict()\n    return word_length_counts\n```"}
{"task_id": "BigCodeBench/599", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, letter):\n    # Filter rows where 'Word' column values start with the specified letter\n    filtered_df = df[df['Word'].str.startswith(letter)]\n    \n    # Calculate the lengths of the words\n    filtered_df['Length'] = filtered_df['Word'].str.len()\n    \n    # Plot a histogram of the word lengths\n    plt.hist(filtered_df['Length'], bins=10, edgecolor='black')\n    plt.xlabel('Word Length')\n    plt.ylabel('Frequency')\n    plt.title(f'Histogram of Word Lengths for Words Starting with {letter}')\n    plt.show()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, letter):\n    # Filter rows where 'Word' column values start with the specified letter\n    filtered_df = df[df['Word'].str.startswith(letter)]\n    \n    # Calculate the lengths of the words\n    filtered_df['Length'] = filtered_df['Word'].str.len()\n    \n    # Plot a histogram of the word lengths\n    plt.hist(filtered_df['Length'], bins=10, edgecolor='black')\n    plt.xlabel('Word Length')\n    plt.ylabel('Frequency')\n    plt.title(f'Histogram of Word Lengths for Words Starting with {letter}')\n    plt.show()\n```"}
{"task_id": "BigCodeBench/600", "solution": "import numpy as np\nimport pandas as pd\nfrom scipy import stats\ndef task_func(df, letter):\n    df = pd.DataFrame(df)\n    df = df[df['Word'].str.startswith(letter)]\n    df['length'] = df['Word'].apply(len)\n    mean = df['length'].mean()\n    median = df['length'].median()\n    mode = stats.mode(df['length'])[0][0]\n    return {'mean': mean, 'median': median, 'mode': mode}", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndef task_func(df, letter):\n    df = pd.DataFrame(df)\n    df = df[df['Word'].str.startswith(letter)]\n    df['length'] = df['Word'].apply(len)\n    mean = df['length'].mean()\n    median = df['length'].median()\n    mode = stats.mode(df['length'])[0][0]\n    return {'mean': mean, 'median': median, 'mode': mode}\n```"}
{"task_id": "BigCodeBench/601", "solution": "import seaborn as sns\nimport time\ndef task_func(df, letter):\n    if df.empty or 'Word' not in df.columns:\n        return None\n    df = df[df['Word'].str.startswith(letter)]\n    df['length'] = df['Word'].apply(len)\n    return sns.boxplot(x=df['length'])", "raw_solution": "import seaborn as sns\nimport time\ndef task_func(df, letter):\n    if df.empty or 'Word' not in df.columns:\n        return None\n    df = df[df['Word'].str.startswith(letter)]\n    df['length'] = df['Word'].apply(len)\n    return sns.boxplot(x=df['length'])\n```"}
{"task_id": "BigCodeBench/602", "solution": "import numpy as np\nimport pandas as pd\nimport string\nLETTERS = list(string.ascii_lowercase)\nOUTPUT_DIR = './output'\ndef task_func(file_path, output_dir=OUTPUT_DIR):\n    # Generate a 2D matrix with random lowercase letters\n    matrix = np.random.choice(LETTERS, size=(10, 10))\n\n    # Convert the matrix to a DataFrame\n    df = pd.DataFrame(matrix)\n\n    # Write the DataFrame to a CSV file\n    df.to_csv(f'{output_dir}/{file_path}', index=False)", "raw_solution": "import numpy as np\nimport pandas as pd\nimport string\n\n# Constants\nLETTERS = list(string.ascii_lowercase)\nOUTPUT_DIR = './output'\n\ndef task_func(file_path, output_dir=OUTPUT_DIR):\n    # Generate a 2D matrix with random lowercase letters\n    matrix = np.random.choice(LETTERS, size=(10, 10))\n\n    # Convert the matrix to a DataFrame\n    df = pd.DataFrame(matrix)\n\n    # Write the DataFrame to a CSV file\n    df.to_csv(f'{output_dir}/{file_path}', index=False)\n```"}
{"task_id": "BigCodeBench/603", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(matrix1, matrix2):\n    df = pd.DataFrame(np.concatenate((matrix1, matrix2), axis=1))\n    return df.to_string(index=False, header=False)", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(matrix1, matrix2):\n    df = pd.DataFrame(np.concatenate((matrix1, matrix2), axis=1))\n    return df.to_string(index=False, header=False)\n```"}
{"task_id": "BigCodeBench/604", "solution": "import subprocess\nimport logging\ndef task_func(filepath):\n    try:\n        subprocess.run([\"g++\", filepath, \"-o\", \"output\"], check=True, stderr=subprocess.PIPE)\n        logging.info(\"Compilation successful\")\n    except subprocess.CalledProcessError as e:\n        logging.error(f\"Compilation failed: {e.output.decode()}\")\n    except FileNotFoundError:\n        logging.error(f\"File not found: {filepath}\")", "raw_solution": "import subprocess\nimport logging\n\ndef task_func(filepath):\n    try:\n        subprocess.run([\"g++\", filepath, \"-o\", \"output\"], check=True, stderr=subprocess.PIPE)\n        logging.info(\"Compilation successful\")\n    except subprocess.CalledProcessError as e:\n        logging.error(f\"Compilation failed: {e.output.decode()}\")\n    except FileNotFoundError:\n        logging.error(f\"File not found: {filepath}\")\n```"}
{"task_id": "BigCodeBench/605", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(matrix):\n    df = pd.DataFrame(matrix)\n    fig, ax = plt.subplots()\n    cax = ax.matshow(df, interpolation='nearest', cmap='hot')\n    fig.colorbar(cax)\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(matrix):\n    df = pd.DataFrame(matrix)\n    fig, ax = plt.subplots()\n    cax = ax.matshow(df, interpolation='nearest', cmap='hot')\n    fig.colorbar(cax)\n    return ax\n```"}
{"task_id": "BigCodeBench/606", "solution": "import pandas as pd\nfrom scipy import stats\ndef task_func(matrix):\n    df = pd.DataFrame(matrix)\n    df_normalized = (df - df.mean()) / df.std()\n    return df_normalized", "raw_solution": "import pandas as pd\nfrom scipy import stats\n\ndef task_func(matrix):\n    df = pd.DataFrame(matrix)\n    df_normalized = (df - df.mean()) / df.std()\n    return df_normalized\n```"}
{"task_id": "BigCodeBench/607", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import sample\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows based on column values\n    for tup in tuples:\n        df = df[~(df[tup[0]] == tup[1])]\n\n    # Generate random scatter plots\n    axes = []\n    for i in range(n_plots):\n        # Select random columns\n        columns = sample(list(df.columns), 2)\n        # Create scatter plot\n        ax = df.plot(kind='scatter', x=columns[0], y=columns[1], alpha=0.5)\n        axes.append(ax)\n\n    return df, axes", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import sample\n\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows based on column values\n    for tup in tuples:\n        df = df[~(df[tup[0]] == tup[1])]\n\n    # Generate random scatter plots\n    axes = []\n    for i in range(n_plots):\n        # Select random columns\n        columns = sample(list(df.columns), 2)\n        # Create scatter plot\n        ax = df.plot(kind='scatter', x=columns[0], y=columns[1], alpha=0.5)\n        axes.append(ax)\n\n    return df, axes\n```"}
{"task_id": "BigCodeBench/608", "solution": "import seaborn as sns\nfrom random import sample\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    for col, val in tuples:\n        df = df[df[col] != val]\n\n    # Generate n random pairs of two columns against each other\n    pairs = sample(COLUMNS, n_plots)\n    pairplots = []\n    for i in range(0, len(pairs), 2):\n        pairplot = sns.pairplot(df, vars=[pairs[i], pairs[i+1]])\n        pairplots.append(pairplot)\n\n    return df, pairplots", "raw_solution": "import seaborn as sns\nfrom random import sample\n\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    for col, val in tuples:\n        df = df[df[col] != val]\n\n    # Generate n random pairs of two columns against each other\n    pairs = sample(COLUMNS, n_plots)\n    pairplots = []\n    for i in range(0, len(pairs), 2):\n        pairplot = sns.pairplot(df, vars=[pairs[i], pairs[i+1]])\n        pairplots.append(pairplot)\n\n    return df, pairplots\n```"}
{"task_id": "BigCodeBench/609", "solution": "from itertools import combinations\nfrom random import sample\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on tuples\n    for tup in tuples:\n        df = df[~(df[tup[0]] == tup[1])]\n\n    # Generate scatter plots\n    plots = []\n    if n_plots > len(df.columns)**2:\n        n_plots = len(df.columns)**2\n    for _ in range(n_plots):\n        cols = sample(list(df.columns), 2)\n        plt.figure(figsize=(5, 5))\n        plt.scatter(df[cols[0]], df[cols[1]])\n        plt.xlabel(cols[0])\n        plt.ylabel(cols[1])\n        plots.append(((cols[0], cols[1]), plt.gcf()))\n\n    return df, plots", "raw_solution": "from itertools import combinations\nfrom random import sample\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on tuples\n    for tup in tuples:\n        df = df[~(df[tup[0]] == tup[1])]\n\n    # Generate scatter plots\n    plots = []\n    if n_plots > len(df.columns)**2:\n        n_plots = len(df.columns)**2\n    for _ in range(n_plots):\n        cols = sample(list(df.columns), 2)\n        plt.figure(figsize=(5, 5))\n        plt.scatter(df[cols[0]], df[cols[1]])\n        plt.xlabel(cols[0])\n        plt.ylabel(cols[1])\n        plots.append(((cols[0], cols[1]), plt.gcf()))\n\n    return df, plots\n```"}
{"task_id": "BigCodeBench/610", "solution": "from random import sample\nimport seaborn as sns\nimport pandas as pd\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows based on values of multiple columns\n    for tup in tuples:\n        df = df[~df[tup[0]].between(tup[1], tup[2])]\n\n    # Create n random joint plots\n    plots = []\n    if not df.empty:\n        for _ in range(n_plots):\n            col1, col2 = sample(COLUMNS, 2)\n            joint_grid = sns.jointplot(x=col1, y=col2, data=df)\n            plots.append(joint_grid)\n\n    return df, plots", "raw_solution": "from random import sample\nimport seaborn as sns\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows based on values of multiple columns\n    for tup in tuples:\n        df = df[~df[tup[0]].between(tup[1], tup[2])]\n\n    # Create n random joint plots\n    plots = []\n    if not df.empty:\n        for _ in range(n_plots):\n            col1, col2 = sample(COLUMNS, 2)\n            joint_grid = sns.jointplot(x=col1, y=col2, data=df)\n            plots.append(joint_grid)\n\n    return df, plots\n```"}
{"task_id": "BigCodeBench/611", "solution": "from random import sample\nimport matplotlib.pyplot as plt\nimport pandas as pd\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    for tup in tuples:\n        df = df[~df[tup[0]].isin(tup[1])]\n\n    # Create n random line plots of two columns against each other\n    plot_details = []\n    for _ in range(n_plots):\n        col1, col2 = sample(COLUMNS, 2)\n        plot_details.append((col1, col2))\n\n    return df, plot_details", "raw_solution": "from random import sample\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    for tup in tuples:\n        df = df[~df[tup[0]].isin(tup[1])]\n\n    # Create n random line plots of two columns against each other\n    plot_details = []\n    for _ in range(n_plots):\n        col1, col2 = sample(COLUMNS, 2)\n        plot_details.append((col1, col2))\n\n    return df, plot_details\n```"}
{"task_id": "BigCodeBench/612", "solution": "from random import choice\nimport numpy as np\nimport pandas as pd\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTIES_COSTS = [100, 200, 300, 400, 500]\ndef task_func(goals, penalties, teams=TEAMS, penalties_costs=PENALTIES_COSTS):\n    df = pd.DataFrame({'Team': teams, 'Goals': goals, 'Penalties': penalties})\n    df['Penalties Cost'] = df['Penalties'].apply(lambda x: choice(penalties_costs) * x)\n    df['Performance Score'] = df['Goals'] - df['Penalties']\n    df['Performance Score'] = df['Performance Score'].apply(lambda x: x if x > 0 else 0)\n    return df", "raw_solution": "from random import choice\nimport numpy as np\nimport pandas as pd\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTIES_COSTS = [100, 200, 300, 400, 500]\ndef task_func(goals, penalties, teams=TEAMS, penalties_costs=PENALTIES_COSTS):\n    df = pd.DataFrame({'Team': teams, 'Goals': goals, 'Penalties': penalties})\n    df['Penalties Cost'] = df['Penalties'].apply(lambda x: choice(penalties_costs) * x)\n    df['Performance Score'] = df['Goals'] - df['Penalties']\n    df['Performance Score'] = df['Performance Score'].apply(lambda x: x if x > 0 else 0)\n    return df\n```"}
{"task_id": "BigCodeBench/613", "solution": "import pandas as pd\nfrom matplotlib import pyplot as plt\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\ndef task_func(goals, penalties):\n    # Calculate net scores\n    net_scores = [goals[i] - penalties[i] for i in range(len(goals))]\n    # Clip scores to stay within -10 to 10\n    net_scores = [max(min(score, 10), -10) for score in net_scores]\n    # Create DataFrame\n    df = pd.DataFrame({'Team': TEAMS, 'Score': net_scores})\n    # Visualize results\n    plt.bar(df['Team'], df['Score'])\n    plt.xlabel('Team')\n    plt.ylabel('Score')\n    plt.title('Team Scores')\n    plt.show()\n    return df", "raw_solution": "import pandas as pd\nfrom matplotlib import pyplot as plt\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nGOALS_RANGE = (-10, 10)\n\ndef task_func(goals, penalties):\n    # Calculate net scores\n    net_scores = [goals[i] - penalties[i] for i in range(len(goals))]\n    # Clip scores to stay within -10 to 10\n    net_scores = [max(min(score, 10), -10) for score in net_scores]\n    # Create DataFrame\n    df = pd.DataFrame({'Team': TEAMS, 'Score': net_scores})\n    # Visualize results\n    plt.bar(df['Team'], df['Score'])\n    plt.xlabel('Team')\n    plt.ylabel('Score')\n    plt.title('Team Scores')\n    plt.show()\n    return df\n```"}
{"task_id": "BigCodeBench/614", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(goals, penalties):\n    df = pd.DataFrame({'Team': range(1, len(goals) + 1), 'Goals': goals, 'Penalties': penalties})\n    pairplot = sns.pairplot(df, hue='Team')\n    return df, pairplot", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(goals, penalties):\n    df = pd.DataFrame({'Team': range(1, len(goals) + 1), 'Goals': goals, 'Penalties': penalties})\n    pairplot = sns.pairplot(df, hue='Team')\n    return df, pairplot\n```"}
{"task_id": "BigCodeBench/615", "solution": "from random import randint, seed\nimport pandas as pd\ndef task_func(goals, penalties, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    teams = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\n    results = []\n    for team in teams:\n        team_goals = sum(randint(0, goals) for _ in range(10))\n        team_penalties = sum(randint(0, penalties) for _ in range(3))\n        team_fines = team_penalties * 10\n        results.append({'Team': team, 'Match Result': f'{team_goals} goals, {team_fines} fines'})\n    return pd.DataFrame(results)", "raw_solution": "from random import randint, seed\nimport pandas as pd\n\ndef task_func(goals, penalties, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    teams = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\n    results = []\n    for team in teams:\n        team_goals = sum(randint(0, goals) for _ in range(10))\n        team_penalties = sum(randint(0, penalties) for _ in range(3))\n        team_fines = team_penalties * 10\n        results.append({'Team': team, 'Match Result': f'{team_goals} goals, {team_fines} fines'})\n    return pd.DataFrame(results)\n```"}
{"task_id": "BigCodeBench/616", "solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties, teams=TEAMS, penalty_cost=PENALTY_COST, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    data = {'Team': teams, 'Goals': [randint(0, 5) for _ in teams], 'Penalty Cost': [randint(0, 5) for _ in teams]}\n    df = pd.DataFrame(data)\n    df['Penalty Cost'] = df['Penalty Cost'] * penalty_cost\n    ax = df.plot(x='Team', y=['Goals', 'Penalty Cost'], kind='bar', ax=plt.gca())\n    ax.set_xlabel('Team')\n    ax.set_ylabel('Score')\n    ax.legend(['Goals', 'Penalty Cost'])\n    return df, ax", "raw_solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants (they can be overridden with default parameters)\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties, teams=TEAMS, penalty_cost=PENALTY_COST, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    data = {'Team': teams, 'Goals': [randint(0, 5) for _ in teams], 'Penalty Cost': [randint(0, 5) for _ in teams]}\n    df = pd.DataFrame(data)\n    df['Penalty Cost'] = df['Penalty Cost'] * penalty_cost\n    ax = df.plot(x='Team', y=['Goals', 'Penalty Cost'], kind='bar', ax=plt.gca())\n    ax.set_xlabel('Team')\n    ax.set_ylabel('Score')\n    ax.legend(['Goals', 'Penalty Cost'])\n    return df, ax\n```"}
{"task_id": "BigCodeBench/617", "solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport re\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties, rng_seed=None, teams=TEAMS):\n    if rng_seed is not None:\n        seed(rng_seed)\n    data = []\n    for team in teams:\n        team_goals = sum(randint(0, 5) for _ in range(goals))\n        team_penalties = sum(randint(0, 5) for _ in range(penalties))\n        team_fines = team_penalties * PENALTY_COST\n        data.append({'Team': team, 'Goals': team_goals, 'Penalty Cost': team_fines})\n    df = pd.DataFrame(data)\n    return df", "raw_solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport re\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\ndef task_func(goals, penalties, rng_seed=None, teams=TEAMS):\n    if rng_seed is not None:\n        seed(rng_seed)\n    data = []\n    for team in teams:\n        team_goals = sum(randint(0, 5) for _ in range(goals))\n        team_penalties = sum(randint(0, 5) for _ in range(penalties))\n        team_fines = team_penalties * PENALTY_COST\n        data.append({'Team': team, 'Goals': team_goals, 'Penalty Cost': team_fines})\n    df = pd.DataFrame(data)\n    return df\n```"}
{"task_id": "BigCodeBench/618", "solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties):\n    # Generate random data\n    data = {\n        'Team': [TEAMS[randint(0, len(TEAMS) - 1)] for _ in range(goals + penalties)],\n        'Goals': [randint(0, 5) for _ in range(goals)],\n        'Penalty Cost': [randint(1, 3) * PENALTY_COST for _ in range(penalties)]\n    }\n    df = pd.DataFrame(data)\n\n    # Calculate total cost\n    df['Total Cost'] = df['Goals'] * 1000 + df['Penalty Cost']\n\n    # Plotting\n    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n\n    # Plot for goals\n    sns.barplot(x='Team', y='Goals', data=df, ax=axes[0])\n    axes[0].set_title('Goals per Team')\n\n    # Plot for penalty costs\n    sns.barplot(x='Team', y='Penalty Cost', data=df, ax=axes[1])\n    axes[1].set_title('Penalty Costs per Team')\n\n    plt.tight_layout()\n    plt.show()\n\n    return df, axes", "raw_solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties):\n    # Generate random data\n    data = {\n        'Team': [TEAMS[randint(0, len(TEAMS) - 1)] for _ in range(goals + penalties)],\n        'Goals': [randint(0, 5) for _ in range(goals)],\n        'Penalty Cost': [randint(1, 3) * PENALTY_COST for _ in range(penalties)]\n    }\n    df = pd.DataFrame(data)\n\n    # Calculate total cost\n    df['Total Cost'] = df['Goals'] * 1000 + df['Penalty Cost']\n\n    # Plotting\n    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n\n    # Plot for goals\n    sns.barplot(x='Team', y='Goals', data=df, ax=axes[0])\n    axes[0].set_title('Goals per Team')\n\n    # Plot for penalty costs\n    sns.barplot(x='Team', y='Penalty Cost', data=df, ax=axes[1])\n    axes[1].set_title('Penalty Costs per Team')\n\n    plt.tight_layout()\n    plt.show()\n\n    return df, axes\n```"}
{"task_id": "BigCodeBench/619", "solution": "from random import randint, seed\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    data = []\n    for team in TEAMS:\n        for _ in range(goals):\n            data.append({\n                'Team': team,\n                'Goals': randint(0, 10),\n                'Penalty Cost': randint(0, PENALTY_COST)\n            })\n    df = pd.DataFrame(data)\n    X = df[['Goals']]\n    y = df['Penalty Cost']\n    model = LinearRegression()\n    model.fit(X, y)\n    return df, model", "raw_solution": "from random import randint, seed\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    data = []\n    for team in TEAMS:\n        for _ in range(goals):\n            data.append({\n                'Team': team,\n                'Goals': randint(0, 10),\n                'Penalty Cost': randint(0, PENALTY_COST)\n            })\n    df = pd.DataFrame(data)\n    X = df[['Goals']]\n    y = df['Penalty Cost']\n    model = LinearRegression()\n    model.fit(X, y)\n    return df, model\n```"}
{"task_id": "BigCodeBench/620", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(L):\n    df = pd.DataFrame(np.random.randint(1, 100, size=(np.prod(L), np.prod(L))))\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(L):\n    df = pd.DataFrame(np.random.randint(1, 100, size=(np.prod(L), np.prod(L))))\n    return df\n```"}
{"task_id": "BigCodeBench/621", "solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n\n    # Convert the list to a numpy array\n    arr = np.array(flat_list).reshape(-1, 1)\n\n    # Standardize the values\n    scaler = StandardScaler()\n    arr_standardized = scaler.fit_transform(arr)\n\n    # Plot the standardized values\n    plt.plot(arr_standardized)\n    plt.xlabel('Index')\n    plt.ylabel('Standardized Value')\n    plt.title('Standardized Values Plot')\n    plt.grid(True)\n    return plt.gca()", "raw_solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n\n    # Convert the list to a numpy array\n    arr = np.array(flat_list).reshape(-1, 1)\n\n    # Standardize the values\n    scaler = StandardScaler()\n    arr_standardized = scaler.fit_transform(arr)\n\n    # Plot the standardized values\n    plt.plot(arr_standardized)\n    plt.xlabel('Index')\n    plt.ylabel('Standardized Value')\n    plt.title('Standardized Values Plot')\n    plt.grid(True)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/622", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import norm\nfrom itertools import chain\ndef task_func(L):\n    flat_list = list(chain(*L))\n    mean, std = norm.fit(flat_list)\n    plt.hist(flat_list, bins=20, density=True)\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mean, std)\n    plt.plot(x, p, 'k', linewidth=2)\n    return plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import norm\nfrom itertools import chain\n\ndef task_func(L):\n    flat_list = list(chain(*L))\n    mean, std = norm.fit(flat_list)\n    plt.hist(flat_list, bins=20, density=True)\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mean, std)\n    plt.plot(x, p, 'k', linewidth=2)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/623", "solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n    # Convert the flattened list to a numpy array\n    data = np.array(flat_list).reshape(-1, 1)\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=3)\n    kmeans.fit(data)\n    # Create a scatter plot with data points color-coded by their cluster\n    fig, ax = plt.subplots()\n    ax.scatter(data, np.zeros_like(data), c=kmeans.labels_)\n    return ax", "raw_solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n    # Convert the flattened list to a numpy array\n    data = np.array(flat_list).reshape(-1, 1)\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=3)\n    kmeans.fit(data)\n    # Create a scatter plot with data points color-coded by their cluster\n    fig, ax = plt.subplots()\n    ax.scatter(data, np.zeros_like(data), c=kmeans.labels_)\n    return ax\n```"}
{"task_id": "BigCodeBench/624", "solution": "from sklearn.decomposition import PCA\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(L):\n    # Convert list of lists to numpy array\n    data = np.array(L)\n\n    # Apply PCA\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(data)\n\n    # Create scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1])\n    ax.set_xlabel('PC 1')\n    ax.set_ylabel('PC 2')\n    ax.set_title('PCA Scatter Plot')\n\n    return pca_result, ax", "raw_solution": "from sklearn.decomposition import PCA\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    # Convert list of lists to numpy array\n    data = np.array(L)\n\n    # Apply PCA\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(data)\n\n    # Create scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1])\n    ax.set_xlabel('PC 1')\n    ax.set_ylabel('PC 2')\n    ax.set_title('PCA Scatter Plot')\n\n    return pca_result, ax\n```"}
{"task_id": "BigCodeBench/625", "solution": "import math\nfrom random import randint\nimport pandas as pd\ndef task_func(cities_list):\n    population_data = []\n    for city in cities_list:\n        population = randint(1, 1000000)\n        population_data.append({'City': city, 'Population': population})\n    df = pd.DataFrame(population_data)\n    return df", "raw_solution": "import math\nfrom random import randint\nimport pandas as pd\n\ndef task_func(cities_list):\n    population_data = []\n    for city in cities_list:\n        population = randint(1, 1000000)\n        population_data.append({'City': city, 'Population': population})\n    df = pd.DataFrame(population_data)\n    return df\n```"}
{"task_id": "BigCodeBench/626", "solution": "from random import choice\nimport pytz\nfrom dateutil.parser import parse\nTIMEZONES = ['America/New_York', 'Europe/London', 'Asia/Shanghai', 'Asia/Tokyo', 'Australia/Sydney']\ndef task_func(date_str, from_tz):\n    # Parse the input date string into a datetime object\n    date_obj = parse(date_str)\n\n    # Convert the datetime object to the from_tz timezone\n    from_tz_obj = pytz.timezone(from_tz)\n    date_obj = from_tz_obj.localize(date_obj)\n\n    # Choose a random timezone from the TIMEZONES list\n    to_tz = choice(TIMEZONES)\n\n    # Convert the datetime object to the to_tz timezone\n    to_tz_obj = pytz.timezone(to_tz)\n    date_obj = date_obj.astimezone(to_tz_obj)\n\n    # Return the converted datetime string and the randomly chosen timezone\n    return (date_obj.strftime('%Y-%m-%d %H:%M:%S %Z%z'), to_tz)", "raw_solution": "from random import choice\nimport pytz\nfrom dateutil.parser import parse\n\n# Constants\nTIMEZONES = ['America/New_York', 'Europe/London', 'Asia/Shanghai', 'Asia/Tokyo', 'Australia/Sydney']\n\ndef task_func(date_str, from_tz):\n    # Parse the input date string into a datetime object\n    date_obj = parse(date_str)\n\n    # Convert the datetime object to the from_tz timezone\n    from_tz_obj = pytz.timezone(from_tz)\n    date_obj = from_tz_obj.localize(date_obj)\n\n    # Choose a random timezone from the TIMEZONES list\n    to_tz = choice(TIMEZONES)\n\n    # Convert the datetime object to the to_tz timezone\n    to_tz_obj = pytz.timezone(to_tz)\n    date_obj = date_obj.astimezone(to_tz_obj)\n\n    # Return the converted datetime string and the randomly chosen timezone\n    return (date_obj.strftime('%Y-%m-%d %H:%M:%S %Z%z'), to_tz)\n```"}
{"task_id": "BigCodeBench/627", "solution": "from random import randint\nfrom statistics import mean\nimport pandas as pd\ndef task_func(products_list):\n    data = []\n    for product in products_list:\n        sales = [randint(1, 100) for _ in range(12)]\n        data.append({\n            'Product': product,\n            'Month 1': sales[0],\n            'Month 2': sales[1],\n            'Month 3': sales[2],\n            'Month 4': sales[3],\n            'Month 5': sales[4],\n            'Month 6': sales[5],\n            'Month 7': sales[6],\n            'Month 8': sales[7],\n            'Month 9': sales[8],\n            'Month 10': sales[9],\n            'Month 11': sales[10],\n            'Month 12': sales[11],\n            'Average Sales': mean(sales)\n        })\n    return pd.DataFrame(data)", "raw_solution": "from random import randint\nfrom statistics import mean\nimport pandas as pd\n\ndef task_func(products_list):\n    data = []\n    for product in products_list:\n        sales = [randint(1, 100) for _ in range(12)]\n        data.append({\n            'Product': product,\n            'Month 1': sales[0],\n            'Month 2': sales[1],\n            'Month 3': sales[2],\n            'Month 4': sales[3],\n            'Month 5': sales[4],\n            'Month 6': sales[5],\n            'Month 7': sales[6],\n            'Month 8': sales[7],\n            'Month 9': sales[8],\n            'Month 10': sales[9],\n            'Month 11': sales[10],\n            'Month 12': sales[11],\n            'Average Sales': mean(sales)\n        })\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/628", "solution": "import math\nfrom random import randint\nimport matplotlib.pyplot as plt\ndef task_func():\n    # Generate random frequency, amplitude and phase shift\n    frequency = randint(1, 10)\n    amplitude = randint(1, 10)\n    phase_shift = randint(1, 10)\n\n    # Generate time and amplitude data\n    time = [i/100 for i in range(100)]\n    amplitude_data = [amplitude * math.sin(2 * math.pi * frequency * t + phase_shift) for t in time]\n\n    # Create the plot\n    fig, ax = plt.subplots()\n    ax.plot(time, amplitude_data)\n    ax.set_title('Random Sine Wave')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n\n    return ax", "raw_solution": "import math\nfrom random import randint\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    # Generate random frequency, amplitude and phase shift\n    frequency = randint(1, 10)\n    amplitude = randint(1, 10)\n    phase_shift = randint(1, 10)\n\n    # Generate time and amplitude data\n    time = [i/100 for i in range(100)]\n    amplitude_data = [amplitude * math.sin(2 * math.pi * frequency * t + phase_shift) for t in time]\n\n    # Create the plot\n    fig, ax = plt.subplots()\n    ax.plot(time, amplitude_data)\n    ax.set_title('Random Sine Wave')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/629", "solution": "import os\nimport time\nOUTPUT_DIR = './output'\ndef task_func(dataset, filename, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    file_path = os.path.join(output_dir, filename)\n    with open(file_path, 'w') as file:\n        for i, df in enumerate(dataset):\n            df.to_csv(file, index=False)\n            if i < len(dataset) - 1:\n                file.write('------\\n')", "raw_solution": "import os\nimport time\nOUTPUT_DIR = './output'\ndef task_func(dataset, filename, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    file_path = os.path.join(output_dir, filename)\n    with open(file_path, 'w') as file:\n        for i, df in enumerate(dataset):\n            df.to_csv(file, index=False)\n            if i < len(dataset) - 1:\n                file.write('------\\n')\n```"}
{"task_id": "BigCodeBench/630", "solution": "import pandas as pd\nimport os\nOUTPUT_DIR = './output'\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    file_path = os.path.join(output_dir, filename)\n    df.to_json(file_path, orient='records')\n    return file_path", "raw_solution": "import pandas as pd\nimport os\nOUTPUT_DIR = './output'\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    file_path = os.path.join(output_dir, filename)\n    df.to_json(file_path, orient='records')\n    return file_path\n```"}
{"task_id": "BigCodeBench/631", "solution": "import csv\nimport os\nOUTPUT_DIR = './output'\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    file_path = os.path.join(output_dir, filename)\n    df.to_csv(file_path, index=False)\n    return os.path.abspath(file_path)", "raw_solution": "import csv\nimport os\nOUTPUT_DIR = './output'\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    file_path = os.path.join(output_dir, filename)\n    df.to_csv(file_path, index=False)\n    return os.path.abspath(file_path)\n```"}
{"task_id": "BigCodeBench/632", "solution": "import pandas as pd\nimport time\nOUTPUT_DIR = './output'\ndef task_func(df: pd.DataFrame, filename: str) -> str:\n    df.to_json(f'{OUTPUT_DIR}/{filename}.jsonl', orient='records', lines=True)\n    return f'{OUTPUT_DIR}/{filename}.jsonl'", "raw_solution": "import pandas as pd\nimport time\nOUTPUT_DIR = './output'\ndef task_func(df: pd.DataFrame, filename: str) -> str:\n    df.to_json(f'{OUTPUT_DIR}/{filename}.jsonl', orient='records', lines=True)\n    return f'{OUTPUT_DIR}/{filename}.jsonl'\n```"}
{"task_id": "BigCodeBench/633", "solution": "import re\nfrom nltk.corpus import stopwords\ndef task_func(text: str) -> dict:\n    stop_words = set(stopwords.words('english'))\n    words = re.findall(r'\\b\\w+\\b', text)\n    words = [word for word in words if word not in stop_words]\n    freq_dist = {}\n    for word in words:\n        if word in freq_dist:\n            freq_dist[word] += 1\n        else:\n            freq_dist[word] = 1\n    return freq_dist", "raw_solution": "import re\nfrom nltk.corpus import stopwords\n\ndef task_func(text: str) -> dict:\n    stop_words = set(stopwords.words('english'))\n    words = re.findall(r'\\b\\w+\\b', text)\n    words = [word for word in words if word not in stop_words]\n    freq_dist = {}\n    for word in words:\n        if word in freq_dist:\n            freq_dist[word] += 1\n        else:\n            freq_dist[word] = 1\n    return freq_dist\n```"}
{"task_id": "BigCodeBench/634", "solution": "import itertools\nfrom typing import Any\nfrom scipy import stats\ndef task_func(input_list: list, repetitions: int) -> Any:\n    flattened_list = list(itertools.chain.from_iterable([input_list]*repetitions))\n    mode_result = stats.mode(flattened_list)\n    return mode_result", "raw_solution": "import itertools\nfrom typing import Any\nfrom scipy import stats\n\ndef task_func(input_list: list, repetitions: int) -> Any:\n    flattened_list = list(itertools.chain.from_iterable([input_list]*repetitions))\n    mode_result = stats.mode(flattened_list)\n    return mode_result\n```"}
{"task_id": "BigCodeBench/635", "solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\ndef task_func(text, n=2):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n\n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    words = text.split()\n    words = [word for word in words if word not in stop_words]\n\n    # Remove duplicate consecutive words\n    words = [words[i] for i in range(len(words)) if i == 0 or words[i] != words[i-1]]\n\n    # Generate co-occurrence matrix\n    vectorizer = CountVectorizer(ngram_range=(n, n), stop_words='english')\n    X = vectorizer.fit_transform([' '.join(words)])\n    matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n\n    # Plot co-occurrence matrix\n    fig, ax = plt.subplots()\n    cax = ax.matshow(matrix, cmap='coolwarm')\n    fig.colorbar(cax)\n\n    return matrix, ax", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\n\ndef task_func(text, n=2):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n\n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    words = text.split()\n    words = [word for word in words if word not in stop_words]\n\n    # Remove duplicate consecutive words\n    words = [words[i] for i in range(len(words)) if i == 0 or words[i] != words[i-1]]\n\n    # Generate co-occurrence matrix\n    vectorizer = CountVectorizer(ngram_range=(n, n), stop_words='english')\n    X = vectorizer.fit_transform([' '.join(words)])\n    matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n\n    # Plot co-occurrence matrix\n    fig, ax = plt.subplots()\n    cax = ax.matshow(matrix, cmap='coolwarm')\n    fig.colorbar(cax)\n\n    return matrix, ax\n```"}
{"task_id": "BigCodeBench/636", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(rows):\n    # Generate DataFrame with random integer values\n    df = pd.DataFrame(np.random.randint(0, 10, size=(rows, len(COLUMNS))), columns=COLUMNS)\n\n    # Count non-zero values in each column\n    non_zero_counts = df.ne(0).sum()\n\n    # Create bar plot\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Column')\n    ax.set_ylabel('Non-zero values')\n    ax.set_title('Count of non-zero values in each column')\n\n    return df, ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(rows):\n    # Generate DataFrame with random integer values\n    df = pd.DataFrame(np.random.randint(0, 10, size=(rows, len(COLUMNS))), columns=COLUMNS)\n\n    # Count non-zero values in each column\n    non_zero_counts = df.ne(0).sum()\n\n    # Create bar plot\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Column')\n    ax.set_ylabel('Non-zero values')\n    ax.set_title('Count of non-zero values in each column')\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/637", "solution": "from random import sample\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\ndef task_func(num_students):\n    np.random.seed(0)\n    courses = ['Math', 'Science', 'English', 'History', 'Art']\n    grades = np.random.randint(1, 101, (num_students, len(courses)))\n    df = pd.DataFrame(grades, columns=courses)\n    df['Student'] = range(1, num_students + 1)\n    df = df.melt(id_vars='Student', var_name='Course', value_name='Grade')\n    df.set_index('Student', inplace=True)\n    df.sort_index(inplace=True)\n    df.reset_index(inplace=True)\n    df.set_index('Course', inplace=True)\n    df.sort_index(inplace=True)\n    df.reset_index(inplace=True)\n    df.set_index('Course', inplace=True)\n    df['Pass'] = df['Grade'] >= 60\n    df.reset_index(inplace=True)\n    df.set_index('Course', inplace=True)\n    df_avg = df.groupby('Course')['Grade'].mean()\n    df_pass = df.groupby('Course')['Pass'].sum()\n    df_result = pd.DataFrame({'Average Grade': df_avg, 'Passing Grade Count': df_pass})\n    df_result.plot(kind='bar', figsize=(10, 6))\n    plt.title('Course-wise Average and Passing Grade Counts')\n    plt.ylabel('Count')\n    plt.grid(axis='y')\n    plt.tight_layout()\n    return df_result, plt.gca()", "raw_solution": "from random import sample\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndef task_func(num_students):\n    np.random.seed(0)\n    courses = ['Math', 'Science', 'English', 'History', 'Art']\n    grades = np.random.randint(1, 101, (num_students, len(courses)))\n    df = pd.DataFrame(grades, columns=courses)\n    df['Student'] = range(1, num_students + 1)\n    df = df.melt(id_vars='Student', var_name='Course', value_name='Grade')\n    df.set_index('Student', inplace=True)\n    df.sort_index(inplace=True)\n    df.reset_index(inplace=True)\n    df.set_index('Course', inplace=True)\n    df.sort_index(inplace=True)\n    df.reset_index(inplace=True)\n    df.set_index('Course', inplace=True)\n    df['Pass'] = df['Grade'] >= 60\n    df.reset_index(inplace=True)\n    df.set_index('Course', inplace=True)\n    df_avg = df.groupby('Course')['Grade'].mean()\n    df_pass = df.groupby('Course')['Pass'].sum()\n    df_result = pd.DataFrame({'Average Grade': df_avg, 'Passing Grade Count': df_pass})\n    df_result.plot(kind='bar', figsize=(10, 6))\n    plt.title('Course-wise Average and Passing Grade Counts')\n    plt.ylabel('Count')\n    plt.grid(axis='y')\n    plt.tight_layout()\n    return df_result, plt.gca()\n```"}
{"task_id": "BigCodeBench/638", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(num_teams=5, num_games=100):\n    teams = [f'Team_{i}' for i in range(1, num_teams + 1)]\n    games = [f'Game_{i}' for i in range(1, num_games + 1)]\n    scores = np.random.randint(0, 100, size=(num_teams, num_games))\n    df = pd.DataFrame(scores, index=teams, columns=games)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(num_teams=5, num_games=100):\n    teams = [f'Team_{i}' for i in range(1, num_teams + 1)]\n    games = [f'Game_{i}' for i in range(1, num_games + 1)]\n    scores = np.random.randint(0, 100, size=(num_teams, num_games))\n    df = pd.DataFrame(scores, index=teams, columns=games)\n    return df\n```"}
{"task_id": "BigCodeBench/639", "solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(num_samples=100, num_features=5):\n    np.random.seed(0)\n    data = np.random.rand(num_samples, num_features)\n    df = pd.DataFrame(data, columns=[f\"Feature_{i}\" for i in range(1, num_features + 1)])\n\n    correlation_matrix = df.corr()\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n    plt.title(\"Correlation Heatmap\")\n    plt.show()\n\n    return df, plt.gca()", "raw_solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(num_samples=100, num_features=5):\n    np.random.seed(0)\n    data = np.random.rand(num_samples, num_features)\n    df = pd.DataFrame(data, columns=[f\"Feature_{i}\" for i in range(1, num_features + 1)])\n\n    correlation_matrix = df.corr()\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n    plt.title(\"Correlation Heatmap\")\n    plt.show()\n\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/640", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nPRODUCTS = ['Product' + str(i) for i in range(1, 6)]\nMONTHS = ['Month' + str(i) for i in range(1, 13)]\ndef task_func():\n    # Generate random sales figures\n    np.random.seed(0)\n    sales_data = np.random.randint(100, 500, size=(12, 5))\n\n    # Create DataFrame\n    df = pd.DataFrame(sales_data, columns=PRODUCTS, index=MONTHS)\n\n    # Plot total sales per product\n    df.sum().plot(kind='line', title='Total Sales per Product')\n    plt.xlabel('Product')\n    plt.ylabel('Total Sales')\n    plt.show()\n\n    # Plot heatmap\n    sns.heatmap(df, annot=True, cmap='YlGnBu')\n    plt.title('Sales Heatmap')\n    plt.show()\n\n    return df", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nPRODUCTS = ['Product' + str(i) for i in range(1, 6)]\nMONTHS = ['Month' + str(i) for i in range(1, 13)]\n\ndef task_func():\n    # Generate random sales figures\n    np.random.seed(0)\n    sales_data = np.random.randint(100, 500, size=(12, 5))\n\n    # Create DataFrame\n    df = pd.DataFrame(sales_data, columns=PRODUCTS, index=MONTHS)\n\n    # Plot total sales per product\n    df.sum().plot(kind='line', title='Total Sales per Product')\n    plt.xlabel('Product')\n    plt.ylabel('Total Sales')\n    plt.show()\n\n    # Plot heatmap\n    sns.heatmap(df, annot=True, cmap='YlGnBu')\n    plt.title('Sales Heatmap')\n    plt.show()\n\n    return df\n```"}
{"task_id": "BigCodeBench/641", "solution": "import os\nimport re\nimport pandas as pd\ndef task_func(pattern: str, directory: str, output_csv: str) -> pd.DataFrame:\n    regex = re.compile(pattern)\n    matched_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if regex.match(file):\n                matched_files.append(os.path.join(root, file))\n    df = pd.DataFrame(matched_files, columns=['File Path'])\n    df.to_csv(output_csv, index=False)\n    return df", "raw_solution": "import os\nimport re\nimport pandas as pd\n\ndef task_func(pattern: str, directory: str, output_csv: str) -> pd.DataFrame:\n    regex = re.compile(pattern)\n    matched_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if regex.match(file):\n                matched_files.append(os.path.join(root, file))\n    df = pd.DataFrame(matched_files, columns=['File Path'])\n    df.to_csv(output_csv, index=False)\n    return df\n```"}
{"task_id": "BigCodeBench/642", "solution": "import os\nimport re\nimport hashlib\ndef task_func(directory: str, pattern: str = r\"(?<!Distillr)\\\\AcroTray\\.exe\") -> dict:\n    result = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(pattern, file):\n                file_path = os.path.join(root, file)\n                with open(file_path, 'rb') as f:\n                    file_content = f.read()\n                    sha256_hash = hashlib.sha256(file_content).hexdigest()\n                    result[file_path] = sha256_hash\n    return result", "raw_solution": "import os\nimport re\nimport hashlib\n\ndef task_func(directory: str, pattern: str = r\"(?<!Distillr)\\\\AcroTray\\.exe\") -> dict:\n    result = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(pattern, file):\n                file_path = os.path.join(root, file)\n                with open(file_path, 'rb') as f:\n                    file_content = f.read()\n                    sha256_hash = hashlib.sha256(file_content).hexdigest()\n                    result[file_path] = sha256_hash\n    return result\n```"}
{"task_id": "BigCodeBench/643", "solution": "import re\nimport pandas as pd\nimport numpy as np\nDATA_PATTERN = r'>\\d+\\.\\d+<'\ndef task_func(dataframe, data_pattern=DATA_PATTERN):\n    for col in dataframe.columns:\n        dataframe[col] = dataframe[col].apply(lambda x: re.findall(data_pattern, str(x)))\n        dataframe[col] = dataframe[col].apply(lambda x: float(x[0][1:-1]) if x else np.nan)\n    return dataframe", "raw_solution": "import re\nimport pandas as pd\nimport numpy as np\n\n# Constants\nDATA_PATTERN = r'>\\d+\\.\\d+<'\n\ndef task_func(dataframe, data_pattern=DATA_PATTERN):\n    for col in dataframe.columns:\n        dataframe[col] = dataframe[col].apply(lambda x: re.findall(data_pattern, str(x)))\n        dataframe[col] = dataframe[col].apply(lambda x: float(x[0][1:-1]) if x else np.nan)\n    return dataframe\n```"}
{"task_id": "BigCodeBench/644", "solution": "import hashlib\nimport base64\nimport os\ndef task_func(filename, data, password):\n    if not os.path.exists(os.path.dirname(filename)):\n        os.makedirs(os.path.dirname(filename))\n\n    with open(filename, 'w') as file:\n        encrypted_data = encrypt_string(data, password)\n        file.write(encrypted_data)\n\n    return encrypted_data\ndef encrypt_string(data, password):\n    password_hash = hashlib.sha256(password.encode()).digest()\n    encrypted_data = base64.b64encode(password_hash + data.encode()).decode()\n    return encrypted_data", "raw_solution": "import hashlib\nimport base64\nimport os\n\ndef task_func(filename, data, password):\n    if not os.path.exists(os.path.dirname(filename)):\n        os.makedirs(os.path.dirname(filename))\n\n    with open(filename, 'w') as file:\n        encrypted_data = encrypt_string(data, password)\n        file.write(encrypted_data)\n\n    return encrypted_data\n\ndef encrypt_string(data, password):\n    password_hash = hashlib.sha256(password.encode()).digest()\n    encrypted_data = base64.b64encode(password_hash + data.encode()).decode()\n    return encrypted_data\n```"}
{"task_id": "BigCodeBench/645", "solution": "import os\nimport pandas as pd\ndef task_func(filename: str) -> pd.DataFrame:\n    if not os.path.exists(filename):\n        raise FileNotFoundError(f\"The file {filename} does not exist.\")\n    df = pd.read_csv(filename)\n    os.remove(filename)\n    return df", "raw_solution": "import os\nimport pandas as pd\n\ndef task_func(filename: str) -> pd.DataFrame:\n    if not os.path.exists(filename):\n        raise FileNotFoundError(f\"The file {filename} does not exist.\")\n    df = pd.read_csv(filename)\n    os.remove(filename)\n    return df\n```"}
{"task_id": "BigCodeBench/646", "solution": "import os\nimport pandas as pd\nfrom dateutil.parser import parse\nimport matplotlib.pyplot as plt\nOUTPUT_DIR = './output'\ndef task_func(csv_path=os.path.join(OUTPUT_DIR, 'data.csv'), date_column='date'):\n    df = pd.read_csv(csv_path)\n    df[date_column] = pd.to_datetime(df[date_column])\n    df['year'] = df[date_column].dt.year\n    hist = df['year'].hist(bins=10)\n    plt.title('Year Distribution')\n    plt.xlabel('Year')\n    plt.ylabel('Frequency')\n    return hist", "raw_solution": "import os\nimport pandas as pd\nfrom dateutil.parser import parse\nimport matplotlib.pyplot as plt\n\nOUTPUT_DIR = './output'\n\ndef task_func(csv_path=os.path.join(OUTPUT_DIR, 'data.csv'), date_column='date'):\n    df = pd.read_csv(csv_path)\n    df[date_column] = pd.to_datetime(df[date_column])\n    df['year'] = df[date_column].dt.year\n    hist = df['year'].hist(bins=10)\n    plt.title('Year Distribution')\n    plt.xlabel('Year')\n    plt.ylabel('Frequency')\n    return hist\n```"}
{"task_id": "BigCodeBench/647", "solution": "import pytz\nfrom dateutil.parser import parse\nfrom datetime import datetime\ndef task_func(date_str, from_tz, to_tz):\n    date = parse(date_str)\n    from_tz = pytz.timezone(from_tz)\n    to_tz = pytz.timezone(to_tz)\n    date = from_tz.localize(date)\n    date = date.astimezone(to_tz)\n    return int((datetime.now(to_tz) - date).total_seconds())", "raw_solution": "import pytz\nfrom dateutil.parser import parse\nfrom datetime import datetime\n\ndef task_func(date_str, from_tz, to_tz):\n    date = parse(date_str)\n    from_tz = pytz.timezone(from_tz)\n    to_tz = pytz.timezone(to_tz)\n    date = from_tz.localize(date)\n    date = date.astimezone(to_tz)\n    return int((datetime.now(to_tz) - date).total_seconds())\n```"}
{"task_id": "BigCodeBench/648", "solution": "from dateutil.parser import parse\nfrom datetime import timedelta\ndef task_func(date_str):\n    date = parse(date_str)\n    while date.weekday() > 4:\n        date += timedelta(days=1)\n    return date", "raw_solution": "from dateutil.parser import parse\nfrom datetime import timedelta\n\ndef task_func(date_str):\n    date = parse(date_str)\n    while date.weekday() > 4:\n        date += timedelta(days=1)\n    return date\n```"}
{"task_id": "BigCodeBench/649", "solution": "import numpy as np\nimport pandas as pd\nfrom dateutil.parser import parse\ndef task_func(dates_str_list):\n    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    weekday_counts = {weekday: 0 for weekday in weekdays}\n    for date_str in dates_str_list:\n        date = parse(date_str)\n        weekday = weekdays[date.weekday()]\n        weekday_counts[weekday] += 1\n    return pd.Series(weekday_counts)", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom dateutil.parser import parse\n\ndef task_func(dates_str_list):\n    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    weekday_counts = {weekday: 0 for weekday in weekdays}\n    for date_str in dates_str_list:\n        date = parse(date_str)\n        weekday = weekdays[date.weekday()]\n        weekday_counts[weekday] += 1\n    return pd.Series(weekday_counts)\n```"}
{"task_id": "BigCodeBench/650", "solution": "from datetime import datetime\nimport pytz\nfrom dateutil.parser import parse\ndef task_func(date_str, tz_str):\n    date = parse(date_str)\n    tz = pytz.timezone(tz_str)\n    date = date.replace(tzinfo=tz)\n    next_year = date.year + 1\n    next_year_date = datetime(next_year, 1, 1, 0, 0, 0, tzinfo=tz)\n    return int((next_year_date - date).total_seconds())", "raw_solution": "from datetime import datetime\nimport pytz\nfrom dateutil.parser import parse\n\ndef task_func(date_str, tz_str):\n    date = parse(date_str)\n    tz = pytz.timezone(tz_str)\n    date = date.replace(tzinfo=tz)\n    next_year = date.year + 1\n    next_year_date = datetime(next_year, 1, 1, 0, 0, 0, tzinfo=tz)\n    return int((next_year_date - date).total_seconds())\n```"}
{"task_id": "BigCodeBench/651", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, target_value):\n    if df.empty:\n        return pd.Series(), None\n    target_rows = df[df == target_value]\n    if target_rows.empty:\n        return pd.Series(), None\n    counts = target_rows.count()\n    plot = counts.plot(kind='bar')\n    plt.ylabel('Count')\n    plt.title('Count of Rows with Target Value per Column')\n    return counts, plot", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_value):\n    if df.empty:\n        return pd.Series(), None\n    target_rows = df[df == target_value]\n    if target_rows.empty:\n        return pd.Series(), None\n    counts = target_rows.count()\n    plot = counts.plot(kind='bar')\n    plt.ylabel('Count')\n    plt.title('Count of Rows with Target Value per Column')\n    return counts, plot\n```"}
{"task_id": "BigCodeBench/652", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\ndef task_func(target_value='332', array=np.array([['0', '1', '2'], ['a', 'bb', 'ccc'], ['332', '33', '2'], ['33', '22', '332']])):\n    # Find the row indices where the first cell matches target_value\n    indices = np.where(array[:, 0] == target_value)[0]\n\n    # If no target value found, return 'N/A'\n    if len(indices) == 0:\n        return 'N/A'\n\n    # Perform statistical analysis on the indices\n    mean = np.mean(indices)\n    variance = np.var(indices)\n    skewness = stats.skew(indices)\n    kurtosis = stats.kurtosis(indices)\n\n    # Return the mean, variance, skewness, and kurtosis of the indices\n    return (mean, variance, skewness, kurtosis)", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\n\ndef task_func(target_value='332', array=np.array([['0', '1', '2'], ['a', 'bb', 'ccc'], ['332', '33', '2'], ['33', '22', '332']])):\n    # Find the row indices where the first cell matches target_value\n    indices = np.where(array[:, 0] == target_value)[0]\n\n    # If no target value found, return 'N/A'\n    if len(indices) == 0:\n        return 'N/A'\n\n    # Perform statistical analysis on the indices\n    mean = np.mean(indices)\n    variance = np.var(indices)\n    skewness = stats.skew(indices)\n    kurtosis = stats.kurtosis(indices)\n\n    # Return the mean, variance, skewness, and kurtosis of the indices\n    return (mean, variance, skewness, kurtosis)\n```"}
{"task_id": "BigCodeBench/653", "solution": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\ndef task_func(dataframe, target_value='332'):\n    # Create a Boolean mask for the target value\n    mask = dataframe == target_value\n\n    # Create a heatmap using seaborn\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(dataframe, mask=mask, cmap='coolwarm', cbar=False)\n    plt.title(f'Heatmap of occurrences of {target_value}')\n\n    return mask, plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\ndef task_func(dataframe, target_value='332'):\n    # Create a Boolean mask for the target value\n    mask = dataframe == target_value\n\n    # Create a heatmap using seaborn\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(dataframe, mask=mask, cmap='coolwarm', cbar=False)\n    plt.title(f'Heatmap of occurrences of {target_value}')\n\n    return mask, plt.gca()\n```"}
{"task_id": "BigCodeBench/654", "solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\ndef task_func(array, target_value):\n    # Filter the array based on the target value\n    filtered_array = array[array[:, 0] == target_value]\n\n    # Define the exponential decay function\n    def exponential_decay(t, a, b, c):\n        return a * np.exp(-b * t) + c\n\n    # Fit the exponential decay function to the filtered array\n    popt, _ = optimize.curve_fit(exponential_decay, filtered_array[:, 1], filtered_array[:, 2])\n\n    # Create a new figure and axis for the plot\n    fig, ax = plt.subplots()\n\n    # Plot the original data points\n    ax.scatter(filtered_array[:, 1], filtered_array[:, 2], color='blue', label='Data')\n\n    # Plot the fitted curve\n    x_fit = np.linspace(filtered_array[:, 1].min(), filtered_array[:, 1].max(), 100)\n    y_fit = exponential_decay(x_fit, *popt)\n    ax.plot(x_fit, y_fit, color='red', label='Fit')\n\n    # Set the plot title and labels\n    ax.set_title('Exponential Decay Fit')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n\n    # Show the legend\n    ax.legend()\n\n    # Return the optimized parameters and the plot\n    return popt, ax", "raw_solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\n\ndef task_func(array, target_value):\n    # Filter the array based on the target value\n    filtered_array = array[array[:, 0] == target_value]\n\n    # Define the exponential decay function\n    def exponential_decay(t, a, b, c):\n        return a * np.exp(-b * t) + c\n\n    # Fit the exponential decay function to the filtered array\n    popt, _ = optimize.curve_fit(exponential_decay, filtered_array[:, 1], filtered_array[:, 2])\n\n    # Create a new figure and axis for the plot\n    fig, ax = plt.subplots()\n\n    # Plot the original data points\n    ax.scatter(filtered_array[:, 1], filtered_array[:, 2], color='blue', label='Data')\n\n    # Plot the fitted curve\n    x_fit = np.linspace(filtered_array[:, 1].min(), filtered_array[:, 1].max(), 100)\n    y_fit = exponential_decay(x_fit, *popt)\n    ax.plot(x_fit, y_fit, color='red', label='Fit')\n\n    # Set the plot title and labels\n    ax.set_title('Exponential Decay Fit')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n\n    # Show the legend\n    ax.legend()\n\n    # Return the optimized parameters and the plot\n    return popt, ax\n```"}
{"task_id": "BigCodeBench/655", "solution": "import re\nimport nltk\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer", "raw_solution": "import re\nimport nltk\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# Ensure nltk's stopwords are downloaded\nnltk.download('stopwords')\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef topic_extraction(texts, num_topics):\n    # Preprocess the texts\n    texts = [ALPHANUMERIC.sub(' ', text.lower()) for text in texts]\n    texts = [' '.join([word for word in text.split() if word not in STOPWORDS]) for text in texts]\n    # Vectorize the texts\n    vectorizer = TfidfVectorizer(max_features=2000)\n    X = vectorizer.fit_transform(texts)\n    # Apply NMF\n    nmf = NMF(n_components=num_topics, random_state=42, alpha=.1, l1_ratio=.5, init='nndsvd').fit(X)\n    # Extract the topics\n    feature_names = vectorizer.get_feature_names_out()\n    topics = []\n    for topic_idx, topic in enumerate(nmf.components_):\n        top_features = topic.argsort()[:-num_topics - 1:-1]\n        topics.append([feature_names[i] for i in top_features])\n    return topics\n```"}
{"task_id": "BigCodeBench/656", "solution": "import re\nimport string\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nALPHANUMERIC = re.compile('[\\W_]+')\nPUNCTUATIONS = string.punctuation\ndef task_func(text: str, sia: SentimentIntensityAnalyzer) -> dict:\n    # Clean the text\n    text = text.lower()\n    text = re.sub(ALPHANUMERIC, ' ', text)\n    text = re.sub(r'['+PUNCTUATIONS+']', '', text)\n\n    # Analyze the sentiment\n    sentiment = sia.polarity_scores(text)\n\n    return sentiment", "raw_solution": "import re\nimport string\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nnltk.download('vader_lexicon')\n\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\nPUNCTUATIONS = string.punctuation\n\ndef task_func(text: str, sia: SentimentIntensityAnalyzer) -> dict:\n    # Clean the text\n    text = text.lower()\n    text = re.sub(ALPHANUMERIC, ' ', text)\n    text = re.sub(r'['+PUNCTUATIONS+']', '', text)\n\n    # Analyze the sentiment\n    sentiment = sia.polarity_scores(text)\n\n    return sentiment\n```"}
{"task_id": "BigCodeBench/657", "solution": "import re\nimport nltk\nfrom gensim.models import Word2Vec\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n    if stopwords is None:\n        stopwords = nltk.corpus.stopwords.words('english')\n    texts = [ALPHANUMERIC.sub(' ', text).lower().split() for text in texts]\n    texts = [[word for word in text if word not in stopwords] for text in texts]\n    model = Word2Vec(texts, min_count=1)\n    return model", "raw_solution": "import re\nimport nltk\nfrom gensim.models import Word2Vec\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n    if stopwords is None:\n        stopwords = nltk.corpus.stopwords.words('english')\n    texts = [ALPHANUMERIC.sub(' ', text).lower().split() for text in texts]\n    texts = [[word for word in text if word not in stopwords] for text in texts]\n    model = Word2Vec(texts, min_count=1)\n    return model\n```"}
{"task_id": "BigCodeBench/658", "solution": "import re\nimport nltk\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(texts):\n    # Preprocess the texts\n    texts = [ALPHANUMERIC.sub(' ', text.lower()) for text in texts]\n    # Create a CountVectorizer with NLTK's list of English stop words\n    vectorizer = CountVectorizer(stop_words=STOPWORDS)\n    # Fit and transform the texts\n    dtm = vectorizer.fit_transform(texts)\n    # Convert the sparse matrix to a DataFrame\n    dtm_df = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n    return dtm_df", "raw_solution": "import re\nimport nltk\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\n# Make sure to download NLTK stopwords\nnltk.download('stopwords')\n# Define a regex pattern for matching all non-alphanumeric characters\nALPHANUMERIC = re.compile('[\\W_]+')\n# Load NLTK's list of English stop words\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(texts):\n    # Preprocess the texts\n    texts = [ALPHANUMERIC.sub(' ', text.lower()) for text in texts]\n    # Create a CountVectorizer with NLTK's list of English stop words\n    vectorizer = CountVectorizer(stop_words=STOPWORDS)\n    # Fit and transform the texts\n    dtm = vectorizer.fit_transform(texts)\n    # Convert the sparse matrix to a DataFrame\n    dtm_df = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n    return dtm_df\n```"}
{"task_id": "BigCodeBench/659", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\ndef task_func(x, y, labels):\n    fig, ax = plt.subplots(figsize=(10, 6))\n    for i in range(len(x)):\n        mu, sigma = x[i], y[i]\n        x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n        ax.plot(x, stats.norm.pdf(x, mu, sigma), label=labels[i])\n    ax.legend()\n    plt.show()\n    return fig", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\n\ndef task_func(x, y, labels):\n    fig, ax = plt.subplots(figsize=(10, 6))\n    for i in range(len(x)):\n        mu, sigma = x[i], y[i]\n        x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n        ax.plot(x, stats.norm.pdf(x, mu, sigma), label=labels[i])\n    ax.legend()\n    plt.show()\n    return fig\n```"}
{"task_id": "BigCodeBench/660", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(x, y, labels):\n    scaler = StandardScaler()\n    x_scaled = scaler.fit_transform(x)\n    y_scaled = scaler.fit_transform(y)\n\n    fig, ax = plt.subplots()\n    ax.scatter(x_scaled, y_scaled, label=labels)\n    ax.set_xlabel('Scaled X')\n    ax.set_ylabel('Scaled Y')\n    ax.legend()\n    return fig", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(x, y, labels):\n    scaler = StandardScaler()\n    x_scaled = scaler.fit_transform(x)\n    y_scaled = scaler.fit_transform(y)\n\n    fig, ax = plt.subplots()\n    ax.scatter(x_scaled, y_scaled, label=labels)\n    ax.set_xlabel('Scaled X')\n    ax.set_ylabel('Scaled Y')\n    ax.legend()\n    return fig\n```"}
{"task_id": "BigCodeBench/661", "solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\ndef task_func(x, y, labels):\n    df = pd.DataFrame(data=np.random.rand(len(x), len(y)), columns=y, index=x)\n    ax = sns.heatmap(df, annot=True, cmap='viridis', fmt=\".2f\", cbar=True, xticklabels=labels, yticklabels=labels)\n    return ax, df", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\n\n# Constants\nLABELS = ['H\\u2082O', 'O\\u2082', 'CO\\u2082', 'N\\u2082', 'Ar']\n\ndef task_func(x, y, labels):\n    df = pd.DataFrame(data=np.random.rand(len(x), len(y)), columns=y, index=x)\n    ax = sns.heatmap(df, annot=True, cmap='viridis', fmt=\".2f\", cbar=True, xticklabels=labels, yticklabels=labels)\n    return ax, df\n```"}
{"task_id": "BigCodeBench/662", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(x, y, labels):\n    data = np.column_stack((x, y))\n    pca = PCA(n_components=2)\n    pca.fit(data)\n    transformed_data = pca.transform(data)\n\n    fig, ax = plt.subplots()\n    for label in np.unique(labels):\n        ax.scatter(transformed_data[labels == label, 0], transformed_data[labels == label, 1], label=label)\n    ax.legend()\n    plt.show()\n    return fig", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(x, y, labels):\n    data = np.column_stack((x, y))\n    pca = PCA(n_components=2)\n    pca.fit(data)\n    transformed_data = pca.transform(data)\n\n    fig, ax = plt.subplots()\n    for label in np.unique(labels):\n        ax.scatter(transformed_data[labels == label, 0], transformed_data[labels == label, 1], label=label)\n    ax.legend()\n    plt.show()\n    return fig\n```"}
{"task_id": "BigCodeBench/663", "solution": "import numpy as np\nfrom scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\ndef exponential_func(x, a, b, c):\n    return a * np.exp(-b * x) + c\ndef task_func(x, y, labels):\n    fig, ax = plt.subplots()\n    for i in range(len(x)):\n        popt, _ = curve_fit(exponential_func, x[i], y[i])\n        a, b, c = popt\n        x_fit = np.linspace(min(x[i]), max(x[i]), 100)\n        y_fit = exponential_func(x_fit, a, b, c)\n        ax.plot(x_fit, y_fit, label=labels[i])\n    ax.legend()\n    return fig", "raw_solution": "import numpy as np\nfrom scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\n\ndef exponential_func(x, a, b, c):\n    return a * np.exp(-b * x) + c\n\ndef task_func(x, y, labels):\n    fig, ax = plt.subplots()\n    for i in range(len(x)):\n        popt, _ = curve_fit(exponential_func, x[i], y[i])\n        a, b, c = popt\n        x_fit = np.linspace(min(x[i]), max(x[i]), 100)\n        y_fit = exponential_func(x_fit, a, b, c)\n        ax.plot(x_fit, y_fit, label=labels[i])\n    ax.legend()\n    return fig\n```"}
{"task_id": "BigCodeBench/664", "solution": "import statistics\nimport matplotlib.pyplot as plt\ndef task_func(sales_data):\n    fig, ax = plt.subplots()\n    for product, sales in sales_data.items():\n        ax.plot(sales, label=product)\n        ax.fill_between(range(12), [mean - std_dev for mean, std_dev in zip(sales, sales_data[product])], [mean + std_dev for mean, std_dev in zip(sales, sales_data[product])], alpha=0.2)\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Sales')\n    ax.legend()\n    return ax", "raw_solution": "import statistics\nimport matplotlib.pyplot as plt\n\ndef task_func(sales_data):\n    fig, ax = plt.subplots()\n    for product, sales in sales_data.items():\n        ax.plot(sales, label=product)\n        ax.fill_between(range(12), [mean - std_dev for mean, std_dev in zip(sales, sales_data[product])], [mean + std_dev for mean, std_dev in zip(sales, sales_data[product])], alpha=0.2)\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Sales')\n    ax.legend()\n    return ax\n```"}
{"task_id": "BigCodeBench/665", "solution": "import shutil\nimport os\nimport fnmatch\nimport itertools\ndef task_func(src_dir, dst_dir):\n    patterns = ['*.txt', '*.docx']\n    for pattern in patterns:\n        for root, dirs, files in os.walk(src_dir):\n            for file in fnmatch.filter(files, pattern):\n                src_file = os.path.join(root, file)\n                dst_file = os.path.join(dst_dir, file)\n                shutil.copy2(src_file, dst_file)\n    return dst_dir", "raw_solution": "import shutil\nimport os\nimport fnmatch\nimport itertools\n\ndef task_func(src_dir, dst_dir):\n    patterns = ['*.txt', '*.docx']\n    for pattern in patterns:\n        for root, dirs, files in os.walk(src_dir):\n            for file in fnmatch.filter(files, pattern):\n                src_file = os.path.join(root, file)\n                dst_file = os.path.join(dst_dir, file)\n                shutil.copy2(src_file, dst_file)\n    return dst_dir\n```"}
{"task_id": "BigCodeBench/666", "solution": "from itertools import combinations\nimport math\ndef task_func(seq, letter_weight_dict):\n    max_weight = 0\n    max_subseq = \"\"\n    for i in range(len(seq), 0, -1):\n        for subseq in combinations(seq, i):\n            weight = sum(letter_weight_dict[char] for char in subseq)\n            if weight > max_weight:\n                max_weight = weight\n                max_subseq = \"\".join(subseq)\n    return max_subseq", "raw_solution": "from itertools import combinations\nimport math\ndef task_func(seq, letter_weight_dict):\n    max_weight = 0\n    max_subseq = \"\"\n    for i in range(len(seq), 0, -1):\n        for subseq in combinations(seq, i):\n            weight = sum(letter_weight_dict[char] for char in subseq)\n            if weight > max_weight:\n                max_weight = weight\n                max_subseq = \"\".join(subseq)\n    return max_subseq\n```"}
{"task_id": "BigCodeBench/667", "solution": "import heapq\nimport collections\ndef task_func(x, n):\n    if not x:\n        return []\n    freq_dict = collections.Counter(x)\n    heap = [(-freq, char) for char, freq in freq_dict.items()]\n    heapq.heapify(heap)\n    return [heapq.heappop(heap)[1] for _ in range(n)]", "raw_solution": "import heapq\nimport collections\ndef task_func(x, n):\n    if not x:\n        return []\n    freq_dict = collections.Counter(x)\n    heap = [(-freq, char) for char, freq in freq_dict.items()]\n    heapq.heapify(heap)\n    return [heapq.heappop(heap)[1] for _ in range(n)]\n```"}
{"task_id": "BigCodeBench/668", "solution": "import itertools\nimport math\ndef task_func(x):\n    if not x:\n        return []\n    sorted_x = sorted(x.items(), key=lambda item: item[1])\n    subsequences = []\n    for length in range(1, len(sorted_x) + 1):\n        for subset in itertools.combinations(sorted_x, length):\n            subsequences.append(list(subset))\n    min_length = math.inf\n    min_subsequence = []\n    for subsequence in subsequences:\n        total_length = sum(value for key, value in subsequence)\n        if total_length < min_length:\n            min_length = total_length\n            min_subsequence = [key for key, value in subsequence]\n    return min_subsequence", "raw_solution": "import itertools\nimport math\ndef task_func(x):\n    if not x:\n        return []\n    sorted_x = sorted(x.items(), key=lambda item: item[1])\n    subsequences = []\n    for length in range(1, len(sorted_x) + 1):\n        for subset in itertools.combinations(sorted_x, length):\n            subsequences.append(list(subset))\n    min_length = math.inf\n    min_subsequence = []\n    for subsequence in subsequences:\n        total_length = sum(value for key, value in subsequence)\n        if total_length < min_length:\n            min_length = total_length\n            min_subsequence = [key for key, value in subsequence]\n    return min_subsequence\n```"}
{"task_id": "BigCodeBench/669", "solution": "import itertools\nimport math\ndef task_func(x):\n    max_sum = -1\n    max_pair = None\n    for pair in itertools.combinations(x.keys(), 2):\n        sum_cos = math.cos(x[pair[0]]) + math.cos(x[pair[1]])\n        if sum_cos > max_sum:\n            max_sum = sum_cos\n            max_pair = pair\n    return max_pair", "raw_solution": "import itertools\nimport math\n\ndef task_func(x):\n    max_sum = -1\n    max_pair = None\n    for pair in itertools.combinations(x.keys(), 2):\n        sum_cos = math.cos(x[pair[0]]) + math.cos(x[pair[1]])\n        if sum_cos > max_sum:\n            max_sum = sum_cos\n            max_pair = pair\n    return max_pair\n```"}
{"task_id": "BigCodeBench/670", "solution": "from itertools import combinations\nimport math\ndef task_func(x, w):\n    max_weight = 0\n    max_substr = \"\"\n    for i in range(len(x), 0, -1):\n        for j in range(len(x) - i + 1):\n            substr = x[j:j+i]\n            weight = sum(w[char] for char in substr)\n            if weight > max_weight:\n                max_weight = weight\n                max_substr = substr\n    return max_substr", "raw_solution": "from itertools import combinations\nimport math\ndef task_func(x, w):\n    max_weight = 0\n    max_substr = \"\"\n    for i in range(len(x), 0, -1):\n        for j in range(len(x) - i + 1):\n            substr = x[j:j+i]\n            weight = sum(w[char] for char in substr)\n            if weight > max_weight:\n                max_weight = weight\n                max_substr = substr\n    return max_substr\n```"}
{"task_id": "BigCodeBench/671", "solution": "import os\nimport random\nimport json\ndef task_func(directory, n):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    for i in range(n):\n        file_name = os.path.join(directory, f\"file_{i}.json\")\n        with open(file_name, \"w\") as file:\n            data = {\"number\": random.randint(1, 100)}\n            json.dump(data, file)\n\n    return directory", "raw_solution": "import os\nimport random\nimport json\n\ndef task_func(directory, n):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    for i in range(n):\n        file_name = os.path.join(directory, f\"file_{i}.json\")\n        with open(file_name, \"w\") as file:\n            data = {\"number\": random.randint(1, 100)}\n            json.dump(data, file)\n\n    return directory\n```"}
{"task_id": "BigCodeBench/672", "solution": "import csv\nimport sys\ndef task_func(filename):\n    with open(filename, 'r') as file:\n        lines = file.readlines()\n    with open(filename, 'w') as file:\n        for line in reversed(lines):\n            file.write(line)\n    with open(filename, 'r+') as file:\n        file.seek(0)", "raw_solution": "import csv\nimport sys\n\ndef task_func(filename):\n    with open(filename, 'r') as file:\n        lines = file.readlines()\n    with open(filename, 'w') as file:\n        for line in reversed(lines):\n            file.write(line)\n    with open(filename, 'r+') as file:\n        file.seek(0)\n```"}
{"task_id": "BigCodeBench/673", "solution": "import os\nimport random\ndef task_func(directory, n_files):\n    for i in range(1, n_files + 1):\n        file_name = os.path.join(directory, f'file_{i}.txt')\n        with open(file_name, 'w') as file:\n            file.write(str(random.randint(0, 9)))\n        file.close()\n    return n_files", "raw_solution": "import os\nimport random\n\ndef task_func(directory, n_files):\n    for i in range(1, n_files + 1):\n        file_name = os.path.join(directory, f'file_{i}.txt')\n        with open(file_name, 'w') as file:\n            file.write(str(random.randint(0, 9)))\n        file.close()\n    return n_files\n```"}
{"task_id": "BigCodeBench/674", "solution": "import pandas as pd\nimport os\ndef task_func(filename):\n    if os.path.exists(filename):\n        df = pd.read_csv(filename)\n        df = df.iloc[::-1]\n        df.to_csv(filename, index=False)\n        with open(filename, 'r+') as file:\n            lines = file.readlines()\n            file.seek(0)\n            file.write(''.join(lines))\n            file.truncate()", "raw_solution": "import pandas as pd\nimport os\n\ndef task_func(filename):\n    if os.path.exists(filename):\n        df = pd.read_csv(filename)\n        df = df.iloc[::-1]\n        df.to_csv(filename, index=False)\n        with open(filename, 'r+') as file:\n            lines = file.readlines()\n            file.seek(0)\n            file.write(''.join(lines))\n            file.truncate()\n```"}
{"task_id": "BigCodeBench/675", "solution": "import os\nimport random\nimport string\ndef task_func(directory, n_files):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    for i in range(n_files):\n        file_name = os.path.join(directory, f\"file_{i}.txt\")\n        with open(file_name, \"w\") as file:\n            file.write(''.join(random.choices(string.ascii_letters, k=10)))\n\n    return directory", "raw_solution": "import os\nimport random\nimport string\n\ndef task_func(directory, n_files):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    for i in range(n_files):\n        file_name = os.path.join(directory, f\"file_{i}.txt\")\n        with open(file_name, \"w\") as file:\n            file.write(''.join(random.choices(string.ascii_letters, k=10)))\n\n    return directory\n```"}
{"task_id": "BigCodeBench/676", "solution": "import pandas as pd\nimport random\ndef task_func(df):\n    df['winner'] = df.apply(lambda row: row['team1'] if row['score1'] > row['score2'] else (row['team2'] if row['score1'] < row['score2'] else random.choice([row['team1'], row['team2']])), axis=1)\n    return df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(df):\n    df['winner'] = df.apply(lambda row: row['team1'] if row['score1'] > row['score2'] else (row['team2'] if row['score1'] < row['score2'] else random.choice([row['team1'], row['team2']])), axis=1)\n    return df\n```"}
{"task_id": "BigCodeBench/677", "solution": "import numpy as np\nimport pandas as pd\nfrom scipy.stats import linregress\ndef task_func(df):\n    slope, intercept, r_value, p_value, std_err = linregress(df['x'], df['y'])\n    df['predicted'] = intercept + slope * df['x']\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom scipy.stats import linregress\n\ndef task_func(df):\n    slope, intercept, r_value, p_value, std_err = linregress(df['x'], df['y'])\n    df['predicted'] = intercept + slope * df['x']\n    return df\n```"}
{"task_id": "BigCodeBench/678", "solution": "import pandas as pd\nimport json\nimport os\nimport shutil\ndef task_func(path):\n    # Create the \"processed\" subdirectory if it doesn't exist\n    if not os.path.exists(os.path.join(path, \"processed\")):\n        os.makedirs(os.path.join(path, \"processed\"))\n\n    # Get a list of all JSON files in the directory\n    json_files = [f for f in os.listdir(path) if f.endswith('.json')]\n\n    # Sort the list of files alphabetically\n    json_files.sort()\n\n    # Initialize an empty DataFrame to store the data from all files\n    df = pd.DataFrame()\n\n    # Process each JSON file\n    for file in json_files:\n        # Read the JSON file into a DataFrame\n        with open(os.path.join(path, file), 'r') as f:\n            data = json.load(f)\n        df_temp = pd.DataFrame(data)\n\n        # Add a \"Source\" column to specify the filename\n        df_temp['Source'] = file\n\n        # Append the data from the current file to the DataFrame\n        df = df.append(df_temp, ignore_index=True)\n\n        # Move the processed file to the \"processed\" subdirectory\n        shutil.move(os.path.join(path, file), os.path.join(path, \"processed\", file))\n\n    return df", "raw_solution": "import pandas as pd\nimport json\nimport os\nimport shutil\n\ndef task_func(path):\n    # Create the \"processed\" subdirectory if it doesn't exist\n    if not os.path.exists(os.path.join(path, \"processed\")):\n        os.makedirs(os.path.join(path, \"processed\"))\n\n    # Get a list of all JSON files in the directory\n    json_files = [f for f in os.listdir(path) if f.endswith('.json')]\n\n    # Sort the list of files alphabetically\n    json_files.sort()\n\n    # Initialize an empty DataFrame to store the data from all files\n    df = pd.DataFrame()\n\n    # Process each JSON file\n    for file in json_files:\n        # Read the JSON file into a DataFrame\n        with open(os.path.join(path, file), 'r') as f:\n            data = json.load(f)\n        df_temp = pd.DataFrame(data)\n\n        # Add a \"Source\" column to specify the filename\n        df_temp['Source'] = file\n\n        # Append the data from the current file to the DataFrame\n        df = df.append(df_temp, ignore_index=True)\n\n        # Move the processed file to the \"processed\" subdirectory\n        shutil.move(os.path.join(path, file), os.path.join(path, \"processed\", file))\n\n    return df\n```"}
{"task_id": "BigCodeBench/679", "solution": "import pandas as pd\nfrom collections import Counter\ndef task_func(df):\n    df['combination'] = df.apply(lambda row: tuple(sorted(row)), axis=1)\n    combination_counts = Counter(df['combination'])\n    return dict(combination_counts)", "raw_solution": "import pandas as pd\nfrom collections import Counter\n\ndef task_func(df):\n    df['combination'] = df.apply(lambda row: tuple(sorted(row)), axis=1)\n    combination_counts = Counter(df['combination'])\n    return dict(combination_counts)\n```"}
{"task_id": "BigCodeBench/680", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, features):\n    scaler = StandardScaler()\n    df[features] = scaler.fit_transform(df[features])\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, features):\n    scaler = StandardScaler()\n    df[features] = scaler.fit_transform(df[features])\n    return df\n```"}
{"task_id": "BigCodeBench/681", "solution": "import pandas as pd\nimport json\ndef task_func(file_path, key):\n    # Load JSON file into a DataFrame\n    df = pd.read_json(file_path)\n\n    # Remove specific key from each object\n    df = df.drop(key, axis=1)\n\n    # Write the processed DataFrame back into a JSON file\n    df.to_json(file_path, orient='records')\n\n    return df", "raw_solution": "import pandas as pd\nimport json\n\ndef task_func(file_path, key):\n    # Load JSON file into a DataFrame\n    df = pd.read_json(file_path)\n\n    # Remove specific key from each object\n    df = df.drop(key, axis=1)\n\n    # Write the processed DataFrame back into a JSON file\n    df.to_json(file_path, orient='records')\n\n    return df\n```"}
{"task_id": "BigCodeBench/682", "solution": "from collections import Counter\nimport math\ndef task_func(nested_dict):\n    flat_dict = flatten_dict(nested_dict)\n    flat_dict.pop(\"ele\", None)\n    result = {k: math.sin(sum(v)) for k, v in flat_dict.items()}\n    return result\ndef flatten_dict(dd, separator='_', prefix=''):\n    return { prefix + separator + k if prefix else k : v\n             for kk, vv in dd.items()\n             for k, v in flatten_dict(vv, separator, kk).items()\n             } | { k: v for k, v in dd.items() if not isinstance(v, dict) }", "raw_solution": "from collections import Counter\nimport math\n\ndef task_func(nested_dict):\n    flat_dict = flatten_dict(nested_dict)\n    flat_dict.pop(\"ele\", None)\n    result = {k: math.sin(sum(v)) for k, v in flat_dict.items()}\n    return result\n\ndef flatten_dict(dd, separator='_', prefix=''):\n    return { prefix + separator + k if prefix else k : v\n             for kk, vv in dd.items()\n             for k, v in flatten_dict(vv, separator, kk).items()\n             } | { k: v for k, v in dd.items() if not isinstance(v, dict) }\n```"}
{"task_id": "BigCodeBench/683", "solution": "import math\nimport yaml\ndef task_func(yaml_path, key):\n    with open(yaml_path, 'r') as file:\n        data = yaml.safe_load(file)\n\n    if key in data:\n        data[key] = math.cos(data[key])\n\n    with open(yaml_path, 'w') as file:\n        yaml.safe_dump(data, file)\n\n    return data", "raw_solution": "import math\nimport yaml\n\ndef task_func(yaml_path, key):\n    with open(yaml_path, 'r') as file:\n        data = yaml.safe_load(file)\n\n    if key in data:\n        data[key] = math.cos(data[key])\n\n    with open(yaml_path, 'w') as file:\n        yaml.safe_dump(data, file)\n\n    return data\n```"}
{"task_id": "BigCodeBench/684", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(df, col):\n    df = df.drop(columns=[col])\n    df['IsEvenIndex'] = df.index % 2 == 0\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\ndef task_func(df, col):\n    df = df.drop(columns=[col])\n    df['IsEvenIndex'] = df.index % 2 == 0\n    return df\n```"}
{"task_id": "BigCodeBench/685", "solution": "from collections import Counter\nfrom itertools import chain\ndef task_func(list_of_lists):\n    merged_list = list(chain(*list_of_lists))\n    return Counter(merged_list)", "raw_solution": "from collections import Counter\nfrom itertools import chain\n\ndef task_func(list_of_lists):\n    merged_list = list(chain(*list_of_lists))\n    return Counter(merged_list)\n```"}
{"task_id": "BigCodeBench/686", "solution": "import numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\ndef task_func(list_of_lists):\n    # Merge the lists\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    \n    # One-hot encode the merged list\n    one_hot_encoder = OneHotEncoder(sparse=False)\n    one_hot = one_hot_encoder.fit_transform(np.array(merged_list).reshape(-1, 1))\n    \n    return one_hot", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\n\ndef task_func(list_of_lists):\n    # Merge the lists\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    \n    # One-hot encode the merged list\n    one_hot_encoder = OneHotEncoder(sparse=False)\n    one_hot = one_hot_encoder.fit_transform(np.array(merged_list).reshape(-1, 1))\n    \n    return one_hot\n```"}
{"task_id": "BigCodeBench/687", "solution": "import numpy as np\nfrom scipy.stats import mode\ndef task_func(list_of_lists):\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    mode_value, mode_count = mode(merged_list)\n    return (mode_value[0], mode_count[0]), mode_value[0], mode_count[0]", "raw_solution": "import numpy as np\nfrom scipy.stats import mode\n\ndef task_func(list_of_lists):\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    mode_value, mode_count = mode(merged_list)\n    return (mode_value[0], mode_count[0]), mode_value[0], mode_count[0]\n```"}
{"task_id": "BigCodeBench/688", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    scaler = StandardScaler()\n    df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df_standardized", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    scaler = StandardScaler()\n    df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df_standardized\n```"}
{"task_id": "BigCodeBench/689", "solution": "import numpy as np\nfrom scipy import stats\ndef task_func(df):\n    p_values = {}\n    for col in df.columns:\n        p_value = stats.shapiro(df[col]).pvalue\n        p_values[col] = p_value\n    return p_values", "raw_solution": "import numpy as np\nfrom scipy import stats\ndef task_func(df):\n    p_values = {}\n    for col in df.columns:\n        p_value = stats.shapiro(df[col]).pvalue\n        p_values[col] = p_value\n    return p_values\n```"}
{"task_id": "BigCodeBench/690", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    model = LinearRegression()\n    model.fit(df[['X']], df['Y'])\n    return model", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\nROWS = 100\nCOLUMNS = ['X', 'Y']\n\ndef task_func(df):\n    model = LinearRegression()\n    model.fit(df[['X']], df['Y'])\n    return model\n```"}
{"task_id": "BigCodeBench/691", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    scaler = StandardScaler()\n    df_scaled = scaler.fit_transform(df)\n    kmeans = KMeans(n_clusters=3)\n    kmeans.fit(df_scaled)\n    labels = kmeans.labels_\n    return labels", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    scaler = StandardScaler()\n    df_scaled = scaler.fit_transform(df)\n    kmeans = KMeans(n_clusters=3)\n    kmeans.fit(df_scaled)\n    labels = kmeans.labels_\n    return labels\n```"}
{"task_id": "BigCodeBench/692", "solution": "import math\nimport pandas as pd\ndef task_func(tuples_list):\n    df = pd.DataFrame(tuples_list, columns=['x', 'y'])\n    df['x'] = df['x'].apply(math.sin)\n    df['y'] = df['y'].apply(math.sin)\n    return df", "raw_solution": "import math\nimport pandas as pd\n\ndef task_func(tuples_list):\n    df = pd.DataFrame(tuples_list, columns=['x', 'y'])\n    df['x'] = df['x'].apply(math.sin)\n    df['y'] = df['y'].apply(math.sin)\n    return df\n```"}
{"task_id": "BigCodeBench/693", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(tuples_list, columns):\n    df = pd.DataFrame(tuples_list, columns=columns)\n    scaler = StandardScaler()\n    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=columns)\n    return df_scaled", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(tuples_list, columns):\n    df = pd.DataFrame(tuples_list, columns=columns)\n    scaler = StandardScaler()\n    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=columns)\n    return df_scaled\n```"}
{"task_id": "BigCodeBench/694", "solution": "import itertools\nimport random\ndef task_func(t, n):\n    combinations = list(itertools.product(t, repeat=n))\n    return random.choice(combinations)", "raw_solution": "import itertools\nimport random\n\ndef task_func(t, n):\n    combinations = list(itertools.product(t, repeat=n))\n    return random.choice(combinations)\n```"}
{"task_id": "BigCodeBench/695", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\ndef task_func(tuples_list, n_components):\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(np.array(tuples_list))\n    return transformed_data", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\n\ndef task_func(tuples_list, n_components):\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(np.array(tuples_list))\n    return transformed_data\n```"}
{"task_id": "BigCodeBench/696", "solution": "import numpy as np\nimport math\nimport random\nfrom random import uniform\ndef task_func(radius, num_points):\n    points = []\n    for _ in range(num_points):\n        angle = random.uniform(0, 2 * math.pi)\n        distance = random.uniform(0, radius)\n        x = distance * math.cos(angle)\n        y = distance * math.sin(angle)\n        points.append((x, y))\n    return points", "raw_solution": "import numpy as np\nimport math\nimport random\nfrom random import uniform\n\ndef task_func(radius, num_points):\n    points = []\n    for _ in range(num_points):\n        angle = random.uniform(0, 2 * math.pi)\n        distance = random.uniform(0, radius)\n        x = distance * math.cos(angle)\n        y = distance * math.sin(angle)\n        points.append((x, y))\n    return points\n```"}
{"task_id": "BigCodeBench/697", "solution": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    X = df[['feature']]\n    y = df['value']\n    model = LinearRegression()\n    model.fit(X, y)\n    result = {'coefficient': model.coef_[0], 'intercept': model.intercept_}\n    return result", "raw_solution": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    X = df[['feature']]\n    y = df['value']\n    model = LinearRegression()\n    model.fit(X, y)\n    result = {'coefficient': model.coef_[0], 'intercept': model.intercept_}\n    return result\n```"}
{"task_id": "BigCodeBench/698", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\ndef task_func(df):\n    X = df.drop('target', axis=1)\n    y = df['target']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    return X_train, X_test, y_train, y_test", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(df):\n    X = df.drop('target', axis=1)\n    y = df['target']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    return X_train, X_test, y_train, y_test\n```"}
{"task_id": "BigCodeBench/699", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\ndef task_func(x_list, y_list, n_clusters=2, random_state=0):\n    data = pd.DataFrame({'x': x_list, 'y': y_list})\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state).fit(data)\n    return kmeans.labels_, kmeans.cluster_centers_", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\n\ndef task_func(x_list, y_list, n_clusters=2, random_state=0):\n    data = pd.DataFrame({'x': x_list, 'y': y_list})\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state).fit(data)\n    return kmeans.labels_, kmeans.cluster_centers_\n```"}
{"task_id": "BigCodeBench/700", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(data, cols):\n    df = pd.DataFrame(data, columns=cols)\n    correlation_matrix = df.corr()\n    return correlation_matrix", "raw_solution": "import pandas as pd\nimport numpy as np\ndef task_func(data, cols):\n    df = pd.DataFrame(data, columns=cols)\n    correlation_matrix = df.corr()\n    return correlation_matrix\n```"}
{"task_id": "BigCodeBench/701", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, target):\n    X = df.drop(columns=[target])\n    y = df[target]\n    model = LinearRegression()\n    model.fit(X, y)\n    score = model.score(X, y)\n    return score", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, target):\n    X = df.drop(columns=[target])\n    y = df[target]\n    model = LinearRegression()\n    model.fit(X, y)\n    score = model.score(X, y)\n    return score\n```"}
{"task_id": "BigCodeBench/702", "solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\ndef task_func(df):\n    pca = PCA(n_components=2)\n    df_pca = pca.fit_transform(df)\n    df_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n    return df_pca", "raw_solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\n\ndef task_func(df):\n    pca = PCA(n_components=2)\n    df_pca = pca.fit_transform(df)\n    df_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n    return df_pca\n```"}
{"task_id": "BigCodeBench/703", "solution": "import pandas as pd\nfrom sklearn.cluster import DBSCAN\ndef task_func(data, cols):\n    df = pd.DataFrame(data, columns=cols)\n    dbscan = DBSCAN(eps=3, min_samples=2)\n    df['Cluster'] = dbscan.fit_predict(df[cols])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import DBSCAN\n\ndef task_func(data, cols):\n    df = pd.DataFrame(data, columns=cols)\n    dbscan = DBSCAN(eps=3, min_samples=2)\n    df['Cluster'] = dbscan.fit_predict(df[cols])\n    return df\n```"}
{"task_id": "BigCodeBench/704", "solution": "import pandas as pd\nfrom itertools import combinations\ndef task_func(data, cols, percentage):\n    # Constants\n    MIN_PERCENTAGE = 0.75\n    # Initialize an empty list to store the combinations\n    corr_combinations = []\n    # Iterate over all possible combinations of columns\n    for i in range(2, len(cols) + 1):\n        for comb in combinations(cols, i):\n            # Calculate the correlation matrix\n            corr_matrix = data[list(comb)].corr()\n            # Check if the absolute correlation is greater than the threshold\n            if (corr_matrix.abs() > percentage).all().all():\n                corr_combinations.append(comb)\n    return corr_combinations", "raw_solution": "import pandas as pd\nfrom itertools import combinations\n\ndef task_func(data, cols, percentage):\n    # Constants\n    MIN_PERCENTAGE = 0.75\n    # Initialize an empty list to store the combinations\n    corr_combinations = []\n    # Iterate over all possible combinations of columns\n    for i in range(2, len(cols) + 1):\n        for comb in combinations(cols, i):\n            # Calculate the correlation matrix\n            corr_matrix = data[list(comb)].corr()\n            # Check if the absolute correlation is greater than the threshold\n            if (corr_matrix.abs() > percentage).all().all():\n                corr_combinations.append(comb)\n    return corr_combinations\n```"}
{"task_id": "BigCodeBench/705", "solution": "import numpy as np\nfrom scipy import stats\ndef task_func(df, column, alpha):\n    \"\"\"\n    Test the normality of a particular numeric column from a DataFrame with Shapiro-Wilk test.\n    :param df: DataFrame to test\n    :param column: Column to test\n    :param alpha: Significance level\n    :return: True if the column passes the normality test, False otherwise.\n    \"\"\"\n    # Extract the column data\n    data = df[column]\n\n    # Perform the Shapiro-Wilk test\n    stat, p = stats.shapiro(data)\n\n    # Check if the p-value is less than the significance level\n    return p < alpha", "raw_solution": "import numpy as np\nfrom scipy import stats\ndef task_func(df, column, alpha):\n    \"\"\"\n    Test the normality of a particular numeric column from a DataFrame with Shapiro-Wilk test.\n    :param df: DataFrame to test\n    :param column: Column to test\n    :param alpha: Significance level\n    :return: True if the column passes the normality test, False otherwise.\n    \"\"\"\n    # Extract the column data\n    data = df[column]\n\n    # Perform the Shapiro-Wilk test\n    stat, p = stats.shapiro(data)\n\n    # Check if the p-value is less than the significance level\n    return p < alpha\n```"}
{"task_id": "BigCodeBench/706", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\ndef task_func(data, columns, target_column):\n    X = data[columns]\n    y = data[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    log_reg = LogisticRegression()\n    log_reg.fit(X_train, y_train)\n    y_pred = log_reg.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    return accuracy", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\ndef task_func(data, columns, target_column):\n    X = data[columns]\n    y = data[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    log_reg = LogisticRegression()\n    log_reg.fit(X_train, y_train)\n    y_pred = log_reg.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    return accuracy\n```"}
{"task_id": "BigCodeBench/707", "solution": "import json\nimport numpy as np\ndef task_func(df):\n    df['IntCol'] = np.log10(df['IntCol'])\n    df.to_json('IntCol.json', orient='records')\n    return df", "raw_solution": "import json\nimport numpy as np\ndef task_func(df):\n    df['IntCol'] = np.log10(df['IntCol'])\n    df.to_json('IntCol.json', orient='records')\n    return df\n```"}
{"task_id": "BigCodeBench/708", "solution": "import json\nimport csv\nimport os\nimport base64\ndef task_func(raw_string, filename, output_dir):\n    decoded_string = base64.b64decode(raw_string).decode('utf-8')\n    data = json.loads(decoded_string)\n\n    file_path = os.path.join(output_dir, filename)\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(data.keys())\n        writer.writerow(data.values())\n\n    return file_path", "raw_solution": "import json\nimport csv\nimport os\nimport base64\n\ndef task_func(raw_string, filename, output_dir):\n    decoded_string = base64.b64decode(raw_string).decode('utf-8')\n    data = json.loads(decoded_string)\n\n    file_path = os.path.join(output_dir, filename)\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(data.keys())\n        writer.writerow(data.values())\n\n    return file_path\n```"}
{"task_id": "BigCodeBench/709", "solution": "import base64\nimport re\nfrom html import unescape\nimport textwrap\ndef task_func(raw_string, line_length):\n    decoded_string = base64.b64decode(raw_string).decode('utf-8')\n    decoupled_string = unescape(decoded_string)\n    replaced_string = re.sub(r'\\s+', ' ', decoupled_string).strip()\n    wrapped_text = textwrap.fill(replaced_string, line_length)\n    return wrapped_text", "raw_solution": "import base64\nimport re\nfrom html import unescape\nimport textwrap\n\ndef task_func(raw_string, line_length):\n    decoded_string = base64.b64decode(raw_string).decode('utf-8')\n    decoupled_string = unescape(decoded_string)\n    replaced_string = re.sub(r'\\s+', ' ', decoupled_string).strip()\n    wrapped_text = textwrap.fill(replaced_string, line_length)\n    return wrapped_text\n```"}
{"task_id": "BigCodeBench/710", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data_path):\n    df = pd.read_csv(data_path)\n    scaler = MinMaxScaler()\n    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data_path):\n    df = pd.read_csv(data_path)\n    scaler = MinMaxScaler()\n    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df\n```"}
{"task_id": "BigCodeBench/711", "solution": "import json\nimport csv\ndef task_func(json_file, csv_file):\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n\n    with open(csv_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(data[0].keys())\n        for row in data:\n            writer.writerow(row.values())\n\n    return csv_file", "raw_solution": "import json\nimport csv\n\ndef task_func(json_file, csv_file):\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n\n    with open(csv_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(data[0].keys())\n        for row in data:\n            writer.writerow(row.values())\n\n    return csv_file\n```"}
{"task_id": "BigCodeBench/712", "solution": "import os\nimport shutil\nimport glob\ndef task_func(source_dir, dest_dir, extension):\n    count = 0\n    for file in glob.glob(os.path.join(source_dir, f\"*.{extension}\")):\n        shutil.move(file, dest_dir)\n        count += 1\n    return count", "raw_solution": "import os\nimport shutil\nimport glob\ndef task_func(source_dir, dest_dir, extension):\n    count = 0\n    for file in glob.glob(os.path.join(source_dir, f\"*.{extension}\")):\n        shutil.move(file, dest_dir)\n        count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/713", "solution": "import os\nimport re\ndef task_func(log_file_path: str, keywords: list):\n    if not os.path.exists(log_file_path):\n        return []\n\n    with open(log_file_path, 'r') as file:\n        lines = file.readlines()\n\n    formatted_lines = []\n    for line in lines:\n        for keyword in keywords:\n            if keyword in line:\n                timestamp = re.search(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', line).group()\n                message = re.search(r'{}: (.*)'.format(keyword), line).group(1)\n                formatted_line = '{:20} {:20} {}'.format(keyword, timestamp, message)\n                formatted_lines.append(formatted_line)\n                break\n\n    return formatted_lines", "raw_solution": "import os\nimport re\n\ndef task_func(log_file_path: str, keywords: list):\n    if not os.path.exists(log_file_path):\n        return []\n\n    with open(log_file_path, 'r') as file:\n        lines = file.readlines()\n\n    formatted_lines = []\n    for line in lines:\n        for keyword in keywords:\n            if keyword in line:\n                timestamp = re.search(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', line).group()\n                message = re.search(r'{}: (.*)'.format(keyword), line).group(1)\n                formatted_line = '{:20} {:20} {}'.format(keyword, timestamp, message)\n                formatted_lines.append(formatted_line)\n                break\n\n    return formatted_lines\n```"}
{"task_id": "BigCodeBench/714", "solution": "import sys\nfrom pathlib import Path\nPATH_TO_APPEND = '/path/to/whatever'\ndef task_func(path_to_append=PATH_TO_APPEND):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n    # Create a directory in the path if it does not exist\n    Path(path_to_append).mkdir(parents=True, exist_ok=True)\n    return path_to_append", "raw_solution": "import sys\nfrom pathlib import Path\n# Constants\nPATH_TO_APPEND = '/path/to/whatever'\ndef task_func(path_to_append=PATH_TO_APPEND):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n    # Create a directory in the path if it does not exist\n    Path(path_to_append).mkdir(parents=True, exist_ok=True)\n    return path_to_append\n```"}
{"task_id": "BigCodeBench/715", "solution": "import sys\nimport subprocess\nPYTHON_VERSION = '3.8'\nPATH_TO_APPEND = '/path/to/whatever'\ndef task_func(python_version=PYTHON_VERSION, path_to_append=PATH_TO_APPEND):\n    # Switch to the specified Python version\n    subprocess.run(['pyenv', 'global', python_version], check=True)\n\n    # Add the specified path to sys.path\n    sys.path.append(path_to_append)\n\n    # Return the Python version that was switched to\n    return python_version", "raw_solution": "import sys\nimport subprocess\n\n# Constants\nPYTHON_VERSION = '3.8'\nPATH_TO_APPEND = '/path/to/whatever'\n\ndef task_func(python_version=PYTHON_VERSION, path_to_append=PATH_TO_APPEND):\n    # Switch to the specified Python version\n    subprocess.run(['pyenv', 'global', python_version], check=True)\n\n    # Add the specified path to sys.path\n    sys.path.append(path_to_append)\n\n    # Return the Python version that was switched to\n    return python_version\n```"}
{"task_id": "BigCodeBench/716", "solution": "import sys\nimport json\nfrom datetime import datetime\nPATH_TO_APPEND = '/path/to/whatever'\nJSON_FILE = '/path/to/json_file.json'\ndef task_func(path_to_append=PATH_TO_APPEND, json_file=JSON_FILE):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Read the JSON file\n    with open(json_file, 'r') as file:\n        json_data = json.load(file)\n\n    # Update the 'last_updated' key with the current date and time\n    json_data['last_updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n    # Write the updated JSON data back to the file\n    with open(json_file, 'w') as file:\n        json.dump(json_data, file)\n\n    return json_data", "raw_solution": "import sys\nimport json\nfrom datetime import datetime\n\n# Constants\nPATH_TO_APPEND = '/path/to/whatever'\nJSON_FILE = '/path/to/json_file.json'\n\ndef task_func(path_to_append=PATH_TO_APPEND, json_file=JSON_FILE):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Read the JSON file\n    with open(json_file, 'r') as file:\n        json_data = json.load(file)\n\n    # Update the 'last_updated' key with the current date and time\n    json_data['last_updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n    # Write the updated JSON data back to the file\n    with open(json_file, 'w') as file:\n        json.dump(json_data, file)\n\n    return json_data\n```"}
{"task_id": "BigCodeBench/717", "solution": "import sys\nfrom configparser import ConfigParser\nPATH_TO_APPEND = '/path/to/whatever'\nCONFIG_FILE = '/path/to/config.ini'\ndef task_func(path_to_append=PATH_TO_APPEND, config_file=CONFIG_FILE):\n    # Add the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Read the configuration file\n    config = ConfigParser()\n    config.read(config_file)\n\n    # Update the configuration file\n    config.set('DEFAULT', 'path', path_to_append)\n    with open(config_file, 'w') as file:\n        config.write(file)\n\n    return config, config_file", "raw_solution": "import sys\nfrom configparser import ConfigParser\n\n# Constants\nPATH_TO_APPEND = '/path/to/whatever'\nCONFIG_FILE = '/path/to/config.ini'\n\ndef task_func(path_to_append=PATH_TO_APPEND, config_file=CONFIG_FILE):\n    # Add the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Read the configuration file\n    config = ConfigParser()\n    config.read(config_file)\n\n    # Update the configuration file\n    config.set('DEFAULT', 'path', path_to_append)\n    with open(config_file, 'w') as file:\n        config.write(file)\n\n    return config, config_file\n```"}
{"task_id": "BigCodeBench/718", "solution": "import re\nimport numpy as np\nfrom scipy.stats import ttest_rel\ndef task_func(text1, text2):\n    if len(text1) != len(text2):\n        return np.nan, np.nan\n\n    words1 = re.findall(r'\\b\\w+\\b', text1)\n    words2 = re.findall(r'\\b\\w+\\b', text2)\n\n    if len(words1) != len(words2):\n        return np.nan, np.nan\n\n    t_statistic, p_value = ttest_rel(words1, words2)\n\n    return t_statistic, p_value", "raw_solution": "import re\nimport numpy as np\nfrom scipy.stats import ttest_rel\n\ndef task_func(text1, text2):\n    if len(text1) != len(text2):\n        return np.nan, np.nan\n\n    words1 = re.findall(r'\\b\\w+\\b', text1)\n    words2 = re.findall(r'\\b\\w+\\b', text2)\n\n    if len(words1) != len(words2):\n        return np.nan, np.nan\n\n    t_statistic, p_value = ttest_rel(words1, words2)\n\n    return t_statistic, p_value\n```"}
{"task_id": "BigCodeBench/719", "solution": "import re\nimport os\nimport glob\ndef task_func(directory, word):\n    count = 0\n    for filename in glob.glob(os.path.join(directory, '*')):\n        if os.path.isfile(filename):\n            with open(filename, 'r') as file:\n                content = file.read()\n                if re.search(word, content):\n                    count += 1\n    return count", "raw_solution": "import re\nimport os\nimport glob\ndef task_func(directory, word):\n    count = 0\n    for filename in glob.glob(os.path.join(directory, '*')):\n        if os.path.isfile(filename):\n            with open(filename, 'r') as file:\n                content = file.read()\n                if re.search(word, content):\n                    count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/720", "solution": "import os\nimport csv\nimport random\nfrom datetime import datetime\ndef task_func():\n    file_path = \"task_func_data/Output.txt\"\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Date\", \"Temperature\", \"Humidity\"])\n        for i in range(10):\n            date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n            temperature = random.uniform(20, 30)\n            humidity = random.uniform(40, 60)\n            writer.writerow([date, temperature, humidity])\n    os.remove(file_path)\n    return file_path", "raw_solution": "import os\nimport csv\nimport random\nfrom datetime import datetime\n\ndef task_func():\n    file_path = \"task_func_data/Output.txt\"\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Date\", \"Temperature\", \"Humidity\"])\n        for i in range(10):\n            date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n            temperature = random.uniform(20, 30)\n            humidity = random.uniform(40, 60)\n            writer.writerow([date, temperature, humidity])\n    os.remove(file_path)\n    return file_path\n```"}
{"task_id": "BigCodeBench/721", "solution": "import os\nimport csv\nfrom collections import Counter\ndef task_func(file_path):\n    if not os.path.exists(file_path):\n        return None\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        words = [row[0] for row in reader]\n        if not words:\n            return None\n        word_count = Counter(words)\n        most_common_word, most_common_count = word_count.most_common(1)[0]\n        return (most_common_word, most_common_count)", "raw_solution": "import os\nimport csv\nfrom collections import Counter\n\ndef task_func(file_path):\n    if not os.path.exists(file_path):\n        return None\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        words = [row[0] for row in reader]\n        if not words:\n            return None\n        word_count = Counter(words)\n        most_common_word, most_common_count = word_count.most_common(1)[0]\n        return (most_common_word, most_common_count)\n```"}
{"task_id": "BigCodeBench/722", "solution": "import urllib.request\nimport os\nimport re\nTARGET_FILE = 'downloaded_file.txt'\nSEARCH_PATTERN = r'\\bERROR\\b'\ndef task_func(url):\n    # Download the file\n    urllib.request.urlretrieve(url, TARGET_FILE)\n\n    # Read the file\n    with open(TARGET_FILE, 'r') as file:\n        content = file.read()\n\n    # Search for occurrences of 'ERROR'\n    occurrences = len(re.findall(SEARCH_PATTERN, content))\n\n    # Remove the downloaded file\n    os.remove(TARGET_FILE)\n\n    return occurrences", "raw_solution": "import urllib.request\nimport os\nimport re\n\n# Constants\nTARGET_FILE = 'downloaded_file.txt'\nSEARCH_PATTERN = r'\\bERROR\\b'\n\ndef task_func(url):\n    # Download the file\n    urllib.request.urlretrieve(url, TARGET_FILE)\n\n    # Read the file\n    with open(TARGET_FILE, 'r') as file:\n        content = file.read()\n\n    # Search for occurrences of 'ERROR'\n    occurrences = len(re.findall(SEARCH_PATTERN, content))\n\n    # Remove the downloaded file\n    os.remove(TARGET_FILE)\n\n    return occurrences\n```"}
{"task_id": "BigCodeBench/723", "solution": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n    # Open the URL\n    response = urllib.request.urlopen(url)\n    # Parse the HTML content\n    soup = BeautifulSoup(response, 'html.parser')\n    # Find the table\n    table = soup.find('table')\n    # Find the rows in the table\n    rows = table.find_all('tr')\n    # Open the CSV file\n    with open(CSV_FILE_PATH, 'w', newline='') as file:\n        writer = csv.writer(file)\n        # Write the headers\n        headers = [header.text for header in rows[0].find_all('th')]\n        writer.writerow(headers)\n        # Write the data\n        for row in rows[1:]:\n            data = [cell.text for cell in row.find_all('td')]\n            writer.writerow(data)\n    return CSV_FILE_PATH", "raw_solution": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n    # Open the URL\n    response = urllib.request.urlopen(url)\n    # Parse the HTML content\n    soup = BeautifulSoup(response, 'html.parser')\n    # Find the table\n    table = soup.find('table')\n    # Find the rows in the table\n    rows = table.find_all('tr')\n    # Open the CSV file\n    with open(CSV_FILE_PATH, 'w', newline='') as file:\n        writer = csv.writer(file)\n        # Write the headers\n        headers = [header.text for header in rows[0].find_all('th')]\n        writer.writerow(headers)\n        # Write the data\n        for row in rows[1:]:\n            data = [cell.text for cell in row.find_all('td')]\n            writer.writerow(data)\n    return CSV_FILE_PATH\n```"}
{"task_id": "BigCodeBench/724", "solution": "import os\nimport json\ndef task_func(config_path: str) -> dict:\n    if not os.path.exists(config_path):\n        raise FileNotFoundError(\"The provided configuration file does not exist.\")\n    with open(config_path, 'r') as file:\n        config = json.load(file)\n    return config", "raw_solution": "import os\nimport json\n\ndef task_func(config_path: str) -> dict:\n    if not os.path.exists(config_path):\n        raise FileNotFoundError(\"The provided configuration file does not exist.\")\n    with open(config_path, 'r') as file:\n        config = json.load(file)\n    return config\n```"}
{"task_id": "BigCodeBench/725", "solution": "import codecs\nimport os\nimport glob\nDIRECTORY_PATH = './files/'\ndef task_func(directory=DIRECTORY_PATH, from_encoding='cp1251', to_encoding='utf8'):\n    for filename in glob.glob(os.path.join(directory, '*.txt')):\n        with codecs.open(filename, 'r', encoding=from_encoding) as f:\n            content = f.read()\n        with codecs.open(filename, 'w', encoding=to_encoding) as f:\n            f.write(content)", "raw_solution": "import codecs\nimport os\nimport glob\n# Constants\nDIRECTORY_PATH = './files/'\ndef task_func(directory=DIRECTORY_PATH, from_encoding='cp1251', to_encoding='utf8'):\n    for filename in glob.glob(os.path.join(directory, '*.txt')):\n        with codecs.open(filename, 'r', encoding=from_encoding) as f:\n            content = f.read()\n        with codecs.open(filename, 'w', encoding=to_encoding) as f:\n            f.write(content)\n```"}
{"task_id": "BigCodeBench/726", "solution": "import re\nimport random\nfrom nltk.corpus import words\nfrom random import sample\nimport nltk\nSAMPLE_ENGLISH_WORDS = set(words.words())\ndef task_func(s, n):\n    # Split the string into words\n    words = re.findall(r'\\b\\w+\\b', s)\n    # Filter out non-English words\n    words = [word.lower() for word in words if word.lower() in SAMPLE_ENGLISH_WORDS]\n    # Return up to n different English words\n    return list(set(words))[:n]", "raw_solution": "import re\nimport random\nfrom nltk.corpus import words\nfrom random import sample\n# Ensure the words corpus is downloaded\nimport nltk\nnltk.download('words')\n# Constants\nSAMPLE_ENGLISH_WORDS = set(words.words())  # Correct initialization\ndef task_func(s, n):\n    # Split the string into words\n    words = re.findall(r'\\b\\w+\\b', s)\n    # Filter out non-English words\n    words = [word.lower() for word in words if word.lower() in SAMPLE_ENGLISH_WORDS]\n    # Return up to n different English words\n    return list(set(words))[:n]\n```"}
{"task_id": "BigCodeBench/727", "solution": "import re\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np\nSENTENCES = ['This is a sentence', 'Another sentence here', 'More sentences']\ndef task_func(s: str) -> np.ndarray:\n    vectorizer = CountVectorizer(stop_words='english')\n    vectorizer.fit_transform(SENTENCES)\n    return vectorizer.transform([s]).toarray()[0]", "raw_solution": "import re\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np\n# Constants\nSENTENCES = ['This is a sentence', 'Another sentence here', 'More sentences']\ndef task_func(s: str) -> np.ndarray:\n    vectorizer = CountVectorizer(stop_words='english')\n    vectorizer.fit_transform(SENTENCES)\n    return vectorizer.transform([s]).toarray()[0]\n```"}
{"task_id": "BigCodeBench/728", "solution": "import csv\nimport io\ndef task_func(filename, from_encoding='cp1251', to_encoding='utf8', delimiter=','):\n    with open(filename, 'r', encoding=from_encoding) as file:\n        csv_data = file.read()\n\n    converted_data = csv_data.encode(to_encoding).decode(to_encoding)\n\n    csv_string = io.StringIO(converted_data)\n    csv_reader = csv.reader(csv_string, delimiter=delimiter)\n\n    headers = next(csv_reader)\n    rows = [dict(zip(headers, row)) for row in csv_reader]\n\n    return rows, converted_data", "raw_solution": "import csv\nimport io\n\ndef task_func(filename, from_encoding='cp1251', to_encoding='utf8', delimiter=','):\n    with open(filename, 'r', encoding=from_encoding) as file:\n        csv_data = file.read()\n\n    converted_data = csv_data.encode(to_encoding).decode(to_encoding)\n\n    csv_string = io.StringIO(converted_data)\n    csv_reader = csv.reader(csv_string, delimiter=delimiter)\n\n    headers = next(csv_reader)\n    rows = [dict(zip(headers, row)) for row in csv_reader]\n\n    return rows, converted_data\n```"}
{"task_id": "BigCodeBench/729", "solution": "import pickle\nimport os\nimport random\nimport string\ndef task_func(strings, filename=None):\n    if filename is None:\n        filename = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10)) + '.pkl'\n    with open(filename, 'wb') as f:\n        pickle.dump(strings, f)\n    with open(filename, 'rb') as f:\n        loaded_strings = pickle.load(f)\n    os.remove(filename)\n    return loaded_strings", "raw_solution": "import pickle\nimport os\nimport random\nimport string\n\ndef task_func(strings, filename=None):\n    if filename is None:\n        filename = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10)) + '.pkl'\n    with open(filename, 'wb') as f:\n        pickle.dump(strings, f)\n    with open(filename, 'rb') as f:\n        loaded_strings = pickle.load(f)\n    os.remove(filename)\n    return loaded_strings\n```"}
{"task_id": "BigCodeBench/730", "solution": "import pickle\nimport os\nfrom datetime import datetime\nFILE_NAME = 'save.pkl'\ndef task_func(dt):\n    with open(FILE_NAME, 'wb') as f:\n        pickle.dump(dt, f)\n\n    with open(FILE_NAME, 'rb') as f:\n        loaded_dt = pickle.load(f)\n\n    return loaded_dt", "raw_solution": "import pickle\nimport os\nfrom datetime import datetime\n\n# Constants\nFILE_NAME = 'save.pkl'\n\ndef task_func(dt):\n    with open(FILE_NAME, 'wb') as f:\n        pickle.dump(dt, f)\n\n    with open(FILE_NAME, 'rb') as f:\n        loaded_dt = pickle.load(f)\n\n    return loaded_dt\n```"}
{"task_id": "BigCodeBench/731", "solution": "import pickle\nimport os\nfrom sklearn.datasets import make_classification\nFILE_NAME = 'save.pkl'\ndef task_func(data, target):\n    with open(FILE_NAME, 'wb') as file:\n        pickle.dump((data, target), file)\n    with open(FILE_NAME, 'rb') as file:\n        loaded_data = pickle.load(file)\n    return loaded_data", "raw_solution": "import pickle\nimport os\nfrom sklearn.datasets import make_classification\n\n# Constants\nFILE_NAME = 'save.pkl'\nDATA, TARGET = make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=10, n_classes=2, random_state=1)\n\ndef task_func(data, target):\n    with open(FILE_NAME, 'wb') as file:\n        pickle.dump((data, target), file)\n    with open(FILE_NAME, 'rb') as file:\n        loaded_data = pickle.load(file)\n    return loaded_data\n\n# Test the function\nassert task_func(DATA, TARGET) == (DATA, TARGET)\n```"}
{"task_id": "BigCodeBench/732", "solution": "import re\nimport string\nfrom nltk.stem import PorterStemmer\nfrom collections import Counter\nSTEMMER = PorterStemmer()\ndef task_func(content):\n    words = re.findall(r'\\b\\w+\\b', content)\n    stems = [STEMMER.stem(word) for word in words[:-1]]\n    return dict(Counter(stems))", "raw_solution": "import re\nimport string\nfrom nltk.stem import PorterStemmer\nfrom collections import Counter\nSTEMMER = PorterStemmer()\ndef task_func(content):\n    words = re.findall(r'\\b\\w+\\b', content)\n    stems = [STEMMER.stem(word) for word in words[:-1]]\n    return dict(Counter(stems))\n```"}
{"task_id": "BigCodeBench/733", "solution": "import re\nimport string\ndef task_func(content):\n    stop_words = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"to\", \"with\", \"for\", \"by\", \"from\", \"of\", \"and\", \"or\", \"but\", \"is\", \"was\", \"that\", \"this\", \"it\", \"to\", \"as\", \"an\", \"with\", \"he\", \"she\", \"they\", \"i\", \"me\", \"my\", \"we\", \"us\", \"our\", \"ours\", \"you\", \"your\", \"yours\", \"he\", \"him\", \"his\", \"her\", \"hers\", \"their\", \"theirs\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n    words = re.findall(r'\\b\\w+\\b', content)\n    count = 0\n    for word in words[:-1]:\n        if word.lower() not in stop_words:\n            count += 1\n    return count", "raw_solution": "import re\nimport string\ndef task_func(content):\n    stop_words = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"to\", \"with\", \"for\", \"by\", \"from\", \"of\", \"and\", \"or\", \"but\", \"is\", \"was\", \"that\", \"this\", \"it\", \"to\", \"as\", \"an\", \"with\", \"he\", \"she\", \"they\", \"i\", \"me\", \"my\", \"we\", \"us\", \"our\", \"ours\", \"you\", \"your\", \"yours\", \"he\", \"him\", \"his\", \"her\", \"hers\", \"their\", \"theirs\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n    words = re.findall(r'\\b\\w+\\b', content)\n    count = 0\n    for word in words[:-1]:\n        if word.lower() not in stop_words:\n            count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/734", "solution": "import nltk\nfrom collections import Counter\ndef task_func(content):\n    words = nltk.word_tokenize(content)\n    tags = nltk.pos_tag(words)\n    pos_count = Counter(tag for word, tag in tags)\n    return pos_count", "raw_solution": "import nltk\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nfrom collections import Counter\ndef task_func(content):\n    words = nltk.word_tokenize(content)\n    tags = nltk.pos_tag(words)\n    pos_count = Counter(tag for word, tag in tags)\n    return pos_count\n```"}
{"task_id": "BigCodeBench/735", "solution": "import numpy as np\nfrom itertools import chain\ndef task_func(L):\n    flat_list = list(chain(*L))\n    mean = np.mean(flat_list)\n    variance = np.var(flat_list)\n    return {'mean': mean, 'variance': variance}", "raw_solution": "import numpy as np\nfrom itertools import chain\n\ndef task_func(L):\n    flat_list = list(chain(*L))\n    mean = np.mean(flat_list)\n    variance = np.var(flat_list)\n    return {'mean': mean, 'variance': variance}\n```"}
{"task_id": "BigCodeBench/736", "solution": "import numpy as np\nfrom scipy import stats\ndef task_func(L):\n    flat_list = [item for sublist in L for item in sublist]\n    mode = stats.mode(flat_list)\n    return mode.mode[0]", "raw_solution": "import numpy as np\nfrom scipy import stats\ndef task_func(L):\n    flat_list = [item for sublist in L for item in sublist]\n    mode = stats.mode(flat_list)\n    return mode.mode[0]\n```"}
{"task_id": "BigCodeBench/737", "solution": "import numpy as np\nimport math\ndef task_func(L):\n    flat_list = [item for sublist in L for item in sublist]\n    flat_list.sort()\n    n = len(flat_list)\n    if n % 2 == 0:\n        median = (flat_list[n//2] + flat_list[n//2 - 1]) / 2\n    else:\n        median = flat_list[n//2]\n    return median", "raw_solution": "import numpy as np\nimport math\ndef task_func(L):\n    flat_list = [item for sublist in L for item in sublist]\n    flat_list.sort()\n    n = len(flat_list)\n    if n % 2 == 0:\n        median = (flat_list[n//2] + flat_list[n//2 - 1]) / 2\n    else:\n        median = flat_list[n//2]\n    return median\n```"}
{"task_id": "BigCodeBench/738", "solution": "import numpy as np\nfrom scipy.stats import iqr\ndef task_func(L):\n    flat_list = [item for sublist in L for item in sublist]\n    return iqr(flat_list)", "raw_solution": "import numpy as np\nfrom scipy.stats import iqr\n\ndef task_func(L):\n    flat_list = [item for sublist in L for item in sublist]\n    return iqr(flat_list)\n```"}
{"task_id": "BigCodeBench/739", "solution": "import struct\nimport random\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_key=None):\n    if hex_key is None:\n        hex_key = random.choice(KEYS)\n    float_number = struct.unpack('f', bytes.fromhex(hex_key))[0]\n    rounded_float = round(float_number, 2)\n    return rounded_float", "raw_solution": "import struct\nimport random\n# Constants\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_key=None):\n    if hex_key is None:\n        hex_key = random.choice(KEYS)\n    float_number = struct.unpack('f', bytes.fromhex(hex_key))[0]\n    rounded_float = round(float_number, 2)\n    return rounded_float\n```"}
{"task_id": "BigCodeBench/740", "solution": "from collections import Counter\nimport heapq\ndef task_func(my_dict):\n    # Create a Counter object from the dictionary\n    counter = Counter(my_dict)\n    # Use heapq to get the 3 most common letters\n    most_common_letters = heapq.nlargest(3, counter.items(), key=lambda x: x[1])\n    # Return the letters as a list\n    return [letter for letter, count in most_common_letters]", "raw_solution": "from collections import Counter\nimport heapq\n# Constants\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\ndef task_func(my_dict):\n    # Create a Counter object from the dictionary\n    counter = Counter(my_dict)\n    # Use heapq to get the 3 most common letters\n    most_common_letters = heapq.nlargest(3, counter.items(), key=lambda x: x[1])\n    # Return the letters as a list\n    return [letter for letter, count in most_common_letters]\n```"}
{"task_id": "BigCodeBench/741", "solution": "from itertools import groupby\nfrom operator import itemgetter\nKEY_FUNC = itemgetter(0)\ndef task_func(my_dict):\n    sorted_dict = sorted(my_dict.items(), key=KEY_FUNC)\n    aggregated_dict = {}\n    for key, group in groupby(sorted_dict, KEY_FUNC):\n        aggregated_dict[key] = sum(value for _, value in group)\n    return aggregated_dict", "raw_solution": "from itertools import groupby\nfrom operator import itemgetter\n# Constants\nKEY_FUNC = itemgetter(0)\ndef task_func(my_dict):\n    sorted_dict = sorted(my_dict.items(), key=KEY_FUNC)\n    aggregated_dict = {}\n    for key, group in groupby(sorted_dict, KEY_FUNC):\n        aggregated_dict[key] = sum(value for _, value in group)\n    return aggregated_dict\n```"}
{"task_id": "BigCodeBench/742", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(list_of_pairs):\n    if not list_of_pairs:\n        raise Exception(\"Input array is empty\")\n    for pair in list_of_pairs:\n        if not isinstance(pair[0], str) or not isinstance(pair[1], (int, float)):\n            raise ValueError(\"Values are not numeric\")\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    scaler = MinMaxScaler()\n    df['Value'] = scaler.fit_transform(df[['Value']])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(list_of_pairs):\n    if not list_of_pairs:\n        raise Exception(\"Input array is empty\")\n    for pair in list_of_pairs:\n        if not isinstance(pair[0], str) or not isinstance(pair[1], (int, float)):\n            raise ValueError(\"Values are not numeric\")\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    scaler = MinMaxScaler()\n    df['Value'] = scaler.fit_transform(df[['Value']])\n    return df\n```"}
{"task_id": "BigCodeBench/743", "solution": "import json\nimport os\nPREFIXES = [\"is_\", \"has_\", \"can_\", \"should_\"]\ndef task_func(directory):\n    stats = {prefix: 0 for prefix in PREFIXES}\n    for filename in os.listdir(directory):\n        if filename.endswith('.json'):\n            with open(os.path.join(directory, filename), 'r') as file:\n                data = json.load(file)\n                for key in data.keys():\n                    for prefix in PREFIXES:\n                        if key.startswith(prefix):\n                            stats[prefix] += 1\n    return stats", "raw_solution": "import json\nimport os\n\n# Constants\nPREFIXES = [\"is_\", \"has_\", \"can_\", \"should_\"]\n\ndef task_func(directory):\n    stats = {prefix: 0 for prefix in PREFIXES}\n    for filename in os.listdir(directory):\n        if filename.endswith('.json'):\n            with open(os.path.join(directory, filename), 'r') as file:\n                data = json.load(file)\n                for key in data.keys():\n                    for prefix in PREFIXES:\n                        if key.startswith(prefix):\n                            stats[prefix] += 1\n    return stats\n```"}
{"task_id": "BigCodeBench/744", "solution": "import nltk\nfrom string import punctuation\nimport pandas as pd\ndef task_func(text):\n    if not isinstance(text, str):\n        raise ValueError(\"text must be a string\")\n\n    words = nltk.word_tokenize(text)\n    words = [word for word in words if word[0] == '$' and word not in punctuation]\n\n    freq = nltk.FreqDist(words)\n    df = pd.DataFrame(list(freq.items()), columns=[\"Word\", \"Frequency\"])\n    df.set_index(\"Word\", inplace=True)\n\n    return df", "raw_solution": "import nltk\nfrom string import punctuation\nimport pandas as pd\n\ndef task_func(text):\n    if not isinstance(text, str):\n        raise ValueError(\"text must be a string\")\n\n    words = nltk.word_tokenize(text)\n    words = [word for word in words if word[0] == '$' and word not in punctuation]\n\n    freq = nltk.FreqDist(words)\n    df = pd.DataFrame(list(freq.items()), columns=[\"Word\", \"Frequency\"])\n    df.set_index(\"Word\", inplace=True)\n\n    return df"}
{"task_id": "BigCodeBench/745", "solution": "import subprocess\nimport random\nSCRIPTS = ['script1.sh', 'script2.sh', 'script3.sh']\nSCRIPTS_DIR = '/path/to/scripts'\ndef task_func():\n    script = random.choice(SCRIPTS)\n    script_path = f\"{SCRIPTS_DIR}/{script}\"\n    subprocess.run([\"bash\", script_path])\n    return script_path", "raw_solution": "import subprocess\nimport random\n\n# Constants\nSCRIPTS = ['script1.sh', 'script2.sh', 'script3.sh']\nSCRIPTS_DIR = '/path/to/scripts'\n\ndef task_func():\n    script = random.choice(SCRIPTS)\n    script_path = f\"{SCRIPTS_DIR}/{script}\"\n    subprocess.run([\"bash\", script_path])\n    return script_path\n```"}
{"task_id": "BigCodeBench/746", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, target_column, target_values=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"df must be a DataFrame\")\n    if not isinstance(target_column, str):\n        raise ValueError(\"target_column must be a string\")\n    if target_values is not None and not hasattr(target_values, '__iter__'):\n        raise ValueError(\"target_values must be an array-like object\")\n\n    if target_values is not None:\n        df = df[df[target_column].isin(target_values)]\n    else:\n        df = df.dropna(subset=[target_column])\n\n    df = df.replace(np.nan, 0)\n\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    model = LinearRegression()\n    model.fit(X, y)\n\n    return model", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, target_column, target_values=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"df must be a DataFrame\")\n    if not isinstance(target_column, str):\n        raise ValueError(\"target_column must be a string\")\n    if target_values is not None and not hasattr(target_values, '__iter__'):\n        raise ValueError(\"target_values must be an array-like object\")\n\n    if target_values is not None:\n        df = df[df[target_column].isin(target_values)]\n    else:\n        df = df.dropna(subset=[target_column])\n\n    df = df.replace(np.nan, 0)\n\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    model = LinearRegression()\n    model.fit(X, y)\n\n    return model\n```"}
{"task_id": "BigCodeBench/747", "solution": "import re\nimport math\ndef task_func(s):\n    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|[-+]?\\d+\", s)\n    count = len(numbers)\n    sqrt_sum = sum(math.sqrt(float(num)) for num in numbers)\n    return count, sqrt_sum", "raw_solution": "import re\nimport math\n\ndef task_func(s):\n    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|[-+]?\\d+\", s)\n    count = len(numbers)\n    sqrt_sum = sum(math.sqrt(float(num)) for num in numbers)\n    return count, sqrt_sum\n```"}
{"task_id": "BigCodeBench/748", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, age, weight):\n    if 'Age' not in df.columns or 'Weight' not in df.columns:\n        raise KeyError(\"The input DataFrame does not contain the required columns 'Age' and 'Weight'.\")\n\n    filtered_df = df[(df['Age'] < age) & (df['Weight'] > weight)]\n\n    if filtered_df.empty:\n        return filtered_df\n\n    scaler = StandardScaler()\n    standardized_df = pd.DataFrame(scaler.fit_transform(filtered_df), columns=filtered_df.columns)\n\n    return standardized_df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, age, weight):\n    if 'Age' not in df.columns or 'Weight' not in df.columns:\n        raise KeyError(\"The input DataFrame does not contain the required columns 'Age' and 'Weight'.\")\n\n    filtered_df = df[(df['Age'] < age) & (df['Weight'] > weight)]\n\n    if filtered_df.empty:\n        return filtered_df\n\n    scaler = StandardScaler()\n    standardized_df = pd.DataFrame(scaler.fit_transform(filtered_df), columns=filtered_df.columns)\n\n    return standardized_df"}
{"task_id": "BigCodeBench/749", "solution": "from sklearn.preprocessing import MinMaxScaler\nimport numpy as np\ndef task_func(myList):\n    myList = np.array(myList).reshape(-1, 1)\n    scaler = MinMaxScaler()\n    scaler.fit(myList)\n    return scaler.transform(myList)", "raw_solution": "from sklearn.preprocessing import MinMaxScaler\nimport numpy as np\ndef task_func(myList):\n    myList = np.array(myList).reshape(-1, 1)\n    scaler = MinMaxScaler()\n    scaler.fit(myList)\n    return scaler.transform(myList)\n```"}
{"task_id": "BigCodeBench/750", "solution": "import pandas as pd\nimport statsmodels.api as sm\ndef task_func(df: pd.DataFrame, height: int, weight: int, columns: list) -> sm.regression.linear_model.RegressionResultsWrapper:\n    if df.empty or df[columns[1]].max() <= height or df[columns[2]].min() >= weight:\n        return None\n    X = df[columns[1:]]\n    y = df[columns[0]]\n    X = sm.add_constant(X)\n    model = sm.OLS(y, X).fit()\n    return model", "raw_solution": "import pandas as pd\nimport statsmodels.api as sm\n\ndef task_func(df: pd.DataFrame, height: int, weight: int, columns: list) -> sm.regression.linear_model.RegressionResultsWrapper:\n    if df.empty or df[columns[1]].max() <= height or df[columns[2]].min() >= weight:\n        return None\n    X = df[columns[1:]]\n    y = df[columns[0]]\n    X = sm.add_constant(X)\n    model = sm.OLS(y, X).fit()\n    return model\n```"}
{"task_id": "BigCodeBench/751", "solution": "import random\nfrom collections import Counter\ndef task_func(values, weights, n_samples):\n    random.seed(0)\n    samples = random.choices(values, weights, k=n_samples)\n    histogram = Counter(samples)\n    return histogram", "raw_solution": "import random\nfrom collections import Counter\n\ndef task_func(values, weights, n_samples):\n    random.seed(0)\n    samples = random.choices(values, weights, k=n_samples)\n    histogram = Counter(samples)\n    return histogram\n```"}
{"task_id": "BigCodeBench/752", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data must be a pandas DataFrame\")\n    if data.empty:\n        raise ValueError(\"Data cannot be empty\")\n    if target_column not in data.columns:\n        raise ValueError(\"Target column is not a column of data\")\n    if not all(data.dtypes == np.float64):\n        raise ValueError(\"Data must contain only numeric values\")\n    if not isinstance(random_state, int):\n        raise ValueError(\"Random state must be an integer\")\n    if not 0 <= test_size <= 1:\n        raise ValueError(\"Test size must be between 0 and 1\")\n\n    X = data.drop(columns=[target_column])\n    y = data[target_column]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    return model.score(X_test, y_test)", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data must be a pandas DataFrame\")\n    if data.empty:\n        raise ValueError(\"Data cannot be empty\")\n    if target_column not in data.columns:\n        raise ValueError(\"Target column is not a column of data\")\n    if not all(data.dtypes == np.float64):\n        raise ValueError(\"Data must contain only numeric values\")\n    if not isinstance(random_state, int):\n        raise ValueError(\"Random state must be an integer\")\n    if not 0 <= test_size <= 1:\n        raise ValueError(\"Test size must be between 0 and 1\")\n\n    X = data.drop(columns=[target_column])\n    y = data[target_column]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    return model.score(X_test, y_test)\n```"}
{"task_id": "BigCodeBench/753", "solution": "import math\nimport random\nimport statistics\nRADIUS = 5\ndef task_func(n):\n    points = []\n    for _ in range(n):\n        angle = random.uniform(0, 2 * math.pi)\n        radius = RADIUS * random.uniform(0, 1)\n        x = radius * math.cos(angle)\n        y = radius * math.sin(angle)\n        points.append((x, y))\n    distances = [math.sqrt(x**2 + y**2) for x, y in points]\n    return statistics.mean(distances)", "raw_solution": "import math\nimport random\nimport statistics\n# Constants\nRADIUS = 5\ndef task_func(n):\n    points = []\n    for _ in range(n):\n        angle = random.uniform(0, 2 * math.pi)\n        radius = RADIUS * random.uniform(0, 1)\n        x = radius * math.cos(angle)\n        y = radius * math.sin(angle)\n        points.append((x, y))\n    distances = [math.sqrt(x**2 + y**2) for x, y in points]\n    return statistics.mean(distances)\n```"}
{"task_id": "BigCodeBench/754", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(result):\n    if \"from_user\" not in result.columns:\n        return pd.Series([np.nan]*6, index=['mean', 'median', 'min', 'max', 'std', 'current_time'])\n\n    from_user_values = result[\"from_user\"].dropna().astype(float)\n    if from_user_values.empty:\n        return pd.Series([np.nan]*6, index=['mean', 'median', 'min', 'max', 'std', 'current_time'])\n\n    mean = np.mean(from_user_values)\n    median = np.median(from_user_values)\n    min_val = np.min(from_user_values)\n    max_val = np.max(from_user_values)\n    std = np.std(from_user_values)\n    current_time = datetime.now().strftime(DATE_FORMAT)\n\n    return pd.Series([mean, median, min_val, max_val, std, current_time], index=['mean', 'median', 'min', 'max', 'std', 'current_time'])", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(result):\n    if \"from_user\" not in result.columns:\n        return pd.Series([np.nan]*6, index=['mean', 'median', 'min', 'max', 'std', 'current_time'])\n\n    from_user_values = result[\"from_user\"].dropna().astype(float)\n    if from_user_values.empty:\n        return pd.Series([np.nan]*6, index=['mean', 'median', 'min', 'max', 'std', 'current_time'])\n\n    mean = np.mean(from_user_values)\n    median = np.median(from_user_values)\n    min_val = np.min(from_user_values)\n    max_val = np.max(from_user_values)\n    std = np.std(from_user_values)\n    current_time = datetime.now().strftime(DATE_FORMAT)\n\n    return pd.Series([mean, median, min_val, max_val, std, current_time], index=['mean', 'median', 'min', 'max', 'std', 'current_time'])\n```"}
{"task_id": "BigCodeBench/755", "solution": "import os\nimport glob\ndef task_func(directory_path):\n    filenames = glob.glob(os.path.join(directory_path, '*'))\n    new_filenames = []\n    for filename in filenames:\n        base_name = os.path.basename(filename)\n        new_name = '.'.join(base_name.split('.')[::-1])\n        new_filenames.append(new_name)\n    return new_filenames", "raw_solution": "import os\nimport glob\n\ndef task_func(directory_path):\n    filenames = glob.glob(os.path.join(directory_path, '*'))\n    new_filenames = []\n    for filename in filenames:\n        base_name = os.path.basename(filename)\n        new_name = '.'.join(base_name.split('.')[::-1])\n        new_filenames.append(new_name)\n    return new_filenames\n```"}
{"task_id": "BigCodeBench/756", "solution": "import shutil\nfrom pathlib import Path\nfrom typing import List\ndef task_func(source_dir: str, target_dir: str, extensions: List[str]) -> int:\n    source_dir_path = Path(source_dir)\n    target_dir_path = Path(target_dir)\n\n    if not source_dir_path.exists() or not target_dir_path.exists():\n        raise ValueError(\"Source or target directory does not exist\")\n\n    moved_files_count = 0\n    for file in source_dir_path.glob(\"*.*\"):\n        if file.suffix in extensions:\n            shutil.move(str(file), target_dir_path)\n            moved_files_count += 1\n\n    return moved_files_count", "raw_solution": "import shutil\nfrom pathlib import Path\nfrom typing import List\n\ndef task_func(source_dir: str, target_dir: str, extensions: List[str]) -> int:\n    source_dir_path = Path(source_dir)\n    target_dir_path = Path(target_dir)\n\n    if not source_dir_path.exists() or not target_dir_path.exists():\n        raise ValueError(\"Source or target directory does not exist\")\n\n    moved_files_count = 0\n    for file in source_dir_path.glob(\"*.*\"):\n        if file.suffix in extensions:\n            shutil.move(str(file), target_dir_path)\n            moved_files_count += 1\n\n    return moved_files_count\n```"}
{"task_id": "BigCodeBench/757", "solution": "import numpy as np\nimport datetime\ndef task_func(arr):\n    arr = np.char.split(arr, sep='.')\n    arr = np.array([i[::-1] for i in arr])\n    arr = np.array(['.'.join(i) for i in arr])\n    return arr", "raw_solution": "import numpy as np\nimport datetime\ndef task_func(arr):\n    arr = np.char.split(arr, sep='.')\n    arr = np.array([i[::-1] for i in arr])\n    arr = np.array(['.'.join(i) for i in arr])\n    return arr\n```"}
{"task_id": "BigCodeBench/758", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(num_samples, countries=['Russia', 'China', 'USA', 'India', 'Brazil'], \n           ages=np.arange(18, 60), genders=['Male', 'Female'], rng_seed=None):\n    if not isinstance(num_samples, int):\n        raise ValueError(\"num_samples must be an integer\")\n    rng = np.random.default_rng(rng_seed)\n    country = rng.choice(countries, num_samples)\n    age = rng.choice(ages, num_samples)\n    gender = rng.choice(genders, num_samples)\n    le = LabelEncoder()\n    gender = le.fit_transform(gender)\n    df = pd.DataFrame({'Country': country, 'Age': age, 'Gender': gender})\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(num_samples, countries=['Russia', 'China', 'USA', 'India', 'Brazil'], \n           ages=np.arange(18, 60), genders=['Male', 'Female'], rng_seed=None):\n    if not isinstance(num_samples, int):\n        raise ValueError(\"num_samples must be an integer\")\n    rng = np.random.default_rng(rng_seed)\n    country = rng.choice(countries, num_samples)\n    age = rng.choice(ages, num_samples)\n    gender = rng.choice(genders, num_samples)\n    le = LabelEncoder()\n    gender = le.fit_transform(gender)\n    df = pd.DataFrame({'Country': country, 'Age': age, 'Gender': gender})\n    return df\n```"}
{"task_id": "BigCodeBench/759", "solution": "import os\nimport shutil\nimport fnmatch\ndef task_func(source_directory, destination_directory, file_pattern):\n    moved_files = []\n    for root, dirs, files in os.walk(source_directory):\n        for file in files:\n            if fnmatch.fnmatch(file, file_pattern):\n                source_path = os.path.join(root, file)\n                destination_path = os.path.join(destination_directory, file)\n                shutil.move(source_path, destination_path)\n                moved_files.append(file)\n    return moved_files", "raw_solution": "import os\nimport shutil\nimport fnmatch\n\ndef task_func(source_directory, destination_directory, file_pattern):\n    moved_files = []\n    for root, dirs, files in os.walk(source_directory):\n        for file in files:\n            if fnmatch.fnmatch(file, file_pattern):\n                source_path = os.path.join(root, file)\n                destination_path = os.path.join(destination_directory, file)\n                shutil.move(source_path, destination_path)\n                moved_files.append(file)\n    return moved_files\n```"}
{"task_id": "BigCodeBench/760", "solution": "import pandas as pd\nimport numpy as np\nimport codecs\nimport re\nimport datetime\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    np.random.seed(rng_seed)\n    df = pd.DataFrame()\n    df['ID'] = np.arange(1, 101)\n    df['Name'] = np.random.choice(latin_names + other_names, 100)\n    df['Date of Birth'] = pd.date_range(start=str(start_year)+'-01-01', end=str(end_year)+'-12-31')\n    df['Email'] = df['Name'] + str(df['Date of Birth'].dt.year) + '@' + email_domain\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport codecs\nimport re\nimport datetime\n\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    np.random.seed(rng_seed)\n    df = pd.DataFrame()\n    df['ID'] = np.arange(1, 101)\n    df['Name'] = np.random.choice(latin_names + other_names, 100)\n    df['Date of Birth'] = pd.date_range(start=str(start_year)+'-01-01', end=str(end_year)+'-12-31')\n    df['Email'] = df['Name'] + str(df['Date of Birth'].dt.year) + '@' + email_domain\n    return df\n```"}
{"task_id": "BigCodeBench/761", "solution": "import json\nimport re\nfrom collections import Counter\nREPLACE_NONE = \"None\"\nEMAIL_REGEX = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\ndef task_func(json_str):\n    data = json.loads(json_str)\n    data = remove_none_values(data)\n    data = replace_emails(data)\n    value_counts = count_values(data)\n    return {\"data\": data, \"value_counts\": value_counts}\ndef remove_none_values(data):\n    if isinstance(data, dict):\n        return {k: remove_none_values(v) for k, v in data.items() if v is not None}\n    elif isinstance(data, list):\n        return [remove_none_values(v) for v in data if v is not None]\n    else:\n        return data\ndef count_values(data):\n    if isinstance(data, dict):\n        return Counter(count_values(v) for v in data.values())\n    elif isinstance(data, list):\n        return Counter(count_values(v) for v in data)\n    else:\n        return data\ndef replace_emails(data):\n    if isinstance(data, dict):\n        return {k: replace_emails(v) for k, v in data.items()}\n    elif isinstance(data, list):\n        return [replace_emails(v) for v in data]\n    elif isinstance(data, str) and re.match(EMAIL_REGEX, data):\n        return REPLACE_NONE\n    else:\n        return data", "raw_solution": "import json\nimport re\nfrom collections import Counter\n\n# Constants\nREPLACE_NONE = \"None\"\nEMAIL_REGEX = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n\ndef task_func(json_str):\n    data = json.loads(json_str)\n    data = remove_none_values(data)\n    data = replace_emails(data)\n    value_counts = count_values(data)\n    return {\"data\": data, \"value_counts\": value_counts}\n\ndef remove_none_values(data):\n    if isinstance(data, dict):\n        return {k: remove_none_values(v) for k, v in data.items() if v is not None}\n    elif isinstance(data, list):\n        return [remove_none_values(v) for v in data if v is not None]\n    else:\n        return data\n\ndef count_values(data):\n    if isinstance(data, dict):\n        return Counter(count_values(v) for v in data.values())\n    elif isinstance(data, list):\n        return Counter(count_values(v) for v in data)\n    else:\n        return data\n\ndef replace_emails(data):\n    if isinstance(data, dict):\n        return {k: replace_emails(v) for k, v in data.items()}\n    elif isinstance(data, list):\n        return [replace_emails(v) for v in data]\n    elif isinstance(data, str) and re.match(EMAIL_REGEX, data):\n        return REPLACE_NONE\n    else:\n        return data\n```"}
{"task_id": "BigCodeBench/762", "solution": "import codecs\nimport os\nimport zipfile\ndef task_func(directory_name=\"latin_files\",\n          content='Sopet\u00f3n',\n          file_names=['file1.txt', 'file2.txt', 'file3.txt'],\n          encoding=\"latin-1\"):\n    # Create directory\n    os.mkdir(directory_name)\n\n    # Create files\n    for file_name in file_names:\n        with open(os.path.join(directory_name, file_name), 'w', encoding=encoding) as file:\n            file.write(content)\n\n    # Zip directory\n    zip_file_name = f\"{directory_name}.zip\"\n    with zipfile.ZipFile(zip_file_name, 'w') as zipf:\n        for root, dirs, files in os.walk(directory_name):\n            for file in files:\n                zipf.write(os.path.join(root, file), arcname=file)\n\n    return zip_file_name", "raw_solution": "import codecs\nimport os\nimport zipfile\n\ndef task_func(directory_name=\"latin_files\",\n          content='Sopet\u00f3n',\n          file_names=['file1.txt', 'file2.txt', 'file3.txt'],\n          encoding=\"latin-1\"):\n    # Create directory\n    os.mkdir(directory_name)\n\n    # Create files\n    for file_name in file_names:\n        with open(os.path.join(directory_name, file_name), 'w', encoding=encoding) as file:\n            file.write(content)\n\n    # Zip directory\n    zip_file_name = f\"{directory_name}.zip\"\n    with zipfile.ZipFile(zip_file_name, 'w') as zipf:\n        for root, dirs, files in os.walk(directory_name):\n            for file in files:\n                zipf.write(os.path.join(root, file), arcname=file)\n\n    return zip_file_name"}
{"task_id": "BigCodeBench/763", "solution": "import numpy as np\nfrom collections import defaultdict\nimport json\nimport csv\ndef task_func(input_file, output_file):\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    field_dict = defaultdict(list)\n    for item in data:\n        for key, value in item.items():\n            field_dict[key].append(value)\n\n    result = {}\n    for key, values in field_dict.items():\n        mean = np.mean(values)\n        median = np.median(values)\n        result[key] = {'mean': mean, 'median': median}\n\n    with open(output_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Field', 'Mean', 'Median'])\n        for key, stats in result.items():\n            writer.writerow([key, stats['mean'], stats['median']])\n\n    return result", "raw_solution": "import numpy as np\nfrom collections import defaultdict\nimport json\nimport csv\n\ndef task_func(input_file, output_file):\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    field_dict = defaultdict(list)\n    for item in data:\n        for key, value in item.items():\n            field_dict[key].append(value)\n\n    result = {}\n    for key, values in field_dict.items():\n        mean = np.mean(values)\n        median = np.median(values)\n        result[key] = {'mean': mean, 'median': median}\n\n    with open(output_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Field', 'Mean', 'Median'])\n        for key, stats in result.items():\n            writer.writerow([key, stats['mean'], stats['median']])\n\n    return result\n```"}
{"task_id": "BigCodeBench/764", "solution": "", "raw_solution": ""}
{"task_id": "BigCodeBench/765", "solution": "import os\nfrom pathlib import Path\nimport shutil\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    copied_files = []\n    for file_path in kwargs.values():\n        if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n            shutil.copy2(file_path, target_dir)\n            copied_files.append(os.path.join(target_dir, os.path.basename(file_path)))\n    return copied_files", "raw_solution": "import os\nfrom pathlib import Path\nimport shutil\n\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    copied_files = []\n    for file_path in kwargs.values():\n        if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n            shutil.copy2(file_path, target_dir)\n            copied_files.append(os.path.join(target_dir, os.path.basename(file_path)))\n    return copied_files\n```"}
{"task_id": "BigCodeBench/766", "solution": "import re\nimport collections\ndef task_func(string, patterns=['nnn', 'aaa', 'sss', 'ddd', 'fff']):\n    if not isinstance(string, str):\n        raise TypeError(\"string must be a str\")\n    if not isinstance(patterns, list) or not all(isinstance(pattern, str) for pattern in patterns):\n        raise TypeError(\"patterns must be a list of str\")\n    pattern_counts = collections.defaultdict(int)\n    for pattern in patterns:\n        pattern_counts[pattern] = len(re.findall(pattern, string))\n    return pattern_counts", "raw_solution": "import re\nimport collections\ndef task_func(string, patterns=['nnn', 'aaa', 'sss', 'ddd', 'fff']):\n    if not isinstance(string, str):\n        raise TypeError(\"string must be a str\")\n    if not isinstance(patterns, list) or not all(isinstance(pattern, str) for pattern in patterns):\n        raise TypeError(\"patterns must be a list of str\")\n    pattern_counts = collections.defaultdict(int)\n    for pattern in patterns:\n        pattern_counts[pattern] = len(re.findall(pattern, string))\n    return pattern_counts\n```"}
{"task_id": "BigCodeBench/767", "solution": "from collections import Counter\nimport random\nimport string\nLETTERS = string.ascii_letters\ndef task_func(list_of_lists):\n    # Replace each sublist with a random letter\n    replaced_list = [random.choice(LETTERS) for _ in range(len(list_of_lists))]\n    # Count the occurrences of each letter in the replaced list\n    letter_counts = Counter(replaced_list)\n    return dict(letter_counts)", "raw_solution": "from collections import Counter\nimport random\nimport string\n# Constants\nLETTERS = string.ascii_letters\ndef task_func(list_of_lists):\n    # Replace each sublist with a random letter\n    replaced_list = [random.choice(LETTERS) for _ in range(len(list_of_lists))]\n    # Count the occurrences of each letter in the replaced list\n    letter_counts = Counter(replaced_list)\n    return dict(letter_counts)\n```"}
{"task_id": "BigCodeBench/768", "solution": "import re\nimport os\nimport glob\ndef task_func(dir_path):\n    if not os.path.exists(dir_path):\n        raise ValueError(\"Directory does not exist\")\n\n    result = {}\n    for file in glob.glob(dir_path + '/**/*.txt', recursive=True):\n        with open(file, 'r') as f:\n            content = f.read()\n            count = len(re.findall(r'\\berror\\b', content, re.IGNORECASE))\n            result[file.replace(dir_path, '')] = count\n\n    return result", "raw_solution": "import re\nimport os\nimport glob\n\ndef task_func(dir_path):\n    if not os.path.exists(dir_path):\n        raise ValueError(\"Directory does not exist\")\n\n    result = {}\n    for file in glob.glob(dir_path + '/**/*.txt', recursive=True):\n        with open(file, 'r') as f:\n            content = f.read()\n            count = len(re.findall(r'\\berror\\b', content, re.IGNORECASE))\n            result[file.replace(dir_path, '')] = count\n\n    return result\n```"}
{"task_id": "BigCodeBench/769", "solution": "from collections import Counter\nimport itertools\nimport operator\ndef task_func(list_of_menuitems):\n    flat_list = list(itertools.chain.from_iterable(list_of_menuitems))\n    counter = Counter(flat_list)\n    most_common = max(counter.items(), key=operator.itemgetter(1))[0]\n    return most_common", "raw_solution": "from collections import Counter\nimport itertools\nimport operator\ndef task_func(list_of_menuitems):\n    flat_list = list(itertools.chain.from_iterable(list_of_menuitems))\n    counter = Counter(flat_list)\n    most_common = max(counter.items(), key=operator.itemgetter(1))[0]\n    return most_common\n```"}
{"task_id": "BigCodeBench/770", "solution": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\ndef task_func(num_samples=500, noise_strength=1, random_seed=None, test_size=0.2):\n    if test_size < 0 or test_size > 1:\n        raise ValueError(\"Test set size must be between 0 and 1\")\n    if num_samples < 2:\n        raise ValueError(\"Number of samples must be at least 2\")\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    X = np.random.uniform(low=-10, high=10, size=(num_samples, 1))\n    y = 3 * X + np.random.normal(loc=0, scale=noise_strength, size=(num_samples, 1))\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    score = model.score(X_test, y_test)\n    return score, model", "raw_solution": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(num_samples=500, noise_strength=1, random_seed=None, test_size=0.2):\n    if test_size < 0 or test_size > 1:\n        raise ValueError(\"Test set size must be between 0 and 1\")\n    if num_samples < 2:\n        raise ValueError(\"Number of samples must be at least 2\")\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    X = np.random.uniform(low=-10, high=10, size=(num_samples, 1))\n    y = 3 * X + np.random.normal(loc=0, scale=noise_strength, size=(num_samples, 1))\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    score = model.score(X_test, y_test)\n    return score, model\n```"}
{"task_id": "BigCodeBench/771", "solution": "import re\nimport os\nfrom pathlib import Path\nimport csv\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n    new_files = []\n    for file in os.listdir(directory):\n        if re.match(pattern, file):\n            filename = re.match(pattern, file).group(1)\n            new_file = filename + \"-new.csv\"\n            new_files.append(new_file)\n            with open(os.path.join(directory, file), 'r') as f_in, open(os.path.join(directory, new_file), 'w', newline='') as f_out:\n                reader = csv.reader(f_in)\n                writer = csv.writer(f_out)\n                for row in reader:\n                    writer.writerow(row)\n    return new_files", "raw_solution": "import re\nimport os\nfrom pathlib import Path\nimport csv\n\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n    new_files = []\n    for file in os.listdir(directory):\n        if re.match(pattern, file):\n            filename = re.match(pattern, file).group(1)\n            new_file = filename + \"-new.csv\"\n            new_files.append(new_file)\n            with open(os.path.join(directory, file), 'r') as f_in, open(os.path.join(directory, new_file), 'w', newline='') as f_out:\n                reader = csv.reader(f_in)\n                writer = csv.writer(f_out)\n                for row in reader:\n                    writer.writerow(row)\n    return new_files\n```"}
{"task_id": "BigCodeBench/772", "solution": "import numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\ndef task_func(num_samples=1000, k=5, d=2, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    # Generate a dataset consisting of random numbers sampled from a gaussian normal distribution\n    X = np.random.normal(size=(num_samples, 1))\n    # Apply a linear transformation to the dataset\n    X_transformed = k * X + d\n    # Standardize the dataset using StandardScaler\n    scaler = StandardScaler()\n    X_standardized = scaler.fit_transform(X_transformed)\n    # Calculate the average square error between the original dataset and the standardized dataset\n    mse = mean_squared_error(X_transformed, X_standardized)\n    return mse", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\n\ndef task_func(num_samples=1000, k=5, d=2, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    # Generate a dataset consisting of random numbers sampled from a gaussian normal distribution\n    X = np.random.normal(size=(num_samples, 1))\n    # Apply a linear transformation to the dataset\n    X_transformed = k * X + d\n    # Standardize the dataset using StandardScaler\n    scaler = StandardScaler()\n    X_standardized = scaler.fit_transform(X_transformed)\n    # Calculate the average square error between the original dataset and the standardized dataset\n    mse = mean_squared_error(X_transformed, X_standardized)\n    return mse\n```"}
{"task_id": "BigCodeBench/773", "solution": "import os\nimport re\nimport shutil\nSOURCE_DIR = '/source/dir'\nTARGET_DIR = '/target/dir'\nFILE_PATTERN = re.compile(r'^(.*?)-\\d+\\.json$')\ndef task_func():\n    for filename in os.listdir(SOURCE_DIR):\n        match = FILE_PATTERN.match(filename)\n        if match:\n            prefix = match.group(1)\n            new_filename = f\"{prefix}.json\"\n            shutil.move(os.path.join(SOURCE_DIR, filename), os.path.join(TARGET_DIR, new_filename))", "raw_solution": "import os\nimport re\nimport shutil\n\n# Constants\nSOURCE_DIR = '/source/dir'\nTARGET_DIR = '/target/dir'\nFILE_PATTERN = re.compile(r'^(.*?)-\\d+\\.json$')\n\ndef task_func():\n    for filename in os.listdir(SOURCE_DIR):\n        match = FILE_PATTERN.match(filename)\n        if match:\n            prefix = match.group(1)\n            new_filename = f\"{prefix}.json\"\n            shutil.move(os.path.join(SOURCE_DIR, filename), os.path.join(TARGET_DIR, new_filename))\n```"}
{"task_id": "BigCodeBench/774", "solution": "import numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\ndef task_func(num_samples=100, n_estimators=100, random_seed=None, cv=5):\n    if num_samples / cv < 2:\n        raise ValueError(\"ValueError: If num_samples / cv < 2\")\n    np.random.seed(random_seed)\n    X = np.random.normal(size=(num_samples, 5))\n    y = np.sum(X, axis=1) + np.random.normal(size=num_samples)\n    model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_seed)\n    scores = cross_val_score(model, X, y, cv=cv)\n    return np.mean(scores), model", "raw_solution": "import numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef task_func(num_samples=100, n_estimators=100, random_seed=None, cv=5):\n    if num_samples / cv < 2:\n        raise ValueError(\"ValueError: If num_samples / cv < 2\")\n    np.random.seed(random_seed)\n    X = np.random.normal(size=(num_samples, 5))\n    y = np.sum(X, axis=1) + np.random.normal(size=num_samples)\n    model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_seed)\n    scores = cross_val_score(model, X, y, cv=cv)\n    return np.mean(scores), model\n```"}
{"task_id": "BigCodeBench/775", "solution": "from string import ascii_lowercase\nimport re\nfrom collections import Counter\nLETTERS_PATTERN = re.compile(r'^(.*?)-[a-z]$')\ndef task_func(string):\n    match = LETTERS_PATTERN.match(string)\n    if match:\n        prefix = match.group(1)\n        return dict(Counter(prefix))\n    else:\n        return {}", "raw_solution": "from string import ascii_lowercase\nimport re\nfrom collections import Counter\n# Constants\nLETTERS_PATTERN = re.compile(r'^(.*?)-[a-z]$')\nLETTERS = ascii_lowercase\ndef task_func(string):\n    match = LETTERS_PATTERN.match(string)\n    if match:\n        prefix = match.group(1)\n        return dict(Counter(prefix))\n    else:\n        return {}\n```"}
{"task_id": "BigCodeBench/776", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(file_path, output_path=None, sort_key='title', linear_regression=False, x_column=None, y_column=None):\n    try:\n        df = pd.read_csv(file_path)\n    except Exception as e:\n        raise Exception(f\"Error reading file: {e}\")\n\n    try:\n        df = df.sort_values(by=sort_key)\n    except Exception as e:\n        raise Exception(f\"Error sorting data: {e}\")\n\n    if output_path is not None:\n        try:\n            df.to_csv(output_path, index=False)\n        except Exception as e:\n            raise Exception(f\"Error writing to file: {e}\")\n\n    if linear_regression:\n        if x_column is None or y_column is None:\n            raise ValueError(\"x_column and y_column must be specified for linear regression\")\n        if x_column not in df.columns or y_column not in df.columns:\n            raise ValueError(\"Specified columns for linear regression do not exist in the dataframe\")\n        try:\n            model = LinearRegression()\n            model.fit(df[[x_column]], df[y_column])\n            return model\n        except Exception as e:\n            raise Exception(f\"Error fitting model: {e}\")\n\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(file_path, output_path=None, sort_key='title', linear_regression=False, x_column=None, y_column=None):\n    try:\n        df = pd.read_csv(file_path)\n    except Exception as e:\n        raise Exception(f\"Error reading file: {e}\")\n\n    try:\n        df = df.sort_values(by=sort_key)\n    except Exception as e:\n        raise Exception(f\"Error sorting data: {e}\")\n\n    if output_path is not None:\n        try:\n            df.to_csv(output_path, index=False)\n        except Exception as e:\n            raise Exception(f\"Error writing to file: {e}\")\n\n    if linear_regression:\n        if x_column is None or y_column is None:\n            raise ValueError(\"x_column and y_column must be specified for linear regression\")\n        if x_column not in df.columns or y_column not in df.columns:\n            raise ValueError(\"Specified columns for linear regression do not exist in the dataframe\")\n        try:\n            model = LinearRegression()\n            model.fit(df[[x_column]], df[y_column])\n            return model\n        except Exception as e:\n            raise Exception(f\"Error fitting model: {e}\")\n\n    return df\n```"}
{"task_id": "BigCodeBench/777", "solution": "import re\nimport os\nimport zipfile\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    extracted_dirs = []\n    for filename in os.listdir(directory):\n        match = re.match(pattern, filename)\n        if match:\n            prefix = match.group(1)\n            if not os.path.exists(os.path.join(directory, prefix)):\n                os.makedirs(os.path.join(directory, prefix))\n            with zipfile.ZipFile(os.path.join(directory, filename), 'r') as zip_ref:\n                zip_ref.extractall(os.path.join(directory, prefix))\n            extracted_dirs.append(os.path.join(directory, prefix))\n    return extracted_dirs", "raw_solution": "import re\nimport os\nimport zipfile\n\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    extracted_dirs = []\n    for filename in os.listdir(directory):\n        match = re.match(pattern, filename)\n        if match:\n            prefix = match.group(1)\n            if not os.path.exists(os.path.join(directory, prefix)):\n                os.makedirs(os.path.join(directory, prefix))\n            with zipfile.ZipFile(os.path.join(directory, filename), 'r') as zip_ref:\n                zip_ref.extractall(os.path.join(directory, prefix))\n            extracted_dirs.append(os.path.join(directory, prefix))\n    return extracted_dirs\n```"}
{"task_id": "BigCodeBench/778", "solution": "from collections import defaultdict\nfrom operator import itemgetter\nfrom itertools import groupby\ndef task_func(news_articles):\n    if not all(isinstance(article, dict) and set(article.keys()) == {'title', 'title_url', 'id', 'category'} for article in news_articles):\n        raise ValueError(\"Invalid news article format\")\n    sorted_articles = sorted(news_articles, key=itemgetter('category', 'title'))\n    grouped_articles = defaultdict(list)\n    for category, articles in groupby(sorted_articles, key=itemgetter('category')):\n        grouped_articles[category].extend(articles)\n    return grouped_articles", "raw_solution": "from collections import defaultdict\nfrom operator import itemgetter\nfrom itertools import groupby\n\ndef task_func(news_articles):\n    if not all(isinstance(article, dict) and set(article.keys()) == {'title', 'title_url', 'id', 'category'} for article in news_articles):\n        raise ValueError(\"Invalid news article format\")\n    sorted_articles = sorted(news_articles, key=itemgetter('category', 'title'))\n    grouped_articles = defaultdict(list)\n    for category, articles in groupby(sorted_articles, key=itemgetter('category')):\n        grouped_articles[category].extend(articles)\n    return grouped_articles\n```"}
{"task_id": "BigCodeBench/779", "solution": "import os\nimport shutil\ndef get_unique_backup_dir():\n    return \"/fake/backup/path\"\ndef task_func(directory):\n    backup_dir = get_unique_backup_dir()\n    errors = []\n\n    try:\n        # Create backup directory if it doesn't exist\n        if not os.path.exists(backup_dir):\n            os.makedirs(backup_dir)\n\n        # Copy directory to backup directory\n        shutil.copytree(directory, os.path.join(backup_dir, os.path.basename(directory)))\n\n        # Clean the directory\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            try:\n                if os.path.isfile(file_path) or os.path.islink(file_path):\n                    os.unlink(file_path)\n                elif os.path.isdir(file_path):\n                    shutil.rmtree(file_path)\n            except Exception as e:\n                errors.append(str(e))\n\n    except Exception as e:\n        errors.append(str(e))\n\n    return backup_dir, errors", "raw_solution": "import os\nimport shutil\n\n# Constants\nBACKUP_DIR = '/tmp/backup'\n\ndef get_unique_backup_dir():\n    return \"/fake/backup/path\"\n\ndef task_func(directory):\n    backup_dir = get_unique_backup_dir()\n    errors = []\n\n    try:\n        # Create backup directory if it doesn't exist\n        if not os.path.exists(backup_dir):\n            os.makedirs(backup_dir)\n\n        # Copy directory to backup directory\n        shutil.copytree(directory, os.path.join(backup_dir, os.path.basename(directory)))\n\n        # Clean the directory\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            try:\n                if os.path.isfile(file_path) or os.path.islink(file_path):\n                    os.unlink(file_path)\n                elif os.path.isdir(file_path):\n                    shutil.rmtree(file_path)\n            except Exception as e:\n                errors.append(str(e))\n\n    except Exception as e:\n        errors.append(str(e))\n\n    return backup_dir, errors\n```"}
{"task_id": "BigCodeBench/780", "solution": "import pandas as pd\nimport pytz\ndef task_func(articles, timezone):\n    if not isinstance(articles, list):\n        raise TypeError(\"articles must be a list of dictionaries\")\n    if not articles:\n        raise ValueError(\"articles list cannot be empty\")\n    for article in articles:\n        if not isinstance(article, dict):\n            raise TypeError(\"articles must be a list of dictionaries\")\n        if not set(article.keys()).issubset(set([\"category\", \"published_time\"])):\n            raise ValueError(\"dictionary keys do not match the requirements\")\n    df = pd.DataFrame(articles)\n    df['published_time'] = pd.to_datetime(df['published_time'])\n    df['published_time'] = df['published_time'].dt.tz_localize(pytz.utc).dt.tz_convert(timezone)\n    df['hour'] = df['published_time'].dt.hour\n    result = df.groupby('category').agg({'hour': ['count', 'mean', 'min', 'max']})\n    result.columns = ['_'.join(col).strip() for col in result.columns.values]\n    result.reset_index(inplace=True)\n    return result", "raw_solution": "import pandas as pd\nimport pytz\n\ndef task_func(articles, timezone):\n    if not isinstance(articles, list):\n        raise TypeError(\"articles must be a list of dictionaries\")\n    if not articles:\n        raise ValueError(\"articles list cannot be empty\")\n    for article in articles:\n        if not isinstance(article, dict):\n            raise TypeError(\"articles must be a list of dictionaries\")\n        if not set(article.keys()).issubset(set([\"category\", \"published_time\"])):\n            raise ValueError(\"dictionary keys do not match the requirements\")\n    df = pd.DataFrame(articles)\n    df['published_time'] = pd.to_datetime(df['published_time'])\n    df['published_time'] = df['published_time'].dt.tz_localize(pytz.utc).dt.tz_convert(timezone)\n    df['hour'] = df['published_time'].dt.hour\n    result = df.groupby('category').agg({'hour': ['count', 'mean', 'min', 'max']})\n    result.columns = ['_'.join(col).strip() for col in result.columns.values]\n    result.reset_index(inplace=True)\n    return result\n```"}
{"task_id": "BigCodeBench/781", "solution": "import os\nfrom datetime import datetime\ndef task_func(filepath: str) -> dict:\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(f\"File {filepath} does not exist.\")\n    file_size = os.path.getsize(filepath)\n    file_mod_time = os.path.getmtime(filepath)\n    file_mod_date = datetime.fromtimestamp(file_mod_time).strftime('%Y-%m-%d %H:%M:%S')\n    return {\"size\": file_size, \"last_modification\": file_mod_date}", "raw_solution": "import os\nfrom datetime import datetime\n\ndef task_func(filepath: str) -> dict:\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(f\"File {filepath} does not exist.\")\n    file_size = os.path.getsize(filepath)\n    file_mod_time = os.path.getmtime(filepath)\n    file_mod_date = datetime.fromtimestamp(file_mod_time).strftime('%Y-%m-%d %H:%M:%S')\n    return {\"size\": file_size, \"last_modification\": file_mod_date}\n```"}
{"task_id": "BigCodeBench/782", "solution": "import random\nimport pandas as pd\nimport numpy as np\ndef task_func(n,\n          domain=\"samplewebsite.com\",\n          categories=['Sports', 'Technology', 'Health', 'Science', 'Business'],\n          random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    data = []\n    for i in range(n):\n        title = f\"Article {i}\"\n        title_url = f\"{domain}/{title}\"\n        id = i\n        category = random.choice(categories)\n        views = np.random.poisson(1000)\n        data.append([title, title_url, id, category, views])\n\n    df = pd.DataFrame(data, columns=['title', 'title_url', 'id', 'category', 'views'])\n    return df", "raw_solution": "import random\nimport pandas as pd\nimport numpy as np\n\ndef task_func(n,\n          domain=\"samplewebsite.com\",\n          categories=['Sports', 'Technology', 'Health', 'Science', 'Business'],\n          random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    data = []\n    for i in range(n):\n        title = f\"Article {i}\"\n        title_url = f\"{domain}/{title}\"\n        id = i\n        category = random.choice(categories)\n        views = np.random.poisson(1000)\n        data.append([title, title_url, id, category, views])\n\n    df = pd.DataFrame(data, columns=['title', 'title_url', 'id', 'category', 'views'])\n    return df\n```"}
{"task_id": "BigCodeBench/783", "solution": "import os\nimport shutil\ndef task_func(src_dir, dest_dir, extension):\n    files_moved = 0\n    for filename in os.listdir(src_dir):\n        if filename.endswith(extension):\n            shutil.move(os.path.join(src_dir, filename), dest_dir)\n            files_moved += 1\n    return files_moved", "raw_solution": "import os\nimport shutil\n\ndef task_func(src_dir, dest_dir, extension):\n    files_moved = 0\n    for filename in os.listdir(src_dir):\n        if filename.endswith(extension):\n            shutil.move(os.path.join(src_dir, filename), dest_dir)\n            files_moved += 1\n    return files_moved\n```"}
{"task_id": "BigCodeBench/784", "solution": "import pandas as pd\nimport random\nimport csv\ndef task_func(n, \n           categories=['Sports', 'Technology', 'Business', 'Politics', 'Entertainment'],\n           news_sites=['New York Times', 'USA Today', 'Apple News', 'CNN', 'BBC'],\n           likert_scale=['Strongly Disagree', 'Disagree', 'Neither Agree nor Disagree', 'Agree', 'Strongly Agree'],\n           file_path='news_survey_data.csv',\n           random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    data = []\n    for i in range(n):\n        site = random.choice(news_sites)\n        category = random.choice(categories)\n        response = random.choice(likert_scale)\n        value = likert_scale.index(response) + 1\n        data.append([site, category, response, value])\n\n    df = pd.DataFrame(data, columns=['Site', 'Category', 'Response', 'Value'])\n    df.to_csv(file_path, index=False)\n\n    return df", "raw_solution": "import pandas as pd\nimport random\nimport csv\n\ndef task_func(n, \n           categories=['Sports', 'Technology', 'Business', 'Politics', 'Entertainment'],\n           news_sites=['New York Times', 'USA Today', 'Apple News', 'CNN', 'BBC'],\n           likert_scale=['Strongly Disagree', 'Disagree', 'Neither Agree nor Disagree', 'Agree', 'Strongly Agree'],\n           file_path='news_survey_data.csv',\n           random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    data = []\n    for i in range(n):\n        site = random.choice(news_sites)\n        category = random.choice(categories)\n        response = random.choice(likert_scale)\n        value = likert_scale.index(response) + 1\n        data.append([site, category, response, value])\n\n    df = pd.DataFrame(data, columns=['Site', 'Category', 'Response', 'Value'])\n    df.to_csv(file_path, index=False)\n\n    return df\n```"}
{"task_id": "BigCodeBench/785", "solution": "import subprocess\nimport os\nimport glob\nARCHIVE_DIR = '/tmp/archive'\ndef task_func(pattern):\n    # Create archive directory if it doesn't exist\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n\n    # Archive files\n    archive_file = os.path.join(ARCHIVE_DIR, f'archive_{pattern}.tar.gz')\n    subprocess.run(['tar', '-czvf', archive_file, pattern])\n\n    # Delete original files\n    files = glob.glob(pattern)\n    for file in files:\n        os.remove(file)\n\n    return archive_file", "raw_solution": "import subprocess\nimport os\nimport glob\n# Constants\nARCHIVE_DIR = '/tmp/archive'\ndef task_func(pattern):\n    # Create archive directory if it doesn't exist\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n\n    # Archive files\n    archive_file = os.path.join(ARCHIVE_DIR, f'archive_{pattern}.tar.gz')\n    subprocess.run(['tar', '-czvf', archive_file, pattern])\n\n    # Delete original files\n    files = glob.glob(pattern)\n    for file in files:\n        os.remove(file)\n\n    return archive_file\n```"}
{"task_id": "BigCodeBench/786", "solution": "import pandas as pd\nimport csv\nimport random\ndef task_func(\n    n, \n    countries=['USA', 'UK', 'China', 'India', 'Germany'], \n    products=['Product A', 'Product B', 'Product C', 'Product D', 'Product E'], \n    output_path=None,\n    random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    data = []\n    for i in range(n):\n        country = random.choice(countries)\n        product = random.choice(products)\n        sales = random.randint(1, 100)\n        data.append([country, product, sales])\n    df = pd.DataFrame(data, columns=['Country', 'Product', 'Sales'])\n    if output_path is not None:\n        df.to_csv(output_path, index=False)\n    return df", "raw_solution": "import pandas as pd\nimport csv\nimport random\n\ndef task_func(\n    n, \n    countries=['USA', 'UK', 'China', 'India', 'Germany'], \n    products=['Product A', 'Product B', 'Product C', 'Product D', 'Product E'], \n    output_path=None,\n    random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    data = []\n    for i in range(n):\n        country = random.choice(countries)\n        product = random.choice(products)\n        sales = random.randint(1, 100)\n        data.append([country, product, sales])\n    df = pd.DataFrame(data, columns=['Country', 'Product', 'Sales'])\n    if output_path is not None:\n        df.to_csv(output_path, index=False)\n    return df\n```"}
{"task_id": "BigCodeBench/787", "solution": "import numpy as np\nfrom itertools import combinations\ndef task_func(array1, array2):\n    if len(array1) != len(array2):\n        raise ValueError(\"Input arrays must have the same length\")\n    if not array1 or not array2:\n        return 0\n    max_distance = 0\n    for i, j in combinations(array1, 2):\n        point1 = np.array([i, j])\n        for x, y in combinations(array2, 2):\n            point2 = np.array([x, y])\n            distance = np.linalg.norm(point1 - point2)\n            if distance > max_distance:\n                max_distance = distance\n    return max_distance", "raw_solution": "import numpy as np\nfrom itertools import combinations\n\ndef task_func(array1, array2):\n    if len(array1) != len(array2):\n        raise ValueError(\"Input arrays must have the same length\")\n    if not array1 or not array2:\n        return 0\n    max_distance = 0\n    for i, j in combinations(array1, 2):\n        point1 = np.array([i, j])\n        for x, y in combinations(array2, 2):\n            point2 = np.array([x, y])\n            distance = np.linalg.norm(point1 - point2)\n            if distance > max_distance:\n                max_distance = distance\n    return max_distance\n```"}
{"task_id": "BigCodeBench/788", "solution": "import heapq\nfrom scipy import stats\ndef task_func(df, col1, col2, N=10):\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"Specified columns are not in the provided DataFrame.\")\n    if N <= 1:\n        raise ValueError(\"N should be greater than 1.\")\n\n    diffs = df[col1] - df[col2]\n    diffs = diffs.abs().nlargest(N)\n\n    t_stat, p_val = stats.ttest_1samp(diffs, 0)\n\n    return p_val", "raw_solution": "import heapq\nfrom scipy import stats\n\ndef task_func(df, col1, col2, N=10):\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"Specified columns are not in the provided DataFrame.\")\n    if N <= 1:\n        raise ValueError(\"N should be greater than 1.\")\n\n    diffs = df[col1] - df[col2]\n    diffs = diffs.abs().nlargest(N)\n\n    t_stat, p_val = stats.ttest_1samp(diffs, 0)\n\n    return p_val"}
{"task_id": "BigCodeBench/789", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nARRAY_LENGTH = 10\ndef task_func():\n    # Generate a random array\n    array = np.random.rand(ARRAY_LENGTH)\n\n    # Apply min-max normalization\n    scaler = MinMaxScaler()\n    scaled_array = scaler.fit_transform(array.reshape(-1, 1))\n\n    return scaled_array", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Constants\nARRAY_LENGTH = 10\n\ndef task_func():\n    # Generate a random array\n    array = np.random.rand(ARRAY_LENGTH)\n\n    # Apply min-max normalization\n    scaler = MinMaxScaler()\n    scaled_array = scaler.fit_transform(array.reshape(-1, 1))\n\n    return scaled_array\n```"}
{"task_id": "BigCodeBench/790", "solution": "import heapq\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, col1, col2, N=10):\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"Specified columns are not in the provided DataFrame.\")\n\n    scaler = StandardScaler()\n    df[[col1, col2]] = scaler.fit_transform(df[[col1, col2]])\n\n    diffs = [abs(df.loc[i, col1] - df.loc[i, col2]) for i in range(len(df))]\n    indices = heapq.nlargest(N, range(len(diffs)), diffs.__getitem__)\n\n    return indices", "raw_solution": "import heapq\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, col1, col2, N=10):\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"Specified columns are not in the provided DataFrame.\")\n\n    scaler = StandardScaler()\n    df[[col1, col2]] = scaler.fit_transform(df[[col1, col2]])\n\n    diffs = [abs(df.loc[i, col1] - df.loc[i, col2]) for i in range(len(df))]\n    indices = heapq.nlargest(N, range(len(diffs)), diffs.__getitem__)\n\n    return indices\n```"}
{"task_id": "BigCodeBench/791", "solution": "from collections import Counter\nimport random\nfrom itertools import cycle\ndef task_func(l):\n    # Shuffle the list\n    random.shuffle(l)\n    # Create a cycled iterator from the list\n    cycled_l = cycle(l)\n    # Create a list with the first 30 elements from the cycled iterator\n    first_30_elements = [next(cycled_l) for _ in range(30)]\n    # Move the first 3 elements to the end of the list\n    first_30_elements = first_30_elements[3:] + first_30_elements[:3]\n    # Create a frequency counter from the list\n    counter = Counter(first_30_elements)\n    return counter", "raw_solution": "from collections import Counter\nimport random\nfrom itertools import cycle\n# Constants\nELEMENTS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\ndef task_func(l):\n    # Shuffle the list\n    random.shuffle(l)\n    # Create a cycled iterator from the list\n    cycled_l = cycle(l)\n    # Create a list with the first 30 elements from the cycled iterator\n    first_30_elements = [next(cycled_l) for _ in range(30)]\n    # Move the first 3 elements to the end of the list\n    first_30_elements = first_30_elements[3:] + first_30_elements[:3]\n    # Create a frequency counter from the list\n    counter = Counter(first_30_elements)\n    return counter\n```"}
{"task_id": "BigCodeBench/792", "solution": "import heapq\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, feature, target, n=10):\n    if feature not in df.columns or target not in df.columns:\n        raise ValueError(\"Specified columns are not in the provided DataFrame.\")\n\n    X = df[[feature]]\n    y = df[target]\n\n    model = LinearRegression()\n    model.fit(X, y)\n\n    residuals = [abs(y[i] - model.predict([X.iloc[i]])) for i in range(len(df))]\n    indices = heapq.nlargest(n, range(len(residuals)), residuals.__getitem__)\n\n    return indices, model", "raw_solution": "import heapq\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, feature, target, n=10):\n    if feature not in df.columns or target not in df.columns:\n        raise ValueError(\"Specified columns are not in the provided DataFrame.\")\n\n    X = df[[feature]]\n    y = df[target]\n\n    model = LinearRegression()\n    model.fit(X, y)\n\n    residuals = [abs(y[i] - model.predict([X.iloc[i]])) for i in range(len(df))]\n    indices = heapq.nlargest(n, range(len(residuals)), residuals.__getitem__)\n\n    return indices, model\n```"}
{"task_id": "BigCodeBench/793", "solution": "import numpy as np\nimport random\nELEMENTS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\ndef task_func(l=None):\n    if l is None:\n        l = random.choices(ELEMENTS, k=10)\n    arr = np.array(l)\n    arr = np.roll(arr, -3)\n    return arr", "raw_solution": "import numpy as np\nimport random\n# Constants\nELEMENTS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\ndef task_func(l=None):\n    if l is None:\n        l = random.choices(ELEMENTS, k=10)\n    arr = np.array(l)\n    arr = np.roll(arr, -3)\n    return arr\n```"}
{"task_id": "BigCodeBench/794", "solution": "import string\nimport random\ndef task_func(length, random_seed=None):\n    BRACKETS = \"(){}[]\"\n    if random_seed is not None:\n        random.seed(random_seed)\n    result = []\n    for _ in range(length):\n        if random.random() < 0.5:\n            result.append(random.choice(string.ascii_lowercase))\n        else:\n            result.append(random.choice(BRACKETS))\n    return \"\".join(result)", "raw_solution": "import string\nimport random\n\ndef task_func(length, random_seed=None):\n    BRACKETS = \"(){}[]\"\n    if random_seed is not None:\n        random.seed(random_seed)\n    result = []\n    for _ in range(length):\n        if random.random() < 0.5:\n            result.append(random.choice(string.ascii_lowercase))\n        else:\n            result.append(random.choice(BRACKETS))\n    return \"\".join(result)\n```"}
{"task_id": "BigCodeBench/795", "solution": "from collections import deque\nimport math\ndef task_func(l):\n    dq = deque(l)\n    dq.rotate(3)\n    sum_elements = sum(i for i in dq if isinstance(i, (int, float)))\n    if sum_elements:\n        print(f\"The square root of the sum of numeric elements: {math.sqrt(sum_elements)}\")\n    return dq", "raw_solution": "from collections import deque\nimport math\n\ndef task_func(l):\n    dq = deque(l)\n    dq.rotate(3)\n    sum_elements = sum(i for i in dq if isinstance(i, (int, float)))\n    if sum_elements:\n        print(f\"The square root of the sum of numeric elements: {math.sqrt(sum_elements)}\")\n    return dq\n```"}
{"task_id": "BigCodeBench/796", "solution": "import os\nimport re\ndef task_func(directory):\n    BRACKET_PATTERN = '[(){}\\\\[\\\\]]'\n    bracket_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(BRACKET_PATTERN, file):\n                bracket_files.append(os.path.join(root, file))\n    return bracket_files", "raw_solution": "import os\nimport re\n\ndef task_func(directory):\n    BRACKET_PATTERN = '[(){}\\\\[\\\\]]'\n    bracket_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(BRACKET_PATTERN, file):\n                bracket_files.append(os.path.join(root, file))\n    return bracket_files\n```"}
{"task_id": "BigCodeBench/797", "solution": "import re\nimport pandas as pd\ndef task_func(df: pd.DataFrame) -> int:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"Input should be a DataFrame\")\n    if 'Test' not in df.columns:\n        raise ValueError(\"DataFrame should have a column named 'Test'\")\n    df['Test'] = df['Test'].astype(str)\n    pattern = r'[(){}[\\]]'\n    df['Brackets'] = df['Test'].str.count(pattern)\n    return df['Brackets'].sum()", "raw_solution": "import re\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> int:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"Input should be a DataFrame\")\n    if 'Test' not in df.columns:\n        raise ValueError(\"DataFrame should have a column named 'Test'\")\n    df['Test'] = df['Test'].astype(str)\n    pattern = r'[(){}[\\]]'\n    df['Brackets'] = df['Test'].str.count(pattern)\n    return df['Brackets'].sum()\n```"}
{"task_id": "BigCodeBench/798", "solution": "import os\nimport shutil\nBACKUP_DIR = '/tmp/backup'\ndef task_func(directory):\n    backup_path = os.path.join(BACKUP_DIR, directory)\n    if not os.path.exists(backup_path):\n        return f\"Backup directory {BACKUP_DIR} does not exist. Cannot rollback update.\"\n    if os.path.exists(directory):\n        shutil.rmtree(directory)\n    shutil.copytree(backup_path, directory)\n    return directory", "raw_solution": "import os\nimport shutil\n\n# Constants\nBACKUP_DIR = '/tmp/backup'\n\ndef task_func(directory):\n    backup_path = os.path.join(BACKUP_DIR, directory)\n    if not os.path.exists(backup_path):\n        return f\"Backup directory {BACKUP_DIR} does not exist. Cannot rollback update.\"\n    if os.path.exists(directory):\n        shutil.rmtree(directory)\n    shutil.copytree(backup_path, directory)\n    return directory\n```"}
{"task_id": "BigCodeBench/799", "solution": "import pandas as pd\nfrom random import seed, choices\ndef task_func(L, num_dataframes=5, random_seed=None):\n    if random_seed is not None:\n        seed(random_seed)\n    if not L:\n        return pd.DataFrame(), []\n    column_names = [chr(97 + i) for i in range(3)]\n    df_list = []\n    for _ in range(num_dataframes):\n        df = pd.DataFrame(columns=column_names)\n        for i in range(3):\n            df = df.append(pd.Series(choices(L, k=3), index=column_names), ignore_index=True)\n        df_list.append(df)\n    common_rows = df_list[0]\n    for df in df_list[1:]:\n        common_rows = pd.merge(common_rows, df, how='inner')\n    return common_rows, df_list", "raw_solution": "import pandas as pd\nfrom random import seed, choices\n\ndef task_func(L, num_dataframes=5, random_seed=None):\n    if random_seed is not None:\n        seed(random_seed)\n    if not L:\n        return pd.DataFrame(), []\n    column_names = [chr(97 + i) for i in range(3)]\n    df_list = []\n    for _ in range(num_dataframes):\n        df = pd.DataFrame(columns=column_names)\n        for i in range(3):\n            df = df.append(pd.Series(choices(L, k=3), index=column_names), ignore_index=True)\n        df_list.append(df)\n    common_rows = df_list[0]\n    for df in df_list[1:]:\n        common_rows = pd.merge(common_rows, df, how='inner')\n    return common_rows, df_list"}
{"task_id": "BigCodeBench/800", "solution": "import csv\nimport os\nfrom collections import Counter\nCSV_FILE_PATH = 'match_data.csv'\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    if not os.path.exists(csv_file_path):\n        return Counter({'goals': 0, 'penalties': 0})\n\n    with open(csv_file_path, 'r') as file:\n        reader = csv.reader(file)\n        next(reader)  # Skip the header\n        total_goals = 0\n        total_penalties = 0\n        for row in reader:\n            total_goals += int(row[1])\n            total_penalties += int(row[2])\n\n    total_goals += goals\n    total_penalties += penalties\n\n    return Counter({'goals': total_goals, 'penalties': total_penalties})", "raw_solution": "import csv\nimport os\nfrom collections import Counter\n\n# Constants\nCSV_FILE_PATH = 'match_data.csv'\n\ndef create_test_csv(filename, content):\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerows(content)\n\n# Example usage in a test setup:\ndef setup_csv():\n    content = [\n        ['team', 'goals', 'penalties'],\n        ['Team A', '2', '1'],\n        ['Team B', '1', '2'],\n        ['Team C', '3', '0']\n    ]\n    create_test_csv('test_data/test_case_2.csv', content)\n\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    if not os.path.exists(csv_file_path):\n        return Counter({'goals': 0, 'penalties': 0})\n\n    with open(csv_file_path, 'r') as file:\n        reader = csv.reader(file)\n        next(reader)  # Skip the header\n        total_goals = 0\n        total_penalties = 0\n        for row in reader:\n            total_goals += int(row[1])\n            total_penalties += int(row[2])\n\n    total_goals += goals\n    total_penalties += penalties\n\n    return Counter({'goals': total_goals, 'penalties': total_penalties})\n```"}
{"task_id": "BigCodeBench/801", "solution": "import collections\nimport numpy as np\ndef task_func(file_name):\n    import csv\n    with open(file_name, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n    if not data:\n        return {}\n    data = np.array(data)\n    column_names = data[0]\n    data = data[1:]\n    result = {}\n    for i, column_name in enumerate(column_names):\n        column_data = data[:, i]\n        counter = collections.Counter(column_data)\n        most_common_value = counter.most_common(1)[0][0]\n        result[column_name] = most_common_value\n    return result", "raw_solution": "import collections\nimport numpy as np\ndef task_func(file_name):\n    import csv\n    with open(file_name, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n    if not data:\n        return {}\n    data = np.array(data)\n    column_names = data[0]\n    data = data[1:]\n    result = {}\n    for i, column_name in enumerate(column_names):\n        column_data = data[:, i]\n        counter = collections.Counter(column_data)\n        most_common_value = counter.most_common(1)[0][0]\n        result[column_name] = most_common_value\n    return result\n```"}
{"task_id": "BigCodeBench/802", "solution": "import numpy as np\nimport itertools\ndef task_func(dimension, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.randint(1, 101, dimension)\n    flat_list = list(itertools.chain.from_iterable(matrix))\n    return matrix, flat_list", "raw_solution": "import numpy as np\nimport itertools\ndef task_func(dimension, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.randint(1, 101, dimension)\n    flat_list = list(itertools.chain.from_iterable(matrix))\n    return matrix, flat_list\n```"}
{"task_id": "BigCodeBench/803", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(file_name: str) -> pd.DataFrame:\n    df = pd.read_csv(file_name)\n    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n    if not numeric_cols.any():\n        raise ValueError(\"Input does not have numeric columns\")\n    scaler = MinMaxScaler()\n    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(file_name: str) -> pd.DataFrame:\n    df = pd.read_csv(file_name)\n    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n    if not numeric_cols.any():\n        raise ValueError(\"Input does not have numeric columns\")\n    scaler = MinMaxScaler()\n    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n    return df\n```"}
{"task_id": "BigCodeBench/804", "solution": "import os\nfrom datetime import datetime\nLOG_DIR = './logs'\ndef task_func(metrics, filename, log_dir=LOG_DIR):\n    try:\n        if not os.path.exists(log_dir):\n            os.makedirs(log_dir)\n        with open(os.path.join(log_dir, filename), 'a') as file:\n            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n            file.write(f'{timestamp} - {metrics}\\n')\n        return True\n    except Exception:\n        return False", "raw_solution": "import os\nfrom datetime import datetime\n\n# Constants\nLOG_DIR = './logs'\n\ndef task_func(metrics, filename, log_dir=LOG_DIR):\n    try:\n        if not os.path.exists(log_dir):\n            os.makedirs(log_dir)\n        with open(os.path.join(log_dir, filename), 'a') as file:\n            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n            file.write(f'{timestamp} - {metrics}\\n')\n        return True\n    except Exception:\n        return False\n```"}
{"task_id": "BigCodeBench/805", "solution": "import pandas as pd\nimport random\ndef task_func(dictionary, item, seed):\n    random.seed(seed)\n    df = pd.DataFrame(dictionary)\n    locations = []\n    for i, row in df.iterrows():\n        for j, value in row.items():\n            if value == item:\n                locations.append((i, j))\n    df = df.applymap(lambda x: x if x != item else random.randint(0, 9))\n    return locations, len(locations), df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(dictionary, item, seed):\n    random.seed(seed)\n    df = pd.DataFrame(dictionary)\n    locations = []\n    for i, row in df.iterrows():\n        for j, value in row.items():\n            if value == item:\n                locations.append((i, j))\n    df = df.applymap(lambda x: x if x != item else random.randint(0, 9))\n    return locations, len(locations), df\n```"}
{"task_id": "BigCodeBench/806", "solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(text, n=2):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n    # Generate n-grams\n    ngrams = zip(*[text.split()[i:] for i in range(n)])\n    ngrams = [' '.join(ngram) for ngram in ngrams]\n    # Count n-grams\n    ngram_counts = Counter(ngrams)\n    return dict(ngram_counts)", "raw_solution": "import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n# Constants\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(text, n=2):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n    # Generate n-grams\n    ngrams = zip(*[text.split()[i:] for i in range(n)])\n    ngrams = [' '.join(ngram) for ngram in ngrams]\n    # Count n-grams\n    ngram_counts = Counter(ngrams)\n    return dict(ngram_counts)\n```"}
{"task_id": "BigCodeBench/807", "solution": "import numpy as np\nfrom scipy.stats import norm\ndef task_func(data: np.ndarray, threshold: float = 2.0) -> list:\n    if np.std(data) == 0:\n        return [], np.mean(data), np.var(data)\n    mean, std_dev = norm.fit(data)\n    z_scores = [(x - mean) / std_dev for x in data]\n    outliers = [i for i, z_score in enumerate(z_scores) if abs(z_score) > threshold]\n    return outliers, mean, np.var(data)", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\n\ndef task_func(data: np.ndarray, threshold: float = 2.0) -> list:\n    if np.std(data) == 0:\n        return [], np.mean(data), np.var(data)\n    mean, std_dev = norm.fit(data)\n    z_scores = [(x - mean) / std_dev for x in data]\n    outliers = [i for i, z_score in enumerate(z_scores) if abs(z_score) > threshold]\n    return outliers, mean, np.var(data)"}
{"task_id": "BigCodeBench/808", "solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(text):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Remove stopwords\n    words = text.split()\n    words = [word for word in words if word not in STOPWORDS]\n    # Join words back into a string\n    text = ' '.join(words)\n    # Analyze sentiment\n    sentiment = TextBlob(text).sentiment.polarity\n    return sentiment", "raw_solution": "import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\n# Constants\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(text):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Remove stopwords\n    words = text.split()\n    words = [word for word in words if word not in STOPWORDS]\n    # Join words back into a string\n    text = ' '.join(words)\n    # Analyze sentiment\n    sentiment = TextBlob(text).sentiment.polarity\n    return sentiment\n```"}
{"task_id": "BigCodeBench/809", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\ndef task_func(data, n_clusters):\n    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data)\n    labels = kmeans.labels_\n    result = {}\n    for i in range(n_clusters):\n        result[i] = np.where(labels == i)[0]\n    return result", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\n\ndef task_func(data, n_clusters):\n    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data)\n    labels = kmeans.labels_\n    result = {}\n    for i in range(n_clusters):\n        result[i] = np.where(labels == i)[0]\n    return result\n```"}
{"task_id": "BigCodeBench/810", "solution": "import re\nimport os\nimport subprocess\ndef task_func(dir_path, exe_pattern, execute_files=True):\n    results = []\n    for root, dirs, files in os.walk(dir_path):\n        for file in files:\n            if re.search(exe_pattern, file):\n                file_path = os.path.join(root, file)\n                if execute_files:\n                    try:\n                        output = subprocess.check_output([file_path], stderr=subprocess.STDOUT)\n                        results.append(output.decode('utf-8'))\n                    except subprocess.CalledProcessError as e:\n                        results.append(e.output.decode('utf-8'))\n                else:\n                    results.append(file_path)\n    return results", "raw_solution": "import re\nimport os\nimport subprocess\n\ndef task_func(dir_path, exe_pattern, execute_files=True):\n    results = []\n    for root, dirs, files in os.walk(dir_path):\n        for file in files:\n            if re.search(exe_pattern, file):\n                file_path = os.path.join(root, file)\n                if execute_files:\n                    try:\n                        output = subprocess.check_output([file_path], stderr=subprocess.STDOUT)\n                        results.append(output.decode('utf-8'))\n                    except subprocess.CalledProcessError as e:\n                        results.append(e.output.decode('utf-8'))\n                else:\n                    results.append(file_path)\n    return results\n```"}
{"task_id": "BigCodeBench/811", "solution": "import pandas as pd\nfrom random import randint, seed\ndef task_func(dictionary, item, sample_size=None, random_seed=None):\n    df = pd.DataFrame(dictionary)\n    positions = [(i, col) for i, row in df.iterrows() for col in row.index if row[col] == item]\n    if sample_size is not None:\n        if random_seed is not None:\n            seed(random_seed)\n        positions = [positions[randint(0, len(positions) - 1)] for _ in range(sample_size)]\n    return positions, df", "raw_solution": "import pandas as pd\nfrom random import randint, seed\n\ndef task_func(dictionary, item, sample_size=None, random_seed=None):\n    df = pd.DataFrame(dictionary)\n    positions = [(i, col) for i, row in df.iterrows() for col in row.index if row[col] == item]\n    if sample_size is not None:\n        if random_seed is not None:\n            seed(random_seed)\n        positions = [positions[randint(0, len(positions) - 1)] for _ in range(sample_size)]\n    return positions, df\n```"}
{"task_id": "BigCodeBench/812", "solution": "import re\nfrom pathlib import Path\nimport tarfile\nPATTERN = r\"(?<!Distillr)\\\\\\\\AcroTray\\.exe\"\nDIRECTORY = r\"C:\\\\SomeDir\\\\\"\ndef task_func(directory=DIRECTORY, file_pattern=PATTERN):\n    \"\"\"\n    Find files that match the pattern of the regular expression '(?<!Distillr)\\\\\\\\AcroTray\\.exe' in the directory 'C:\\\\SomeDir\\\\'.\n    If found, archive these files in a tar file.\n    \"\"\"\n    # Create a list to store the paths of the files that match the pattern\n    file_paths = []\n\n    # Iterate over all files in the directory\n    for file in Path(directory).glob(\"**/*\"):\n        # Check if the file name matches the pattern\n        if re.search(file_pattern, file.name):\n            file_paths.append(str(file))\n\n    # Create a tar file\n    tar_file_path = Path(directory) / \"archive.tar\"\n    with tarfile.open(tar_file_path, \"w\") as tar:\n        for file_path in file_paths:\n            tar.add(file_path)\n\n    return str(tar_file_path)", "raw_solution": "import re\nfrom pathlib import Path\nimport tarfile\n\n# Constants\nPATTERN = r\"(?<!Distillr)\\\\\\\\AcroTray\\.exe\"\nDIRECTORY = r\"C:\\\\SomeDir\\\\\"\n\ndef task_func(directory=DIRECTORY, file_pattern=PATTERN):\n    \"\"\"\n    Find files that match the pattern of the regular expression '(?<!Distillr)\\\\\\\\AcroTray\\.exe' in the directory 'C:\\\\SomeDir\\\\'.\n    If found, archive these files in a tar file.\n    \"\"\"\n    # Create a list to store the paths of the files that match the pattern\n    file_paths = []\n\n    # Iterate over all files in the directory\n    for file in Path(directory).glob(\"**/*\"):\n        # Check if the file name matches the pattern\n        if re.search(file_pattern, file.name):\n            file_paths.append(str(file))\n\n    # Create a tar file\n    tar_file_path = Path(directory) / \"archive.tar\"\n    with tarfile.open(tar_file_path, \"w\") as tar:\n        for file_path in file_paths:\n            tar.add(file_path)\n\n    return str(tar_file_path)\n```"}
{"task_id": "BigCodeBench/813", "solution": "from itertools import combinations\nimport pandas as pd\ndef task_func(number_list, element):\n    if not number_list:\n        return pd.DataFrame(columns=['Combinations'])\n    result = [list(comb) for comb in combinations(number_list, 3) if sum(comb) == element]\n    return pd.DataFrame(result, columns=['Combinations'])", "raw_solution": "from itertools import combinations\nimport pandas as pd\n\ndef task_func(number_list, element):\n    if not number_list:\n        return pd.DataFrame(columns=['Combinations'])\n    result = [list(comb) for comb in combinations(number_list, 3) if sum(comb) == element]\n    return pd.DataFrame(result, columns=['Combinations'])\n```"}
{"task_id": "BigCodeBench/814", "solution": "import re\nimport os\nimport shutil\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    # Create a list to store the file paths\n    file_paths = []\n\n    # Iterate over the files in the source directory\n    for root, dirs, files in os.walk(source_dir):\n        for file in files:\n            # Check if the file matches the file pattern\n            if re.match(file_pattern, file):\n                # Append the file path to the list\n                file_paths.append(os.path.join(root, file))\n\n    # Write the file paths to a configuration file\n    with open(target_dir, 'w') as file:\n        for path in file_paths:\n            file.write(path + '\\n')\n\n    # Return the path to the configuration file\n    return target_dir", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    # Create a list to store the file paths\n    file_paths = []\n\n    # Iterate over the files in the source directory\n    for root, dirs, files in os.walk(source_dir):\n        for file in files:\n            # Check if the file matches the file pattern\n            if re.match(file_pattern, file):\n                # Append the file path to the list\n                file_paths.append(os.path.join(root, file))\n\n    # Write the file paths to a configuration file\n    with open(target_dir, 'w') as file:\n        for path in file_paths:\n            file.write(path + '\\n')\n\n    # Return the path to the configuration file\n    return target_dir\n```"}
{"task_id": "BigCodeBench/815", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(test_scores, student):\n    df = pd.DataFrame(test_scores)\n    if student not in df['Student'].values:\n        raise ValueError(\"student is not present in the test_scores dataframe\")\n    student_scores = df[df['Student'] == student]['Score']\n    return np.array([student_scores.mean(), student_scores.std()]), df", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(test_scores, student):\n    df = pd.DataFrame(test_scores)\n    if student not in df['Student'].values:\n        raise ValueError(\"student is not present in the test_scores dataframe\")\n    student_scores = df[df['Student'] == student]['Score']\n    return np.array([student_scores.mean(), student_scores.std()]), df\n```"}
{"task_id": "BigCodeBench/816", "solution": "from collections import Counter\nimport random\nHAND_RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\nSUITS = ['H', 'D', 'C', 'S']\ndef task_func():\n    hand = [random.choice(HAND_RANKS) + random.choice(SUITS) for _ in range(5)]\n    rank_count = Counter(card[0] for card in hand)\n    return (hand, rank_count)", "raw_solution": "from collections import Counter\nimport random\n\n# Constants\nHAND_RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\nSUITS = ['H', 'D', 'C', 'S']\n\ndef task_func():\n    hand = [random.choice(HAND_RANKS) + random.choice(SUITS) for _ in range(5)]\n    rank_count = Counter(card[0] for card in hand)\n    return (hand, rank_count)\n```"}
{"task_id": "BigCodeBench/817", "solution": "from collections import Counter\nimport logging\ndef task_func(letter_list, element, log_path):\n    logging.basicConfig(filename=f\"{log_path}/task_func.log\", encoding='utf-8', level=logging.DEBUG)\n    logging.info(f\"Function called with list: {letter_list} and element: {element}\")\n    if element not in letter_list:\n        logging.error(f\"The element '{element}' is not in the letter list.\")\n        raise ValueError(\"The element is not in the letter list.\")\n    element_frequency = Counter(letter_list)[element]\n    logging.info(f\"Frequency of '{element}' is {element_frequency}\")\n    logging.shutdown()\n    return element_frequency", "raw_solution": "from collections import Counter\nimport logging\n\ndef task_func(letter_list, element, log_path):\n    logging.basicConfig(filename=f\"{log_path}/task_func.log\", encoding='utf-8', level=logging.DEBUG)\n    logging.info(f\"Function called with list: {letter_list} and element: {element}\")\n    if element not in letter_list:\n        logging.error(f\"The element '{element}' is not in the letter list.\")\n        raise ValueError(\"The element is not in the letter list.\")\n    element_frequency = Counter(letter_list)[element]\n    logging.info(f\"Frequency of '{element}' is {element_frequency}\")\n    logging.shutdown()\n    return element_frequency\n```"}
{"task_id": "BigCodeBench/818", "solution": "import re\nimport string\nPUNCTUATION = string.punctuation\ndef task_func(text):\n    # Remove punctuation and convert to lowercase\n    cleaned_text = re.sub(r'[' + re.escape(PUNCTUATION) + ']', '', text).lower()\n    # Split the text into words\n    cleaned_words = cleaned_text.split()\n    return cleaned_words", "raw_solution": "import re\nimport string\n# Constants\nPUNCTUATION = string.punctuation\ndef task_func(text):\n    # Remove punctuation and convert to lowercase\n    cleaned_text = re.sub(r'[' + re.escape(PUNCTUATION) + ']', '', text).lower()\n    # Split the text into words\n    cleaned_words = cleaned_text.split()\n    return cleaned_words\n```"}
{"task_id": "BigCodeBench/819", "solution": "import time\nimport random\ndef task_func(iterations=5, min_delay=1.0, max_delay=2.0, seed=None):\n    if iterations <= 0 or not isinstance(iterations, int):\n        raise ValueError(\"Iterations must be a positive integer\")\n    if min_delay <= 0 or max_delay <= 0 or min_delay > max_delay:\n        raise ValueError(\"Min_delay and max_delay must be positive and min_delay <= max_delay\")\n    if seed is not None:\n        random.seed(seed)\n    messages = []\n    total_delay = 0\n    for i in range(iterations):\n        delay = random.uniform(min_delay, max_delay)\n        time.sleep(delay)\n        messages.append(f\"{delay:.2f} seconds have passed\")\n        total_delay += delay\n    return messages, total_delay", "raw_solution": "import time\nimport random\n\ndef task_func(iterations=5, min_delay=1.0, max_delay=2.0, seed=None):\n    if iterations <= 0 or not isinstance(iterations, int):\n        raise ValueError(\"Iterations must be a positive integer\")\n    if min_delay <= 0 or max_delay <= 0 or min_delay > max_delay:\n        raise ValueError(\"Min_delay and max_delay must be positive and min_delay <= max_delay\")\n    if seed is not None:\n        random.seed(seed)\n    messages = []\n    total_delay = 0\n    for i in range(iterations):\n        delay = random.uniform(min_delay, max_delay)\n        time.sleep(delay)\n        messages.append(f\"{delay:.2f} seconds have passed\")\n        total_delay += delay\n    return messages, total_delay\n```"}
{"task_id": "BigCodeBench/820", "solution": "import random\nimport string\nLETTERS = string.ascii_letters\ndef task_func(num_words, word_length):\n    if num_words < 0 or word_length < 0:\n        raise ValueError(\"Both num_words and word_length must be non-negative\")\n    words = []\n    for _ in range(num_words):\n        word = ''.join(random.choice(LETTERS) for _ in range(word_length))\n        words.append(word)\n    return words", "raw_solution": "import random\nimport string\n# Constants\nLETTERS = string.ascii_letters\ndef task_func(num_words, word_length):\n    if num_words < 0 or word_length < 0:\n        raise ValueError(\"Both num_words and word_length must be non-negative\")\n    words = []\n    for _ in range(num_words):\n        word = ''.join(random.choice(LETTERS) for _ in range(word_length))\n        words.append(word)\n    return words\n```"}
{"task_id": "BigCodeBench/821", "solution": "import time\nimport threading\ndef task_func(delay_time: float = 1.0, num_threads: int = 5):\n    def worker(i):\n        time.sleep(delay_time)\n        return f'Delay in thread {i} completed'\n\n    threads = []\n    results = []\n\n    for i in range(num_threads):\n        t = threading.Thread(target=lambda: results.append(worker(i)))\n        threads.append(t)\n        t.start()\n\n    for t in threads:\n        t.join()\n\n    return results", "raw_solution": "import time\nimport threading\n\ndef task_func(delay_time: float = 1.0, num_threads: int = 5):\n    def worker(i):\n        time.sleep(delay_time)\n        return f'Delay in thread {i} completed'\n\n    threads = []\n    results = []\n\n    for i in range(num_threads):\n        t = threading.Thread(target=lambda: results.append(worker(i)))\n        threads.append(t)\n        t.start()\n\n    for t in threads:\n        t.join()\n\n    return results\n```"}
{"task_id": "BigCodeBench/822", "solution": "import random\nimport string\nLETTERS = string.ascii_letters\nDIGITS = string.digits\ndef task_func(length, num_digits):\n    if num_digits > length:\n        raise ValueError(\"Number of digits cannot exceed the length of the password\")\n    password = []\n    for i in range(num_digits):\n        password.append(random.choice(DIGITS))\n    for i in range(length - num_digits):\n        password.append(random.choice(LETTERS))\n    random.shuffle(password)\n    return ''.join(password)", "raw_solution": "import random\nimport string\n\n# Constants\nLETTERS = string.ascii_letters\nDIGITS = string.digits\n\ndef task_func(length, num_digits):\n    if num_digits > length:\n        raise ValueError(\"Number of digits cannot exceed the length of the password\")\n    password = []\n    for i in range(num_digits):\n        password.append(random.choice(DIGITS))\n    for i in range(length - num_digits):\n        password.append(random.choice(LETTERS))\n    random.shuffle(password)\n    return ''.join(password)\n```"}
{"task_id": "BigCodeBench/823", "solution": "import time\nimport numpy as np\ndef task_func(samples=10, delay=0.1):\n    delay_times = []\n    for i in range(samples):\n        start_time = time.time()\n        time.sleep(delay)\n        end_time = time.time()\n        delay_times.append(end_time - start_time)\n    mean_delay = np.mean(delay_times)\n    std_dev_delay = np.std(delay_times)\n    return (mean_delay, std_dev_delay)", "raw_solution": "import time\nimport numpy as np\n\ndef task_func(samples=10, delay=0.1):\n    delay_times = []\n    for i in range(samples):\n        start_time = time.time()\n        time.sleep(delay)\n        end_time = time.time()\n        delay_times.append(end_time - start_time)\n    mean_delay = np.mean(delay_times)\n    std_dev_delay = np.std(delay_times)\n    return (mean_delay, std_dev_delay)\n```"}
{"task_id": "BigCodeBench/824", "solution": "import re\nimport string\nPUNCTUATION = string.punctuation\ndef task_func(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    punctuation_marks = sum(1 for char in text if char in PUNCTUATION)\n    return (len(words), punctuation_marks)", "raw_solution": "import re\nimport string\n# Constants\nPUNCTUATION = string.punctuation\ndef task_func(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    punctuation_marks = sum(1 for char in text if char in PUNCTUATION)\n    return (len(words), punctuation_marks)\n```"}
{"task_id": "BigCodeBench/825", "solution": "import numpy as np\nfrom itertools import product\nimport string\ndef task_func(length, seed=None, alphabets=list(string.ascii_lowercase)):\n    np.random.seed(seed)\n    return [''.join(np.random.choice(alphabets, size=length)) for _ in range(10)]", "raw_solution": "import numpy as np\nfrom itertools import product\nimport string\n\ndef task_func(length, seed=None, alphabets=list(string.ascii_lowercase)):\n    np.random.seed(seed)\n    return [''.join(np.random.choice(alphabets, size=length)) for _ in range(10)]\n```"}
{"task_id": "BigCodeBench/826", "solution": "import re\nimport os\nimport shutil\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    moved_files_count = 0\n    for filename in os.listdir(source_dir):\n        if re.match(file_pattern, filename):\n            shutil.move(os.path.join(source_dir, filename), target_dir)\n            moved_files_count += 1\n    return moved_files_count", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    moved_files_count = 0\n    for filename in os.listdir(source_dir):\n        if re.match(file_pattern, filename):\n            shutil.move(os.path.join(source_dir, filename), target_dir)\n            moved_files_count += 1\n    return moved_files_count\n```"}
{"task_id": "BigCodeBench/827", "solution": "import math\nfrom sympy import isprime\ndef task_func(input_list):\n    prime_list = [num for num in input_list if isprime(num)]\n    prime_list.sort(key=lambda x: math.degrees(math.atan(x)))\n    return prime_list", "raw_solution": "import math\nfrom sympy import isprime\n\ndef task_func(input_list):\n    prime_list = [num for num in input_list if isprime(num)]\n    prime_list.sort(key=lambda x: math.degrees(math.atan(x)))\n    return prime_list\n```"}
{"task_id": "BigCodeBench/828", "solution": "import os\nimport errno\nimport shutil\ndef task_func(filename, dest_dir):\n    try:\n        if not os.path.exists(dest_dir):\n            os.makedirs(dest_dir)\n        shutil.copy(filename, dest_dir)\n        with open(os.path.join(dest_dir, os.path.basename(filename)), 'w') as f:\n            pass\n        return os.path.join(dest_dir, os.path.basename(filename))\n    except OSError as e:\n        if e.errno == errno.ENOENT:\n            raise OSError(\"Destination directory does not exist\")\n        elif e.errno == errno.EEXIST:\n            raise OSError(\"File already exists in destination directory\")\n        else:\n            raise OSError(\"Failed to copy file\")", "raw_solution": "import os\nimport errno\nimport shutil\n\ndef task_func(filename, dest_dir):\n    try:\n        if not os.path.exists(dest_dir):\n            os.makedirs(dest_dir)\n        shutil.copy(filename, dest_dir)\n        with open(os.path.join(dest_dir, os.path.basename(filename)), 'w') as f:\n            pass\n        return os.path.join(dest_dir, os.path.basename(filename))\n    except OSError as e:\n        if e.errno == errno.ENOENT:\n            raise OSError(\"Destination directory does not exist\")\n        elif e.errno == errno.EEXIST:\n            raise OSError(\"File already exists in destination directory\")\n        else:\n            raise OSError(\"Failed to copy file\")\n```"}
{"task_id": "BigCodeBench/829", "solution": "import pandas as pd\nfrom statistics import mean\ndef task_func(df: pd.DataFrame) -> dict:\n    if 'Name' not in df.columns or 'Score' not in df.columns:\n        raise ValueError(\"DataFrame must have 'Name' and 'Score' columns\")\n    df_grouped = df.groupby('Name')['Score'].mean().reset_index()\n    return {name: ((name, score) for score in df_grouped[df_grouped['Name'] == name]['Score']) for name in df_grouped['Name']}", "raw_solution": "import pandas as pd\nfrom statistics import mean\n\ndef task_func(df: pd.DataFrame) -> dict:\n    if 'Name' not in df.columns or 'Score' not in df.columns:\n        raise ValueError(\"DataFrame must have 'Name' and 'Score' columns\")\n    df_grouped = df.groupby('Name')['Score'].mean().reset_index()\n    return {name: ((name, score) for score in df_grouped[df_grouped['Name'] == name]['Score']) for name in df_grouped['Name']}\n```"}
{"task_id": "BigCodeBench/830", "solution": "import json\nimport os\ndef task_func(filename, data):\n    try:\n        with open(filename, 'w') as file:\n            json.dump(data, file)\n        with open(filename, 'r') as file:\n            read_data = json.load(file)\n        return (True, read_data)\n    except Exception as e:\n        return (False, str(e))", "raw_solution": "import json\nimport os\n\ndef task_func(filename, data):\n    try:\n        with open(filename, 'w') as file:\n            json.dump(data, file)\n        with open(filename, 'r') as file:\n            read_data = json.load(file)\n        return (True, read_data)\n    except Exception as e:\n        return (False, str(e))\n```"}
{"task_id": "BigCodeBench/831", "solution": "import random\nimport math\ndef task_func(range_start=1, range_end=100, pairs_count=10, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    for _ in range(pairs_count):\n        num1 = random.randint(range_start, range_end)\n        num2 = random.randint(range_start, range_end)\n        yield (num1, num2, math.sqrt(abs(num1 - num2)))", "raw_solution": "import random\nimport math\n\ndef task_func(range_start=1, range_end=100, pairs_count=10, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    for _ in range(pairs_count):\n        num1 = random.randint(range_start, range_end)\n        num2 = random.randint(range_start, range_end)\n        yield (num1, num2, math.sqrt(abs(num1 - num2)))\n```"}
{"task_id": "BigCodeBench/832", "solution": "import pickle\nimport os\ndef task_func(filename, data):\n    try:\n        if not os.path.exists(os.path.dirname(filename)):\n            os.makedirs(os.path.dirname(filename))\n        with open(filename, 'wb') as file:\n            pickle.dump(data, file)\n        return True\n    except Exception:\n        return False", "raw_solution": "import pickle\nimport os\n\ndef task_func(filename, data):\n    try:\n        if not os.path.exists(os.path.dirname(filename)):\n            os.makedirs(os.path.dirname(filename))\n        with open(filename, 'wb') as file:\n            pickle.dump(data, file)\n        return True\n    except Exception:\n        return False\n```"}
{"task_id": "BigCodeBench/833", "solution": "import random\nfrom collections import Counter\nfrom statistics import mode\ndef task_func(list_length=1000, range_start=1, range_end=10, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    random_list = [random.randint(range_start, range_end) for _ in range(list_length)]\n    numbers = Counter(random_list)\n    return mode(random_list), ((num, freq) for num, freq in numbers.items())", "raw_solution": "import random\nfrom collections import Counter\nfrom statistics import mode\n\ndef task_func(list_length=1000, range_start=1, range_end=10, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    random_list = [random.randint(range_start, range_end) for _ in range(list_length)]\n    numbers = Counter(random_list)\n    return mode(random_list), ((num, freq) for num, freq in numbers.items())\n```"}
{"task_id": "BigCodeBench/834", "solution": "import binascii\nimport io\nimport gzip\ndef task_func(compressed_hex):\n    try:\n        compressed_bytes = binascii.unhexlify(compressed_hex)\n        decompressed_bytes = gzip.decompress(compressed_bytes)\n        decoded_string = decompressed_bytes.decode('utf-8')\n        return decoded_string\n    except Exception as e:\n        return str(e)", "raw_solution": "import binascii\nimport io\nimport gzip\ndef task_func(compressed_hex):\n    try:\n        compressed_bytes = binascii.unhexlify(compressed_hex)\n        decompressed_bytes = gzip.decompress(compressed_bytes)\n        decoded_string = decompressed_bytes.decode('utf-8')\n        return decoded_string\n    except Exception as e:\n        return str(e)\n```"}
{"task_id": "BigCodeBench/835", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(n_rows, remove_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.randint(0, 100, size=(n_rows, len(columns))), columns=columns)\n    df = df.drop(columns=df.columns[remove_cols])\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(n_rows, remove_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.randint(0, 100, size=(n_rows, len(columns))), columns=columns)\n    df = df.drop(columns=df.columns[remove_cols])\n    return df\n```"}
{"task_id": "BigCodeBench/836", "solution": "import os\nimport shutil\nimport csv\ndef task_func(target_value='332', csv_dir='./csv_files/', processed_dir='./processed_files/', simulate=False):\n    result = {}\n    for filename in os.listdir(csv_dir):\n        if filename.endswith('.csv'):\n            with open(os.path.join(csv_dir, filename), 'r') as file:\n                reader = csv.reader(file)\n                for index, row in enumerate(reader):\n                    if row[0] == target_value:\n                        result[filename] = index\n                        if not simulate:\n                            shutil.move(os.path.join(csv_dir, filename), os.path.join(processed_dir, filename))\n                        break\n    return result", "raw_solution": "import os\nimport shutil\nimport csv\n\ndef task_func(target_value='332', csv_dir='./csv_files/', processed_dir='./processed_files/', simulate=False):\n    result = {}\n    for filename in os.listdir(csv_dir):\n        if filename.endswith('.csv'):\n            with open(os.path.join(csv_dir, filename), 'r') as file:\n                reader = csv.reader(file)\n                for index, row in enumerate(reader):\n                    if row[0] == target_value:\n                        result[filename] = index\n                        if not simulate:\n                            shutil.move(os.path.join(csv_dir, filename), os.path.join(processed_dir, filename))\n                        break\n    return result\n```"}
{"task_id": "BigCodeBench/837", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(n_rows, scale_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.randint(0,100,size=(n_rows, len(columns))), columns=columns)\n    scaler = StandardScaler()\n    df.iloc[:, scale_cols] = scaler.fit_transform(df.iloc[:, scale_cols])\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(n_rows, scale_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.randint(0,100,size=(n_rows, len(columns))), columns=columns)\n    scaler = StandardScaler()\n    df.iloc[:, scale_cols] = scaler.fit_transform(df.iloc[:, scale_cols])\n    return df\n```"}
{"task_id": "BigCodeBench/838", "solution": "import re\nfrom nltk.stem import PorterStemmer\ndef task_func(text_series):\n    stemmer = PorterStemmer()\n    text_series = text_series.str.lower()\n    text_series = text_series.apply(lambda x: re.sub(r'[^a-zA-Z0-9 ]', '', x))\n    text_series = text_series.apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n    return text_series", "raw_solution": "import re\nfrom nltk.stem import PorterStemmer\n\ndef task_func(text_series):\n    stemmer = PorterStemmer()\n    text_series = text_series.str.lower()\n    text_series = text_series.apply(lambda x: re.sub(r'[^a-zA-Z0-9 ]', '', x))\n    text_series = text_series.apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n    return text_series\n```"}
{"task_id": "BigCodeBench/839", "solution": "import csv\nimport random\nimport string\ndef task_func(file_path,\n          num_rows,\n          gender=['Male', 'Female', 'Non-Binary'],\n          countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n          seed=None):\n    if seed is not None:\n        random.seed(seed)\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Name', 'Age', 'Gender', 'Country'])\n        for _ in range(num_rows):\n            name = ''.join(random.choice(string.ascii_uppercase) for _ in range(5))\n            age = random.randint(20, 60)\n            gend = random.choice(gender)\n            countr = random.choice(countries)\n            writer.writerow([name, age, gend, countr])\n    return file_path", "raw_solution": "import csv\nimport random\nimport string\n\ndef task_func(file_path,\n          num_rows,\n          gender=['Male', 'Female', 'Non-Binary'],\n          countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n          seed=None):\n    if seed is not None:\n        random.seed(seed)\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Name', 'Age', 'Gender', 'Country'])\n        for _ in range(num_rows):\n            name = ''.join(random.choice(string.ascii_uppercase) for _ in range(5))\n            age = random.randint(20, 60)\n            gend = random.choice(gender)\n            countr = random.choice(countries)\n            writer.writerow([name, age, gend, countr])\n    return file_path\n```"}
{"task_id": "BigCodeBench/840", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(file_path, num_rows, data_dimensions=5, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    data = np.random.rand(num_rows, data_dimensions)\n    df = pd.DataFrame(data, columns=[f'Feature_{i+1}' for i in range(data_dimensions)])\n    df.to_csv(file_path, index=False)\n    return file_path", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(file_path, num_rows, data_dimensions=5, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    data = np.random.rand(num_rows, data_dimensions)\n    df = pd.DataFrame(data, columns=[f'Feature_{i+1}' for i in range(data_dimensions)])\n    df.to_csv(file_path, index=False)\n    return file_path\n```"}
{"task_id": "BigCodeBench/841", "solution": "import re\nimport json\nfrom collections import defaultdict\nimport string\ndef task_func(json_string):\n    try:\n        data = json.loads(json_string)\n        if \"text\" in data:\n            text = data[\"text\"]\n            text = text.lower()\n            text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n            words = text.split()\n            word_count = defaultdict(int)\n            for word in words:\n                word_count[word] += 1\n            return dict(word_count)\n        else:\n            return {}\n    except json.JSONDecodeError:\n        return {}", "raw_solution": "import re\nimport json\nfrom collections import defaultdict\nimport string\n\ndef task_func(json_string):\n    try:\n        data = json.loads(json_string)\n        if \"text\" in data:\n            text = data[\"text\"]\n            text = text.lower()\n            text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n            words = text.split()\n            word_count = defaultdict(int)\n            for word in words:\n                word_count[word] += 1\n            return dict(word_count)\n        else:\n            return {}\n    except json.JSONDecodeError:\n        return {}"}
{"task_id": "BigCodeBench/842", "solution": "import sqlite3\nimport random\ndef task_func(db_path,\n          num_entries,\n          users=['Alice', 'Bob', 'Charlie', 'Dave', 'Eve'],\n          countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n          random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    conn = sqlite3.connect(db_path)\n    c = conn.cursor()\n\n    c.execute('''CREATE TABLE users\n                 (id INTEGER PRIMARY KEY, name TEXT, age INTEGER, country TEXT)''')\n\n    for i in range(num_entries):\n        name = random.choice(users)\n        age = random.randint(20, 60)\n        country = random.choice(countries)\n        c.execute(\"INSERT INTO users VALUES (?, ?, ?, ?)\", (i+1, name, age, country))\n\n    conn.commit()\n    conn.close()\n\n    return db_path", "raw_solution": "import sqlite3\nimport random\n\ndef task_func(db_path,\n          num_entries,\n          users=['Alice', 'Bob', 'Charlie', 'Dave', 'Eve'],\n          countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n          random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    conn = sqlite3.connect(db_path)\n    c = conn.cursor()\n\n    c.execute('''CREATE TABLE users\n                 (id INTEGER PRIMARY KEY, name TEXT, age INTEGER, country TEXT)''')\n\n    for i in range(num_entries):\n        name = random.choice(users)\n        age = random.randint(20, 60)\n        country = random.choice(countries)\n        c.execute(\"INSERT INTO users VALUES (?, ?, ?, ?)\", (i+1, name, age, country))\n\n    conn.commit()\n    conn.close()\n\n    return db_path\n```"}
{"task_id": "BigCodeBench/843", "solution": "import random\nimport re\nWORD_LIST = [\"sample\", \"text\", \"contains\", \"several\", \"words\", \"including\"]\ndef task_func(n_sentences):\n    sentences = []\n    for _ in range(n_sentences):\n        sentence = \" \".join(random.choice(WORD_LIST) for _ in range(random.randint(1, 10)))\n        sentences.append(sentence)\n    return re.sub(r'[^a-zA-Z0-9 ]', '', ' '.join(sentences))", "raw_solution": "import random\nimport re\n\n# Constants\nWORD_LIST = [\"sample\", \"text\", \"contains\", \"several\", \"words\", \"including\"]\n\ndef task_func(n_sentences):\n    sentences = []\n    for _ in range(n_sentences):\n        sentence = \" \".join(random.choice(WORD_LIST) for _ in range(random.randint(1, 10)))\n        sentences.append(sentence)\n    return re.sub(r'[^a-zA-Z0-9 ]', '', ' '.join(sentences))\n```"}
{"task_id": "BigCodeBench/844", "solution": "import csv\nimport random\nfrom faker import Faker\ndef task_func(file_path, num_rows, random_seed=None):\n    if not isinstance(num_rows, int) or num_rows < 0:\n        raise ValueError(\"num_rows must be an integer >= 0\")\n    if random_seed is not None:\n        random.seed(random_seed)\n    fake = Faker()\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Name', 'Age', 'Address', 'Email'])\n        for _ in range(num_rows):\n            name = fake.name()\n            age = random.randint(20, 60)\n            address = fake.address().replace('\\n', ', ')\n            email = fake.email()\n            writer.writerow([name, age, address, email])\n    return file_path", "raw_solution": "import csv\nimport random\nfrom faker import Faker\n\ndef task_func(file_path, num_rows, random_seed=None):\n    if not isinstance(num_rows, int) or num_rows < 0:\n        raise ValueError(\"num_rows must be an integer >= 0\")\n    if random_seed is not None:\n        random.seed(random_seed)\n    fake = Faker()\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Name', 'Age', 'Address', 'Email'])\n        for _ in range(num_rows):\n            name = fake.name()\n            age = random.randint(20, 60)\n            address = fake.address().replace('\\n', ', ')\n            email = fake.email()\n            writer.writerow([name, age, address, email])\n    return file_path\n```"}
{"task_id": "BigCodeBench/845", "solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom Levenshtein import ratio\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(text1, text2):\n    # Clean the texts\n    text1 = ALPHANUMERIC.sub(' ', text1).lower()\n    text2 = ALPHANUMERIC.sub(' ', text2).lower()\n\n    # Calculate term frequency\n    term_freq1 = Counter(text1.split())\n    term_freq2 = Counter(text2.split())\n\n    # Calculate cosine similarity\n    cosine_similarity = np.dot(list(term_freq1.values()), list(term_freq2.values())) / (np.linalg.norm(list(term_freq1.values())) * np.linalg.norm(list(term_freq2.values())))\n\n    # Calculate Levenshtein ratio\n    levenshtein_ratio = ratio(text1, text2)\n\n    return (cosine_similarity, levenshtein_ratio)", "raw_solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom Levenshtein import ratio\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(text1, text2):\n    # Clean the texts\n    text1 = ALPHANUMERIC.sub(' ', text1).lower()\n    text2 = ALPHANUMERIC.sub(' ', text2).lower()\n\n    # Calculate term frequency\n    term_freq1 = Counter(text1.split())\n    term_freq2 = Counter(text2.split())\n\n    # Calculate cosine similarity\n    cosine_similarity = np.dot(list(term_freq1.values()), list(term_freq2.values())) / (np.linalg.norm(list(term_freq1.values())) * np.linalg.norm(list(term_freq2.values())))\n\n    # Calculate Levenshtein ratio\n    levenshtein_ratio = ratio(text1, text2)\n\n    return (cosine_similarity, levenshtein_ratio)\n```"}
{"task_id": "BigCodeBench/846", "solution": "import collections\nimport pandas as pd\ndef task_func(obj_list, attr):\n    if not obj_list:\n        return pd.DataFrame(columns=['attribute', 'count'])\n\n    attr_values = [getattr(obj, attr) for obj in obj_list]\n    counter = collections.Counter(attr_values)\n\n    df = pd.DataFrame(list(counter.items()), columns=['attribute', 'count'])\n    return df", "raw_solution": "import collections\nimport pandas as pd\n\nclass ExampleObject:\n    def __init__(self, animal, shape):\n        self.animal = animal\n        self.shape = shape\n\ndef task_func(obj_list, attr):\n    if not obj_list:\n        return pd.DataFrame(columns=['attribute', 'count'])\n\n    attr_values = [getattr(obj, attr) for obj in obj_list]\n    counter = collections.Counter(attr_values)\n\n    df = pd.DataFrame(list(counter.items()), columns=['attribute', 'count'])\n    return df\n```"}
{"task_id": "BigCodeBench/847", "solution": "import re\nimport os\nimport string\nimport random\ndef task_func(input_string, directory='./text_files'):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    file_paths = []\n    lines = input_string.split('\\n')\n    for line in lines:\n        line = re.sub(r'[^A-Za-z0-9 ]+', '', line)\n        file_name = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10)) + '.txt'\n        file_path = os.path.join(directory, file_name)\n        with open(file_path, 'w') as file:\n            file.write(line)\n        file_paths.append(file_path)\n\n    return file_paths", "raw_solution": "import re\nimport os\nimport string\nimport random\n\ndef task_func(input_string, directory='./text_files'):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    file_paths = []\n    lines = input_string.split('\\n')\n    for line in lines:\n        line = re.sub(r'[^A-Za-z0-9 ]+', '', line)\n        file_name = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10)) + '.txt'\n        file_path = os.path.join(directory, file_name)\n        with open(file_path, 'w') as file:\n            file.write(line)\n        file_paths.append(file_path)\n\n    return file_paths\n```"}
{"task_id": "BigCodeBench/848", "solution": "import heapq\nimport random\ndef task_func(obj_list, attr, top_n=5, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    values = [getattr(obj, attr) for obj in obj_list]\n    top_values = heapq.nlargest(top_n, values)\n    random_value = random.choice(values)\n    return top_values, random_value", "raw_solution": "import heapq\nimport random\n\nclass Object:\n    def __init__(self, value):\n        self.test = value\n\ndef task_func(obj_list, attr, top_n=5, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    values = [getattr(obj, attr) for obj in obj_list]\n    top_values = heapq.nlargest(top_n, values)\n    random_value = random.choice(values)\n    return top_values, random_value\n```"}
{"task_id": "BigCodeBench/849", "solution": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(input_string):\n    lines = input_string.split('\\n')\n    words = []\n    for line in lines:\n        words.extend(re.findall(r'\\b\\w+\\b', line))\n    words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n    return dict(Counter(words))", "raw_solution": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(input_string):\n    lines = input_string.split('\\n')\n    words = []\n    for line in lines:\n        words.extend(re.findall(r'\\b\\w+\\b', line))\n    words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n    return dict(Counter(words))\n```"}
{"task_id": "BigCodeBench/850", "solution": "import pandas as pd\nimport statistics\nimport random\ndef task_func(students, subjects, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    data = []\n    for student in range(1, students + 1):\n        grades = [random.randint(1, 100) for _ in range(subjects)]\n        average = statistics.mean(grades)\n        data.append([student] + grades + [average])\n    df = pd.DataFrame(data, columns=['Student'] + [f'Subject{i}' for i in range(1, subjects + 1)] + ['Average Grade'])\n    return df", "raw_solution": "import pandas as pd\nimport statistics\nimport random\n\ndef task_func(students, subjects, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    data = []\n    for student in range(1, students + 1):\n        grades = [random.randint(1, 100) for _ in range(subjects)]\n        average = statistics.mean(grades)\n        data.append([student] + grades + [average])\n    df = pd.DataFrame(data, columns=['Student'] + [f'Subject{i}' for i in range(1, subjects + 1)] + ['Average Grade'])\n    return df\n```"}
{"task_id": "BigCodeBench/851", "solution": "import textwrap\nimport re\ndef task_func(input_string, width):\n    lines = input_string.split('\\n')\n    wrapped_lines = [textwrap.fill(line, width) for line in lines]\n    return '\\n'.join(wrapped_lines)", "raw_solution": "import textwrap\nimport re\ndef task_func(input_string, width):\n    lines = input_string.split('\\n')\n    wrapped_lines = [textwrap.fill(line, width) for line in lines]\n    return '\\n'.join(wrapped_lines)\n```"}
{"task_id": "BigCodeBench/852", "solution": "import random\nimport string\ndef task_func(max_length, n_samples, seed=None):\n    if max_length < 1:\n        raise ValueError(\"max_length must be greater than 0\")\n    random.seed(seed)\n    return [''.join(random.choices(string.ascii_lowercase, k=random.randint(1, max_length))) for _ in range(n_samples)]", "raw_solution": "import random\nimport string\n\ndef task_func(max_length, n_samples, seed=None):\n    if max_length < 1:\n        raise ValueError(\"max_length must be greater than 0\")\n    random.seed(seed)\n    return [''.join(random.choices(string.ascii_lowercase, k=random.randint(1, max_length))) for _ in range(n_samples)]\n```"}
{"task_id": "BigCodeBench/853", "solution": "import os\nimport shutil\nimport string\nINVALID_CHARACTERS = string.punctuation + string.whitespace\ndef task_func(directory_path):\n    invalid_dir = os.path.join(directory_path, \"Invalid\")\n    if not os.path.exists(invalid_dir):\n        os.makedirs(invalid_dir)\n    summary = {\"Invalid\": 0}\n    for filename in os.listdir(directory_path):\n        if any(char in filename for char in INVALID_CHARACTERS):\n            shutil.move(os.path.join(directory_path, filename), invalid_dir)\n            summary[\"Invalid\"] += 1\n    return summary", "raw_solution": "import os\nimport shutil\nimport string\n# Constants\nINVALID_CHARACTERS = string.punctuation + string.whitespace\ndef task_func(directory_path):\n    invalid_dir = os.path.join(directory_path, \"Invalid\")\n    if not os.path.exists(invalid_dir):\n        os.makedirs(invalid_dir)\n    summary = {\"Invalid\": 0}\n    for filename in os.listdir(directory_path):\n        if any(char in filename for char in INVALID_CHARACTERS):\n            shutil.move(os.path.join(directory_path, filename), invalid_dir)\n            summary[\"Invalid\"] += 1\n    return summary\n```"}
{"task_id": "BigCodeBench/854", "solution": "from functools import reduce\nfrom itertools import permutations\nimport math\ndef task_func(numbers):\n    if not isinstance(numbers, list):\n        raise TypeError(\"Input must be a list of integers\")\n    if not all(isinstance(i, int) for i in numbers):\n        raise TypeError(\"Input must be a list of integers\")\n    if not all(i >= 0 for i in numbers):\n        raise ValueError(\"Input numbers must be non-negative\")\n    if not numbers:\n        return ([], [])\n    fac = [math.factorial(i) for i in numbers]\n    perm = [i for i in permutations(numbers)]\n    return (fac, perm)", "raw_solution": "from functools import reduce\nfrom itertools import permutations\nimport math\n\ndef task_func(numbers):\n    if not isinstance(numbers, list):\n        raise TypeError(\"Input must be a list of integers\")\n    if not all(isinstance(i, int) for i in numbers):\n        raise TypeError(\"Input must be a list of integers\")\n    if not all(i >= 0 for i in numbers):\n        raise ValueError(\"Input numbers must be non-negative\")\n    if not numbers:\n        return ([], [])\n    fac = [math.factorial(i) for i in numbers]\n    perm = [i for i in permutations(numbers)]\n    return (fac, perm)\n```"}
{"task_id": "BigCodeBench/855", "solution": "import random\nimport string\nimport collections\nVALID_CHARACTERS = string.ascii_letters + string.digits\ndef task_func(n_strings, string_length):\n    # Generate n random strings of a specified length\n    strings = [''.join(random.choices(VALID_CHARACTERS, k=string_length)) for _ in range(n_strings)]\n    # Count the frequency of each character across all strings\n    char_counts = collections.Counter(''.join(strings))\n    return dict(char_counts)", "raw_solution": "import random\nimport string\nimport collections\n# Constants\nVALID_CHARACTERS = string.ascii_letters + string.digits\ndef task_func(n_strings, string_length):\n    # Generate n random strings of a specified length\n    strings = [''.join(random.choices(VALID_CHARACTERS, k=string_length)) for _ in range(n_strings)]\n    # Count the frequency of each character across all strings\n    char_counts = collections.Counter(''.join(strings))\n    return dict(char_counts)\n```"}
{"task_id": "BigCodeBench/856", "solution": "from functools import reduce\nfrom itertools import combinations\nimport numpy as np\ndef task_func(shape=(3, 3), low=1, high=10, seed=None):\n    if high <= low:\n        raise ValueError(\"high must be greater than low\")\n    np.random.seed(seed)\n    matrix = np.random.randint(low, high, shape)\n    pairs = list(combinations(matrix.flatten(), 2))\n    sum_of_products = sum(reduce(lambda x, y: x * y, pair) for pair in pairs)\n    return sum_of_products, matrix", "raw_solution": "from functools import reduce\nfrom itertools import combinations\nimport numpy as np\n\ndef task_func(shape=(3, 3), low=1, high=10, seed=None):\n    if high <= low:\n        raise ValueError(\"high must be greater than low\")\n    np.random.seed(seed)\n    matrix = np.random.randint(low, high, shape)\n    pairs = list(combinations(matrix.flatten(), 2))\n    sum_of_products = sum(reduce(lambda x, y: x * y, pair) for pair in pairs)\n    return sum_of_products, matrix\n```"}
{"task_id": "BigCodeBench/857", "solution": "import warnings\nimport os\nimport glob\nimport shutil\nimport time\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    transferred_files = []\n    for extension in EXTENSIONS:\n        source_files = glob.glob(os.path.join(SOURCE_DIR, f\"*.{extension}\"))\n        for source_file in source_files:\n            try:\n                shutil.move(source_file, DEST_DIR)\n                transferred_files.append(os.path.basename(source_file))\n            except Exception as e:\n                warnings.warn(f\"Could not transfer file {source_file} due to {str(e)}\")\n    return transferred_files", "raw_solution": "import warnings\nimport os\nimport glob\nimport shutil\nimport time\n\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    transferred_files = []\n    for extension in EXTENSIONS:\n        source_files = glob.glob(os.path.join(SOURCE_DIR, f\"*.{extension}\"))\n        for source_file in source_files:\n            try:\n                shutil.move(source_file, DEST_DIR)\n                transferred_files.append(os.path.basename(source_file))\n            except Exception as e:\n                warnings.warn(f\"Could not transfer file {source_file} due to {str(e)}\")\n    return transferred_files\n```"}
{"task_id": "BigCodeBench/858", "solution": "import string\nimport random\nfrom collections import Counter\ndef task_func(n, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    letters = [random.choice(string.ascii_lowercase) for _ in range(n)]\n    return Counter(letters)", "raw_solution": "import string\nimport random\nfrom collections import Counter\n\ndef task_func(n, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    letters = [random.choice(string.ascii_lowercase) for _ in range(n)]\n    return Counter(letters)\n```"}
{"task_id": "BigCodeBench/859", "solution": "import warnings\nimport sklearn.model_selection as model_selection\nimport sklearn.svm as svm\nimport sklearn.datasets as datasets\nimport sklearn.metrics as metrics\ndef task_func():\n    iris = datasets.load_iris()\n    X = iris.data\n    y = iris.target\n\n    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n\n    clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n\n    if accuracy < 0.9:\n        warnings.warn(\"Accuracy is less than 0.9\", UserWarning, stacklevel=2)\n        warning_msg = \"Accuracy is less than 0.9\"\n    else:\n        warning_msg = None\n\n    return accuracy, warning_msg", "raw_solution": "import warnings\nimport sklearn.model_selection as model_selection\nimport sklearn.svm as svm\nimport sklearn.datasets as datasets\nimport sklearn.metrics as metrics\n\ndef task_func():\n    iris = datasets.load_iris()\n    X = iris.data\n    y = iris.target\n\n    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n\n    clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n\n    if accuracy < 0.9:\n        warnings.warn(\"Accuracy is less than 0.9\", UserWarning, stacklevel=2)\n        warning_msg = \"Accuracy is less than 0.9\"\n    else:\n        warning_msg = None\n\n    return accuracy, warning_msg\n```"}
{"task_id": "BigCodeBench/860", "solution": "import re\nimport random\nimport string\ndef task_func(n, pattern, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=n))\n    matches = re.findall(pattern, random_string)\n    return matches", "raw_solution": "import re\nimport random\nimport string\n\ndef task_func(n, pattern, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=n))\n    matches = re.findall(pattern, random_string)\n    return matches\n```"}
{"task_id": "BigCodeBench/861", "solution": "from collections import Counter\nfrom random import choice, seed\nPOSSIBLE_ITEMS = ['apple', 'banana', 'cherry', 'date', 'elderberry']\ndef task_func(list_of_lists):\n    baskets = []\n    for sublist in list_of_lists:\n        basket = Counter()\n        for _ in range(len(sublist)):\n            item = choice(POSSIBLE_ITEMS)\n            basket[item] += 1\n        baskets.append(basket)\n    return baskets", "raw_solution": "from collections import Counter\nfrom random import choice, seed\n# Constants\nPOSSIBLE_ITEMS = ['apple', 'banana', 'cherry', 'date', 'elderberry']\ndef task_func(list_of_lists):\n    baskets = []\n    for sublist in list_of_lists:\n        basket = Counter()\n        for _ in range(len(sublist)):\n            item = choice(POSSIBLE_ITEMS)\n            basket[item] += 1\n        baskets.append(basket)\n    return baskets\n```"}
{"task_id": "BigCodeBench/862", "solution": "import random\nimport string\nfrom collections import defaultdict\ndef task_func(n, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    alphabet = list(string.ascii_lowercase)\n    result = defaultdict(list)\n    for _ in range(n):\n        letter = random.choice(alphabet)\n        result[letter].append(letter)\n    return result", "raw_solution": "import random\nimport string\nfrom collections import defaultdict\n\ndef task_func(n, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    alphabet = list(string.ascii_lowercase)\n    result = defaultdict(list)\n    for _ in range(n):\n        letter = random.choice(alphabet)\n        result[letter].append(letter)\n    return result\n```"}
{"task_id": "BigCodeBench/863", "solution": "import numpy as np\nimport math\nPOSSIBLE_NUMBERS = np.arange(1, 11)\ndef task_func(list_of_lists):\n    sums = []\n    for lst in list_of_lists:\n        if len(lst) > len(POSSIBLE_NUMBERS):\n            lst = lst[:len(POSSIBLE_NUMBERS)]\n        sum_of_squares = sum([num**2 for num in lst])\n        sums.append(sum_of_squares)\n    return sums", "raw_solution": "import numpy as np\nimport math\n# Constants\nPOSSIBLE_NUMBERS = np.arange(1, 11)\ndef task_func(list_of_lists):\n    sums = []\n    for lst in list_of_lists:\n        if len(lst) > len(POSSIBLE_NUMBERS):\n            lst = lst[:len(POSSIBLE_NUMBERS)]\n        sum_of_squares = sum([num**2 for num in lst])\n        sums.append(sum_of_squares)\n    return sums\n```"}
{"task_id": "BigCodeBench/864", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(fruit_data):\n    if not fruit_data:\n        return pd.DataFrame(columns=['Total Count', 'Average Count'])\n    df = pd.DataFrame(fruit_data, columns=['Fruit', 'Count'])\n    df = df.groupby('Fruit').sum()\n    df['Average Count'] = df['Count'] / df.shape[0]\n    df.rename(columns={'Count': 'Total Count'}, inplace=True)\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\ndef task_func(fruit_data):\n    if not fruit_data:\n        return pd.DataFrame(columns=['Total Count', 'Average Count'])\n    df = pd.DataFrame(fruit_data, columns=['Fruit', 'Count'])\n    df = df.groupby('Fruit').sum()\n    df['Average Count'] = df['Count'] / df.shape[0]\n    df.rename(columns={'Count': 'Total Count'}, inplace=True)\n    return df\n```"}
{"task_id": "BigCodeBench/865", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data):\n    df = pd.DataFrame(data, columns=['Item', 'Count', 'Weight'])\n    df['Normalized Count'] = zscore(df['Count'])\n    df['Normalized Weight'] = MinMaxScaler().fit_transform(df[['Weight']])\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=['Item', 'Count', 'Weight'])\n    df['Normalized Count'] = zscore(df['Count'])\n    df['Normalized Weight'] = MinMaxScaler().fit_transform(df[['Weight']])\n    return df\n```"}
{"task_id": "BigCodeBench/866", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\ndef task_func(data, n_clusters=2, random_state=0):\n    # Extract the coordinates from the data\n    coordinates = [(x[1], x[2]) for x in data]\n    coordinates = np.array(coordinates)\n\n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(coordinates)\n\n    # Return the cluster labels\n    return kmeans.labels_", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\n\ndef task_func(data, n_clusters=2, random_state=0):\n    # Extract the coordinates from the data\n    coordinates = [(x[1], x[2]) for x in data]\n    coordinates = np.array(coordinates)\n\n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(coordinates)\n\n    # Return the cluster labels\n    return kmeans.labels_\n```"}
{"task_id": "BigCodeBench/867", "solution": "import re\nimport string\ndef task_func(text1, text2):\n    # Define the punctuation to be removed\n    punctuation = string.punctuation\n\n    # Remove punctuation from the texts\n    cleaned_text1 = re.sub(r'[{}]'.format(re.escape(punctuation)), '', text1)\n    cleaned_text2 = re.sub(r'[{}]'.format(re.escape(punctuation)), '', text2)\n\n    return (cleaned_text1, cleaned_text2)", "raw_solution": "import re\nimport string\n\ndef task_func(text1, text2):\n    # Define the punctuation to be removed\n    punctuation = string.punctuation\n\n    # Remove punctuation from the texts\n    cleaned_text1 = re.sub(r'[{}]'.format(re.escape(punctuation)), '', text1)\n    cleaned_text2 = re.sub(r'[{}]'.format(re.escape(punctuation)), '', text2)\n\n    return (cleaned_text1, cleaned_text2)\n```"}
{"task_id": "BigCodeBench/868", "solution": "from itertools import cycle\nfrom random import choice, seed\ndef task_func(n_colors, colors=['Red', 'Green', 'Blue', 'Yellow', 'Purple'], rng_seed=None):\n    if n_colors <= 0:\n        return []\n    if rng_seed is not None:\n        seed(rng_seed)\n    color_pattern = []\n    color_cycle = cycle(colors)\n    for i in range(n_colors):\n        if i % 2 == 0:\n            color_pattern.append(next(color_cycle))\n        else:\n            color_pattern.append(choice(colors))\n    return color_pattern", "raw_solution": "from itertools import cycle\nfrom random import choice, seed\n\ndef task_func(n_colors, colors=['Red', 'Green', 'Blue', 'Yellow', 'Purple'], rng_seed=None):\n    if n_colors <= 0:\n        return []\n    if rng_seed is not None:\n        seed(rng_seed)\n    color_pattern = []\n    color_cycle = cycle(colors)\n    for i in range(n_colors):\n        if i % 2 == 0:\n            color_pattern.append(next(color_cycle))\n        else:\n            color_pattern.append(choice(colors))\n    return color_pattern\n```"}
{"task_id": "BigCodeBench/869", "solution": "import pandas as pd\nfrom itertools import cycle\nfrom random import randint, seed\ndef task_func(\n    n_grades,\n    students=['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    grade_range=range(1, 11),\n    rng_seed=None\n):\n    if not students:\n        raise ValueError(\"List of students cannot be empty\")\n    if rng_seed is not None:\n        seed(rng_seed)\n    student_cycle = cycle(students)\n    grade_report = []\n    for _ in range(n_grades):\n        student = next(student_cycle)\n        grade = randint(grade_range.start, grade_range.stop - 1)\n        grade_report.append({'Student': student, 'Grade': grade})\n    return pd.DataFrame(grade_report)", "raw_solution": "import pandas as pd\nfrom itertools import cycle\nfrom random import randint, seed\n\ndef task_func(\n    n_grades,\n    students=['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    grade_range=range(1, 11),\n    rng_seed=None\n):\n    if not students:\n        raise ValueError(\"List of students cannot be empty\")\n    if rng_seed is not None:\n        seed(rng_seed)\n    student_cycle = cycle(students)\n    grade_report = []\n    for _ in range(n_grades):\n        student = next(student_cycle)\n        grade = randint(grade_range.start, grade_range.stop - 1)\n        grade_report.append({'Student': student, 'Grade': grade})\n    return pd.DataFrame(grade_report)\n```"}
{"task_id": "BigCodeBench/870", "solution": "import pandas as pd\nimport numpy as np\nimport itertools\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    if not data_list:\n        return pd.DataFrame(columns=['Mean Value'])\n\n    # Extract numerical values from tuples\n    num_values = [tuple(filter(lambda x: isinstance(x, (int, float)), t)) for t in data_list]\n\n    # Calculate mean for each position\n    means = [np.mean(list(itertools.chain(*[t[i] for t in num_values if i < len(t)]))) for i in range(max(map(len, num_values)))]\n\n    # Create DataFrame\n    df = pd.DataFrame(means, columns=['Mean Value'], index=['Position ' + str(i) for i in range(len(means))])\n\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport itertools\n\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    if not data_list:\n        return pd.DataFrame(columns=['Mean Value'])\n\n    # Extract numerical values from tuples\n    num_values = [tuple(filter(lambda x: isinstance(x, (int, float)), t)) for t in data_list]\n\n    # Calculate mean for each position\n    means = [np.mean(list(itertools.chain(*[t[i] for t in num_values if i < len(t)]))) for i in range(max(map(len, num_values)))]\n\n    # Create DataFrame\n    df = pd.DataFrame(means, columns=['Mean Value'], index=['Position ' + str(i) for i in range(len(means))])\n\n    return df\n```"}
{"task_id": "BigCodeBench/871", "solution": "import numpy as np\nimport itertools\ndef task_func(data_list, file_name):\n    if not data_list:\n        with open(file_name, 'w') as f:\n            f.write('')\n        return []\n\n    means = []\n    with open(file_name, 'w') as f:\n        for i, data in enumerate(data_list, start=1):\n            values = [x for x in data[1:] if isinstance(x, (int, float))]\n            if not values:\n                means.append(np.nan)\n                f.write(f'Position {i}: {np.nan}\\n')\n            else:\n                mean = np.mean(values)\n                means.append(mean)\n                f.write(f'Position {i}: {mean}\\n')\n    return means", "raw_solution": "import numpy as np\nimport itertools\n\ndef task_func(data_list, file_name):\n    if not data_list:\n        with open(file_name, 'w') as f:\n            f.write('')\n        return []\n\n    means = []\n    with open(file_name, 'w') as f:\n        for i, data in enumerate(data_list, start=1):\n            values = [x for x in data[1:] if isinstance(x, (int, float))]\n            if not values:\n                means.append(np.nan)\n                f.write(f'Position {i}: {np.nan}\\n')\n            else:\n                mean = np.mean(values)\n                means.append(mean)\n                f.write(f'Position {i}: {mean}\\n')\n    return means\n```"}
{"task_id": "BigCodeBench/872", "solution": "import numpy as np\nimport itertools\ndef task_func(data_list):\n    if not data_list:\n        return []\n    unzipped = list(itertools.zip_longest(*data_list, fillvalue=0))\n    numeric_means = []\n    for i in range(len(unzipped)):\n        numeric_values = [float(x) for x in unzipped[i] if x.replace('.','').isdigit()]\n        if numeric_values:\n            numeric_means.append(np.mean(numeric_values))\n        else:\n            numeric_means.append(np.nan)\n    return numeric_means", "raw_solution": "import numpy as np\nimport itertools\n\ndef task_func(data_list):\n    if not data_list:\n        return []\n    unzipped = list(itertools.zip_longest(*data_list, fillvalue=0))\n    numeric_means = []\n    for i in range(len(unzipped)):\n        numeric_values = [float(x) for x in unzipped[i] if x.replace('.','').isdigit()]\n        if numeric_values:\n            numeric_means.append(np.mean(numeric_values))\n        else:\n            numeric_means.append(np.nan)\n    return numeric_means\n```"}
{"task_id": "BigCodeBench/873", "solution": "import csv\nimport os\ndef task_func(data, file_path, headers):\n    if file_path is None:\n        raise ValueError(\"file_path cannot be None\")\n    with open(file_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(headers)\n        for row in data:\n            writer.writerow(row)\n    return os.path.abspath(file_path)", "raw_solution": "import csv\nimport os\n\ndef task_func(data, file_path, headers):\n    if file_path is None:\n        raise ValueError(\"file_path cannot be None\")\n    with open(file_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(headers)\n        for row in data:\n            writer.writerow(row)\n    return os.path.abspath(file_path)\n```"}
{"task_id": "BigCodeBench/874", "solution": "from itertools import zip_longest\nfrom scipy.spatial import distance\ndef task_func(points):\n    if len(points) < 2:\n        return []\n    result = []\n    for i in range(len(points) - 1):\n        point1 = points[i]\n        point2 = points[i + 1]\n        if len(point1) == 1:\n            point1 = (point1[0], point1[0])\n        if len(point2) == 1:\n            point2 = (point2[0], point2[0])\n        result.append(distance.euclidean(point1, point2))\n    return result", "raw_solution": "from itertools import zip_longest\nfrom scipy.spatial import distance\n\ndef task_func(points):\n    if len(points) < 2:\n        return []\n    result = []\n    for i in range(len(points) - 1):\n        point1 = points[i]\n        point2 = points[i + 1]\n        if len(point1) == 1:\n            point1 = (point1[0], point1[0])\n        if len(point2) == 1:\n            point2 = (point2[0], point2[0])\n        result.append(distance.euclidean(point1, point2))\n    return result\n```"}
{"task_id": "BigCodeBench/875", "solution": "import pandas as pd\nimport random\ndef task_func(data, columns=['Name', 'Age', 'Occupation'], fill_missing=False, num_range=(0, 100), seed=None):\n    if seed is not None:\n        random.seed(seed)\n    df = pd.DataFrame(data, columns=columns)\n    if fill_missing:\n        for col in columns:\n            if pd.api.types.is_numeric_dtype(df[col]):\n                df[col] = df[col].fillna(random.uniform(num_range[0], num_range[1]))\n            else:\n                df[col] = df[col].fillna(None)\n    return df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(data, columns=['Name', 'Age', 'Occupation'], fill_missing=False, num_range=(0, 100), seed=None):\n    if seed is not None:\n        random.seed(seed)\n    df = pd.DataFrame(data, columns=columns)\n    if fill_missing:\n        for col in columns:\n            if pd.api.types.is_numeric_dtype(df[col]):\n                df[col] = df[col].fillna(random.uniform(num_range[0], num_range[1]))\n            else:\n                df[col] = df[col].fillna(None)\n    return df\n```"}
{"task_id": "BigCodeBench/876", "solution": "import collections\nimport operator\nimport os\nimport shutil\ndef task_func(data_dict, source_directory, backup_directory):\n    data_dict['a'] = 1\n    sorted_dict = sorted(data_dict.items(), key=operator.itemgetter(1), reverse=True)\n    value_frequencies = collections.Counter(data_dict.values()).most_common()\n    backup_status = False\n    if os.path.exists(source_directory):\n        if not os.path.exists(backup_directory):\n            os.makedirs(backup_directory)\n        for file_name in os.listdir(source_directory):\n            shutil.copy(os.path.join(source_directory, file_name), backup_directory)\n        backup_status = True\n    return data_dict, value_frequencies, backup_status", "raw_solution": "import collections\nimport operator\nimport os\nimport shutil\n\ndef task_func(data_dict, source_directory, backup_directory):\n    data_dict['a'] = 1\n    sorted_dict = sorted(data_dict.items(), key=operator.itemgetter(1), reverse=True)\n    value_frequencies = collections.Counter(data_dict.values()).most_common()\n    backup_status = False\n    if os.path.exists(source_directory):\n        if not os.path.exists(backup_directory):\n            os.makedirs(backup_directory)\n        for file_name in os.listdir(source_directory):\n            shutil.copy(os.path.join(source_directory, file_name), backup_directory)\n        backup_status = True\n    return data_dict, value_frequencies, backup_status"}
{"task_id": "BigCodeBench/877", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\ndef task_func(data, n_components=2):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data must be a pandas DataFrame\")\n    if not data.select_dtypes(include=[np.number]).columns.all():\n        raise ValueError(\"Input data must contain only numeric data\")\n    if n_components > data.shape[1]:\n        raise ValueError(\"n_components must be less than or equal to the number of columns in the data\")\n    if data.empty:\n        raise ValueError(\"Input data cannot be empty\")\n\n    scaler = StandardScaler()\n    data_scaled = scaler.fit_transform(data)\n\n    pca = PCA(n_components=n_components)\n    data_pca = pca.fit_transform(data_scaled)\n\n    return pd.DataFrame(data_pca)", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data must be a pandas DataFrame\")\n    if not data.select_dtypes(include=[np.number]).columns.all():\n        raise ValueError(\"Input data must contain only numeric data\")\n    if n_components > data.shape[1]:\n        raise ValueError(\"n_components must be less than or equal to the number of columns in the data\")\n    if data.empty:\n        raise ValueError(\"Input data cannot be empty\")\n\n    scaler = StandardScaler()\n    data_scaled = scaler.fit_transform(data)\n\n    pca = PCA(n_components=n_components)\n    data_pca = pca.fit_transform(data_scaled)\n\n    return pd.DataFrame(data_pca)"}
{"task_id": "BigCodeBench/878", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\ndef task_func(data, target, test_size=0.2, random_state=None):\n    if not data:\n        raise ValueError(\"Input DataFrame is empty\")\n    if target not in data.columns:\n        raise ValueError(f\"Target column '{target}' not found in DataFrame\")\n\n    df = pd.DataFrame(data)\n    X = df.drop(columns=[target])\n    y = df[target]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    model = RandomForestRegressor()\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n\n    return mse, model, df", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\ndef task_func(data, target, test_size=0.2, random_state=None):\n    if not data:\n        raise ValueError(\"Input DataFrame is empty\")\n    if target not in data.columns:\n        raise ValueError(f\"Target column '{target}' not found in DataFrame\")\n\n    df = pd.DataFrame(data)\n    X = df.drop(columns=[target])\n    y = df[target]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    model = RandomForestRegressor()\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n\n    return mse, model, df\n```"}
{"task_id": "BigCodeBench/879", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\ndef task_func(data, col1, col2):\n    if data.empty:\n        raise ValueError(\"Data is empty\")\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError(\"One or both of the columns are not in the data\")\n    if data[col1].nunique() < 2 or data[col2].nunique() < 2:\n        raise ValueError(\"One or both of the columns do not have multiple categories\")\n    if data[col1].value_counts().min() < 5 or data[col2].value_counts().min() < 5:\n        raise ValueError(\"Some categories have less than 5 observations\")\n    if not np.issubdtype(data[col1].dtype, np.str) or not np.issubdtype(data[col2].dtype, np.str):\n        raise TypeError(\"One or both of the columns contain non-categorical data\")\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    return p", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\n\ndef task_func(data, col1, col2):\n    if data.empty:\n        raise ValueError(\"Data is empty\")\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError(\"One or both of the columns are not in the data\")\n    if data[col1].nunique() < 2 or data[col2].nunique() < 2:\n        raise ValueError(\"One or both of the columns do not have multiple categories\")\n    if data[col1].value_counts().min() < 5 or data[col2].value_counts().min() < 5:\n        raise ValueError(\"Some categories have less than 5 observations\")\n    if not np.issubdtype(data[col1].dtype, np.str) or not np.issubdtype(data[col2].dtype, np.str):\n        raise TypeError(\"One or both of the columns contain non-categorical data\")\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    return p"}
{"task_id": "BigCodeBench/880", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\ndef task_func(data, n_clusters=3, seed=None):\n    if not all(data.dtypes == 'int64'):\n        raise ValueError(\"DataFrame should only contain numeric entries\")\n    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=seed)\n    labels = kmeans.fit_predict(data)\n    return labels, kmeans", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\n\ndef task_func(data, n_clusters=3, seed=None):\n    if not all(data.dtypes == 'int64'):\n        raise ValueError(\"DataFrame should only contain numeric entries\")\n    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=seed)\n    labels = kmeans.fit_predict(data)\n    return labels, kmeans\n```"}
{"task_id": "BigCodeBench/881", "solution": "import pandas as pd\nimport re\nimport random\ndef task_func(csv_file, column_name='data', pattern='\\d+[xX]', sample_size=None, seed=42):\n    random.seed(seed)\n    df = pd.read_csv(csv_file)\n    df = df[df[column_name].str.contains(pattern)]\n    if sample_size is not None:\n        df = df.sample(n=sample_size)\n    return df", "raw_solution": "import pandas as pd\nimport re\nimport random\n\ndef task_func(csv_file, column_name='data', pattern='\\d+[xX]', sample_size=None, seed=42):\n    random.seed(seed)\n    df = pd.read_csv(csv_file)\n    df = df[df[column_name].str.contains(pattern)]\n    if sample_size is not None:\n        df = df.sample(n=sample_size)\n    return df\n```"}
{"task_id": "BigCodeBench/882", "solution": "import sqlite3\nimport pandas as pd\nimport os\nimport re\ndef task_func(db_file, table_name, column_name, pattern='\\d+[xX]'):\n    if not os.path.exists(db_file):\n        raise ValueError(\"The specified database file does not exist.\")\n\n    conn = sqlite3.connect(db_file)\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    conn.close()\n\n    df = df[df[column_name].str.contains(pattern)]\n\n    return df", "raw_solution": "import sqlite3\nimport pandas as pd\nimport os\nimport re\n\ndef task_func(db_file, table_name, column_name, pattern='\\d+[xX]'):\n    if not os.path.exists(db_file):\n        raise ValueError(\"The specified database file does not exist.\")\n\n    conn = sqlite3.connect(db_file)\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    conn.close()\n\n    df = df[df[column_name].str.contains(pattern)]\n\n    return df\n```"}
{"task_id": "BigCodeBench/883", "solution": "import pandas as pd\nfrom statsmodels.tsa.stattools import adfuller\ndef task_func(df: pd.DataFrame, column_a: str, column_b: str, column_c: str) -> bool:\n    df = df[df[column_b] > 50]\n    df = df[df[column_c] == 900]\n    if df[column_a].empty or df[column_a].nunique() == 1:\n        return True\n    result = adfuller(df[column_a])\n    return result[1] < 0.05", "raw_solution": "import pandas as pd\nfrom statsmodels.tsa.stattools import adfuller\n\ndef task_func(df: pd.DataFrame, column_a: str, column_b: str, column_c: str) -> bool:\n    df = df[df[column_b] > 50]\n    df = df[df[column_c] == 900]\n    if df[column_a].empty or df[column_a].nunique() == 1:\n        return True\n    result = adfuller(df[column_a])\n    return result[1] < 0.05\n```"}
{"task_id": "BigCodeBench/884", "solution": "import pandas as pd\nfrom scipy.stats import chi2_contingency\ndef task_func(df, columns=['A', 'B', 'C'], larger=50, equal=900):\n    if len(columns) != 3:\n        raise ValueError(\"The number of specified columns must be 3.\")\n    if not all(col in df.columns for col in columns):\n        raise ValueError(\"The specified columns must be contained in df.\")\n    if df.shape[0] < 3:\n        raise ValueError(\"Insufficient data for the test.\")\n\n    filtered_df = df[(df[columns[1]] > larger) & (df[columns[2]] == equal)]\n\n    if filtered_df.shape[0] < 3:\n        raise ValueError(\"Insufficient data for the test.\")\n\n    contingency_table = pd.crosstab(filtered_df[columns[0]], filtered_df[columns[1]])\n    _, p_value, _, _ = chi2_contingency(contingency_table)\n\n    return p_value", "raw_solution": "import pandas as pd\nfrom scipy.stats import chi2_contingency\n\ndef task_func(df, columns=['A', 'B', 'C'], larger=50, equal=900):\n    if len(columns) != 3:\n        raise ValueError(\"The number of specified columns must be 3.\")\n    if not all(col in df.columns for col in columns):\n        raise ValueError(\"The specified columns must be contained in df.\")\n    if df.shape[0] < 3:\n        raise ValueError(\"Insufficient data for the test.\")\n\n    filtered_df = df[(df[columns[1]] > larger) & (df[columns[2]] == equal)]\n\n    if filtered_df.shape[0] < 3:\n        raise ValueError(\"Insufficient data for the test.\")\n\n    contingency_table = pd.crosstab(filtered_df[columns[0]], filtered_df[columns[1]])\n    _, p_value, _, _ = chi2_contingency(contingency_table)\n\n    return p_value"}
{"task_id": "BigCodeBench/885", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, col_a='A', col_b='B', col_c='C', seed=None):\n    if df.empty or df.select_dtypes(include=['number']).empty or col_a not in df.columns or col_b not in df.columns or col_c not in df.columns:\n        return None\n    df = df[df[col_b] > 50]\n    df = df[df[col_c] == 900]\n    if df.empty:\n        return None\n    X = df[col_a].values.reshape(-1, 1)\n    y = df[col_b].values.reshape(-1, 1)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    return predictions, model", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, col_a='A', col_b='B', col_c='C', seed=None):\n    if df.empty or df.select_dtypes(include=['number']).empty or col_a not in df.columns or col_b not in df.columns or col_c not in df.columns:\n        return None\n    df = df[df[col_b] > 50]\n    df = df[df[col_c] == 900]\n    if df.empty:\n        return None\n    X = df[col_a].values.reshape(-1, 1)\n    y = df[col_b].values.reshape(-1, 1)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    return predictions, model\n```"}
{"task_id": "BigCodeBench/886", "solution": "import pandas as pd\nfrom collections import Counter\ndef task_func(data):\n    if not all(key in data[0] for key in ['Name', 'Age', 'Score']):\n        raise ValueError(\"Invalid data format. Expected keys: 'Name', 'Age', 'Score'\")\n\n    df = pd.DataFrame(data)\n    df = df.sort_values(by=['Name', 'Age'])\n\n    avg_scores = df.groupby('Name')['Score'].mean()\n\n    if df['Age'].empty:\n        most_common_age = None\n    else:\n        age_counts = Counter(df['Age'])\n        most_common_age = age_counts.most_common(1)[0][0]\n\n    return df, avg_scores, most_common_age", "raw_solution": "import pandas as pd\nfrom collections import Counter\n\ndef task_func(data):\n    if not all(key in data[0] for key in ['Name', 'Age', 'Score']):\n        raise ValueError(\"Invalid data format. Expected keys: 'Name', 'Age', 'Score'\")\n\n    df = pd.DataFrame(data)\n    df = df.sort_values(by=['Name', 'Age'])\n\n    avg_scores = df.groupby('Name')['Score'].mean()\n\n    if df['Age'].empty:\n        most_common_age = None\n    else:\n        age_counts = Counter(df['Age'])\n        most_common_age = age_counts.most_common(1)[0][0]\n\n    return df, avg_scores, most_common_age\n```"}
{"task_id": "BigCodeBench/887", "solution": "import pandas as pd\nimport numpy as np\nimport itertools\ndef task_func(T1, row_num=50, seed=None):\n    np.random.seed(seed)\n    T1 = list(itertools.chain(*T1))\n    T1 = [int(i) for i in T1]\n    df = pd.DataFrame(np.random.randint(0,100,size=(row_num, sum(T1))))\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport itertools\n\ndef task_func(T1, row_num=50, seed=None):\n    np.random.seed(seed)\n    T1 = list(itertools.chain(*T1))\n    T1 = [int(i) for i in T1]\n    df = pd.DataFrame(np.random.randint(0,100,size=(row_num, sum(T1))))\n    return df\n```"}
{"task_id": "BigCodeBench/888", "solution": "import pandas as pd\nimport os\ndef task_func(data_dir: str, csv_files: list) -> pd.DataFrame:\n    if not csv_files:\n        return pd.DataFrame()\n    dfs = []\n    for file in csv_files:\n        file_path = os.path.join(data_dir, file)\n        df = pd.read_csv(file_path)\n        dfs.append(df)\n    return pd.concat(dfs, ignore_index=True)", "raw_solution": "import pandas as pd\nimport os\n\ndef task_func(data_dir: str, csv_files: list) -> pd.DataFrame:\n    if not csv_files:\n        return pd.DataFrame()\n    dfs = []\n    for file in csv_files:\n        file_path = os.path.join(data_dir, file)\n        df = pd.read_csv(file_path)\n        dfs.append(df)\n    return pd.concat(dfs, ignore_index=True)\n```"}
{"task_id": "BigCodeBench/889", "solution": "import os\nimport pandas as pd\nimport numpy as np\ndef task_func(data_dir: str, csv_file: str) -> pd.DataFrame:\n    if not os.path.exists(os.path.join(data_dir, csv_file)):\n        raise FileNotFoundError(f\"File {csv_file} not found in directory {data_dir}\")\n    df = pd.read_csv(os.path.join(data_dir, csv_file))\n    for col in df.select_dtypes(include=[np.number]).columns:\n        df[col] = df[col].fillna(df[col].mean())\n    return df", "raw_solution": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(data_dir: str, csv_file: str) -> pd.DataFrame:\n    if not os.path.exists(os.path.join(data_dir, csv_file)):\n        raise FileNotFoundError(f\"File {csv_file} not found in directory {data_dir}\")\n    df = pd.read_csv(os.path.join(data_dir, csv_file))\n    for col in df.select_dtypes(include=[np.number]).columns:\n        df[col] = df[col].fillna(df[col].mean())\n    return df\n```"}
{"task_id": "BigCodeBench/890", "solution": "import os\nimport random\nimport pandas as pd\ndef task_func(data_dir,\n          csv_files=['file1.csv', 'file2.csv', 'file3.csv'],\n          seed=None):\n    if seed is not None:\n        random.seed(seed)\n    if not csv_files:\n        return None, pd.DataFrame()\n    csv_file = random.choice(csv_files)\n    file_path = os.path.join(data_dir, csv_file)\n    if not os.path.exists(file_path):\n        return csv_file, pd.DataFrame()\n    df = pd.read_csv(file_path)\n    if df.empty:\n        return csv_file, pd.DataFrame()\n    selected_rows = df.sample(n=1)\n    return csv_file, selected_rows", "raw_solution": "import os\nimport random\nimport pandas as pd\n\ndef task_func(data_dir,\n          csv_files=['file1.csv', 'file2.csv', 'file3.csv'],\n          seed=None):\n    if seed is not None:\n        random.seed(seed)\n    if not csv_files:\n        return None, pd.DataFrame()\n    csv_file = random.choice(csv_files)\n    file_path = os.path.join(data_dir, csv_file)\n    if not os.path.exists(file_path):\n        return csv_file, pd.DataFrame()\n    df = pd.read_csv(file_path)\n    if df.empty:\n        return csv_file, pd.DataFrame()\n    selected_rows = df.sample(n=1)\n    return csv_file, selected_rows\n```"}
{"task_id": "BigCodeBench/891", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\ndef task_func(csv_file_path, attribute, test_size=0.2, random_state=42):\n    # Read the CSV file into a DataFrame\n    df = pd.read_csv(csv_file_path)\n\n    # Separate the data into features and target\n    X = df.drop(attribute, axis=1)\n    y = df[attribute]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    # Train the linear regression model\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    # Predict the values for the test set\n    predictions = model.predict(X_test)\n\n    return model, predictions", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(csv_file_path, attribute, test_size=0.2, random_state=42):\n    # Read the CSV file into a DataFrame\n    df = pd.read_csv(csv_file_path)\n\n    # Separate the data into features and target\n    X = df.drop(attribute, axis=1)\n    y = df[attribute]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    # Train the linear regression model\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    # Predict the values for the test set\n    predictions = model.predict(X_test)\n\n    return model, predictions\n```"}
{"task_id": "BigCodeBench/892", "solution": "import random\nfrom collections import Counter\ndef task_func(strings: list) -> dict:\n    pattern = \"abc\"\n    pattern_counts = Counter()\n    for string in strings:\n        pattern_counts += Counter(string[i:i+len(pattern)] for i in range(len(string)))\n    return pattern_counts", "raw_solution": "import random\nfrom collections import Counter\ndef task_func(strings: list) -> dict:\n    pattern = \"abc\"\n    pattern_counts = Counter()\n    for string in strings:\n        pattern_counts += Counter(string[i:i+len(pattern)] for i in range(len(string)))\n    return pattern_counts\n```"}
{"task_id": "BigCodeBench/893", "solution": "import re\nfrom datetime import datetime\ndef task_func(logs: list):\n    error_times = []\n    for log in logs:\n        if \"error\" in log:\n            time_str = re.search(r'\\d{2}:\\d{2}:\\d{2}', log).group()\n            time_obj = datetime.strptime(time_str, '%H:%M:%S')\n            error_times.append(time_obj)\n    if not error_times:\n        return None, None\n    avg_time = sum(error_times, datetime.min) / len(error_times)\n    return [time.strftime('%H:%M:%S') for time in error_times], avg_time.strftime('%H:%M:%S')", "raw_solution": "import re\nfrom datetime import datetime\n\ndef task_func(logs: list):\n    error_times = []\n    for log in logs:\n        if \"error\" in log:\n            time_str = re.search(r'\\d{2}:\\d{2}:\\d{2}', log).group()\n            time_obj = datetime.strptime(time_str, '%H:%M:%S')\n            error_times.append(time_obj)\n    if not error_times:\n        return None, None\n    avg_time = sum(error_times, datetime.min) / len(error_times)\n    return [time.strftime('%H:%M:%S') for time in error_times], avg_time.strftime('%H:%M:%S')"}
{"task_id": "BigCodeBench/894", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nARRAY_SIZE = 10000\ndef task_func():\n    # Generate random integers\n    array = np.random.randint(1, 101, ARRAY_SIZE)\n\n    # Calculate mean and standard deviation\n    mean = np.mean(array)\n    std_dev = np.std(array)\n\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(array, bins=100, color='blue', edgecolor='black')\n    ax.axvline(mean, color='red', linestyle='dashed', linewidth=1)\n    ax.axvline(mean + std_dev, color='purple', linestyle='dashed', linewidth=1)\n    ax.axvline(mean - std_dev, color='purple', linestyle='dashed', linewidth=1)\n    ax.set_title('Histogram of Random Integers')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return (array, mean, std_dev, ax)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nARRAY_SIZE = 10000\n\ndef task_func():\n    # Generate random integers\n    array = np.random.randint(1, 101, ARRAY_SIZE)\n\n    # Calculate mean and standard deviation\n    mean = np.mean(array)\n    std_dev = np.std(array)\n\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(array, bins=100, color='blue', edgecolor='black')\n    ax.axvline(mean, color='red', linestyle='dashed', linewidth=1)\n    ax.axvline(mean + std_dev, color='purple', linestyle='dashed', linewidth=1)\n    ax.axvline(mean - std_dev, color='purple', linestyle='dashed', linewidth=1)\n    ax.set_title('Histogram of Random Integers')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return (array, mean, std_dev, ax)\n```"}
{"task_id": "BigCodeBench/895", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nARRAY_SIZE = 10000\ndef task_func():\n    # Generate random integers\n    random_array = np.random.randint(1, 101, ARRAY_SIZE)\n\n    # Calculate mean and standard deviation\n    mean = np.mean(random_array)\n    std_dev = np.std(random_array)\n\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(random_array, bins=100, color='blue', edgecolor='black')\n    ax.axvline(mean, color='red', linestyle='dashed', linewidth=1)\n    ax.axvline(mean + std_dev, color='purple', linestyle='dashed', linewidth=1)\n    ax.axvline(mean - std_dev, color='purple', linestyle='dashed', linewidth=1)\n    ax.set_title('Histogram of Random Values')\n    ax.set_xlabel('Val')\n    ax.set_ylabel('Freq')\n\n    return (random_array, mean, std_dev, ax)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nARRAY_SIZE = 10000\n\ndef task_func():\n    # Generate random integers\n    random_array = np.random.randint(1, 101, ARRAY_SIZE)\n\n    # Calculate mean and standard deviation\n    mean = np.mean(random_array)\n    std_dev = np.std(random_array)\n\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(random_array, bins=100, color='blue', edgecolor='black')\n    ax.axvline(mean, color='red', linestyle='dashed', linewidth=1)\n    ax.axvline(mean + std_dev, color='purple', linestyle='dashed', linewidth=1)\n    ax.axvline(mean - std_dev, color='purple', linestyle='dashed', linewidth=1)\n    ax.set_title('Histogram of Random Values')\n    ax.set_xlabel('Val')\n    ax.set_ylabel('Freq')\n\n    return (random_array, mean, std_dev, ax)\n```"}
{"task_id": "BigCodeBench/896", "solution": "from collections import Counter\nimport random\nimport itertools\ndef task_func(length, count, seed=0):\n    random.seed(seed)\n    letters = ['a', 'b', 'c', 'd', 'e']\n    strings = [''.join(random.choices(letters, k=length)) for _ in range(count)]\n    flattened_string = ''.join(strings)\n    counter = Counter(flattened_string)\n    return counter", "raw_solution": "from collections import Counter\nimport random\nimport itertools\n\ndef task_func(length, count, seed=0):\n    random.seed(seed)\n    letters = ['a', 'b', 'c', 'd', 'e']\n    strings = [''.join(random.choices(letters, k=length)) for _ in range(count)]\n    flattened_string = ''.join(strings)\n    counter = Counter(flattened_string)\n    return counter\n```"}
{"task_id": "BigCodeBench/897", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nNUMBERS = list(range(1, 7))\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    results = [random.randint(1, 6) for _ in range(rolls)]\n    freq_array = np.array([results.count(i) for i in NUMBERS])\n    fig, ax = plt.subplots()\n    ax.bar(NUMBERS, freq_array)\n    ax.set_title(\"Histogram of Dice Rolls\")\n    ax.set_xlabel(\"Dice Value\")\n    ax.set_ylabel(\"Frequency\")\n    return freq_array, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    results = [random.randint(1, 6) for _ in range(rolls)]\n    freq_array = np.array([results.count(i) for i in NUMBERS])\n    fig, ax = plt.subplots()\n    ax.bar(NUMBERS, freq_array)\n    ax.set_title(\"Histogram of Dice Rolls\")\n    ax.set_xlabel(\"Dice Value\")\n    ax.set_ylabel(\"Frequency\")\n    return freq_array, ax\n```"}
{"task_id": "BigCodeBench/898", "solution": "from collections import Counter\nimport random\nLETTERS = ['a', 'b', 'c', 'd', 'e']\ndef task_func(count, seed=0):\n    random.seed(seed)\n    pairs = [random.choice(LETTERS) + random.choice(LETTERS) for _ in range(count)]\n    return Counter(pairs)", "raw_solution": "from collections import Counter\nimport random\n\nLETTERS = ['a', 'b', 'c', 'd', 'e']\n\ndef task_func(count, seed=0):\n    random.seed(seed)\n    pairs = [random.choice(LETTERS) + random.choice(LETTERS) for _ in range(count)]\n    return Counter(pairs)\n```"}
{"task_id": "BigCodeBench/899", "solution": "import numpy as np\nimport random\ndef task_func(length=10000, seed=0):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    random.seed(seed)\n    walk = np.zeros(length)\n    for i in range(1, length):\n        walk[i] = walk[i-1] + random.choice([-1, 1])\n    return walk", "raw_solution": "import numpy as np\nimport random\n\ndef task_func(length=10000, seed=0):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    random.seed(seed)\n    walk = np.zeros(length)\n    for i in range(1, length):\n        walk[i] = walk[i-1] + random.choice([-1, 1])\n    return walk\n```"}
{"task_id": "BigCodeBench/900", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(d):\n    if not isinstance(d, list):\n        raise ValueError(\"Input should be a list of dictionaries\")\n    for i in d:\n        if not isinstance(i, dict):\n            raise ValueError(\"Input should be a list of dictionaries\")\n    df = pd.DataFrame(d)\n    result = {}\n    for col in df.columns:\n        if col in ['x', 'y', 'z']:\n            result[col] = {\n                'mean': df[col].mean(),\n                'sum': df[col].sum(),\n                'max': df[col].max(),\n                'min': df[col].min(),\n                'std': df[col].std()\n            }\n    return result", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(d):\n    if not isinstance(d, list):\n        raise ValueError(\"Input should be a list of dictionaries\")\n    for i in d:\n        if not isinstance(i, dict):\n            raise ValueError(\"Input should be a list of dictionaries\")\n    df = pd.DataFrame(d)\n    result = {}\n    for col in df.columns:\n        if col in ['x', 'y', 'z']:\n            result[col] = {\n                'mean': df[col].mean(),\n                'sum': df[col].sum(),\n                'max': df[col].max(),\n                'min': df[col].min(),\n                'std': df[col].std()\n            }\n    return result\n```"}
{"task_id": "BigCodeBench/901", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(d):\n    if not d:\n        return pd.DataFrame()\n    df = pd.DataFrame(d)\n    scaler = MinMaxScaler()\n    df[['x', 'y', 'z']] = scaler.fit_transform(df[['x', 'y', 'z']])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(d):\n    if not d:\n        return pd.DataFrame()\n    df = pd.DataFrame(d)\n    scaler = MinMaxScaler()\n    df[['x', 'y', 'z']] = scaler.fit_transform(df[['x', 'y', 'z']])\n    return df\n```"}
{"task_id": "BigCodeBench/902", "solution": "from collections import Counter\ndef task_func(d):\n    result = {'x': Counter(), 'y': Counter(), 'z': Counter()}\n    for item in d:\n        if 'x' in item:\n            result['x'][item['x']] += 1\n        if 'y' in item:\n            result['y'][item['y']] += 1\n        if 'z' in item:\n            result['z'][item['z']] += 1\n    return result", "raw_solution": "from collections import Counter\n\ndef task_func(d):\n    result = {'x': Counter(), 'y': Counter(), 'z': Counter()}\n    for item in d:\n        if 'x' in item:\n            result['x'][item['x']] += 1\n        if 'y' in item:\n            result['y'][item['y']] += 1\n        if 'z' in item:\n            result['z'][item['z']] += 1\n    return result\n```"}
{"task_id": "BigCodeBench/903", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(d, target='z'):\n    df = pd.DataFrame(d)\n    X = df[['x', 'y']]\n    y = df[target]\n    model = LinearRegression()\n    model.fit(X, y)\n    return model", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(d, target='z'):\n    df = pd.DataFrame(d)\n    X = df[['x', 'y']]\n    y = df[target]\n    model = LinearRegression()\n    model.fit(X, y)\n    return model\n```"}
{"task_id": "BigCodeBench/904", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(d, keys=['x', 'y', 'z']):\n    df = pd.DataFrame(d)\n    ax = df[keys].plot()\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(d, keys=['x', 'y', 'z']):\n    df = pd.DataFrame(d)\n    ax = df[keys].plot()\n    return ax\n```"}
{"task_id": "BigCodeBench/905", "solution": "import os\nimport glob\nimport csv\ndef task_func(directory_path, file_extension='.csv'):\n    data = {}\n    for file in glob.glob(os.path.join(directory_path, f'*{file_extension}')):\n        with open(file, 'r') as f:\n            reader = csv.reader(f)\n            data[os.path.splitext(os.path.basename(file))[0]] = list(reader)\n    return data", "raw_solution": "import os\nimport glob\nimport csv\n\ndef task_func(directory_path, file_extension='.csv'):\n    data = {}\n    for file in glob.glob(os.path.join(directory_path, f'*{file_extension}')):\n        with open(file, 'r') as f:\n            reader = csv.reader(f)\n            data[os.path.splitext(os.path.basename(file))[0]] = list(reader)\n    return data\n```"}
{"task_id": "BigCodeBench/906", "solution": "import zipfile\nimport os\nimport re\nimport shutil\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    # Create the archive file\n    archive_path = os.path.join(target_dir, archive_name)\n    with zipfile.ZipFile(archive_path, 'w') as archive:\n        # Iterate over all files in the source directory\n        for root, dirs, files in os.walk(source_dir):\n            for file in files:\n                # Check if the file is processed\n                if re.search(r'_processed$', file):\n                    # Get the full path to the file\n                    file_path = os.path.join(root, file)\n                    # Add the file to the archive\n                    archive.write(file_path, arcname=file)\n                    # Move the file to the target directory\n                    shutil.move(file_path, target_dir)\n    return archive_path", "raw_solution": "import zipfile\nimport os\nimport re\nimport shutil\n\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    # Create the archive file\n    archive_path = os.path.join(target_dir, archive_name)\n    with zipfile.ZipFile(archive_path, 'w') as archive:\n        # Iterate over all files in the source directory\n        for root, dirs, files in os.walk(source_dir):\n            for file in files:\n                # Check if the file is processed\n                if re.search(r'_processed$', file):\n                    # Get the full path to the file\n                    file_path = os.path.join(root, file)\n                    # Add the file to the archive\n                    archive.write(file_path, arcname=file)\n                    # Move the file to the target directory\n                    shutil.move(file_path, target_dir)\n    return archive_path\n```"}
{"task_id": "BigCodeBench/907", "solution": "import os\nimport re\ndef task_func(pattern: str, replacement: str, directory: str) -> bool:\n    try:\n        for filename in os.listdir(directory):\n            if re.search(pattern, filename):\n                new_filename = re.sub(pattern, replacement, filename)\n                os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n        return True\n    except Exception:\n        return False", "raw_solution": "import os\nimport re\n\ndef task_func(pattern: str, replacement: str, directory: str) -> bool:\n    try:\n        for filename in os.listdir(directory):\n            if re.search(pattern, filename):\n                new_filename = re.sub(pattern, replacement, filename)\n                os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n        return True\n    except Exception:\n        return False\n```"}
{"task_id": "BigCodeBench/908", "solution": "import os\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\ndef task_func(directory: str, pattern: str) -> list:\n    axes_list = []\n    for filename in os.listdir(directory):\n        if re.match(pattern, filename):\n            df = pd.read_csv(os.path.join(directory, filename))\n            ax = df.plot(x='Month', y='Sales', kind='line')\n            axes_list.append(ax)\n    return axes_list", "raw_solution": "import os\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\n\ndef task_func(directory: str, pattern: str) -> list:\n    axes_list = []\n    for filename in os.listdir(directory):\n        if re.match(pattern, filename):\n            df = pd.read_csv(os.path.join(directory, filename))\n            ax = df.plot(x='Month', y='Sales', kind='line')\n            axes_list.append(ax)\n    return axes_list\n```"}
{"task_id": "BigCodeBench/909", "solution": "import pandas as pd\nimport itertools\nfrom random import shuffle\ndef task_func(letters=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'], categories=['Category 1', 'Category 2', 'Category 3']):\n    shuffle(categories)\n    df = pd.DataFrame(list(itertools.product(letters, categories)), columns=['Letter', 'Category'])\n    return df", "raw_solution": "import pandas as pd\nimport itertools\nfrom random import shuffle\n\ndef task_func(letters=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'], categories=['Category 1', 'Category 2', 'Category 3']):\n    shuffle(categories)\n    df = pd.DataFrame(list(itertools.product(letters, categories)), columns=['Letter', 'Category'])\n    return df\n```"}
{"task_id": "BigCodeBench/910", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(letters, repetitions, colors):\n    if len(letters) != len(repetitions) or len(colors) != len(repetitions) or not letters or not repetitions or not colors:\n        raise ValueError(\"Invalid input\")\n\n    flat_letters = [letter for letter, repetition in zip(letters, repetitions) for _ in range(repetition)]\n\n    unique_letters, counts = np.unique(flat_letters, return_counts=True)\n\n    fig, ax = plt.subplots()\n    ax.bar(unique_letters, counts, color=colors)\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of Letters')\n\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(letters, repetitions, colors):\n    if len(letters) != len(repetitions) or len(colors) != len(repetitions) or not letters or not repetitions or not colors:\n        raise ValueError(\"Invalid input\")\n\n    flat_letters = [letter for letter, repetition in zip(letters, repetitions) for _ in range(repetition)]\n\n    unique_letters, counts = np.unique(flat_letters, return_counts=True)\n\n    fig, ax = plt.subplots()\n    ax.bar(unique_letters, counts, color=colors)\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of Letters')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/911", "solution": "from functools import reduce\nimport operator\nimport string\ndef task_func(letters):\n    letter_to_num = {letter: num for num, letter in enumerate(string.ascii_uppercase, start=1)}\n    return reduce(operator.mul, [letter_to_num[letter] for letter in letters])", "raw_solution": "from functools import reduce\nimport operator\nimport string\n\ndef task_func(letters):\n    letter_to_num = {letter: num for num, letter in enumerate(string.ascii_uppercase, start=1)}\n    return reduce(operator.mul, [letter_to_num[letter] for letter in letters])\n```"}
{"task_id": "BigCodeBench/912", "solution": "from collections import Counter\nimport itertools\ndef task_func(letters: list, repetitions: int) -> dict:\n    repeated_letters = list(itertools.chain.from_iterable(itertools.repeat(letters, repetitions)))\n    return dict(Counter(repeated_letters))", "raw_solution": "from collections import Counter\nimport itertools\ndef task_func(letters: list, repetitions: int) -> dict:\n    repeated_letters = list(itertools.chain.from_iterable(itertools.repeat(letters, repetitions)))\n    return dict(Counter(repeated_letters))\n```"}
{"task_id": "BigCodeBench/913", "solution": "from typing import List, Union\nimport numpy as np\nimport scipy.fft\ndef task_func(data: List[Union[int, str]], repetitions: int = 1):\n    if not data or repetitions <= 0:\n        return {'mode': np.array([]), 'count': np.array([])}\n\n    data = data * repetitions\n    data_fft = scipy.fft.fft(data)\n\n    unique, counts = np.unique(data, return_counts=True)\n    max_count_indices = np.where(counts == np.max(counts))[0]\n    mode = unique[max_count_indices]\n    count = counts[max_count_indices]\n\n    return {'mode': np.sort(mode), 'count': count}", "raw_solution": "from typing import List, Union\nimport numpy as np\nimport scipy.fft\n\ndef task_func(data: List[Union[int, str]], repetitions: int = 1):\n    if not data or repetitions <= 0:\n        return {'mode': np.array([]), 'count': np.array([])}\n\n    data = data * repetitions\n    data_fft = scipy.fft.fft(data)\n\n    unique, counts = np.unique(data, return_counts=True)\n    max_count_indices = np.where(counts == np.max(counts))[0]\n    mode = unique[max_count_indices]\n    count = counts[max_count_indices]\n\n    return {'mode': np.sort(mode), 'count': count}\n```"}
{"task_id": "BigCodeBench/914", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df.set_index('timestamp', inplace=True)\n    df.sort_index(inplace=True)\n\n    # Generate future timestamps\n    future_timestamps = pd.date_range(start=df.index[-1], periods=7, freq='24H')\n\n    # Create a new DataFrame for the future timestamps\n    future_df = pd.DataFrame(index=future_timestamps)\n\n    # Merge the original DataFrame and the future DataFrame\n    df = df.join(future_df, how='outer').fillna(method='ffill')\n\n    # Create a new column for the day of the week\n    df['day_of_week'] = df.index.dayofweek\n\n    # Create a new column for the hour of the day\n    df['hour_of_day'] = df.index.hour\n\n    # Create a new column for the minute of the hour\n    df['minute_of_hour'] = df.index.minute\n\n    # Create a new column for the second of the minute\n    df['second_of_minute'] = df.index.second\n\n    # Create a new column for the day of the month\n    df['day_of_month'] = df.index.day\n\n    # Create a new column for the month\n    df['month'] = df.index.month\n\n    # Create a new column for the year\n    df['year'] = df.index.year\n\n    # Create a new column for the day of the year\n    df['day_of_year'] = df.index.dayofyear\n\n    # Create a new column for the week of the year\n    df['week_of_year'] = df.index.weekofyear\n\n    # Create a new column for the quarter of the year\n    df['quarter_of_year'] = df.index.quarter\n\n    # Create a new column for the weekday or weekend\n    df['is_weekday'] = df['day_of_week'].apply(lambda x: 1 if x < 5 else 0)\n\n    # Create a new column for the morning or afternoon\n    df['is_afternoon'] = df['hour_of_day'].apply(lambda x: 1 if x >= 12 else 0)\n\n    # Create a new column for the morning or evening\n    df['is_evening'] = df['hour_of_day'].apply(lambda x: 1 if x >= 18 else 0)\n\n    # Create a new column for the morning or night\n    df['is_night'] = df['hour_of_day'].apply(lambda x: 1 if x < 6 else 0)\n\n    # Create a new column for the morning or late morning\n    df['is_late_morning'] = df['hour_of_day'].apply(lambda x: 1 if x < 10 else 0)\n\n    # Create a new column for the morning or late afternoon\n    df['is_late_afternoon'] = df['hour_of_day'].apply(lambda x: 1 if x >= 16 else 0)\n\n    # Create a new column for the morning or late evening\n    df['is_late_evening'] = df['hour_of_day'].apply(lambda x: 1 if x >= 19 else 0)\n\n    # Create a new column for the morning or late night\n    df['is_late_night'] = df['hour_of_day'].apply(lambda x: 1 if x < 7 else 0)\n\n    # Create a new column for the morning or early morning\n    df['is_early_morning'] = df['hour_of_day'].apply(lambda x: 1 if x < 8 else 0)\n\n    # Create a new column for the morning or early afternoon\n    df['is_early_afternoon'] = df['hour_of_day'].apply(lambda x: 1 if x >= 14 else 0)\n\n    # Create a new column for the morning or early evening", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df.set_index('timestamp', inplace=True)\n    df.sort_index(inplace=True)\n\n    # Generate future timestamps\n    future_timestamps = pd.date_range(start=df.index[-1], periods=7, freq='24H')\n\n    # Create a new DataFrame for the future timestamps\n    future_df = pd.DataFrame(index=future_timestamps)\n\n    # Merge the original DataFrame and the future DataFrame\n    df = df.join(future_df, how='outer').fillna(method='ffill')\n\n    # Create a new column for the day of the week\n    df['day_of_week'] = df.index.dayofweek\n\n    # Create a new column for the hour of the day\n    df['hour_of_day'] = df.index.hour\n\n    # Create a new column for the minute of the hour\n    df['minute_of_hour'] = df.index.minute\n\n    # Create a new column for the second of the minute\n    df['second_of_minute'] = df.index.second\n\n    # Create a new column for the day of the month\n    df['day_of_month'] = df.index.day\n\n    # Create a new column for the month\n    df['month'] = df.index.month\n\n    # Create a new column for the year\n    df['year'] = df.index.year\n\n    # Create a new column for the day of the year\n    df['day_of_year'] = df.index.dayofyear\n\n    # Create a new column for the week of the year\n    df['week_of_year'] = df.index.weekofyear\n\n    # Create a new column for the quarter of the year\n    df['quarter_of_year'] = df.index.quarter\n\n    # Create a new column for the weekday or weekend\n    df['is_weekday'] = df['day_of_week'].apply(lambda x: 1 if x < 5 else 0)\n\n    # Create a new column for the morning or afternoon\n    df['is_afternoon'] = df['hour_of_day'].apply(lambda x: 1 if x >= 12 else 0)\n\n    # Create a new column for the morning or evening\n    df['is_evening'] = df['hour_of_day'].apply(lambda x: 1 if x >= 18 else 0)\n\n    # Create a new column for the morning or night\n    df['is_night'] = df['hour_of_day'].apply(lambda x: 1 if x < 6 else 0)\n\n    # Create a new column for the morning or late morning\n    df['is_late_morning'] = df['hour_of_day'].apply(lambda x: 1 if x < 10 else 0)\n\n    # Create a new column for the morning or late afternoon\n    df['is_late_afternoon'] = df['hour_of_day'].apply(lambda x: 1 if x >= 16 else 0)\n\n    # Create a new column for the morning or late evening\n    df['is_late_evening'] = df['hour_of_day'].apply(lambda x: 1 if x >= 19 else 0)\n\n    # Create a new column for the morning or late night\n    df['is_late_night'] = df['hour_of_day'].apply(lambda x: 1 if x < 7 else 0)\n\n    # Create a new column for the morning or early morning\n    df['is_early_morning'] = df['hour_of_day'].apply(lambda x: 1 if x < 8 else 0)\n\n    # Create a new column for the morning or early afternoon\n    df['is_early_afternoon'] = df['hour_of_day'].apply(lambda x: 1 if x >= 14 else 0)\n\n    # Create a new column for the morning or early evening\n   "}
{"task_id": "BigCodeBench/915", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\ndef task_func(df, z_threshold=2):\n    df['z_score'] = zscore(df['closing_price'])\n    outliers = df[np.abs(df['z_score']) > z_threshold]\n    plot = df['closing_price'].plot(kind='line', title='Outliers in Closing Prices')\n    plot.set_xlabel('Index')\n    plot.set_ylabel('Closing Price')\n    plt.show()\n    return outliers, plot", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\n\ndef task_func(df, z_threshold=2):\n    df['z_score'] = zscore(df['closing_price'])\n    outliers = df[np.abs(df['z_score']) > z_threshold]\n    plot = df['closing_price'].plot(kind='line', title='Outliers in Closing Prices')\n    plot.set_xlabel('Index')\n    plot.set_ylabel('Closing Price')\n    plt.show()\n    return outliers, plot\n```"}
{"task_id": "BigCodeBench/916", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df: pd.DataFrame) -> tuple:\n    fig, axes = plt.subplots(2, figsize=(10, 10))\n    sns.boxplot(data=df['Close'], ax=axes[0])\n    axes[0].set_title('Box Plot of Closing Prices')\n    sns.histplot(data=df['Close'], ax=axes[1])\n    axes[1].set_title('Histogram of Closing Prices')\n    plt.tight_layout()\n    return axes[0], axes[1]", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df: pd.DataFrame) -> tuple:\n    fig, axes = plt.subplots(2, figsize=(10, 10))\n    sns.boxplot(data=df['Close'], ax=axes[0])\n    axes[0].set_title('Box Plot of Closing Prices')\n    sns.histplot(data=df['Close'], ax=axes[1])\n    axes[1].set_title('Histogram of Closing Prices')\n    plt.tight_layout()\n    return axes[0], axes[1]\n```"}
{"task_id": "BigCodeBench/917", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    model = ARIMA(df['Close'], order=(5,1,0))\n    model_fit = model.fit(disp=0)\n    forecast = model_fit.forecast(steps=7)\n\n    fig, ax = plt.subplots(figsize=(12, 6))\n    ax.plot(df['Date'], df['Close'], label='Actual')\n    ax.plot(pd.date_range(start=df['Date'].iloc[-1], periods=8)[1:], forecast, label='Forecast')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Share Price')\n    ax.set_title('ARIMA Model Forecast')\n    ax.legend()\n\n    return forecast.tolist(), ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\n\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    model = ARIMA(df['Close'], order=(5,1,0))\n    model_fit = model.fit(disp=0)\n    forecast = model_fit.forecast(steps=7)\n\n    fig, ax = plt.subplots(figsize=(12, 6))\n    ax.plot(df['Date'], df['Close'], label='Actual')\n    ax.plot(pd.date_range(start=df['Date'].iloc[-1], periods=8)[1:], forecast, label='Forecast')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Share Price')\n    ax.set_title('ARIMA Model Forecast')\n    ax.legend()\n\n    return forecast.tolist(), ax\n```"}
{"task_id": "BigCodeBench/918", "solution": "import pandas as pd\nimport re\ndef task_func(data, mapping):\n    for col in data.columns:\n        if data[col].dtype == 'object':\n            for acronym, full_word in mapping.items():\n                data[col] = data[col].str.replace(acronym, full_word)\n    return data", "raw_solution": "import pandas as pd\nimport re\n\ndef task_func(data, mapping):\n    for col in data.columns:\n        if data[col].dtype == 'object':\n            for acronym, full_word in mapping.items():\n                data[col] = data[col].str.replace(acronym, full_word)\n    return data\n```"}
{"task_id": "BigCodeBench/919", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data, column):\n    CATEGORIES = ['A', 'B', 'C', 'D', 'E']\n    df = pd.DataFrame(data)\n    df = df[column].value_counts().reindex(CATEGORIES).fillna(0)\n    df.plot(kind='bar', xlabel='Category', ylabel='Count', title=f'Distribution of {column}')\n    plt.show()\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data, column):\n    CATEGORIES = ['A', 'B', 'C', 'D', 'E']\n    df = pd.DataFrame(data)\n    df = df[column].value_counts().reindex(CATEGORIES).fillna(0)\n    df.plot(kind='bar', xlabel='Category', ylabel='Count', title=f'Distribution of {column}')\n    plt.show()\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/920", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    corr = data.corr()\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n    ax.set_title('Correlation Matrix')\n    return ax", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    corr = data.corr()\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n    ax.set_title('Correlation Matrix')\n    return ax\n```"}
{"task_id": "BigCodeBench/921", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data, columns):\n    scaler = MinMaxScaler()\n    data[columns] = scaler.fit_transform(data[columns])\n    return data", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data, columns):\n    scaler = MinMaxScaler()\n    data[columns] = scaler.fit_transform(data[columns])\n    return data\n```"}
{"task_id": "BigCodeBench/922", "solution": "import pandas as pd\nimport re\nSTOPWORDS = set([\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n    \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n    \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n    \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\",\n    \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\",\n    \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\",\n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\",\n    \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\",\n    \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\",\n    \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\",\n    \"don\", \"should\", \"now\"\n])\ndef task_func(data, column):\n    def remove_stopwords(text):\n        words = text.split()\n        new_words = [word for word in words if word not in STOPWORDS]\n        return ' '.join(new_words)\n\n    data[column] = data[column].apply(remove_stopwords)\n    return data", "raw_solution": "import pandas as pd\nimport re\n# Constants\nSTOPWORDS = set([\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n    \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n    \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n    \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\",\n    \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\",\n    \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\",\n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\",\n    \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\",\n    \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\",\n    \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\",\n    \"don\", \"should\", \"now\"\n])\ndef task_func(data, column):\n    def remove_stopwords(text):\n        words = text.split()\n        new_words = [word for word in words if word not in STOPWORDS]\n        return ' '.join(new_words)\n\n    data[column] = data[column].apply(remove_stopwords)\n    return data\n```"}
{"task_id": "BigCodeBench/923", "solution": "import pandas as pd\nimport random\nimport re\ndef task_func(person_names, email_domains, num_records=5):\n    if len(person_names) < num_records:\n        raise ValueError(\"Number of names provided is less than the number of records requested\")\n    if not email_domains:\n        raise ValueError(\"No email domains are provided\")\n    df = pd.DataFrame(columns=['Name', 'Email'])\n    for i in range(num_records):\n        name = random.choice(person_names)\n        domain = random.choice(email_domains)\n        email = re.sub(r'@', '[at]', f\"{name}@{domain}\")\n        df = df.append({'Name': name, 'Email': email}, ignore_index=True)\n    return df", "raw_solution": "import pandas as pd\nimport random\nimport re\n\ndef task_func(person_names, email_domains, num_records=5):\n    if len(person_names) < num_records:\n        raise ValueError(\"Number of names provided is less than the number of records requested\")\n    if not email_domains:\n        raise ValueError(\"No email domains are provided\")\n    df = pd.DataFrame(columns=['Name', 'Email'])\n    for i in range(num_records):\n        name = random.choice(person_names)\n        domain = random.choice(email_domains)\n        email = re.sub(r'@', '[at]', f\"{name}@{domain}\")\n        df = df.append({'Name': name, 'Email': email}, ignore_index=True)\n    return df\n```"}
{"task_id": "BigCodeBench/924", "solution": "import pandas as pd\nimport os\nimport sys\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    if not os.path.exists(file_path):\n        print(f\"File {file_path} does not exist.\")\n        sys.exit(1)\n\n    df = pd.read_csv(file_path)\n\n    if column_name not in df.columns:\n        print(f\"Column {column_name} does not exist in the DataFrame.\")\n        sys.exit(1)\n\n    df[column_name] = df[column_name].apply(lambda x: str(x).replace('\\n', '<br>'))\n\n    return df", "raw_solution": "import pandas as pd\nimport os\nimport sys\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    if not os.path.exists(file_path):\n        print(f\"File {file_path} does not exist.\")\n        sys.exit(1)\n\n    df = pd.read_csv(file_path)\n\n    if column_name not in df.columns:\n        print(f\"Column {column_name} does not exist in the DataFrame.\")\n        sys.exit(1)\n\n    df[column_name] = df[column_name].apply(lambda x: str(x).replace('\\n', '<br>'))\n\n    return df\n```"}
{"task_id": "BigCodeBench/925", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(data_size=1000, column_names=['A', 'B', 'C', 'D', 'E'], seed=0):\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.randint(1, 101, size=(data_size, len(column_names))), columns=column_names)\n    df = df.applymap(lambda x: -1 if x < 10 else x)\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(data_size=1000, column_names=['A', 'B', 'C', 'D', 'E'], seed=0):\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.randint(1, 101, size=(data_size, len(column_names))), columns=column_names)\n    df = df.applymap(lambda x: -1 if x < 10 else x)\n    return df\n```"}
{"task_id": "BigCodeBench/926", "solution": "import pandas as pd\nimport sqlite3\ndef task_func(db_path: str, table_name: str, column_name: str) -> pd.DataFrame:\n    conn = sqlite3.connect(db_path)\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    return df", "raw_solution": "import pandas as pd\nimport sqlite3\n\ndef task_func(db_path: str, table_name: str, column_name: str) -> pd.DataFrame:\n    conn = sqlite3.connect(db_path)\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    return df\n```"}
{"task_id": "BigCodeBench/927", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    df = pd.read_csv(file_path)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    le = LabelEncoder()\n    df[column_name] = le.fit_transform(df[column_name])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    df = pd.read_csv(file_path)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    le = LabelEncoder()\n    df[column_name] = le.fit_transform(df[column_name])\n    return df\n```"}
{"task_id": "BigCodeBench/928", "solution": "from collections import Counter\nimport itertools\nimport string\ndef task_func(word: str) -> dict:\n    alphabet = string.ascii_lowercase\n    combinations = [''.join(x) for x in itertools.product(alphabet, repeat=2)]\n    word_combinations = [word[i:i+2] for i in range(len(word)-1)]\n    word_counter = Counter(word_combinations)\n    result = {comb: word_counter[comb] for comb in combinations}\n    return result", "raw_solution": "from collections import Counter\nimport itertools\nimport string\ndef task_func(word: str) -> dict:\n    alphabet = string.ascii_lowercase\n    combinations = [''.join(x) for x in itertools.product(alphabet, repeat=2)]\n    word_combinations = [word[i:i+2] for i in range(len(word)-1)]\n    word_counter = Counter(word_combinations)\n    result = {comb: word_counter[comb] for comb in combinations}\n    return result\n```"}
{"task_id": "BigCodeBench/929", "solution": "import numpy as np\nfrom scipy import stats\ndef task_func(word: str) -> np.ndarray:\n    # Calculate the difference between the ASCII values of each pair of adjacent letters in the word\n    diffs = np.array([ord(word[i]) - ord(word[i-1]) for i in range(1, len(word))])\n\n    # Calculate the entropy of the differences\n    entropy = stats.entropy(diffs)\n\n    return diffs, entropy", "raw_solution": "import numpy as np\nfrom scipy import stats\n\ndef task_func(word: str) -> np.ndarray:\n    # Calculate the difference between the ASCII values of each pair of adjacent letters in the word\n    diffs = np.array([ord(word[i]) - ord(word[i-1]) for i in range(1, len(word))])\n\n    # Calculate the entropy of the differences\n    entropy = stats.entropy(diffs)\n\n    return diffs, entropy\n```"}
{"task_id": "BigCodeBench/930", "solution": "import random\nimport string\nPOSSIBLE_LETTERS = ['a', 'b', 'c']\ndef task_func(word):\n    if not all(char.isalpha() for char in word):\n        raise ValueError(\"Input contains non-letter characters\")\n    if len(word) < 2:\n        return [\"\"] * len(POSSIBLE_LETTERS)\n    pairs = []\n    for i in range(len(word) - 1):\n        pair = word[i:i+2]\n        pairs.append(pair)\n    return pairs", "raw_solution": "import random\nimport string\nPOSSIBLE_LETTERS = ['a', 'b', 'c']\ndef task_func(word):\n    if not all(char.isalpha() for char in word):\n        raise ValueError(\"Input contains non-letter characters\")\n    if len(word) < 2:\n        return [\"\"] * len(POSSIBLE_LETTERS)\n    pairs = []\n    for i in range(len(word) - 1):\n        pair = word[i:i+2]\n        pairs.append(pair)\n    return pairs\n```"}
{"task_id": "BigCodeBench/931", "solution": "from collections import defaultdict\nimport re\ndef task_func(word: str) -> dict:\n    sanitized_word = re.sub(r'[^a-zA-Z]', '', word)\n    two_letter_combinations = [sanitized_word[i:i+2] for i in range(len(sanitized_word)-1)]\n    result = defaultdict(int)\n    for combination in two_letter_combinations:\n        result[combination] += 1\n    return result", "raw_solution": "from collections import defaultdict\nimport re\n\ndef task_func(word: str) -> dict:\n    sanitized_word = re.sub(r'[^a-zA-Z]', '', word)\n    two_letter_combinations = [sanitized_word[i:i+2] for i in range(len(sanitized_word)-1)]\n    result = defaultdict(int)\n    for combination in two_letter_combinations:\n        result[combination] += 1\n    return result\n```"}
{"task_id": "BigCodeBench/932", "solution": "from collections import Counter\nimport re\ndef task_func(word: str) -> list:\n    word = re.sub(r'[^a-z]', '', word.lower())\n    if len(word) < 2:\n        return []\n    two_letter_combinations = [word[i:i+2] for i in range(len(word)-1)]\n    counter = Counter(two_letter_combinations)\n    most_common = counter.most_common(1)\n    return [(most_common[0][0], most_common[0][1])]", "raw_solution": "from collections import Counter\nimport re\n\ndef task_func(word: str) -> list:\n    word = re.sub(r'[^a-z]', '', word.lower())\n    if len(word) < 2:\n        return []\n    two_letter_combinations = [word[i:i+2] for i in range(len(word)-1)]\n    counter = Counter(two_letter_combinations)\n    most_common = counter.most_common(1)\n    return [(most_common[0][0], most_common[0][1])]\n```"}
{"task_id": "BigCodeBench/933", "solution": "import string\nimport wordninja\ndef task_func(word):\n    alphabet = string.ascii_lowercase\n    word_list = []\n    for letter in word:\n        position = alphabet.index(letter) + 1\n        word_list.append((letter, position))\n    return word_list", "raw_solution": "import string\nimport wordninja\n\ndef task_func(word):\n    alphabet = string.ascii_lowercase\n    word_list = []\n    for letter in word:\n        position = alphabet.index(letter) + 1\n        word_list.append((letter, position))\n    return word_list\n```"}
{"task_id": "BigCodeBench/934", "solution": "from collections import Counter\nimport hashlib\ndef task_func(word: str) -> dict:\n    pairs = [word[i:i+2] for i in range(len(word)-1)]\n    count = Counter(pairs)\n    return count", "raw_solution": "from collections import Counter\nimport hashlib\ndef task_func(word: str) -> dict:\n    pairs = [word[i:i+2] for i in range(len(word)-1)]\n    count = Counter(pairs)\n    return count\n```"}
{"task_id": "BigCodeBench/935", "solution": "import pandas as pd\nimport string\ndef task_func(word):\n    if not word.islower():\n        raise ValueError(\"The input word should be in lowercase.\")\n    if not word.isalpha():\n        raise ValueError(\"The input word should contain only alphabetic characters.\")\n    alphabet = string.ascii_lowercase\n    df = pd.DataFrame(list(enumerate(word, 1)), columns=['Position', 'Letter'])\n    df['Position'] = df['Letter'].apply(lambda x: alphabet.index(x) + 1)\n    return df", "raw_solution": "import pandas as pd\nimport string\n\ndef task_func(word):\n    if not word.islower():\n        raise ValueError(\"The input word should be in lowercase.\")\n    if not word.isalpha():\n        raise ValueError(\"The input word should contain only alphabetic characters.\")\n    alphabet = string.ascii_lowercase\n    df = pd.DataFrame(list(enumerate(word, 1)), columns=['Position', 'Letter'])\n    df['Position'] = df['Letter'].apply(lambda x: alphabet.index(x) + 1)\n    return df\n```"}
{"task_id": "BigCodeBench/936", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport string\nALPHABET = list(string.ascii_lowercase)\ndef task_func(word):\n    positions = [ALPHABET.index(char) + 1 for char in word]\n    plt.bar(range(1, len(positions) + 1), positions)\n    plt.xlabel('Letter Position')\n    plt.ylabel('Alphabet Position')\n    plt.title('Position of each letter in the word')\n    plt.grid(True)\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport string\n# Constants\nALPHABET = list(string.ascii_lowercase)\ndef task_func(word):\n    positions = [ALPHABET.index(char) + 1 for char in word]\n    plt.bar(range(1, len(positions) + 1), positions)\n    plt.xlabel('Letter Position')\n    plt.ylabel('Alphabet Position')\n    plt.title('Position of each letter in the word')\n    plt.grid(True)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/937", "solution": "import re\nfrom collections import Counter\ndef task_func(input_str):\n    # Remove non-alphanumeric characters and convert to lowercase\n    cleaned_str = re.sub(r'[^a-zA-Z0-9]', '', input_str).lower()\n    # Count the frequency of each character\n    freq_dict = Counter(cleaned_str)\n    return freq_dict", "raw_solution": "import re\nfrom collections import Counter\ndef task_func(input_str):\n    # Remove non-alphanumeric characters and convert to lowercase\n    cleaned_str = re.sub(r'[^a-zA-Z0-9]', '', input_str).lower()\n    # Count the frequency of each character\n    freq_dict = Counter(cleaned_str)\n    return freq_dict\n```"}
{"task_id": "BigCodeBench/938", "solution": "import re\nimport pandas as pd\ndef task_func(input_df):\n    input_df['clean_text'] = input_df['text'].apply(lambda x: re.sub(r'[^A-Za-z0-9 ]+', '', x))\n    input_df['text_length'] = input_df['clean_text'].apply(lambda x: len(x))\n    return input_df", "raw_solution": "import re\nimport pandas as pd\ndef task_func(input_df):\n    input_df['clean_text'] = input_df['text'].apply(lambda x: re.sub(r'[^A-Za-z0-9 ]+', '', x))\n    input_df['text_length'] = input_df['clean_text'].apply(lambda x: len(x))\n    return input_df\n```"}
{"task_id": "BigCodeBench/939", "solution": "import re\nimport os\nimport glob\ndef task_func(dir_path: str) -> list:\n    files = glob.glob(dir_path + \"/*\")\n    new_names = []\n    for file in files:\n        if os.path.isfile(file):\n            new_name = re.sub(r'[^a-zA-Z0-9]', '', os.path.basename(file))\n            new_names.append(new_name)\n    return new_names", "raw_solution": "import re\nimport os\nimport glob\ndef task_func(dir_path: str) -> list:\n    files = glob.glob(dir_path + \"/*\")\n    new_names = []\n    for file in files:\n        if os.path.isfile(file):\n            new_name = re.sub(r'[^a-zA-Z0-9]', '', os.path.basename(file))\n            new_names.append(new_name)\n    return new_names\n```"}
{"task_id": "BigCodeBench/940", "solution": "import re\nfrom nltk import word_tokenize\nfrom collections import Counter\ndef task_func(input_str):\n    # Remove all special characters, punctuation marks and spaces from the string\n    cleaned_str = re.sub(r'[^\\w\\s]', '', input_str).replace(\" \", \"\")\n\n    # Tokenize the string into words\n    words = word_tokenize(cleaned_str)\n\n    # Count the frequency of each word\n    word_freq = Counter(words)\n\n    return word_freq", "raw_solution": "import re\nfrom nltk import word_tokenize\nfrom collections import Counter\n\ndef task_func(input_str):\n    # Remove all special characters, punctuation marks and spaces from the string\n    cleaned_str = re.sub(r'[^\\w\\s]', '', input_str).replace(\" \", \"\")\n\n    # Tokenize the string into words\n    words = word_tokenize(cleaned_str)\n\n    # Count the frequency of each word\n    word_freq = Counter(words)\n\n    return word_freq\n```"}
{"task_id": "BigCodeBench/941", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_date: str, periods: int, freq: str, random_seed: int = 0) -> (pd.DataFrame, plt.Axes):\n    np.random.seed(random_seed)\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n    sales_forecast = pd.DataFrame({\n        'Date': date_range,\n        'Sales': np.random.randint(100, 500, size=periods)\n    })\n    fig, ax = plt.subplots()\n    sales_forecast.plot(x='Date', y='Sales', ax=ax)\n    ax.set_title('Sales Forecast')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    return sales_forecast, ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date: str, periods: int, freq: str, random_seed: int = 0) -> (pd.DataFrame, plt.Axes):\n    np.random.seed(random_seed)\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n    sales_forecast = pd.DataFrame({\n        'Date': date_range,\n        'Sales': np.random.randint(100, 500, size=periods)\n    })\n    fig, ax = plt.subplots()\n    sales_forecast.plot(x='Date', y='Sales', ax=ax)\n    ax.set_title('Sales Forecast')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    return sales_forecast, ax\n```"}
{"task_id": "BigCodeBench/942", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Create a date range\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n\n    # Create a DataFrame with the date range and categories\n    df = pd.DataFrame({'Date': date_range, 'Category': np.random.choice(categories, periods)})\n\n    # Generate random sales data\n    df['Sales'] = np.random.randint(100, 1000, size=periods)\n\n    # Group by 'Category' and 'Date' and sum the 'Sales'\n    df = df.groupby(['Category', 'Date']).sum().reset_index()\n\n    # Plot the sales data\n    ax = df.plot(x='Date', y='Sales', kind='bar', figsize=(10, 6))\n    ax.set_title('Sales Report by Category')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Create a date range\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n\n    # Create a DataFrame with the date range and categories\n    df = pd.DataFrame({'Date': date_range, 'Category': np.random.choice(categories, periods)})\n\n    # Generate random sales data\n    df['Sales'] = np.random.randint(100, 1000, size=periods)\n\n    # Group by 'Category' and 'Date' and sum the 'Sales'\n    df = df.groupby(['Category', 'Date']).sum().reset_index()\n\n    # Plot the sales data\n    ax = df.plot(x='Date', y='Sales', kind='bar', figsize=(10, 6))\n    ax.set_title('Sales Report by Category')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/943", "solution": "import pandas as pd\nimport numpy as np\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(start_date='2016-01-01', periods=24, freq='M', model='additive'):\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n    sales_data = pd.Series(np.random.randint(1, 100, size=periods), index=date_range)\n    decomposition = seasonal_decompose(sales_data, model=model)\n    trend = decomposition.trend\n    seasonal = decomposition.seasonal\n    residual = decomposition.resid\n    return {'trend': trend, 'seasonal': seasonal, 'residual': residual}", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndef task_func(start_date='2016-01-01', periods=24, freq='M', model='additive'):\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n    sales_data = pd.Series(np.random.randint(1, 100, size=periods), index=date_range)\n    decomposition = seasonal_decompose(sales_data, model=model)\n    trend = decomposition.trend\n    seasonal = decomposition.seasonal\n    residual = decomposition.resid\n    return {'trend': trend, 'seasonal': seasonal, 'residual': residual}\n```"}
{"task_id": "BigCodeBench/944", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=0):\n    np.random.seed(seed)\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    prices = np.random.uniform(100, 500, size=periods)\n    df = pd.DataFrame({'Date': dates, 'Price': prices})\n    fig, ax = plt.subplots()\n    df.plot(x='Date', y='Price', ax=ax)\n    ax.set_title('Share Prices Over Time')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price')\n    return df, ax.figure", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=0):\n    np.random.seed(seed)\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    prices = np.random.uniform(100, 500, size=periods)\n    df = pd.DataFrame({'Date': dates, 'Price': prices})\n    fig, ax = plt.subplots()\n    df.plot(x='Date', y='Price', ax=ax)\n    ax.set_title('Share Prices Over Time')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price')\n    return df, ax.figure\n```"}
{"task_id": "BigCodeBench/945", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    if sales_data is None:\n        sales_data = pd.date_range(start=start_date, periods=periods, freq=freq)\n        sales_data = pd.Series(np.random.randint(1, 100, size=periods), index=sales_data)\n    else:\n        sales_data = pd.Series(sales_data, index=pd.date_range(start=start_date, periods=len(sales_data), freq=freq))\n\n    X = np.array(range(len(sales_data))).reshape(-1, 1)\n    Y = sales_data.values.reshape(-1, 1)\n\n    model = LinearRegression()\n    model.fit(X, Y)\n\n    future_dates = pd.date_range(start=sales_data.index[-1], periods=periods, freq=freq)\n    future_X = np.array(range(len(future_dates))).reshape(-1, 1)\n\n    forecasted_sales = model.predict(future_X)\n\n    return forecasted_sales.flatten()", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    if sales_data is None:\n        sales_data = pd.date_range(start=start_date, periods=periods, freq=freq)\n        sales_data = pd.Series(np.random.randint(1, 100, size=periods), index=sales_data)\n    else:\n        sales_data = pd.Series(sales_data, index=pd.date_range(start=start_date, periods=len(sales_data), freq=freq))\n\n    X = np.array(range(len(sales_data))).reshape(-1, 1)\n    Y = sales_data.values.reshape(-1, 1)\n\n    model = LinearRegression()\n    model.fit(X, Y)\n\n    future_dates = pd.date_range(start=sales_data.index[-1], periods=periods, freq=freq)\n    future_X = np.array(range(len(future_dates))).reshape(-1, 1)\n\n    forecasted_sales = model.predict(future_X)\n\n    return forecasted_sales.flatten()\n```"}
{"task_id": "BigCodeBench/946", "solution": "import numpy as np\nimport pandas as pd\nimport random\ndef task_func(rows=3, cols=2, min_val=0, max_val=100, seed=0):\n    random.seed(seed)\n    matrix = [[random.randint(min_val, max_val) for _ in range(cols)] for _ in range(rows)]\n    df = pd.DataFrame(matrix)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nimport random\ndef task_func(rows=3, cols=2, min_val=0, max_val=100, seed=0):\n    random.seed(seed)\n    matrix = [[random.randint(min_val, max_val) for _ in range(cols)] for _ in range(rows)]\n    df = pd.DataFrame(matrix)\n    return df\n```"}
{"task_id": "BigCodeBench/947", "solution": "import numpy as np\nimport random\nfrom datetime import datetime, timedelta\ndef task_func(rows=3, columns=2, start_date=datetime(2021, 1, 1), end_date=datetime(2021, 12, 31), seed=0):\n    random.seed(seed)\n    date_range = (end_date - start_date).days + 1\n    dates = [start_date + timedelta(days=random.randint(0, date_range - 1)) for _ in range(rows * columns)]\n    dates = list(set(dates))  # Remove duplicates\n    dates.sort()\n    matrix = np.array(dates).reshape(rows, columns)\n    return matrix", "raw_solution": "import numpy as np\nimport random\nfrom datetime import datetime, timedelta\n\ndef task_func(rows=3, columns=2, start_date=datetime(2021, 1, 1), end_date=datetime(2021, 12, 31), seed=0):\n    random.seed(seed)\n    date_range = (end_date - start_date).days + 1\n    dates = [start_date + timedelta(days=random.randint(0, date_range - 1)) for _ in range(rows * columns)]\n    dates = list(set(dates))  # Remove duplicates\n    dates.sort()\n    matrix = np.array(dates).reshape(rows, columns)\n    return matrix\n```"}
{"task_id": "BigCodeBench/948", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(rows=3, columns=2, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    scaler = MinMaxScaler()\n    scaled_matrix = scaler.fit_transform(matrix)\n    return scaled_matrix", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(rows=3, columns=2, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    scaler = MinMaxScaler()\n    scaled_matrix = scaler.fit_transform(matrix)\n    return scaled_matrix\n```"}
{"task_id": "BigCodeBench/949", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(rows, columns, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    df = pd.DataFrame(matrix)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(rows, columns, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    df = pd.DataFrame(matrix)\n    return df\n```"}
{"task_id": "BigCodeBench/950", "solution": "import numpy as np\nfrom scipy.linalg import svd\ndef task_func(rows=3, columns=2, seed=0):\n    np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    U, s, Vh = svd(matrix)\n    return U, s, Vh", "raw_solution": "import numpy as np\nfrom scipy.linalg import svd\n\ndef task_func(rows=3, columns=2, seed=0):\n    np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    U, s, Vh = svd(matrix)\n    return U, s, Vh\n```"}
{"task_id": "BigCodeBench/951", "solution": "import pandas as pd\nimport numpy as np\nimport random\nfrom random import randint, seed\nCATEGORIES = ['Electronics', 'Clothing', 'Home & Kitchen', 'Books', 'Toys & Games']\ndef task_func(mystrings, n_products, seed=0):\n    random.seed(seed)\n    product_names = [name.replace(' ', '_') for name in mystrings]\n    categories = [random.choice(CATEGORIES) for _ in range(n_products)]\n    prices = np.random.normal(50, 10, n_products).round(2)\n    df = pd.DataFrame({\n        'Product Name': product_names,\n        'Category': categories,\n        'Price': prices\n    })\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport random\nfrom random import randint, seed\n# Constants\nCATEGORIES = ['Electronics', 'Clothing', 'Home & Kitchen', 'Books', 'Toys & Games']\n\ndef task_func(mystrings, n_products, seed=0):\n    random.seed(seed)\n    product_names = [name.replace(' ', '_') for name in mystrings]\n    categories = [random.choice(CATEGORIES) for _ in range(n_products)]\n    prices = np.random.normal(50, 10, n_products).round(2)\n    df = pd.DataFrame({\n        'Product Name': product_names,\n        'Category': categories,\n        'Price': prices\n    })\n    return df\n```"}
{"task_id": "BigCodeBench/952", "solution": "import pandas as pd\nimport random\nfrom datetime import datetime\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks cannot be negative\")\n    if seed is not None:\n        random.seed(seed)\n    tasks = [task.replace(\" \", \"_\") for task in task_list]\n    random.shuffle(tasks)\n    tasks = tasks[:n_tasks]\n    assigned_tasks = []\n    for task in tasks:\n        assigned_to = random.choice(employees)\n        due_date = datetime.now().date()\n        assigned_tasks.append({\"Task Name\": task, \"Assigned To\": assigned_to, \"Due Date\": due_date})\n    return pd.DataFrame(assigned_tasks)", "raw_solution": "import pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks cannot be negative\")\n    if seed is not None:\n        random.seed(seed)\n    tasks = [task.replace(\" \", \"_\") for task in task_list]\n    random.shuffle(tasks)\n    tasks = tasks[:n_tasks]\n    assigned_tasks = []\n    for task in tasks:\n        assigned_to = random.choice(employees)\n        due_date = datetime.now().date()\n        assigned_tasks.append({\"Task Name\": task, \"Assigned To\": assigned_to, \"Due Date\": due_date})\n    return pd.DataFrame(assigned_tasks)\n```"}
{"task_id": "BigCodeBench/953", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(mystrings, folder_path, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    if not os.path.exists(folder_path):\n        raise FileNotFoundError(f\"The provided directory path {folder_path} does not exist and cannot be created.\")\n    file_names = []\n    for string in mystrings:\n        data = np.random.rand(10)\n        plt.bar(range(1, 11), data)\n        plt.title(string)\n        plt.xlabel('Index')\n        plt.ylabel('Value')\n        file_name = f\"{string}.png\"\n        file_path = os.path.join(folder_path, file_name)\n        plt.savefig(file_path)\n        file_names.append(file_name)\n        plt.clf()\n    return file_names", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(mystrings, folder_path, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    if not os.path.exists(folder_path):\n        raise FileNotFoundError(f\"The provided directory path {folder_path} does not exist and cannot be created.\")\n    file_names = []\n    for string in mystrings:\n        data = np.random.rand(10)\n        plt.bar(range(1, 11), data)\n        plt.title(string)\n        plt.xlabel('Index')\n        plt.ylabel('Value')\n        file_name = f\"{string}.png\"\n        file_path = os.path.join(folder_path, file_name)\n        plt.savefig(file_path)\n        file_names.append(file_name)\n        plt.clf()\n    return file_names"}
{"task_id": "BigCodeBench/954", "solution": "import random\nimport re\ndef task_func(target_words, n_sentences, vocabulary):\n    if n_sentences < 0 or not vocabulary:\n        raise ValueError(\"Invalid input\")\n    sentences = []\n    for _ in range(n_sentences):\n        sentence = \" \".join(random.choices(vocabulary, k=10))\n        for word in target_words:\n            sentence = re.sub(r\"\\b\" + re.escape(word) + r\"\\b\", word.replace(\" \", \"_\"), sentence)\n        sentences.append(sentence.lower())\n    return sentences", "raw_solution": "import random\nimport re\n\ndef task_func(target_words, n_sentences, vocabulary):\n    if n_sentences < 0 or not vocabulary:\n        raise ValueError(\"Invalid input\")\n    sentences = []\n    for _ in range(n_sentences):\n        sentence = \" \".join(random.choices(vocabulary, k=10))\n        for word in target_words:\n            sentence = re.sub(r\"\\b\" + re.escape(word) + r\"\\b\", word.replace(\" \", \"_\"), sentence)\n        sentences.append(sentence.lower())\n    return sentences\n```"}
{"task_id": "BigCodeBench/955", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter\ndef task_func(mystrings, text):\n    if not text:\n        raise ValueError(\"Input text is empty\")\n    words = re.findall(r'\\b\\w+\\b', text)\n    words = [word.lower() for word in words]\n    words = [word.replace(\" \", \"_\") for word in words]\n    word_counts = Counter(words)\n    unique_words = list(word_counts.keys())\n    frequencies = list(word_counts.values())\n    plt.figure(figsize=(10, 5))\n    plt.bar(unique_words, frequencies)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of each unique word')\n    plt.xticks(rotation=90)\n    plt.tight_layout()\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter\n\ndef task_func(mystrings, text):\n    if not text:\n        raise ValueError(\"Input text is empty\")\n    words = re.findall(r'\\b\\w+\\b', text)\n    words = [word.lower() for word in words]\n    words = [word.replace(\" \", \"_\") for word in words]\n    word_counts = Counter(words)\n    unique_words = list(word_counts.keys())\n    frequencies = list(word_counts.values())\n    plt.figure(figsize=(10, 5))\n    plt.bar(unique_words, frequencies)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of each unique word')\n    plt.xticks(rotation=90)\n    plt.tight_layout()\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/956", "solution": "import re\nimport string\nimport random\ndef task_func(text: str, seed=None) -> str:\n    if seed is not None:\n        random.seed(seed)\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = re.sub(r'\\s+', '_', text)\n    text = re.sub(r'__+', '__', text)\n    text = re.sub(r'___+', '___', text)\n    text = ''.join(c.upper() if random.random() < 0.5 else c.lower() for c in text)\n    return text", "raw_solution": "import re\nimport string\nimport random\n\ndef task_func(text: str, seed=None) -> str:\n    if seed is not None:\n        random.seed(seed)\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = re.sub(r'\\s+', '_', text)\n    text = re.sub(r'__+', '__', text)\n    text = re.sub(r'___+', '___', text)\n    text = ''.join(c.upper() if random.random() < 0.5 else c.lower() for c in text)\n    return text\n```"}
{"task_id": "BigCodeBench/957", "solution": "import string\nimport re\ndef task_func(text: str) -> tuple:\n    words = re.findall(r'\\b\\w+\\b', text)\n    characters = re.findall(r'[a-zA-Z]', text)\n    unique_characters = set(characters)\n    return len(words), len(characters), len(unique_characters)", "raw_solution": "import string\nimport re\n\ndef task_func(text: str) -> tuple:\n    words = re.findall(r'\\b\\w+\\b', text)\n    characters = re.findall(r'[a-zA-Z]', text)\n    unique_characters = set(characters)\n    return len(words), len(characters), len(unique_characters)\n```"}
{"task_id": "BigCodeBench/958", "solution": "import random\nimport re\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    words = re.findall(r'\\b\\w+\\b', text)\n    for i, word in enumerate(words):\n        if len(word) > 3:\n            middle = list(word[1:-1])\n            random.shuffle(middle)\n            words[i] = word[0] + ''.join(middle) + word[-1]\n    return ' '.join(words)", "raw_solution": "import random\nimport re\n\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    words = re.findall(r'\\b\\w+\\b', text)\n    for i, word in enumerate(words):\n        if len(word) > 3:\n            middle = list(word[1:-1])\n            random.shuffle(middle)\n            words[i] = word[0] + ''.join(middle) + word[-1]\n    return ' '.join(words)\n```"}
{"task_id": "BigCodeBench/959", "solution": "import string\nimport random\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    result = []\n    for char in text:\n        if char.isalpha():\n            if char.isupper():\n                result.append(random.choice(string.ascii_uppercase))\n            else:\n                result.append(random.choice(string.ascii_lowercase))\n        else:\n            result.append(char)\n    return ''.join(result)", "raw_solution": "import string\nimport random\n\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    result = []\n    for char in text:\n        if char.isalpha():\n            if char.isupper():\n                result.append(random.choice(string.ascii_uppercase))\n            else:\n                result.append(random.choice(string.ascii_lowercase))\n        else:\n            result.append(char)\n    return ''.join(result)\n```"}
{"task_id": "BigCodeBench/960", "solution": "import string\nimport random\ndef task_func(text, seed=None):\n    if not text:\n        raise ValueError(\"Input text cannot be empty\")\n    random.seed(seed)\n    password = []\n    for char in text:\n        if char.isalpha():\n            password.append(random.choice(string.ascii_lowercase))\n        elif char.isdigit():\n            password.append(str(random.randint(0, 9)))\n        elif char == ' ':\n            password.append(random.choice(string.ascii_lowercase + str(random.randint(0, 9))))\n        else:\n            password.append(char)\n    return ''.join(password)", "raw_solution": "import string\nimport random\n\ndef task_func(text, seed=None):\n    if not text:\n        raise ValueError(\"Input text cannot be empty\")\n    random.seed(seed)\n    password = []\n    for char in text:\n        if char.isalpha():\n            password.append(random.choice(string.ascii_lowercase))\n        elif char.isdigit():\n            password.append(str(random.randint(0, 9)))\n        elif char == ' ':\n            password.append(random.choice(string.ascii_lowercase + str(random.randint(0, 9))))\n        else:\n            password.append(char)\n    return ''.join(password)\n```"}
{"task_id": "BigCodeBench/961", "solution": "import os\nimport glob\nfrom collections import Counter\ndef task_func(directory, extensions=[\".txt\", \".docx\", \".xlsx\", \".csv\"], keep_zero=True):\n    if not os.path.exists(directory):\n        raise OSError(\"The specified directory does not exist.\")\n    counter = Counter()\n    for extension in extensions:\n        files = glob.glob(os.path.join(directory, \"**\", f\"*{extension}\"), recursive=True)\n        counter.update(files)\n    return counter", "raw_solution": "import os\nimport glob\nfrom collections import Counter\n\ndef task_func(directory, extensions=[\".txt\", \".docx\", \".xlsx\", \".csv\"], keep_zero=True):\n    if not os.path.exists(directory):\n        raise OSError(\"The specified directory does not exist.\")\n    counter = Counter()\n    for extension in extensions:\n        files = glob.glob(os.path.join(directory, \"**\", f\"*{extension}\"), recursive=True)\n        counter.update(files)\n    return counter\n```"}
{"task_id": "BigCodeBench/962", "solution": "import os\nfrom pathlib import Path\nimport glob\nimport shutil\ndef task_func(source_directory: str, target_directory: str):\n    if not os.path.exists(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n\n    extensions = [\".txt\", \".docx\", \".xlsx\", \".csv\"]\n    files_moved = 0\n\n    for ext in extensions:\n        for file in glob.glob(source_directory + '/**/*' + ext, recursive=True):\n            file_path = Path(file)\n            target_file_path = Path(target_directory) / file_path.relative_to(source_directory)\n\n            if not target_file_path.exists():\n                shutil.move(file, target_directory)\n                files_moved += 1\n            else:\n                base, extension = os.path.splitext(target_file_path)\n                i = 1\n                while os.path.exists(target_file_path):\n                    target_file_path = Path(target_directory) / f\"{base}-{i}{extension}\"\n                    i += 1\n                shutil.move(file, target_file_path)\n                files_moved += 1\n\n    return files_moved", "raw_solution": "import os\nfrom pathlib import Path\nimport glob\nimport shutil\n\ndef task_func(source_directory: str, target_directory: str):\n    if not os.path.exists(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n\n    extensions = [\".txt\", \".docx\", \".xlsx\", \".csv\"]\n    files_moved = 0\n\n    for ext in extensions:\n        for file in glob.glob(source_directory + '/**/*' + ext, recursive=True):\n            file_path = Path(file)\n            target_file_path = Path(target_directory) / file_path.relative_to(source_directory)\n\n            if not target_file_path.exists():\n                shutil.move(file, target_directory)\n                files_moved += 1\n            else:\n                base, extension = os.path.splitext(target_file_path)\n                i = 1\n                while os.path.exists(target_file_path):\n                    target_file_path = Path(target_directory) / f\"{base}-{i}{extension}\"\n                    i += 1\n                shutil.move(file, target_file_path)\n                files_moved += 1\n\n    return files_moved\n```"}
{"task_id": "BigCodeBench/963", "solution": "import os\nimport glob\nfrom pathlib import Path\nimport zipfile\ndef task_func(source_directory, target_directory, zip_name):\n    valid_extensions = ['.txt', '.docx', '.xlsx', '.csv']\n    if not os.path.exists(source_directory):\n        raise OSError(\"Source directory does not exist.\")\n    zip_path = os.path.join(target_directory, zip_name + \".zip\")\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for ext in valid_extensions:\n            for file in glob.glob(os.path.join(source_directory, \"*\" + ext)):\n                zipf.write(file, arcname=os.path.basename(file))\n    return zip_path", "raw_solution": "import os\nimport glob\nfrom pathlib import Path\nimport zipfile\n\ndef task_func(source_directory, target_directory, zip_name):\n    valid_extensions = ['.txt', '.docx', '.xlsx', '.csv']\n    if not os.path.exists(source_directory):\n        raise OSError(\"Source directory does not exist.\")\n    zip_path = os.path.join(target_directory, zip_name + \".zip\")\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for ext in valid_extensions:\n            for file in glob.glob(os.path.join(source_directory, \"*\" + ext)):\n                zipf.write(file, arcname=os.path.basename(file))\n    return zip_path\n```"}
{"task_id": "BigCodeBench/964", "solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nimport docx\ndef task_func(source_directory: str, target_directory: str) -> int:\n    if not os.path.exists(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n\n    converted_count = 0\n    for filename in os.listdir(source_directory):\n        if filename.endswith(\".txt\"):\n            with open(os.path.join(source_directory, filename), 'r') as file:\n                text = file.read()\n                df = pd.DataFrame({'Text': [text]})\n                df.to_csv(os.path.join(target_directory, filename.replace(\".txt\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".docx\"):\n            doc = docx.Document(os.path.join(source_directory, filename))\n            text = ' '.join([p.text for p in doc.paragraphs])\n            df = pd.DataFrame({'Text': [text]})\n            df.to_csv(os.path.join(target_directory, filename.replace(\".docx\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".xlsx\"):\n            df = pd.read_excel(os.path.join(source_directory, filename))\n            df.to_csv(os.path.join(target_directory, filename.replace(\".xlsx\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".csv\"):\n            df = pd.read_csv(os.path.join(source_directory, filename))\n            df.to_csv(os.path.join(target_directory, filename), index=False)\n            converted_count += 1\n\n    return converted_count", "raw_solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nimport docx\n\ndef task_func(source_directory: str, target_directory: str) -> int:\n    if not os.path.exists(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n\n    converted_count = 0\n    for filename in os.listdir(source_directory):\n        if filename.endswith(\".txt\"):\n            with open(os.path.join(source_directory, filename), 'r') as file:\n                text = file.read()\n                df = pd.DataFrame({'Text': [text]})\n                df.to_csv(os.path.join(target_directory, filename.replace(\".txt\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".docx\"):\n            doc = docx.Document(os.path.join(source_directory, filename))\n            text = ' '.join([p.text for p in doc.paragraphs])\n            df = pd.DataFrame({'Text': [text]})\n            df.to_csv(os.path.join(target_directory, filename.replace(\".docx\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".xlsx\"):\n            df = pd.read_excel(os.path.join(source_directory, filename))\n            df.to_csv(os.path.join(target_directory, filename.replace(\".xlsx\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".csv\"):\n            df = pd.read_csv(os.path.join(source_directory, filename))\n            df.to_csv(os.path.join(target_directory, filename), index=False)\n            converted_count += 1\n\n    return converted_count\n```"}
{"task_id": "BigCodeBench/965", "solution": "import os\nimport re\nimport shutil\ndef task_func(source_directory: str, target_directory: str, pattern: str = r\"\\d{4}\") -> int:\n    if not os.path.exists(source_directory) or not os.path.isdir(source_directory):\n        return 0\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n    count = 0\n    for filename in os.listdir(source_directory):\n        if re.match(pattern, filename):\n            shutil.move(os.path.join(source_directory, filename), target_directory)\n            count += 1\n    return count", "raw_solution": "import os\nimport re\nimport shutil\n\ndef task_func(source_directory: str, target_directory: str, pattern: str = r\"\\d{4}\") -> int:\n    if not os.path.exists(source_directory) or not os.path.isdir(source_directory):\n        return 0\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n    count = 0\n    for filename in os.listdir(source_directory):\n        if re.match(pattern, filename):\n            shutil.move(os.path.join(source_directory, filename), target_directory)\n            count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/966", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not df.select_dtypes(include=[int, float]).empty:\n        raise ValueError(\"DataFrame contains non-numeric data\")\n\n    cumulative_sum = df.cumsum()\n    fig, ax = plt.subplots()\n    cumulative_sum.plot(kind='bar', ax=ax)\n    ax.set_title('Cumulative Sum per Column')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Cumulative Sum')\n    plt.legend(loc='upper left')\n    plt.tight_layout()\n\n    return cumulative_sum, fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not df.select_dtypes(include=[int, float]).empty:\n        raise ValueError(\"DataFrame contains non-numeric data\")\n\n    cumulative_sum = df.cumsum()\n    fig, ax = plt.subplots()\n    cumulative_sum.plot(kind='bar', ax=ax)\n    ax.set_title('Cumulative Sum per Column')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Cumulative Sum')\n    plt.legend(loc='upper left')\n    plt.tight_layout()\n\n    return cumulative_sum, fig\n```"}
{"task_id": "BigCodeBench/967", "solution": "import numpy as np\nfrom scipy import integrate\nimport matplotlib.pyplot as plt\ndef task_func(func, x_range=(-2, 2), num_points=1000):\n    x = np.linspace(x_range[0], x_range[1], num_points)\n    y = [func(i) for i in x]\n    integral = integrate.cumtrapz(y, x, initial=0)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y, label='Function')\n    ax.plot(x, integral, label='Integral')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.legend()\n    plt.show()\n    return ax", "raw_solution": "import numpy as np\nfrom scipy import integrate\nimport matplotlib.pyplot as plt\n\ndef task_func(func, x_range=(-2, 2), num_points=1000):\n    x = np.linspace(x_range[0], x_range[1], num_points)\n    y = [func(i) for i in x]\n    integral = integrate.cumtrapz(y, x, initial=0)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y, label='Function')\n    ax.plot(x, integral, label='Integral')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.legend()\n    plt.show()\n    return ax\n```"}
{"task_id": "BigCodeBench/968", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if data.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not any(data.dtypes == 'number'):\n        raise ValueError(\"No numeric columns are present\")\n\n    cumulative_sum = data.select_dtypes(include=['number']).cumsum()\n    heatmap = sns.heatmap(cumulative_sum, cmap=\"YlGnBu\")\n    plt.show()\n    return heatmap", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if data.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not any(data.dtypes == 'number'):\n        raise ValueError(\"No numeric columns are present\")\n\n    cumulative_sum = data.select_dtypes(include=['number']).cumsum()\n    heatmap = sns.heatmap(cumulative_sum, cmap=\"YlGnBu\")\n    plt.show()\n    return heatmap\n```"}
{"task_id": "BigCodeBench/969", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if df.isnull().values.any():\n        raise ValueError(\"DataFrame contains NaN values\")\n    if not df.select_dtypes(include=[np.number]).empty:\n        raise TypeError(\"DataFrame contains non-numeric data types\")\n\n    scaler = MinMaxScaler()\n    df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    df_cumulative = df_normalized.cumsum()\n\n    return df_cumulative", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if df.isnull().values.any():\n        raise ValueError(\"DataFrame contains NaN values\")\n    if not df.select_dtypes(include=[np.number]).empty:\n        raise TypeError(\"DataFrame contains non-numeric data types\")\n\n    scaler = MinMaxScaler()\n    df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    df_cumulative = df_normalized.cumsum()\n\n    return df_cumulative\n```"}
{"task_id": "BigCodeBench/970", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data: np.ndarray) -> plt.Axes:\n    if not isinstance(data, np.ndarray):\n        raise TypeError(\"Input data must be a NumPy array.\")\n    if np.any(np.isnan(data)):\n        raise ValueError(\"Input data must not contain NaNs.\")\n    if np.any(data < 0):\n        raise ValueError(\"Input data must not contain negative numbers.\")\n\n    sorted_data = np.sort(data)\n    cumulative_prob = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n\n    plt.plot(sorted_data, cumulative_prob, marker='o', linestyle='-')\n    plt.title(\"Cumulative Probability Plot\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Cumulative Probability\")\n\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data: np.ndarray) -> plt.Axes:\n    if not isinstance(data, np.ndarray):\n        raise TypeError(\"Input data must be a NumPy array.\")\n    if np.any(np.isnan(data)):\n        raise ValueError(\"Input data must not contain NaNs.\")\n    if np.any(data < 0):\n        raise ValueError(\"Input data must not contain negative numbers.\")\n\n    sorted_data = np.sort(data)\n    cumulative_prob = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n\n    plt.plot(sorted_data, cumulative_prob, marker='o', linestyle='-')\n    plt.title(\"Cumulative Probability Plot\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Cumulative Probability\")\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/971", "solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\ndef task_func(directory_path: str):\n    if not os.path.exists(directory_path):\n        raise ValueError(\"Directory does not exist\")\n\n    result = []\n    for file in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, file)\n        if os.path.isfile(file_path):\n            file_size = os.path.getsize(file_path)\n            creation_time = os.path.getctime(file_path)\n            modification_time = os.path.getmtime(file_path)\n            result.append((file, file_size, datetime.fromtimestamp(creation_time, tz=timezone.utc).isoformat(), datetime.fromtimestamp(modification_time, tz=timezone.utc).isoformat()))\n\n    return result", "raw_solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\n\ndef task_func(directory_path: str):\n    if not os.path.exists(directory_path):\n        raise ValueError(\"Directory does not exist\")\n\n    result = []\n    for file in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, file)\n        if os.path.isfile(file_path):\n            file_size = os.path.getsize(file_path)\n            creation_time = os.path.getctime(file_path)\n            modification_time = os.path.getmtime(file_path)\n            result.append((file, file_size, datetime.fromtimestamp(creation_time, tz=timezone.utc).isoformat(), datetime.fromtimestamp(modification_time, tz=timezone.utc).isoformat()))\n\n    return result\n```"}
{"task_id": "BigCodeBench/972", "solution": "import pathlib\nimport os\ndef task_func(path: str, delimiter: str = os.path.sep) -> list:\n    invalid_chars = ['<', '>', ':', '\"', '|', '?', '*']\n    for char in path:\n        if char in invalid_chars:\n            raise ValueError(\"Invalid characters in path\")\n    path = path.replace('\\\\', '/')\n    return path.split(delimiter)", "raw_solution": "import pathlib\nimport os\n\ndef task_func(path: str, delimiter: str = os.path.sep) -> list:\n    invalid_chars = ['<', '>', ':', '\"', '|', '?', '*']\n    for char in path:\n        if char in invalid_chars:\n            raise ValueError(\"Invalid characters in path\")\n    path = path.replace('\\\\', '/')\n    return path.split(delimiter)\n```"}
{"task_id": "BigCodeBench/973", "solution": "import os\nimport shutil\ndef task_func(path, delimiter=\"/\"):\n    if not isinstance(path, str) or not path:\n        raise ValueError(\"Invalid path\")\n    if not isinstance(delimiter, str) or not delimiter:\n        raise ValueError(\"Invalid delimiter\")\n    if not os.path.exists(path):\n        raise FileNotFoundError(\"Path does not exist\")\n\n    disk_usage = []\n    for component in path.split(delimiter):\n        if not component:\n            continue\n        usage = shutil.disk_usage(component)\n        disk_usage.append((component, {'total': usage.total, 'used': usage.used, 'free': usage.free}))\n    return disk_usage", "raw_solution": "import os\nimport shutil\n\ndef task_func(path, delimiter=\"/\"):\n    if not isinstance(path, str) or not path:\n        raise ValueError(\"Invalid path\")\n    if not isinstance(delimiter, str) or not delimiter:\n        raise ValueError(\"Invalid delimiter\")\n    if not os.path.exists(path):\n        raise FileNotFoundError(\"Path does not exist\")\n\n    disk_usage = []\n    for component in path.split(delimiter):\n        if not component:\n            continue\n        usage = shutil.disk_usage(component)\n        disk_usage.append((component, {'total': usage.total, 'used': usage.used, 'free': usage.free}))\n    return disk_usage\n```"}
{"task_id": "BigCodeBench/974", "solution": "import shutil\nimport pathlib\ndef task_func(source_path, destination_path):\n    source_path = pathlib.Path(source_path)\n    destination_path = pathlib.Path(destination_path)\n\n    if not source_path.exists() or not source_path.is_dir():\n        raise ValueError(\"Source path does not exist or is not a directory.\")\n\n    if not destination_path.exists() or not destination_path.is_dir():\n        raise ValueError(\"Destination path does not exist or is not a directory.\")\n\n    copied_files = []\n    for file in source_path.iterdir():\n        if file.is_file():\n            shutil.copy2(file, destination_path)\n            copied_files.append(file.name)\n\n    return (source_path.name, copied_files)", "raw_solution": "import shutil\nimport pathlib\n\ndef task_func(source_path, destination_path):\n    source_path = pathlib.Path(source_path)\n    destination_path = pathlib.Path(destination_path)\n\n    if not source_path.exists() or not source_path.is_dir():\n        raise ValueError(\"Source path does not exist or is not a directory.\")\n\n    if not destination_path.exists() or not destination_path.is_dir():\n        raise ValueError(\"Destination path does not exist or is not a directory.\")\n\n    copied_files = []\n    for file in source_path.iterdir():\n        if file.is_file():\n            shutil.copy2(file, destination_path)\n            copied_files.append(file.name)\n\n    return (source_path.name, copied_files)\n```"}
{"task_id": "BigCodeBench/975", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(rows, columns=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=0) -> pd.DataFrame:\n    np.random.seed(seed)\n    data = np.random.rand(rows, len(columns))\n    df = pd.DataFrame(data, columns=columns)\n    df = df.reindex(np.random.permutation(df.columns), axis=1)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(rows, columns=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=0) -> pd.DataFrame:\n    np.random.seed(seed)\n    data = np.random.rand(rows, len(columns))\n    df = pd.DataFrame(data, columns=columns)\n    df = df.reindex(np.random.permutation(df.columns), axis=1)\n    return df\n```"}
{"task_id": "BigCodeBench/976", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(records: np.ndarray, random_seed: int = 0) -> pd.DataFrame:\n    if records.ndim != 2:\n        raise ValueError(\"records must be a 2D array\")\n\n    np.random.seed(random_seed)\n    np.random.shuffle(records)\n\n    scaler = StandardScaler()\n    records = scaler.fit_transform(records)\n\n    feature_names = [f\"f{i+1}\" for i in range(records.shape[1])]\n    np.random.shuffle(feature_names)\n\n    return pd.DataFrame(records, columns=feature_names)", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(records: np.ndarray, random_seed: int = 0) -> pd.DataFrame:\n    if records.ndim != 2:\n        raise ValueError(\"records must be a 2D array\")\n\n    np.random.seed(random_seed)\n    np.random.shuffle(records)\n\n    scaler = StandardScaler()\n    records = scaler.fit_transform(records)\n\n    feature_names = [f\"f{i+1}\" for i in range(records.shape[1])]\n    np.random.shuffle(feature_names)\n\n    return pd.DataFrame(records, columns=feature_names)\n```"}
{"task_id": "BigCodeBench/977", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(array, features=None, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    if not isinstance(array, np.ndarray) or array.ndim != 2:\n        raise ValueError(\"'array' must be a 2-dimensional numpy array\")\n    if array.size == 0:\n        raise ValueError(\"'array' must not be empty\")\n    if features is not None:\n        if not isinstance(features, list) or len(features) != array.shape[1]:\n            raise ValueError(\"'features' must be a list of strings with the same length as the number of columns in 'array'\")\n    if features is None:\n        features = [str(i+1) for i in range(array.shape[1])]\n    np.random.shuffle(array.T)\n    ax = sns.heatmap(array, xticklabels=features, yticklabels=True, cmap=\"YlGnBu\")\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(array, features=None, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    if not isinstance(array, np.ndarray) or array.ndim != 2:\n        raise ValueError(\"'array' must be a 2-dimensional numpy array\")\n    if array.size == 0:\n        raise ValueError(\"'array' must not be empty\")\n    if features is not None:\n        if not isinstance(features, list) or len(features) != array.shape[1]:\n            raise ValueError(\"'features' must be a list of strings with the same length as the number of columns in 'array'\")\n    if features is None:\n        features = [str(i+1) for i in range(array.shape[1])]\n    np.random.shuffle(array.T)\n    ax = sns.heatmap(array, xticklabels=features, yticklabels=True, cmap=\"YlGnBu\")\n    return ax\n```"}
{"task_id": "BigCodeBench/978", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\ndef task_func(array, seed=None):\n    if array.ndim != 2:\n        raise ValueError(\"Input array must be 2D\")\n    if array.size == 0:\n        return pd.DataFrame()\n    np.random.seed(seed)\n    np.random.shuffle(array.T)\n    pca = PCA(n_components=2)\n    pca.fit(array)\n    components = pca.transform(array)\n    return pd.DataFrame(components, columns=['PC1', 'PC2'])", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\ndef task_func(array, seed=None):\n    if array.ndim != 2:\n        raise ValueError(\"Input array must be 2D\")\n    if array.size == 0:\n        return pd.DataFrame()\n    np.random.seed(seed)\n    np.random.shuffle(array.T)\n    pca = PCA(n_components=2)\n    pca.fit(array)\n    components = pca.transform(array)\n    return pd.DataFrame(components, columns=['PC1', 'PC2'])\n```"}
{"task_id": "BigCodeBench/979", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\ndef task_func(\n    feature_array,\n    target_array,\n    feature_names=[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\"],\n    target_name=\"target\",\n    seed=None,\n):\n    np.random.seed(seed)\n    df = pd.DataFrame(data=feature_array, columns=feature_names)\n    df[target_name] = target_array\n    df = df.sample(frac=1).reset_index(drop=True)\n    X = df.drop(columns=[target_name])\n    y = df[target_name]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n    clf = RandomForestClassifier(random_state=seed)\n    clf.fit(X_train, y_train)\n    return clf", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(\n    feature_array,\n    target_array,\n    feature_names=[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\"],\n    target_name=\"target\",\n    seed=None,\n):\n    np.random.seed(seed)\n    df = pd.DataFrame(data=feature_array, columns=feature_names)\n    df[target_name] = target_array\n    df = df.sample(frac=1).reset_index(drop=True)\n    X = df.drop(columns=[target_name])\n    y = df[target_name]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n    clf = RandomForestClassifier(random_state=seed)\n    clf.fit(X_train, y_train)\n    return clf\n```"}
{"task_id": "BigCodeBench/980", "solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not df.select_dtypes(include=[np.number]).columns.any():\n        raise ValueError(\"No numeric columns are present\")\n\n    # Standardize the numeric columns\n    scaler = StandardScaler()\n    df_standardized = pd.DataFrame(scaler.fit_transform(df.select_dtypes(include=[np.number])), columns=df.select_dtypes(include=[np.number]).columns)\n\n    # Create the correlation matrix\n    corr_matrix = df_standardized.corr()\n\n    # Create the heatmap\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n    plt.show()\n\n    return df_standardized, fig", "raw_solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not df.select_dtypes(include=[np.number]).columns.any():\n        raise ValueError(\"No numeric columns are present\")\n\n    # Standardize the numeric columns\n    scaler = StandardScaler()\n    df_standardized = pd.DataFrame(scaler.fit_transform(df.select_dtypes(include=[np.number])), columns=df.select_dtypes(include=[np.number]).columns)\n\n    # Create the correlation matrix\n    corr_matrix = df_standardized.corr()\n\n    # Create the heatmap\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n    plt.show()\n\n    return df_standardized, fig"}
{"task_id": "BigCodeBench/981", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\nimport matplotlib.pyplot as plt\ndef task_func(start_date, end_date, num_series, seed=None):\n    if start_date > end_date:\n        raise ValueError(\"start_date cannot be later than end_date\")\n    if num_series < 1:\n        raise ValueError(\"num_series must be greater than 0\")\n\n    random.seed(seed)\n\n    # Generate dates\n    dates = pd.date_range(start=start_date, end=end_date)\n\n    # Generate time series\n    data = {f'series_{i+1}': [random.randint(0, 100) for _ in range(len(dates))] for i in range(num_series)}\n\n    # Create DataFrame\n    df = pd.DataFrame(data, index=dates)\n\n    # Plot time series\n    fig, ax = plt.subplots()\n    df.plot(ax=ax)\n    ax.set_title(\"Random Time Series\")\n    ax.set_xlabel(\"Date\")\n    ax.set_ylabel(\"Value\")\n\n    return df, ax", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date, end_date, num_series, seed=None):\n    if start_date > end_date:\n        raise ValueError(\"start_date cannot be later than end_date\")\n    if num_series < 1:\n        raise ValueError(\"num_series must be greater than 0\")\n\n    random.seed(seed)\n\n    # Generate dates\n    dates = pd.date_range(start=start_date, end=end_date)\n\n    # Generate time series\n    data = {f'series_{i+1}': [random.randint(0, 100) for _ in range(len(dates))] for i in range(num_series)}\n\n    # Create DataFrame\n    df = pd.DataFrame(data, index=dates)\n\n    # Plot time series\n    fig, ax = plt.subplots()\n    df.plot(ax=ax)\n    ax.set_title(\"Random Time Series\")\n    ax.set_xlabel(\"Date\")\n    ax.set_ylabel(\"Value\")\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/982", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(df, column, bins=30, density=True, alpha=0.6, color=\"g\", seed=None):\n    np.random.seed(seed)\n    data = df[column].dropna()\n    mu, std = norm.fit(data)\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, std)\n    plt.hist(data, bins=bins, density=density, alpha=alpha, color=color)\n    plt.plot(x, p, 'k', linewidth=2)\n    plt.show()\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(df, column, bins=30, density=True, alpha=0.6, color=\"g\", seed=None):\n    np.random.seed(seed)\n    data = df[column].dropna()\n    mu, std = norm.fit(data)\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, std)\n    plt.hist(data, bins=bins, density=density, alpha=alpha, color=color)\n    plt.plot(x, p, 'k', linewidth=2)\n    plt.show()\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/983", "solution": "import seaborn as sns\nimport numpy as np\nimport pandas as pd\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not df.select_dtypes(include=[np.number]).empty:\n        raise TypeError(\"DataFrame contains non-numeric data types\")\n\n    covariance_df = df.cov()\n    pair_plot = sns.pairplot(df)\n\n    return covariance_df, pair_plot", "raw_solution": "import seaborn as sns\nimport numpy as np\nimport pandas as pd\n\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not df.select_dtypes(include=[np.number]).empty:\n        raise TypeError(\"DataFrame contains non-numeric data types\")\n\n    covariance_df = df.cov()\n    pair_plot = sns.pairplot(df)\n\n    return covariance_df, pair_plot\n```"}
{"task_id": "BigCodeBench/984", "solution": "import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef task_func(df, x_column, y_column):\n    # Create a scatter plot\n    plt.scatter(df[x_column], df[y_column])\n    plt.xlabel(x_column)\n    plt.ylabel(y_column)\n\n    # Fit a linear regression model\n    model = LinearRegression()\n    model.fit(df[[x_column]], df[y_column])\n\n    # Create a line of best fit\n    x_fit = np.linspace(df[x_column].min(), df[x_column].max(), 100)\n    y_fit = model.predict(x_fit[:, np.newaxis])\n\n    # Plot the line of best fit\n    plt.plot(x_fit, y_fit, color='red')\n\n    return plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(df, x_column, y_column):\n    # Create a scatter plot\n    plt.scatter(df[x_column], df[y_column])\n    plt.xlabel(x_column)\n    plt.ylabel(y_column)\n\n    # Fit a linear regression model\n    model = LinearRegression()\n    model.fit(df[[x_column]], df[y_column])\n\n    # Create a line of best fit\n    x_fit = np.linspace(df[x_column].min(), df[x_column].max(), 100)\n    y_fit = model.predict(x_fit[:, np.newaxis])\n\n    # Plot the line of best fit\n    plt.plot(x_fit, y_fit, color='red')\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/985", "solution": "import pandas as pd\nimport json\nimport os\nimport math\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    try:\n        data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON data\")\n    if not data:\n        raise ValueError(\"Empty JSON data\")\n    report = []\n    for country, population in data.items():\n        if not isinstance(country, str):\n            raise ValueError(\"Non-string country names\")\n        if not isinstance(population, (int, float)) or population < 0:\n            raise ValueError(\"Non-numeric or negative populations\")\n        report.append({\"Country\": country, \"Population\": int(population)})\n    df = pd.DataFrame(report)\n    file_path = os.path.join(output_dir, file_name)\n    try:\n        df.to_csv(file_path, index=False)\n    except IOError:\n        raise IOError(\"Cannot write to the specified directory\")\n    return file_path, df", "raw_solution": "import pandas as pd\nimport json\nimport os\nimport math\n\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    try:\n        data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON data\")\n    if not data:\n        raise ValueError(\"Empty JSON data\")\n    report = []\n    for country, population in data.items():\n        if not isinstance(country, str):\n            raise ValueError(\"Non-string country names\")\n        if not isinstance(population, (int, float)) or population < 0:\n            raise ValueError(\"Non-numeric or negative populations\")\n        report.append({\"Country\": country, \"Population\": int(population)})\n    df = pd.DataFrame(report)\n    file_path = os.path.join(output_dir, file_name)\n    try:\n        df.to_csv(file_path, index=False)\n    except IOError:\n        raise IOError(\"Cannot write to the specified directory\")\n    return file_path, df\n```"}
{"task_id": "BigCodeBench/986", "solution": "import json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\ndef task_func(json_data: str, key_path: list):\n    data = json.loads(json_data)\n    for key in key_path:\n        try:\n            data = data[key]\n        except KeyError:\n            raise KeyError(f\"Key '{key}' not found in JSON data.\")\n    if not isinstance(data, list) or not all(isinstance(item, (int, float)) for item in data):\n        raise ValueError(\"No numeric data found or data string is empty or corrupted.\")\n    df = pd.DataFrame(data, columns=[\"Value\"])\n    fig, ax = plt.subplots()\n    sns.boxplot(x=\"Value\", data=df, ax=ax)\n    return fig", "raw_solution": "import json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\ndef task_func(json_data: str, key_path: list):\n    data = json.loads(json_data)\n    for key in key_path:\n        try:\n            data = data[key]\n        except KeyError:\n            raise KeyError(f\"Key '{key}' not found in JSON data.\")\n    if not isinstance(data, list) or not all(isinstance(item, (int, float)) for item in data):\n        raise ValueError(\"No numeric data found or data string is empty or corrupted.\")\n    df = pd.DataFrame(data, columns=[\"Value\"])\n    fig, ax = plt.subplots()\n    sns.boxplot(x=\"Value\", data=df, ax=ax)\n    return fig\n```"}
{"task_id": "BigCodeBench/987", "solution": "import json\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(json_data: str, data_key: str):\n    data = json.loads(json_data)\n    if data_key not in data:\n        raise KeyError(f\"Key path {data_key} not found in the given data.\")\n    data = pd.Series(data[data_key])\n    if data.empty:\n        return data, None, None\n    scaler = MinMaxScaler()\n    data_scaled = scaler.fit_transform(data.values.reshape(-1, 1))\n    data_scaled = pd.Series(data_scaled.flatten(), index=data.index)\n    fig, ax = plt.subplots()\n    ax.plot(data.index, data.values, label=\"Original Data\")\n    ax.plot(data_scaled.index, data_scaled.values, label=\"Normalized Data\")\n    ax.set_title(\"Comparison of Original and Normalized Data\")\n    ax.set_xlabel(\"Index\")\n    ax.set_ylabel(\"Value\")\n    ax.legend()\n    return data, data_scaled, ax", "raw_solution": "import json\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(json_data: str, data_key: str):\n    data = json.loads(json_data)\n    if data_key not in data:\n        raise KeyError(f\"Key path {data_key} not found in the given data.\")\n    data = pd.Series(data[data_key])\n    if data.empty:\n        return data, None, None\n    scaler = MinMaxScaler()\n    data_scaled = scaler.fit_transform(data.values.reshape(-1, 1))\n    data_scaled = pd.Series(data_scaled.flatten(), index=data.index)\n    fig, ax = plt.subplots()\n    ax.plot(data.index, data.values, label=\"Original Data\")\n    ax.plot(data_scaled.index, data_scaled.values, label=\"Normalized Data\")\n    ax.set_title(\"Comparison of Original and Normalized Data\")\n    ax.set_xlabel(\"Index\")\n    ax.set_ylabel(\"Value\")\n    ax.legend()\n    return data, data_scaled, ax"}
{"task_id": "BigCodeBench/988", "solution": "import os\nimport re\nfrom pathlib import Path\ndef task_func(dir_path: str, predicates: list) -> dict:\n    if not predicates:\n        raise ValueError(\"No valid predicates provided\")\n    if not os.path.exists(dir_path) or not os.path.isdir(dir_path):\n        raise FileNotFoundError(\"Specified directory does not exist or is not a directory\")\n    result = {}\n    for item in os.listdir(dir_path):\n        item_path = os.path.join(dir_path, item)\n        if os.path.isfile(item_path):\n            for predicate in predicates:\n                if re.search(predicate, item):\n                    result[item] = True\n                    break\n        elif os.path.isdir(item_path):\n            for predicate in predicates:\n                if re.search(predicate, item):\n                    result[item] = True\n                    break\n    return result", "raw_solution": "import os\nimport re\nfrom pathlib import Path\n\ndef task_func(dir_path: str, predicates: list) -> dict:\n    if not predicates:\n        raise ValueError(\"No valid predicates provided\")\n    if not os.path.exists(dir_path) or not os.path.isdir(dir_path):\n        raise FileNotFoundError(\"Specified directory does not exist or is not a directory\")\n    result = {}\n    for item in os.listdir(dir_path):\n        item_path = os.path.join(dir_path, item)\n        if os.path.isfile(item_path):\n            for predicate in predicates:\n                if re.search(predicate, item):\n                    result[item] = True\n                    break\n        elif os.path.isdir(item_path):\n            for predicate in predicates:\n                if re.search(predicate, item):\n                    result[item] = True\n                    break\n    return result\n```"}
{"task_id": "BigCodeBench/989", "solution": "import random\nimport string\ndef task_func(length: int, predicates: list, seed: int = None):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    if seed is not None:\n        random.seed(seed)\n    text = ''.join(random.choices(string.ascii_letters + string.digits + string.punctuation, k=length))\n    characteristics = {}\n    for predicate in predicates:\n        if predicate == 'has_upper':\n            characteristics[predicate] = any(char.isupper() for char in text)\n        elif predicate == 'has_lower':\n            characteristics[predicate] = any(char.islower() for char in text)\n        elif predicate == 'has_digit':\n            characteristics[predicate] = any(char.isdigit() for char in text)\n        elif predicate == 'has_punctuation':\n            characteristics[predicate] = any(char in string.punctuation for char in text)\n        else:\n            raise KeyError(f\"Unrecognized predicate: {predicate}\")\n    return text, characteristics", "raw_solution": "import random\nimport string\n\ndef task_func(length: int, predicates: list, seed: int = None):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    if seed is not None:\n        random.seed(seed)\n    text = ''.join(random.choices(string.ascii_letters + string.digits + string.punctuation, k=length))\n    characteristics = {}\n    for predicate in predicates:\n        if predicate == 'has_upper':\n            characteristics[predicate] = any(char.isupper() for char in text)\n        elif predicate == 'has_lower':\n            characteristics[predicate] = any(char.islower() for char in text)\n        elif predicate == 'has_digit':\n            characteristics[predicate] = any(char.isdigit() for char in text)\n        elif predicate == 'has_punctuation':\n            characteristics[predicate] = any(char in string.punctuation for char in text)\n        else:\n            raise KeyError(f\"Unrecognized predicate: {predicate}\")\n    return text, characteristics\n```"}
{"task_id": "BigCodeBench/990", "solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\ndef task_func(hex_string):\n    # Decode hexadecimal string to bytes\n    bytes_obj = binascii.unhexlify(hex_string)\n\n    # Convert bytes to UTF-8 string\n    utf8_string = bytes_obj.decode('utf-8')\n\n    # Encode UTF-8 string to various formats\n    hex_encoded = binascii.hexlify(bytes_obj).decode('utf-8')\n    base64_encoded = base64.b64encode(bytes_obj).decode('utf-8')\n    utf16_encoded = utf8_string.encode('utf-16').decode('utf-8')\n    utf32_encoded = utf8_string.encode('utf-32').decode('utf-8')\n    ascii_encoded = 'Not representable in ASCII'\n    try:\n        ascii_encoded = utf8_string.encode('ascii').decode('utf-8')\n    except UnicodeEncodeError:\n        pass\n    url_encoded = urllib.parse.quote(utf8_string)\n    rot13_encoded = codecs.encode(utf8_string, 'rot_13')\n\n    # Return dictionary of encoded strings\n    return {\n        'hex': hex_encoded,\n        'base64': base64_encoded,\n        'utf-8': utf8_string,\n        'utf-16': utf16_encoded,\n        'utf-32': utf32_encoded,\n        'ASCII': ascii_encoded,\n        'URL': url_encoded,\n        'ROT13': rot13_encoded\n    }", "raw_solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\n\ndef task_func(hex_string):\n    # Decode hexadecimal string to bytes\n    bytes_obj = binascii.unhexlify(hex_string)\n\n    # Convert bytes to UTF-8 string\n    utf8_string = bytes_obj.decode('utf-8')\n\n    # Encode UTF-8 string to various formats\n    hex_encoded = binascii.hexlify(bytes_obj).decode('utf-8')\n    base64_encoded = base64.b64encode(bytes_obj).decode('utf-8')\n    utf16_encoded = utf8_string.encode('utf-16').decode('utf-8')\n    utf32_encoded = utf8_string.encode('utf-32').decode('utf-8')\n    ascii_encoded = 'Not representable in ASCII'\n    try:\n        ascii_encoded = utf8_string.encode('ascii').decode('utf-8')\n    except UnicodeEncodeError:\n        pass\n    url_encoded = urllib.parse.quote(utf8_string)\n    rot13_encoded = codecs.encode(utf8_string, 'rot_13')\n\n    # Return dictionary of encoded strings\n    return {\n        'hex': hex_encoded,\n        'base64': base64_encoded,\n        'utf-8': utf8_string,\n        'utf-16': utf16_encoded,\n        'utf-32': utf32_encoded,\n        'ASCII': ascii_encoded,\n        'URL': url_encoded,\n        'ROT13': rot13_encoded\n    }\n```"}
{"task_id": "BigCodeBench/991", "solution": "import binascii\nimport string\nimport random\ndef task_func(length):\n    hex_string = ''.join(random.choices(string.hexdigits, k=length))\n    try:\n        ascii_string = binascii.unhexlify(hex_string).decode('utf-8')\n    except UnicodeDecodeError:\n        ascii_string = 'Decoding failed'\n    return ascii_string", "raw_solution": "import binascii\nimport string\nimport random\n\ndef task_func(length):\n    hex_string = ''.join(random.choices(string.hexdigits, k=length))\n    try:\n        ascii_string = binascii.unhexlify(hex_string).decode('utf-8')\n    except UnicodeDecodeError:\n        ascii_string = 'Decoding failed'\n    return ascii_string\n```"}
{"task_id": "BigCodeBench/992", "solution": "import sys\nimport sqlite3\nPATH_TO_APPEND = \"path/to/whatever\"\nDATABASE = \"path/to/database.db\"\ndef task_func(path_to_append=PATH_TO_APPEND, database=DATABASE):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Connect to the SQLite database\n    conn = sqlite3.connect(database)\n    c = conn.cursor()\n\n    # Create the table if it doesn't exist\n    c.execute('''\n        CREATE TABLE IF NOT EXISTS paths\n        (path TEXT PRIMARY KEY)\n    ''')\n\n    # Insert the path into the table, avoiding duplicates\n    c.execute('''\n        INSERT OR IGNORE INTO paths (path) VALUES (?)\n    ''', (path_to_append,))\n\n    # Commit the changes and close the connection\n    conn.commit()\n    conn.close()\n\n    # Return the path that was appended to sys.path and inserted into the database\n    return path_to_append", "raw_solution": "import sys\nimport sqlite3\n\n# Constants\nPATH_TO_APPEND = \"path/to/whatever\"\nDATABASE = \"path/to/database.db\"\n\ndef task_func(path_to_append=PATH_TO_APPEND, database=DATABASE):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Connect to the SQLite database\n    conn = sqlite3.connect(database)\n    c = conn.cursor()\n\n    # Create the table if it doesn't exist\n    c.execute('''\n        CREATE TABLE IF NOT EXISTS paths\n        (path TEXT PRIMARY KEY)\n    ''')\n\n    # Insert the path into the table, avoiding duplicates\n    c.execute('''\n        INSERT OR IGNORE INTO paths (path) VALUES (?)\n    ''', (path_to_append,))\n\n    # Commit the changes and close the connection\n    conn.commit()\n    conn.close()\n\n    # Return the path that was appended to sys.path and inserted into the database\n    return path_to_append\n```"}
{"task_id": "BigCodeBench/993", "solution": "import re\nfrom scipy.stats import gaussian_kde\nfrom scipy import linalg\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    word_lengths = [len(word) for word in words]\n\n    fig, ax = plt.subplots()\n    ax.hist(word_lengths, bins=20, color='blue', alpha=0.5)\n    ax.set_xlabel('Word Length')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Word Length Distribution')\n\n    if len(word_lengths) > 1:\n        kde = gaussian_kde(word_lengths)\n        x_range = np.linspace(min(word_lengths), max(word_lengths), 100)\n        ax.plot(x_range, kde(x_range), color='red')\n\n    return ax", "raw_solution": "import re\nfrom scipy.stats import gaussian_kde\nfrom scipy import linalg\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    word_lengths = [len(word) for word in words]\n\n    fig, ax = plt.subplots()\n    ax.hist(word_lengths, bins=20, color='blue', alpha=0.5)\n    ax.set_xlabel('Word Length')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Word Length Distribution')\n\n    if len(word_lengths) > 1:\n        kde = gaussian_kde(word_lengths)\n        x_range = np.linspace(min(word_lengths), max(word_lengths), 100)\n        ax.plot(x_range, kde(x_range), color='red')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/994", "solution": "import requests\nimport pandas as pd\nfrom bs4 import BeautifulSoup\ndef task_func(url: str, csv_file_path: str) -> list:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        raise RuntimeError(f\"Error fetching URL: {e}\")\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    data = []\n\n    for container in soup.find_all('div', class_='container'):\n        title = container.find('h1')\n        date = container.find('span', class_='date')\n        author = container.find('span', class_='author')\n\n        data.append((\n            title.text if title else 'No Title',\n            date.text if date else 'No Date',\n            author.text if author else 'No Author'\n        ))\n\n    df = pd.DataFrame(data, columns=['Title', 'Date', 'Author'])\n    df.to_csv(csv_file_path, index=False)\n\n    return data", "raw_solution": "import requests\nimport pandas as pd\nfrom bs4 import BeautifulSoup\n\ndef task_func(url: str, csv_file_path: str) -> list:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        raise RuntimeError(f\"Error fetching URL: {e}\")\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    data = []\n\n    for container in soup.find_all('div', class_='container'):\n        title = container.find('h1')\n        date = container.find('span', class_='date')\n        author = container.find('span', class_='author')\n\n        data.append((\n            title.text if title else 'No Title',\n            date.text if date else 'No Date',\n            author.text if author else 'No Author'\n        ))\n\n    df = pd.DataFrame(data, columns=['Title', 'Date', 'Author'])\n    df.to_csv(csv_file_path, index=False)\n\n    return data\n```"}
{"task_id": "BigCodeBench/995", "solution": "import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(file_path: str, plot_path: str) -> (float, float, str):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"File not found\")\n\n    df = pd.read_csv(file_path)\n    df = df.select_dtypes(include=[np.number])\n\n    if df.empty:\n        return (np.nan, np.nan, plot_path)\n\n    mean = df.mean().mean()\n    median = df.median().median()\n\n    df.plot(kind='line', title='Data Visualization', xlabel='Index', ylabel='Value')\n    plt.savefig(plot_path)\n\n    return (mean, median, plot_path)", "raw_solution": "import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(file_path: str, plot_path: str) -> (float, float, str):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"File not found\")\n\n    df = pd.read_csv(file_path)\n    df = df.select_dtypes(include=[np.number])\n\n    if df.empty:\n        return (np.nan, np.nan, plot_path)\n\n    mean = df.mean().mean()\n    median = df.median().median()\n\n    df.plot(kind='line', title='Data Visualization', xlabel='Index', ylabel='Value')\n    plt.savefig(plot_path)\n\n    return (mean, median, plot_path)\n```"}
{"task_id": "BigCodeBench/996", "solution": "import requests\nimport json\nfrom bs4 import BeautifulSoup\ndef task_func(url: str, file_name: str = \"Output.txt\") -> str:\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        title = soup.title.string if soup.title else None\n    except requests.exceptions.RequestException:\n        title = None\n\n    data = {\"url\": url, \"title\": title}\n\n    with open(file_name, 'a') as file:\n        file.write(json.dumps(data) + '\\n')\n\n    return file_name", "raw_solution": "import requests\nimport json\nfrom bs4 import BeautifulSoup\n\ndef task_func(url: str, file_name: str = \"Output.txt\") -> str:\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        title = soup.title.string if soup.title else None\n    except requests.exceptions.RequestException:\n        title = None\n\n    data = {\"url\": url, \"title\": title}\n\n    with open(file_name, 'a') as file:\n        file.write(json.dumps(data) + '\\n')\n\n    return file_name\n```"}
{"task_id": "BigCodeBench/997", "solution": "import urllib.request\nimport os\nimport zipfile\nTARGET_DIR = \"downloaded_files\"\nTARGET_ZIP_FILE = \"downloaded_files.zip\"\ndef task_func(url):\n    # Create target directory if it doesn't exist\n    if not os.path.exists(TARGET_DIR):\n        os.makedirs(TARGET_DIR)\n\n    # Download the zip file\n    urllib.request.urlretrieve(url, TARGET_ZIP_FILE)\n\n    # Extract the zip file\n    with zipfile.ZipFile(TARGET_ZIP_FILE, 'r') as zip_ref:\n        zip_ref.extractall(TARGET_DIR)\n\n    # Delete the local zip file\n    os.remove(TARGET_ZIP_FILE)\n\n    return TARGET_DIR", "raw_solution": "import urllib.request\nimport os\nimport zipfile\n\n# Constants\nTARGET_DIR = \"downloaded_files\"\nTARGET_ZIP_FILE = \"downloaded_files.zip\"\n\ndef task_func(url):\n    # Create target directory if it doesn't exist\n    if not os.path.exists(TARGET_DIR):\n        os.makedirs(TARGET_DIR)\n\n    # Download the zip file\n    urllib.request.urlretrieve(url, TARGET_ZIP_FILE)\n\n    # Extract the zip file\n    with zipfile.ZipFile(TARGET_ZIP_FILE, 'r') as zip_ref:\n        zip_ref.extractall(TARGET_DIR)\n\n    # Delete the local zip file\n    os.remove(TARGET_ZIP_FILE)\n\n    return TARGET_DIR\n```"}
{"task_id": "BigCodeBench/998", "solution": "import urllib.request\nimport os\nimport hashlib\nimport tarfile\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5_CHECKSUM = \"d41d8cd98f00b204e9800998ecf8427e\"\ndef task_func(url):\n    try:\n        # Download the file\n        urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n    except Exception as e:\n        print(f\"Failed to download file: {e}\")\n        return False\n\n    # Calculate the MD5 checksum of the downloaded file\n    md5_hash = hashlib.md5()\n    with open(TARGET_TAR_FILE, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            md5_hash.update(chunk)\n    calculated_md5_checksum = md5_hash.hexdigest()\n\n    # Check if the calculated checksum matches the expected value\n    if calculated_md5_checksum != EXPECTED_MD5_CHECKSUM:\n        print(\"Checksum does not match the expected value.\")\n        # Delete the downloaded file\n        os.remove(TARGET_TAR_FILE)\n        return False\n\n    # Extract the contents of the tar.gz file\n    try:\n        with tarfile.open(TARGET_TAR_FILE, \"r:gz\") as tar:\n            tar.extractall()\n    except Exception as e:\n        print(f\"Failed to extract file: {e}\")\n        # Delete the downloaded file\n        os.remove(TARGET_TAR_FILE)\n        return False\n\n    # Delete the downloaded file\n    os.remove(TARGET_TAR_FILE)\n\n    return True", "raw_solution": "import urllib.request\nimport os\nimport hashlib\nimport tarfile\n\n# Constants\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5_CHECKSUM = \"d41d8cd98f00b204e9800998ecf8427e\"\n\ndef task_func(url):\n    try:\n        # Download the file\n        urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n    except Exception as e:\n        print(f\"Failed to download file: {e}\")\n        return False\n\n    # Calculate the MD5 checksum of the downloaded file\n    md5_hash = hashlib.md5()\n    with open(TARGET_TAR_FILE, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            md5_hash.update(chunk)\n    calculated_md5_checksum = md5_hash.hexdigest()\n\n    # Check if the calculated checksum matches the expected value\n    if calculated_md5_checksum != EXPECTED_MD5_CHECKSUM:\n        print(\"Checksum does not match the expected value.\")\n        # Delete the downloaded file\n        os.remove(TARGET_TAR_FILE)\n        return False\n\n    # Extract the contents of the tar.gz file\n    try:\n        with tarfile.open(TARGET_TAR_FILE, \"r:gz\") as tar:\n            tar.extractall()\n    except Exception as e:\n        print(f\"Failed to extract file: {e}\")\n        # Delete the downloaded file\n        os.remove(TARGET_TAR_FILE)\n        return False\n\n    # Delete the downloaded file\n    os.remove(TARGET_TAR_FILE)\n\n    return True\n```"}
{"task_id": "BigCodeBench/999", "solution": "import urllib.request\nimport os\nimport csv\nimport collections\ndef task_func(url, column_name, csv_file_path):\n    try:\n        urllib.request.urlretrieve(url, csv_file_path)\n    except Exception as e:\n        print(f\"Error downloading file: {e}\")\n        return\n\n    try:\n        with open(csv_file_path, 'r') as file:\n            reader = csv.DictReader(file)\n            column_values = [row[column_name] for row in reader if column_name in row]\n    except KeyError:\n        print(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n        os.remove(csv_file_path)\n        raise ValueError(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n    except Exception as e:\n        print(f\"Error reading CSV file: {e}\")\n        os.remove(csv_file_path)\n        return\n\n    os.remove(csv_file_path)\n    return dict(collections.Counter(column_values))", "raw_solution": "import urllib.request\nimport os\nimport csv\nimport collections\n\ndef task_func(url, column_name, csv_file_path):\n    try:\n        urllib.request.urlretrieve(url, csv_file_path)\n    except Exception as e:\n        print(f\"Error downloading file: {e}\")\n        return\n\n    try:\n        with open(csv_file_path, 'r') as file:\n            reader = csv.DictReader(file)\n            column_values = [row[column_name] for row in reader if column_name in row]\n    except KeyError:\n        print(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n        os.remove(csv_file_path)\n        raise ValueError(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n    except Exception as e:\n        print(f\"Error reading CSV file: {e}\")\n        os.remove(csv_file_path)\n        return\n\n    os.remove(csv_file_path)\n    return dict(collections.Counter(column_values))\n```"}
{"task_id": "BigCodeBench/1000", "solution": "import urllib.request\nimport os\nimport json\nimport pandas as pd\nTARGET_JSON_FILE = \"downloaded_file.json\"\ndef task_func(url):\n    # Download the JSON file\n    urllib.request.urlretrieve(url, TARGET_JSON_FILE)\n\n    # Read the JSON file\n    with open(TARGET_JSON_FILE, 'r') as file:\n        data = json.load(file)\n\n    # Convert the JSON data into a DataFrame\n    df = pd.DataFrame(data)\n\n    # Delete the temporary JSON file\n    os.remove(TARGET_JSON_FILE)\n\n    return df", "raw_solution": "import urllib.request\nimport os\nimport json\nimport pandas as pd\n\n# Constants\nTARGET_JSON_FILE = \"downloaded_file.json\"\n\ndef task_func(url):\n    # Download the JSON file\n    urllib.request.urlretrieve(url, TARGET_JSON_FILE)\n\n    # Read the JSON file\n    with open(TARGET_JSON_FILE, 'r') as file:\n        data = json.load(file)\n\n    # Convert the JSON data into a DataFrame\n    df = pd.DataFrame(data)\n\n    # Delete the temporary JSON file\n    os.remove(TARGET_JSON_FILE)\n\n    return df\n```"}
{"task_id": "BigCodeBench/1001", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(csv_file_path: str):\n    # Read data from CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Normalize 'column1'\n    df['column1'] = (df['column1'] - df['column1'].mean()) / df['column1'].std()\n\n    # Create plot\n    fig, ax = plt.subplots()\n    ax.hist(df['column1'], bins=30, color='blue', edgecolor='black')\n\n    # Set plot title\n    ax.set_title('{:^20}: {:^20}'.format('Plot Title', 'Normalized Column 1'))\n\n    # Set x-label\n    ax.set_xlabel('{:^20}: {:^20}'.format('Index', 'Normalized Value'))\n\n    # Set y-label\n    ax.set_ylabel('{:^20}: {:^20}'.format('Frequency', 'Normalized Value'))\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file_path: str):\n    # Read data from CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Normalize 'column1'\n    df['column1'] = (df['column1'] - df['column1'].mean()) / df['column1'].std()\n\n    # Create plot\n    fig, ax = plt.subplots()\n    ax.hist(df['column1'], bins=30, color='blue', edgecolor='black')\n\n    # Set plot title\n    ax.set_title('{:^20}: {:^20}'.format('Plot Title', 'Normalized Column 1'))\n\n    # Set x-label\n    ax.set_xlabel('{:^20}: {:^20}'.format('Index', 'Normalized Value'))\n\n    # Set y-label\n    ax.set_ylabel('{:^20}: {:^20}'.format('Frequency', 'Normalized Value'))\n\n    return ax\n```"}
{"task_id": "BigCodeBench/1002", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data, column_name=\"target_column\"):\n    df = pd.read_json(data)\n    if column_name not in df.columns:\n        raise ValueError(f\"Column '{column_name}' does not exist in the DataFrame.\")\n    df[column_name] = pd.Categorical(df[column_name]).codes\n    ax = df[column_name].hist(bins=10)\n    ax.set_title(f'Histogram of {column_name}')\n    ax.set_xlabel(column_name)\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data, column_name=\"target_column\"):\n    df = pd.read_json(data)\n    if column_name not in df.columns:\n        raise ValueError(f\"Column '{column_name}' does not exist in the DataFrame.\")\n    df[column_name] = pd.Categorical(df[column_name]).codes\n    ax = df[column_name].hist(bins=10)\n    ax.set_title(f'Histogram of {column_name}')\n    ax.set_xlabel(column_name)\n    return df, ax\n```"}
{"task_id": "BigCodeBench/1003", "solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\ndef task_func(url):\n    try:\n        response = urllib.request.urlopen(url)\n        xml_data = response.read()\n    except urllib.error.URLError:\n        raise ValueError(\"URL is invalid or XML file cannot be fetched from the URL.\")\n\n    try:\n        root = etree.fromstring(xml_data)\n    except etree.XMLSyntaxError:\n        raise ValueError(\"XML file has invalid syntax.\")\n\n    items = root.findall('item')\n    if not items:\n        raise ValueError(\"XML structure does not match expected format.\")\n\n    data = []\n    for item in items:\n        row = {}\n        for child in item:\n            row[child.tag] = child.text\n        data.append(row)\n\n    return pd.DataFrame(data)", "raw_solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\n\ndef task_func(url):\n    try:\n        response = urllib.request.urlopen(url)\n        xml_data = response.read()\n    except urllib.error.URLError:\n        raise ValueError(\"URL is invalid or XML file cannot be fetched from the URL.\")\n\n    try:\n        root = etree.fromstring(xml_data)\n    except etree.XMLSyntaxError:\n        raise ValueError(\"XML file has invalid syntax.\")\n\n    items = root.findall('item')\n    if not items:\n        raise ValueError(\"XML structure does not match expected format.\")\n\n    data = []\n    for item in items:\n        row = {}\n        for child in item:\n            row[child.tag] = child.text\n        data.append(row)\n\n    return pd.DataFrame(data)"}
{"task_id": "BigCodeBench/1004", "solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(url):\n    # Download the text file\n    response = urllib.request.urlopen(url)\n    text = response.read().decode('utf-8')\n\n    # Extract words from the text\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Count the frequency of each word\n    word_count = Counter(words)\n\n    # Create a bar chart of the ten most common words\n    fig, ax = plt.subplots()\n    ax.bar(word_count.most_common(10)[::-1], word_count.most_common(10)[::-1])\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Word Frequency')\n\n    return word_count, ax", "raw_solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(url):\n    # Download the text file\n    response = urllib.request.urlopen(url)\n    text = response.read().decode('utf-8')\n\n    # Extract words from the text\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Count the frequency of each word\n    word_count = Counter(words)\n\n    # Create a bar chart of the ten most common words\n    fig, ax = plt.subplots()\n    ax.bar(word_count.most_common(10)[::-1], word_count.most_common(10)[::-1])\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Word Frequency')\n\n    return word_count, ax\n```"}
{"task_id": "BigCodeBench/1005", "solution": "import urllib.request\nimport zipfile\nimport os\nimport urllib.error\ndef task_func(\n    url: str,\n    save_path: str = \"downloaded_file.zip\",\n    extract_path: str = \"extracted_files\",\n) -> str:\n    try:\n        urllib.request.urlretrieve(url, save_path)\n    except urllib.error.URLError as e:\n        return f\"URL Error: {str(e)}\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    try:\n        with zipfile.ZipFile(save_path, 'r') as zip_ref:\n            zip_ref.extractall(extract_path)\n    except zipfile.BadZipFile as e:\n        return f\"ZIP Error: {str(e)}\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    try:\n        os.remove(save_path)\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    return extract_path", "raw_solution": "import urllib.request\nimport zipfile\nimport os\nimport urllib.error\n\ndef task_func(\n    url: str,\n    save_path: str = \"downloaded_file.zip\",\n    extract_path: str = \"extracted_files\",\n) -> str:\n    try:\n        urllib.request.urlretrieve(url, save_path)\n    except urllib.error.URLError as e:\n        return f\"URL Error: {str(e)}\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    try:\n        with zipfile.ZipFile(save_path, 'r') as zip_ref:\n            zip_ref.extractall(extract_path)\n    except zipfile.BadZipFile as e:\n        return f\"ZIP Error: {str(e)}\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    try:\n        os.remove(save_path)\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    return extract_path\n```"}
{"task_id": "BigCodeBench/1006", "solution": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        return \"Error: Unable to download the file from the provided URL.\"\n\n    if response.headers.get('content-type') != 'application/zip':\n        return \"Error: The URL does not point to a ZIP file.\"\n\n    file_path = os.path.join(download_path, \"file.zip\")\n    with open(file_path, 'wb') as f:\n        f.write(response.content)\n\n    try:\n        with ZipFile(file_path, 'r') as zip_ref:\n            zip_ref.test_zipfile()\n    except BadZipFile:\n        return \"Error: The downloaded file is not a valid ZIP file.\"\n\n    try:\n        with ZipFile(file_path, 'r') as zip_ref:\n            zip_ref.extractall(download_path)\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    return download_path", "raw_solution": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\n\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        return \"Error: Unable to download the file from the provided URL.\"\n\n    if response.headers.get('content-type') != 'application/zip':\n        return \"Error: The URL does not point to a ZIP file.\"\n\n    file_path = os.path.join(download_path, \"file.zip\")\n    with open(file_path, 'wb') as f:\n        f.write(response.content)\n\n    try:\n        with ZipFile(file_path, 'r') as zip_ref:\n            zip_ref.test_zipfile()\n    except BadZipFile:\n        return \"Error: The downloaded file is not a valid ZIP file.\"\n\n    try:\n        with ZipFile(file_path, 'r') as zip_ref:\n            zip_ref.extractall(download_path)\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    return download_path"}
{"task_id": "BigCodeBench/1007", "solution": "import requests\nimport pandas as pd\nfrom requests.exceptions import RequestException\ndef task_func(url: str) -> pd.DataFrame:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except RequestException as e:\n        raise SystemError(f\"Network error: {str(e)}\")\n\n    try:\n        data = response.json()\n    except ValueError:\n        raise ValueError(\"Invalid JSON format\")\n\n    return pd.DataFrame(data)", "raw_solution": "import requests\nimport pandas as pd\nfrom requests.exceptions import RequestException\n\ndef task_func(url: str) -> pd.DataFrame:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except RequestException as e:\n        raise SystemError(f\"Network error: {str(e)}\")\n\n    try:\n        data = response.json()\n    except ValueError:\n        raise ValueError(\"Invalid JSON format\")\n\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/1008", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        raise errh\n    except requests.exceptions.RequestException as err:\n        raise err\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    table = soup.find('table', {'id': table_id})\n\n    if table is None:\n        raise ValueError(\"Table with the specified ID not found.\")\n\n    table_data = StringIO(table.prettify())\n    df = pd.read_html(table_data)[0]\n\n    return df", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\n\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        raise errh\n    except requests.exceptions.RequestException as err:\n        raise err\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    table = soup.find('table', {'id': table_id})\n\n    if table is None:\n        raise ValueError(\"Table with the specified ID not found.\")\n\n    table_data = StringIO(table.prettify())\n    df = pd.read_html(table_data)[0]\n\n    return df\n```"}
{"task_id": "BigCodeBench/1009", "solution": "import xml.etree.ElementTree as ET\nimport csv\ndef task_func(xml_content, output_csv_path):\n    try:\n        root = ET.fromstring(xml_content)\n    except ET.ParseError as e:\n        raise Exception(f\"XML parsing error: {str(e)}\")\n\n    try:\n        with open(output_csv_path, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for child in root:\n                writer.writerow([child.tag, child.text])\n    except IOError as e:\n        raise Exception(f\"IO error: {str(e)}\")", "raw_solution": "import xml.etree.ElementTree as ET\nimport csv\n\ndef task_func(xml_content, output_csv_path):\n    try:\n        root = ET.fromstring(xml_content)\n    except ET.ParseError as e:\n        raise Exception(f\"XML parsing error: {str(e)}\")\n\n    try:\n        with open(output_csv_path, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for child in root:\n                writer.writerow([child.tag, child.text])\n    except IOError as e:\n        raise Exception(f\"IO error: {str(e)}\")\n```"}
{"task_id": "BigCodeBench/1010", "solution": "import requests\nfrom PIL import Image\nimport io\ndef task_func(url):\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise ValueError(f\"Invalid URL or cannot reach within timeout period: {e}\")\n\n    if response.status_code not in range(200, 300):\n        raise ValueError(f\"Unsuccessful HTTP status code: {response.status_code}\")\n\n    try:\n        image = Image.open(io.BytesIO(response.content))\n    except IOError:\n        raise ValueError(\"Invalid image format\")\n\n    return image", "raw_solution": "import requests\nfrom PIL import Image\nimport io\n\ndef task_func(url):\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise ValueError(f\"Invalid URL or cannot reach within timeout period: {e}\")\n\n    if response.status_code not in range(200, 300):\n        raise ValueError(f\"Unsuccessful HTTP status code: {response.status_code}\")\n\n    try:\n        image = Image.open(io.BytesIO(response.content))\n    except IOError:\n        raise ValueError(\"Invalid image format\")\n\n    return image\n```"}
{"task_id": "BigCodeBench/1011", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(csv_file_path, col1_name=\"column1\", col2_name=\"column2\"):\n    # Read the CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Group by col1_name and calculate the mean of col2_name\n    grouped_df = df.groupby(col1_name)[col2_name].mean().reset_index()\n\n    # Create a bar plot\n    ax = grouped_df.plot(kind='bar', x=col1_name, y=col2_name, legend=False)\n\n    # Configure the plot\n    ax.set_title(f\"Mean of {col2_name} Grouped by {col1_name}\")\n    ax.set_xlabel(col1_name)\n    ax.set_ylabel(f\"Mean of {col2_name}\")\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file_path, col1_name=\"column1\", col2_name=\"column2\"):\n    # Read the CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Group by col1_name and calculate the mean of col2_name\n    grouped_df = df.groupby(col1_name)[col2_name].mean().reset_index()\n\n    # Create a bar plot\n    ax = grouped_df.plot(kind='bar', x=col1_name, y=col2_name, legend=False)\n\n    # Configure the plot\n    ax.set_title(f\"Mean of {col2_name} Grouped by {col1_name}\")\n    ax.set_xlabel(col1_name)\n    ax.set_ylabel(f\"Mean of {col2_name}\")\n\n    return ax\n```"}
{"task_id": "BigCodeBench/1012", "solution": "import requests\nfrom pathlib import Path\nimport zipfile\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\ndef task_func(url, filename):\n    try:\n        # Download the file\n        response = requests.get(url)\n        response.raise_for_status()\n\n        # Save the file\n        download_path = DOWNLOAD_DIR / filename\n        download_path.write_bytes(response.content)\n\n        # Extract the file\n        zip_path = DOWNLOAD_DIR / filename\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall(ZIP_DIR)\n\n        # Get the list of filenames in the unzipped directory\n        unzipped_files = [file.name for file in ZIP_DIR.iterdir()]\n\n        return \"Success\", unzipped_files\n\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {str(e)}\", []\n\n    except Exception as e:\n        return f\"Error: {str(e)}\", []", "raw_solution": "import requests\nfrom pathlib import Path\nimport zipfile\n\n# Constants\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\n\ndef task_func(url, filename):\n    try:\n        # Download the file\n        response = requests.get(url)\n        response.raise_for_status()\n\n        # Save the file\n        download_path = DOWNLOAD_DIR / filename\n        download_path.write_bytes(response.content)\n\n        # Extract the file\n        zip_path = DOWNLOAD_DIR / filename\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall(ZIP_DIR)\n\n        # Get the list of filenames in the unzipped directory\n        unzipped_files = [file.name for file in ZIP_DIR.iterdir()]\n\n        return \"Success\", unzipped_files\n\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {str(e)}\", []\n\n    except Exception as e:\n        return f\"Error: {str(e)}\", []\n```"}
{"task_id": "BigCodeBench/1013", "solution": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    links = set()\n\n    for link in soup.find_all('a'):\n        href = link.get('href')\n        if href and href.startswith('http'):\n            links.add(href)\n        elif href and href.startswith('/'):\n            links.add(urljoin(base_url, href))\n\n    with open(csv_file, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"URL\"])\n        for link in links:\n            writer.writerow([link])\n\n    return len(links)", "raw_solution": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\n\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    links = set()\n\n    for link in soup.find_all('a'):\n        href = link.get('href')\n        if href and href.startswith('http'):\n            links.add(href)\n        elif href and href.startswith('/'):\n            links.add(urljoin(base_url, href))\n\n    with open(csv_file, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"URL\"])\n        for link in links:\n            writer.writerow([link])\n\n    return len(links)\n```"}
{"task_id": "BigCodeBench/1014", "solution": "import requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(api_url):\n    if not isinstance(api_url, str):\n        raise TypeError(\"api_url must be a string\")\n    try:\n        response = requests.get(api_url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as err:\n        raise err\n    except Exception as e:\n        raise Exception(\"An error occurred: \", e)\n\n    data = response.json()\n    df = pd.DataFrame(data)\n\n    if df.empty:\n        return df, None\n\n    ax = df.plot(kind='bar')\n    plt.tight_layout()\n    return df, ax.figure", "raw_solution": "import requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(api_url):\n    if not isinstance(api_url, str):\n        raise TypeError(\"api_url must be a string\")\n    try:\n        response = requests.get(api_url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as err:\n        raise err\n    except Exception as e:\n        raise Exception(\"An error occurred: \", e)\n\n    data = response.json()\n    df = pd.DataFrame(data)\n\n    if df.empty:\n        return df, None\n\n    ax = df.plot(kind='bar')\n    plt.tight_layout()\n    return df, ax.figure\n```"}
{"task_id": "BigCodeBench/1015", "solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        raise requests.RequestException(f\"Error fetching data from {webpage_url}: {str(e)}\")\n\n    tree = html.fromstring(response.content)\n    table = tree.xpath('//table')\n\n    if not table:\n        return 0\n\n    table_data = pd.read_html(response.text)[0]\n\n    if table_data.empty:\n        return 0\n\n    try:\n        conn = sqlite3.connect(database_name)\n        cursor = conn.cursor()\n        cursor.execute('DROP TABLE IF EXISTS my_table')\n        table_data.to_sql('my_table', conn, if_exists='replace', index=False)\n        conn.commit()\n    except sqlite3.DatabaseError as e:\n        raise sqlite3.DatabaseError(f\"Error writing to SQLite database {database_name}: {str(e)}\")\n\n    return table_data.shape[0]", "raw_solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\n\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        raise requests.RequestException(f\"Error fetching data from {webpage_url}: {str(e)}\")\n\n    tree = html.fromstring(response.content)\n    table = tree.xpath('//table')\n\n    if not table:\n        return 0\n\n    table_data = pd.read_html(response.text)[0]\n\n    if table_data.empty:\n        return 0\n\n    try:\n        conn = sqlite3.connect(database_name)\n        cursor = conn.cursor()\n        cursor.execute('DROP TABLE IF EXISTS my_table')\n        table_data.to_sql('my_table', conn, if_exists='replace', index=False)\n        conn.commit()\n    except sqlite3.DatabaseError as e:\n        raise sqlite3.DatabaseError(f\"Error writing to SQLite database {database_name}: {str(e)}\")\n\n    return table_data.shape[0]"}
{"task_id": "BigCodeBench/1016", "solution": "import requests\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(url: str) -> \"matplotlib.axes._axes.Axes\":\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise ValueError(f\"Error downloading image: {str(e)}\")\n\n    try:\n        image = Image.open(BytesIO(response.content))\n    except IOError as e:\n        raise IOError(f\"Error processing image: {str(e)}\")\n\n    image = image.convert('L')\n    image_array = np.array(image)\n\n    histogram, bins = np.histogram(image_array, bins=256, range=(0, 256))\n\n    plt.bar(bins[:-1], histogram, width=1)\n    plt.xlabel('Grayscale Value')\n    plt.ylabel('Frequency')\n    plt.title('Grayscale Histogram')\n    plt.xlim([0, 256])\n    plt.ylim([0, np.max(histogram)])\n    plt.grid(True)\n\n    return plt.gca()", "raw_solution": "import requests\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(url: str) -> \"matplotlib.axes._axes.Axes\":\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise ValueError(f\"Error downloading image: {str(e)}\")\n\n    try:\n        image = Image.open(BytesIO(response.content))\n    except IOError as e:\n        raise IOError(f\"Error processing image: {str(e)}\")\n\n    image = image.convert('L')\n    image_array = np.array(image)\n\n    histogram, bins = np.histogram(image_array, bins=256, range=(0, 256))\n\n    plt.bar(bins[:-1], histogram, width=1)\n    plt.xlabel('Grayscale Value')\n    plt.ylabel('Frequency')\n    plt.title('Grayscale Histogram')\n    plt.xlim([0, 256])\n    plt.ylim([0, np.max(histogram)])\n    plt.grid(True)\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/1017", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\ndef task_func(csv_file_path, target_column=\"target\", test_size=0.2, n_estimators=100):\n    # Load the CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Check if the target_column exists in the DataFrame\n    if target_column not in df.columns:\n        raise ValueError(f\"The specified target_column '{target_column}' is not found in the CSV file.\")\n\n    # Split the DataFrame into features and target\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n\n    # Train the Random Forest classifier\n    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n    clf.fit(X_train, y_train)\n\n    # Predict the target values for the test set\n    y_pred = clf.predict(X_test)\n\n    # Generate and return the classification report\n    return classification_report(y_test, y_pred)", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\ndef task_func(csv_file_path, target_column=\"target\", test_size=0.2, n_estimators=100):\n    # Load the CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Check if the target_column exists in the DataFrame\n    if target_column not in df.columns:\n        raise ValueError(f\"The specified target_column '{target_column}' is not found in the CSV file.\")\n\n    # Split the DataFrame into features and target\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n\n    # Train the Random Forest classifier\n    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n    clf.fit(X_train, y_train)\n\n    # Predict the target values for the test set\n    y_pred = clf.predict(X_test)\n\n    # Generate and return the classification report\n    return classification_report(y_test, y_pred)\n```"}
{"task_id": "BigCodeBench/1018", "solution": "from bs4 import BeautifulSoup\nimport requests\ndef task_func(url=\"http://example.com\", from_encoding=\"cp1251\", use_lxml=False):\n    if not url:\n        return None\n    try:\n        response = requests.get(url)\n        if response.status_code != 200:\n            return None\n        content = response.content.decode(from_encoding)\n        return BeautifulSoup(content, 'lxml' if use_lxml else 'html.parser')\n    except (requests.exceptions.RequestException, UnicodeDecodeError):\n        return None", "raw_solution": "from bs4 import BeautifulSoup\nimport requests\n\ndef task_func(url=\"http://example.com\", from_encoding=\"cp1251\", use_lxml=False):\n    if not url:\n        return None\n    try:\n        response = requests.get(url)\n        if response.status_code != 200:\n            return None\n        content = response.content.decode(from_encoding)\n        return BeautifulSoup(content, 'lxml' if use_lxml else 'html.parser')\n    except (requests.exceptions.RequestException, UnicodeDecodeError):\n        return None\n```"}
{"task_id": "BigCodeBench/1019", "solution": "from PIL import Image\nimport codecs\nimport pytesseract\nIMAGE_PATH = \"image.png\"\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        image = Image.open(filename)\n        text = pytesseract.image_to_string(image)\n        return codecs.decode(text, from_encoding).encode(to_encoding).decode()\n    except (ValueError, LookupError) as e:\n        raise ValueError(f\"Error during conversion: {e}\")\n    except Exception as e:\n        return \"\"", "raw_solution": "from PIL import Image\nimport codecs\nimport pytesseract\n\nIMAGE_PATH = \"image.png\"\n\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        image = Image.open(filename)\n        text = pytesseract.image_to_string(image)\n        return codecs.decode(text, from_encoding).encode(to_encoding).decode()\n    except (ValueError, LookupError) as e:\n        raise ValueError(f\"Error during conversion: {e}\")\n    except Exception as e:\n        return \"\"\n```"}
{"task_id": "BigCodeBench/1020", "solution": "import json\nimport requests\nimport chardet\nAPI_URL = \"http://api.example.com/data\"\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    try:\n        response = requests.get(url, timeout=5)\n        content = response.content\n        if not content:\n            return {}\n        if not from_encoding:\n            from_encoding = chardet.detect(content)['encoding']\n        if not from_encoding:\n            raise ValueError(\"Unable to detect encoding for non-empty content\")\n        decoded_content = content.decode(from_encoding)\n        reencoded_content = decoded_content.encode(to_encoding)\n        return json.loads(reencoded_content)\n    except Exception as e:\n        raise e", "raw_solution": "import json\nimport requests\nimport chardet\n\n# Constants\nAPI_URL = \"http://api.example.com/data\"\n\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    try:\n        response = requests.get(url, timeout=5)\n        content = response.content\n        if not content:\n            return {}\n        if not from_encoding:\n            from_encoding = chardet.detect(content)['encoding']\n        if not from_encoding:\n            raise ValueError(\"Unable to detect encoding for non-empty content\")\n        decoded_content = content.decode(from_encoding)\n        reencoded_content = decoded_content.encode(to_encoding)\n        return json.loads(reencoded_content)\n    except Exception as e:\n        raise e\n```"}
{"task_id": "BigCodeBench/1021", "solution": "import binascii\nimport hashlib\ndef task_func(input_string, verify_hash=None):\n    if not isinstance(input_string, str):\n        raise TypeError(\"input_string must be a string\")\n    if verify_hash is not None and not isinstance(verify_hash, str):\n        raise TypeError(\"verify_hash must be a string or None\")\n\n    hash_object = hashlib.sha256(input_string.encode())\n    hex_dig = hash_object.hexdigest()\n\n    if verify_hash is not None:\n        return hex_dig, hex_dig == verify_hash\n    else:\n        return hex_dig", "raw_solution": "import binascii\nimport hashlib\n\ndef task_func(input_string, verify_hash=None):\n    if not isinstance(input_string, str):\n        raise TypeError(\"input_string must be a string\")\n    if verify_hash is not None and not isinstance(verify_hash, str):\n        raise TypeError(\"verify_hash must be a string or None\")\n\n    hash_object = hashlib.sha256(input_string.encode())\n    hex_dig = hash_object.hexdigest()\n\n    if verify_hash is not None:\n        return hex_dig, hex_dig == verify_hash\n    else:\n        return hex_dig\n```"}
{"task_id": "BigCodeBench/1022", "solution": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    if not os.path.exists(csv_file_path):\n        raise FileNotFoundError(f\"File {csv_file_path} not found\")\n    try:\n        df = pd.read_csv(csv_file_path)\n    except EmptyDataError:\n        return pd.DataFrame()\n    if column_name not in df.columns:\n        raise ValueError(f\"Column {column_name} not found in CSV file\")\n    df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n    df = df[df[column_name] >= datetime.now()]\n    df = df.sort_values(by=[column_name])\n    return df", "raw_solution": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\n\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    if not os.path.exists(csv_file_path):\n        raise FileNotFoundError(f\"File {csv_file_path} not found\")\n    try:\n        df = pd.read_csv(csv_file_path)\n    except EmptyDataError:\n        return pd.DataFrame()\n    if column_name not in df.columns:\n        raise ValueError(f\"Column {column_name} not found in CSV file\")\n    df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n    df = df[df[column_name] >= datetime.now()]\n    df = df.sort_values(by=[column_name])\n    return df\n```"}
{"task_id": "BigCodeBench/1023", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(dataframe):\n    if dataframe.empty:\n        raise ValueError(\"The input DataFrame is empty.\")\n    if dataframe.select_dtypes(include=[np.number]).columns.size < 2:\n        raise ValueError(\"The DataFrame has fewer than two numeric columns.\")\n    if not all(dataframe.dtypes == np.float64 or dataframe.dtypes == np.int64 for col in dataframe):\n        raise TypeError(\"All columns in the DataFrame should be numeric.\")\n\n    corr_matrix = dataframe.corr().abs()\n    unstacked_corr_matrix = corr_matrix.unstack()\n    sorted_pairs = unstacked_corr_matrix.sort_values(ascending=False, kind=\"quicksort\")\n    highest_correlation_pair = sorted_pairs.index[1]\n\n    fig, ax = plt.subplots()\n    ax.scatter(dataframe[highest_correlation_pair[0]], dataframe[highest_correlation_pair[1]])\n    ax.set_xlabel(highest_correlation_pair[0])\n    ax.set_ylabel(highest_correlation_pair[1])\n    ax.set_title(f\"Scatter plot of {highest_correlation_pair[0]} and {highest_correlation_pair[1]}\")\n    return ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(dataframe):\n    if dataframe.empty:\n        raise ValueError(\"The input DataFrame is empty.\")\n    if dataframe.select_dtypes(include=[np.number]).columns.size < 2:\n        raise ValueError(\"The DataFrame has fewer than two numeric columns.\")\n    if not all(dataframe.dtypes == np.float64 or dataframe.dtypes == np.int64 for col in dataframe):\n        raise TypeError(\"All columns in the DataFrame should be numeric.\")\n\n    corr_matrix = dataframe.corr().abs()\n    unstacked_corr_matrix = corr_matrix.unstack()\n    sorted_pairs = unstacked_corr_matrix.sort_values(ascending=False, kind=\"quicksort\")\n    highest_correlation_pair = sorted_pairs.index[1]\n\n    fig, ax = plt.subplots()\n    ax.scatter(dataframe[highest_correlation_pair[0]], dataframe[highest_correlation_pair[1]])\n    ax.set_xlabel(highest_correlation_pair[0])\n    ax.set_ylabel(highest_correlation_pair[1])\n    ax.set_title(f\"Scatter plot of {highest_correlation_pair[0]} and {highest_correlation_pair[1]}\")\n    return ax\n```"}
{"task_id": "BigCodeBench/1024", "solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nPLOT_TITLE = \"Value Distribution\"\ndef task_func(data_dict):\n    # Create a DataFrame from the dictionary\n    df = pd.DataFrame(list(data_dict.items()), columns=['Key', 'Value'])\n    # Remove None values\n    df = df[df['Value'].notna()]\n    # If the DataFrame is empty or all values are the same, return None\n    if df.empty or df['Value'].nunique() == 1:\n        return df, None\n    # Calculate the number of bins dynamically\n    num_bins = max(2, min(11, int(df.shape[0] / 2)))\n    # Generate the histogram\n    plot = sns.histplot(df['Value'], bins=num_bins, kde=False, color='blue')\n    plot.set_title(PLOT_TITLE)\n    return df, plot", "raw_solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\n# Constants\nPLOT_TITLE = \"Value Distribution\"\ndef task_func(data_dict):\n    # Create a DataFrame from the dictionary\n    df = pd.DataFrame(list(data_dict.items()), columns=['Key', 'Value'])\n    # Remove None values\n    df = df[df['Value'].notna()]\n    # If the DataFrame is empty or all values are the same, return None\n    if df.empty or df['Value'].nunique() == 1:\n        return df, None\n    # Calculate the number of bins dynamically\n    num_bins = max(2, min(11, int(df.shape[0] / 2)))\n    # Generate the histogram\n    plot = sns.histplot(df['Value'], bins=num_bins, kde=False, color='blue')\n    plot.set_title(PLOT_TITLE)\n    return df, plot\n```"}
{"task_id": "BigCodeBench/1025", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nPLOT_TITLE = \"Scaled Values\"\ndef task_func(data_dict):\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame(data_dict)\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the DataFrame\n    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    # Plot the scaled data\n    fig, ax = plt.subplots()\n    df_scaled.plot(kind='line', ax=ax)\n    ax.set_title(PLOT_TITLE)\n\n    return df_scaled, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Constants\nPLOT_TITLE = \"Scaled Values\"\n\ndef task_func(data_dict):\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame(data_dict)\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the DataFrame\n    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    # Plot the scaled data\n    fig, ax = plt.subplots()\n    df_scaled.plot(kind='line', ax=ax)\n    ax.set_title(PLOT_TITLE)\n\n    return df_scaled, ax\n```"}
{"task_id": "BigCodeBench/1026", "solution": "import numpy as np\nfrom scipy.stats import ttest_ind\nimport matplotlib.pyplot as plt\ndef task_func(kwargs):\n    group1 = kwargs.get('group1')\n    group2 = kwargs.get('group2')\n\n    if group1 is None or group2 is None:\n        raise ValueError(\"Both 'group1' and 'group2' must be provided.\")\n\n    group1 = np.array(group1)\n    group2 = np.array(group2)\n\n    if group1.size < 2 or group2.size < 2:\n        raise ValueError(\"Both groups must have at least two non-NaN values.\")\n\n    group1 = group1[~np.isnan(group1)]\n    group2 = group2[~np.isnan(group2)]\n\n    if group1.size < 2 or group2.size < 2:\n        raise ValueError(\"Both groups must have at least two non-NaN values.\")\n\n    if np.var(group1) < 1e-8 or np.var(group2) < 1e-8:\n        raise ValueError(\"Both groups must have a variance greater than 1e-8.\")\n\n    t_stat, p_val = ttest_ind(group1, group2, nan_policy='omit')\n\n    significant = p_val < 0.05\n\n    group1_stats = {\n        'mean': np.mean(group1),\n        'std_dev': np.std(group1)\n    }\n\n    group2_stats = {\n        'mean': np.mean(group2),\n        'std_dev': np.std(group2)\n    }\n\n    fig, (ax_boxplot, ax_histogram) = plt.subplots(2, 1, figsize=(10, 10))\n\n    ax_boxplot.boxplot([group1, group2], labels=['Group 1', 'Group 2'])\n    ax_boxplot.set_title('Boxplot Comparison of Groups')\n\n    ax_histogram.hist(group1, alpha=0.5, label='Group 1')\n    ax_histogram.hist(group2, alpha=0.5, label='Group 2')\n    ax_histogram.set_title('Histogram Comparison of Groups')\n    ax_histogram.legend()\n\n    plt.tight_layout()\n\n    return {\n        'significant': significant,\n        'group1_stats': group1_stats,\n        'group2_stats': group2_stats,\n        'ax_boxplot': ax_boxplot,\n        'ax_histogram': ax_histogram\n    }", "raw_solution": "import numpy as np\nfrom scipy.stats import ttest_ind\nimport matplotlib.pyplot as plt\n\ndef task_func(kwargs):\n    group1 = kwargs.get('group1')\n    group2 = kwargs.get('group2')\n\n    if group1 is None or group2 is None:\n        raise ValueError(\"Both 'group1' and 'group2' must be provided.\")\n\n    group1 = np.array(group1)\n    group2 = np.array(group2)\n\n    if group1.size < 2 or group2.size < 2:\n        raise ValueError(\"Both groups must have at least two non-NaN values.\")\n\n    group1 = group1[~np.isnan(group1)]\n    group2 = group2[~np.isnan(group2)]\n\n    if group1.size < 2 or group2.size < 2:\n        raise ValueError(\"Both groups must have at least two non-NaN values.\")\n\n    if np.var(group1) < 1e-8 or np.var(group2) < 1e-8:\n        raise ValueError(\"Both groups must have a variance greater than 1e-8.\")\n\n    t_stat, p_val = ttest_ind(group1, group2, nan_policy='omit')\n\n    significant = p_val < 0.05\n\n    group1_stats = {\n        'mean': np.mean(group1),\n        'std_dev': np.std(group1)\n    }\n\n    group2_stats = {\n        'mean': np.mean(group2),\n        'std_dev': np.std(group2)\n    }\n\n    fig, (ax_boxplot, ax_histogram) = plt.subplots(2, 1, figsize=(10, 10))\n\n    ax_boxplot.boxplot([group1, group2], labels=['Group 1', 'Group 2'])\n    ax_boxplot.set_title('Boxplot Comparison of Groups')\n\n    ax_histogram.hist(group1, alpha=0.5, label='Group 1')\n    ax_histogram.hist(group2, alpha=0.5, label='Group 2')\n    ax_histogram.set_title('Histogram Comparison of Groups')\n    ax_histogram.legend()\n\n    plt.tight_layout()\n\n    return {\n        'significant': significant,\n        'group1_stats': group1_stats,\n        'group2_stats': group2_stats,\n        'ax_boxplot': ax_boxplot,\n        'ax_histogram': ax_histogram\n    }\n```"}
{"task_id": "BigCodeBench/1027", "solution": "import binascii\nimport urllib.parse\ndef task_func(url):\n    try:\n        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(url).query)\n        hex_string = query_params.get('q', [None])[0]\n        if hex_string is None:\n            return None\n        decoded_string = binascii.unhexlify(hex_string).decode('utf-8')\n        return decoded_string\n    except binascii.Error:\n        return None", "raw_solution": "import binascii\nimport urllib.parse\n\ndef task_func(url):\n    try:\n        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(url).query)\n        hex_string = query_params.get('q', [None])[0]\n        if hex_string is None:\n            return None\n        decoded_string = binascii.unhexlify(hex_string).decode('utf-8')\n        return decoded_string\n    except binascii.Error:\n        return None\n```"}
{"task_id": "BigCodeBench/1028", "solution": "import subprocess\nimport time\nimport json\nimport platform\nLOGFILE_PATH = \"logfile.log\"\ndef task_func(interval, duration):\n    if interval <= 0 or duration <= 0:\n        raise ValueError(\"Interval and duration must be greater than 0\")\n\n    if platform.system() == \"Windows\":\n        command = \"wmic cpu get loadpercentage\"\n    else:\n        command = \"top -bn1 | grep \\\"Cpu(s)\\\" | sed \\\"s/.*, *\\\\([0-9.]*\\\\)%* id.*/\\1/\\\" | awk '{print 100 - $1}'\"\n\n    start_time = time.time()\n    with open(LOGFILE_PATH, \"w\") as logfile:\n        while time.time() - start_time <= duration:\n            cpu_usage = subprocess.check_output(command, shell=True).decode().strip()\n            timestamp = time.time()\n            logfile.write(json.dumps({\"timestamp\": timestamp, \"cpu_usage\": cpu_usage}) + \"\\n\")\n            logfile.flush()\n            time.sleep(interval)\n\n    return LOGFILE_PATH", "raw_solution": "import subprocess\nimport time\nimport json\nimport platform\n\nLOGFILE_PATH = \"logfile.log\"\n\ndef task_func(interval, duration):\n    if interval <= 0 or duration <= 0:\n        raise ValueError(\"Interval and duration must be greater than 0\")\n\n    if platform.system() == \"Windows\":\n        command = \"wmic cpu get loadpercentage\"\n    else:\n        command = \"top -bn1 | grep \\\"Cpu(s)\\\" | sed \\\"s/.*, *\\\\([0-9.]*\\\\)%* id.*/\\1/\\\" | awk '{print 100 - $1}'\"\n\n    start_time = time.time()\n    with open(LOGFILE_PATH, \"w\") as logfile:\n        while time.time() - start_time <= duration:\n            cpu_usage = subprocess.check_output(command, shell=True).decode().strip()\n            timestamp = time.time()\n            logfile.write(json.dumps({\"timestamp\": timestamp, \"cpu_usage\": cpu_usage}) + \"\\n\")\n            logfile.flush()\n            time.sleep(interval)\n\n    return LOGFILE_PATH\n```"}
{"task_id": "BigCodeBench/1029", "solution": "import pandas as pd\nimport numpy as np\nimport string\ndef task_func(rows=100, columns=3):\n    alphabets = string.ascii_lowercase\n    df = pd.DataFrame(np.random.choice(list(alphabets), size=(rows, columns)))\n    df.columns = [chr(65 + i) for i in range(columns)]\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport string\n\ndef task_func(rows=100, columns=3):\n    alphabets = string.ascii_lowercase\n    df = pd.DataFrame(np.random.choice(list(alphabets), size=(rows, columns)))\n    df.columns = [chr(65 + i) for i in range(columns)]\n    return df\n```"}
{"task_id": "BigCodeBench/1030", "solution": "import itertools\nimport string\nimport pandas as pd\ndef task_func():\n    alphabet = string.ascii_lowercase\n    combinations = list(itertools.product(alphabet, repeat=3))\n    df = pd.DataFrame(combinations, columns=['Letter1', 'Letter2', 'Letter3'])\n    return df", "raw_solution": "import itertools\nimport string\nimport pandas as pd\n\ndef task_func():\n    alphabet = string.ascii_lowercase\n    combinations = list(itertools.product(alphabet, repeat=3))\n    df = pd.DataFrame(combinations, columns=['Letter1', 'Letter2', 'Letter3'])\n    return df\n```"}
{"task_id": "BigCodeBench/1031", "solution": "import random\nimport string\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(n_rows=1000):\n    if n_rows <= 0:\n        raise ValueError(\"n_rows must be greater than 0\")\n\n    # Generate random 3-letter strings\n    strings = [''.join(random.choices(string.ascii_lowercase, k=3)) for _ in range(n_rows)]\n\n    # Count the frequency of each string\n    freq = pd.Series(strings).value_counts()\n\n    # Get the top 30 most common strings\n    top_30 = freq.nlargest(30)\n\n    # Plot the histogram\n    fig, ax = plt.subplots()\n    top_30.plot(kind='bar', ax=ax)\n    ax.set_xlabel('String')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of Top 30 Unique Random 3-Letter Strings')\n\n    return ax", "raw_solution": "import random\nimport string\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(n_rows=1000):\n    if n_rows <= 0:\n        raise ValueError(\"n_rows must be greater than 0\")\n\n    # Generate random 3-letter strings\n    strings = [''.join(random.choices(string.ascii_lowercase, k=3)) for _ in range(n_rows)]\n\n    # Count the frequency of each string\n    freq = pd.Series(strings).value_counts()\n\n    # Get the top 30 most common strings\n    top_30 = freq.nlargest(30)\n\n    # Plot the histogram\n    fig, ax = plt.subplots()\n    top_30.plot(kind='bar', ax=ax)\n    ax.set_xlabel('String')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of Top 30 Unique Random 3-Letter Strings')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/1032", "solution": "import matplotlib.pyplot as plt\nimport random\nimport string\nimport pandas as pd\nimport seaborn as sns\nLETTERS = list(string.ascii_lowercase)\ndef task_func(rows=1000, string_length=3):\n    if rows == 0:\n        print(\"No data to generate heatmap.\")\n        return None\n    # Generate random strings\n    strings = [''.join(random.choices(LETTERS, k=string_length)) for _ in range(rows)]\n    # Convert strings to one-hot encoded format\n    df = pd.get_dummies(strings)\n    # Calculate frequency of each letter\n    freq = df.sum().to_dict()\n    # Create a DataFrame with frequencies\n    freq_df = pd.DataFrame(freq, index=[0])\n    # Create a heatmap\n    plt.figure(figsize=(10, 10))\n    sns.heatmap(freq_df, annot=True, cmap='viridis')\n    plt.title('Frequency of each letter in strings')\n    plt.show()", "raw_solution": "import matplotlib.pyplot as plt\nimport random\nimport string\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nLETTERS = list(string.ascii_lowercase)\n\ndef task_func(rows=1000, string_length=3):\n    if rows == 0:\n        print(\"No data to generate heatmap.\")\n        return None\n    # Generate random strings\n    strings = [''.join(random.choices(LETTERS, k=string_length)) for _ in range(rows)]\n    # Convert strings to one-hot encoded format\n    df = pd.get_dummies(strings)\n    # Calculate frequency of each letter\n    freq = df.sum().to_dict()\n    # Create a DataFrame with frequencies\n    freq_df = pd.DataFrame(freq, index=[0])\n    # Create a heatmap\n    plt.figure(figsize=(10, 10))\n    sns.heatmap(freq_df, annot=True, cmap='viridis')\n    plt.title('Frequency of each letter in strings')\n    plt.show()\n```"}
{"task_id": "BigCodeBench/1033", "solution": "import itertools\nimport string\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func():\n    # Generate all possible 3-letter combinations\n    combinations = [''.join(x) for x in itertools.product(string.ascii_lowercase, repeat=3)]\n\n    # Create a DataFrame from the combinations\n    df = pd.DataFrame(combinations, columns=['Combination'])\n\n    # Count the frequency of the first letters in the combinations\n    first_letter_counts = df['Combination'].str[0].value_counts()\n\n    # Plot a histogram of the frequency of the first letters\n    fig, ax = plt.subplots()\n    first_letter_counts.plot(kind='bar', ax=ax)\n    ax.set_xlabel('First Letter')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of First Letters in 3-Letter Combinations')\n\n    return df, ax", "raw_solution": "import itertools\nimport string\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    # Generate all possible 3-letter combinations\n    combinations = [''.join(x) for x in itertools.product(string.ascii_lowercase, repeat=3)]\n\n    # Create a DataFrame from the combinations\n    df = pd.DataFrame(combinations, columns=['Combination'])\n\n    # Count the frequency of the first letters in the combinations\n    first_letter_counts = df['Combination'].str[0].value_counts()\n\n    # Plot a histogram of the frequency of the first letters\n    fig, ax = plt.subplots()\n    first_letter_counts.plot(kind='bar', ax=ax)\n    ax.set_xlabel('First Letter')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of First Letters in 3-Letter Combinations')\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/1034", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import distance\nCATEGORIES = [\"Electronics\", \"Clothing\", \"Home Decor\", \"Automotive\", \"Books\"]\ndef task_func(s1, s2):\n    s1 = pd.Series(s1, index=CATEGORIES)\n    s2 = pd.Series(s2, index=CATEGORIES)\n    common_categories = s1[s1 > 200].index.intersection(s2[s2 > 200].index)\n    if len(common_categories) == 0:\n        return None, 0.0\n    common_sales = s1[common_categories]\n    common_sales_2 = s2[common_categories]\n    euclidean_distance = distance.euclidean(common_sales, common_sales_2)\n    common_sales.plot(kind='bar', title='Categories with Sales Exceeding 200')\n    plt.show()\n    return common_sales.plot(kind='bar', title='Categories with Sales Exceeding 200'), euclidean_distance", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import distance\n\nCATEGORIES = [\"Electronics\", \"Clothing\", \"Home Decor\", \"Automotive\", \"Books\"]\n\ndef task_func(s1, s2):\n    s1 = pd.Series(s1, index=CATEGORIES)\n    s2 = pd.Series(s2, index=CATEGORIES)\n    common_categories = s1[s1 > 200].index.intersection(s2[s2 > 200].index)\n    if len(common_categories) == 0:\n        return None, 0.0\n    common_sales = s1[common_categories]\n    common_sales_2 = s2[common_categories]\n    euclidean_distance = distance.euclidean(common_sales, common_sales_2)\n    common_sales.plot(kind='bar', title='Categories with Sales Exceeding 200')\n    plt.show()\n    return common_sales.plot(kind='bar', title='Categories with Sales Exceeding 200'), euclidean_distance"}
{"task_id": "BigCodeBench/1035", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(feature: pd.Series, target: pd.Series) -> (np.ndarray, plt.Axes):\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(feature.values.reshape(-1, 1), target, test_size=0.2, random_state=42)\n\n    # Train the logistic regression model\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n\n    # Predict the target for the test set\n    y_pred = model.predict(X_test)\n\n    # Create the confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n\n    # Create the confusion matrix plot\n    fig, ax = plt.subplots(figsize=(5, 5))\n    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', ax=ax)\n    ax.set_xlabel('Predicted')\n    ax.set_ylabel('Actual')\n    ax.set_title('Confusion Matrix')\n\n    return cm, ax", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(feature: pd.Series, target: pd.Series) -> (np.ndarray, plt.Axes):\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(feature.values.reshape(-1, 1), target, test_size=0.2, random_state=42)\n\n    # Train the logistic regression model\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n\n    # Predict the target for the test set\n    y_pred = model.predict(X_test)\n\n    # Create the confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n\n    # Create the confusion matrix plot\n    fig, ax = plt.subplots(figsize=(5, 5))\n    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', ax=ax)\n    ax.set_xlabel('Predicted')\n    ax.set_ylabel('Actual')\n    ax.set_title('Confusion Matrix')\n\n    return cm, ax\n```"}
{"task_id": "BigCodeBench/1036", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(s1, s2):\n    # Create a DataFrame from the two Series\n    df = pd.DataFrame({'s1': s1, 's2': s2})\n    \n    # Create a swarm plot\n    ax = sns.swarmplot(x='s1', y='s2', data=df)\n    \n    # Highlight the intersecting data points\n    intersecting_data = df[df['s1'] == df['s2']]\n    for i, row in intersecting_data.iterrows():\n        ax.plot(row['s1'], row['s2'], 'ro')\n        ax.plot(row['s1'], row['s2'], 'r--')\n    \n    # Return the Axes object and the number of intersecting data points\n    return ax, len(intersecting_data)", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(s1, s2):\n    # Create a DataFrame from the two Series\n    df = pd.DataFrame({'s1': s1, 's2': s2})\n    \n    # Create a swarm plot\n    ax = sns.swarmplot(x='s1', y='s2', data=df)\n    \n    # Highlight the intersecting data points\n    intersecting_data = df[df['s1'] == df['s2']]\n    for i, row in intersecting_data.iterrows():\n        ax.plot(row['s1'], row['s2'], 'ro')\n        ax.plot(row['s1'], row['s2'], 'r--')\n    \n    # Return the Axes object and the number of intersecting data points\n    return ax, len(intersecting_data)\n```"}
{"task_id": "BigCodeBench/1037", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(s1, s2, n_clusters=3):\n    if not isinstance(s1, pd.Series) or not isinstance(s2, pd.Series):\n        raise ValueError(\"s1 and s2 must be pandas Series\")\n    if len(s1) != len(s2):\n        raise ValueError(\"s1 and s2 must have the same length\")\n\n    data = pd.concat([s1, s2], axis=1)\n    kmeans = KMeans(n_clusters=n_clusters)\n    labels = kmeans.fit_predict(data)\n\n    plt.figure(figsize=(8, 6))\n    plt.scatter(data[0], data[1], c=labels, cmap='viridis')\n    plt.title(\"K-Means Clustering\")\n    plt.xlabel(s1.name)\n    plt.ylabel(s2.name)\n    plt.legend(title=\"Clusters\")\n    plt.tight_layout()\n\n    return labels, plt.gca()", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(s1, s2, n_clusters=3):\n    if not isinstance(s1, pd.Series) or not isinstance(s2, pd.Series):\n        raise ValueError(\"s1 and s2 must be pandas Series\")\n    if len(s1) != len(s2):\n        raise ValueError(\"s1 and s2 must have the same length\")\n\n    data = pd.concat([s1, s2], axis=1)\n    kmeans = KMeans(n_clusters=n_clusters)\n    labels = kmeans.fit_predict(data)\n\n    plt.figure(figsize=(8, 6))\n    plt.scatter(data[0], data[1], c=labels, cmap='viridis')\n    plt.title(\"K-Means Clustering\")\n    plt.xlabel(s1.name)\n    plt.ylabel(s2.name)\n    plt.legend(title=\"Clusters\")\n    plt.tight_layout()\n\n    return labels, plt.gca()\n```"}
{"task_id": "BigCodeBench/1038", "solution": "from datetime import datetime\nimport json\ndef task_func(client_socket):\n    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    message = {\"time\": current_time, \"greeting\": \"Hello, Client!\"}\n    client_socket.send(json.dumps(message).encode())", "raw_solution": "from datetime import datetime\nimport json\n\ndef task_func(client_socket):\n    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    message = {\"time\": current_time, \"greeting\": \"Hello, Client!\"}\n    client_socket.send(json.dumps(message).encode())\n```"}
{"task_id": "BigCodeBench/1039", "solution": "import ssl\nimport os\nimport hashlib\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n    context.load_cert_chain(cert_file, key_file)\n    server_socket = context.wrap_socket(client_socket, server_side=True)\n    try:\n        file_path = server_socket.recv(buffer_size).decode()\n        if os.path.isfile(file_path):\n            with open(file_path, 'rb') as file:\n                file_data = file.read()\n                file_hash = hashlib.sha256(file_data).hexdigest()\n            return file_hash\n        else:\n            return 'File not found'\n    except Exception as e:\n        return str(e)", "raw_solution": "import ssl\nimport os\nimport hashlib\n\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n    context.load_cert_chain(cert_file, key_file)\n    server_socket = context.wrap_socket(client_socket, server_side=True)\n    try:\n        file_path = server_socket.recv(buffer_size).decode()\n        if os.path.isfile(file_path):\n            with open(file_path, 'rb') as file:\n                file_data = file.read()\n                file_hash = hashlib.sha256(file_data).hexdigest()\n            return file_hash\n        else:\n            return 'File not found'\n    except Exception as e:\n        return str(e)\n```"}
{"task_id": "BigCodeBench/1040", "solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_socket.bind((server_address, server_port))\n    server_socket.listen(5)\n\n    inputs = [server_socket]\n    outputs = []\n    message_queues = {}\n\n    start_time = datetime.now()\n    while (datetime.now() - start_time).seconds < run_duration:\n        readable, writable, exceptional = select.select(inputs, outputs, inputs)\n\n        for sock in readable:\n            if sock is server_socket:\n                connection, client_address = sock.accept()\n                print(f\"Accepted connection from {client_address}\")\n                connection.setblocking(0)\n                inputs.append(connection)\n                message_queues[connection] = queue.Queue()\n            else:\n                data = sock.recv(buffer_size)\n                if data:\n                    message_queues[sock].put(data)\n                    if sock not in outputs:\n                        outputs.append(sock)\n                else:\n                    print(f\"Closed connection from {sock.getpeername()}\")\n                    sock.close()\n                    inputs.remove(sock)\n                    if sock in outputs:\n                        outputs.remove(sock)\n                    del message_queues[sock]\n\n        for sock in writable:\n            try:\n                next_msg = message_queues[sock].get_nowait()\n            except queue.Empty:\n                outputs.remove(sock)\n            else:\n                sock.send(next_msg + str(datetime.now()).encode())\n\n        for sock in exceptional:\n            print(f\"Exceptional condition on {sock.getpeername()}\")\n            sock.close()\n            inputs.remove(sock)\n            if sock in outputs:\n                outputs.remove(sock)\n            del message_queues[sock]\n\n    server_socket.close()\n    return f\"Server ran for {run_duration} seconds.\"", "raw_solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_socket.bind((server_address, server_port))\n    server_socket.listen(5)\n\n    inputs = [server_socket]\n    outputs = []\n    message_queues = {}\n\n    start_time = datetime.now()\n    while (datetime.now() - start_time).seconds < run_duration:\n        readable, writable, exceptional = select.select(inputs, outputs, inputs)\n\n        for sock in readable:\n            if sock is server_socket:\n                connection, client_address = sock.accept()\n                print(f\"Accepted connection from {client_address}\")\n                connection.setblocking(0)\n                inputs.append(connection)\n                message_queues[connection] = queue.Queue()\n            else:\n                data = sock.recv(buffer_size)\n                if data:\n                    message_queues[sock].put(data)\n                    if sock not in outputs:\n                        outputs.append(sock)\n                else:\n                    print(f\"Closed connection from {sock.getpeername()}\")\n                    sock.close()\n                    inputs.remove(sock)\n                    if sock in outputs:\n                        outputs.remove(sock)\n                    del message_queues[sock]\n\n        for sock in writable:\n            try:\n                next_msg = message_queues[sock].get_nowait()\n            except queue.Empty:\n                outputs.remove(sock)\n            else:\n                sock.send(next_msg + str(datetime.now()).encode())\n\n        for sock in exceptional:\n            print(f\"Exceptional condition on {sock.getpeername()}\")\n            sock.close()\n            inputs.remove(sock)\n            if sock in outputs:\n                outputs.remove(sock)\n            del message_queues[sock]\n\n    server_socket.close()\n    return f\"Server ran for {run_duration} seconds.\"\n```"}
{"task_id": "BigCodeBench/1041", "solution": "import re\nimport os\ndef task_func(request):\n    if request.startswith(\"GET /\"):\n        filename = re.search(r\"GET /(.*) \", request).group(1)\n        if os.path.exists(filename):\n            with open(filename, \"r\") as file:\n                content = file.read()\n            response = f\"HTTP/1.1 200 OK\\r\\nContent-Length: {len(content)}\\r\\n\\r\\n{content}\"\n        else:\n            response = \"HTTP/1.1 404 Not Found\\r\\nContent-Length: 0\\r\\n\\r\\n\"\n    else:\n        response = \"HTTP/1.1 400 Bad Request\\r\\nContent-Length: 0\\r\\n\\r\\n\"\n    return response", "raw_solution": "import re\nimport os\n\ndef task_func(request):\n    if request.startswith(\"GET /\"):\n        filename = re.search(r\"GET /(.*) \", request).group(1)\n        if os.path.exists(filename):\n            with open(filename, \"r\") as file:\n                content = file.read()\n            response = f\"HTTP/1.1 200 OK\\r\\nContent-Length: {len(content)}\\r\\n\\r\\n{content}\"\n        else:\n            response = \"HTTP/1.1 404 Not Found\\r\\nContent-Length: 0\\r\\n\\r\\n\"\n    else:\n        response = \"HTTP/1.1 400 Bad Request\\r\\nContent-Length: 0\\r\\n\\r\\n\"\n    return response\n```"}
{"task_id": "BigCodeBench/1042", "solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\ndef send_email(sender, recipient, password, message):\n    msg = EmailMessage()\n    msg.set_content(message)\n    msg['Subject'] = 'Message from Client'\n    msg['From'] = sender\n    msg['To'] = recipient\n\n    server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n    server.starttls()\n    server.login(sender, password)\n    server.send_message(msg)\n    server.quit()\ndef task_func(client_socket):\n    message = client_socket.recv(BUFFER_SIZE).decode()\n    sender = input(\"Enter your email: \")\n    recipient = input(\"Enter recipient's email: \")\n    password = getpass.getpass(\"Enter your email password: \")\n    send_email(sender, recipient, password, message)", "raw_solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\n\ndef send_email(sender, recipient, password, message):\n    msg = EmailMessage()\n    msg.set_content(message)\n    msg['Subject'] = 'Message from Client'\n    msg['From'] = sender\n    msg['To'] = recipient\n\n    server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n    server.starttls()\n    server.login(sender, password)\n    server.send_message(msg)\n    server.quit()\n\ndef task_func(client_socket):\n    message = client_socket.recv(BUFFER_SIZE).decode()\n    sender = input(\"Enter your email: \")\n    recipient = input(\"Enter recipient's email: \")\n    password = getpass.getpass(\"Enter your email password: \")\n    send_email(sender, recipient, password, message)"}
{"task_id": "BigCodeBench/1043", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nCATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\"]\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"The data list is empty.\")\n\n    # Create a DataFrame from the data_list\n    df = pd.DataFrame(data_list, columns=[\"Category\"])\n\n    # Count the occurrences of each category\n    category_counts = df[\"Category\"].value_counts()\n\n    # Create a list of all categories, including the predefined ones and any extra ones found in the data_list\n    all_categories = list(set(CATEGORIES + list(category_counts.index)))\n\n    # Create a histogram\n    fig, ax = plt.subplots()\n    ax.bar(all_categories, category_counts.reindex(all_categories, fill_value=0), width=0.8, align=\"center\")\n    ax.set_xlabel(\"Categories\")\n    ax.set_ylabel(\"Counts\")\n    ax.set_title(\"Category Distribution\")\n\n    # Check if the distribution is uniform\n    if not category_counts.equals(category_counts.iloc[0]):\n        print(\"The distribution of predefined categories is not uniform.\")\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"The data list is empty.\")\n\n    # Create a DataFrame from the data_list\n    df = pd.DataFrame(data_list, columns=[\"Category\"])\n\n    # Count the occurrences of each category\n    category_counts = df[\"Category\"].value_counts()\n\n    # Create a list of all categories, including the predefined ones and any extra ones found in the data_list\n    all_categories = list(set(CATEGORIES + list(category_counts.index)))\n\n    # Create a histogram\n    fig, ax = plt.subplots()\n    ax.bar(all_categories, category_counts.reindex(all_categories, fill_value=0), width=0.8, align=\"center\")\n    ax.set_xlabel(\"Categories\")\n    ax.set_ylabel(\"Counts\")\n    ax.set_title(\"Category Distribution\")\n\n    # Check if the distribution is uniform\n    if not category_counts.equals(category_counts.iloc[0]):\n        print(\"The distribution of predefined categories is not uniform.\")\n\n    return ax\n```"}
{"task_id": "BigCodeBench/1044", "solution": "import pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nROOMS = [\"Room1\", \"Room2\", \"Room3\", \"Room4\", \"Room5\"]\ndef task_func(date_str, booking_data):\n    try:\n        date = datetime.strptime(date_str, \"%Y-%m-%d\")\n    except ValueError:\n        raise ValueError(\"Invalid date format. Please use 'yyyy-mm-dd' format.\")\n\n    if date < datetime.now():\n        raise ValueError(\"Date cannot be in the past.\")\n\n    report = pd.DataFrame(columns=[\"Room\", \"Status\"])\n\n    for room in ROOMS:\n        status = \"Available\" if room not in booking_data.keys() or date not in booking_data[room] else \"Booked\"\n        report = report.append({\"Room\": room, \"Status\": status}, ignore_index=True)\n\n    fig, ax = plt.subplots()\n    report.groupby(\"Status\").count().plot(kind=\"bar\", ax=ax)\n    ax.set_title(f\"Booking Status for {date_str}\")\n    ax.set_xlabel(\"Status\")\n    ax.set_ylabel(\"Count\")\n\n    return report, ax.figure", "raw_solution": "import pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\n# Constants\nROOMS = [\"Room1\", \"Room2\", \"Room3\", \"Room4\", \"Room5\"]\n\ndef task_func(date_str, booking_data):\n    try:\n        date = datetime.strptime(date_str, \"%Y-%m-%d\")\n    except ValueError:\n        raise ValueError(\"Invalid date format. Please use 'yyyy-mm-dd' format.\")\n\n    if date < datetime.now():\n        raise ValueError(\"Date cannot be in the past.\")\n\n    report = pd.DataFrame(columns=[\"Room\", \"Status\"])\n\n    for room in ROOMS:\n        status = \"Available\" if room not in booking_data.keys() or date not in booking_data[room] else \"Booked\"\n        report = report.append({\"Room\": room, \"Status\": status}, ignore_index=True)\n\n    fig, ax = plt.subplots()\n    report.groupby(\"Status\").count().plot(kind=\"bar\", ax=ax)\n    ax.set_title(f\"Booking Status for {date_str}\")\n    ax.set_xlabel(\"Status\")\n    ax.set_ylabel(\"Count\")\n\n    return report, ax.figure\n```"}
{"task_id": "BigCodeBench/1045", "solution": "from datetime import datetime\nimport numpy as np\nfrom dateutil.parser import parse\nLEAP_SECONDS = np.array(\n    [\n        1972,\n        1973,\n        1974,\n        1975,\n        1976,\n        1977,\n        1978,\n        1979,\n        1980,\n        1981,\n        1982,\n        1983,\n        1985,\n        1988,\n        1990,\n        1993,\n        1994,\n        1997,\n        1999,\n        2006,\n        2009,\n        2012,\n        2015,\n        2016,\n        2020,\n    ]\n)\ndef task_func(date_str):\n    date = parse(date_str)\n    now = datetime.now()\n    total_seconds = int((now - date).total_seconds())\n    leap_seconds = np.sum(LEAP_SECONDS <= now.year)\n    return total_seconds + leap_seconds", "raw_solution": "from datetime import datetime\nimport numpy as np\nfrom dateutil.parser import parse\nLEAP_SECONDS = np.array(\n    [\n        1972,\n        1973,\n        1974,\n        1975,\n        1976,\n        1977,\n        1978,\n        1979,\n        1980,\n        1981,\n        1982,\n        1983,\n        1985,\n        1988,\n        1990,\n        1993,\n        1994,\n        1997,\n        1999,\n        2006,\n        2009,\n        2012,\n        2015,\n        2016,\n        2020,\n    ]\n)\ndef task_func(date_str):\n    date = parse(date_str)\n    now = datetime.now()\n    total_seconds = int((now - date).total_seconds())\n    leap_seconds = np.sum(LEAP_SECONDS <= now.year)\n    return total_seconds + leap_seconds\n```"}
{"task_id": "BigCodeBench/1046", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nfrom itertools import product\nEMPLOYEES = [\"John\", \"Alice\", \"Bob\", \"Charlie\", \"Dave\"]\ndef task_func(date_str):\n    date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n    dates = [(date_obj + timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range(10)]\n    df = pd.DataFrame(list(product(EMPLOYEES, dates)), columns=[\"Employee\", \"Date\"])\n    return df", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\nfrom itertools import product\n\n# Constants\nEMPLOYEES = [\"John\", \"Alice\", \"Bob\", \"Charlie\", \"Dave\"]\n\ndef task_func(date_str):\n    date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n    dates = [(date_obj + timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range(10)]\n    df = pd.DataFrame(list(product(EMPLOYEES, dates)), columns=[\"Employee\", \"Date\"])\n    return df\n```"}
{"task_id": "BigCodeBench/1047", "solution": "from datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\ndef task_func(date_str):\n    date = datetime.strptime(date_str, \"%Y-%m-%d\")\n    day_of_month = date.day\n    random_numbers = [random.randint(1, 100) for _ in range(day_of_month)]\n    fig, ax = plt.subplots()\n    ax.plot(range(1, day_of_month + 1), random_numbers)\n    ax.set_xlabel(\"Day of Month\")\n    ax.set_ylabel(\"Random Number\")\n    ax.set_title(\"Random Number Plot\")\n    return ax", "raw_solution": "from datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\n\ndef task_func(date_str):\n    date = datetime.strptime(date_str, \"%Y-%m-%d\")\n    day_of_month = date.day\n    random_numbers = [random.randint(1, 100) for _ in range(day_of_month)]\n    fig, ax = plt.subplots()\n    ax.plot(range(1, day_of_month + 1), random_numbers)\n    ax.set_xlabel(\"Day of Month\")\n    ax.set_ylabel(\"Random Number\")\n    ax.set_title(\"Random Number Plot\")\n    return ax\n```"}
{"task_id": "BigCodeBench/1048", "solution": "from datetime import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(date_str):\n    date = datetime.strptime(date_str, '%Y-%m-%d')\n    day_of_month = date.day\n    frequency = day_of_month / 30\n    x = np.linspace(0, 2 * np.pi, 100)\n    y = np.sin(frequency * x)\n    plt.plot(x, y)\n    plt.title('Sine Wave with Frequency Determined by Day of Month')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    return plt.gca()", "raw_solution": "from datetime import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(date_str):\n    date = datetime.strptime(date_str, '%Y-%m-%d')\n    day_of_month = date.day\n    frequency = day_of_month / 30\n    x = np.linspace(0, 2 * np.pi, 100)\n    y = np.sin(frequency * x)\n    plt.plot(x, y)\n    plt.title('Sine Wave with Frequency Determined by Day of Month')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/1049", "solution": "import re\nimport pandas as pd\ndef task_func(input_string: str) -> pd.DataFrame:\n    lines = input_string.split('\\n')\n    lines = [line.strip() for line in lines if line.strip()]\n    lines = [re.sub(r'\\t', ' ', line) for line in lines]\n    return pd.DataFrame(lines, columns=['Text'])", "raw_solution": "import re\nimport pandas as pd\n\ndef task_func(input_string: str) -> pd.DataFrame:\n    lines = input_string.split('\\n')\n    lines = [line.strip() for line in lines if line.strip()]\n    lines = [re.sub(r'\\t', ' ', line) for line in lines]\n    return pd.DataFrame(lines, columns=['Text'])\n```"}
{"task_id": "BigCodeBench/1050", "solution": "import os\nimport hashlib\nDIRECTORY = \"./hashed_files\"\ndef task_func(input_string):\n    if not os.path.exists(DIRECTORY):\n        os.makedirs(DIRECTORY)\n\n    lines = input_string.split('\\n')\n    file_paths = []\n\n    for line in lines:\n        if line.strip():\n            hashed_line = hashlib.sha256(line.encode()).hexdigest()\n            file_path = os.path.join(DIRECTORY, hashed_line[:10] + '.txt')\n            file_paths.append(file_path)\n\n            with open(file_path, 'w') as file:\n                file.write(hashed_line)\n\n    return file_paths", "raw_solution": "import os\nimport hashlib\n\n# Constants\nDIRECTORY = \"./hashed_files\"\n\ndef task_func(input_string):\n    if not os.path.exists(DIRECTORY):\n        os.makedirs(DIRECTORY)\n\n    lines = input_string.split('\\n')\n    file_paths = []\n\n    for line in lines:\n        if line.strip():\n            hashed_line = hashlib.sha256(line.encode()).hexdigest()\n            file_path = os.path.join(DIRECTORY, hashed_line[:10] + '.txt')\n            file_paths.append(file_path)\n\n            with open(file_path, 'w') as file:\n                file.write(hashed_line)\n\n    return file_paths\n```"}
{"task_id": "BigCodeBench/1051", "solution": "import collections\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data_dict):\n    if not data_dict:\n        return None, \"The distribution is uniform.\"\n\n    counts = list(data_dict.values())\n    average_count = np.mean(counts)\n    is_uniform = all(abs(count - average_count) <= 1e-5 for count in counts)\n\n    fig, ax = plt.subplots()\n    ax.hist(counts, bins=min(10, len(set(counts))), edgecolor='black')\n    ax.set_xticks(range(len(counts)))\n    ax.set_xticklabels(list(data_dict.keys()))\n    plt.tight_layout()\n\n    return ax, \"The distribution is uniform.\" if is_uniform else \"The distribution is not uniform.\"", "raw_solution": "import collections\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict):\n    if not data_dict:\n        return None, \"The distribution is uniform.\"\n\n    counts = list(data_dict.values())\n    average_count = np.mean(counts)\n    is_uniform = all(abs(count - average_count) <= 1e-5 for count in counts)\n\n    fig, ax = plt.subplots()\n    ax.hist(counts, bins=min(10, len(set(counts))), edgecolor='black')\n    ax.set_xticks(range(len(counts)))\n    ax.set_xticklabels(list(data_dict.keys()))\n    plt.tight_layout()\n\n    return ax, \"The distribution is uniform.\" if is_uniform else \"The distribution is not uniform.\"\n```"}
{"task_id": "BigCodeBench/1052", "solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\ndef task_func(file_path, save_path=None):\n    # Read the CSV file\n    df = pd.read_csv(file_path)\n\n    # Check if the dataframe is empty\n    if df.empty:\n        print(\"The input file is empty.\")\n        return None\n\n    # Vectorize the text data\n    vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n    X = vectorizer.fit_transform(df['text'])\n\n    # Get the word counts\n    word_counts = X.toarray().sum(axis=0)\n\n    # Check if there are any valid words\n    if word_counts.sum() == 0:\n        print(\"The input file contains only stop words.\")\n        return None\n\n    # Create a histogram\n    plt.figure(figsize=(10, 6))\n    plt.bar(vectorizer.get_feature_names_out(), word_counts)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Word Frequency Histogram')\n    plt.xticks(rotation=90)\n\n    # Save the plot if a save_path is provided\n    if save_path is not None:\n        plt.savefig(save_path)\n        return None\n\n    # Display the plot\n    plt.show()\n    return plt.gca()", "raw_solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n\n# Constants\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\n\ndef task_func(file_path, save_path=None):\n    # Read the CSV file\n    df = pd.read_csv(file_path)\n\n    # Check if the dataframe is empty\n    if df.empty:\n        print(\"The input file is empty.\")\n        return None\n\n    # Vectorize the text data\n    vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n    X = vectorizer.fit_transform(df['text'])\n\n    # Get the word counts\n    word_counts = X.toarray().sum(axis=0)\n\n    # Check if there are any valid words\n    if word_counts.sum() == 0:\n        print(\"The input file contains only stop words.\")\n        return None\n\n    # Create a histogram\n    plt.figure(figsize=(10, 6))\n    plt.bar(vectorizer.get_feature_names_out(), word_counts)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Word Frequency Histogram')\n    plt.xticks(rotation=90)\n\n    # Save the plot if a save_path is provided\n    if save_path is not None:\n        plt.savefig(save_path)\n        return None\n\n    # Display the plot\n    plt.show()\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/1053", "solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\ndef task_func(file_path, save_path=None):\n    try:\n        # Read the CSV file\n        df = pd.read_csv(file_path)\n\n        # Check if the CSV file has a header\n        if df.columns[0] != 'Text':\n            df.columns = ['Text']\n\n        # Split the text into words\n        words = df['Text'].str.split()\n\n        # Create a histogram of the frequency of the top ten most common words\n        vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n        word_counts = vectorizer.fit_transform(words)\n        word_counts = word_counts.toarray().sum(axis=0)\n        word_counts_df = pd.DataFrame(word_counts, index=vectorizer.get_feature_names_out(), columns=['Count'])\n        word_counts_df = word_counts_df.sort_values(by='Count', ascending=False)\n        top_10_words = word_counts_df.head(10)\n\n        # Plot the histogram\n        plt.figure(figsize=(10, 5))\n        plt.bar(top_10_words.index, top_10_words['Count'])\n        plt.xlabel('Words')\n        plt.ylabel('Frequency')\n        plt.title('Top 10 Most Common Words')\n        plt.xticks(rotation=90)\n\n        # Save the plot to a file if a save_path is provided\n        if save_path is not None:\n            plt.savefig(save_path)\n            return None\n\n        return plt.gca()\n\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return None", "raw_solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n\n# Constants\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\n\ndef task_func(file_path, save_path=None):\n    try:\n        # Read the CSV file\n        df = pd.read_csv(file_path)\n\n        # Check if the CSV file has a header\n        if df.columns[0] != 'Text':\n            df.columns = ['Text']\n\n        # Split the text into words\n        words = df['Text'].str.split()\n\n        # Create a histogram of the frequency of the top ten most common words\n        vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n        word_counts = vectorizer.fit_transform(words)\n        word_counts = word_counts.toarray().sum(axis=0)\n        word_counts_df = pd.DataFrame(word_counts, index=vectorizer.get_feature_names_out(), columns=['Count'])\n        word_counts_df = word_counts_df.sort_values(by='Count', ascending=False)\n        top_10_words = word_counts_df.head(10)\n\n        # Plot the histogram\n        plt.figure(figsize=(10, 5))\n        plt.bar(top_10_words.index, top_10_words['Count'])\n        plt.xlabel('Words')\n        plt.ylabel('Frequency')\n        plt.title('Top 10 Most Common Words')\n        plt.xticks(rotation=90)\n\n        # Save the plot to a file if a save_path is provided\n        if save_path is not None:\n            plt.savefig(save_path)\n            return None\n\n        return plt.gca()\n\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return None\n```"}
{"task_id": "BigCodeBench/1054", "solution": "import csv\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\ndef task_func(file_path):\n    try:\n        with open(file_path, 'r') as file:\n            reader = csv.reader(file)\n            data = [float(row[0]) for row in reader]\n    except FileNotFoundError:\n        raise FileNotFoundError(\"File not found\")\n    except Exception as e:\n        raise e\n\n    sample = np.random.choice(data, size=30, replace=False)\n    mean = np.mean(sample)\n    std_dev = np.std(sample, ddof=1)\n\n    fig, ax = plt.subplots()\n    ax.hist(sample, bins='auto', alpha=0.7, color='blue', edgecolor='black')\n    x = np.linspace(min(sample), max(sample), 100)\n    y = stats.norm.pdf(x, mean, std_dev)\n    ax.plot(x, y, color='red')\n\n    return mean, std_dev, ax", "raw_solution": "import csv\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path):\n    try:\n        with open(file_path, 'r') as file:\n            reader = csv.reader(file)\n            data = [float(row[0]) for row in reader]\n    except FileNotFoundError:\n        raise FileNotFoundError(\"File not found\")\n    except Exception as e:\n        raise e\n\n    sample = np.random.choice(data, size=30, replace=False)\n    mean = np.mean(sample)\n    std_dev = np.std(sample, ddof=1)\n\n    fig, ax = plt.subplots()\n    ax.hist(sample, bins='auto', alpha=0.7, color='blue', edgecolor='black')\n    x = np.linspace(min(sample), max(sample), 100)\n    y = stats.norm.pdf(x, mean, std_dev)\n    ax.plot(x, y, color='red')\n\n    return mean, std_dev, ax\n```"}
{"task_id": "BigCodeBench/1055", "solution": "import pandas as pd\nimport itertools\nimport random\ndef task_func(colors, states):\n    # Generate combinations\n    combinations = list(itertools.product(colors, states))\n    # Shuffle combinations\n    random.shuffle(combinations)\n    # Create DataFrame\n    df = pd.DataFrame(combinations, columns=[\"Color:State\"])\n    return df", "raw_solution": "import pandas as pd\nimport itertools\nimport random\n\ndef task_func(colors, states):\n    # Generate combinations\n    combinations = list(itertools.product(colors, states))\n    # Shuffle combinations\n    random.shuffle(combinations)\n    # Create DataFrame\n    df = pd.DataFrame(combinations, columns=[\"Color:State\"])\n    return df\n```"}
{"task_id": "BigCodeBench/1056", "solution": "import numpy as np\nimport random\nimport matplotlib.pyplot as plt\nLETTERS = list(\"abcdefghijklmnopqrstuvwxyz\")\nNUMBERS = list(range(1, 27))\ndef task_func(n_pairs=26):\n    if n_pairs < 1 or n_pairs > 26:\n        raise ValueError(\"'n_pairs' must be between 1 and 26\")\n\n    # Generate letter-number pairs\n    pairs = [f\"{LETTERS[i]}:{NUMBERS[i]}\" for i in range(n_pairs)]\n    random.shuffle(pairs)\n\n    # Generate random counts\n    counts = [random.randint(1, 9) for _ in range(n_pairs)]\n\n    # Create bar chart\n    plt.bar(pairs, counts)\n    plt.title(\"Random Letter:Number Pairs Chart\")\n    plt.xlabel(\"Letter:Number Pairs\")\n    plt.ylabel(\"Counts\")\n    plt.show()\n\n    return plt.gca()", "raw_solution": "import numpy as np\nimport random\nimport matplotlib.pyplot as plt\n\n# Constants\nLETTERS = list(\"abcdefghijklmnopqrstuvwxyz\")\nNUMBERS = list(range(1, 27))\n\ndef task_func(n_pairs=26):\n    if n_pairs < 1 or n_pairs > 26:\n        raise ValueError(\"'n_pairs' must be between 1 and 26\")\n\n    # Generate letter-number pairs\n    pairs = [f\"{LETTERS[i]}:{NUMBERS[i]}\" for i in range(n_pairs)]\n    random.shuffle(pairs)\n\n    # Generate random counts\n    counts = [random.randint(1, 9) for _ in range(n_pairs)]\n\n    # Create bar chart\n    plt.bar(pairs, counts)\n    plt.title(\"Random Letter:Number Pairs Chart\")\n    plt.xlabel(\"Letter:Number Pairs\")\n    plt.ylabel(\"Counts\")\n    plt.show()\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/1057", "solution": "import pandas as pd\nimport itertools\nimport numpy as np\ndef task_func(animals=None, foods=None):\n    if animals is None:\n        animals = ['Dog', 'Cat', 'Bird']\n    if foods is None:\n        foods = ['Burger', 'Pizza', 'Sushi']\n    if not animals or not foods:\n        return pd.DataFrame()\n    combinations = list(itertools.product(animals, foods))\n    np.random.shuffle(combinations)\n    df = pd.DataFrame(combinations, columns=foods)\n    df.index = animals\n    df = df.applymap(lambda x: f'{x[0]}:{x[1]}')\n    return df", "raw_solution": "import pandas as pd\nimport itertools\nimport numpy as np\n\ndef task_func(animals=None, foods=None):\n    if animals is None:\n        animals = ['Dog', 'Cat', 'Bird']\n    if foods is None:\n        foods = ['Burger', 'Pizza', 'Sushi']\n    if not animals or not foods:\n        return pd.DataFrame()\n    combinations = list(itertools.product(animals, foods))\n    np.random.shuffle(combinations)\n    df = pd.DataFrame(combinations, columns=foods)\n    df.index = animals\n    df = df.applymap(lambda x: f'{x[0]}:{x[1]}')\n    return df\n```"}
{"task_id": "BigCodeBench/1058", "solution": "import itertools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nSHAPES = [\n    \"Circle\",\n    \"Square\",\n    \"Triangle\",\n    \"Rectangle\",\n    \"Pentagon\",\n    \"Hexagon\",\n    \"Heptagon\",\n    \"Octagon\",\n    \"Nonagon\",\n    \"Decagon\",\n]\nCOLORS = [\n    \"Red\",\n    \"Blue\",\n    \"Green\",\n    \"Yellow\",\n    \"Black\",\n    \"White\",\n    \"Purple\",\n    \"Orange\",\n    \"Pink\",\n    \"Brown\",\n]\ndef task_func(num_pairs=10):\n    # Generate shape-color pairs\n    pairs = list(itertools.product(SHAPES, COLORS))\n    # Select the first 'num_pairs' pairs\n    pairs = pairs[:num_pairs]\n    # Create a DataFrame from the pairs\n    df = pd.DataFrame(pairs, columns=[\"Shape\", \"Color\"])\n    # Generate the countplot\n    ax = sns.countplot(x=\"Shape\", hue=\"Color\", data=df)\n    return ax", "raw_solution": "import itertools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Constants\nSHAPES = [\n    \"Circle\",\n    \"Square\",\n    \"Triangle\",\n    \"Rectangle\",\n    \"Pentagon\",\n    \"Hexagon\",\n    \"Heptagon\",\n    \"Octagon\",\n    \"Nonagon\",\n    \"Decagon\",\n]\nCOLORS = [\n    \"Red\",\n    \"Blue\",\n    \"Green\",\n    \"Yellow\",\n    \"Black\",\n    \"White\",\n    \"Purple\",\n    \"Orange\",\n    \"Pink\",\n    \"Brown\",\n]\n\ndef task_func(num_pairs=10):\n    # Generate shape-color pairs\n    pairs = list(itertools.product(SHAPES, COLORS))\n    # Select the first 'num_pairs' pairs\n    pairs = pairs[:num_pairs]\n    # Create a DataFrame from the pairs\n    df = pd.DataFrame(pairs, columns=[\"Shape\", \"Color\"])\n    # Generate the countplot\n    ax = sns.countplot(x=\"Shape\", hue=\"Color\", data=df)\n    return ax\n```"}
{"task_id": "BigCodeBench/1059", "solution": "import numpy as np\nimport random\nimport itertools\nimport pandas as pd\nPLANETS = [\n    \"Mercury\",\n    \"Venus\",\n    \"Earth\",\n    \"Mars\",\n    \"Jupiter\",\n    \"Saturn\",\n    \"Uranus\",\n    \"Neptune\",\n]\nELEMENTS = [\n    \"Hydrogen\",\n    \"Helium\",\n    \"Oxygen\",\n    \"Carbon\",\n    \"Nitrogen\",\n    \"Magnesium\",\n    \"Silicon\",\n    \"Iron\",\n    \"Nickel\",\n]\ndef task_func():\n    # Generate a DataFrame where each row contains random planet-element pairs\n    df = pd.DataFrame(list(itertools.product(PLANETS, ELEMENTS)))\n    df.columns = ['Planet:Element']\n    return df", "raw_solution": "import numpy as np\nimport random\nimport itertools\nimport pandas as pd\n\n# Constants\nPLANETS = [\n    \"Mercury\",\n    \"Venus\",\n    \"Earth\",\n    \"Mars\",\n    \"Jupiter\",\n    \"Saturn\",\n    \"Uranus\",\n    \"Neptune\",\n]\nELEMENTS = [\n    \"Hydrogen\",\n    \"Helium\",\n    \"Oxygen\",\n    \"Carbon\",\n    \"Nitrogen\",\n    \"Magnesium\",\n    \"Silicon\",\n    \"Iron\",\n    \"Nickel\",\n]\n\ndef task_func():\n    # Generate a DataFrame where each row contains random planet-element pairs\n    df = pd.DataFrame(list(itertools.product(PLANETS, ELEMENTS)))\n    df.columns = ['Planet:Element']\n    return df\n```"}
{"task_id": "BigCodeBench/1060", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame, column_name: str) -> (str, plt.Axes):\n    if df.empty or column_name not in df.columns or df[column_name].isnull().all():\n        plt.figure(figsize=(10, 5))\n        plt.title(f\"Distribution of values in {column_name} (No Data)\")\n        plt.xlabel(\"Values\")\n        plt.ylabel(\"Frequency\")\n        plt.show()\n        return \"The DataFrame is empty or the specified column has no data.\", plt.gca()\n\n    unique_values = df[column_name].nunique()\n    plt.figure(figsize=(10, 5))\n    plt.hist(df[column_name], bins=unique_values, edgecolor='black', alpha=0.7)\n    plt.xlabel(\"Values\")\n    plt.ylabel(\"Frequency\")\n    plt.title(f\"Distribution of values in {column_name}\")\n    plt.show()\n\n    if df[column_name].nunique() == 1:\n        return \"The distribution of values is uniform.\", plt.gca()\n    else:\n        return \"The distribution of values is not uniform.\", plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame, column_name: str) -> (str, plt.Axes):\n    if df.empty or column_name not in df.columns or df[column_name].isnull().all():\n        plt.figure(figsize=(10, 5))\n        plt.title(f\"Distribution of values in {column_name} (No Data)\")\n        plt.xlabel(\"Values\")\n        plt.ylabel(\"Frequency\")\n        plt.show()\n        return \"The DataFrame is empty or the specified column has no data.\", plt.gca()\n\n    unique_values = df[column_name].nunique()\n    plt.figure(figsize=(10, 5))\n    plt.hist(df[column_name], bins=unique_values, edgecolor='black', alpha=0.7)\n    plt.xlabel(\"Values\")\n    plt.ylabel(\"Frequency\")\n    plt.title(f\"Distribution of values in {column_name}\")\n    plt.show()\n\n    if df[column_name].nunique() == 1:\n        return \"The distribution of values is uniform.\", plt.gca()\n    else:\n        return \"The distribution of values is not uniform.\", plt.gca()\n```"}
{"task_id": "BigCodeBench/1061", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(arr: np.ndarray) -> (plt.Axes, np.ndarray):\n    # Calculate the sum of elements in each row of the array\n    row_sums = np.sum(arr, axis=1)\n\n    # Normalize the row sums\n    mean = np.mean(row_sums)\n    std_dev = np.std(row_sums)\n    normalized_data = (row_sums - mean) / std_dev if std_dev != 0 else np.zeros_like(row_sums)\n\n    # Plot the histogram of the normalized data\n    fig, ax = plt.subplots()\n    ax.hist(normalized_data, bins=30, density=True, alpha=0.6, color='green')\n\n    # Plot the PDF of a standard normal distribution\n    x = np.linspace(-4, 4, 1000)\n    ax.plot(x, norm.pdf(x), color='red', linewidth=2)\n\n    # Set the title of the plot\n    plt.title(\"Histogram of Normalized Data with Standard Normal PDF\")\n\n    return ax, normalized_data", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(arr: np.ndarray) -> (plt.Axes, np.ndarray):\n    # Calculate the sum of elements in each row of the array\n    row_sums = np.sum(arr, axis=1)\n\n    # Normalize the row sums\n    mean = np.mean(row_sums)\n    std_dev = np.std(row_sums)\n    normalized_data = (row_sums - mean) / std_dev if std_dev != 0 else np.zeros_like(row_sums)\n\n    # Plot the histogram of the normalized data\n    fig, ax = plt.subplots()\n    ax.hist(normalized_data, bins=30, density=True, alpha=0.6, color='green')\n\n    # Plot the PDF of a standard normal distribution\n    x = np.linspace(-4, 4, 1000)\n    ax.plot(x, norm.pdf(x), color='red', linewidth=2)\n\n    # Set the title of the plot\n    plt.title(\"Histogram of Normalized Data with Standard Normal PDF\")\n\n    return ax, normalized_data\n```"}
{"task_id": "BigCodeBench/1062", "solution": "import pandas as pd\nfrom matplotlib import pyplot as plt\ndef task_func(arr):\n    if arr.size == 0:\n        fig, ax = plt.subplots()\n        ax.set_title('Time Series of Row Sums')\n        return ax\n    else:\n        dates = pd.date_range(start='1/1/2020', periods=arr.shape[1])\n        df = pd.DataFrame(arr.sum(axis=1), index=dates)\n        df.plot(kind='line', title='Time Series of Row Sums')\n        plt.xlabel('Dates')\n        plt.ylabel('Row Sums')\n        return plt.gca()", "raw_solution": "import pandas as pd\nfrom matplotlib import pyplot as plt\n\ndef task_func(arr):\n    if arr.size == 0:\n        fig, ax = plt.subplots()\n        ax.set_title('Time Series of Row Sums')\n        return ax\n    else:\n        dates = pd.date_range(start='1/1/2020', periods=arr.shape[1])\n        df = pd.DataFrame(arr.sum(axis=1), index=dates)\n        df.plot(kind='line', title='Time Series of Row Sums')\n        plt.xlabel('Dates')\n        plt.ylabel('Row Sums')\n        return plt.gca()\n```"}
{"task_id": "BigCodeBench/1063", "solution": "from matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(arr):\n    pca = PCA(n_components=1)\n    pca.fit(arr)\n    explained_variance_ratio = pca.explained_variance_ratio_\n\n    fig, ax = plt.subplots()\n    ax.bar(range(1), explained_variance_ratio)\n    ax.set_title(\"Explained Variance Ratio of Principal Components\")\n    ax.set_xlabel(\"Principal Component\")\n    ax.set_ylabel(\"Explained Variance Ratio\")\n    return ax", "raw_solution": "from matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(arr):\n    pca = PCA(n_components=1)\n    pca.fit(arr)\n    explained_variance_ratio = pca.explained_variance_ratio_\n\n    fig, ax = plt.subplots()\n    ax.bar(range(1), explained_variance_ratio)\n    ax.set_title(\"Explained Variance Ratio of Principal Components\")\n    ax.set_xlabel(\"Principal Component\")\n    ax.set_ylabel(\"Explained Variance Ratio\")\n    return ax\n```"}
{"task_id": "BigCodeBench/1064", "solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(arr):\n    # Calculate the sum of each row\n    row_sums = np.sum(arr, axis=1)\n    print(row_sums)\n\n    # Create a heatmap\n    ax = sns.heatmap(arr, cmap=\"YlGnBu\", vmin=np.min(arr), vmax=np.max(arr))\n\n    return ax", "raw_solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(arr):\n    # Calculate the sum of each row\n    row_sums = np.sum(arr, axis=1)\n    print(row_sums)\n\n    # Create a heatmap\n    ax = sns.heatmap(arr, cmap=\"YlGnBu\", vmin=np.min(arr), vmax=np.max(arr))\n\n    return ax\n```"}
{"task_id": "BigCodeBench/1065", "solution": "from scipy import fftpack\nfrom matplotlib import pyplot as plt\nimport numpy as np\ndef task_func(arr):\n    # Perform FFT on each row and sum them up\n    sum_row = np.sum(arr, axis=1)\n    fft_coeff = np.abs(fftpack.fft(sum_row))\n\n    # Plot the absolute values of the FFT coefficients\n    plt.plot(fft_coeff)\n    plt.title('FFT Coefficients')\n    plt.xlabel('Frequency')\n    plt.ylabel('Magnitude')\n    plt.grid(True)\n    return plt.gca()", "raw_solution": "from scipy import fftpack\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\ndef task_func(arr):\n    # Perform FFT on each row and sum them up\n    sum_row = np.sum(arr, axis=1)\n    fft_coeff = np.abs(fftpack.fft(sum_row))\n\n    # Plot the absolute values of the FFT coefficients\n    plt.plot(fft_coeff)\n    plt.title('FFT Coefficients')\n    plt.xlabel('Frequency')\n    plt.ylabel('Magnitude')\n    plt.grid(True)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/1066", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nNUM_SAMPLES = 100\nNUM_OUTLIERS = 5\ndef task_func(num_samples=NUM_SAMPLES, num_outliers=NUM_OUTLIERS):\n    # Generate normally distributed data\n    data = np.random.normal(loc=0, scale=1, size=num_samples)\n\n    # Generate artificially introduced outliers\n    outliers = np.random.uniform(low=-5, high=5, size=num_outliers)\n    data = np.append(data, outliers)\n\n    # Calculate IQR\n    q1 = np.percentile(data, 25)\n    q3 = np.percentile(data, 75)\n    iqr = q3 - q1\n\n    # Define outlier range\n    outlier_range = iqr * 1.5\n    lower_bound = q1 - outlier_range\n    upper_bound = q3 + outlier_range\n\n    # Detect outliers\n    outliers_detected = data[(data < lower_bound) | (data > upper_bound)]\n\n    # Plot histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=20, color='blue', alpha=0.5)\n    ax.axvline(x=lower_bound, color='red', linestyle='--')\n    ax.axvline(x=upper_bound, color='red', linestyle='--')\n\n    return data, outliers_detected, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nNUM_SAMPLES = 100\nNUM_OUTLIERS = 5\n\ndef task_func(num_samples=NUM_SAMPLES, num_outliers=NUM_OUTLIERS):\n    # Generate normally distributed data\n    data = np.random.normal(loc=0, scale=1, size=num_samples)\n\n    # Generate artificially introduced outliers\n    outliers = np.random.uniform(low=-5, high=5, size=num_outliers)\n    data = np.append(data, outliers)\n\n    # Calculate IQR\n    q1 = np.percentile(data, 25)\n    q3 = np.percentile(data, 75)\n    iqr = q3 - q1\n\n    # Define outlier range\n    outlier_range = iqr * 1.5\n    lower_bound = q1 - outlier_range\n    upper_bound = q3 + outlier_range\n\n    # Detect outliers\n    outliers_detected = data[(data < lower_bound) | (data > upper_bound)]\n\n    # Plot histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=20, color='blue', alpha=0.5)\n    ax.axvline(x=lower_bound, color='red', linestyle='--')\n    ax.axvline(x=upper_bound, color='red', linestyle='--')\n\n    return data, outliers_detected, ax\n```"}
{"task_id": "BigCodeBench/1067", "solution": "import requests\nimport logging\ndef task_func(repo_url: str) -> dict:\n    try:\n        response = requests.get(repo_url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        logging.error(\"HTTP Error:\", errh)\n        raise errh\n    except requests.exceptions.RequestException as errr:\n        logging.error(\"Request Exception:\", errr)\n        raise errr\n\n    repo_info = response.json()\n\n    open_issues_count = repo_info.get('open_issues_count', 0)\n    if open_issues_count > 100:\n        logging.warning(f\"The repository has a large number of open issues ({open_issues_count}). Consider managing them.\")\n\n    return repo_info", "raw_solution": "import requests\nimport logging\n\ndef task_func(repo_url: str) -> dict:\n    try:\n        response = requests.get(repo_url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        logging.error(\"HTTP Error:\", errh)\n        raise errh\n    except requests.exceptions.RequestException as errr:\n        logging.error(\"Request Exception:\", errr)\n        raise errr\n\n    repo_info = response.json()\n\n    open_issues_count = repo_info.get('open_issues_count', 0)\n    if open_issues_count > 100:\n        logging.warning(f\"The repository has a large number of open issues ({open_issues_count}). Consider managing them.\")\n\n    return repo_info\n```"}
{"task_id": "BigCodeBench/1068", "solution": "import warnings\nimport sqlite3\nimport pandas as pd\ndef task_func(db_path, query, warn_large_dataset=True):\n    try:\n        conn = sqlite3.connect(db_path)\n        cursor = conn.cursor()\n        cursor.execute(query)\n        data = cursor.fetchall()\n        if warn_large_dataset and len(data) > 10000:\n            warnings.warn(\"The data contains more than 10000 rows.\")\n        return pd.DataFrame(data)\n    except Exception as e:\n        raise Exception(f\"Error fetching data from the database: {str(e)}\")", "raw_solution": "import warnings\nimport sqlite3\nimport pandas as pd\n\ndef task_func(db_path, query, warn_large_dataset=True):\n    try:\n        conn = sqlite3.connect(db_path)\n        cursor = conn.cursor()\n        cursor.execute(query)\n        data = cursor.fetchall()\n        if warn_large_dataset and len(data) > 10000:\n            warnings.warn(\"The data contains more than 10000 rows.\")\n        return pd.DataFrame(data)\n    except Exception as e:\n        raise Exception(f\"Error fetching data from the database: {str(e)}\")\n```"}
{"task_id": "BigCodeBench/1069", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data_dict):\n    df = pd.DataFrame(data_dict)\n    axes = []\n    for column in df.columns:\n        ax = df[column].hist(bins=10)\n        axes.append(ax)\n        if not df[column].nunique() == df[column].size:\n            print(f\"The distribution of values in column '{column}' is not uniform.\")\n    return axes", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict):\n    df = pd.DataFrame(data_dict)\n    axes = []\n    for column in df.columns:\n        ax = df[column].hist(bins=10)\n        axes.append(ax)\n        if not df[column].nunique() == df[column].size:\n            print(f\"The distribution of values in column '{column}' is not uniform.\")\n    return axes\n```"}
{"task_id": "BigCodeBench/1070", "solution": "import pandas as pd\nfrom random import shuffle\nPOSSIBLE_VALUES = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"]\ndef task_func(list_of_lists):\n    result = []\n    for sublist in list_of_lists:\n        shuffled_values = POSSIBLE_VALUES.copy()\n        shuffle(shuffled_values)\n        df = pd.DataFrame(shuffled_values, columns=sublist)\n        result.append(df)\n    return result", "raw_solution": "import pandas as pd\nfrom random import shuffle\n\n# Constants\nPOSSIBLE_VALUES = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"]\n\ndef task_func(list_of_lists):\n    result = []\n    for sublist in list_of_lists:\n        shuffled_values = POSSIBLE_VALUES.copy()\n        shuffle(shuffled_values)\n        df = pd.DataFrame(shuffled_values, columns=sublist)\n        result.append(df)\n    return result\n```"}
{"task_id": "BigCodeBench/1071", "solution": "import matplotlib.pyplot as plt\nfrom itertools import cycle\nimport numpy as np\nfrom random import shuffle\nCOLORS = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\ndef task_func(list_of_lists):\n    fig, ax = plt.subplots()\n    color_cycle = cycle(COLORS)\n    for lst in list_of_lists:\n        if lst:\n            x = np.arange(1, len(lst) + 1)\n            y = lst[:]\n            shuffle(y)\n            ax.plot(x, y, color=next(color_cycle))\n    return fig, ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom itertools import cycle\nimport numpy as np\nfrom random import shuffle\nCOLORS = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\ndef task_func(list_of_lists):\n    fig, ax = plt.subplots()\n    color_cycle = cycle(COLORS)\n    for lst in list_of_lists:\n        if lst:\n            x = np.arange(1, len(lst) + 1)\n            y = lst[:]\n            shuffle(y)\n            ax.plot(x, y, color=next(color_cycle))\n    return fig, ax\n```"}
{"task_id": "BigCodeBench/1072", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(list_of_lists):\n    series_list = []\n    for sub_list in list_of_lists:\n        series = pd.Series(np.arange(1, len(sub_list) + 1))\n        np.random.shuffle(series.values)\n        series_list.append(series)\n    return series_list", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(list_of_lists):\n    series_list = []\n    for sub_list in list_of_lists:\n        series = pd.Series(np.arange(1, len(sub_list) + 1))\n        np.random.shuffle(series.values)\n        series_list.append(series)\n    return series_list\n```"}
{"task_id": "BigCodeBench/1073", "solution": "import time\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\ndef task_func(time_strings, time_format=\"%d/%m/%Y %H:%M:%S.%f\"):\n    try:\n        seconds = [time.mktime(datetime.strptime(t, time_format).timetuple()) for t in time_strings]\n    except ValueError:\n        return None\n\n    fig, ax = plt.subplots()\n    ax.hist(seconds, bins=10)\n    ax.set_xlabel('Seconds')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Seconds Component')\n    return ax", "raw_solution": "import time\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\ndef task_func(time_strings, time_format=\"%d/%m/%Y %H:%M:%S.%f\"):\n    try:\n        seconds = [time.mktime(datetime.strptime(t, time_format).timetuple()) for t in time_strings]\n    except ValueError:\n        return None\n\n    fig, ax = plt.subplots()\n    ax.hist(seconds, bins=10)\n    ax.set_xlabel('Seconds')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Seconds Component')\n    return ax\n```"}
{"task_id": "BigCodeBench/1074", "solution": "import pytz\nfrom dateutil.parser import parse\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_string, from_tz, to_tz):\n    # Parse the time string into a datetime object\n    dt = parse(time_string)\n\n    # Convert the datetime object to the source timezone\n    dt = dt.replace(tzinfo=pytz.timezone(from_tz))\n\n    # Convert the datetime object to the target timezone\n    dt = dt.astimezone(pytz.timezone(to_tz))\n\n    # Format the datetime object as a string\n    result = dt.strftime(TIME_FORMAT)\n\n    return result", "raw_solution": "import pytz\nfrom dateutil.parser import parse\n\n# Constants\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\n\ndef task_func(time_string, from_tz, to_tz):\n    # Parse the time string into a datetime object\n    dt = parse(time_string)\n\n    # Convert the datetime object to the source timezone\n    dt = dt.replace(tzinfo=pytz.timezone(from_tz))\n\n    # Convert the datetime object to the target timezone\n    dt = dt.astimezone(pytz.timezone(to_tz))\n\n    # Format the datetime object as a string\n    result = dt.strftime(TIME_FORMAT)\n\n    return result\n```"}
{"task_id": "BigCodeBench/1075", "solution": "import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_strings):\n    # Convert the time strings to datetime objects\n    time_objs = [datetime.datetime.strptime(time, TIME_FORMAT) for time in time_strings]\n    # Calculate the differences in seconds between consecutive datetime objects\n    diffs = [(time_objs[i+1] - time_objs[i]).total_seconds() for i in range(len(time_objs)-1)]\n    # Plot the differences as a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(range(len(diffs)), diffs)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Time Difference (s)')\n    return ax", "raw_solution": "import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_strings):\n    # Convert the time strings to datetime objects\n    time_objs = [datetime.datetime.strptime(time, TIME_FORMAT) for time in time_strings]\n    # Calculate the differences in seconds between consecutive datetime objects\n    diffs = [(time_objs[i+1] - time_objs[i]).total_seconds() for i in range(len(time_objs)-1)]\n    # Plot the differences as a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(range(len(diffs)), diffs)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Time Difference (s)')\n    return ax\n```"}
{"task_id": "BigCodeBench/1076", "solution": "from datetime import datetime\nimport pandas as pd\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_strings, target_tz):\n    \"\"\"\n    Convert a list of time strings from UTC to a specified timezone and return a DataFrame.\n    \"\"\"\n    # Create a DataFrame with two columns: 'Original Time' and 'Converted Time'\n    df = pd.DataFrame(time_strings, columns=['Original Time'])\n\n    # Convert each time string to a datetime object in UTC\n    df['Original Time'] = df['Original Time'].apply(lambda x: datetime.strptime(x, TIME_FORMAT))\n\n    # Convert each datetime object to the target timezone\n    df['Converted Time'] = df['Original Time'].apply(lambda x: x.astimezone(ZoneInfo(target_tz)))\n\n    return df", "raw_solution": "from datetime import datetime\nimport pandas as pd\n# For Python versions lower than 3.9, use 'pytz' instead of 'zoneinfo'\ntry:\n    from zoneinfo import ZoneInfo\nexcept ImportError:\n    from pytz import timezone as ZoneInfo\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_strings, target_tz):\n    \"\"\"\n    Convert a list of time strings from UTC to a specified timezone and return a DataFrame.\n    \"\"\"\n    # Create a DataFrame with two columns: 'Original Time' and 'Converted Time'\n    df = pd.DataFrame(time_strings, columns=['Original Time'])\n\n    # Convert each time string to a datetime object in UTC\n    df['Original Time'] = df['Original Time'].apply(lambda x: datetime.strptime(x, TIME_FORMAT))\n\n    # Convert each datetime object to the target timezone\n    df['Converted Time'] = df['Original Time'].apply(lambda x: x.astimezone(ZoneInfo(target_tz)))\n\n    return df\n```"}
{"task_id": "BigCodeBench/1077", "solution": "from datetime import datetime\nimport pytz\nimport numpy as np\ndef task_func(time_strings, timezone):\n    if len(time_strings) < 2:\n        return 0.0\n\n    # Convert each timestamp to the specified timezone\n    time_objs = [datetime.strptime(time_string, \"%Y-%m-%d %H:%M:%S\") for time_string in time_strings]\n    time_objs = [time_obj.astimezone(pytz.timezone(timezone)) for time_obj in time_objs]\n\n    # Calculate the absolute time difference in seconds between each consecutive pair of timestamps\n    time_diffs = [(time_objs[i+1] - time_objs[i]).total_seconds() for i in range(len(time_objs)-1)]\n\n    # Calculate the average time difference\n    avg_time_diff = np.mean(time_diffs)\n\n    return avg_time_diff", "raw_solution": "from datetime import datetime\nimport pytz\nimport numpy as np\n\ndef task_func(time_strings, timezone):\n    if len(time_strings) < 2:\n        return 0.0\n\n    # Convert each timestamp to the specified timezone\n    time_objs = [datetime.strptime(time_string, \"%Y-%m-%d %H:%M:%S\") for time_string in time_strings]\n    time_objs = [time_obj.astimezone(pytz.timezone(timezone)) for time_obj in time_objs]\n\n    # Calculate the absolute time difference in seconds between each consecutive pair of timestamps\n    time_diffs = [(time_objs[i+1] - time_objs[i]).total_seconds() for i in range(len(time_objs)-1)]\n\n    # Calculate the average time difference\n    avg_time_diff = np.mean(time_diffs)\n\n    return avg_time_diff\n```"}
{"task_id": "BigCodeBench/1078", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(arr):\n    unique, counts = np.unique(arr, return_counts=True)\n    ax = plt.hist(unique, bins=np.arange(len(unique) + 1) - 0.5, edgecolor='black')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.title('Value Distribution')\n    plt.grid(True)\n    plt.show()\n    return (np.all(counts == counts[0]), ax)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(arr):\n    unique, counts = np.unique(arr, return_counts=True)\n    ax = plt.hist(unique, bins=np.arange(len(unique) + 1) - 0.5, edgecolor='black')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.title('Value Distribution')\n    plt.grid(True)\n    plt.show()\n    return (np.all(counts == counts[0]), ax)"}
{"task_id": "BigCodeBench/1079", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Convert string prices to float\n    data['Price'] = data['Price_String'].apply(lambda x: float(x.replace(',', '')))\n\n    # Calculate statistical measures\n    stats = {\n        'mean': data['Price'].mean(),\n        'median': data['Price'].median(),\n        'std_dev': data['Price'].std()\n    }\n\n    # Generate histogram\n    fig, ax = plt.subplots()\n    ax.hist(data['Price'], bins='auto', color='blue', alpha=0.7, rwidth=0.85)\n    ax.set_title('Histogram of Product Prices')\n    ax.set_xlabel('Price')\n    ax.set_ylabel('Frequency')\n\n    return stats, ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Convert string prices to float\n    data['Price'] = data['Price_String'].apply(lambda x: float(x.replace(',', '')))\n\n    # Calculate statistical measures\n    stats = {\n        'mean': data['Price'].mean(),\n        'median': data['Price'].median(),\n        'std_dev': data['Price'].std()\n    }\n\n    # Generate histogram\n    fig, ax = plt.subplots()\n    ax.hist(data['Price'], bins='auto', color='blue', alpha=0.7, rwidth=0.85)\n    ax.set_title('Histogram of Product Prices')\n    ax.set_xlabel('Price')\n    ax.set_ylabel('Frequency')\n\n    return stats, ax\n```"}
{"task_id": "BigCodeBench/1080", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nDATA = {\n    \"Area_String\": [\"1,000\", \"2,000\", \"3,000\", \"4,000\", \"5,000\"],\n    \"Price\": [100, 200, 300, 400, 500],\n}\ndef task_func(area_string, data=DATA):\n    df = pd.DataFrame(data)\n    df['Area'] = df['Area_String'].str.replace(',', '').astype(int)\n    X = df[['Area']]\n    y = df['Price']\n    model = LinearRegression()\n    model.fit(X, y)\n    area = [int(area_string.replace(',', ''))]\n    return float(model.predict([area])[0])", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\nDATA = {\n    \"Area_String\": [\"1,000\", \"2,000\", \"3,000\", \"4,000\", \"5,000\"],\n    \"Price\": [100, 200, 300, 400, 500],\n}\n\ndef task_func(area_string, data=DATA):\n    df = pd.DataFrame(data)\n    df['Area'] = df['Area_String'].str.replace(',', '').astype(int)\n    X = df[['Area']]\n    y = df['Price']\n    model = LinearRegression()\n    model.fit(X, y)\n    area = [int(area_string.replace(',', ''))]\n    return float(model.predict([area])[0])\n```"}
{"task_id": "BigCodeBench/1081", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(data=None):\n    if data is None:\n        data = {'Weight_String': ['70.0', '65.0', '60.0', '75.0', '80.0'],\n                'Height': [170, 165, 160, 175, 180]}\n    else:\n        if not isinstance(data, dict):\n            raise ValueError(\"Input data should be a dictionary.\")\n        if 'Weight_String' not in data or 'Height' not in data:\n            raise ValueError(\"Input data should contain 'Weight_String' and 'Height' keys.\")\n        if not isinstance(data['Weight_String'], list) or not isinstance(data['Height'], list):\n            raise ValueError(\"'Weight_String' and 'Height' values should be lists.\")\n        if len(data['Weight_String']) != len(data['Height']):\n            raise ValueError(\"'Weight_String' and 'Height' lists should have the same length.\")\n        for weight in data['Weight_String']:\n            if not isinstance(weight, str):\n                raise ValueError(\"All values in 'Weight_String' should be strings.\")\n\n    df = pd.DataFrame(data)\n    df['Weight'] = df['Weight_String'].astype(float)\n    df = df.drop(columns=['Weight_String'])\n\n    ax = sns.scatterplot(x='Weight', y='Height', data=df)\n    ax.set_title(\"Weight vs Height\")\n    return ax", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data=None):\n    if data is None:\n        data = {'Weight_String': ['70.0', '65.0', '60.0', '75.0', '80.0'],\n                'Height': [170, 165, 160, 175, 180]}\n    else:\n        if not isinstance(data, dict):\n            raise ValueError(\"Input data should be a dictionary.\")\n        if 'Weight_String' not in data or 'Height' not in data:\n            raise ValueError(\"Input data should contain 'Weight_String' and 'Height' keys.\")\n        if not isinstance(data['Weight_String'], list) or not isinstance(data['Height'], list):\n            raise ValueError(\"'Weight_String' and 'Height' values should be lists.\")\n        if len(data['Weight_String']) != len(data['Height']):\n            raise ValueError(\"'Weight_String' and 'Height' lists should have the same length.\")\n        for weight in data['Weight_String']:\n            if not isinstance(weight, str):\n                raise ValueError(\"All values in 'Weight_String' should be strings.\")\n\n    df = pd.DataFrame(data)\n    df['Weight'] = df['Weight_String'].astype(float)\n    df = df.drop(columns=['Weight_String'])\n\n    ax = sns.scatterplot(x='Weight', y='Height', data=df)\n    ax.set_title(\"Weight vs Height\")\n    return ax\n```"}
{"task_id": "BigCodeBench/1082", "solution": "import pandas as pd\nfrom scipy.stats import pearsonr\ndef task_func(data):\n    if len(data) < 2:\n        return float('NaN')\n    data['Score'] = data['Score'].astype(float)\n    grade_ranks = {'A+': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5, 'F': 6}\n    data['Grade'] = data['Grade'].map(grade_ranks)\n    correlation, _ = pearsonr(data['Score'], data['Grade'])\n    return correlation", "raw_solution": "import pandas as pd\nfrom scipy.stats import pearsonr\n\ndef task_func(data):\n    if len(data) < 2:\n        return float('NaN')\n    data['Score'] = data['Score'].astype(float)\n    grade_ranks = {'A+': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5, 'F': 6}\n    data['Grade'] = data['Grade'].map(grade_ranks)\n    correlation, _ = pearsonr(data['Score'], data['Grade'])\n    return correlation\n```"}
{"task_id": "BigCodeBench/1083", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Input Validation\n    if not all(key in data for key in ('Salary_String', 'Experience')):\n        raise ValueError(\"Input data must contain 'Salary_String' and 'Experience' keys\")\n\n    # DataFrame Conversion\n    df = pd.DataFrame(data)\n\n    # Empty Data Handling\n    if df.empty:\n        return plt.gca()\n\n    # Salary Conversion\n    try:\n        df['Salary'] = df['Salary_String'].apply(lambda x: float(x.replace(',', '')))\n    except ValueError as e:\n        raise ValueError(\"Failed to convert salary string to float\") from e\n\n    # Salary Normalization\n    scaler = MinMaxScaler()\n    df['Normalized_Salary'] = scaler.fit_transform(df[['Salary']])\n\n    # Data Plotting\n    ax = df.plot.scatter(x='Experience', y='Normalized_Salary', ax=plt.gca())\n    ax.set_xlabel('Experience')\n    ax.set_ylabel('Normalized Salary')\n    return ax", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Input Validation\n    if not all(key in data for key in ('Salary_String', 'Experience')):\n        raise ValueError(\"Input data must contain 'Salary_String' and 'Experience' keys\")\n\n    # DataFrame Conversion\n    df = pd.DataFrame(data)\n\n    # Empty Data Handling\n    if df.empty:\n        return plt.gca()\n\n    # Salary Conversion\n    try:\n        df['Salary'] = df['Salary_String'].apply(lambda x: float(x.replace(',', '')))\n    except ValueError as e:\n        raise ValueError(\"Failed to convert salary string to float\") from e\n\n    # Salary Normalization\n    scaler = MinMaxScaler()\n    df['Normalized_Salary'] = scaler.fit_transform(df[['Salary']])\n\n    # Data Plotting\n    ax = df.plot.scatter(x='Experience', y='Normalized_Salary', ax=plt.gca())\n    ax.set_xlabel('Experience')\n    ax.set_ylabel('Normalized Salary')\n    return ax\n```"}
{"task_id": "BigCodeBench/1084", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import f_oneway\ndef task_func(data_file_path: str):\n    # Read the CSV file\n    df = pd.read_csv(data_file_path)\n\n    # Convert string representations of numbers with commas into floating point numbers\n    df = df.apply(lambda x: x.str.replace(',', '.').astype(float) if x.dtype == 'object' else x)\n\n    # Calculate the mean and standard deviation for each numerical column\n    means = df.select_dtypes(include=[float]).mean()\n    std_devs = df.select_dtypes(include=[float]).std()\n\n    # Generate a histogram plot for each numerical column\n    axes = []\n    for col in df.select_dtypes(include=[float]).columns:\n        ax = df[col].hist(bins=10)\n        axes.append(ax)\n\n    # Perform an ANOVA test to check the statistical significance of differences between means of numerical columns (if applicable)\n    anova_results = pd.DataFrame(columns=['F-value', 'P-value'])\n    if len(df.select_dtypes(include=[float]).columns) > 1:\n        for i in range(len(df.select_dtypes(include=[float]).columns)):\n            for j in range(i+1, len(df.select_dtypes(include=[float]).columns)):\n                col1 = df.select_dtypes(include=[float]).columns[i]\n                col2 = df.select_dtypes(include=[float]).columns[j]\n                f_val, p_val = f_oneway(df[col1], df[col2])\n                anova_results.loc[f'{col1} vs {col2}'] = [f_val, p_val]\n\n    return means, std_devs, axes, anova_results", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import f_oneway\n\ndef task_func(data_file_path: str):\n    # Read the CSV file\n    df = pd.read_csv(data_file_path)\n\n    # Convert string representations of numbers with commas into floating point numbers\n    df = df.apply(lambda x: x.str.replace(',', '.').astype(float) if x.dtype == 'object' else x)\n\n    # Calculate the mean and standard deviation for each numerical column\n    means = df.select_dtypes(include=[float]).mean()\n    std_devs = df.select_dtypes(include=[float]).std()\n\n    # Generate a histogram plot for each numerical column\n    axes = []\n    for col in df.select_dtypes(include=[float]).columns:\n        ax = df[col].hist(bins=10)\n        axes.append(ax)\n\n    # Perform an ANOVA test to check the statistical significance of differences between means of numerical columns (if applicable)\n    anova_results = pd.DataFrame(columns=['F-value', 'P-value'])\n    if len(df.select_dtypes(include=[float]).columns) > 1:\n        for i in range(len(df.select_dtypes(include=[float]).columns)):\n            for j in range(i+1, len(df.select_dtypes(include=[float]).columns)):\n                col1 = df.select_dtypes(include=[float]).columns[i]\n                col2 = df.select_dtypes(include=[float]).columns[j]\n                f_val, p_val = f_oneway(df[col1], df[col2])\n                anova_results.loc[f'{col1} vs {col2}'] = [f_val, p_val]\n\n    return means, std_devs, axes, anova_results\n```"}
{"task_id": "BigCodeBench/1085", "solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Lowercase the text and remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text.lower())\n    # Split the text into words\n    words = text.split()\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    # Get the 10 most common words and their counts\n    top_10_words = word_counts.most_common(10)\n    # Create a bar chart of the top 10 words\n    fig, ax = plt.subplots()\n    ax.bar(range(len(top_10_words)), [count for word, count in top_10_words])\n    ax.set_xticks(range(len(top_10_words)))\n    ax.set_xticklabels([word for word, count in top_10_words])\n    ax.set_xlabel('Word')\n    ax.set_ylabel('Count')\n    ax.set_title('Top 10 Most Common Words')\n    plt.tight_layout()\n    return top_10_words, ax", "raw_solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Lowercase the text and remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text.lower())\n    # Split the text into words\n    words = text.split()\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    # Get the 10 most common words and their counts\n    top_10_words = word_counts.most_common(10)\n    # Create a bar chart of the top 10 words\n    fig, ax = plt.subplots()\n    ax.bar(range(len(top_10_words)), [count for word, count in top_10_words])\n    ax.set_xticks(range(len(top_10_words)))\n    ax.set_xticklabels([word for word, count in top_10_words])\n    ax.set_xlabel('Word')\n    ax.set_ylabel('Count')\n    ax.set_title('Top 10 Most Common Words')\n    plt.tight_layout()\n    return top_10_words, ax\n```"}
{"task_id": "BigCodeBench/1086", "solution": "import string\nimport random\nimport pandas as pd\nimport numpy as np\nNUM_SAMPLES = 1000\ndef task_func():\n    # Generate random strings\n    random_strings = [''.join(random.choices(string.ascii_letters, k=10)) for _ in range(NUM_SAMPLES)]\n\n    # Generate random floats\n    random_floats = np.random.uniform(0, 10000, NUM_SAMPLES)\n\n    # Format floats with two decimal places and a comma as the thousands separator\n    formatted_floats = [f\"{float_num:,.2f}\" for float_num in random_floats]\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        'String Field': random_strings,\n        'Float Field': formatted_floats\n    })\n\n    return df", "raw_solution": "import string\nimport random\nimport pandas as pd\nimport numpy as np\n\n# Constants\nNUM_SAMPLES = 1000  # Number of samples\n\ndef task_func():\n    # Generate random strings\n    random_strings = [''.join(random.choices(string.ascii_letters, k=10)) for _ in range(NUM_SAMPLES)]\n\n    # Generate random floats\n    random_floats = np.random.uniform(0, 10000, NUM_SAMPLES)\n\n    # Format floats with two decimal places and a comma as the thousands separator\n    formatted_floats = [f\"{float_num:,.2f}\" for float_num in random_floats]\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        'String Field': random_strings,\n        'Float Field': formatted_floats\n    })\n\n    return df\n```"}
{"task_id": "BigCodeBench/1087", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(mean=123456.908, std_dev=1.2, save_plots=False):\n    np.random.seed(0)\n    sample = np.random.normal(mean, std_dev, 1000)\n    skewness = stats.skew(sample)\n    kurtosis = stats.kurtosis(sample)\n    if save_plots:\n        plt.figure(figsize=(10, 5))\n        plt.subplot(1, 2, 1)\n        plt.hist(sample, bins=30, color='skyblue', edgecolor='black')\n        plt.title('Histogram')\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plt.subplot(1, 2, 2)\n        stats.probplot(sample, plot=plt)\n        plt.title('QQ Plot')\n        plt.tight_layout()\n        plt.savefig('histogram_qq_plot.png')\n        plt.close()\n        return skewness, kurtosis, ['histogram_qq_plot.png']\n    else:\n        return skewness, kurtosis, []", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(mean=123456.908, std_dev=1.2, save_plots=False):\n    np.random.seed(0)\n    sample = np.random.normal(mean, std_dev, 1000)\n    skewness = stats.skew(sample)\n    kurtosis = stats.kurtosis(sample)\n    if save_plots:\n        plt.figure(figsize=(10, 5))\n        plt.subplot(1, 2, 1)\n        plt.hist(sample, bins=30, color='skyblue', edgecolor='black')\n        plt.title('Histogram')\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plt.subplot(1, 2, 2)\n        stats.probplot(sample, plot=plt)\n        plt.title('QQ Plot')\n        plt.tight_layout()\n        plt.savefig('histogram_qq_plot.png')\n        plt.close()\n        return skewness, kurtosis, ['histogram_qq_plot.png']\n    else:\n        return skewness, kurtosis, []\n```"}
{"task_id": "BigCodeBench/1088", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data=None):\n    if data is None:\n        return None\n    df = pd.DataFrame(data)\n    df[df < 0.5] = 0\n    scaler = StandardScaler()\n    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data=None):\n    if data is None:\n        return None\n    df = pd.DataFrame(data)\n    df[df < 0.5] = 0\n    scaler = StandardScaler()\n    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df\n```"}
{"task_id": "BigCodeBench/1089", "solution": "import numpy as np\nfrom collections import Counter\ndef task_func(list_of_tuples):\n    sum_of_values = sum(x[0] for x in list_of_tuples)\n    category_counts = Counter(x[1] for x in list_of_tuples)\n    return (sum_of_values, dict(category_counts))", "raw_solution": "import numpy as np\nfrom collections import Counter\ndef task_func(list_of_tuples):\n    sum_of_values = sum(x[0] for x in list_of_tuples)\n    category_counts = Counter(x[1] for x in list_of_tuples)\n    return (sum_of_values, dict(category_counts))\n```"}
{"task_id": "BigCodeBench/1090", "solution": "import ast\nimport json\nfrom collections import Counter\ndef task_func(file_pointer):\n    data = json.load(file_pointer)\n    counter = Counter()\n    for item in data:\n        if isinstance(item, str):\n            item = ast.literal_eval(item)\n        if isinstance(item, dict):\n            counter.update(item)\n    return counter", "raw_solution": "import ast\nimport json\nfrom collections import Counter\n\ndef task_func(file_pointer):\n    data = json.load(file_pointer)\n    counter = Counter()\n    for item in data:\n        if isinstance(item, str):\n            item = ast.literal_eval(item)\n        if isinstance(item, dict):\n            counter.update(item)\n    return counter\n```"}
{"task_id": "BigCodeBench/1091", "solution": "import ast\nimport os\nimport glob\ndef task_func(directory):\n    # Initialize an empty list to store the dictionaries\n    dict_list = []\n\n    # Get all text files in the directory\n    text_files = glob.glob(os.path.join(directory, '*.txt'))\n\n    # Iterate over each text file\n    for text_file in text_files:\n        # Open the text file and read its content\n        with open(text_file, 'r') as file:\n            content = file.read()\n\n        # Try to convert the content to a dictionary\n        try:\n            dict_obj = ast.literal_eval(content)\n\n            # Check if the object is a dictionary\n            if not isinstance(dict_obj, dict):\n                raise ValueError(f\"Invalid dictionary representation in file: {text_file}\")\n\n            # Append the dictionary to the list\n            dict_list.append(dict_obj)\n        except Exception as e:\n            raise ValueError(f\"Invalid dictionary representation in file: {text_file}\")\n\n    # Return the list of dictionaries\n    return dict_list", "raw_solution": "import ast\nimport os\nimport glob\n\n# Constants\nDIRECTORY = 'data'\n\ndef task_func(directory):\n    # Initialize an empty list to store the dictionaries\n    dict_list = []\n\n    # Get all text files in the directory\n    text_files = glob.glob(os.path.join(directory, '*.txt'))\n\n    # Iterate over each text file\n    for text_file in text_files:\n        # Open the text file and read its content\n        with open(text_file, 'r') as file:\n            content = file.read()\n\n        # Try to convert the content to a dictionary\n        try:\n            dict_obj = ast.literal_eval(content)\n\n            # Check if the object is a dictionary\n            if not isinstance(dict_obj, dict):\n                raise ValueError(f\"Invalid dictionary representation in file: {text_file}\")\n\n            # Append the dictionary to the list\n            dict_list.append(dict_obj)\n        except Exception as e:\n            raise ValueError(f\"Invalid dictionary representation in file: {text_file}\")\n\n    # Return the list of dictionaries\n    return dict_list\n```"}
{"task_id": "BigCodeBench/1092", "solution": "import ast\nimport requests\nfrom bs4 import BeautifulSoup\ndef task_func(url):\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        scripts = soup.find_all('script')\n        result = []\n        for script in scripts:\n            script_text = script.string\n            if script_text is not None:\n                try:\n                    eval_result = ast.literal_eval(script_text)\n                    if isinstance(eval_result, dict):\n                        result.append(eval_result)\n                except (SyntaxError, ValueError):\n                    pass\n        return result\n    except requests.exceptions.RequestException:\n        return []", "raw_solution": "import ast\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef task_func(url):\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        scripts = soup.find_all('script')\n        result = []\n        for script in scripts:\n            script_text = script.string\n            if script_text is not None:\n                try:\n                    eval_result = ast.literal_eval(script_text)\n                    if isinstance(eval_result, dict):\n                        result.append(eval_result)\n                except (SyntaxError, ValueError):\n                    pass\n        return result\n    except requests.exceptions.RequestException:\n        return []"}
{"task_id": "BigCodeBench/1093", "solution": "import ast\nimport re\ndef task_func(text_file: str) -> list:\n    with open(text_file, 'r') as file:\n        data = file.read()\n\n    pattern = r\"\\{[^{}]*\\}\"\n    matches = re.findall(pattern, data)\n\n    dictionaries = []\n    for match in matches:\n        try:\n            dictionary = ast.literal_eval(match)\n            dictionaries.append(dictionary)\n        except:\n            pass\n\n    return dictionaries", "raw_solution": "import ast\nimport re\n\ndef task_func(text_file: str) -> list:\n    with open(text_file, 'r') as file:\n        data = file.read()\n\n    pattern = r\"\\{[^{}]*\\}\"\n    matches = re.findall(pattern, data)\n\n    dictionaries = []\n    for match in matches:\n        try:\n            dictionary = ast.literal_eval(match)\n            dictionaries.append(dictionary)\n        except:\n            pass\n\n    return dictionaries\n```"}
{"task_id": "BigCodeBench/1094", "solution": "from nltk.tokenize import RegexpTokenizer\nfrom collections import Counter\ndef task_func(text):\n    tokenizer = RegexpTokenizer(r'\\$\\w+')\n    tokens = tokenizer.tokenize(text)\n    dollar_words = [word[1:] for word in tokens if word.startswith('$')]\n    word_counts = Counter(dollar_words)\n    return word_counts.most_common(5)", "raw_solution": "from nltk.tokenize import RegexpTokenizer\nfrom collections import Counter\n\ndef task_func(text):\n    tokenizer = RegexpTokenizer(r'\\$\\w+')\n    tokens = tokenizer.tokenize(text)\n    dollar_words = [word[1:] for word in tokens if word.startswith('$')]\n    word_counts = Counter(dollar_words)\n    return word_counts.most_common(5)\n```"}
{"task_id": "BigCodeBench/1095", "solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport os\ndef task_func(text, output_filename):\n    tokenizer = RegexpTokenizer(r'\\b\\$\\w+\\b')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if not all(char in punctuation for char in word)]\n    with open(output_filename, 'w') as file:\n        for word in words:\n            file.write(word + '\\n')\n    return os.path.abspath(output_filename)", "raw_solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport os\n\ndef task_func(text, output_filename):\n    tokenizer = RegexpTokenizer(r'\\b\\$\\w+\\b')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if not all(char in punctuation for char in word)]\n    with open(output_filename, 'w') as file:\n        for word in words:\n            file.write(word + '\\n')\n    return os.path.abspath(output_filename)\n```"}
{"task_id": "BigCodeBench/1096", "solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport csv\nimport os\nPUNCTUATION = set(punctuation)\ndef task_func(text, filename):\n    tokenizer = RegexpTokenizer(r'\\$\\w+')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if not set(word).issubset(PUNCTUATION)]\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Word\"])\n        for word in words:\n            writer.writerow([word])\n    return os.path.abspath(filename)", "raw_solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport csv\nimport os\nPUNCTUATION = set(punctuation)\ndef task_func(text, filename):\n    tokenizer = RegexpTokenizer(r'\\$\\w+')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if not set(word).issubset(PUNCTUATION)]\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Word\"])\n        for word in words:\n            writer.writerow([word])\n    return os.path.abspath(filename)\n```"}
{"task_id": "BigCodeBench/1097", "solution": "import re\nfrom string import punctuation\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\ndef task_func(text):\n    # Remove URLs\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', punctuation))\n    # Remove stopwords\n    words = text.split()\n    text = ' '.join([word for word in words if word not in PREDEFINED_STOPWORDS])\n    return text", "raw_solution": "import re\nfrom string import punctuation\n\n# Predefined list of common stopwords\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\n\ndef task_func(text):\n    # Remove URLs\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', punctuation))\n    # Remove stopwords\n    words = text.split()\n    text = ' '.join([word for word in words if word not in PREDEFINED_STOPWORDS])\n    return text\n```"}
{"task_id": "BigCodeBench/1098", "solution": "import re\nfrom collections import Counter\ndef task_func(text, top_n):\n    # Remove URLs\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n    # Split the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n    # Count the frequency of each word\n    word_count = Counter(words)\n    # Return the N most common words\n    return word_count.most_common(top_n)", "raw_solution": "import re\nfrom collections import Counter\n\ndef task_func(text, top_n):\n    # Remove URLs\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n    # Split the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n    # Count the frequency of each word\n    word_count = Counter(words)\n    # Return the N most common words\n    return word_count.most_common(top_n)\n```"}
{"task_id": "BigCodeBench/1099", "solution": "import re\nfrom collections import Counter\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\ndef task_func(text):\n    # Remove URLs from the text\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    text = url_pattern.sub('', text)\n\n    # Tokenize the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Count the frequency of each word\n    word_count = Counter(words)\n\n    # Filter out stopwords\n    filtered_words = {word: count for word, count in word_count.items() if word.lower() not in PREDEFINED_STOPWORDS}\n\n    # Sort the words by frequency\n    sorted_words = sorted(filtered_words.items(), key=lambda x: x[1], reverse=True)\n\n    return sorted_words", "raw_solution": "import re\nfrom collections import Counter\n\n# Predefined list of common stopwords\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\n\ndef task_func(text):\n    # Remove URLs from the text\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    text = url_pattern.sub('', text)\n\n    # Tokenize the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Count the frequency of each word\n    word_count = Counter(words)\n\n    # Filter out stopwords\n    filtered_words = {word: count for word, count in word_count.items() if word.lower() not in PREDEFINED_STOPWORDS}\n\n    # Sort the words by frequency\n    sorted_words = sorted(filtered_words.items(), key=lambda x: x[1], reverse=True)\n\n    return sorted_words\n```"}
{"task_id": "BigCodeBench/1100", "solution": "import re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndef task_func(texts):\n    # Remove URLs from the texts\n    texts = [re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) for text in texts]\n\n    # Initialize TfidfVectorizer\n    vectorizer = TfidfVectorizer()\n\n    # Fit and transform the texts\n    tfidf_matrix = vectorizer.fit_transform(texts)\n\n    # Get the feature names\n    feature_names = vectorizer.get_feature_names_out()\n\n    # Convert the tfidf matrix to a list of tuples\n    tfidf_tuples = [tuple(tfidf_matrix[i].toarray()[0]) for i in range(tfidf_matrix.shape[0])]\n\n    return tfidf_tuples, list(feature_names)", "raw_solution": "import re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ndef task_func(texts):\n    # Remove URLs from the texts\n    texts = [re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) for text in texts]\n\n    # Initialize TfidfVectorizer\n    vectorizer = TfidfVectorizer()\n\n    # Fit and transform the texts\n    tfidf_matrix = vectorizer.fit_transform(texts)\n\n    # Get the feature names\n    feature_names = vectorizer.get_feature_names_out()\n\n    # Convert the tfidf matrix to a list of tuples\n    tfidf_tuples = [tuple(tfidf_matrix[i].toarray()[0]) for i in range(tfidf_matrix.shape[0])]\n\n    return tfidf_tuples, list(feature_names)\n```"}
{"task_id": "BigCodeBench/1101", "solution": "import subprocess\nimport os\nimport glob\nimport time\ndef task_func(test_dir):\n    result = {}\n    for file in glob.glob(os.path.join(test_dir, \"*.py\")):\n        start_time = time.time()\n        subprocess.run([\"python\", file])\n        end_time = time.time()\n        result[file] = end_time - start_time\n    return result", "raw_solution": "import subprocess\nimport os\nimport glob\nimport time\n\ndef task_func(test_dir):\n    result = {}\n    for file in glob.glob(os.path.join(test_dir, \"*.py\")):\n        start_time = time.time()\n        subprocess.run([\"python\", file])\n        end_time = time.time()\n        result[file] = end_time - start_time\n    return result\n```"}
{"task_id": "BigCodeBench/1102", "solution": "import subprocess\nimport shlex\nfrom datetime import datetime\ndef task_func(script_path: str) -> dict:\n    start_time = datetime.now()\n    with subprocess.Popen(shlex.split(f\"Rscript {script_path}\"), stdout=subprocess.PIPE, stderr=subprocess.PIPE) as process:\n        stdout, stderr = process.communicate()\n    end_time = datetime.now()\n    return {\n        \"start_time\": start_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n        \"end_time\": end_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n        \"stdout\": stdout.decode(),\n        \"stderr\": stderr.decode()\n    }", "raw_solution": "import subprocess\nimport shlex\nfrom datetime import datetime\n\ndef task_func(script_path: str) -> dict:\n    start_time = datetime.now()\n    with subprocess.Popen(shlex.split(f\"Rscript {script_path}\"), stdout=subprocess.PIPE, stderr=subprocess.PIPE) as process:\n        stdout, stderr = process.communicate()\n    end_time = datetime.now()\n    return {\n        \"start_time\": start_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n        \"end_time\": end_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n        \"stdout\": stdout.decode(),\n        \"stderr\": stderr.decode()\n    }\n```"}
{"task_id": "BigCodeBench/1103", "solution": "import subprocess\nimport shutil\nimport os\ndef task_func(script_path: str, temp_dir: str) -> str:\n    try:\n        shutil.copy(script_path, temp_dir)\n        subprocess.run([\"python\", os.path.join(temp_dir, os.path.basename(script_path))], check=True, timeout=10)\n        return \"Script executed successfully!\"\n    except subprocess.CalledProcessError:\n        return \"Script execution failed!\"\n    except TimeoutError:\n        return \"Script execution timed out!\"", "raw_solution": "import subprocess\nimport shutil\nimport os\n\ndef task_func(script_path: str, temp_dir: str) -> str:\n    try:\n        shutil.copy(script_path, temp_dir)\n        subprocess.run([\"python\", os.path.join(temp_dir, os.path.basename(script_path))], check=True, timeout=10)\n        return \"Script executed successfully!\"\n    except subprocess.CalledProcessError:\n        return \"Script execution failed!\"\n    except TimeoutError:\n        return \"Script execution timed out!\"\n```"}
{"task_id": "BigCodeBench/1104", "solution": "import subprocess\nimport os\nimport threading\ndef task_func(script_path: str, timeout: int = 60) -> str:\n    if not os.path.exists(script_path):\n        raise FileNotFoundError(f\"File {script_path} does not exist.\")\n\n    def target():\n        subprocess.run([\"python\", script_path])\n\n    thread = threading.Thread(target=target)\n    thread.start()\n\n    thread.join(timeout)\n\n    if thread.is_alive():\n        thread.terminate()\n        return \"Terminating process due to timeout.\"\n\n    return \"Script executed successfully.\"", "raw_solution": "import subprocess\nimport os\nimport threading\n\ndef task_func(script_path: str, timeout: int = 60) -> str:\n    if not os.path.exists(script_path):\n        raise FileNotFoundError(f\"File {script_path} does not exist.\")\n\n    def target():\n        subprocess.run([\"python\", script_path])\n\n    thread = threading.Thread(target=target)\n    thread.start()\n\n    thread.join(timeout)\n\n    if thread.is_alive():\n        thread.terminate()\n        return \"Terminating process due to timeout.\"\n\n    return \"Script executed successfully.\"\n```"}
{"task_id": "BigCodeBench/1105", "solution": "import subprocess\nimport os\nimport time\nimport glob\ndef task_func(r_script_path: str, output_path: str, duration: int) -> (bool, str):\n    start_time = time.time()\n    while time.time() - start_time < duration:\n        if os.path.exists(output_path):\n            return True, 'File generated successfully within the specified duration.'\n        subprocess.run([\"Rscript\", r_script_path])\n    return False, 'File not generated within the specified duration.'", "raw_solution": "import subprocess\nimport os\nimport time\nimport glob\n\ndef task_func(r_script_path: str, output_path: str, duration: int) -> (bool, str):\n    start_time = time.time()\n    while time.time() - start_time < duration:\n        if os.path.exists(output_path):\n            return True, 'File generated successfully within the specified duration.'\n        subprocess.run([\"Rscript\", r_script_path])\n    return False, 'File not generated within the specified duration.'\n```"}
{"task_id": "BigCodeBench/1106", "solution": "from datetime import datetime\nimport os\nfrom pathlib import Path\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(file_path):\n    file_path = Path(file_path)\n    if not file_path.exists():\n        raise FileNotFoundError(f\"File {file_path} does not exist\")\n    creation_time = os.path.getctime(file_path)\n    creation_time_str = datetime.fromtimestamp(creation_time).strftime(DATE_FORMAT)\n    return creation_time_str", "raw_solution": "from datetime import datetime\nimport os\nfrom pathlib import Path\n\n# Constants\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(file_path):\n    file_path = Path(file_path)\n    if not file_path.exists():\n        raise FileNotFoundError(f\"File {file_path} does not exist\")\n    creation_time = os.path.getctime(file_path)\n    creation_time_str = datetime.fromtimestamp(creation_time).strftime(DATE_FORMAT)\n    return creation_time_str\n```"}
{"task_id": "BigCodeBench/1107", "solution": "from datetime import datetime\nimport pytz\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(unix_timestamp, target_timezone):\n    # Convert Unix timestamp to datetime object\n    dt = datetime.utcfromtimestamp(unix_timestamp)\n\n    # Convert datetime object to target timezone\n    target_tz = pytz.timezone(target_timezone)\n    dt = dt.replace(tzinfo=pytz.utc).astimezone(target_tz)\n\n    # Format datetime object as string\n    return dt.strftime(DATE_FORMAT)", "raw_solution": "from datetime import datetime\nimport pytz\n\n# Constants\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(unix_timestamp, target_timezone):\n    # Convert Unix timestamp to datetime object\n    dt = datetime.utcfromtimestamp(unix_timestamp)\n\n    # Convert datetime object to target timezone\n    target_tz = pytz.timezone(target_timezone)\n    dt = dt.replace(tzinfo=pytz.utc).astimezone(target_tz)\n\n    # Format datetime object as string\n    return dt.strftime(DATE_FORMAT)\n```"}
{"task_id": "BigCodeBench/1108", "solution": "from collections import Counter\nimport re\ndef task_func(result):\n    url_values = [item['url'] for item in result]\n    url_values_count = Counter(url_values)\n    most_common_values = url_values_count.most_common(1)\n    return {most_common_values[0][0]: most_common_values[0][1]}", "raw_solution": "from collections import Counter\nimport re\ndef task_func(result):\n    url_values = [item['url'] for item in result]\n    url_values_count = Counter(url_values)\n    most_common_values = url_values_count.most_common(1)\n    return {most_common_values[0][0]: most_common_values[0][1]}\n```"}
{"task_id": "BigCodeBench/1109", "solution": "import os\nfrom nltk import word_tokenize\ndef task_func(file_path='File.txt'):\n    if not os.path.exists(file_path):\n        return \"File not found\"\n\n    with open(file_path, 'r') as file:\n        lines = file.readlines()\n\n    tokens = []\n    for line in lines:\n        tokens.extend(word_tokenize(line))\n\n    return tokens", "raw_solution": "import os\nfrom nltk import word_tokenize\n\ndef task_func(file_path='File.txt'):\n    if not os.path.exists(file_path):\n        return \"File not found\"\n\n    with open(file_path, 'r') as file:\n        lines = file.readlines()\n\n    tokens = []\n    for line in lines:\n        tokens.extend(word_tokenize(line))\n\n    return tokens\n```"}
{"task_id": "BigCodeBench/1110", "solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\ndef task_func(word_dict):\n    # Create a list of all letters in the words\n    letters = list(itertools.chain(*[list(word) for word in word_dict.values()]))\n    # Count the frequency of each letter\n    letter_counts = Counter(letters)\n    return dict(letter_counts)", "raw_solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\ndef task_func(word_dict):\n    # Create a list of all letters in the words\n    letters = list(itertools.chain(*[list(word) for word in word_dict.values()]))\n    # Count the frequency of each letter\n    letter_counts = Counter(letters)\n    return dict(letter_counts)\n```"}
{"task_id": "BigCodeBench/1111", "solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\nANIMAL = ['cat', 'camel', 'cow', 'dog', 'elephant', 'fox', 'giraffe', 'hippo', 'iguana', 'jaguar']\ndef task_func(animal_dict):\n    # Filter dictionary to only include animals\n    animal_dict = {key: value for key, value in animal_dict.items() if key in ANIMAL}\n    # Flatten values and count frequencies\n    letter_counts = Counter(itertools.chain.from_iterable(animal_dict.values()))\n    # Sort by frequency in descending order\n    sorted_counts = sorted(letter_counts.items(), key=itemgetter(1), reverse=True)\n    # Convert to dictionary and return\n    return dict(sorted_counts)", "raw_solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\n#CONSTANT\nANIMAL = ['cat', 'camel', 'cow', 'dog', 'elephant', 'fox', 'giraffe', 'hippo', 'iguana', 'jaguar']\ndef task_func(animal_dict):\n    # Filter dictionary to only include animals\n    animal_dict = {key: value for key, value in animal_dict.items() if key in ANIMAL}\n    # Flatten values and count frequencies\n    letter_counts = Counter(itertools.chain.from_iterable(animal_dict.values()))\n    # Sort by frequency in descending order\n    sorted_counts = sorted(letter_counts.items(), key=itemgetter(1), reverse=True)\n    # Convert to dictionary and return\n    return dict(sorted_counts)\n```"}
{"task_id": "BigCodeBench/1112", "solution": "import csv\nimport random\nDATA = ['Temperature', 'Humidity', 'Pressure']\nRANGE = {\n    'Temperature': (-50, 50),\n    'Humidity': (0, 100),\n    'Pressure': (980, 1040)\n}\ndef task_func(file_name=\"data.csv\"):\n    with open(file_name, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(DATA)\n        for hour in range(24):\n            row = [random.randint(RANGE[data][0], RANGE[data][1]) for data in DATA]\n            writer.writerow(row)\n    return file_name", "raw_solution": "import csv\nimport random\n\n# Constants\nDATA = ['Temperature', 'Humidity', 'Pressure']\nRANGE = {\n    'Temperature': (-50, 50),\n    'Humidity': (0, 100),\n    'Pressure': (980, 1040)\n}\n\ndef task_func(file_name=\"data.csv\"):\n    with open(file_name, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(DATA)\n        for hour in range(24):\n            row = [random.randint(RANGE[data][0], RANGE[data][1]) for data in DATA]\n            writer.writerow(row)\n    return file_name\n```"}
{"task_id": "BigCodeBench/1113", "solution": "import csv\nimport collections\ndef task_func(csv_file, emp_prefix='EMP$$'):\n    with open(csv_file, 'r') as file:\n        reader = csv.reader(file)\n        next(reader)  # Skip the header\n        emp_count = collections.defaultdict(int)\n        for row in reader:\n            emp_id = row[0]\n            if emp_id.startswith(emp_prefix):\n                emp_count[emp_id] += 1\n    return emp_count", "raw_solution": "import csv\nimport collections\ndef task_func(csv_file, emp_prefix='EMP$$'):\n    with open(csv_file, 'r') as file:\n        reader = csv.reader(file)\n        next(reader)  # Skip the header\n        emp_count = collections.defaultdict(int)\n        for row in reader:\n            emp_id = row[0]\n            if emp_id.startswith(emp_prefix):\n                emp_count[emp_id] += 1\n    return emp_count\n```"}
{"task_id": "BigCodeBench/1114", "solution": "from collections import defaultdict\nfrom random import randint\ndef task_func(dict1):\n    result = defaultdict(list)\n    for key, value in dict1.items():\n        if key.startswith('EMP$$'):\n            result[key].append(value)\n    return result", "raw_solution": "from collections import defaultdict\nfrom random import randint\n\ndef task_func(dict1):\n    result = defaultdict(list)\n    for key, value in dict1.items():\n        if key.startswith('EMP$$'):\n            result[key].append(value)\n    return result\n```"}
{"task_id": "BigCodeBench/1115", "solution": "import random\nfrom string import ascii_uppercase\ndef task_func(dict1):\n    result = []\n    for key, value in dict1.items():\n        for i in range(value):\n            random_string = ''.join(random.choice(ascii_uppercase) for _ in range(5))\n            result.append(key + random_string)\n    return result", "raw_solution": "import random\nfrom string import ascii_uppercase\n\ndef task_func(dict1):\n    result = []\n    for key, value in dict1.items():\n        for i in range(value):\n            random_string = ''.join(random.choice(ascii_uppercase) for _ in range(5))\n            result.append(key + random_string)\n    return result\n```"}
{"task_id": "BigCodeBench/1116", "solution": "import random\nimport statistics\nAGE_RANGE = (22, 60)\ndef task_func(dict1):\n    if \"EMP$$\" in dict1:\n        ages = [random.randint(AGE_RANGE[0], AGE_RANGE[1]) for _ in range(len(dict1[\"EMP$$\"]))]\n        mean = statistics.mean(ages)\n        median = statistics.median(ages)\n        mode = statistics.mode(ages)\n        return (mean, median, mode)\n    else:\n        return (None, None, None)", "raw_solution": "import random\nimport statistics\n# Constants\nAGE_RANGE = (22, 60)\ndef task_func(dict1):\n    if \"EMP$$\" in dict1:\n        ages = [random.randint(AGE_RANGE[0], AGE_RANGE[1]) for _ in range(len(dict1[\"EMP$$\"]))]\n        mean = statistics.mean(ages)\n        median = statistics.median(ages)\n        mode = statistics.mode(ages)\n        return (mean, median, mode)\n    else:\n        return (None, None, None)\n```"}
{"task_id": "BigCodeBench/1117", "solution": "import collections\nimport random\nimport json\nLEVELS = ['Junior', 'Mid', 'Senior']\ndef task_func(department_data):\n    result = {}\n    for department in department_data:\n        result[department] = random.choices(LEVELS, k=department_data[department])\n    return json.dumps(result)", "raw_solution": "import collections\nimport random\nimport json\n# Constants\nPREFICES = ['EMP$$', 'MAN$$', 'DEV$$', 'HR$$']\nLEVELS = ['Junior', 'Mid', 'Senior']\ndef task_func(department_data):\n    result = {}\n    for department in department_data:\n        result[department] = random.choices(LEVELS, k=department_data[department])\n    return json.dumps(result)\n```"}
{"task_id": "BigCodeBench/1118", "solution": "import json\nimport csv\nimport requests\nfrom io import StringIO\nCSV_URL = 'https://example.com/data.csv'\nJSON_FILE = 'data.json'\ndef task_func(csv_url=CSV_URL, json_file_path=JSON_FILE):\n    # Download CSV file\n    response = requests.get(csv_url)\n    response.raise_for_status()\n\n    # Convert CSV to JSON\n    csv_data = StringIO(response.text)\n    reader = csv.DictReader(csv_data)\n    json_data = [row for row in reader]\n\n    # Save JSON to file\n    with open(json_file_path, 'w') as json_file:\n        json.dump(json_data, json_file)\n\n    return json_file_path", "raw_solution": "import json\nimport csv\nimport requests\nfrom io import StringIO\n\n# Constants\nCSV_URL = 'https://example.com/data.csv'\nJSON_FILE = 'data.json'\n\ndef task_func(csv_url=CSV_URL, json_file_path=JSON_FILE):\n    # Download CSV file\n    response = requests.get(csv_url)\n    response.raise_for_status()\n\n    # Convert CSV to JSON\n    csv_data = StringIO(response.text)\n    reader = csv.DictReader(csv_data)\n    json_data = [row for row in reader]\n\n    # Save JSON to file\n    with open(json_file_path, 'w') as json_file:\n        json.dump(json_data, json_file)\n\n    return json_file_path\n```"}
{"task_id": "BigCodeBench/1119", "solution": "import codecs\nimport random\nimport string\nimport hashlib\ndef task_func(password_length=10, salt=\"salty\"):\n    characters = string.ascii_letters + string.digits + string.punctuation\n    password = ''.join(random.choice(characters) for i in range(password_length))\n    salted_password = password + salt\n    hashed_password = hashlib.sha256(salted_password.encode()).hexdigest()\n    return hashed_password", "raw_solution": "import codecs\nimport random\nimport string\nimport hashlib\n\ndef task_func(password_length=10, salt=\"salty\"):\n    characters = string.ascii_letters + string.digits + string.punctuation\n    password = ''.join(random.choice(characters) for i in range(password_length))\n    salted_password = password + salt\n    hashed_password = hashlib.sha256(salted_password.encode()).hexdigest()\n    return hashed_password\n```"}
{"task_id": "BigCodeBench/1120", "solution": "import re\nimport urllib.parse\nimport requests\nimport json\ndef task_func(myString, API_KEY):\n    # Extract URLs from the string\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n\n    # Extract domain from URLs\n    domains = [urllib.parse.urlparse(url).netloc for url in urls]\n\n    # Initialize dictionary to store geolocation data\n    geolocation_data = {}\n\n    # Iterate over each domain\n    for domain in domains:\n        # Construct the IP API URL\n        url = f\"https://ipapi.co/{domain}/json/\"\n\n        # Send the API request\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n        except requests.exceptions.RequestException:\n            geolocation_data[domain] = None\n            continue\n\n        # Parse the response JSON\n        data = response.json()\n\n        # Store the geolocation data in the dictionary\n        geolocation_data[domain] = data\n\n    return geolocation_data", "raw_solution": "import re\nimport urllib.parse\nimport requests\nimport json\n\ndef task_func(myString, API_KEY):\n    # Extract URLs from the string\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n\n    # Extract domain from URLs\n    domains = [urllib.parse.urlparse(url).netloc for url in urls]\n\n    # Initialize dictionary to store geolocation data\n    geolocation_data = {}\n\n    # Iterate over each domain\n    for domain in domains:\n        # Construct the IP API URL\n        url = f\"https://ipapi.co/{domain}/json/\"\n\n        # Send the API request\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n        except requests.exceptions.RequestException:\n            geolocation_data[domain] = None\n            continue\n\n        # Parse the response JSON\n        data = response.json()\n\n        # Store the geolocation data in the dictionary\n        geolocation_data[domain] = data\n\n    return geolocation_data\n```"}
{"task_id": "BigCodeBench/1121", "solution": "import re\nimport urllib.parse\nimport requests\nimport json\ndef task_func(myString, API_KEY):\n    # Extract URLs from the string\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n\n    # Extract domain from URLs\n    domains = [urllib.parse.urlparse(url).netloc for url in urls]\n\n    # Initialize dictionary to store geolocation data\n    geolocation_data = {}\n\n    # Iterate over each domain\n    for domain in domains:\n        # Construct the IP API URL\n        url = f\"https://ipapi.co/{domain}/json/\"\n\n        # Send the API request\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n        except requests.exceptions.RequestException:\n            geolocation_data[domain] = None\n            continue\n\n        # Parse the response JSON\n        data = response.json()\n\n        # Store the geolocation data in the dictionary\n        geolocation_data[domain] = data\n\n    return geolocation_data", "raw_solution": "import re\nimport urllib.parse\nimport requests\nimport json\n\ndef task_func(myString, API_KEY):\n    # Extract URLs from the string\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n\n    # Extract domain from URLs\n    domains = [urllib.parse.urlparse(url).netloc for url in urls]\n\n    # Initialize dictionary to store geolocation data\n    geolocation_data = {}\n\n    # Iterate over each domain\n    for domain in domains:\n        # Construct the IP API URL\n        url = f\"https://ipapi.co/{domain}/json/\"\n\n        # Send the API request\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n        except requests.exceptions.RequestException:\n            geolocation_data[domain] = None\n            continue\n\n        # Parse the response JSON\n        data = response.json()\n\n        # Store the geolocation data in the dictionary\n        geolocation_data[domain] = data\n\n    return geolocation_data\n```"}
{"task_id": "BigCodeBench/1122", "solution": "import re\nimport socket\nimport urllib.parse\ndef task_func(myString):\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    urls = re.findall(url_pattern, myString)\n    domain_ip_dict = {}\n    for url in urls:\n        domain = urllib.parse.urlparse(url).netloc\n        try:\n            ip = socket.gethostbyname(domain)\n            domain_ip_dict[domain] = ip\n        except socket.gaierror:\n            domain_ip_dict[domain] = None\n    return domain_ip_dict", "raw_solution": "import re\nimport socket\nimport urllib.parse\n\ndef task_func(myString):\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    urls = re.findall(url_pattern, myString)\n    domain_ip_dict = {}\n    for url in urls:\n        domain = urllib.parse.urlparse(url).netloc\n        try:\n            ip = socket.gethostbyname(domain)\n            domain_ip_dict[domain] = ip\n        except socket.gaierror:\n            domain_ip_dict[domain] = None\n    return domain_ip_dict\n```"}
{"task_id": "BigCodeBench/1123", "solution": "import re\nimport urllib.parse\nimport ssl\nimport socket\ndef task_func(myString):\n    # Extract all URLs from the string\n    urls = re.findall(r'https://[^\\s]+', myString)\n\n    # Initialize an empty dictionary to store the domain and SSL certificate expiry date\n    domain_ssl_dict = {}\n\n    # Loop through each URL\n    for url in urls:\n        try:\n            # Parse the URL to get the domain\n            domain = urllib.parse.urlparse(url).netloc\n\n            # Get the SSL certificate\n            context = ssl.create_default_context()\n            with socket.create_connection((domain, 443)) as sock:\n                with context.wrap_socket(sock, server_hostname=domain) as ssock:\n                    print(ssock.getpeercert())\n                    # Extract the SSL certificate expiry date\n                    ssl_info = ssock.getpeercert()\n                    expiry_date = ssl_info['notAfter']\n\n                    # Add the domain and SSL certificate expiry date to the dictionary\n                    domain_ssl_dict[domain] = expiry_date\n        except:\n            # Ignore any URLs where the SSL certificate cannot be retrieved\n            pass\n\n    return domain_ssl_dict", "raw_solution": "import re\nimport urllib.parse\nimport ssl\nimport socket\n\ndef task_func(myString):\n    # Extract all URLs from the string\n    urls = re.findall(r'https://[^\\s]+', myString)\n\n    # Initialize an empty dictionary to store the domain and SSL certificate expiry date\n    domain_ssl_dict = {}\n\n    # Loop through each URL\n    for url in urls:\n        try:\n            # Parse the URL to get the domain\n            domain = urllib.parse.urlparse(url).netloc\n\n            # Get the SSL certificate\n            context = ssl.create_default_context()\n            with socket.create_connection((domain, 443)) as sock:\n                with context.wrap_socket(sock, server_hostname=domain) as ssock:\n                    print(ssock.getpeercert())\n                    # Extract the SSL certificate expiry date\n                    ssl_info = ssock.getpeercert()\n                    expiry_date = ssl_info['notAfter']\n\n                    # Add the domain and SSL certificate expiry date to the dictionary\n                    domain_ssl_dict[domain] = expiry_date\n        except:\n            # Ignore any URLs where the SSL certificate cannot be retrieved\n            pass\n\n    return domain_ssl_dict\n```"}
{"task_id": "BigCodeBench/1124", "solution": "import re\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nimport requests\ndef task_func(myString):\n    url_regex = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    url_match = url_regex.search(myString)\n    if url_match:\n        url = url_match.group(0)\n        try:\n            response = requests.get(url)\n            if response.status_code == 200:\n                soup = BeautifulSoup(response.text, 'html.parser')\n                title_tag = soup.find('title')\n                if title_tag:\n                    return title_tag.text\n                else:\n                    return \"No title tag found in the webpage.\"\n            else:\n                return f\"Unable to fetch the content of the URL: {url}\"\n        except requests.exceptions.RequestException as e:\n            return f\"Unable to fetch the content of the URL: {url}\"\n    else:\n        return \"No valid URL found in the provided string.\"", "raw_solution": "import re\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nimport requests\n\ndef task_func(myString):\n    url_regex = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    url_match = url_regex.search(myString)\n    if url_match:\n        url = url_match.group(0)\n        try:\n            response = requests.get(url)\n            if response.status_code == 200:\n                soup = BeautifulSoup(response.text, 'html.parser')\n                title_tag = soup.find('title')\n                if title_tag:\n                    return title_tag.text\n                else:\n                    return \"No title tag found in the webpage.\"\n            else:\n                return f\"Unable to fetch the content of the URL: {url}\"\n        except requests.exceptions.RequestException as e:\n            return f\"Unable to fetch the content of the URL: {url}\"\n    else:\n        return \"No valid URL found in the provided string.\"\n```"}
{"task_id": "BigCodeBench/1125", "solution": "import re\nimport json\nimport requests\ndef task_func(myString, token):\n    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n    urls = re.findall(url_pattern, myString)\n    if urls:\n        url = urls[0]\n        headers = {'Authorization': 'Bearer ' + token}\n        payload = {'url': url}\n        response = requests.post('https://api.example.com/url', headers=headers, data=json.dumps(payload))\n        return response.json()\n    else:\n        return None", "raw_solution": "import re\nimport json\nimport requests\n\ndef task_func(myString, token):\n    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n    urls = re.findall(url_pattern, myString)\n    if urls:\n        url = urls[0]\n        headers = {'Authorization': 'Bearer ' + token}\n        payload = {'url': url}\n        response = requests.post('https://api.example.com/url', headers=headers, data=json.dumps(payload))\n        return response.json()\n    else:\n        return None\n```"}
{"task_id": "BigCodeBench/1126", "solution": "import re\nimport hashlib\ndef task_func(input_str):\n    cleaned_str = re.sub(r'[^a-zA-Z0-9]', '', input_str)\n    hashed_str = hashlib.sha256(cleaned_str.encode()).hexdigest()\n    return hashed_str", "raw_solution": "import re\nimport hashlib\n\ndef task_func(input_str):\n    cleaned_str = re.sub(r'[^a-zA-Z0-9]', '', input_str)\n    hashed_str = hashlib.sha256(cleaned_str.encode()).hexdigest()\n    return hashed_str\n```"}
{"task_id": "BigCodeBench/1127", "solution": "import os\nimport re\nimport hashlib\ndef task_func(path, delimiter):\n    if not os.path.exists(path):\n        return []\n    components = re.split(delimiter, path)\n    result = []\n    for component in components:\n        if os.path.isfile(component):\n            with open(component, 'rb') as file:\n                file_hash = hashlib.sha256()\n                chunk = file.read(8192)\n                while chunk:\n                    file_hash.update(chunk)\n                    chunk = file.read(8192)\n                result.append((component, file_hash.hexdigest()))\n        else:\n            result.append((component, None))\n    return result", "raw_solution": "import os\nimport re\nimport hashlib\n\ndef task_func(path, delimiter):\n    if not os.path.exists(path):\n        return []\n    components = re.split(delimiter, path)\n    result = []\n    for component in components:\n        if os.path.isfile(component):\n            with open(component, 'rb') as file:\n                file_hash = hashlib.sha256()\n                chunk = file.read(8192)\n                while chunk:\n                    file_hash.update(chunk)\n                    chunk = file.read(8192)\n                result.append((component, file_hash.hexdigest()))\n        else:\n            result.append((component, None))\n    return result\n```"}
{"task_id": "BigCodeBench/1128", "solution": "import json\nimport os\nimport hashlib\nimport base64\nimport time\ndef task_func(file_path, unknown_key):\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n\n    value_to_hash = data['A'][unknown_key]['maindata'][0]['Info']\n    hashed_value = hashlib.sha256(value_to_hash.encode()).digest()\n    encoded_hash = base64.b64encode(hashed_value).decode()\n\n    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n    new_file_path = os.path.join(os.path.dirname(file_path), f\"{timestamp}.txt\")\n\n    with open(new_file_path, 'w') as new_file:\n        new_file.write(encoded_hash)\n\n    return new_file_path", "raw_solution": "import json\nimport os\nimport hashlib\nimport base64\nimport time\n\ndef task_func(file_path, unknown_key):\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n\n    value_to_hash = data['A'][unknown_key]['maindata'][0]['Info']\n    hashed_value = hashlib.sha256(value_to_hash.encode()).digest()\n    encoded_hash = base64.b64encode(hashed_value).decode()\n\n    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n    new_file_path = os.path.join(os.path.dirname(file_path), f\"{timestamp}.txt\")\n\n    with open(new_file_path, 'w') as new_file:\n        new_file.write(encoded_hash)\n\n    return new_file_path\n```"}
{"task_id": "BigCodeBench/1129", "solution": "import json\nimport requests\nimport os\nfrom datetime import datetime\ndef task_func(json_data, unknown_key, save_dir=None):\n    data = json.loads(json_data)\n    url = data[unknown_key]\n    response = requests.get(url)\n    if save_dir is None:\n        save_dir = os.getcwd()\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S%f')\n    filename = f\"{unknown_key}_{timestamp}.txt\"\n    file_path = os.path.join(save_dir, filename)\n    with open(file_path, 'wb') as file:\n        file.write(response.content)\n    return file_path", "raw_solution": "import json\nimport requests\nimport os\nfrom datetime import datetime\n\ndef task_func(json_data, unknown_key, save_dir=None):\n    data = json.loads(json_data)\n    url = data[unknown_key]\n    response = requests.get(url)\n    if save_dir is None:\n        save_dir = os.getcwd()\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S%f')\n    filename = f\"{unknown_key}_{timestamp}.txt\"\n    file_path = os.path.join(save_dir, filename)\n    with open(file_path, 'wb') as file:\n        file.write(response.content)\n    return file_path\n```"}
{"task_id": "BigCodeBench/1130", "solution": "import os\nimport hashlib\nimport json\nfrom pathlib import Path\ndef task_func(directory: str) -> str:\n    hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, 'rb') as f:\n                file_hash = hashlib.sha256(f.read()).hexdigest()\n            hashes[file_path] = file_hash\n\n    json_file_path = os.path.join(directory, 'hashes.json')\n    with open(json_file_path, 'w') as f:\n        json.dump(hashes, f)\n\n    return json_file_path", "raw_solution": "import os\nimport hashlib\nimport json\nfrom pathlib import Path\n\ndef task_func(directory: str) -> str:\n    hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, 'rb') as f:\n                file_hash = hashlib.sha256(f.read()).hexdigest()\n            hashes[file_path] = file_hash\n\n    json_file_path = os.path.join(directory, 'hashes.json')\n    with open(json_file_path, 'w') as f:\n        json.dump(hashes, f)\n\n    return json_file_path\n```"}
{"task_id": "BigCodeBench/1131", "solution": "import hashlib\nimport binascii\ndef task_func(salt, cursor):\n    if not isinstance(salt, str):\n        raise TypeError(\"Salt must be a string\")\n\n    cursor.execute(\"SELECT * FROM users\")\n    users = cursor.fetchall()\n\n    updated_count = 0\n    for user in users:\n        password = user[1]\n        hashed_password = hashlib.pbkdf2_hmac('sha256', password.encode(), salt.encode(), 100000)\n        hashed_password = binascii.hexlify(hashed_password).decode()\n\n        cursor.execute(\"UPDATE users SET password = ? WHERE id = ?\", (hashed_password, user[0]))\n        updated_count += 1\n\n    return updated_count", "raw_solution": "import hashlib\nimport binascii\n\ndef task_func(salt, cursor):\n    if not isinstance(salt, str):\n        raise TypeError(\"Salt must be a string\")\n\n    cursor.execute(\"SELECT * FROM users\")\n    users = cursor.fetchall()\n\n    updated_count = 0\n    for user in users:\n        password = user[1]\n        hashed_password = hashlib.pbkdf2_hmac('sha256', password.encode(), salt.encode(), 100000)\n        hashed_password = binascii.hexlify(hashed_password).decode()\n\n        cursor.execute(\"UPDATE users SET password = ? WHERE id = ?\", (hashed_password, user[0]))\n        updated_count += 1\n\n    return updated_count\n```"}
{"task_id": "BigCodeBench/1132", "solution": "import os\nimport hashlib\nimport base64\ndef task_func(password, PREFIX=\"ME\", SALT_LENGTH=16):\n    if SALT_LENGTH < 0:\n        raise ValueError(\"SALT_LENGTH cannot be negative\")\n    salt = os.urandom(SALT_LENGTH)\n    hashed_password = hashlib.sha256(salt + password.encode()).digest()\n    return base64.b64encode(hashed_password).decode()", "raw_solution": "import os\nimport hashlib\nimport base64\n\ndef task_func(password, PREFIX=\"ME\", SALT_LENGTH=16):\n    if SALT_LENGTH < 0:\n        raise ValueError(\"SALT_LENGTH cannot be negative\")\n    salt = os.urandom(SALT_LENGTH)\n    hashed_password = hashlib.sha256(salt + password.encode()).digest()\n    return base64.b64encode(hashed_password).decode()\n```"}
{"task_id": "BigCodeBench/1133", "solution": "import json\nimport requests\ndef task_func(API_URL, endpoint, PREFIX):\n    try:\n        response = requests.get(API_URL + endpoint)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise RuntimeError(f\"Error fetching data from API: {e}\")\n\n    data = response.json()\n    filename = f\"{PREFIX}_{endpoint}.json\"\n\n    try:\n        with open(filename, 'w') as file:\n            json.dump(data, file)\n    except IOError as e:\n        raise RuntimeError(f\"Error writing to file: {e}\")\n\n    return filename", "raw_solution": "import json\nimport requests\n\ndef task_func(API_URL, endpoint, PREFIX):\n    try:\n        response = requests.get(API_URL + endpoint)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise RuntimeError(f\"Error fetching data from API: {e}\")\n\n    data = response.json()\n    filename = f\"{PREFIX}_{endpoint}.json\"\n\n    try:\n        with open(filename, 'w') as file:\n            json.dump(data, file)\n    except IOError as e:\n        raise RuntimeError(f\"Error writing to file: {e}\")\n\n    return filename\n```"}
{"task_id": "BigCodeBench/1134", "solution": "import os\nimport glob\nimport hashlib\ndef task_func(source_dir, target_dir, prefix='#Hash: '):\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory {source_dir} does not exist.\")\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    file_paths = glob.glob(os.path.join(source_dir, '*'))\n    new_file_paths = []\n\n    for file_path in file_paths:\n        with open(file_path, 'r') as file:\n            content = file.read()\n            hash_value = hashlib.md5(content.encode()).hexdigest()\n            modified_content = f\"{prefix}{hash_value}\\n{content}\"\n\n            new_file_path = os.path.join(target_dir, os.path.basename(file_path))\n            with open(new_file_path, 'w') as new_file:\n                new_file.write(modified_content)\n\n            new_file_paths.append(new_file_path)\n\n    return new_file_paths", "raw_solution": "import os\nimport glob\nimport hashlib\n\ndef task_func(source_dir, target_dir, prefix='#Hash: '):\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory {source_dir} does not exist.\")\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    file_paths = glob.glob(os.path.join(source_dir, '*'))\n    new_file_paths = []\n\n    for file_path in file_paths:\n        with open(file_path, 'r') as file:\n            content = file.read()\n            hash_value = hashlib.md5(content.encode()).hexdigest()\n            modified_content = f\"{prefix}{hash_value}\\n{content}\"\n\n            new_file_path = os.path.join(target_dir, os.path.basename(file_path))\n            with open(new_file_path, 'w') as new_file:\n                new_file.write(modified_content)\n\n            new_file_paths.append(new_file_path)\n\n    return new_file_paths\n```"}
{"task_id": "BigCodeBench/1135", "solution": "import collections\nimport json\nimport requests\ndef task_func(user, API_URL = 'https://api.github.com/users/'):\n    response = requests.get(API_URL + user + '/repos')\n    data = json.loads(response.text)\n    repo_data = [(repo['name'], repo['created_at']) for repo in data]\n    repo_data.sort(key=lambda x: x[1])\n    return [repo[0] for repo in repo_data]", "raw_solution": "import collections\nimport json\nimport requests\n\ndef task_func(user, API_URL = 'https://api.github.com/users/'):\n    response = requests.get(API_URL + user + '/repos')\n    data = json.loads(response.text)\n    repo_data = [(repo['name'], repo['created_at']) for repo in data]\n    repo_data.sort(key=lambda x: x[1])\n    return [repo[0] for repo in repo_data]\n```"}
{"task_id": "BigCodeBench/1136", "solution": "import bs4\nimport requests\nimport re\nimport csv\ndef task_func(url=\"http://example.com\", csv_path=\"emails.csv\", \n          regex=r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b\", \n          headers={'User-Agent': 'Mozilla/5.0'}):\n    response = requests.get(url, headers=headers)\n    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n    emails = re.findall(regex, str(soup))\n\n    with open(csv_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Emails\"])\n        for email in emails:\n            writer.writerow([email])\n\n    return csv_path", "raw_solution": "import bs4\nimport requests\nimport re\nimport csv\n\ndef task_func(url=\"http://example.com\", csv_path=\"emails.csv\", \n          regex=r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b\", \n          headers={'User-Agent': 'Mozilla/5.0'}):\n    response = requests.get(url, headers=headers)\n    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n    emails = re.findall(regex, str(soup))\n\n    with open(csv_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Emails\"])\n        for email in emails:\n            writer.writerow([email])\n\n    return csv_path\n```"}
{"task_id": "BigCodeBench/1137", "solution": "import bs4\nimport requests\nimport re\nimport json\ndef task_func(url: str, output_path: str) -> list:\n    if url.startswith(\"http\"):\n        response = requests.get(url)\n        soup = bs4.BeautifulSoup(response.text, 'html.parser')\n    else:\n        with open(url, 'r') as file:\n            soup = bs4.BeautifulSoup(file.read(), 'html.parser')\n\n    phone_numbers = re.findall(r'\\(?\\b[2-9][0-9]{2}\\)?[-. ]?[2-9][0-9]{2}[-. ]?[0-9]{4}\\b', soup.text)\n\n    with open(output_path, 'w') as file:\n        json.dump(phone_numbers, file)\n\n    return phone_numbers", "raw_solution": "import bs4\nimport requests\nimport re\nimport json\n\ndef task_func(url: str, output_path: str) -> list:\n    if url.startswith(\"http\"):\n        response = requests.get(url)\n        soup = bs4.BeautifulSoup(response.text, 'html.parser')\n    else:\n        with open(url, 'r') as file:\n            soup = bs4.BeautifulSoup(file.read(), 'html.parser')\n\n    phone_numbers = re.findall(r'\\(?\\b[2-9][0-9]{2}\\)?[-. ]?[2-9][0-9]{2}[-. ]?[0-9]{4}\\b', soup.text)\n\n    with open(output_path, 'w') as file:\n        json.dump(phone_numbers, file)\n\n    return phone_numbers\n```"}
{"task_id": "BigCodeBench/1138", "solution": "import numpy as np\nimport itertools\ndef task_func(matrix):\n    # Flatten the 2D array and sort it\n    flat_array = np.sort(matrix.flatten())\n\n    # Generate all unique combinations of two elements\n    combinations = list(itertools.combinations(flat_array, 2))\n\n    return flat_array, combinations", "raw_solution": "import numpy as np\nimport itertools\n\ndef task_func(matrix):\n    # Flatten the 2D array and sort it\n    flat_array = np.sort(matrix.flatten())\n\n    # Generate all unique combinations of two elements\n    combinations = list(itertools.combinations(flat_array, 2))\n\n    return flat_array, combinations\n```"}
{"task_id": "BigCodeBench/1139", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef task_func(data):\n    X = data.iloc[:, :-1].values\n    y = data.iloc[:, 1].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    regressor = LinearRegression()\n    regressor.fit(X_train, y_train)\n    y_pred = regressor.predict(X_test)\n    from sklearn.metrics import mean_squared_error\n    mse = mean_squared_error(y_test, y_pred)\n    return mse", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef task_func(data):\n    X = data.iloc[:, :-1].values\n    y = data.iloc[:, 1].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    regressor = LinearRegression()\n    regressor.fit(X_train, y_train)\n    y_pred = regressor.predict(X_test)\n    from sklearn.metrics import mean_squared_error\n    mse = mean_squared_error(y_test, y_pred)\n    return mse\n```"}
