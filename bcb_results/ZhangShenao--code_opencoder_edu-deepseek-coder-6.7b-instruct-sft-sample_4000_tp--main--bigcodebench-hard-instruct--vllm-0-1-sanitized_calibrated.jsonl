{"task_id": "BigCodeBench/13", "solution": "import subprocess\nimport ftplib\nimport os\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        ftp = ftplib.FTP(ftp_server)\n        ftp.login(ftp_user, ftp_password)\n    except Exception as e:\n        raise Exception(f\"Failed to connect to FTP server {ftp_server}: {str(e)}\")\n\n    try:\n        ftp.cwd(ftp_dir)\n    except Exception as e:\n        raise Exception(f\"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n\n    filenames = []\n    try:\n        ftp.retrlines('LIST', lambda x: filenames.append(x.split()[-1]))\n    except Exception as e:\n        raise Exception(f\"Failed to list files in directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n\n    for filename in filenames:\n        try:\n            with open(filename, 'wb') as file:\n                ftp.retrbinary('RETR ' + filename, file.write)\n        except Exception as e:\n            print(f\"Failed to download file {filename} from server {ftp_server}: {str(e)}\")\n\n    ftp.quit()\n    return filenames", "raw_solution": "import subprocess\nimport ftplib\nimport os\n\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        ftp = ftplib.FTP(ftp_server)\n        ftp.login(ftp_user, ftp_password)\n    except Exception as e:\n        raise Exception(f\"Failed to connect to FTP server {ftp_server}: {str(e)}\")\n\n    try:\n        ftp.cwd(ftp_dir)\n    except Exception as e:\n        raise Exception(f\"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n\n    filenames = []\n    try:\n        ftp.retrlines('LIST', lambda x: filenames.append(x.split()[-1]))\n    except Exception as e:\n        raise Exception(f\"Failed to list files in directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n\n    for filename in filenames:\n        try:\n            with open(filename, 'wb') as file:\n                ftp.retrbinary('RETR ' + filename, file.write)\n        except Exception as e:\n            print(f\"Failed to download file {filename} from server {ftp_server}: {str(e)}\")\n\n    ftp.quit()\n    return filenames\n```"}
{"task_id": "BigCodeBench/15", "solution": "import subprocess\nimport csv\nimport os\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(f\"File {commands_file_path} does not exist.\")\n\n    if not os.path.exists(output_dir_path):\n        os.makedirs(output_dir_path)\n\n    with open(commands_file_path, 'r') as file:\n        reader = csv.reader(file)\n        command_list = list(reader)\n\n    output_file_paths = []\n    for i, command in enumerate(command_list):\n        output_file_path = os.path.join(output_dir_path, f'command_{i}_output.txt')\n        output_file_paths.append(output_file_path)\n\n        with open(output_file_path, 'w') as output_file:\n            try:\n                result = subprocess.run(command, capture_output=True, text=True, shell=True, check=True)\n                output_file.write(result.stdout)\n            except subprocess.CalledProcessError as e:\n                output_file.write(f\"Error: {e.output}\\nExit code: {e.returncode}\")\n\n    return output_file_paths", "raw_solution": "import subprocess\nimport csv\nimport os\n\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(f\"File {commands_file_path} does not exist.\")\n\n    if not os.path.exists(output_dir_path):\n        os.makedirs(output_dir_path)\n\n    with open(commands_file_path, 'r') as file:\n        reader = csv.reader(file)\n        command_list = list(reader)\n\n    output_file_paths = []\n    for i, command in enumerate(command_list):\n        output_file_path = os.path.join(output_dir_path, f'command_{i}_output.txt')\n        output_file_paths.append(output_file_path)\n\n        with open(output_file_path, 'w') as output_file:\n            try:\n                result = subprocess.run(command, capture_output=True, text=True, shell=True, check=True)\n                output_file.write(result.stdout)\n            except subprocess.CalledProcessError as e:\n                output_file.write(f\"Error: {e.output}\\nExit code: {e.returncode}\")\n\n    return output_file_paths\n```"}
{"task_id": "BigCodeBench/17", "solution": "import subprocess\nimport psutil\nimport time\ndef task_func(process_name: str) -> str:\n    if process_name not in (p.name() for p in psutil.process_iter(['name'])):\n        subprocess.Popen(process_name, shell=True)\n        return f\"Process not found. Starting {process_name}.\"\n    else:\n        for proc in psutil.process_iter(['pid', 'name']):\n            if proc.info['name'] == process_name:\n                proc.terminate()\n                time.sleep(1)\n                subprocess.Popen(process_name, shell=True)\n                return f\"Process found. Restarting {process_name}.\"", "raw_solution": "import subprocess\nimport psutil\nimport time\n\ndef task_func(process_name: str) -> str:\n    if process_name not in (p.name() for p in psutil.process_iter(['name'])):\n        subprocess.Popen(process_name, shell=True)\n        return f\"Process not found. Starting {process_name}.\"\n    else:\n        for proc in psutil.process_iter(['pid', 'name']):\n            if proc.info['name'] == process_name:\n                proc.terminate()\n                time.sleep(1)\n                subprocess.Popen(process_name, shell=True)\n                return f\"Process found. Restarting {process_name}.\"\n```"}
{"task_id": "BigCodeBench/19", "solution": "import os\nimport glob\nimport zipfile\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n\n    files = glob.glob(os.path.join(directory, \"*\"))\n    files = [file for file in files if os.path.isfile(file)]\n\n    if not files:\n        return None\n\n    zip_path = os.path.join(directory, \"files.zip\")\n    with zipfile.ZipFile(zip_path, \"w\") as zipf:\n        for file in files:\n            zipf.write(file, arcname=os.path.basename(file))\n\n    return zip_path", "raw_solution": "import os\nimport glob\nimport zipfile\n\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n\n    files = glob.glob(os.path.join(directory, \"*\"))\n    files = [file for file in files if os.path.isfile(file)]\n\n    if not files:\n        return None\n\n    zip_path = os.path.join(directory, \"files.zip\")\n    with zipfile.ZipFile(zip_path, \"w\") as zipf:\n        for file in files:\n            zipf.write(file, arcname=os.path.basename(file))\n\n    return zip_path\n```"}
{"task_id": "BigCodeBench/34", "solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n\n    # Split the text into words\n    words = text.split()\n\n    # If there are no words available to generate a word cloud, raise an exception\n    if not words:\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n\n    # Generate a word cloud from the words\n    wordcloud = WordCloud(width=480, height=480, max_words=150, background_color=\"white\").generate(text)\n\n    # Plot the word cloud\n    plt.figure(figsize=(10, 7))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n\n    return wordcloud", "raw_solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n\n    # Split the text into words\n    words = text.split()\n\n    # If there are no words available to generate a word cloud, raise an exception\n    if not words:\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n\n    # Generate a word cloud from the words\n    wordcloud = WordCloud(width=480, height=480, max_words=150, background_color=\"white\").generate(text)\n\n    # Plot the word cloud\n    plt.figure(figsize=(10, 7))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n\n    return wordcloud\n```"}
{"task_id": "BigCodeBench/37", "solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, target_column):\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    # Train the Random Forest Classifier\n    clf = RandomForestClassifier(random_state=42)\n    clf.fit(X, y)\n\n    # Get feature importances\n    importances = clf.feature_importances_\n\n    # Create a dataframe for feature importances\n    df_importances = pd.DataFrame({\n        'Feature': X.columns,\n        'Importance': importances\n    })\n\n    # Sort the dataframe by importance\n    df_importances = df_importances.sort_values('Importance', ascending=False)\n\n    # Create the bar plot\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=df_importances)\n    plt.xlabel('Feature Importance Score')\n    plt.ylabel('Features')\n    plt.title('Visualizing Important Features')\n    plt.tight_layout()\n\n    return clf, plt.gca()", "raw_solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_column):\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    # Train the Random Forest Classifier\n    clf = RandomForestClassifier(random_state=42)\n    clf.fit(X, y)\n\n    # Get feature importances\n    importances = clf.feature_importances_\n\n    # Create a dataframe for feature importances\n    df_importances = pd.DataFrame({\n        'Feature': X.columns,\n        'Importance': importances\n    })\n\n    # Sort the dataframe by importance\n    df_importances = df_importances.sort_values('Importance', ascending=False)\n\n    # Create the bar plot\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=df_importances)\n    plt.xlabel('Feature Importance Score')\n    plt.ylabel('Features')\n    plt.title('Visualizing Important Features')\n    plt.tight_layout()\n\n    return clf, plt.gca()\n```"}
{"task_id": "BigCodeBench/82", "solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\nclass LoginForm(FlaskForm):\n    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n    password = PasswordField('Password', validators=[DataRequired(), Length(min=8, max=80)])\n    submit = SubmitField('Log In')\nlogin_manager = LoginManager()\nclass User(UserMixin):\n    def __init__(self, username, password):\n        self.username = username\n        self.password = generate_password_hash(password)\n\n    def check_password(self, password):\n        return check_password_hash(self.password, password)\ndef create_app(secret_key, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    app.config['SECRET_KEY'] = secret_key\n    login_manager.init_app(app)\n    return app\ndef task_func(secret_key, template_folder):\n    app = create_app(secret_key, template_folder)\n\n    users = [User(username='admin', password='password')]\n\n    @app.route('/login', methods=['GET', 'POST'])\n    def login():\n        form = LoginForm()\n        if form.validate_on_submit():\n            user = next((user for user in users if user.username == form.username.data), None)\n            if user and user.check_password(form.password.data):\n                login_user(user)\n                return redirect(url_for('protected'))\n        return render_template('login.html', form=form)\n\n    @app.route('/logout')\n    @login_required\n    def logout():\n        logout_user()\n        return redirect(url_for('login'))\n\n    @app.route('/protected')\n    @login_required\n    def protected():\n        return render_template('protected.html')\n\n    return app", "raw_solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\n\nclass LoginForm(FlaskForm):\n    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n    password = PasswordField('Password', validators=[DataRequired(), Length(min=8, max=80)])\n    submit = SubmitField('Log In')\n\nlogin_manager = LoginManager()\n\nclass User(UserMixin):\n    def __init__(self, username, password):\n        self.username = username\n        self.password = generate_password_hash(password)\n\n    def check_password(self, password):\n        return check_password_hash(self.password, password)\n\n@login_manager.user_loader\ndef load_user(user_id):\n    for user in users:\n        if user.id == int(user_id):\n            return user\n    return None\n\ndef create_app(secret_key, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    app.config['SECRET_KEY'] = secret_key\n    login_manager.init_app(app)\n    return app\n\ndef task_func(secret_key, template_folder):\n    app = create_app(secret_key, template_folder)\n\n    users = [User(username='admin', password='password')]\n\n    @app.route('/login', methods=['GET', 'POST'])\n    def login():\n        form = LoginForm()\n        if form.validate_on_submit():\n            user = next((user for user in users if user.username == form.username.data), None)\n            if user and user.check_password(form.password.data):\n                login_user(user)\n                return redirect(url_for('protected'))\n        return render_template('login.html', form=form)\n\n    @app.route('/logout')\n    @login_required\n    def logout():\n        logout_user()\n        return redirect(url_for('login'))\n\n    @app.route('/protected')\n    @login_required\n    def protected():\n        return render_template('protected.html')\n\n    return app\n```"}
{"task_id": "BigCodeBench/89", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data, column, outlier_z_score):\n    # Standardize the column\n    scaler = StandardScaler()\n    data[column] = scaler.fit_transform(data[column].values.reshape(-1, 1))\n\n    # Calculate Z-scores\n    z_scores = np.abs(stats.zscore(data[column]))\n\n    # Identify outliers\n    outliers = np.where(z_scores > outlier_z_score)[0]\n\n    # Remove outliers\n    data_without_outliers = data.drop(outliers)\n\n    # Visualize data before and after outlier removal\n    plt.figure(figsize=(12, 6))\n\n    plt.subplot(1, 2, 1)\n    plt.scatter(range(len(data[column])), data[column])\n    plt.title('Data with Outliers')\n\n    plt.subplot(1, 2, 2)\n    plt.scatter(range(len(data_without_outliers[column])), data_without_outliers[column])\n    plt.title('Data without Outliers')\n\n    plt.tight_layout()\n    plt.show()\n\n    return (data, data_without_outliers, outliers)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data, column, outlier_z_score):\n    # Standardize the column\n    scaler = StandardScaler()\n    data[column] = scaler.fit_transform(data[column].values.reshape(-1, 1))\n\n    # Calculate Z-scores\n    z_scores = np.abs(stats.zscore(data[column]))\n\n    # Identify outliers\n    outliers = np.where(z_scores > outlier_z_score)[0]\n\n    # Remove outliers\n    data_without_outliers = data.drop(outliers)\n\n    # Visualize data before and after outlier removal\n    plt.figure(figsize=(12, 6))\n\n    plt.subplot(1, 2, 1)\n    plt.scatter(range(len(data[column])), data[column])\n    plt.title('Data with Outliers')\n\n    plt.subplot(1, 2, 2)\n    plt.scatter(range(len(data_without_outliers[column])), data_without_outliers[column])\n    plt.title('Data without Outliers')\n\n    plt.tight_layout()\n    plt.show()\n\n    return (data, data_without_outliers, outliers)\n```"}
{"task_id": "BigCodeBench/92", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.collections import PathCollection\ndef task_func(data, n_clusters=3):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' must be a pandas DataFrame\")\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"'n_clusters' must be an integer greater than 1\")\n\n    kmeans = KMeans(n_clusters=n_clusters)\n    kmeans.fit(data)\n\n    labels = kmeans.labels_\n\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels)\n    ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n\n    return labels, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.collections import PathCollection\n\ndef task_func(data, n_clusters=3):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' must be a pandas DataFrame\")\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"'n_clusters' must be an integer greater than 1\")\n\n    kmeans = KMeans(n_clusters=n_clusters)\n    kmeans.fit(data)\n\n    labels = kmeans.labels_\n\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels)\n    ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n\n    return labels, ax\n```"}
{"task_id": "BigCodeBench/93", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(data, n_components=2):\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError(\"n_components must be a positive integer\")\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n    transformed_df = pd.DataFrame(transformed_data, columns=[f\"PC{i+1}\" for i in range(n_components)])\n    fig, ax = plt.subplots()\n    ax.scatter(transformed_df.iloc[:, 0], transformed_df.iloc[:, 1])\n    ax.set_xlabel(f\"PC1\")\n    ax.set_ylabel(f\"PC2\")\n    return transformed_df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError(\"n_components must be a positive integer\")\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n    transformed_df = pd.DataFrame(transformed_data, columns=[f\"PC{i+1}\" for i in range(n_components)])\n    fig, ax = plt.subplots()\n    ax.scatter(transformed_df.iloc[:, 0], transformed_df.iloc[:, 1])\n    ax.set_xlabel(f\"PC1\")\n    ax.set_ylabel(f\"PC2\")\n    return transformed_df, ax\n```"}
{"task_id": "BigCodeBench/99", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\ndef task_func():\n    iris = load_iris()\n    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    df['species'] = iris.target\n    sns.set(font='Arial')\n    g = sns.pairplot(df, hue='species', palette='Dark2', diag_kind='kde', height=2.5)\n    g.fig.suptitle(\"Iris Dataset Pair Plot\", y=1.08)\n    plt.show()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\n\ndef task_func():\n    iris = load_iris()\n    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    df['species'] = iris.target\n    sns.set(font='Arial')\n    g = sns.pairplot(df, hue='species', palette='Dark2', diag_kind='kde', height=2.5)\n    g.fig.suptitle(\"Iris Dataset Pair Plot\", y=1.08)\n    plt.show()\n```"}
{"task_id": "BigCodeBench/100", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\ndef task_func(seed=42):\n    try:\n        random.seed(seed)\n        dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(30)]\n        values = [random.randint(1, 100) for _ in range(30)]\n        df = pd.DataFrame({'Date': dates, 'Value': values})\n        df['Date'] = pd.to_datetime(df['Date'])\n        df.set_index('Date', inplace=True)\n\n        plt.figure(figsize=(10, 6))\n        plt.plot(df.index, df['Value'])\n        plt.xlabel('Date')\n        plt.ylabel('Value')\n        plt.title('Random Time Series Data')\n        plt.xticks(rotation=45)\n        plt.grid(True)\n        plt.tight_layout()\n        plt.style.use('seaborn-whitegrid')\n        plt.rcParams['font.family'] = 'Arial'\n        return plt.gca()\n    except Exception as e:\n        raise ValueError(f\"Error generating data or plot: {e}\")", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\n\ndef task_func(seed=42):\n    try:\n        random.seed(seed)\n        dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(30)]\n        values = [random.randint(1, 100) for _ in range(30)]\n        df = pd.DataFrame({'Date': dates, 'Value': values})\n        df['Date'] = pd.to_datetime(df['Date'])\n        df.set_index('Date', inplace=True)\n\n        plt.figure(figsize=(10, 6))\n        plt.plot(df.index, df['Value'])\n        plt.xlabel('Date')\n        plt.ylabel('Value')\n        plt.title('Random Time Series Data')\n        plt.xticks(rotation=45)\n        plt.grid(True)\n        plt.tight_layout()\n        plt.style.use('seaborn-whitegrid')\n        plt.rcParams['font.family'] = 'Arial'\n        return plt.gca()\n    except Exception as e:\n        raise ValueError(f\"Error generating data or plot: {e}\")\n```"}
{"task_id": "BigCodeBench/101", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n    np.random.seed(seed)\n    try:\n        data = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n        data.columns = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n        correlation_matrix = data.corr()\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n        plt.title(\"Correlation Heatmap of Boston Housing Dataset\")\n        plt.show()\n    except Exception as e:\n        raise ValueError(f\"Error in generating or saving the plot: {e}\")", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n    np.random.seed(seed)\n    try:\n        data = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n        data.columns = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n        correlation_matrix = data.corr()\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n        plt.title(\"Correlation Heatmap of Boston Housing Dataset\")\n        plt.show()\n    except Exception as e:\n        raise ValueError(f\"Error in generating or saving the plot: {e}\")\n```"}
{"task_id": "BigCodeBench/108", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' must be a pandas DataFrame\")\n    if 'value' not in df.columns:\n        raise ValueError(\"'df' must contain a 'value' column\")\n    if not isinstance(freq, str):\n        raise ValueError(\"'freq' must be a string\")\n    if decomposition_model not in ['additive', 'multiplicative']:\n        raise ValueError(\"'decomposition_model' must be 'additive' or 'multiplicative'\")\n    if not df['value'].apply(lambda x: isinstance(x, (int, float))).all():\n        raise ValueError(\"'value' column must contain numeric data\")\n\n    result = seasonal_decompose(df['value'], model=decomposition_model, freq=freq)\n\n    fig, ax = plt.subplots(4, 1, figsize=(10, 10))\n    result.observed.plot(ax=ax[0])\n    ax[0].set_ylabel('Observed')\n    result.trend.plot(ax=ax[1])\n    ax[1].set_ylabel('Trend')\n    result.seasonal.plot(ax=ax[2])\n    ax[2].set_ylabel('Seasonality')\n    result.resid.plot(ax=ax[3])\n    ax[3].set_ylabel('Residuals')\n    plt.tight_layout()\n\n    return (result, ax)", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' must be a pandas DataFrame\")\n    if 'value' not in df.columns:\n        raise ValueError(\"'df' must contain a 'value' column\")\n    if not isinstance(freq, str):\n        raise ValueError(\"'freq' must be a string\")\n    if decomposition_model not in ['additive', 'multiplicative']:\n        raise ValueError(\"'decomposition_model' must be 'additive' or 'multiplicative'\")\n    if not df['value'].apply(lambda x: isinstance(x, (int, float))).all():\n        raise ValueError(\"'value' column must contain numeric data\")\n\n    result = seasonal_decompose(df['value'], model=decomposition_model, freq=freq)\n\n    fig, ax = plt.subplots(4, 1, figsize=(10, 10))\n    result.observed.plot(ax=ax[0])\n    ax[0].set_ylabel('Observed')\n    result.trend.plot(ax=ax[1])\n    ax[1].set_ylabel('Trend')\n    result.seasonal.plot(ax=ax[2])\n    ax[2].set_ylabel('Seasonality')\n    result.resid.plot(ax=ax[3])\n    ax[3].set_ylabel('Residuals')\n    plt.tight_layout()\n\n    return (result, ax)\n```"}
{"task_id": "BigCodeBench/120", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"'start_date' and 'end_date' must be datetime.datetime instances\")\n    if start_date > end_date:\n        raise ValueError(\"'start_date' must be earlier than 'end_date'\")\n    random_seed(seed)\n    total_days = (end_date - start_date).days + 1\n    random_days = [randint(0, total_days - 1) for _ in range(total_days)]\n    dates = [start_date + timedelta(days=day) for day in random_days]\n    return pd.Series(dates)", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"'start_date' and 'end_date' must be datetime.datetime instances\")\n    if start_date > end_date:\n        raise ValueError(\"'start_date' must be earlier than 'end_date'\")\n    random_seed(seed)\n    total_days = (end_date - start_date).days + 1\n    random_days = [randint(0, total_days - 1) for _ in range(total_days)]\n    dates = [start_date + timedelta(days=day) for day in random_days]\n    return pd.Series(dates)"}
{"task_id": "BigCodeBench/123", "solution": "import pandas as pd\nimport os\nimport glob\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' must be a list\")\n    my_list.append('12')\n    if not os.path.exists(file_dir):\n        raise FileNotFoundError(\"No files found in the specified directory\")\n    file_list = glob.glob(file_dir + '*' + file_ext)\n    if not file_list:\n        raise FileNotFoundError(\"No files found in the specified directory\")\n    df = pd.DataFrame()\n    for file in file_list:\n        df_temp = pd.read_csv(file)\n        df = pd.concat([df, df_temp])\n    return df", "raw_solution": "import pandas as pd\nimport os\nimport glob\n\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' must be a list\")\n    my_list.append('12')\n    if not os.path.exists(file_dir):\n        raise FileNotFoundError(\"No files found in the specified directory\")\n    file_list = glob.glob(file_dir + '*' + file_ext)\n    if not file_list:\n        raise FileNotFoundError(\"No files found in the specified directory\")\n    df = pd.DataFrame()\n    for file in file_list:\n        df_temp = pd.read_csv(file)\n        df = pd.concat([df, df_temp])\n    return df\n```"}
{"task_id": "BigCodeBench/124", "solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' must be a list\")\n    if not all(isinstance(x, (int, float)) for x in my_list):\n        raise ValueError(\"All elements in 'my_list' must be numeric (int or float)\")\n\n    random_seed(seed)\n    my_list.append(12)\n    sum_list = sum(my_list)\n    if sum_list > size:\n        raise ValueError(\"Sum of elements in 'my_list' exceeds 'size'\")\n\n    start_time = time.time()\n    random_list = [randint(1, 100) for _ in range(sum_list)]\n    end_time = time.time()\n\n    fig, ax = plt.subplots()\n    ax.hist(random_list, bins=range(1, 101), edgecolor='black')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n    plt.show()\n\n    return (end_time - start_time, ax)", "raw_solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' must be a list\")\n    if not all(isinstance(x, (int, float)) for x in my_list):\n        raise ValueError(\"All elements in 'my_list' must be numeric (int or float)\")\n\n    random_seed(seed)\n    my_list.append(12)\n    sum_list = sum(my_list)\n    if sum_list > size:\n        raise ValueError(\"Sum of elements in 'my_list' exceeds 'size'\")\n\n    start_time = time.time()\n    random_list = [randint(1, 100) for _ in range(sum_list)]\n    end_time = time.time()\n\n    fig, ax = plt.subplots()\n    ax.hist(random_list, bins=range(1, 101), edgecolor='black')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n    plt.show()\n\n    return (end_time - start_time, ax)\n```"}
{"task_id": "BigCodeBench/129", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef scrape_table(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise ValueError(\"Failed to connect to the URL\") from e\n\n    soup = BeautifulSoup(response.content, 'html.parser')\n    table = soup.find('table')\n\n    if table is None:\n        raise ValueError(\"No table data found on the page\")\n\n    rows = table.find_all('tr')\n    header = [th.text for th in rows[0].find_all('th')]\n    data = [[td.text for td in row.find_all('td')] for row in rows[1:]]\n\n    return pd.DataFrame(data, columns=header)"}
{"task_id": "BigCodeBench/139", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"Input should be a non-empty DataFrame\")\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if numeric_cols.empty:\n        raise ValueError(\"There are no numeric columns in the DataFrame\")\n    plots = []\n    for col in numeric_cols:\n        plt.figure()\n        plt.hist(df[col], bins='auto', color='blue', edgecolor='black')\n        plt.title(col)\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plots.append(plt.gca())\n    return plots", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"Input should be a non-empty DataFrame\")\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if numeric_cols.empty:\n        raise ValueError(\"There are no numeric columns in the DataFrame\")\n    plots = []\n    for col in numeric_cols:\n        plt.figure()\n        plt.hist(df[col], bins='auto', color='blue', edgecolor='black')\n        plt.title(col)\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plots.append(plt.gca())\n    return plots\n```"}
{"task_id": "BigCodeBench/147", "solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\ndef task_func(ip_range, port):\n    def check_port(ip, port):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1)\n        result = sock.connect_ex((ip, port))\n        sock.close()\n        return result == 0\n\n    def worker(ip):\n        return {ip: check_port(ip, port)}\n\n    threads = []\n    results = {}\n\n    for ip in IPv4Network(ip_range):\n        t = Thread(target=worker, args=(str(ip),))\n        threads.append(t)\n        t.start()\n\n    for t in threads:\n        t.join()\n\n    for t in threads:\n        results.update(t.result)\n\n    return results", "raw_solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\n\ndef task_func(ip_range, port):\n    def check_port(ip, port):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1)\n        result = sock.connect_ex((ip, port))\n        sock.close()\n        return result == 0\n\n    def worker(ip):\n        return {ip: check_port(ip, port)}\n\n    threads = []\n    results = {}\n\n    for ip in IPv4Network(ip_range):\n        t = Thread(target=worker, args=(str(ip),))\n        threads.append(t)\n        t.start()\n\n    for t in threads:\n        t.join()\n\n    for t in threads:\n        results.update(t.result)\n\n    return results\n```"}
{"task_id": "BigCodeBench/161", "solution": "import re\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(log_file):\n    # Define the regular expression pattern for log entries\n    pattern = r'^(\\w+): \\[(.*)\\] - (.*)$'\n\n    # Initialize an empty list to store the log entries\n    log_entries = []\n\n    # Open the log file and read each line\n    with open(log_file, 'r') as file:\n        for line in file:\n            # Use the regular expression to match the log entry pattern\n            match = re.match(pattern, line.strip())\n\n            # If a match is found, extract the message type, timestamp, and message\n            if match:\n                message_type, timestamp, message = match.groups()\n\n                # Convert the timestamp to a datetime object\n                try:\n                    timestamp = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n                except ValueError:\n                    raise ValueError('Invalid timestamp in log entry: {}'.format(line.strip()))\n\n                # Append the log entry to the list\n                log_entries.append({\n                    'message_type': message_type,\n                    'timestamp': timestamp,\n                    'message': message\n                })\n\n    # If no valid log entries are found, raise an exception\n    if not log_entries:\n        raise ValueError('No valid log entries found in file: {}'.format(log_file))\n\n    # Convert the log entries list to a pandas DataFrame\n    df = pd.DataFrame(log_entries)\n\n    # Save the DataFrame to a CSV file\n    csv_file = '{}_structured.csv'.format(log_file)\n    df.to_csv(csv_file, index=False)\n\n    return csv_file", "raw_solution": "import re\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(log_file):\n    # Define the regular expression pattern for log entries\n    pattern = r'^(\\w+): \\[(.*)\\] - (.*)$'\n\n    # Initialize an empty list to store the log entries\n    log_entries = []\n\n    # Open the log file and read each line\n    with open(log_file, 'r') as file:\n        for line in file:\n            # Use the regular expression to match the log entry pattern\n            match = re.match(pattern, line.strip())\n\n            # If a match is found, extract the message type, timestamp, and message\n            if match:\n                message_type, timestamp, message = match.groups()\n\n                # Convert the timestamp to a datetime object\n                try:\n                    timestamp = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n                except ValueError:\n                    raise ValueError('Invalid timestamp in log entry: {}'.format(line.strip()))\n\n                # Append the log entry to the list\n                log_entries.append({\n                    'message_type': message_type,\n                    'timestamp': timestamp,\n                    'message': message\n                })\n\n    # If no valid log entries are found, raise an exception\n    if not log_entries:\n        raise ValueError('No valid log entries found in file: {}'.format(log_file))\n\n    # Convert the log entries list to a pandas DataFrame\n    df = pd.DataFrame(log_entries)\n\n    # Save the DataFrame to a CSV file\n    csv_file = '{}_structured.csv'.format(log_file)\n    df.to_csv(csv_file, index=False)\n\n    return csv_file\n```"}
{"task_id": "BigCodeBench/162", "solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(text, rwidth=0.8):\n    words = re.findall(r'\\b\\w+\\b', text)\n    lengths = [len(word) for word in words]\n    bins = np.arange(min(lengths), max(lengths) + 2, 1)\n    hist, bins = np.histogram(lengths, bins=bins)\n    ax = plt.subplot()\n    ax.bar(bins[:-1], hist, align='edge', width=rwidth)\n    ax.set_xlabel('Word Length')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Word Length Distribution')\n    return ax", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(text, rwidth=0.8):\n    words = re.findall(r'\\b\\w+\\b', text)\n    lengths = [len(word) for word in words]\n    bins = np.arange(min(lengths), max(lengths) + 2, 1)\n    hist, bins = np.histogram(lengths, bins=bins)\n    ax = plt.subplot()\n    ax.bar(bins[:-1], hist, align='edge', width=rwidth)\n    ax.set_xlabel('Word Length')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Word Length Distribution')\n    return ax\n```"}
{"task_id": "BigCodeBench/177", "solution": "import re\nimport nltk\nfrom string import punctuation\ndef task_func(df):\n    if df.empty or 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError(\"DataFrame is empty or does not contain the necessary columns 'Title' and 'Content'\")\n\n    df = df[df['Title'].str.contains(r'like|what', case=False)]\n    words = []\n    for content in df['Content']:\n        words.extend(nltk.word_tokenize(re.sub(r'[^\\w\\s]', '', content).lower()))\n\n    word_freq = {}\n    for word in words:\n        if word in word_freq:\n            word_freq[word] += 1\n        else:\n            word_freq[word] = 1\n\n    return word_freq", "raw_solution": "import re\nimport nltk\nfrom string import punctuation\n\ndef task_func(df):\n    if df.empty or 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError(\"DataFrame is empty or does not contain the necessary columns 'Title' and 'Content'\")\n\n    df = df[df['Title'].str.contains(r'like|what', case=False)]\n    words = []\n    for content in df['Content']:\n        words.extend(nltk.word_tokenize(re.sub(r'[^\\w\\s]', '', content).lower()))\n\n    word_freq = {}\n    for word in words:\n        if word in word_freq:\n            word_freq[word] += 1\n        else:\n            word_freq[word] = 1\n\n    return word_freq\n```"}
{"task_id": "BigCodeBench/184", "solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\ndef task_func(dataframe, text_column):\n    # Preprocessing\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: ' '.join([word for word in x.split() if word not in STOPWORDS]))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: ' '.join([word for word in x.split() if not word.isnumeric()]))\n    # Vectorization\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(dataframe[text_column])\n    # Create DataFrame\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n    return df", "raw_solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\n# Constants\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\ndef task_func(dataframe, text_column):\n    # Preprocessing\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: ' '.join([word for word in x.split() if word not in STOPWORDS]))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: ' '.join([word for word in x.split() if not word.isnumeric()]))\n    # Vectorization\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(dataframe[text_column])\n    # Create DataFrame\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n    return df\n```"}
{"task_id": "BigCodeBench/187", "solution": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"'Lon' and 'Lat' keys are required in the dictionary.\")\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples.\")\n\n    lon_range, lat_range = dic['Lon'], dic['Lat']\n    coordinates = [(np.random.uniform(lon_range[0], lon_range[1]), np.random.uniform(lat_range[0], lat_range[1])) for _ in range(len(cities))]\n\n    geometry = [Point(coord) for coord in coordinates]\n    df = gpd.GeoDataFrame(cities, geometry=geometry)\n    df.columns = ['City', 'Coordinates']\n\n    return df", "raw_solution": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"'Lon' and 'Lat' keys are required in the dictionary.\")\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples.\")\n\n    lon_range, lat_range = dic['Lon'], dic['Lat']\n    coordinates = [(np.random.uniform(lon_range[0], lon_range[1]), np.random.uniform(lat_range[0], lat_range[1])) for _ in range(len(cities))]\n\n    geometry = [Point(coord) for coord in coordinates]\n    df = gpd.GeoDataFrame(cities, geometry=geometry)\n    df.columns = ['City', 'Coordinates']\n\n    return df\n```"}
{"task_id": "BigCodeBench/199", "solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime must be a datetime object\")\n    if not all(isinstance(city, str) for city in cities):\n        raise ValueError(\"All cities must be strings\")\n    if not all(isinstance(condition, str) for condition in weather_conditions):\n        raise ValueError(\"All weather conditions must be strings\")\n    if not all(isinstance(timezone, str) for timezone in timezones.values()):\n        raise ValueError(\"All timezones must be strings\")\n    if not isinstance(seed, int):\n        raise ValueError(\"Seed must be an integer\")\n\n    set_seed(seed)\n\n    data = []\n    for city in cities:\n        local_time = utc_datetime.astimezone(pytz.timezone(timezones[city]))\n        weather_condition = weather_conditions[randint(0, len(weather_conditions) - 1)]\n        data.append([city, local_time.strftime('%Y-%m-%d %H:%M:%S %Z'), weather_condition])\n\n    return pd.DataFrame(data, columns=['City', 'Local Time', 'Weather Condition'])", "raw_solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\n\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime must be a datetime object\")\n    if not all(isinstance(city, str) for city in cities):\n        raise ValueError(\"All cities must be strings\")\n    if not all(isinstance(condition, str) for condition in weather_conditions):\n        raise ValueError(\"All weather conditions must be strings\")\n    if not all(isinstance(timezone, str) for timezone in timezones.values()):\n        raise ValueError(\"All timezones must be strings\")\n    if not isinstance(seed, int):\n        raise ValueError(\"Seed must be an integer\")\n\n    set_seed(seed)\n\n    data = []\n    for city in cities:\n        local_time = utc_datetime.astimezone(pytz.timezone(timezones[city]))\n        weather_condition = weather_conditions[randint(0, len(weather_conditions) - 1)]\n        data.append([city, local_time.strftime('%Y-%m-%d %H:%M:%S %Z'), weather_condition])\n\n    return pd.DataFrame(data, columns=['City', 'Local Time', 'Weather Condition'])\n```"}
{"task_id": "BigCodeBench/208", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError(\"elements must be a positive integer\")\n    np.random.seed(seed)\n    random_walk = np.random.choice([-1, 1], size=elements)\n    random_walk_cumulative = np.cumsum(random_walk)\n    stats = pd.Series(random_walk_cumulative).describe()\n    fig, ax = plt.subplots()\n    ax.plot(random_walk_cumulative)\n    ax.set_xlabel('Steps')\n    ax.set_ylabel('Cumulative Sum')\n    ax.set_title('Random Walk')\n    return stats, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError(\"elements must be a positive integer\")\n    np.random.seed(seed)\n    random_walk = np.random.choice([-1, 1], size=elements)\n    random_walk_cumulative = np.cumsum(random_walk)\n    stats = pd.Series(random_walk_cumulative).describe()\n    fig, ax = plt.subplots()\n    ax.plot(random_walk_cumulative)\n    ax.set_xlabel('Steps')\n    ax.set_ylabel('Cumulative Sum')\n    ax.set_title('Random Walk')\n    return stats, ax\n```"}
{"task_id": "BigCodeBench/211", "solution": "import requests\nimport os\nimport zipfile\ndef task_func(url, destination_directory, headers=None):\n    response = requests.get(url, headers=headers)\n    with open('temp.zip', 'wb') as f:\n        f.write(response.content)\n    with zipfile.ZipFile('temp.zip', 'r') as zip_ref:\n        zip_ref.extractall(destination_directory)\n    os.remove('temp.zip')\n    return [file for file in os.listdir(destination_directory) if os.path.isfile(os.path.join(destination_directory, file))]", "raw_solution": "import requests\nimport os\nimport zipfile\n\ndef task_func(url, destination_directory, headers=None):\n    response = requests.get(url, headers=headers)\n    with open('temp.zip', 'wb') as f:\n        f.write(response.content)\n    with zipfile.ZipFile('temp.zip', 'r') as zip_ref:\n        zip_ref.extractall(destination_directory)\n    os.remove('temp.zip')\n    return [file for file in os.listdir(destination_directory) if os.path.isfile(os.path.join(destination_directory, file))]\n```"}
{"task_id": "BigCodeBench/214", "solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low >= range_high:\n        raise ValueError(\"range_low must be less than range_high\")\n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, size=image_size)\n    plt.imshow(image)\n    plt.show()\n    return image", "raw_solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low >= range_high:\n        raise ValueError(\"range_low must be less than range_high\")\n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, size=image_size)\n    plt.imshow(image)\n    plt.show()\n    return image\n```"}
{"task_id": "BigCodeBench/227", "solution": "import numpy as np\nimport os\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\ndef task_func(L, M, N, audio_file):\n    if not os.path.exists(audio_file):\n        raise FileNotFoundError(\"The specified audio file does not exist.\")\n\n    data, sample_rate = librosa.load(audio_file)\n    SPL = 20 * np.log10(np.sqrt(np.mean(data**2)))\n\n    matrix = np.array(L).reshape(M, N)\n    normalized_matrix = matrix / np.max(matrix) * SPL\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(normalized_matrix, shading='gouraud')\n    ax.set_yscale('log')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Spectrogram')\n    plt.show()\n\n    return normalized_matrix, fig", "raw_solution": "import numpy as np\nimport os\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\n\ndef task_func(L, M, N, audio_file):\n    if not os.path.exists(audio_file):\n        raise FileNotFoundError(\"The specified audio file does not exist.\")\n\n    data, sample_rate = librosa.load(audio_file)\n    SPL = 20 * np.log10(np.sqrt(np.mean(data**2)))\n\n    matrix = np.array(L).reshape(M, N)\n    normalized_matrix = matrix / np.max(matrix) * SPL\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(normalized_matrix, shading='gouraud')\n    ax.set_yscale('log')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Spectrogram')\n    plt.show()\n\n    return normalized_matrix, fig\n```"}
{"task_id": "BigCodeBench/239", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(original):\n    # Extract numeric values\n    numeric_values = [x for x in original if isinstance(x, (int, float))]\n    numeric_values = np.array(numeric_values)\n\n    # Compute basic statistics\n    stats_dict = {\n        'mean': np.mean(numeric_values),\n        'std_dev': np.std(numeric_values),\n        'min': np.min(numeric_values),\n        'max': np.max(numeric_values)\n    }\n\n    # Generate histogram with overlaid PDF\n    fig, ax = plt.subplots()\n    ax.hist(numeric_values, density=True, alpha=0.6, bins='auto')\n    xmin, xmax = ax.get_xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = stats.norm.pdf(x, stats_dict['mean'], stats_dict['std_dev'])\n    ax.plot(x, p, 'k', linewidth=2)\n    title = \"Histogram with Overlaid PDF\\nMean: {:.2f}, Std Dev: {:.2f}, Min: {}, Max: {}\".format(\n        stats_dict['mean'], stats_dict['std_dev'], stats_dict['min'], stats_dict['max'])\n    ax.set_title(title)\n\n    return numeric_values, stats_dict, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(original):\n    # Extract numeric values\n    numeric_values = [x for x in original if isinstance(x, (int, float))]\n    numeric_values = np.array(numeric_values)\n\n    # Compute basic statistics\n    stats_dict = {\n        'mean': np.mean(numeric_values),\n        'std_dev': np.std(numeric_values),\n        'min': np.min(numeric_values),\n        'max': np.max(numeric_values)\n    }\n\n    # Generate histogram with overlaid PDF\n    fig, ax = plt.subplots()\n    ax.hist(numeric_values, density=True, alpha=0.6, bins='auto')\n    xmin, xmax = ax.get_xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = stats.norm.pdf(x, stats_dict['mean'], stats_dict['std_dev'])\n    ax.plot(x, p, 'k', linewidth=2)\n    title = \"Histogram with Overlaid PDF\\nMean: {:.2f}, Std Dev: {:.2f}, Min: {}, Max: {}\".format(\n        stats_dict['mean'], stats_dict['std_dev'], stats_dict['min'], stats_dict['max'])\n    ax.set_title(title)\n\n    return numeric_values, stats_dict, ax\n```"}
{"task_id": "BigCodeBench/241", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\ndef task_func(original):\n    # Convert the original list to a numpy array\n    original_array = np.array(original)\n\n    # Normalize the array\n    normalized_array = preprocessing.normalize([original_array], norm='l2')[0]\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot the original and normalized arrays\n    ax.plot(original_array, label='Original')\n    ax.plot(normalized_array, label='Normalized')\n\n    # Set the title and labels\n    ax.set_title('Original vs. Normalized Data')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n\n    # Add a legend\n    ax.legend()\n\n    # Return the numpy arrays and the axes object\n    return original_array, normalized_array, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\n\ndef task_func(original):\n    # Convert the original list to a numpy array\n    original_array = np.array(original)\n\n    # Normalize the array\n    normalized_array = preprocessing.normalize([original_array], norm='l2')[0]\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot the original and normalized arrays\n    ax.plot(original_array, label='Original')\n    ax.plot(normalized_array, label='Normalized')\n\n    # Set the title and labels\n    ax.set_title('Original vs. Normalized Data')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n\n    # Add a legend\n    ax.legend()\n\n    # Return the numpy arrays and the axes object\n    return original_array, normalized_array, ax\n```"}
{"task_id": "BigCodeBench/267", "solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\ndef task_func(data, sample_rate=8000):\n    data['a'] = 1\n    signal = np.array(list(data.values()))\n    fft_signal = fftpack.fft(signal)\n    freqs = fftpack.fftfreq(len(signal), d=1/sample_rate)\n\n    fig, ax = plt.subplots()\n    ax.plot(freqs, np.abs(fft_signal))\n    ax.set_title('FFT of the signal')\n    ax.set_xlabel('Frequency (Hz)')\n    ax.set_ylabel('Amplitude')\n\n    return fft_signal, ax", "raw_solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\n\ndef task_func(data, sample_rate=8000):\n    data['a'] = 1\n    signal = np.array(list(data.values()))\n    fft_signal = fftpack.fft(signal)\n    freqs = fftpack.fftfreq(len(signal), d=1/sample_rate)\n\n    fig, ax = plt.subplots()\n    ax.plot(freqs, np.abs(fft_signal))\n    ax.set_title('FFT of the signal')\n    ax.set_xlabel('Frequency (Hz)')\n    ax.set_ylabel('Amplitude')\n\n    return fft_signal, ax\n```"}
{"task_id": "BigCodeBench/273", "solution": "import cgi\nimport http.server\nimport json", "raw_solution": "import cgi\nimport http.server\nimport json\n\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\n\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\n\nclass DataHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers.get('content-length'))\n        post_data = self.rfile.read(content_length)\n\n        if self.headers.get('content-type') != 'application/json':\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({\n                'status': 'error',\n                'message': 'Content-Type header is not application/json'\n            }).encode())\n            return\n\n        try:\n            data = json.loads(post_data)\n        except json.JSONDecodeError:\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({\n                'status': 'error',\n                'message': 'Invalid JSON'\n            }).encode())\n            return\n\n        if 'data' not in data:\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({\n                'status': 'error',\n                'message': 'No data key in request'\n            }).encode())\n            return\n\n        self.send_response(200)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        self.wfile.write(json.dumps(SUCCESS_RESPONSE).encode())\n```"}
{"task_id": "BigCodeBench/274", "solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class EmailHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            try:\n                content_length = int(self.headers['Content-Length'])\n                post_data = self.rfile.read(content_length)\n                email_data = json.loads(post_data)\n\n                if 'subject' not in email_data or 'message' not in email_data or 'to' not in email_data:\n                    self.send_response(400)\n                    self.end_headers()\n                    self.wfile.write(b'Missing required fields: subject, message, to')\n                    return\n\n                msg = MIMEText(email_data['message'])\n                msg['Subject'] = email_data['subject']\n                msg['From'] = smtp_username\n                msg['To'] = email_data['to']\n\n                smtp = smtplib.SMTP(smtp_server, smtp_port)\n                smtp.starttls()\n                smtp.login(smtp_username, smtp_password)\n                smtp.send_message(msg)\n                smtp.quit()\n\n                self.send_response(200)\n                self.end_headers()\n                self.wfile.write(b'Email sent successfully')\n\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Invalid JSON')\n\n            except smtplib.SMTPAuthenticationError:\n                self.send_response(535)\n                self.end_headers()\n                self.wfile.write(b'Authentication Failed')\n\n    return EmailHandler", "raw_solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\n\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class EmailHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            try:\n                content_length = int(self.headers['Content-Length'])\n                post_data = self.rfile.read(content_length)\n                email_data = json.loads(post_data)\n\n                if 'subject' not in email_data or 'message' not in email_data or 'to' not in email_data:\n                    self.send_response(400)\n                    self.end_headers()\n                    self.wfile.write(b'Missing required fields: subject, message, to')\n                    return\n\n                msg = MIMEText(email_data['message'])\n                msg['Subject'] = email_data['subject']\n                msg['From'] = smtp_username\n                msg['To'] = email_data['to']\n\n                smtp = smtplib.SMTP(smtp_server, smtp_port)\n                smtp.starttls()\n                smtp.login(smtp_username, smtp_password)\n                smtp.send_message(msg)\n                smtp.quit()\n\n                self.send_response(200)\n                self.end_headers()\n                self.wfile.write(b'Email sent successfully')\n\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Invalid JSON')\n\n            except smtplib.SMTPAuthenticationError:\n                self.send_response(535)\n                self.end_headers()\n                self.wfile.write(b'Authentication Failed')\n\n    return EmailHandler\n```"}
{"task_id": "BigCodeBench/287", "solution": "from collections import Counter\nimport os\nimport json\ndef task_func(filename, directory):\n    word_count = Counter()\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith('.txt'):\n                with open(os.path.join(root, file), 'r') as f:\n                    words = f.read().split()\n                    word_count.update(words)\n    with open(filename, 'w') as f:\n        json.dump(word_count, f)\n    return sum(word_count.values())", "raw_solution": "from collections import Counter\nimport os\nimport json\n\ndef task_func(filename, directory):\n    word_count = Counter()\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith('.txt'):\n                with open(os.path.join(root, file), 'r') as f:\n                    words = f.read().split()\n                    word_count.update(words)\n    with open(filename, 'w') as f:\n        json.dump(word_count, f)\n    return sum(word_count.values())\n```"}
{"task_id": "BigCodeBench/302", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df, plot=False):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if 'Value' not in df.columns:\n        raise ValueError(\"'Value' column not found in DataFrame\")\n    if not all(isinstance(x, list) for x in df['Value']):\n        raise ValueError(\"'Value' column contains non-list values\")\n\n    # Split lists in the 'Value' column into separate columns\n    df = df['Value'].apply(pd.Series)\n    df.columns = [f'Value_{i}' for i in range(1, len(df.columns) + 1)]\n\n    # Calculate the Pearson correlation coefficient\n    corr = df.corr()\n\n    if plot:\n        # Visualize the correlation matrix using a heatmap\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(corr, annot=True, cmap='coolwarm')\n        plt.title(\"Correlation Heatmap\")\n        plt.show()\n\n    return corr", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df, plot=False):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if 'Value' not in df.columns:\n        raise ValueError(\"'Value' column not found in DataFrame\")\n    if not all(isinstance(x, list) for x in df['Value']):\n        raise ValueError(\"'Value' column contains non-list values\")\n\n    # Split lists in the 'Value' column into separate columns\n    df = df['Value'].apply(pd.Series)\n    df.columns = [f'Value_{i}' for i in range(1, len(df.columns) + 1)]\n\n    # Calculate the Pearson correlation coefficient\n    corr = df.corr()\n\n    if plot:\n        # Visualize the correlation matrix using a heatmap\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(corr, annot=True, cmap='coolwarm')\n        plt.title(\"Correlation Heatmap\")\n        plt.show()\n\n    return corr"}
{"task_id": "BigCodeBench/308", "solution": "import pandas as pd\nfrom statistics import mean\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\ndef task_func(additional_fields = []):\n    # Generate random grades for each student in each subject\n    data = {student: {field: random.randint(0, 100) for field in FIELDS} for student in STUDENTS}\n\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Calculate the average grade for each student\n    df['Average'] = df.mean(axis=1)\n\n    # Calculate the average grade for each subject\n    df.loc['Average Grade'] = df.mean()\n\n    return df", "raw_solution": "import pandas as pd\nfrom statistics import mean\nimport random\n\n# Constants for generating the report data\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\n\ndef task_func(additional_fields = []):\n    # Generate random grades for each student in each subject\n    data = {student: {field: random.randint(0, 100) for field in FIELDS} for student in STUDENTS}\n\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Calculate the average grade for each student\n    df['Average'] = df.mean(axis=1)\n\n    # Calculate the average grade for each subject\n    df.loc['Average Grade'] = df.mean()\n\n    return df\n```"}
{"task_id": "BigCodeBench/310", "solution": "import os\nimport csv\nimport random\nfrom statistics import mean\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\ndef task_func(filename):\n    # Generate data\n    data = []\n    for i in range(PEOPLE_COUNT):\n        name = f'Person{i+1}'\n        age = random.randint(18, 60)\n        height = round(random.uniform(1.50, 2.00), 2)\n        weight = round(random.uniform(50, 150), 2)\n        data.append([name, age, height, weight])\n\n    # Calculate averages\n    avg_age = round(mean([row[1] for row in data]), 2)\n    avg_height = round(mean([row[2] for row in data]), 2)\n    avg_weight = round(mean([row[3] for row in data]), 2)\n\n    # Append averages to data\n    data.append([f'Average', avg_age, avg_height, avg_weight])\n\n    # Write to CSV file\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(COLUMNS)\n        writer.writerows(data)\n\n    return filename", "raw_solution": "import os\nimport csv\nimport random\nfrom statistics import mean\n\n# Constants\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\n\ndef task_func(filename):\n    # Generate data\n    data = []\n    for i in range(PEOPLE_COUNT):\n        name = f'Person{i+1}'\n        age = random.randint(18, 60)\n        height = round(random.uniform(1.50, 2.00), 2)\n        weight = round(random.uniform(50, 150), 2)\n        data.append([name, age, height, weight])\n\n    # Calculate averages\n    avg_age = round(mean([row[1] for row in data]), 2)\n    avg_height = round(mean([row[2] for row in data]), 2)\n    avg_weight = round(mean([row[3] for row in data]), 2)\n\n    # Append averages to data\n    data.append([f'Average', avg_age, avg_height, avg_weight])\n\n    # Write to CSV file\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(COLUMNS)\n        writer.writerows(data)\n\n    return filename\n```"}
{"task_id": "BigCodeBench/313", "solution": "import re\nimport os\nimport shutil\nfrom datetime import datetime\ndef task_func(directory):\n    # Initialize the dictionary to store the subdirectories and their corresponding files\n    subdir_files = {}\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the file is a regular file\n        if os.path.isfile(os.path.join(directory, filename)):\n            # Extract the text that is not enclosed in square brackets\n            match = re.search(r'\\[(.*?)\\]', filename)\n            if match:\n                # If the text is found, move the file to a subdirectory named after this text\n                subdir = os.path.join(directory, match.group(1))\n                if not os.path.exists(subdir):\n                    os.makedirs(subdir)\n                shutil.move(os.path.join(directory, filename), subdir)\n                # Add the file to the list of files in the subdirectory\n                if subdir in subdir_files:\n                    subdir_files[subdir].append(filename)\n                else:\n                    subdir_files[subdir] = [filename]\n\n    # Return the directory path and the dictionary of subdirectories and their corresponding files\n    return directory, subdir_files", "raw_solution": "import re\nimport os\nimport shutil\nfrom datetime import datetime\n\ndef task_func(directory):\n    # Initialize the dictionary to store the subdirectories and their corresponding files\n    subdir_files = {}\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the file is a regular file\n        if os.path.isfile(os.path.join(directory, filename)):\n            # Extract the text that is not enclosed in square brackets\n            match = re.search(r'\\[(.*?)\\]', filename)\n            if match:\n                # If the text is found, move the file to a subdirectory named after this text\n                subdir = os.path.join(directory, match.group(1))\n                if not os.path.exists(subdir):\n                    os.makedirs(subdir)\n                shutil.move(os.path.join(directory, filename), subdir)\n                # Add the file to the list of files in the subdirectory\n                if subdir in subdir_files:\n                    subdir_files[subdir].append(filename)\n                else:\n                    subdir_files[subdir] = [filename]\n\n    # Return the directory path and the dictionary of subdirectories and their corresponding files\n    return directory, subdir_files\n```"}
{"task_id": "BigCodeBench/324", "solution": "import subprocess\nimport time\nimport threading\ndef task_func(file_list):\n    exit_codes = []\n    threads = []\n\n    def run_file(file):\n        try:\n            result = subprocess.run([file], capture_output=True, text=True, check=True)\n            exit_codes.append(result.returncode)\n        except subprocess.CalledProcessError as e:\n            exit_codes.append(e.returncode)\n\n    for file in file_list:\n        thread = threading.Thread(target=run_file, args=(file,))\n        threads.append(thread)\n        thread.start()\n\n    for thread in threads:\n        thread.join()\n\n    return exit_codes", "raw_solution": "import subprocess\nimport time\nimport threading\n\ndef task_func(file_list):\n    exit_codes = []\n    threads = []\n\n    def run_file(file):\n        try:\n            result = subprocess.run([file], capture_output=True, text=True, check=True)\n            exit_codes.append(result.returncode)\n        except subprocess.CalledProcessError as e:\n            exit_codes.append(e.returncode)\n\n    for file in file_list:\n        thread = threading.Thread(target=run_file, args=(file,))\n        threads.append(thread)\n        thread.start()\n\n    for thread in threads:\n        thread.join()\n\n    return exit_codes\n```"}
{"task_id": "BigCodeBench/326", "solution": "import subprocess\nimport os\nimport sys\nimport glob\ndef task_func(directory_path):\n    result = []\n    for file in glob.glob(os.path.join(directory_path, \"*.bat\")):\n        try:\n            exit_code = subprocess.call(file, shell=True)\n            result.append((file, exit_code))\n        except Exception as e:\n            result.append((file, None))\n    return result", "raw_solution": "import subprocess\nimport os\nimport sys\nimport glob\n\ndef task_func(directory_path):\n    result = []\n    for file in glob.glob(os.path.join(directory_path, \"*.bat\")):\n        try:\n            exit_code = subprocess.call(file, shell=True)\n            result.append((file, exit_code))\n        except Exception as e:\n            result.append((file, None))\n    return result\n```"}
{"task_id": "BigCodeBench/341", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"The input df must contain the specified column\")\n\n    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n\n    if df[col].dtype in ['int64', 'float64']:\n        sns.histplot(df[col], kde=True, ax=axes[0])\n    else:\n        sns.countplot(df[col], ax=axes[0])\n\n    sns.boxplot(df[col], ax=axes[1])\n\n    plt.tight_layout()\n\n    return fig", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"The input df must contain the specified column\")\n\n    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n\n    if df[col].dtype in ['int64', 'float64']:\n        sns.histplot(df[col], kde=True, ax=axes[0])\n    else:\n        sns.countplot(df[col], ax=axes[0])\n\n    sns.boxplot(df[col], ax=axes[1])\n\n    plt.tight_layout()\n\n    return fig\n```"}
{"task_id": "BigCodeBench/346", "solution": "import subprocess\nimport os\nimport sys\nimport time\ndef task_func(script_path, wait=True, *args):\n    if not os.path.exists(script_path):\n        raise ValueError(\"Script does not exist\")\n    try:\n        if wait:\n            return subprocess.run([sys.executable, script_path] + list(args), check=True, capture_output=True).returncode\n        else:\n            subprocess.Popen([sys.executable, script_path] + list(args))\n            return None\n    except subprocess.CalledProcessError as e:\n        raise subprocess.CalledProcessError(e.returncode, e.cmd, e.output)", "raw_solution": "import subprocess\nimport os\nimport sys\nimport time\n\ndef task_func(script_path, wait=True, *args):\n    if not os.path.exists(script_path):\n        raise ValueError(\"Script does not exist\")\n    try:\n        if wait:\n            return subprocess.run([sys.executable, script_path] + list(args), check=True, capture_output=True).returncode\n        else:\n            subprocess.Popen([sys.executable, script_path] + list(args))\n            return None\n    except subprocess.CalledProcessError as e:\n        raise subprocess.CalledProcessError(e.returncode, e.cmd, e.output)\n```"}
{"task_id": "BigCodeBench/360", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(file_location, sheet_name):\n    if not os.path.exists(file_location):\n        raise FileNotFoundError(\"File does not exist at the specified path.\")\n    if not pd.ExcelFile(file_location).sheet_names.count(sheet_name):\n        raise ValueError(\"Specified sheet does not exist in the workbook.\")\n    df = pd.read_excel(file_location, sheet_name=sheet_name)\n    stats = df.describe().T.to_dict()\n    fig, ax = plt.subplots()\n    ax.bar(stats.keys(), [stat['mean'] for stat in stats.values()], color='b', label='Mean')\n    ax.bar(stats.keys(), [stat['std'] for stat in stats.values()], color='r', label='Standard Deviation')\n    ax.set_title('Mean and Standard Deviation')\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Values')\n    ax.legend()\n    return stats, fig", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(file_location, sheet_name):\n    if not os.path.exists(file_location):\n        raise FileNotFoundError(\"File does not exist at the specified path.\")\n    if not pd.ExcelFile(file_location).sheet_names.count(sheet_name):\n        raise ValueError(\"Specified sheet does not exist in the workbook.\")\n    df = pd.read_excel(file_location, sheet_name=sheet_name)\n    stats = df.describe().T.to_dict()\n    fig, ax = plt.subplots()\n    ax.bar(stats.keys(), [stat['mean'] for stat in stats.values()], color='b', label='Mean')\n    ax.bar(stats.keys(), [stat['std'] for stat in stats.values()], color='r', label='Standard Deviation')\n    ax.set_title('Mean and Standard Deviation')\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Values')\n    ax.legend()\n    return stats, fig\n```"}
{"task_id": "BigCodeBench/367", "solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\ndef task_func(activities):\n    if not all(isinstance(activity, datetime) for activity in activities):\n        raise TypeError(\"Activities must be datetime objects\")\n\n    activity_counts = defaultdict(int)\n    for activity in activities:\n        activity_counts[activity.strftime('%A')] += 1\n\n    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    counts = [activity_counts[day] for day in days_of_week]\n\n    plt.bar(days_of_week, counts)\n    plt.xlabel('Day of the Week')\n    plt.ylabel('Number of Activities')\n    plt.title('Weekly Activity')\n    plt.show()\n\n    return plt.gca()", "raw_solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef task_func(activities):\n    if not all(isinstance(activity, datetime) for activity in activities):\n        raise TypeError(\"Activities must be datetime objects\")\n\n    activity_counts = defaultdict(int)\n    for activity in activities:\n        activity_counts[activity.strftime('%A')] += 1\n\n    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    counts = [activity_counts[day] for day in days_of_week]\n\n    plt.bar(days_of_week, counts)\n    plt.xlabel('Day of the Week')\n    plt.ylabel('Number of Activities')\n    plt.title('Weekly Activity')\n    plt.show()\n\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/368", "solution": "import os\nimport shutil\nimport random\ndef task_func(src_dir: str, dest_dir: str, seed:int = 100) -> str:\n    random.seed(seed)\n    files = os.listdir(src_dir)\n    if not files:\n        raise ValueError(\"Source directory is empty\")\n    file_to_move = random.choice(files)\n    shutil.move(os.path.join(src_dir, file_to_move), dest_dir)\n    return file_to_move", "raw_solution": "import os\nimport shutil\nimport random\n\ndef task_func(src_dir: str, dest_dir: str, seed:int = 100) -> str:\n    random.seed(seed)\n    files = os.listdir(src_dir)\n    if not files:\n        raise ValueError(\"Source directory is empty\")\n    file_to_move = random.choice(files)\n    shutil.move(os.path.join(src_dir, file_to_move), dest_dir)\n    return file_to_move\n```"}
{"task_id": "BigCodeBench/374", "solution": "import regex as re\nimport glob\nimport os\nfrom openpyxl import load_workbook\ndef task_func(directory_path='./xlsx_files/'):\n    count = 0\n    for file in glob.glob(os.path.join(directory_path, '*.xlsx')):\n        wb = load_workbook(filename=file, read_only=False)\n        for sheet in wb.worksheets:\n            for row in sheet.iter_rows():\n                for cell in row:\n                    if cell.value is not None:\n                        cell.value = re.sub(r'(?<=\")', '\\\\\\\\', str(cell.value))\n        wb.save(file)\n        count += 1\n    return count", "raw_solution": "import regex as re\nimport glob\nimport os\nfrom openpyxl import load_workbook\n\ndef task_func(directory_path='./xlsx_files/'):\n    count = 0\n    for file in glob.glob(os.path.join(directory_path, '*.xlsx')):\n        wb = load_workbook(filename=file, read_only=False)\n        for sheet in wb.worksheets:\n            for row in sheet.iter_rows():\n                for cell in row:\n                    if cell.value is not None:\n                        cell.value = re.sub(r'(?<=\")', '\\\\\\\\', str(cell.value))\n        wb.save(file)\n        count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/399", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency cannot be negative\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be positive\")\n\n    x = np.linspace(0, 1, sample_size)\n    y_sin = np.sin(2 * np.pi * frequency * x)\n    y_cos = np.cos(2 * np.pi * frequency * x)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y_sin, label='Sine')\n    ax.plot(x, y_cos, label='Cosine')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n    ax.legend()\n    return fig, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency cannot be negative\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be positive\")\n\n    x = np.linspace(0, 1, sample_size)\n    y_sin = np.sin(2 * np.pi * frequency * x)\n    y_cos = np.cos(2 * np.pi * frequency * x)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y_sin, label='Sine')\n    ax.plot(x, y_cos, label='Cosine')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n    ax.legend()\n    return fig, ax\n```"}
{"task_id": "BigCodeBench/401", "solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\ndef task_func(app_name):\n    app = Flask(app_name)\n    mail = Mail(app)\n\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'localhost')\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', 25))\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'False').lower() in ['true', '1']\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', None)\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', None)\n\n    return mail, app.config", "raw_solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\n\ndef task_func(app_name):\n    app = Flask(app_name)\n    mail = Mail(app)\n\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'localhost')\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', 25))\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'False').lower() in ['true', '1']\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', None)\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', None)\n\n    return mail, app.config\n```"}
{"task_id": "BigCodeBench/409", "solution": "import os\nimport pandas as pd\nimport numpy as np\ndef task_func(excel_file_path, file_name, column_name):\n    if not os.path.exists(excel_file_path):\n        raise FileNotFoundError(\"The specified Excel file does not exist.\")\n    if not os.path.exists(os.path.join(excel_file_path, file_name)):\n        raise ValueError(\"The specified file does not exist in the specified directory.\")\n    df = pd.read_excel(os.path.join(excel_file_path, file_name))\n    if column_name not in df.columns:\n        raise ValueError(\"The specified column does not exist in the file.\")\n    mean = df[column_name].mean()\n    median = df[column_name].median()\n    std_dev = df[column_name].std()\n    return {\"mean\": mean, \"median\": median, \"std_dev\": std_dev}", "raw_solution": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(excel_file_path, file_name, column_name):\n    if not os.path.exists(excel_file_path):\n        raise FileNotFoundError(\"The specified Excel file does not exist.\")\n    if not os.path.exists(os.path.join(excel_file_path, file_name)):\n        raise ValueError(\"The specified file does not exist in the specified directory.\")\n    df = pd.read_excel(os.path.join(excel_file_path, file_name))\n    if column_name not in df.columns:\n        raise ValueError(\"The specified column does not exist in the file.\")\n    mean = df[column_name].mean()\n    median = df[column_name].median()\n    std_dev = df[column_name].std()\n    return {\"mean\": mean, \"median\": median, \"std_dev\": std_dev}\n```"}
{"task_id": "BigCodeBench/417", "solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\ndef task_func(X, Y, learning_rate=0.01):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n\n    # Construct the model\n    model = Sequential()\n    model.add(Dense(1, input_dim=2, activation='sigmoid'))\n\n    # Compile the model\n    sgd = SGD(lr=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\n    # Train the model\n    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=0)\n\n    # Plot the training and validation loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    return model, plt.gca()", "raw_solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\n\ndef task_func(X, Y, learning_rate=0.01):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n\n    # Construct the model\n    model = Sequential()\n    model.add(Dense(1, input_dim=2, activation='sigmoid'))\n\n    # Compile the model\n    sgd = SGD(lr=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\n    # Train the model\n    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=0)\n\n    # Plot the training and validation loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    return model, plt.gca()\n```"}
{"task_id": "BigCodeBench/418", "solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\ndef task_func(X, Y):\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    model = keras.Sequential([\n        keras.layers.Dense(1, input_shape=(X_train.shape[1],), activation='sigmoid')\n    ])\n\n    model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\n    history = model.fit(X_train, y_train, epochs=100, verbose=0)\n\n    y_pred = model.predict(X_test)\n    fpr, tpr, _ = roc_curve(y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return model, plt.gca()", "raw_solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\ndef task_func(X, Y):\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    model = keras.Sequential([\n        keras.layers.Dense(1, input_shape=(X_train.shape[1],), activation='sigmoid')\n    ])\n\n    model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\n    history = model.fit(X_train, y_train, epochs=100, verbose=0)\n\n    y_pred = model.predict(X_test)\n    fpr, tpr, _ = roc_curve(y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return model, plt.gca()\n```"}
{"task_id": "BigCodeBench/424", "solution": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n    if n_clusters <= 0 or not isinstance(n_clusters, int):\n        raise ValueError(\"'n_clusters' must be a positive integer.\")\n\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = image.reshape((image.shape[0] * image.shape[1], 3))\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(image)\n\n    segmented_image = kmeans.cluster_centers_[kmeans.labels_]\n    segmented_image = segmented_image.reshape(image.shape[0], 1, 3)\n\n    return image, segmented_image", "raw_solution": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"Image file does not exist at the specified path.\")\n    if n_clusters <= 0 or not isinstance(n_clusters, int):\n        raise ValueError(\"'n_clusters' must be a positive integer.\")\n\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = image.reshape((image.shape[0] * image.shape[1], 3))\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(image)\n\n    segmented_image = kmeans.cluster_centers_[kmeans.labels_]\n    segmented_image = segmented_image.reshape(image.shape[0], 1, 3)\n\n    return image, segmented_image\n```"}
{"task_id": "BigCodeBench/443", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    # Calculate the product of a matrix 'P' and a 3D tensor 'T'\n    result = np.dot(P, T)\n    # Flatten the result\n    flattened_result = result.flatten()\n    # Apply KMeans clustering to the flattened data\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    kmeans.fit(flattened_result.reshape(-1, 1))\n    # Visualize it\n    fig, ax = plt.subplots()\n    ax.scatter(flattened_result, np.zeros_like(flattened_result), c=kmeans.labels_)\n    ax.set_title('KMeans Clustering Visualization')\n    return kmeans.labels_, ax", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    # Calculate the product of a matrix 'P' and a 3D tensor 'T'\n    result = np.dot(P, T)\n    # Flatten the result\n    flattened_result = result.flatten()\n    # Apply KMeans clustering to the flattened data\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    kmeans.fit(flattened_result.reshape(-1, 1))\n    # Visualize it\n    fig, ax = plt.subplots()\n    ax.scatter(flattened_result, np.zeros_like(flattened_result), c=kmeans.labels_)\n    ax.set_title('KMeans Clustering Visualization')\n    return kmeans.labels_, ax\n```"}
{"task_id": "BigCodeBench/445", "solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\ndef task_func(points, seed=0):\n    if not isinstance(points, np.ndarray):\n        raise ValueError(\"Input points must be a numpy array\")\n    if points.shape[1] != 2:\n        raise ValueError(\"Input points must be a 2D array\")\n    np.random.seed(seed)\n    jitter = np.random.uniform(-0.01, 0.01, points.shape)\n    points += jitter\n    vor = Voronoi(points)\n    fig, ax = plt.subplots()\n    voronoi_plot_2d(vor, ax=ax)\n    ax.scatter(points[:, 0], points[:, 1], color='r')\n    return vor, ax", "raw_solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\n\ndef task_func(points, seed=0):\n    if not isinstance(points, np.ndarray):\n        raise ValueError(\"Input points must be a numpy array\")\n    if points.shape[1] != 2:\n        raise ValueError(\"Input points must be a 2D array\")\n    np.random.seed(seed)\n    jitter = np.random.uniform(-0.01, 0.01, points.shape)\n    points += jitter\n    vor = Voronoi(points)\n    fig, ax = plt.subplots()\n    voronoi_plot_2d(vor, ax=ax)\n    ax.scatter(points[:, 0], points[:, 1], color='r')\n    return vor, ax\n```"}
{"task_id": "BigCodeBench/454", "solution": "import os\nimport shutil\nimport glob\ndef task_func(src_dir, dest_dir, ext):\n    if not os.path.exists(src_dir) or not os.path.exists(dest_dir):\n        raise FileNotFoundError(\"Source or Destination directory does not exist\")\n\n    moved_files = []\n    for file in glob.glob(os.path.join(src_dir, f\"*.{ext}\")):\n        filename = os.path.basename(file)\n        dest_file = os.path.join(dest_dir, filename)\n        if not os.path.exists(dest_file):\n            shutil.move(file, dest_dir)\n            moved_files.append(dest_file)\n    return moved_files", "raw_solution": "import os\nimport shutil\nimport glob\n\ndef task_func(src_dir, dest_dir, ext):\n    if not os.path.exists(src_dir) or not os.path.exists(dest_dir):\n        raise FileNotFoundError(\"Source or Destination directory does not exist\")\n\n    moved_files = []\n    for file in glob.glob(os.path.join(src_dir, f\"*.{ext}\")):\n        filename = os.path.basename(file)\n        dest_file = os.path.join(dest_dir, filename)\n        if not os.path.exists(dest_file):\n            shutil.move(file, dest_dir)\n            moved_files.append(dest_file)\n    return moved_files\n```"}
{"task_id": "BigCodeBench/458", "solution": "import json\nimport re\nimport pandas as pd\ndef task_func(json_str):\n    if not json_str:\n        return pd.DataFrame()\n    data = json.loads(json_str)\n    for key, value in data.items():\n        if isinstance(value, list):\n            for i, item in enumerate(value):\n                if isinstance(item, str) and re.match(r'^-?\\d+(?:\\.\\d+)?$', item):\n                    value[i] = float(item) * 2\n                elif isinstance(item, (int, float)):\n                    value[i] = item * 2\n        elif isinstance(value, str) and re.match(r'^-?\\d+(?:\\.\\d+)?$', value):\n            data[key] = float(value) * 2\n        elif isinstance(value, (int, float)):\n            data[key] = value * 2\n    return pd.DataFrame(data)", "raw_solution": "import json\nimport re\nimport pandas as pd\n\ndef task_func(json_str):\n    if not json_str:\n        return pd.DataFrame()\n    data = json.loads(json_str)\n    for key, value in data.items():\n        if isinstance(value, list):\n            for i, item in enumerate(value):\n                if isinstance(item, str) and re.match(r'^-?\\d+(?:\\.\\d+)?$', item):\n                    value[i] = float(item) * 2\n                elif isinstance(item, (int, float)):\n                    value[i] = item * 2\n        elif isinstance(value, str) and re.match(r'^-?\\d+(?:\\.\\d+)?$', value):\n            data[key] = float(value) * 2\n        elif isinstance(value, (int, float)):\n            data[key] = value * 2\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/461", "solution": "import subprocess\nimport psutil\nimport time\nimport os\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.exists(script_path):\n        raise FileNotFoundError(f\"Script path {script_path} does not exist.\")\n\n    start_time = time.time()\n    process = subprocess.Popen(['python', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    cpu_usage = 0\n    memory_usage = 0\n\n    while time.time() - start_time < timeout:\n        if process.poll() is not None:\n            break\n\n        for proc in psutil.process_iter(['pid', 'cpu_percent', 'memory_info']):\n            if proc.info['pid'] == process.pid:\n                cpu_usage += proc.info['cpu_percent']\n                memory_usage += proc.info['memory_info'].rss\n                break\n\n        time.sleep(0.1)\n\n    if process.poll() is None:\n        process.terminate()\n\n    return {'CPU Usage': cpu_usage, 'Memory Usage': memory_usage}", "raw_solution": "import subprocess\nimport psutil\nimport time\nimport os\n\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.exists(script_path):\n        raise FileNotFoundError(f\"Script path {script_path} does not exist.\")\n\n    start_time = time.time()\n    process = subprocess.Popen(['python', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    cpu_usage = 0\n    memory_usage = 0\n\n    while time.time() - start_time < timeout:\n        if process.poll() is not None:\n            break\n\n        for proc in psutil.process_iter(['pid', 'cpu_percent', 'memory_info']):\n            if proc.info['pid'] == process.pid:\n                cpu_usage += proc.info['cpu_percent']\n                memory_usage += proc.info['memory_info'].rss\n                break\n\n        time.sleep(0.1)\n\n    if process.poll() is None:\n        process.terminate()\n\n    return {'CPU Usage': cpu_usage, 'Memory Usage': memory_usage}\n```"}
{"task_id": "BigCodeBench/477", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n    df = pd.DataFrame({\n        \"x\": np.random.rand(N),\n        \"y\": np.random.rand(N),\n        \"category\": np.random.choice(CATEGORIES, N, replace=True if N >= len(CATEGORIES) else False)\n    })\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(df[\"x\"], df[\"y\"], c=df[\"category\"])\n    plt.show()\n    return df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n    df = pd.DataFrame({\n        \"x\": np.random.rand(N),\n        \"y\": np.random.rand(N),\n        \"category\": np.random.choice(CATEGORIES, N, replace=True if N >= len(CATEGORIES) else False)\n    })\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(df[\"x\"], df[\"y\"], c=df[\"category\"])\n    plt.show()\n    return df, ax\n```"}
{"task_id": "BigCodeBench/486", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    time_range = pd.date_range(start=start_time, end=end_time, freq=step)\n    values = np.random.normal(0, 1, len(time_range)) + trend * np.arange(len(time_range))\n    df = pd.DataFrame({'Time': time_range, 'Value': values})\n    fig, ax = plt.subplots()\n    ax.plot(df['Time'], df['Value'])\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n    return ax", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    time_range = pd.date_range(start=start_time, end=end_time, freq=step)\n    values = np.random.normal(0, 1, len(time_range)) + trend * np.arange(len(time_range))\n    df = pd.DataFrame({'Time': time_range, 'Value': values})\n    fig, ax = plt.subplots()\n    ax.plot(df['Time'], df['Value'])\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n    return ax\n```"}
{"task_id": "BigCodeBench/492", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    if not isinstance(epoch_milliseconds, int) or not isinstance(random_seed, int) or not isinstance(products, list):\n        raise ValueError(\"Invalid input type\")\n    if len(products) != 5:\n        raise ValueError(\"Invalid number of products\")\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    end_date = datetime.now()\n    date_range = (end_date - start_date).days\n    data = []\n    for i in range(date_range):\n        for product in products:\n            data.append({\n                \"Product\": product,\n                \"Date\": start_date + timedelta(days=i),\n                \"Sales\": random.randint(10, 50),\n            })\n    return pd.DataFrame(data)", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\n\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    if not isinstance(epoch_milliseconds, int) or not isinstance(random_seed, int) or not isinstance(products, list):\n        raise ValueError(\"Invalid input type\")\n    if len(products) != 5:\n        raise ValueError(\"Invalid number of products\")\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    end_date = datetime.now()\n    date_range = (end_date - start_date).days\n    data = []\n    for i in range(date_range):\n        for product in products:\n            data.append({\n                \"Product\": product,\n                \"Date\": start_date + timedelta(days=i),\n                \"Sales\": random.randint(10, 50),\n            })\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/501", "solution": "import xlwt\nimport os\nimport pandas as pd\nimport json\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    if not isinstance(json_str, (str, bytes, bytearray)):\n        raise TypeError(\"json_str must be a string, bytes, or bytearray\")\n    try:\n        data = json.loads(json_str)\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON\")\n    if not isinstance(data, list):\n        raise ValueError(\"JSON must be a list\")\n    if not isinstance(filename, str):\n        raise TypeError(\"filename must be a string\")\n    if not isinstance(sheet_name, str):\n        raise TypeError(\"sheet_name must be a string\")\n    if not data:\n        wb = xlwt.Workbook()\n        wb.save(filename)\n        return os.path.abspath(filename)\n    df = pd.DataFrame(data)\n    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n    df.to_excel(writer, sheet_name=sheet_name, index=False)\n    writer.save()\n    return os.path.abspath(filename)", "raw_solution": "import xlwt\nimport os\nimport pandas as pd\nimport json\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    if not isinstance(json_str, (str, bytes, bytearray)):\n        raise TypeError(\"json_str must be a string, bytes, or bytearray\")\n    try:\n        data = json.loads(json_str)\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON\")\n    if not isinstance(data, list):\n        raise ValueError(\"JSON must be a list\")\n    if not isinstance(filename, str):\n        raise TypeError(\"filename must be a string\")\n    if not isinstance(sheet_name, str):\n        raise TypeError(\"sheet_name must be a string\")\n    if not data:\n        wb = xlwt.Workbook()\n        wb.save(filename)\n        return os.path.abspath(filename)\n    df = pd.DataFrame(data)\n    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n    df.to_excel(writer, sheet_name=sheet_name, index=False)\n    writer.save()\n    return os.path.abspath(filename)\n```"}
{"task_id": "BigCodeBench/502", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\ndef task_func(days_in_past=7, random_seed=0):\n    random.seed(random_seed)\n    activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n    df = pd.DataFrame(columns=[\"Date\", \"Activity\", \"Duration\"])\n    for i in range(days_in_past):\n        date = datetime.now() - timedelta(days=i)\n        for activity in activities:\n            duration = random.randint(0, 120)\n            df = df.append({\"Date\": date, \"Activity\": activity, \"Duration\": duration}, ignore_index=True)\n    df[\"Date\"] = df[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n    g = sns.lineplot(data=df, x=\"Date\", y=\"Duration\", hue=\"Activity\", palette=\"deep\")\n    return (g, df)", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\n\ndef task_func(days_in_past=7, random_seed=0):\n    random.seed(random_seed)\n    activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n    df = pd.DataFrame(columns=[\"Date\", \"Activity\", \"Duration\"])\n    for i in range(days_in_past):\n        date = datetime.now() - timedelta(days=i)\n        for activity in activities:\n            duration = random.randint(0, 120)\n            df = df.append({\"Date\": date, \"Activity\": activity, \"Duration\": duration}, ignore_index=True)\n    df[\"Date\"] = df[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n    g = sns.lineplot(data=df, x=\"Date\", y=\"Duration\", hue=\"Activity\", palette=\"deep\")\n    return (g, df)\n```"}
{"task_id": "BigCodeBench/503", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0\n):\n    np.random.seed(random_seed)\n    dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days_in_past)]\n    prices = np.random.rand(days_in_past, len(stock_names))\n    df = pd.DataFrame(prices, index=dates, columns=stock_names)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0\n):\n    np.random.seed(random_seed)\n    dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days_in_past)]\n    prices = np.random.rand(days_in_past, len(stock_names))\n    df = pd.DataFrame(prices, index=dates, columns=stock_names)\n    return df\n```"}
{"task_id": "BigCodeBench/509", "solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    try:\n        with open(file_path1, 'r') as file1, open(file_path2, 'r') as file2:\n            reader1 = csv.reader(file1, delimiter=delimiter, quotechar=quotechar)\n            reader2 = csv.reader(file2, delimiter=delimiter, quotechar=quotechar)\n            lines1 = list(reader1)\n            lines2 = list(reader2)\n\n            if not lines1 or not lines2:\n                raise ValueError(\"One or both of the files are empty.\")\n\n            diff_lines = []\n            for line1, line2 in zip(lines1, lines2):\n                if line1 != line2:\n                    diff_lines.append(line1)\n                    diff_lines.append(line2)\n\n            if len(lines1) > len(lines2):\n                diff_lines.extend(lines1[len(lines2):])\n            elif len(lines2) > len(lines1):\n                diff_lines.extend(lines2[len(lines1):])\n\n            diff_report = []\n            for i, line in enumerate(diff_lines, start=1):\n                if i % 2 == 1:\n                    status = '-'\n                else:\n                    status = '+'\n                diff_report.append([i, status, line])\n\n            df = pd.DataFrame(diff_report, columns=['Line Number', 'Status', 'Content'])\n            return df\n\n    except FileNotFoundError:\n        raise FileNotFoundError(\"One or both of the files cannot be found.\")\n    except Exception as e:\n        raise Exception(\"An error occurred: \" + str(e))", "raw_solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    try:\n        with open(file_path1, 'r') as file1, open(file_path2, 'r') as file2:\n            reader1 = csv.reader(file1, delimiter=delimiter, quotechar=quotechar)\n            reader2 = csv.reader(file2, delimiter=delimiter, quotechar=quotechar)\n            lines1 = list(reader1)\n            lines2 = list(reader2)\n\n            if not lines1 or not lines2:\n                raise ValueError(\"One or both of the files are empty.\")\n\n            diff_lines = []\n            for line1, line2 in zip(lines1, lines2):\n                if line1 != line2:\n                    diff_lines.append(line1)\n                    diff_lines.append(line2)\n\n            if len(lines1) > len(lines2):\n                diff_lines.extend(lines1[len(lines2):])\n            elif len(lines2) > len(lines1):\n                diff_lines.extend(lines2[len(lines1):])\n\n            diff_report = []\n            for i, line in enumerate(diff_lines, start=1):\n                if i % 2 == 1:\n                    status = '-'\n                else:\n                    status = '+'\n                diff_report.append([i, status, line])\n\n            df = pd.DataFrame(diff_report, columns=['Line Number', 'Status', 'Content'])\n            return df\n\n    except FileNotFoundError:\n        raise FileNotFoundError(\"One or both of the files cannot be found.\")\n    except Exception as e:\n        raise Exception(\"An error occurred: \" + str(e))"}
{"task_id": "BigCodeBench/511", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if data.empty:\n        return ({'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}, None)\n    else:\n        stats = {\n            'sum': data[column].sum(),\n            'mean': data[column].mean(),\n            'min': data[column].min(),\n            'max': data[column].max()\n        }\n        fig, ax = plt.subplots()\n        ax.pie(data[column], labels=data['Age'], autopct='%1.1f%%')\n        ax.axis('equal')\n        return (stats, ax)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if data.empty:\n        return ({'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}, None)\n    else:\n        stats = {\n            'sum': data[column].sum(),\n            'mean': data[column].mean(),\n            'min': data[column].min(),\n            'max': data[column].max()\n        }\n        fig, ax = plt.subplots()\n        ax.pie(data[column], labels=data['Age'], autopct='%1.1f%%')\n        ax.axis('equal')\n        return (stats, ax)\n```"}
{"task_id": "BigCodeBench/513", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if not data:\n        raise ValueError(\"Data list is empty\")\n    df = pd.DataFrame(data)\n    if column not in df.columns:\n        raise KeyError(\"Invalid column\")\n    if (df[column] < 0).any():\n        raise ValueError(\"Negative values are not allowed\")\n    summary = {\n        'sum': df[column].sum(),\n        'mean': df[column].mean(),\n        'min': df[column].min(),\n        'max': df[column].max()\n    }\n    ax = df.plot(x='Date', y=column, kind='line', title=f'Line Chart of {column}')\n    plt.show()\n    return summary, ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if not data:\n        raise ValueError(\"Data list is empty\")\n    df = pd.DataFrame(data)\n    if column not in df.columns:\n        raise KeyError(\"Invalid column\")\n    if (df[column] < 0).any():\n        raise ValueError(\"Negative values are not allowed\")\n    summary = {\n        'sum': df[column].sum(),\n        'mean': df[column].mean(),\n        'min': df[column].min(),\n        'max': df[column].max()\n    }\n    ax = df.plot(x='Date', y=column, kind='line', title=f'Line Chart of {column}')\n    plt.show()\n    return summary, ax\n```"}
{"task_id": "BigCodeBench/526", "solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\ndef task_func(input_file=\"data.json\"):\n    with open(input_file, 'r') as file:\n        data = json.load(file)\n\n    stats = defaultdict(list)\n    for item in data:\n        for key, value in item.items():\n            if isinstance(value, (int, float)):\n                stats[key].append(value)\n\n    df = pd.DataFrame(stats)\n    df = df.apply(pd.to_numeric, errors='coerce')\n    df = df.dropna(axis=1, how='all')\n    df = df.dropna(axis=0, how='any')\n\n    df['mean'] = df.mean(axis=0)\n    df['median'] = df.median(axis=0)\n\n    df = df.sort_index(axis=1)\n    df = df.sort_index()\n\n    return df", "raw_solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\ndef task_func(input_file=\"data.json\"):\n    with open(input_file, 'r') as file:\n        data = json.load(file)\n\n    stats = defaultdict(list)\n    for item in data:\n        for key, value in item.items():\n            if isinstance(value, (int, float)):\n                stats[key].append(value)\n\n    df = pd.DataFrame(stats)\n    df = df.apply(pd.to_numeric, errors='coerce')\n    df = df.dropna(axis=1, how='all')\n    df = df.dropna(axis=0, how='any')\n\n    df['mean'] = df.mean(axis=0)\n    df['median'] = df.median(axis=0)\n\n    df = df.sort_index(axis=1)\n    df = df.sort_index()\n\n    return df\n```"}
{"task_id": "BigCodeBench/528", "solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(file_path):\n    if not file_path.endswith('.csv'):\n        raise ValueError(\"File must be a CSV file\")\n\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        rows = list(reader)\n\n    duplicates = [row for row in rows if rows.count(row) > 1]\n    duplicate_counts = Counter(tuple(sorted(row)) for row in duplicates)\n\n    df = pd.DataFrame(list(duplicate_counts.items()), columns=['Duplicates', 'Count'])\n    df.set_index('Duplicates', inplace=True)\n\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Duplicates')\n    ax.set_ylabel('Count')\n    ax.set_title('Duplicate Rows')\n\n    return duplicate_counts, ax", "raw_solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path):\n    if not file_path.endswith('.csv'):\n        raise ValueError(\"File must be a CSV file\")\n\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        rows = list(reader)\n\n    duplicates = [row for row in rows if rows.count(row) > 1]\n    duplicate_counts = Counter(tuple(sorted(row)) for row in duplicates)\n\n    df = pd.DataFrame(list(duplicate_counts.items()), columns=['Duplicates', 'Count'])\n    df.set_index('Duplicates', inplace=True)\n\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Duplicates')\n    ax.set_ylabel('Count')\n    ax.set_title('Duplicate Rows')\n\n    return duplicate_counts, ax"}
{"task_id": "BigCodeBench/530", "solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if (df['age'] < 0).any():\n        raise ValueError(\"Age cannot be negative\")\n    df['age'] = df['age'].apply(np.floor)\n    duplicates = df[df.duplicated(subset='name', keep=False)]\n    if duplicates.empty:\n        return Counter(), None\n    age_distribution = Counter(duplicates['age'])\n    min_age = min(age_distribution.keys())\n    max_age = max(age_distribution.keys())\n    bins = np.arange(min_age, max_age + 1) - 0.5\n    hist = sns.histplot(duplicates['age'], bins=bins, kde=False)\n    hist.set_title('Age Distribution for Duplicate Names')\n    hist.set_xlabel('Age')\n    hist.set_ylabel('Count')\n    return age_distribution, hist.get_figure()", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if (df['age'] < 0).any():\n        raise ValueError(\"Age cannot be negative\")\n    df['age'] = df['age'].apply(np.floor)\n    duplicates = df[df.duplicated(subset='name', keep=False)]\n    if duplicates.empty:\n        return Counter(), None\n    age_distribution = Counter(duplicates['age'])\n    min_age = min(age_distribution.keys())\n    max_age = max(age_distribution.keys())\n    bins = np.arange(min_age, max_age + 1) - 0.5\n    hist = sns.histplot(duplicates['age'], bins=bins, kde=False)\n    hist.set_title('Age Distribution for Duplicate Names')\n    hist.set_xlabel('Age')\n    hist.set_ylabel('Count')\n    return age_distribution, hist.get_figure()\n```"}
{"task_id": "BigCodeBench/532", "solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(df, bins=4):\n    # Identify and count duplicate values in the 'value' column\n    value_counts = df['value'].value_counts()\n    duplicate_counts = value_counts[value_counts > 1]\n\n    # Plot histogram with normal distribution curve\n    fig, ax = plt.subplots()\n    ax.hist(df['value'], bins=bins, color='green', alpha=0.6, edgecolor='black')\n    ax.set_title(\"Distribution\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n\n    # Fit a normal distribution to the data\n    mu, sigma = norm.fit(df['value'])\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, sigma)\n    ax.plot(x, p, 'k', linewidth=2)\n\n    return duplicate_counts, ax", "raw_solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(df, bins=4):\n    # Identify and count duplicate values in the 'value' column\n    value_counts = df['value'].value_counts()\n    duplicate_counts = value_counts[value_counts > 1]\n\n    # Plot histogram with normal distribution curve\n    fig, ax = plt.subplots()\n    ax.hist(df['value'], bins=bins, color='green', alpha=0.6, edgecolor='black')\n    ax.set_title(\"Distribution\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n\n    # Fit a normal distribution to the data\n    mu, sigma = norm.fit(df['value'])\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, sigma)\n    ax.plot(x, p, 'k', linewidth=2)\n\n    return duplicate_counts, ax\n```"}
{"task_id": "BigCodeBench/553", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(a, b):\n    df = pd.DataFrame(np.random.randint(0,100,size=(len(a), len(b))), index=a, columns=COLUMNS[:len(b)])\n    ax = df.plot(kind='bar', figsize=(10,5))\n    plt.title('Bar Chart')\n    plt.xlabel('Index')\n    plt.ylabel('Value')\n    return ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(a, b):\n    df = pd.DataFrame(np.random.randint(0,100,size=(len(a), len(b))), index=a, columns=COLUMNS[:len(b)])\n    ax = df.plot(kind='bar', figsize=(10,5))\n    plt.title('Bar Chart')\n    plt.xlabel('Index')\n    plt.ylabel('Value')\n    return ax\n```"}
{"task_id": "BigCodeBench/560", "solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(data):\n    # Convert the 'date' column to datetime format\n    data['date'] = pd.to_datetime(data['date'])\n\n    # Extract the year from the 'date' column\n    year = data['date'].dt.year.iloc[0]\n\n    # Set the 'date' column as the index\n    data.set_index('date', inplace=True)\n\n    # Group the data by month and calculate the mean value for each month\n    monthly_data = data.groupby(data.index.month).mean()\n\n    # Create a bar chart\n    ax = monthly_data.plot(kind='bar', legend=False)\n\n    # Set the title and labels\n    ax.set_title(f'Monthly Data for {year}')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n\n    return ax", "raw_solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(data):\n    # Convert the 'date' column to datetime format\n    data['date'] = pd.to_datetime(data['date'])\n\n    # Extract the year from the 'date' column\n    year = data['date'].dt.year.iloc[0]\n\n    # Set the 'date' column as the index\n    data.set_index('date', inplace=True)\n\n    # Group the data by month and calculate the mean value for each month\n    monthly_data = data.groupby(data.index.month).mean()\n\n    # Create a bar chart\n    ax = monthly_data.plot(kind='bar', legend=False)\n\n    # Set the title and labels\n    ax.set_title(f'Monthly Data for {year}')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/567", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Convert the string data to a numeric array\n    data = np.array([float(x) for x in data.split(',')])\n\n    # Calculate the bins\n    bins = np.arange(data.min(), data.max()+2) - 0.5\n\n    # Create the histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=bins, edgecolor='black')\n\n    # Set the title and labels\n    ax.set_title('Histogram of Values')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Convert the string data to a numeric array\n    data = np.array([float(x) for x in data.split(',')])\n\n    # Calculate the bins\n    bins = np.arange(data.min(), data.max()+2) - 0.5\n\n    # Create the histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=bins, edgecolor='black')\n\n    # Set the title and labels\n    ax.set_title('Histogram of Values')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return ax\n```"}
{"task_id": "BigCodeBench/574", "solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array_length=100, noise_level=0.2):\n    def sine_func(x, a, b, c):\n        return a * np.sin(b * x) + c\n\n    x = np.linspace(0, 1, array_length)\n    y = np.sin(2 * np.pi * x) + np.random.normal(0, noise_level, array_length)\n\n    popt, _ = curve_fit(sine_func, x, y)\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(x, y, 'o', label='Noisy data')\n    plt.plot(x, sine_func(x, *popt), '-', label='Fitted curve')\n    plt.legend()\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title('Sine wave with noise and fitted curve')\n    plt.grid(True)\n    return plt.gca()", "raw_solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(array_length=100, noise_level=0.2):\n    def sine_func(x, a, b, c):\n        return a * np.sin(b * x) + c\n\n    x = np.linspace(0, 1, array_length)\n    y = np.sin(2 * np.pi * x) + np.random.normal(0, noise_level, array_length)\n\n    popt, _ = curve_fit(sine_func, x, y)\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(x, y, 'o', label='Noisy data')\n    plt.plot(x, sine_func(x, *popt), '-', label='Fitted curve')\n    plt.legend()\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title('Sine wave with noise and fitted curve')\n    plt.grid(True)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/579", "solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r') as file:\n            reader = csv.reader(file)\n            data = list(reader)\n    except FileNotFoundError:\n        raise FileNotFoundError(\"File not found\")\n    except IOError:\n        raise IOError(\"Error in reading file\")\n\n    text = ' '.join(str(row) for row in data)\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode()\n    words = text.split()\n    word_count = Counter(words)\n    most_common_words = word_count.most_common(10)\n\n    words, frequencies = zip(*most_common_words)\n\n    fig, ax = plt.subplots()\n    ax.bar(words, frequencies)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('Most Common Words')\n\n    return (ax, most_common_words)", "raw_solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r') as file:\n            reader = csv.reader(file)\n            data = list(reader)\n    except FileNotFoundError:\n        raise FileNotFoundError(\"File not found\")\n    except IOError:\n        raise IOError(\"Error in reading file\")\n\n    text = ' '.join(str(row) for row in data)\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode()\n    words = text.split()\n    word_count = Counter(words)\n    most_common_words = word_count.most_common(10)\n\n    words, frequencies = zip(*most_common_words)\n\n    fig, ax = plt.subplots()\n    ax.bar(words, frequencies)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('Most Common Words')\n\n    return (ax, most_common_words)\n```"}
{"task_id": "BigCodeBench/582", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(size=1000):\n    # Generate normally distributed random numbers\n    data = np.random.normal(0, 1, size)\n\n    # Create a figure and axis\n    fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n\n    # Plot histogram\n    ax[0].hist(data, bins=30, density=True, color='skyblue', edgecolor='black')\n    ax[0].set_title('Histogram')\n    ax[0].set_xlabel('Value')\n    ax[0].set_ylabel('Frequency')\n\n    # Plot PDF\n    x = np.linspace(-4, 4, 100)\n    y = stats.norm.pdf(x, 0, 1)\n    ax[1].plot(x, y, color='red')\n    ax[1].set_title('Probability Density Function')\n    ax[1].set_xlabel('Value')\n    ax[1].set_ylabel('Probability')\n\n    # Adjust layout and spacing\n    plt.tight_layout()\n    plt.subplots_adjust(hspace=0.4)\n\n    return fig", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(size=1000):\n    # Generate normally distributed random numbers\n    data = np.random.normal(0, 1, size)\n\n    # Create a figure and axis\n    fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n\n    # Plot histogram\n    ax[0].hist(data, bins=30, density=True, color='skyblue', edgecolor='black')\n    ax[0].set_title('Histogram')\n    ax[0].set_xlabel('Value')\n    ax[0].set_ylabel('Frequency')\n\n    # Plot PDF\n    x = np.linspace(-4, 4, 100)\n    y = stats.norm.pdf(x, 0, 1)\n    ax[1].plot(x, y, color='red')\n    ax[1].set_title('Probability Density Function')\n    ax[1].set_xlabel('Value')\n    ax[1].set_ylabel('Probability')\n\n    # Adjust layout and spacing\n    plt.tight_layout()\n    plt.subplots_adjust(hspace=0.4)\n\n    return fig\n```"}
{"task_id": "BigCodeBench/583", "solution": "import rsa\nimport os\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES\nfrom base64 import b64encode, b64decode\ndef task_func():\n    # Generate RSA key pair\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Generate AES key and nonce\n    aes_key = get_random_bytes(16)\n    aes_nonce = get_random_bytes(16)\n\n    # Encrypt the private key with AES\n    cipher_aes = AES.new(aes_key, AES.MODE_EAX)\n    cipher_aes.nonce = aes_nonce\n    encrypted_private_key = cipher_aes.encrypt(rsa.key.exportKey('PEM'))\n\n    # Save the encrypted private key to a file\n    filename = f\"private_key_{b64encode(get_random_bytes(8)).decode()}.txt\"\n    with open(filename, 'wb') as file:\n        file.write(b64encode(encrypted_private_key))\n\n    return pubkey, filename, aes_key, aes_nonce", "raw_solution": "import rsa\nimport os\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES\nfrom base64 import b64encode, b64decode\n\ndef task_func():\n    # Generate RSA key pair\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Generate AES key and nonce\n    aes_key = get_random_bytes(16)\n    aes_nonce = get_random_bytes(16)\n\n    # Encrypt the private key with AES\n    cipher_aes = AES.new(aes_key, AES.MODE_EAX)\n    cipher_aes.nonce = aes_nonce\n    encrypted_private_key = cipher_aes.encrypt(rsa.key.exportKey('PEM'))\n\n    # Save the encrypted private key to a file\n    filename = f\"private_key_{b64encode(get_random_bytes(8)).decode()}.txt\"\n    with open(filename, 'wb') as file:\n        file.write(b64encode(encrypted_private_key))\n\n    return pubkey, filename, aes_key, aes_nonce\n```"}
{"task_id": "BigCodeBench/587", "solution": "import rsa\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\nfrom base64 import b64encode\ndef task_func(file_path):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # AES Encryption\n    aes_key = os.urandom(32)\n    cipher = Cipher(algorithms.AES(aes_key), modes.CBC())\n    encryptor = cipher.encryptor()\n\n    with open(file_path, 'rb') as file:\n        plaintext = file.read()\n\n    padder = padding.PKCS7(128).padder()\n    padded_data = padder.update(plaintext) + padder.finalize()\n\n    cipher_text = encryptor.update(padded_data) + encryptor.finalize()\n\n    # Save encrypted file\n    encrypted_file_name = \"encrypted_file.bin\"\n    with open(encrypted_file_name, 'wb') as file:\n        file.write(cipher_text)\n\n    # Encrypt AES key with RSA\n    encrypted_aes_key = rsa.encrypt(aes_key, pubkey)\n\n    # Save encrypted AES key\n    encrypted_aes_key_file_name = \"encrypted_aes_key.bin\"\n    with open(encrypted_aes_key_file_name, 'wb') as file:\n        file.write(encrypted_aes_key)\n\n    return pubkey, encrypted_file_name, encrypted_aes_key_file_name", "raw_solution": "import rsa\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\nfrom base64 import b64encode\n\ndef task_func(file_path):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # AES Encryption\n    aes_key = os.urandom(32)\n    cipher = Cipher(algorithms.AES(aes_key), modes.CBC())\n    encryptor = cipher.encryptor()\n\n    with open(file_path, 'rb') as file:\n        plaintext = file.read()\n\n    padder = padding.PKCS7(128).padder()\n    padded_data = padder.update(plaintext) + padder.finalize()\n\n    cipher_text = encryptor.update(padded_data) + encryptor.finalize()\n\n    # Save encrypted file\n    encrypted_file_name = \"encrypted_file.bin\"\n    with open(encrypted_file_name, 'wb') as file:\n        file.write(cipher_text)\n\n    # Encrypt AES key with RSA\n    encrypted_aes_key = rsa.encrypt(aes_key, pubkey)\n\n    # Save encrypted AES key\n    encrypted_aes_key_file_name = \"encrypted_aes_key.bin\"\n    with open(encrypted_aes_key_file_name, 'wb') as file:\n        file.write(encrypted_aes_key)\n\n    return pubkey, encrypted_file_name, encrypted_aes_key_file_name\n```"}
{"task_id": "BigCodeBench/590", "solution": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\ndef task_func(url):\n    if not url:\n        raise ValueError(\"URL is invalid or empty\")\n    try:\n        response = urllib.request.urlopen(url)\n    except urllib.error.URLError as e:\n        raise urllib.error.URLError(\"Network connectivity or server issue\") from e\n    html = response.read().decode('utf-8')\n    doc = pq(html)\n    data = []\n    for tag in doc('a'):\n        text = tag.text\n        href = tag.attrib['href']\n        data.append({'text': text, 'href': href, 'fetch_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n    return pd.DataFrame(data)", "raw_solution": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\n\ndef task_func(url):\n    if not url:\n        raise ValueError(\"URL is invalid or empty\")\n    try:\n        response = urllib.request.urlopen(url)\n    except urllib.error.URLError as e:\n        raise urllib.error.URLError(\"Network connectivity or server issue\") from e\n    html = response.read().decode('utf-8')\n    doc = pq(html)\n    data = []\n    for tag in doc('a'):\n        text = tag.text\n        href = tag.attrib['href']\n        data.append({'text': text, 'href': href, 'fetch_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/592", "solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    file_path = os.path.join(output_dir, 'sensor_data.csv')\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Time', 'Temperature', 'Humidity', 'Pressure'])\n\n        start_time = datetime.now()\n        for _ in range(hours):\n            for sensor in SENSORS:\n                data = [start_time.strftime('%Y-%m-%d %H:%M:%S'), randint(10, 30), randint(20, 80), randint(900, 1100)]\n                writer.writerow(data)\n            start_time += timedelta(hours=1)", "raw_solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\n\n# Constants\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    file_path = os.path.join(output_dir, 'sensor_data.csv')\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Time', 'Temperature', 'Humidity', 'Pressure'])\n\n        start_time = datetime.now()\n        for _ in range(hours):\n            for sensor in SENSORS:\n                data = [start_time.strftime('%Y-%m-%d %H:%M:%S'), randint(10, 30), randint(20, 80), randint(900, 1100)]\n                writer.writerow(data)\n            start_time += timedelta(hours=1)\n```"}
{"task_id": "BigCodeBench/593", "solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Generate traffic data\n    traffic_data = []\n    for i in range(hours):\n        traffic_count = {vehicle_type: randint(1, 100) for vehicle_type in VEHICLE_TYPES}\n        traffic_data.append({'Time': datetime.now() + timedelta(hours=i), **traffic_count})\n\n    # Save traffic data to CSV file\n    csv_file_path = os.path.join(output_dir, 'traffic_data.csv')\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        csv_writer = csv.DictWriter(csv_file, fieldnames=['Time', *VEHICLE_TYPES])\n        csv_writer.writeheader()\n        for data in traffic_data:\n            csv_writer.writerow(data)\n\n    # Load traffic data from CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Plot traffic data\n    fig, ax = plt.subplots()\n    for vehicle_type in VEHICLE_TYPES:\n        ax.plot(df['Time'], df[vehicle_type], label=vehicle_type)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Vehicle Count')\n    ax.legend()\n\n    return csv_file_path, ax", "raw_solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Generate traffic data\n    traffic_data = []\n    for i in range(hours):\n        traffic_count = {vehicle_type: randint(1, 100) for vehicle_type in VEHICLE_TYPES}\n        traffic_data.append({'Time': datetime.now() + timedelta(hours=i), **traffic_count})\n\n    # Save traffic data to CSV file\n    csv_file_path = os.path.join(output_dir, 'traffic_data.csv')\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        csv_writer = csv.DictWriter(csv_file, fieldnames=['Time', *VEHICLE_TYPES])\n        csv_writer.writeheader()\n        for data in traffic_data:\n            csv_writer.writerow(data)\n\n    # Load traffic data from CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Plot traffic data\n    fig, ax = plt.subplots()\n    for vehicle_type in VEHICLE_TYPES:\n        ax.plot(df['Time'], df[vehicle_type], label=vehicle_type)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Vehicle Count')\n    ax.legend()\n\n    return csv_file_path, ax\n```"}
{"task_id": "BigCodeBench/594", "solution": "import csv\nimport os\nimport shutil\nfrom datetime import datetime, timedelta\nfrom random import randint\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Generate weather data\n    weather_data = []\n    current_time = datetime.now()\n    for i in range(hours):\n        time = current_time + timedelta(hours=i)\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS)-1)]\n        weather_data.append([time.strftime('%Y-%m-%d %H:%M:%S'), condition])\n\n    # Save weather data to CSV file\n    csv_file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow(['Time', 'Condition'])\n        writer.writerows(weather_data)\n\n    # Back up the CSV file to a backup directory\n    backup_dir = os.path.join(output_dir, 'backup')\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n    backup_file_path = os.path.join(backup_dir, 'weather_data.csv')\n    shutil.copy(csv_file_path, backup_file_path)\n\n    return csv_file_path", "raw_solution": "import csv\nimport os\nimport shutil\nfrom datetime import datetime, timedelta\nfrom random import randint\n\n# Constants\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Generate weather data\n    weather_data = []\n    current_time = datetime.now()\n    for i in range(hours):\n        time = current_time + timedelta(hours=i)\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS)-1)]\n        weather_data.append([time.strftime('%Y-%m-%d %H:%M:%S'), condition])\n\n    # Save weather data to CSV file\n    csv_file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow(['Time', 'Condition'])\n        writer.writerows(weather_data)\n\n    # Back up the CSV file to a backup directory\n    backup_dir = os.path.join(output_dir, 'backup')\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n    backup_file_path = os.path.join(backup_dir, 'weather_data.csv')\n    shutil.copy(csv_file_path, backup_file_path)\n\n    return csv_file_path\n```"}
{"task_id": "BigCodeBench/618", "solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties):\n    # Generate random data\n    data = {\n        'Team': [TEAMS[randint(0, len(TEAMS) - 1)] for _ in range(goals + penalties)],\n        'Goals': [randint(0, 5) for _ in range(goals)],\n        'Penalty Cost': [randint(1, 3) * PENALTY_COST for _ in range(penalties)]\n    }\n    df = pd.DataFrame(data)\n\n    # Calculate total cost\n    df['Total Cost'] = df['Goals'] * 1000 + df['Penalty Cost']\n\n    # Plotting\n    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n\n    # Plot for goals\n    sns.barplot(x='Team', y='Goals', data=df, ax=axes[0])\n    axes[0].set_title('Goals per Team')\n\n    # Plot for penalty costs\n    sns.barplot(x='Team', y='Penalty Cost', data=df, ax=axes[1])\n    axes[1].set_title('Penalty Costs per Team')\n\n    plt.tight_layout()\n    plt.show()\n\n    return df, axes", "raw_solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties):\n    # Generate random data\n    data = {\n        'Team': [TEAMS[randint(0, len(TEAMS) - 1)] for _ in range(goals + penalties)],\n        'Goals': [randint(0, 5) for _ in range(goals)],\n        'Penalty Cost': [randint(1, 3) * PENALTY_COST for _ in range(penalties)]\n    }\n    df = pd.DataFrame(data)\n\n    # Calculate total cost\n    df['Total Cost'] = df['Goals'] * 1000 + df['Penalty Cost']\n\n    # Plotting\n    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n\n    # Plot for goals\n    sns.barplot(x='Team', y='Goals', data=df, ax=axes[0])\n    axes[0].set_title('Goals per Team')\n\n    # Plot for penalty costs\n    sns.barplot(x='Team', y='Penalty Cost', data=df, ax=axes[1])\n    axes[1].set_title('Penalty Costs per Team')\n\n    plt.tight_layout()\n    plt.show()\n\n    return df, axes\n```"}
{"task_id": "BigCodeBench/636", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(rows):\n    # Generate DataFrame with random integer values\n    df = pd.DataFrame(np.random.randint(0, 10, size=(rows, len(COLUMNS))), columns=COLUMNS)\n\n    # Count non-zero values in each column\n    non_zero_counts = df.ne(0).sum()\n\n    # Create bar plot\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Column')\n    ax.set_ylabel('Non-zero values')\n    ax.set_title('Count of non-zero values in each column')\n\n    return df, ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(rows):\n    # Generate DataFrame with random integer values\n    df = pd.DataFrame(np.random.randint(0, 10, size=(rows, len(COLUMNS))), columns=COLUMNS)\n\n    # Count non-zero values in each column\n    non_zero_counts = df.ne(0).sum()\n\n    # Create bar plot\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Column')\n    ax.set_ylabel('Non-zero values')\n    ax.set_title('Count of non-zero values in each column')\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/637", "solution": "from random import sample\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\ndef task_func(num_students):\n    np.random.seed(0)\n    courses = ['Math', 'English', 'Science', 'History', 'Art']\n    grades = np.random.randint(1, 101, (num_students, len(courses)))\n    df = pd.DataFrame(grades, columns=courses)\n\n    df['Average'] = df.mean(axis=1)\n    df['Passing'] = df['Average'].apply(lambda x: 1 if x >= 60 else 0)\n\n    avg_pass_counts = df.groupby(df.index)['Passing'].sum()\n    avg_grades = df.groupby(df.index)['Average'].mean()\n\n    fig, ax = plt.subplots()\n    ax.bar(courses, avg_grades, color='b', label='Average Grade')\n    ax.bar(courses, avg_pass_counts, color='g', label='Passing Grade Count')\n    ax.set_title('Course-wise Average and Passing Grade Counts')\n    ax.legend()\n\n    return df, ax", "raw_solution": "from random import sample\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndef task_func(num_students):\n    np.random.seed(0)\n    courses = ['Math', 'English', 'Science', 'History', 'Art']\n    grades = np.random.randint(1, 101, (num_students, len(courses)))\n    df = pd.DataFrame(grades, columns=courses)\n\n    df['Average'] = df.mean(axis=1)\n    df['Passing'] = df['Average'].apply(lambda x: 1 if x >= 60 else 0)\n\n    avg_pass_counts = df.groupby(df.index)['Passing'].sum()\n    avg_grades = df.groupby(df.index)['Average'].mean()\n\n    fig, ax = plt.subplots()\n    ax.bar(courses, avg_grades, color='b', label='Average Grade')\n    ax.bar(courses, avg_pass_counts, color='g', label='Passing Grade Count')\n    ax.set_title('Course-wise Average and Passing Grade Counts')\n    ax.legend()\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/654", "solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\ndef task_func(array, target_value):\n    # Filter the array based on the target value\n    filtered_array = array[array[:, 0] == target_value]\n\n    # Define the exponential decay function\n    def exponential_decay(t, a, b, c):\n        return a * np.exp(-b * t) + c\n\n    # Perform the curve fitting\n    popt, _ = optimize.curve_fit(exponential_decay, filtered_array[:, 0], filtered_array[:, 1])\n\n    # Create a new figure\n    fig, ax = plt.subplots()\n\n    # Plot the original data\n    ax.scatter(filtered_array[:, 0], filtered_array[:, 1], label='Data')\n\n    # Plot the fitted curve\n    x_fit = np.linspace(filtered_array[0, 0], filtered_array[-1, 0], 100)\n    y_fit = exponential_decay(x_fit, *popt)\n    ax.plot(x_fit, y_fit, label='Fit')\n\n    # Set the labels and title\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.set_title('Exponential Decay Fit')\n\n    # Add the legend\n    ax.legend()\n\n    # Return the optimized parameters and the Axes object\n    return popt, ax", "raw_solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\n\ndef task_func(array, target_value):\n    # Filter the array based on the target value\n    filtered_array = array[array[:, 0] == target_value]\n\n    # Define the exponential decay function\n    def exponential_decay(t, a, b, c):\n        return a * np.exp(-b * t) + c\n\n    # Perform the curve fitting\n    popt, _ = optimize.curve_fit(exponential_decay, filtered_array[:, 0], filtered_array[:, 1])\n\n    # Create a new figure\n    fig, ax = plt.subplots()\n\n    # Plot the original data\n    ax.scatter(filtered_array[:, 0], filtered_array[:, 1], label='Data')\n\n    # Plot the fitted curve\n    x_fit = np.linspace(filtered_array[0, 0], filtered_array[-1, 0], 100)\n    y_fit = exponential_decay(x_fit, *popt)\n    ax.plot(x_fit, y_fit, label='Fit')\n\n    # Set the labels and title\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.set_title('Exponential Decay Fit')\n\n    # Add the legend\n    ax.legend()\n\n    # Return the optimized parameters and the Axes object\n    return popt, ax\n```"}
{"task_id": "BigCodeBench/655", "solution": "import re\nimport nltk\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer", "raw_solution": "import re\nimport nltk\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# Ensure nltk's stopwords are downloaded\nnltk.download('stopwords')\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef topic_extraction(texts, num_topics):\n    # Preprocess the texts\n    texts = [ALPHANUMERIC.sub(' ', text.lower()) for text in texts]\n    texts = [' '.join([word for word in text.split() if word not in STOPWORDS]) for text in texts]\n    # Vectorize the texts\n    vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000, stop_words='english')\n    tfidf = vectorizer.fit_transform(texts)\n    # Apply NMF\n    nmf = NMF(n_components=num_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n    # Extract the topics\n    feature_names = vectorizer.get_feature_names_out()\n    topics = []\n    for topic_idx, topic in enumerate(nmf.components_):\n        top_features = topic.argsort()[:-num_topics - 1:-1]\n        topics.append([feature_names[i] for i in top_features])\n    return topics\n```"}
{"task_id": "BigCodeBench/657", "solution": "import re\nimport nltk\nfrom gensim.models import Word2Vec\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n    if stopwords is None:\n        stopwords = nltk.corpus.stopwords.words('english')\n    texts = [ALPHANUMERIC.sub(' ', text).lower().split() for text in texts]\n    texts = [[word for word in text if word not in stopwords] for text in texts]\n    model = Word2Vec(texts, min_count=1)\n    return model", "raw_solution": "import re\nimport nltk\nfrom gensim.models import Word2Vec\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n    if stopwords is None:\n        stopwords = nltk.corpus.stopwords.words('english')\n    texts = [ALPHANUMERIC.sub(' ', text).lower().split() for text in texts]\n    texts = [[word for word in text if word not in stopwords] for text in texts]\n    model = Word2Vec(texts, min_count=1)\n    return model\n```"}
{"task_id": "BigCodeBench/678", "solution": "import pandas as pd\nimport json\nimport os\nimport shutil\ndef task_func(path):\n    # Initialize an empty list to store the dataframes\n    dfs = []\n\n    # Get a list of all json files in the directory\n    json_files = [f for f in os.listdir(path) if f.endswith('.json')]\n\n    # Sort the list of files alphabetically\n    json_files.sort()\n\n    # Process each json file\n    for file in json_files:\n        # Read the json file into a dataframe\n        df = pd.read_json(os.path.join(path, file))\n\n        # Add a \"Source\" column to the dataframe\n        df['Source'] = file\n\n        # Append the dataframe to the list\n        dfs.append(df)\n\n        # Move the json file to the \"processed\" subdirectory\n        shutil.move(os.path.join(path, file), os.path.join(path, 'processed', file))\n\n    # Concatenate all dataframes in the list into one dataframe\n    df = pd.concat(dfs, ignore_index=True)\n\n    return df", "raw_solution": "import pandas as pd\nimport json\nimport os\nimport shutil\n\ndef task_func(path):\n    # Initialize an empty list to store the dataframes\n    dfs = []\n\n    # Get a list of all json files in the directory\n    json_files = [f for f in os.listdir(path) if f.endswith('.json')]\n\n    # Sort the list of files alphabetically\n    json_files.sort()\n\n    # Process each json file\n    for file in json_files:\n        # Read the json file into a dataframe\n        df = pd.read_json(os.path.join(path, file))\n\n        # Add a \"Source\" column to the dataframe\n        df['Source'] = file\n\n        # Append the dataframe to the list\n        dfs.append(df)\n\n        # Move the json file to the \"processed\" subdirectory\n        shutil.move(os.path.join(path, file), os.path.join(path, 'processed', file))\n\n    # Concatenate all dataframes in the list into one dataframe\n    df = pd.concat(dfs, ignore_index=True)\n\n    return df\n```"}
{"task_id": "BigCodeBench/720", "solution": "import os\nimport csv\nimport random\nfrom datetime import datetime\ndef task_func():\n    file_path = \"task_func_data/Output.txt\"\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Date\", \"Temperature\", \"Humidity\"])\n        for i in range(10):\n            date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n            temperature = random.uniform(20, 30)\n            humidity = random.uniform(40, 60)\n            writer.writerow([date, temperature, humidity])\n    os.remove(file_path)\n    return file_path", "raw_solution": "import os\nimport csv\nimport random\nfrom datetime import datetime\n\ndef task_func():\n    file_path = \"task_func_data/Output.txt\"\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Date\", \"Temperature\", \"Humidity\"])\n        for i in range(10):\n            date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n            temperature = random.uniform(20, 30)\n            humidity = random.uniform(40, 60)\n            writer.writerow([date, temperature, humidity])\n    os.remove(file_path)\n    return file_path\n```"}
{"task_id": "BigCodeBench/723", "solution": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n    # Open the URL\n    response = urllib.request.urlopen(url)\n    # Parse the HTML content\n    soup = BeautifulSoup(response, 'html.parser')\n    # Find the table\n    table = soup.find('table')\n    # Find the rows in the table\n    rows = table.find_all('tr')\n    # Open the CSV file\n    with open(CSV_FILE_PATH, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        # Write the header row\n        writer.writerow([header.text for header in rows[0].find_all('th')])\n        # Write the data rows\n        for row in rows[1:]:\n            writer.writerow([cell.text for cell in row.find_all('td')])\n    return CSV_FILE_PATH", "raw_solution": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n    # Open the URL\n    response = urllib.request.urlopen(url)\n    # Parse the HTML content\n    soup = BeautifulSoup(response, 'html.parser')\n    # Find the table\n    table = soup.find('table')\n    # Find the rows in the table\n    rows = table.find_all('tr')\n    # Open the CSV file\n    with open(CSV_FILE_PATH, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        # Write the header row\n        writer.writerow([header.text for header in rows[0].find_all('th')])\n        # Write the data rows\n        for row in rows[1:]:\n            writer.writerow([cell.text for cell in row.find_all('td')])\n    return CSV_FILE_PATH\n```"}
{"task_id": "BigCodeBench/752", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data must be a pandas DataFrame\")\n    if data.empty:\n        raise ValueError(\"Data cannot be empty\")\n    if target_column not in data.columns:\n        raise ValueError(\"Target column is not a column of data\")\n    if not all(data.dtypes == np.float64):\n        raise ValueError(\"Data must contain only numeric values\")\n    if not isinstance(random_state, int):\n        raise ValueError(\"Random state must be an integer\")\n    if not 0 <= test_size <= 1:\n        raise ValueError(\"Test size must be between 0 and 1\")\n\n    X = data.drop(columns=[target_column])\n    y = data[target_column]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    return model.score(X_test, y_test)", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data must be a pandas DataFrame\")\n    if data.empty:\n        raise ValueError(\"Data cannot be empty\")\n    if target_column not in data.columns:\n        raise ValueError(\"Target column is not a column of data\")\n    if not all(data.dtypes == np.float64):\n        raise ValueError(\"Data must contain only numeric values\")\n    if not isinstance(random_state, int):\n        raise ValueError(\"Random state must be an integer\")\n    if not 0 <= test_size <= 1:\n        raise ValueError(\"Test size must be between 0 and 1\")\n\n    X = data.drop(columns=[target_column])\n    y = data[target_column]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    return model.score(X_test, y_test)\n```"}
{"task_id": "BigCodeBench/760", "solution": "import pandas as pd\nimport numpy as np\nimport codecs\nimport re\nimport datetime\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    np.random.seed(rng_seed)\n    names = np.random.choice(latin_names + other_names, size=100)\n    birth_dates = pd.date_range(start=str(start_year)+'-01-01', end=str(end_year)+'-12-31', periods=100)\n    emails = [f\"{name}{birth_date.year}@{email_domain}\" for name, birth_date in zip(names, birth_dates)]\n    df = pd.DataFrame({'ID': np.arange(1, 101), 'Name': names, 'Date of Birth': birth_dates, 'Email': emails})\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport codecs\nimport re\nimport datetime\n\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    np.random.seed(rng_seed)\n    names = np.random.choice(latin_names + other_names, size=100)\n    birth_dates = pd.date_range(start=str(start_year)+'-01-01', end=str(end_year)+'-12-31', periods=100)\n    emails = [f\"{name}{birth_date.year}@{email_domain}\" for name, birth_date in zip(names, birth_dates)]\n    df = pd.DataFrame({'ID': np.arange(1, 101), 'Name': names, 'Date of Birth': birth_dates, 'Email': emails})\n    return df\n```"}
{"task_id": "BigCodeBench/763", "solution": "import numpy as np\nfrom collections import defaultdict\nimport json\nimport csv\ndef task_func(input_file, output_file):\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    field_dict = defaultdict(list)\n    for item in data:\n        for key, value in item.items():\n            field_dict[key].append(value)\n\n    result = {}\n    for key, values in field_dict.items():\n        mean = np.mean(values)\n        median = np.median(values)\n        result[key] = {'mean': mean, 'median': median}\n\n    with open(output_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Field', 'Mean', 'Median'])\n        for key, stats in result.items():\n            writer.writerow([key, stats['mean'], stats['median']])\n\n    return result", "raw_solution": "import numpy as np\nfrom collections import defaultdict\nimport json\nimport csv\n\ndef task_func(input_file, output_file):\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    field_dict = defaultdict(list)\n    for item in data:\n        for key, value in item.items():\n            field_dict[key].append(value)\n\n    result = {}\n    for key, values in field_dict.items():\n        mean = np.mean(values)\n        median = np.median(values)\n        result[key] = {'mean': mean, 'median': median}\n\n    with open(output_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Field', 'Mean', 'Median'])\n        for key, stats in result.items():\n            writer.writerow([key, stats['mean'], stats['median']])\n\n    return result\n```"}
{"task_id": "BigCodeBench/765", "solution": "import os\nfrom pathlib import Path\nimport shutil\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    copied_files = []\n    for file_path in kwargs.values():\n        if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n            shutil.copy2(file_path, target_dir)\n            copied_files.append(os.path.join(target_dir, os.path.basename(file_path)))\n    return copied_files", "raw_solution": "import os\nfrom pathlib import Path\nimport shutil\n\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    copied_files = []\n    for file_path in kwargs.values():\n        if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n            shutil.copy2(file_path, target_dir)\n            copied_files.append(os.path.join(target_dir, os.path.basename(file_path)))\n    return copied_files\n```"}
{"task_id": "BigCodeBench/771", "solution": "import re\nimport os\nfrom pathlib import Path\nimport csv\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n    new_files = []\n    for file in os.listdir(directory):\n        if re.match(pattern, file):\n            filename = re.match(pattern, file).group(1)\n            new_file = filename + \"-new.csv\"\n            new_files.append(new_file)\n            with open(os.path.join(directory, file), 'r') as f_in, open(os.path.join(directory, new_file), 'w', newline='') as f_out:\n                reader = csv.reader(f_in)\n                writer = csv.writer(f_out)\n                for row in reader:\n                    writer.writerow(row)\n    return new_files", "raw_solution": "import re\nimport os\nfrom pathlib import Path\nimport csv\n\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n    new_files = []\n    for file in os.listdir(directory):\n        if re.match(pattern, file):\n            filename = re.match(pattern, file).group(1)\n            new_file = filename + \"-new.csv\"\n            new_files.append(new_file)\n            with open(os.path.join(directory, file), 'r') as f_in, open(os.path.join(directory, new_file), 'w', newline='') as f_out:\n                reader = csv.reader(f_in)\n                writer = csv.writer(f_out)\n                for row in reader:\n                    writer.writerow(row)\n    return new_files\n```"}
{"task_id": "BigCodeBench/777", "solution": "import re\nimport os\nimport zipfile\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    extracted_dirs = []\n    for filename in os.listdir(directory):\n        match = re.match(pattern, filename)\n        if match:\n            prefix = match.group(1)\n            if not os.path.exists(os.path.join(directory, prefix)):\n                os.makedirs(os.path.join(directory, prefix))\n            with zipfile.ZipFile(os.path.join(directory, filename), 'r') as zip_ref:\n                zip_ref.extractall(os.path.join(directory, prefix))\n            extracted_dirs.append(os.path.join(directory, prefix))\n    return extracted_dirs", "raw_solution": "import re\nimport os\nimport zipfile\n\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    extracted_dirs = []\n    for filename in os.listdir(directory):\n        match = re.match(pattern, filename)\n        if match:\n            prefix = match.group(1)\n            if not os.path.exists(os.path.join(directory, prefix)):\n                os.makedirs(os.path.join(directory, prefix))\n            with zipfile.ZipFile(os.path.join(directory, filename), 'r') as zip_ref:\n                zip_ref.extractall(os.path.join(directory, prefix))\n            extracted_dirs.append(os.path.join(directory, prefix))\n    return extracted_dirs\n```"}
{"task_id": "BigCodeBench/785", "solution": "import subprocess\nimport os\nimport glob\nARCHIVE_DIR = '/tmp/archive'\ndef task_func(pattern):\n    # Create archive directory if it doesn't exist\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n\n    # Archive files\n    archive_file = os.path.join(ARCHIVE_DIR, f'archive_{pattern}.tar.gz')\n    subprocess.run(['tar', '-czvf', archive_file, pattern])\n\n    # Delete original files\n    files = glob.glob(pattern)\n    for file in files:\n        os.remove(file)\n\n    return archive_file", "raw_solution": "import subprocess\nimport os\nimport glob\n# Constants\nARCHIVE_DIR = '/tmp/archive'\ndef task_func(pattern):\n    # Create archive directory if it doesn't exist\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n\n    # Archive files\n    archive_file = os.path.join(ARCHIVE_DIR, f'archive_{pattern}.tar.gz')\n    subprocess.run(['tar', '-czvf', archive_file, pattern])\n\n    # Delete original files\n    files = glob.glob(pattern)\n    for file in files:\n        os.remove(file)\n\n    return archive_file\n```"}
{"task_id": "BigCodeBench/800", "solution": "import csv\nimport os\nfrom collections import Counter\nCSV_FILE_PATH = 'match_data.csv'\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    if not os.path.exists(csv_file_path):\n        return Counter({'goals': 0, 'penalties': 0})\n\n    with open(csv_file_path, 'r') as file:\n        reader = csv.reader(file)\n        next(reader)  # Skip the header\n        total_goals = 0\n        total_penalties = 0\n        for row in reader:\n            total_goals += int(row[1])\n            total_penalties += int(row[2])\n\n    total_goals += goals\n    total_penalties += penalties\n\n    return Counter({'goals': total_goals, 'penalties': total_penalties})", "raw_solution": "import csv\nimport os\nfrom collections import Counter\n\n# Constants\nCSV_FILE_PATH = 'match_data.csv'\n\ndef create_test_csv(filename, content):\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerows(content)\n\n# Example usage in a test setup:\ndef setup_csv():\n    content = [\n        ['team', 'goals', 'penalties'],\n        ['Team A', '2', '1'],\n        ['Team B', '1', '2'],\n        ['Team C', '3', '0']\n    ]\n    create_test_csv('test_data/test_case_2.csv', content)\n\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    if not os.path.exists(csv_file_path):\n        return Counter({'goals': 0, 'penalties': 0})\n\n    with open(csv_file_path, 'r') as file:\n        reader = csv.reader(file)\n        next(reader)  # Skip the header\n        total_goals = 0\n        total_penalties = 0\n        for row in reader:\n            total_goals += int(row[1])\n            total_penalties += int(row[2])\n\n    total_goals += goals\n    total_penalties += penalties\n\n    return Counter({'goals': total_goals, 'penalties': total_penalties})\n```"}
{"task_id": "BigCodeBench/826", "solution": "import re\nimport os\nimport shutil\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    moved_files_count = 0\n    for filename in os.listdir(source_dir):\n        if re.match(file_pattern, filename):\n            shutil.move(os.path.join(source_dir, filename), target_dir)\n            moved_files_count += 1\n    return moved_files_count", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    moved_files_count = 0\n    for filename in os.listdir(source_dir):\n        if re.match(file_pattern, filename):\n            shutil.move(os.path.join(source_dir, filename), target_dir)\n            moved_files_count += 1\n    return moved_files_count\n```"}
{"task_id": "BigCodeBench/845", "solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom Levenshtein import ratio\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(text1, text2):\n    # Clean the texts\n    text1 = ALPHANUMERIC.sub(' ', text1).lower()\n    text2 = ALPHANUMERIC.sub(' ', text2).lower()\n\n    # Calculate term frequency\n    term_freq1 = Counter(text1.split())\n    term_freq2 = Counter(text2.split())\n\n    # Calculate cosine similarity\n    cosine_similarity = np.dot(list(term_freq1.values()), list(term_freq2.values())) / (np.linalg.norm(list(term_freq1.values())) * np.linalg.norm(list(term_freq2.values())))\n\n    # Calculate Levenshtein ratio\n    levenshtein_ratio = ratio(text1, text2)\n\n    return (cosine_similarity, levenshtein_ratio)", "raw_solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom Levenshtein import ratio\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(text1, text2):\n    # Clean the texts\n    text1 = ALPHANUMERIC.sub(' ', text1).lower()\n    text2 = ALPHANUMERIC.sub(' ', text2).lower()\n\n    # Calculate term frequency\n    term_freq1 = Counter(text1.split())\n    term_freq2 = Counter(text2.split())\n\n    # Calculate cosine similarity\n    cosine_similarity = np.dot(list(term_freq1.values()), list(term_freq2.values())) / (np.linalg.norm(list(term_freq1.values())) * np.linalg.norm(list(term_freq2.values())))\n\n    # Calculate Levenshtein ratio\n    levenshtein_ratio = ratio(text1, text2)\n\n    return (cosine_similarity, levenshtein_ratio)\n```"}
{"task_id": "BigCodeBench/854", "solution": "from functools import reduce\nfrom itertools import permutations\nimport math\ndef task_func(numbers):\n    if not isinstance(numbers, list):\n        raise TypeError(\"Input must be a list of integers\")\n    if not all(isinstance(i, int) for i in numbers):\n        raise TypeError(\"Input must be a list of integers\")\n    if not all(i >= 0 for i in numbers):\n        raise ValueError(\"Input numbers must be non-negative\")\n    if not numbers:\n        return ([], [])\n    fac = [math.factorial(i) for i in numbers]\n    perm = [i for i in permutations(numbers)]\n    return (fac, perm)", "raw_solution": "from functools import reduce\nfrom itertools import permutations\nimport math\n\ndef task_func(numbers):\n    if not isinstance(numbers, list):\n        raise TypeError(\"Input must be a list of integers\")\n    if not all(isinstance(i, int) for i in numbers):\n        raise TypeError(\"Input must be a list of integers\")\n    if not all(i >= 0 for i in numbers):\n        raise ValueError(\"Input numbers must be non-negative\")\n    if not numbers:\n        return ([], [])\n    fac = [math.factorial(i) for i in numbers]\n    perm = [i for i in permutations(numbers)]\n    return (fac, perm)\n```"}
{"task_id": "BigCodeBench/857", "solution": "import warnings\nimport os\nimport glob\nimport shutil\nimport time\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    transferred_files = []\n    for ext in EXTENSIONS:\n        files = glob.glob(os.path.join(SOURCE_DIR, f'*.{ext}'))\n        for file in files:\n            try:\n                shutil.move(file, DEST_DIR)\n                transferred_files.append(os.path.basename(file))\n            except Exception as e:\n                warnings.warn(f\"Could not transfer file {file} due to {str(e)}\")\n    return transferred_files", "raw_solution": "import warnings\nimport os\nimport glob\nimport shutil\nimport time\n\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    transferred_files = []\n    for ext in EXTENSIONS:\n        files = glob.glob(os.path.join(SOURCE_DIR, f'*.{ext}'))\n        for file in files:\n            try:\n                shutil.move(file, DEST_DIR)\n                transferred_files.append(os.path.basename(file))\n            except Exception as e:\n                warnings.warn(f\"Could not transfer file {file} due to {str(e)}\")\n    return transferred_files\n```"}
{"task_id": "BigCodeBench/865", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data):\n    df = pd.DataFrame(data, columns=['Item', 'Count', 'Weight'])\n    df['Normalized Count'] = zscore(df['Count'])\n    df['Normalized Weight'] = MinMaxScaler().fit_transform(df[['Weight']])\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=['Item', 'Count', 'Weight'])\n    df['Normalized Count'] = zscore(df['Count'])\n    df['Normalized Weight'] = MinMaxScaler().fit_transform(df[['Weight']])\n    return df\n```"}
{"task_id": "BigCodeBench/870", "solution": "import pandas as pd\nimport numpy as np\nimport itertools\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    if not data_list:\n        return pd.DataFrame(columns=['Mean Value'])\n\n    # Extract numerical values from tuples\n    num_values = [tuple(filter(lambda x: isinstance(x, (int, float)), t)) for t in data_list]\n\n    # Calculate mean for each position\n    means = [np.mean(list(itertools.chain(*[t[i] for t in num_values if i < len(t)]))) for i in range(max(map(len, num_values)))]\n\n    # Create DataFrame\n    df = pd.DataFrame(means, columns=['Mean Value'], index=['Position ' + str(i) for i in range(len(means))])\n\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport itertools\n\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    if not data_list:\n        return pd.DataFrame(columns=['Mean Value'])\n\n    # Extract numerical values from tuples\n    num_values = [tuple(filter(lambda x: isinstance(x, (int, float)), t)) for t in data_list]\n\n    # Calculate mean for each position\n    means = [np.mean(list(itertools.chain(*[t[i] for t in num_values if i < len(t)]))) for i in range(max(map(len, num_values)))]\n\n    # Create DataFrame\n    df = pd.DataFrame(means, columns=['Mean Value'], index=['Position ' + str(i) for i in range(len(means))])\n\n    return df\n```"}
{"task_id": "BigCodeBench/879", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\ndef task_func(data, col1, col2):\n    if data.empty:\n        raise ValueError(\"Data is empty\")\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError(\"One or both of the columns are not in the data\")\n    if data[col1].nunique() < 2 or data[col2].nunique() < 2:\n        raise ValueError(\"One or both of the columns do not have multiple categories\")\n    if data[col1].value_counts().min() < 5 or data[col2].value_counts().min() < 5:\n        raise ValueError(\"Some categories have less than 5 observations\")\n    if not np.issubdtype(data[col1].dtype, np.str) or not np.issubdtype(data[col2].dtype, np.str):\n        raise TypeError(\"One or both of the columns contain non-categorical data\")\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    return p", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\n\ndef task_func(data, col1, col2):\n    if data.empty:\n        raise ValueError(\"Data is empty\")\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError(\"One or both of the columns are not in the data\")\n    if data[col1].nunique() < 2 or data[col2].nunique() < 2:\n        raise ValueError(\"One or both of the columns do not have multiple categories\")\n    if data[col1].value_counts().min() < 5 or data[col2].value_counts().min() < 5:\n        raise ValueError(\"Some categories have less than 5 observations\")\n    if not np.issubdtype(data[col1].dtype, np.str) or not np.issubdtype(data[col2].dtype, np.str):\n        raise TypeError(\"One or both of the columns contain non-categorical data\")\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    return p"}
{"task_id": "BigCodeBench/897", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nNUMBERS = list(range(1, 7))\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    results = [random.randint(1, 6) for _ in range(rolls)]\n    freq_array = np.array([results.count(i) for i in NUMBERS])\n    fig, ax = plt.subplots()\n    ax.bar(NUMBERS, freq_array)\n    ax.set_title(\"Histogram of Dice Rolls\")\n    ax.set_xlabel(\"Dice Value\")\n    ax.set_ylabel(\"Frequency\")\n    return freq_array, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    results = [random.randint(1, 6) for _ in range(rolls)]\n    freq_array = np.array([results.count(i) for i in NUMBERS])\n    fig, ax = plt.subplots()\n    ax.bar(NUMBERS, freq_array)\n    ax.set_title(\"Histogram of Dice Rolls\")\n    ax.set_xlabel(\"Dice Value\")\n    ax.set_ylabel(\"Frequency\")\n    return freq_array, ax\n```"}
{"task_id": "BigCodeBench/906", "solution": "import zipfile\nimport os\nimport re\nimport shutil\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    # Create the archive file\n    archive_path = os.path.join(target_dir, archive_name)\n    with zipfile.ZipFile(archive_path, 'w') as archive:\n        # Iterate over all files in the source directory\n        for root, dirs, files in os.walk(source_dir):\n            for file in files:\n                # Check if the file is processed\n                if re.search(r'_processed$', file):\n                    # Get the full path to the file\n                    file_path = os.path.join(root, file)\n                    # Add the file to the archive\n                    archive.write(file_path, arcname=file)\n                    # Move the file to the target directory\n                    shutil.move(file_path, target_dir)\n    return archive_path", "raw_solution": "import zipfile\nimport os\nimport re\nimport shutil\n\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    # Create the archive file\n    archive_path = os.path.join(target_dir, archive_name)\n    with zipfile.ZipFile(archive_path, 'w') as archive:\n        # Iterate over all files in the source directory\n        for root, dirs, files in os.walk(source_dir):\n            for file in files:\n                # Check if the file is processed\n                if re.search(r'_processed$', file):\n                    # Get the full path to the file\n                    file_path = os.path.join(root, file)\n                    # Add the file to the archive\n                    archive.write(file_path, arcname=file)\n                    # Move the file to the target directory\n                    shutil.move(file_path, target_dir)\n    return archive_path\n```"}
{"task_id": "BigCodeBench/914", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    df = df.sort_values('timestamp')\n    df.set_index('timestamp', inplace=True)\n    df = df.resample('1D').mean()\n    df.dropna(inplace=True)\n    X = np.array(range(len(df))).reshape(-1, 1)\n    Y = df['close'].values.reshape(-1, 1)\n    model = LinearRegression()\n    model.fit(X, Y)\n    future_timestamps = pd.date_range(start=df.index[-1], periods=7, freq='1D')\n    future_X = np.array(range(len(df), len(df)+7)).reshape(-1, 1)\n    future_Y = model.predict(future_X)\n    plt.figure(figsize=(10, 5))\n    plt.plot(df.index, df['close'], label='Actual')\n    plt.plot(future_timestamps, future_Y, label='Predicted')\n    plt.xlabel('Date')\n    plt.ylabel('Price')\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    return future_Y.flatten().tolist(), plt.gca()", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    df = df.sort_values('timestamp')\n    df.set_index('timestamp', inplace=True)\n    df = df.resample('1D').mean()\n    df.dropna(inplace=True)\n    X = np.array(range(len(df))).reshape(-1, 1)\n    Y = df['close'].values.reshape(-1, 1)\n    model = LinearRegression()\n    model.fit(X, Y)\n    future_timestamps = pd.date_range(start=df.index[-1], periods=7, freq='1D')\n    future_X = np.array(range(len(df), len(df)+7)).reshape(-1, 1)\n    future_Y = model.predict(future_X)\n    plt.figure(figsize=(10, 5))\n    plt.plot(df.index, df['close'], label='Actual')\n    plt.plot(future_timestamps, future_Y, label='Predicted')\n    plt.xlabel('Date')\n    plt.ylabel('Price')\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    return future_Y.flatten().tolist(), plt.gca()\n```"}
{"task_id": "BigCodeBench/915", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\ndef task_func(df, z_threshold=2):\n    df['z_score'] = zscore(df['closing_price'])\n    outliers = df[np.abs(df['z_score']) > z_threshold]\n    plot = df['closing_price'].plot(kind='line', title='Outliers in Closing Prices')\n    plot.set_xlabel('Index')\n    plot.set_ylabel('Closing Price')\n    plt.scatter(outliers.index, outliers['closing_price'], color='red')\n    return outliers, plot", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\n\ndef task_func(df, z_threshold=2):\n    df['z_score'] = zscore(df['closing_price'])\n    outliers = df[np.abs(df['z_score']) > z_threshold]\n    plot = df['closing_price'].plot(kind='line', title='Outliers in Closing Prices')\n    plot.set_xlabel('Index')\n    plot.set_ylabel('Closing Price')\n    plt.scatter(outliers.index, outliers['closing_price'], color='red')\n    return outliers, plot\n```"}
{"task_id": "BigCodeBench/916", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df: pd.DataFrame) -> tuple:\n    fig, axes = plt.subplots(2, figsize=(10, 10))\n    sns.boxplot(data=df['Close'], ax=axes[0])\n    axes[0].set_title('Box Plot of Closing Prices')\n    sns.histplot(data=df['Close'], ax=axes[1])\n    axes[1].set_title('Histogram of Closing Prices')\n    plt.tight_layout()\n    return axes[0], axes[1]", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df: pd.DataFrame) -> tuple:\n    fig, axes = plt.subplots(2, figsize=(10, 10))\n    sns.boxplot(data=df['Close'], ax=axes[0])\n    axes[0].set_title('Box Plot of Closing Prices')\n    sns.histplot(data=df['Close'], ax=axes[1])\n    axes[1].set_title('Histogram of Closing Prices')\n    plt.tight_layout()\n    return axes[0], axes[1]\n```"}
{"task_id": "BigCodeBench/917", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    model = ARIMA(df['Close'], order=(5,1,0))\n    model_fit = model.fit(disp=0)\n    forecast = model_fit.forecast(steps=7)\n\n    fig, ax = plt.subplots(figsize=(12, 6))\n    ax.plot(df['Date'], df['Close'], label='Actual')\n    ax.plot(pd.date_range(start=df['Date'].iloc[-1], periods=8)[1:], forecast, label='Forecast')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Share Price')\n    ax.set_title('ARIMA Model Forecast')\n    ax.legend()\n\n    return forecast.tolist(), ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\n\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    model = ARIMA(df['Close'], order=(5,1,0))\n    model_fit = model.fit(disp=0)\n    forecast = model_fit.forecast(steps=7)\n\n    fig, ax = plt.subplots(figsize=(12, 6))\n    ax.plot(df['Date'], df['Close'], label='Actual')\n    ax.plot(pd.date_range(start=df['Date'].iloc[-1], periods=8)[1:], forecast, label='Forecast')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Share Price')\n    ax.set_title('ARIMA Model Forecast')\n    ax.legend()\n\n    return forecast.tolist(), ax\n```"}
{"task_id": "BigCodeBench/928", "solution": "from collections import Counter\nimport itertools\nimport string\ndef task_func(word: str) -> dict:\n    alphabet = string.ascii_lowercase\n    combinations = [''.join(x) for x in itertools.product(alphabet, repeat=2)]\n    word_combinations = [word[i:i+2] for i in range(len(word)-1)]\n    word_counter = Counter(word_combinations)\n    result = {comb: word_counter[comb] for comb in combinations}\n    return result", "raw_solution": "from collections import Counter\nimport itertools\nimport string\ndef task_func(word: str) -> dict:\n    alphabet = string.ascii_lowercase\n    combinations = [''.join(x) for x in itertools.product(alphabet, repeat=2)]\n    word_combinations = [word[i:i+2] for i in range(len(word)-1)]\n    word_counter = Counter(word_combinations)\n    result = {comb: word_counter[comb] for comb in combinations}\n    return result\n```"}
{"task_id": "BigCodeBench/942", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Create a date range\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n\n    # Create a DataFrame with the date range and categories\n    df = pd.DataFrame({'Date': date_range, 'Category': np.random.choice(categories, periods)})\n\n    # Generate random sales data\n    df['Sales'] = np.random.randint(100, 1000, periods)\n\n    # Group by 'Category' and 'Date' and sum the sales\n    df = df.groupby(['Category', 'Date']).sum().reset_index()\n\n    # Plot the sales data\n    ax = df.plot(x='Date', y='Sales', kind='bar', figsize=(10, 6))\n    ax.set_title('Sales Report by Category')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Create a date range\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n\n    # Create a DataFrame with the date range and categories\n    df = pd.DataFrame({'Date': date_range, 'Category': np.random.choice(categories, periods)})\n\n    # Generate random sales data\n    df['Sales'] = np.random.randint(100, 1000, periods)\n\n    # Group by 'Category' and 'Date' and sum the sales\n    df = df.groupby(['Category', 'Date']).sum().reset_index()\n\n    # Plot the sales data\n    ax = df.plot(x='Date', y='Sales', kind='bar', figsize=(10, 6))\n    ax.set_title('Sales Report by Category')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n\n    return df, ax\n```"}
{"task_id": "BigCodeBench/945", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    if sales_data is None:\n        sales_data = pd.date_range(start=start_date, periods=periods, freq=freq)\n    else:\n        sales_data = pd.to_datetime(sales_data)\n\n    # Generate sales data\n    np.random.seed(0)\n    sales = np.random.randint(100, 200, size=len(sales_data))\n\n    # Create a DataFrame\n    df = pd.DataFrame({'Date': sales_data, 'Sales': sales})\n    df.set_index('Date', inplace=True)\n\n    # Create a time series index\n    df.index = pd.to_datetime(df.index)\n\n    # Create a new column 'Time'\n    df['Time'] = range(1, len(df) + 1)\n\n    # Create a Linear Regression model\n    model = LinearRegression()\n\n    # Fit the model\n    model.fit(df[['Time']], df['Sales'])\n\n    # Generate future sales data\n    future_sales = model.predict(df[['Time']])\n\n    return future_sales", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    if sales_data is None:\n        sales_data = pd.date_range(start=start_date, periods=periods, freq=freq)\n    else:\n        sales_data = pd.to_datetime(sales_data)\n\n    # Generate sales data\n    np.random.seed(0)\n    sales = np.random.randint(100, 200, size=len(sales_data))\n\n    # Create a DataFrame\n    df = pd.DataFrame({'Date': sales_data, 'Sales': sales})\n    df.set_index('Date', inplace=True)\n\n    # Create a time series index\n    df.index = pd.to_datetime(df.index)\n\n    # Create a new column 'Time'\n    df['Time'] = range(1, len(df) + 1)\n\n    # Create a Linear Regression model\n    model = LinearRegression()\n\n    # Fit the model\n    model.fit(df[['Time']], df['Sales'])\n\n    # Generate future sales data\n    future_sales = model.predict(df[['Time']])\n\n    return future_sales\n```"}
{"task_id": "BigCodeBench/952", "solution": "import pandas as pd\nimport random\nfrom datetime import datetime\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks cannot be negative\")\n    if seed is not None:\n        random.seed(seed)\n    tasks = [task.replace(\" \", \"_\") for task in task_list]\n    random.shuffle(tasks)\n    tasks = tasks[:n_tasks]\n    assigned_tasks = []\n    for task in tasks:\n        assigned_to = random.choice(employees)\n        assigned_tasks.append({\n            \"Task Name\": task,\n            \"Assigned To\": assigned_to,\n            \"Due Date\": datetime.now().date(),\n        })\n    return pd.DataFrame(assigned_tasks)", "raw_solution": "import pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks cannot be negative\")\n    if seed is not None:\n        random.seed(seed)\n    tasks = [task.replace(\" \", \"_\") for task in task_list]\n    random.shuffle(tasks)\n    tasks = tasks[:n_tasks]\n    assigned_tasks = []\n    for task in tasks:\n        assigned_to = random.choice(employees)\n        assigned_tasks.append({\n            \"Task Name\": task,\n            \"Assigned To\": assigned_to,\n            \"Due Date\": datetime.now().date(),\n        })\n    return pd.DataFrame(assigned_tasks)\n```"}
{"task_id": "BigCodeBench/955", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter\ndef task_func(mystrings, text):\n    if not text:\n        raise ValueError(\"Input text is empty\")\n    words = re.findall(r'\\b\\w+\\b', text)\n    words = [word.lower() for word in words]\n    words = [word.replace(\" \", \"_\") for word in words]\n    word_counts = Counter(words)\n    unique_words = list(word_counts.keys())\n    frequencies = list(word_counts.values())\n    plt.figure(figsize=(10, 5))\n    plt.bar(unique_words, frequencies)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of each unique word')\n    plt.xticks(rotation=90)\n    plt.tight_layout()\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter\n\ndef task_func(mystrings, text):\n    if not text:\n        raise ValueError(\"Input text is empty\")\n    words = re.findall(r'\\b\\w+\\b', text)\n    words = [word.lower() for word in words]\n    words = [word.replace(\" \", \"_\") for word in words]\n    word_counts = Counter(words)\n    unique_words = list(word_counts.keys())\n    frequencies = list(word_counts.values())\n    plt.figure(figsize=(10, 5))\n    plt.bar(unique_words, frequencies)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of each unique word')\n    plt.xticks(rotation=90)\n    plt.tight_layout()\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/963", "solution": "import os\nimport glob\nfrom pathlib import Path\nimport zipfile\ndef task_func(source_directory, target_directory, zip_name):\n    valid_extensions = ['.txt', '.docx', '.xlsx', '.csv']\n    if not os.path.exists(source_directory):\n        raise OSError(\"Source directory does not exist.\")\n    zip_path = os.path.join(target_directory, zip_name + \".zip\")\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for ext in valid_extensions:\n            for file in glob.glob(os.path.join(source_directory, \"*\" + ext)):\n                zipf.write(file, arcname=os.path.basename(file))\n    return zip_path", "raw_solution": "import os\nimport glob\nfrom pathlib import Path\nimport zipfile\n\ndef task_func(source_directory, target_directory, zip_name):\n    valid_extensions = ['.txt', '.docx', '.xlsx', '.csv']\n    if not os.path.exists(source_directory):\n        raise OSError(\"Source directory does not exist.\")\n    zip_path = os.path.join(target_directory, zip_name + \".zip\")\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for ext in valid_extensions:\n            for file in glob.glob(os.path.join(source_directory, \"*\" + ext)):\n                zipf.write(file, arcname=os.path.basename(file))\n    return zip_path\n```"}
{"task_id": "BigCodeBench/964", "solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nimport docx\ndef task_func(source_directory: str, target_directory: str) -> int:\n    if not os.path.exists(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n\n    converted_count = 0\n    for filename in os.listdir(source_directory):\n        if filename.endswith(\".txt\"):\n            with open(os.path.join(source_directory, filename), 'r') as file:\n                text = file.read()\n                df = pd.DataFrame({'Text': [text]})\n                df.to_csv(os.path.join(target_directory, filename.replace(\".txt\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".docx\"):\n            doc = docx.Document(os.path.join(source_directory, filename))\n            text = ' '.join([p.text for p in doc.paragraphs])\n            df = pd.DataFrame({'Text': [text]})\n            df.to_csv(os.path.join(target_directory, filename.replace(\".docx\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".xlsx\"):\n            df = pd.read_excel(os.path.join(source_directory, filename))\n            df.to_csv(os.path.join(target_directory, filename.replace(\".xlsx\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".csv\"):\n            df = pd.read_csv(os.path.join(source_directory, filename))\n            df.to_csv(os.path.join(target_directory, filename), index=False)\n            converted_count += 1\n\n    return converted_count", "raw_solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nimport docx\n\ndef task_func(source_directory: str, target_directory: str) -> int:\n    if not os.path.exists(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n\n    converted_count = 0\n    for filename in os.listdir(source_directory):\n        if filename.endswith(\".txt\"):\n            with open(os.path.join(source_directory, filename), 'r') as file:\n                text = file.read()\n                df = pd.DataFrame({'Text': [text]})\n                df.to_csv(os.path.join(target_directory, filename.replace(\".txt\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".docx\"):\n            doc = docx.Document(os.path.join(source_directory, filename))\n            text = ' '.join([p.text for p in doc.paragraphs])\n            df = pd.DataFrame({'Text': [text]})\n            df.to_csv(os.path.join(target_directory, filename.replace(\".docx\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".xlsx\"):\n            df = pd.read_excel(os.path.join(source_directory, filename))\n            df.to_csv(os.path.join(target_directory, filename.replace(\".xlsx\", \".csv\")), index=False)\n            converted_count += 1\n        elif filename.endswith(\".csv\"):\n            df = pd.read_csv(os.path.join(source_directory, filename))\n            df.to_csv(os.path.join(target_directory, filename), index=False)\n            converted_count += 1\n\n    return converted_count\n```"}
{"task_id": "BigCodeBench/969", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if df.isnull().values.any():\n        raise ValueError(\"DataFrame contains NaN values\")\n    if not df.select_dtypes(include=[np.number]).empty:\n        raise TypeError(\"DataFrame contains non-numeric data types\")\n\n    scaler = MinMaxScaler()\n    df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    df_cumulative = df_normalized.cumsum()\n\n    return df_cumulative", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if df.isnull().values.any():\n        raise ValueError(\"DataFrame contains NaN values\")\n    if not df.select_dtypes(include=[np.number]).empty:\n        raise TypeError(\"DataFrame contains non-numeric data types\")\n\n    scaler = MinMaxScaler()\n    df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    df_cumulative = df_normalized.cumsum()\n\n    return df_cumulative\n```"}
{"task_id": "BigCodeBench/971", "solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\ndef task_func(directory_path: str):\n    if not os.path.exists(directory_path):\n        raise ValueError(\"Directory does not exist\")\n\n    result = []\n    for file in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, file)\n        if os.path.isfile(file_path):\n            file_size = os.path.getsize(file_path)\n            creation_time = os.path.getctime(file_path)\n            modification_time = os.path.getmtime(file_path)\n            result.append((file, file_size, datetime.fromtimestamp(creation_time, tz=timezone.utc).isoformat(), datetime.fromtimestamp(modification_time, tz=timezone.utc).isoformat()))\n\n    return result", "raw_solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\n\ndef task_func(directory_path: str):\n    if not os.path.exists(directory_path):\n        raise ValueError(\"Directory does not exist\")\n\n    result = []\n    for file in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, file)\n        if os.path.isfile(file_path):\n            file_size = os.path.getsize(file_path)\n            creation_time = os.path.getctime(file_path)\n            modification_time = os.path.getmtime(file_path)\n            result.append((file, file_size, datetime.fromtimestamp(creation_time, tz=timezone.utc).isoformat(), datetime.fromtimestamp(modification_time, tz=timezone.utc).isoformat()))\n\n    return result\n```"}
{"task_id": "BigCodeBench/985", "solution": "import pandas as pd\nimport json\nimport os\nimport math\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    try:\n        data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON data\")\n\n    if not data:\n        raise ValueError(\"Empty JSON data\")\n\n    report = []\n    for country, population in data.items():\n        if not isinstance(country, str):\n            raise ValueError(\"Non-string country names\")\n        if not isinstance(population, (int, float)) or population < 0:\n            raise ValueError(\"Non-numeric or negative populations\")\n        report.append({\"Country\": country, \"Population\": int(population)})\n\n    df = pd.DataFrame(report)\n    file_path = os.path.join(output_dir, file_name)\n    try:\n        df.to_csv(file_path, index=False)\n    except IOError:\n        raise IOError(\"Cannot write to the specified directory\")\n\n    return file_path, df", "raw_solution": "import pandas as pd\nimport json\nimport os\nimport math\n\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    try:\n        data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON data\")\n\n    if not data:\n        raise ValueError(\"Empty JSON data\")\n\n    report = []\n    for country, population in data.items():\n        if not isinstance(country, str):\n            raise ValueError(\"Non-string country names\")\n        if not isinstance(population, (int, float)) or population < 0:\n            raise ValueError(\"Non-numeric or negative populations\")\n        report.append({\"Country\": country, \"Population\": int(population)})\n\n    df = pd.DataFrame(report)\n    file_path = os.path.join(output_dir, file_name)\n    try:\n        df.to_csv(file_path, index=False)\n    except IOError:\n        raise IOError(\"Cannot write to the specified directory\")\n\n    return file_path, df\n```"}
{"task_id": "BigCodeBench/988", "solution": "import os\nimport re\nfrom pathlib import Path\ndef task_func(dir_path: str, predicates: list) -> dict:\n    if not predicates:\n        raise ValueError(\"No valid predicates provided\")\n    if not os.path.exists(dir_path) or not os.path.isdir(dir_path):\n        raise FileNotFoundError(\"Specified directory does not exist or is not a directory\")\n    result = {}\n    for item in os.listdir(dir_path):\n        item_path = os.path.join(dir_path, item)\n        if os.path.isfile(item_path):\n            for predicate in predicates:\n                if re.search(predicate, item):\n                    result[item] = True\n                    break\n        elif os.path.isdir(item_path):\n            for predicate in predicates:\n                if re.search(predicate, item):\n                    result[item] = True\n                    break\n    return result", "raw_solution": "import os\nimport re\nfrom pathlib import Path\n\ndef task_func(dir_path: str, predicates: list) -> dict:\n    if not predicates:\n        raise ValueError(\"No valid predicates provided\")\n    if not os.path.exists(dir_path) or not os.path.isdir(dir_path):\n        raise FileNotFoundError(\"Specified directory does not exist or is not a directory\")\n    result = {}\n    for item in os.listdir(dir_path):\n        item_path = os.path.join(dir_path, item)\n        if os.path.isfile(item_path):\n            for predicate in predicates:\n                if re.search(predicate, item):\n                    result[item] = True\n                    break\n        elif os.path.isdir(item_path):\n            for predicate in predicates:\n                if re.search(predicate, item):\n                    result[item] = True\n                    break\n    return result\n```"}
{"task_id": "BigCodeBench/990", "solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\ndef task_func(hex_string):\n    # Decode hexadecimal string to bytes\n    bytes_obj = binascii.unhexlify(hex_string)\n\n    # Convert bytes to UTF-8 string\n    utf8_string = bytes_obj.decode('utf-8')\n\n    # Encode UTF-8 string to various formats\n    hex_encoded = binascii.hexlify(bytes_obj).decode('utf-8')\n    base64_encoded = base64.b64encode(bytes_obj).decode('utf-8')\n    utf16_encoded = utf8_string.encode('utf-16').decode('utf-8')\n    utf32_encoded = utf8_string.encode('utf-32').decode('utf-8')\n    ascii_encoded = 'Not representable in ASCII'\n    try:\n        ascii_encoded = utf8_string.encode('ascii').decode('utf-8')\n    except UnicodeEncodeError:\n        pass\n    url_encoded = urllib.parse.quote(utf8_string)\n    rot13_encoded = codecs.encode(utf8_string, 'rot_13')\n\n    # Return dictionary of encoded strings\n    return {\n        'hex': hex_encoded,\n        'base64': base64_encoded,\n        'utf-8': utf8_string,\n        'utf-16': utf16_encoded,\n        'utf-32': utf32_encoded,\n        'ASCII': ascii_encoded,\n        'URL': url_encoded,\n        'ROT13': rot13_encoded\n    }", "raw_solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\n\ndef task_func(hex_string):\n    # Decode hexadecimal string to bytes\n    bytes_obj = binascii.unhexlify(hex_string)\n\n    # Convert bytes to UTF-8 string\n    utf8_string = bytes_obj.decode('utf-8')\n\n    # Encode UTF-8 string to various formats\n    hex_encoded = binascii.hexlify(bytes_obj).decode('utf-8')\n    base64_encoded = base64.b64encode(bytes_obj).decode('utf-8')\n    utf16_encoded = utf8_string.encode('utf-16').decode('utf-8')\n    utf32_encoded = utf8_string.encode('utf-32').decode('utf-8')\n    ascii_encoded = 'Not representable in ASCII'\n    try:\n        ascii_encoded = utf8_string.encode('ascii').decode('utf-8')\n    except UnicodeEncodeError:\n        pass\n    url_encoded = urllib.parse.quote(utf8_string)\n    rot13_encoded = codecs.encode(utf8_string, 'rot_13')\n\n    # Return dictionary of encoded strings\n    return {\n        'hex': hex_encoded,\n        'base64': base64_encoded,\n        'utf-8': utf8_string,\n        'utf-16': utf16_encoded,\n        'utf-32': utf32_encoded,\n        'ASCII': ascii_encoded,\n        'URL': url_encoded,\n        'ROT13': rot13_encoded\n    }\n```"}
{"task_id": "BigCodeBench/998", "solution": "import urllib.request\nimport os\nimport hashlib\nimport tarfile\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5_CHECKSUM = \"d41d8cd98f00b204e9800998ecf8427e\"\ndef task_func(url):\n    try:\n        # Download the file\n        urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n    except Exception as e:\n        print(f\"Failed to download file: {e}\")\n        return False\n\n    # Calculate the MD5 checksum of the downloaded file\n    md5_hash = hashlib.md5()\n    with open(TARGET_TAR_FILE, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            md5_hash.update(chunk)\n    calculated_md5_checksum = md5_hash.hexdigest()\n\n    # Check if the calculated checksum matches the expected value\n    if calculated_md5_checksum != EXPECTED_MD5_CHECKSUM:\n        print(\"Checksum does not match the expected value.\")\n        # Delete the downloaded file\n        os.remove(TARGET_TAR_FILE)\n        return False\n\n    # Extract the contents of the tar.gz file\n    try:\n        with tarfile.open(TARGET_TAR_FILE, \"r:gz\") as tar:\n            tar.extractall()\n    except Exception as e:\n        print(f\"Failed to extract file: {e}\")\n        # Delete the downloaded file\n        os.remove(TARGET_TAR_FILE)\n        return False\n\n    # Delete the downloaded file\n    os.remove(TARGET_TAR_FILE)\n\n    return True", "raw_solution": "import urllib.request\nimport os\nimport hashlib\nimport tarfile\n\n# Constants\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5_CHECKSUM = \"d41d8cd98f00b204e9800998ecf8427e\"\n\ndef task_func(url):\n    try:\n        # Download the file\n        urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n    except Exception as e:\n        print(f\"Failed to download file: {e}\")\n        return False\n\n    # Calculate the MD5 checksum of the downloaded file\n    md5_hash = hashlib.md5()\n    with open(TARGET_TAR_FILE, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            md5_hash.update(chunk)\n    calculated_md5_checksum = md5_hash.hexdigest()\n\n    # Check if the calculated checksum matches the expected value\n    if calculated_md5_checksum != EXPECTED_MD5_CHECKSUM:\n        print(\"Checksum does not match the expected value.\")\n        # Delete the downloaded file\n        os.remove(TARGET_TAR_FILE)\n        return False\n\n    # Extract the contents of the tar.gz file\n    try:\n        with tarfile.open(TARGET_TAR_FILE, \"r:gz\") as tar:\n            tar.extractall()\n    except Exception as e:\n        print(f\"Failed to extract file: {e}\")\n        # Delete the downloaded file\n        os.remove(TARGET_TAR_FILE)\n        return False\n\n    # Delete the downloaded file\n    os.remove(TARGET_TAR_FILE)\n\n    return True\n```"}
{"task_id": "BigCodeBench/999", "solution": "import urllib.request\nimport os\nimport csv\nimport collections\ndef task_func(url, column_name, csv_file_path):\n    try:\n        urllib.request.urlretrieve(url, csv_file_path)\n    except Exception as e:\n        print(f\"Error downloading file: {e}\")\n        return\n\n    try:\n        with open(csv_file_path, 'r') as file:\n            reader = csv.DictReader(file)\n            column_values = [row[column_name] for row in reader if column_name in row]\n    except KeyError:\n        print(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n        os.remove(csv_file_path)\n        raise ValueError(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n    except Exception as e:\n        print(f\"Error reading CSV file: {e}\")\n        os.remove(csv_file_path)\n        return\n\n    os.remove(csv_file_path)\n    return dict(collections.Counter(column_values))", "raw_solution": "import urllib.request\nimport os\nimport csv\nimport collections\n\ndef task_func(url, column_name, csv_file_path):\n    try:\n        urllib.request.urlretrieve(url, csv_file_path)\n    except Exception as e:\n        print(f\"Error downloading file: {e}\")\n        return\n\n    try:\n        with open(csv_file_path, 'r') as file:\n            reader = csv.DictReader(file)\n            column_values = [row[column_name] for row in reader if column_name in row]\n    except KeyError:\n        print(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n        os.remove(csv_file_path)\n        raise ValueError(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n    except Exception as e:\n        print(f\"Error reading CSV file: {e}\")\n        os.remove(csv_file_path)\n        return\n\n    os.remove(csv_file_path)\n    return dict(collections.Counter(column_values))\n```"}
{"task_id": "BigCodeBench/1003", "solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\ndef task_func(url):\n    try:\n        response = urllib.request.urlopen(url)\n        xml_data = response.read()\n    except urllib.error.URLError:\n        raise ValueError(\"URL is invalid or XML file cannot be fetched from the URL.\")\n\n    try:\n        root = etree.fromstring(xml_data)\n    except etree.XMLSyntaxError:\n        raise ValueError(\"XML file has invalid syntax.\")\n\n    items = root.findall('item')\n    if not items:\n        raise ValueError(\"XML structure does not match expected format.\")\n\n    data = []\n    for item in items:\n        row = {}\n        for child in item:\n            row[child.tag] = child.text\n        data.append(row)\n\n    return pd.DataFrame(data)", "raw_solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\n\ndef task_func(url):\n    try:\n        response = urllib.request.urlopen(url)\n        xml_data = response.read()\n    except urllib.error.URLError:\n        raise ValueError(\"URL is invalid or XML file cannot be fetched from the URL.\")\n\n    try:\n        root = etree.fromstring(xml_data)\n    except etree.XMLSyntaxError:\n        raise ValueError(\"XML file has invalid syntax.\")\n\n    items = root.findall('item')\n    if not items:\n        raise ValueError(\"XML structure does not match expected format.\")\n\n    data = []\n    for item in items:\n        row = {}\n        for child in item:\n            row[child.tag] = child.text\n        data.append(row)\n\n    return pd.DataFrame(data)"}
{"task_id": "BigCodeBench/1004", "solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(url):\n    # Download the text file\n    response = urllib.request.urlopen(url)\n    text = response.read().decode('utf-8')\n\n    # Extract words from the text\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Count the frequency of each word\n    word_count = Counter(words)\n\n    # Create a bar chart of the ten most common words\n    fig, ax = plt.subplots()\n    ax.bar(word_count.most_common(10)[::-1], word_count.most_common(10)[::-1])\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Word Frequency')\n\n    return word_count, ax", "raw_solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(url):\n    # Download the text file\n    response = urllib.request.urlopen(url)\n    text = response.read().decode('utf-8')\n\n    # Extract words from the text\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Count the frequency of each word\n    word_count = Counter(words)\n\n    # Create a bar chart of the ten most common words\n    fig, ax = plt.subplots()\n    ax.bar(word_count.most_common(10)[::-1], word_count.most_common(10)[::-1])\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Word Frequency')\n\n    return word_count, ax\n```"}
{"task_id": "BigCodeBench/1006", "solution": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        return \"Error: Unable to download the file from the provided URL.\"\n\n    if response.headers.get('content-type') != 'application/zip':\n        return \"Error: The URL does not point to a ZIP file.\"\n\n    file_path = os.path.join(download_path, \"file.zip\")\n    with open(file_path, 'wb') as f:\n        f.write(response.content)\n\n    try:\n        with ZipFile(file_path, 'r') as zip_ref:\n            zip_ref.extractall(download_path)\n    except BadZipFile:\n        return \"Error: The downloaded file is not a valid ZIP file.\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    return download_path", "raw_solution": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\n\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        return \"Error: Unable to download the file from the provided URL.\"\n\n    if response.headers.get('content-type') != 'application/zip':\n        return \"Error: The URL does not point to a ZIP file.\"\n\n    file_path = os.path.join(download_path, \"file.zip\")\n    with open(file_path, 'wb') as f:\n        f.write(response.content)\n\n    try:\n        with ZipFile(file_path, 'r') as zip_ref:\n            zip_ref.extractall(download_path)\n    except BadZipFile:\n        return \"Error: The downloaded file is not a valid ZIP file.\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    return download_path\n```"}
{"task_id": "BigCodeBench/1008", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        raise errh\n    except requests.exceptions.RequestException as err:\n        raise err\n\n    soup = BeautifulSoup(response.content, 'html.parser')\n    table = soup.find('table', {'id': table_id})\n\n    if table is None:\n        raise ValueError(\"Table with the specified ID not found.\")\n\n    table_data = StringIO(table.prettify())\n    df = pd.read_html(table_data)[0]\n\n    return df", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\n\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        raise errh\n    except requests.exceptions.RequestException as err:\n        raise err\n\n    soup = BeautifulSoup(response.content, 'html.parser')\n    table = soup.find('table', {'id': table_id})\n\n    if table is None:\n        raise ValueError(\"Table with the specified ID not found.\")\n\n    table_data = StringIO(table.prettify())\n    df = pd.read_html(table_data)[0]\n\n    return df\n```"}
{"task_id": "BigCodeBench/1012", "solution": "import requests\nfrom pathlib import Path\nimport zipfile\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\ndef task_func(url, filename):\n    try:\n        # Download the file\n        response = requests.get(url)\n        response.raise_for_status()\n\n        # Save the file\n        download_path = DOWNLOAD_DIR / filename\n        download_path.write_bytes(response.content)\n\n        # Extract the file\n        zip_path = DOWNLOAD_DIR / filename\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall(ZIP_DIR)\n\n        # Get the list of filenames in the unzipped directory\n        unzipped_files = [file.name for file in ZIP_DIR.iterdir()]\n\n        return \"Success\", unzipped_files\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {str(e)}\", []\n    except Exception as e:\n        return f\"Error: {str(e)}\", []", "raw_solution": "import requests\nfrom pathlib import Path\nimport zipfile\n\n# Constants\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\n\ndef task_func(url, filename):\n    try:\n        # Download the file\n        response = requests.get(url)\n        response.raise_for_status()\n\n        # Save the file\n        download_path = DOWNLOAD_DIR / filename\n        download_path.write_bytes(response.content)\n\n        # Extract the file\n        zip_path = DOWNLOAD_DIR / filename\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall(ZIP_DIR)\n\n        # Get the list of filenames in the unzipped directory\n        unzipped_files = [file.name for file in ZIP_DIR.iterdir()]\n\n        return \"Success\", unzipped_files\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {str(e)}\", []\n    except Exception as e:\n        return f\"Error: {str(e)}\", []\n```"}
{"task_id": "BigCodeBench/1013", "solution": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    links = set()\n\n    for link in soup.find_all('a'):\n        href = link.get('href')\n        if href and not href.startswith('#'):\n            absolute_url = urljoin(base_url, href)\n            links.add(absolute_url)\n\n    with open(csv_file, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"URL\"])\n        for link in links:\n            writer.writerow([link])\n\n    return len(links)", "raw_solution": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\n\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    links = set()\n\n    for link in soup.find_all('a'):\n        href = link.get('href')\n        if href and not href.startswith('#'):\n            absolute_url = urljoin(base_url, href)\n            links.add(absolute_url)\n\n    with open(csv_file, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"URL\"])\n        for link in links:\n            writer.writerow([link])\n\n    return len(links)\n```"}
{"task_id": "BigCodeBench/1015", "solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        raise requests.RequestException(f\"Error fetching data from {webpage_url}: {str(e)}\")\n\n    tree = html.fromstring(response.content)\n    table = tree.xpath('//table')\n\n    if not table:\n        return 0\n\n    table_data = pd.read_html(response.text)[0]\n\n    if table_data.empty:\n        return 0\n\n    try:\n        conn = sqlite3.connect(database_name)\n        cursor = conn.cursor()\n        cursor.execute('DROP TABLE IF EXISTS my_table')\n        table_data.to_sql('my_table', conn, if_exists='replace', index=False)\n        conn.commit()\n    except sqlite3.DatabaseError as e:\n        raise sqlite3.DatabaseError(f\"Error writing to SQLite database {database_name}: {str(e)}\")\n\n    return table_data.shape[0]", "raw_solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\n\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        raise requests.RequestException(f\"Error fetching data from {webpage_url}: {str(e)}\")\n\n    tree = html.fromstring(response.content)\n    table = tree.xpath('//table')\n\n    if not table:\n        return 0\n\n    table_data = pd.read_html(response.text)[0]\n\n    if table_data.empty:\n        return 0\n\n    try:\n        conn = sqlite3.connect(database_name)\n        cursor = conn.cursor()\n        cursor.execute('DROP TABLE IF EXISTS my_table')\n        table_data.to_sql('my_table', conn, if_exists='replace', index=False)\n        conn.commit()\n    except sqlite3.DatabaseError as e:\n        raise sqlite3.DatabaseError(f\"Error writing to SQLite database {database_name}: {str(e)}\")\n\n    return table_data.shape[0]"}
{"task_id": "BigCodeBench/1019", "solution": "from PIL import Image\nimport codecs\nimport pytesseract\nIMAGE_PATH = \"image.png\"\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        image = Image.open(filename)\n        text = pytesseract.image_to_string(image)\n        return codecs.decode(text, from_encoding).encode(to_encoding).decode()\n    except (ValueError, LookupError) as e:\n        raise ValueError(f\"Error during conversion: {e}\")\n    except Exception as e:\n        return \"\"", "raw_solution": "from PIL import Image\nimport codecs\nimport pytesseract\n\nIMAGE_PATH = \"image.png\"\n\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        image = Image.open(filename)\n        text = pytesseract.image_to_string(image)\n        return codecs.decode(text, from_encoding).encode(to_encoding).decode()\n    except (ValueError, LookupError) as e:\n        raise ValueError(f\"Error during conversion: {e}\")\n    except Exception as e:\n        return \"\"\n```"}
{"task_id": "BigCodeBench/1020", "solution": "import json\nimport requests\nimport chardet\nAPI_URL = \"http://api.example.com/data\"\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    try:\n        response = requests.get(url, timeout=5)\n        content = response.content\n        if not content:\n            return {}\n        if not from_encoding:\n            from_encoding = chardet.detect(content)['encoding']\n        if not from_encoding:\n            raise ValueError(\"Unable to detect encoding for non-empty content\")\n        decoded_content = content.decode(from_encoding)\n        reencoded_content = decoded_content.encode(to_encoding)\n        return json.loads(reencoded_content)\n    except Exception as e:\n        raise e", "raw_solution": "import json\nimport requests\nimport chardet\n\n# Constants\nAPI_URL = \"http://api.example.com/data\"\n\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    try:\n        response = requests.get(url, timeout=5)\n        content = response.content\n        if not content:\n            return {}\n        if not from_encoding:\n            from_encoding = chardet.detect(content)['encoding']\n        if not from_encoding:\n            raise ValueError(\"Unable to detect encoding for non-empty content\")\n        decoded_content = content.decode(from_encoding)\n        reencoded_content = decoded_content.encode(to_encoding)\n        return json.loads(reencoded_content)\n    except Exception as e:\n        raise e\n```"}
{"task_id": "BigCodeBench/1022", "solution": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    if not os.path.exists(csv_file_path):\n        raise FileNotFoundError(f\"File not found at path: {csv_file_path}\")\n\n    try:\n        df = pd.read_csv(csv_file_path)\n    except EmptyDataError:\n        return pd.DataFrame()\n\n    if column_name not in df.columns:\n        raise ValueError(f\"Column not found in CSV file: {column_name}\")\n\n    df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n    df = df[df[column_name] <= datetime.now()]\n    df = df.sort_values(by=column_name)\n\n    return df", "raw_solution": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\n\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    if not os.path.exists(csv_file_path):\n        raise FileNotFoundError(f\"File not found at path: {csv_file_path}\")\n\n    try:\n        df = pd.read_csv(csv_file_path)\n    except EmptyDataError:\n        return pd.DataFrame()\n\n    if column_name not in df.columns:\n        raise ValueError(f\"Column not found in CSV file: {column_name}\")\n\n    df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n    df = df[df[column_name] <= datetime.now()]\n    df = df.sort_values(by=column_name)\n\n    return df\n```"}
{"task_id": "BigCodeBench/1039", "solution": "import ssl\nimport os\nimport hashlib\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n    context.load_cert_chain(cert_file, key_file)\n    server_socket = context.wrap_socket(client_socket, server_side=True)\n    try:\n        file_path = server_socket.recv(buffer_size).decode()\n        if os.path.exists(file_path):\n            with open(file_path, 'rb') as file:\n                file_data = file.read()\n                file_hash = hashlib.sha256(file_data).hexdigest()\n            return file_hash\n        else:\n            return 'File not found'\n    except Exception as e:\n        return str(e)", "raw_solution": "import ssl\nimport os\nimport hashlib\n\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n    context.load_cert_chain(cert_file, key_file)\n    server_socket = context.wrap_socket(client_socket, server_side=True)\n    try:\n        file_path = server_socket.recv(buffer_size).decode()\n        if os.path.exists(file_path):\n            with open(file_path, 'rb') as file:\n                file_data = file.read()\n                file_hash = hashlib.sha256(file_data).hexdigest()\n            return file_hash\n        else:\n            return 'File not found'\n    except Exception as e:\n        return str(e)\n```"}
{"task_id": "BigCodeBench/1040", "solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_socket.bind((server_address, server_port))\n    server_socket.listen(5)\n\n    inputs = [server_socket]\n    outputs = []\n    message_queues = {}\n\n    start_time = datetime.now()\n    while (datetime.now() - start_time).seconds < run_duration:\n        readable, writable, exceptional = select.select(inputs, outputs, inputs)\n\n        for sock in readable:\n            if sock is server_socket:\n                connection, client_address = sock.accept()\n                print(f\"Accepted connection from {client_address}\")\n                connection.setblocking(0)\n                inputs.append(connection)\n                message_queues[connection] = queue.Queue()\n            else:\n                data = sock.recv(buffer_size)\n                if data:\n                    message_queues[sock].put(data)\n                    if sock not in outputs:\n                        outputs.append(sock)\n                else:\n                    print(f\"Closed connection from {sock.getpeername()}\")\n                    sock.close()\n                    inputs.remove(sock)\n                    if sock in outputs:\n                        outputs.remove(sock)\n                    del message_queues[sock]\n\n        for sock in writable:\n            try:\n                next_msg = message_queues[sock].get_nowait()\n            except queue.Empty:\n                outputs.remove(sock)\n            else:\n                sock.send(next_msg + str(datetime.now()).encode())\n\n        for sock in exceptional:\n            print(f\"Exceptional condition on {sock.getpeername()}\")\n            sock.close()\n            inputs.remove(sock)\n            if sock in outputs:\n                outputs.remove(sock)\n            del message_queues[sock]\n\n    server_socket.close()\n    return f\"Server ran for {run_duration} seconds.\"", "raw_solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_socket.bind((server_address, server_port))\n    server_socket.listen(5)\n\n    inputs = [server_socket]\n    outputs = []\n    message_queues = {}\n\n    start_time = datetime.now()\n    while (datetime.now() - start_time).seconds < run_duration:\n        readable, writable, exceptional = select.select(inputs, outputs, inputs)\n\n        for sock in readable:\n            if sock is server_socket:\n                connection, client_address = sock.accept()\n                print(f\"Accepted connection from {client_address}\")\n                connection.setblocking(0)\n                inputs.append(connection)\n                message_queues[connection] = queue.Queue()\n            else:\n                data = sock.recv(buffer_size)\n                if data:\n                    message_queues[sock].put(data)\n                    if sock not in outputs:\n                        outputs.append(sock)\n                else:\n                    print(f\"Closed connection from {sock.getpeername()}\")\n                    sock.close()\n                    inputs.remove(sock)\n                    if sock in outputs:\n                        outputs.remove(sock)\n                    del message_queues[sock]\n\n        for sock in writable:\n            try:\n                next_msg = message_queues[sock].get_nowait()\n            except queue.Empty:\n                outputs.remove(sock)\n            else:\n                sock.send(next_msg + str(datetime.now()).encode())\n\n        for sock in exceptional:\n            print(f\"Exceptional condition on {sock.getpeername()}\")\n            sock.close()\n            inputs.remove(sock)\n            if sock in outputs:\n                outputs.remove(sock)\n            del message_queues[sock]\n\n    server_socket.close()\n    return f\"Server ran for {run_duration} seconds.\"\n```"}
{"task_id": "BigCodeBench/1042", "solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\ndef send_email(sender, recipient, password, message):\n    msg = EmailMessage()\n    msg.set_content(message)\n    msg['Subject'] = 'Message from Client'\n    msg['From'] = sender\n    msg['To'] = recipient\n\n    server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n    server.starttls()\n    server.login(sender, password)\n    server.send_message(msg)\n    server.quit()\ndef task_func(client_socket):\n    message = client_socket.recv(BUFFER_SIZE).decode()\n    sender = input(\"Enter your email: \")\n    recipient = input(\"Enter recipient's email: \")\n    password = getpass.getpass(\"Enter your email password: \")\n    send_email(sender, recipient, password, message)", "raw_solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\n\ndef send_email(sender, recipient, password, message):\n    msg = EmailMessage()\n    msg.set_content(message)\n    msg['Subject'] = 'Message from Client'\n    msg['From'] = sender\n    msg['To'] = recipient\n\n    server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n    server.starttls()\n    server.login(sender, password)\n    server.send_message(msg)\n    server.quit()\n\ndef task_func(client_socket):\n    message = client_socket.recv(BUFFER_SIZE).decode()\n    sender = input(\"Enter your email: \")\n    recipient = input(\"Enter recipient's email: \")\n    password = getpass.getpass(\"Enter your email password: \")\n    send_email(sender, recipient, password, message)"}
{"task_id": "BigCodeBench/1053", "solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\ndef task_func(file_path, save_path=None):\n    try:\n        df = pd.read_csv(file_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File {file_path} not found.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None\n\n    # Check if the CSV file has a header\n    if df.columns[0] != 'Text':\n        df.columns = ['Text']\n\n    # Split the text into words\n    words = df['Text'].str.split()\n\n    # Create a histogram of the frequency of the top ten most common words\n    vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n    word_counts = vectorizer.fit_transform(words.sum())\n    word_counts = word_counts.toarray()\n    word_counts = word_counts.sum(axis=0)\n    word_counts = pd.Series(word_counts, index=vectorizer.get_feature_names_out())\n    top_words = word_counts.sort_values(ascending=False).head(10)\n\n    # Plot the histogram\n    plt.figure(figsize=(10, 5))\n    plt.bar(top_words.index, top_words.values)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Top 10 Most Common Words')\n    plt.xticks(rotation=90)\n\n    if save_path is not None:\n        plt.savefig(save_path)\n        return None\n    else:\n        return plt.gca()", "raw_solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n\n# Constants\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\n\ndef task_func(file_path, save_path=None):\n    try:\n        df = pd.read_csv(file_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File {file_path} not found.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None\n\n    # Check if the CSV file has a header\n    if df.columns[0] != 'Text':\n        df.columns = ['Text']\n\n    # Split the text into words\n    words = df['Text'].str.split()\n\n    # Create a histogram of the frequency of the top ten most common words\n    vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n    word_counts = vectorizer.fit_transform(words.sum())\n    word_counts = word_counts.toarray()\n    word_counts = word_counts.sum(axis=0)\n    word_counts = pd.Series(word_counts, index=vectorizer.get_feature_names_out())\n    top_words = word_counts.sort_values(ascending=False).head(10)\n\n    # Plot the histogram\n    plt.figure(figsize=(10, 5))\n    plt.bar(top_words.index, top_words.values)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Top 10 Most Common Words')\n    plt.xticks(rotation=90)\n\n    if save_path is not None:\n        plt.savefig(save_path)\n        return None\n    else:\n        return plt.gca()\n```"}
{"task_id": "BigCodeBench/1057", "solution": "import pandas as pd\nimport itertools\nimport numpy as np\ndef task_func(animals=None, foods=None):\n    if animals is None:\n        animals = ['Dog', 'Cat', 'Bird']\n    if foods is None:\n        foods = ['Burger', 'Pizza', 'Sushi']\n    if not animals or not foods:\n        return pd.DataFrame()\n    combinations = list(itertools.product(animals, foods))\n    np.random.shuffle(combinations)\n    df = pd.DataFrame(combinations, columns=foods)\n    df.index = animals\n    df = df.applymap(lambda x: f'{x[0]}:{x[1]}')\n    return df", "raw_solution": "import pandas as pd\nimport itertools\nimport numpy as np\n\ndef task_func(animals=None, foods=None):\n    if animals is None:\n        animals = ['Dog', 'Cat', 'Bird']\n    if foods is None:\n        foods = ['Burger', 'Pizza', 'Sushi']\n    if not animals or not foods:\n        return pd.DataFrame()\n    combinations = list(itertools.product(animals, foods))\n    np.random.shuffle(combinations)\n    df = pd.DataFrame(combinations, columns=foods)\n    df.index = animals\n    df = df.applymap(lambda x: f'{x[0]}:{x[1]}')\n    return df\n```"}
{"task_id": "BigCodeBench/1077", "solution": "from datetime import datetime\nimport pytz\nimport numpy as np\ndef task_func(time_strings, timezone):\n    if len(time_strings) < 2:\n        return 0.0\n\n    time_diffs = []\n    for i in range(1, len(time_strings)):\n        time1 = datetime.strptime(time_strings[i-1], \"%Y-%m-%d %H:%M:%S\")\n        time2 = datetime.strptime(time_strings[i], \"%Y-%m-%d %H:%M:%S\")\n\n        time1 = pytz.utc.localize(time1)\n        time2 = pytz.utc.localize(time2)\n\n        time1 = time1.astimezone(pytz.timezone(timezone))\n        time2 = time2.astimezone(pytz.timezone(timezone))\n\n        diff = (time2 - time1).total_seconds()\n        time_diffs.append(abs(diff))\n\n    return np.mean(time_diffs)", "raw_solution": "from datetime import datetime\nimport pytz\nimport numpy as np\n\ndef task_func(time_strings, timezone):\n    if len(time_strings) < 2:\n        return 0.0\n\n    time_diffs = []\n    for i in range(1, len(time_strings)):\n        time1 = datetime.strptime(time_strings[i-1], \"%Y-%m-%d %H:%M:%S\")\n        time2 = datetime.strptime(time_strings[i], \"%Y-%m-%d %H:%M:%S\")\n\n        time1 = pytz.utc.localize(time1)\n        time2 = pytz.utc.localize(time2)\n\n        time1 = time1.astimezone(pytz.timezone(timezone))\n        time2 = time2.astimezone(pytz.timezone(timezone))\n\n        diff = (time2 - time1).total_seconds()\n        time_diffs.append(abs(diff))\n\n    return np.mean(time_diffs)"}
{"task_id": "BigCodeBench/1085", "solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Lowercase the text and remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text.lower())\n    # Split the text into words\n    words = text.split()\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    # Get the 10 most common words\n    most_common_words = word_counts.most_common(10)\n    # Create a bar chart of the word counts\n    fig, ax = plt.subplots()\n    ax.bar(range(len(most_common_words)), [count for word, count in most_common_words])\n    ax.set_xticks(range(len(most_common_words)))\n    ax.set_xticklabels([word for word, count in most_common_words])\n    ax.set_xlabel('Word')\n    ax.set_ylabel('Count')\n    ax.set_title('Top 10 Most Common Words')\n    plt.tight_layout()\n    return most_common_words, ax", "raw_solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Lowercase the text and remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text.lower())\n    # Split the text into words\n    words = text.split()\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    # Get the 10 most common words\n    most_common_words = word_counts.most_common(10)\n    # Create a bar chart of the word counts\n    fig, ax = plt.subplots()\n    ax.bar(range(len(most_common_words)), [count for word, count in most_common_words])\n    ax.set_xticks(range(len(most_common_words)))\n    ax.set_xticklabels([word for word, count in most_common_words])\n    ax.set_xlabel('Word')\n    ax.set_ylabel('Count')\n    ax.set_title('Top 10 Most Common Words')\n    plt.tight_layout()\n    return most_common_words, ax\n```"}
{"task_id": "BigCodeBench/1124", "solution": "import re\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nimport requests\ndef task_func(myString):\n    url_regex = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    url_match = url_regex.search(myString)\n    if url_match:\n        url = url_match.group()\n        try:\n            response = requests.get(url)\n            if response.status_code == 200:\n                soup = BeautifulSoup(response.text, 'html.parser')\n                title_tag = soup.find('title')\n                if title_tag:\n                    return title_tag.text\n                else:\n                    return \"No title tag found in the webpage.\"\n            else:\n                return f\"Unable to fetch the content of the URL: {url}\"\n        except requests.exceptions.RequestException as e:\n            return f\"Unable to fetch the content of the URL: {url}\"\n    else:\n        return \"No valid URL found in the provided string.\"", "raw_solution": "import re\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nimport requests\n\ndef task_func(myString):\n    url_regex = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    url_match = url_regex.search(myString)\n    if url_match:\n        url = url_match.group()\n        try:\n            response = requests.get(url)\n            if response.status_code == 200:\n                soup = BeautifulSoup(response.text, 'html.parser')\n                title_tag = soup.find('title')\n                if title_tag:\n                    return title_tag.text\n                else:\n                    return \"No title tag found in the webpage.\"\n            else:\n                return f\"Unable to fetch the content of the URL: {url}\"\n        except requests.exceptions.RequestException as e:\n            return f\"Unable to fetch the content of the URL: {url}\"\n    else:\n        return \"No valid URL found in the provided string.\"\n```"}
{"task_id": "BigCodeBench/1129", "solution": "import json\nimport requests\nimport os\nfrom datetime import datetime\ndef task_func(json_data, unknown_key, save_dir=None):\n    data = json.loads(json_data)\n    url = data[unknown_key]\n    response = requests.get(url)\n    if save_dir is None:\n        save_dir = os.getcwd()\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S%f')\n    filename = f\"{unknown_key}_{timestamp}.txt\"\n    file_path = os.path.join(save_dir, filename)\n    with open(file_path, 'wb') as file:\n        file.write(response.content)\n    return file_path", "raw_solution": "import json\nimport requests\nimport os\nfrom datetime import datetime\n\ndef task_func(json_data, unknown_key, save_dir=None):\n    data = json.loads(json_data)\n    url = data[unknown_key]\n    response = requests.get(url)\n    if save_dir is None:\n        save_dir = os.getcwd()\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S%f')\n    filename = f\"{unknown_key}_{timestamp}.txt\"\n    file_path = os.path.join(save_dir, filename)\n    with open(file_path, 'wb') as file:\n        file.write(response.content)\n    return file_path\n```"}
{"task_id": "BigCodeBench/1137", "solution": "import bs4\nimport requests\nimport re\nimport json\ndef task_func(url: str, output_path: str) -> list:\n    if url.startswith(\"http\"):\n        response = requests.get(url)\n        soup = bs4.BeautifulSoup(response.text, 'html.parser')\n    else:\n        with open(url, 'r') as file:\n            soup = bs4.BeautifulSoup(file.read(), 'html.parser')\n\n    phone_numbers = re.findall(r'\\(?\\b[2-9][0-9]{2}\\)?[-. ]?[2-9][0-9]{2}[-. ]?[0-9]{4}\\b', soup.text)\n\n    with open(output_path, 'w') as file:\n        json.dump(phone_numbers, file)\n\n    return phone_numbers", "raw_solution": "import bs4\nimport requests\nimport re\nimport json\n\ndef task_func(url: str, output_path: str) -> list:\n    if url.startswith(\"http\"):\n        response = requests.get(url)\n        soup = bs4.BeautifulSoup(response.text, 'html.parser')\n    else:\n        with open(url, 'r') as file:\n            soup = bs4.BeautifulSoup(file.read(), 'html.parser')\n\n    phone_numbers = re.findall(r'\\(?\\b[2-9][0-9]{2}\\)?[-. ]?[2-9][0-9]{2}[-. ]?[0-9]{4}\\b', soup.text)\n\n    with open(output_path, 'w') as file:\n        json.dump(phone_numbers, file)\n\n    return phone_numbers\n```"}
