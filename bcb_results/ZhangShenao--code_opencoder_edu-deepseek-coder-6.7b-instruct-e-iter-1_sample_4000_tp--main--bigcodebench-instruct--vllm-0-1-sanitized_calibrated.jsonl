{"task_id": "BigCodeBench/0", "solution": "import itertools\nfrom random import shuffle\ndef task_func(numbers=list(range(1, 11))):\n    # Calculate all permutations\n    perms = list(itertools.permutations(numbers))\n\n    # Initialize sum of absolute differences\n    sum_diffs = 0\n\n    # For each permutation\n    for perm in perms:\n        # Shuffle the permutation\n        shuffle(perm)\n        # Calculate the sum of absolute differences\n        sum_diffs += sum(abs(perm[i] - perm[i+1]) for i in range(len(perm)-1))\n\n    # Calculate the average\n    avg_diffs = sum_diffs / len(perms)\n\n    return avg_diffs", "raw_solution": "import itertools\nfrom random import shuffle\n\ndef task_func(numbers=list(range(1, 11))):\n    # Calculate all permutations\n    perms = list(itertools.permutations(numbers))\n\n    # Initialize sum of absolute differences\n    sum_diffs = 0\n\n    # For each permutation\n    for perm in perms:\n        # Shuffle the permutation\n        shuffle(perm)\n        # Calculate the sum of absolute differences\n        sum_diffs += sum(abs(perm[i] - perm[i+1]) for i in range(len(perm)-1))\n\n    # Calculate the average\n    avg_diffs = sum_diffs / len(perms)\n\n    return avg_diffs\n\n# Test the function"}
{"task_id": "BigCodeBench/1", "solution": "import collections\nimport random\nimport string\ndef task_func(length=100):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    random_string = ''.join(random.choice(string.ascii_letters) for _ in range(length))\n    count_dict = collections.Counter(random_string)\n    return count_dict", "raw_solution": "import collections\nimport random\nimport string\n\ndef task_func(length=100):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    random_string = ''.join(random.choice(string.ascii_letters) for _ in range(length))\n    count_dict = collections.Counter(random_string)\n    return count_dict"}
{"task_id": "BigCodeBench/2", "solution": "import random\nimport statistics\nimport string\ndef task_func(LETTERS):\n    # Create a dictionary with random letters as keys and lists of random integers as values\n    my_dict = {chr(i): [random.randint(1, 100) for _ in range(5)] for i in range(65, 65+LETTERS)}\n\n    # Calculate the mean of the values in the dictionary and sort it in descending order\n    sorted_dict = {k: v for k, v in sorted(my_dict.items(), key=lambda item: statistics.mean(item[1]), reverse=True)}\n\n    return sorted_dict", "raw_solution": "import random\nimport statistics\nimport string\n\ndef task_func(LETTERS):\n    # Create a dictionary with random letters as keys and lists of random integers as values\n    my_dict = {chr(i): [random.randint(1, 100) for _ in range(5)] for i in range(65, 65+LETTERS)}\n\n    # Calculate the mean of the values in the dictionary and sort it in descending order\n    sorted_dict = {k: v for k, v in sorted(my_dict.items(), key=lambda item: statistics.mean(item[1]), reverse=True)}\n\n    return sorted_dict\n\n# Test the function"}
{"task_id": "BigCodeBench/3", "solution": "import random\nimport numpy as np\ndef task_func(LETTERS):\n    random.seed(0)  # for reproducibility\n    result = {}\n    for letter in LETTERS:\n        random_list = [random.randint(0, 100) for _ in range(random.randint(1, 10))]\n        result[letter] = np.mean(random_list)\n    return result\nLETTERS = ['a', 'b', 'c', 'd', 'e']", "raw_solution": "import random\nimport numpy as np\n\ndef task_func(LETTERS):\n    random.seed(0)  # for reproducibility\n    result = {}\n    for letter in LETTERS:\n        random_list = [random.randint(0, 100) for _ in range(random.randint(1, 10))]\n        result[letter] = np.mean(random_list)\n    return result\n\n# Test the function\nLETTERS = ['a', 'b', 'c', 'd', 'e']"}
{"task_id": "BigCodeBench/4", "solution": "from collections import Counter\nimport itertools\ndef task_func(d):\n    # Flatten the list of values in the dictionary\n    flat_list = list(itertools.chain.from_iterable(d.values()))\n    \n    # Count the occurrence of each integer in the flattened list\n    count_dict = dict(Counter(flat_list))\n    \n    return count_dict\nd = {\n    'a': [1, 2, 2, 3],\n    'b': [2, 3, 4],\n    'c': [1, 1, 1, 2, 3, 3, 4, 4, 4, 4]\n}", "raw_solution": "from collections import Counter\nimport itertools\n\ndef task_func(d):\n    # Flatten the list of values in the dictionary\n    flat_list = list(itertools.chain.from_iterable(d.values()))\n    \n    # Count the occurrence of each integer in the flattened list\n    count_dict = dict(Counter(flat_list))\n    \n    return count_dict\n\n# Test the function\nd = {\n    'a': [1, 2, 2, 3],\n    'b': [2, 3, 4],\n    'c': [1, 1, 1, 2, 3, 3, 4, 4, 4, 4]\n}\n"}
{"task_id": "BigCodeBench/5", "solution": "import random\nimport math\nimport statistics\ndef task_func(LETTERS=[chr(i) for i in range(97, 123)]):\n    random.seed(1)\n    dict_std_dev = {}\n    for letter in LETTERS:\n        list_size = random.randint(1, 10)\n        random_list = [random.randint(0, 100) for _ in range(list_size)]\n        dict_std_dev[letter] = statistics.pstdev(random_list)\n    return dict_std_dev", "raw_solution": "import random\nimport math\nimport statistics\n\ndef task_func(LETTERS=[chr(i) for i in range(97, 123)]):\n    random.seed(1)\n    dict_std_dev = {}\n    for letter in LETTERS:\n        list_size = random.randint(1, 10)\n        random_list = [random.randint(0, 100) for _ in range(list_size)]\n        dict_std_dev[letter] = statistics.pstdev(random_list)\n    return dict_std_dev\n\n# Test the function"}
{"task_id": "BigCodeBench/6", "solution": "import os\nimport re\ndef task_func(pattern, log_dir='/var/log/'):\n    # Compile the regex pattern\n    regex = re.compile(pattern)\n\n    # Initialize variables to keep track of the latest file\n    latest_file = None\n    latest_mtime = 0\n\n    # Iterate over all files in the log directory\n    for filename in os.listdir(log_dir):\n        # Check if the file matches the regex pattern\n        if regex.match(filename):\n            # Get the modification time of the file\n            mtime = os.path.getmtime(os.path.join(log_dir, filename))\n            # If the modification time is greater than the current latest, update the latest\n            if mtime > latest_mtime:\n                latest_mtime = mtime\n                latest_file = os.path.join(log_dir, filename)\n\n    # Return the path to the latest file or None if no files match the pattern\n    return latest_file", "raw_solution": "import os\nimport re\n\ndef task_func(pattern, log_dir='/var/log/'):\n    # Compile the regex pattern\n    regex = re.compile(pattern)\n\n    # Initialize variables to keep track of the latest file\n    latest_file = None\n    latest_mtime = 0\n\n    # Iterate over all files in the log directory\n    for filename in os.listdir(log_dir):\n        # Check if the file matches the regex pattern\n        if regex.match(filename):\n            # Get the modification time of the file\n            mtime = os.path.getmtime(os.path.join(log_dir, filename))\n            # If the modification time is greater than the current latest, update the latest\n            if mtime > latest_mtime:\n                latest_mtime = mtime\n                latest_file = os.path.join(log_dir, filename)\n\n    # Return the path to the latest file or None if no files match the pattern\n    return latest_file"}
{"task_id": "BigCodeBench/7", "solution": "import csv\nimport collections\nimport operator\ndef task_func(csv_file_path):\n    with open(csv_file_path, 'r') as csv_file:\n        csv_reader = csv.DictReader(csv_file)\n        product_sales = collections.defaultdict(int)\n        for row in csv_reader:\n            product_sales[row['product']] += int(row['quantity'])\n    return max(product_sales.items(), key=operator.itemgetter(1))[0]", "raw_solution": "import csv\nimport collections\nimport operator\n\ndef task_func(csv_file_path):\n    with open(csv_file_path, 'r') as csv_file:\n        csv_reader = csv.DictReader(csv_file)\n        product_sales = collections.defaultdict(int)\n        for row in csv_reader:\n            product_sales[row['product']] += int(row['quantity'])\n    return max(product_sales.items(), key=operator.itemgetter(1))[0]\n\n# Test the function"}
{"task_id": "BigCodeBench/8", "solution": "from collections import Counter\nimport itertools\nfrom random import randint\ndef task_func(T1, RANGE=100):\n    # Convert elements in 'T1' to integers\n    T1 = list(map(int, T1))\n\n    # Calculate the sum of the integers in T1\n    sum_T1 = sum(T1)\n\n    # Generate a list of random integers\n    random_list = [randint(0, RANGE) for _ in range(sum_T1)]\n\n    # Count the occurrences of each number in the generated list\n    counter = Counter(random_list)\n\n    return counter\nT1 = ['1', '2', '3']", "raw_solution": "from collections import Counter\nimport itertools\nfrom random import randint\n\ndef task_func(T1, RANGE=100):\n    # Convert elements in 'T1' to integers\n    T1 = list(map(int, T1))\n\n    # Calculate the sum of the integers in T1\n    sum_T1 = sum(T1)\n\n    # Generate a list of random integers\n    random_list = [randint(0, RANGE) for _ in range(sum_T1)]\n\n    # Count the occurrences of each number in the generated list\n    counter = Counter(random_list)\n\n    return counter\n\n# Test the function\nT1 = ['1', '2', '3']"}
{"task_id": "BigCodeBench/9", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(list_of_pairs):\n    # Create a pandas DataFrame from the list of pairs\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    sns.barplot(x='Category', y='Value', data=df, ax=ax)\n    ax.set_title('Category vs Value')\n\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(list_of_pairs):\n    # Create a pandas DataFrame from the list of pairs\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    sns.barplot(x='Category', y='Value', data=df, ax=ax)\n    ax.set_title('Category vs Value')\n\n    return df, ax\n\n# Test the function\ndf, ax = task_func([('A', 10), ('B', 20), ('C', 15)])\nplt.show()"}
{"task_id": "BigCodeBench/10", "solution": "import numpy as np\nimport itertools\nimport random\nimport statistics\nfrom scipy import stats\ndef task_func(T1, RANGE=100):\n    # Convert elements in 'T1' to integers\n    try:\n        T1 = [int(i) for i in T1]\n    except ValueError:\n        raise ValueError(\"All elements in T1 should be convertible to integers.\")\n\n    # Create a list of random integers\n    try:\n        random_list = [random.randint(0, RANGE) for _ in range(sum(T1))]\n    except TypeError:\n        raise TypeError(\"T1 should be iterable.\")\n\n    # Calculate and return the mean, median, and mode of the list\n    try:\n        mean_val = statistics.mean(random_list)\n        median_val = statistics.median(random_list)\n        mode_val = int(stats.mode(random_list)[0])\n    except statistics.StatisticsError:\n        raise statistics.StatisticsError(\"T1 is empty or random_list is not properly generated.\")\n\n    return (mean_val, median_val, mode_val)", "raw_solution": "import numpy as np\nimport itertools\nimport random\nimport statistics\nfrom scipy import stats\n\ndef task_func(T1, RANGE=100):\n    # Convert elements in 'T1' to integers\n    try:\n        T1 = [int(i) for i in T1]\n    except ValueError:\n        raise ValueError(\"All elements in T1 should be convertible to integers.\")\n\n    # Create a list of random integers\n    try:\n        random_list = [random.randint(0, RANGE) for _ in range(sum(T1))]\n    except TypeError:\n        raise TypeError(\"T1 should be iterable.\")\n\n    # Calculate and return the mean, median, and mode of the list\n    try:\n        mean_val = statistics.mean(random_list)\n        median_val = statistics.median(random_list)\n        mode_val = int(stats.mode(random_list)[0])\n    except statistics.StatisticsError:\n        raise statistics.StatisticsError(\"T1 is empty or random_list is not properly generated.\")\n\n    return (mean_val, median_val, mode_val)"}
{"task_id": "BigCodeBench/11", "solution": "import numpy as np\nimport itertools\nimport random\ndef task_func(T1, max_value=100):\n    # Convert elements in 'T1' to integers\n    T1 = list(itertools.chain.from_iterable(T1))\n    T1 = [int(i) for i in T1]\n\n    # Create a list of random integers with size equal to the sum of 'T1'\n    random_list = [random.randint(0, max_value) for _ in range(sum(T1))]\n\n    # Calculate 25th, 50th, and 75th percentiles\n    p25 = np.percentile(random_list, 25)\n    p50 = np.percentile(random_list, 50)\n    p75 = np.percentile(random_list, 75)\n\n    return (p25, p50, p75)\nT1 = (('1', '2', '3'), ('4', '5', '6'), ('7', '8', '9'))", "raw_solution": "import numpy as np\nimport itertools\nimport random\n\ndef task_func(T1, max_value=100):\n    # Convert elements in 'T1' to integers\n    T1 = list(itertools.chain.from_iterable(T1))\n    T1 = [int(i) for i in T1]\n\n    # Create a list of random integers with size equal to the sum of 'T1'\n    random_list = [random.randint(0, max_value) for _ in range(sum(T1))]\n\n    # Calculate 25th, 50th, and 75th percentiles\n    p25 = np.percentile(random_list, 25)\n    p50 = np.percentile(random_list, 50)\n    p75 = np.percentile(random_list, 75)\n\n    return (p25, p50, p75)\n\n# Test the function\nT1 = (('1', '2', '3'), ('4', '5', '6'), ('7', '8', '9'))"}
{"task_id": "BigCodeBench/12", "solution": "import subprocess\nimport os\nimport json\nfrom datetime import datetime\ndef task_func(script_name='backup.sh', log_file='/home/user/backup_log.json'):\n    if not os.path.exists(script_name):\n        raise FileNotFoundError(f\"The script file {script_name} does not exist.\")\n\n    start_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    try:\n        subprocess.check_output(['bash', script_name])\n        exit_status = 0\n    except subprocess.CalledProcessError as e:\n        exit_status = e.returncode\n        raise RuntimeError(f\"There was an error executing the script: {str(e)}\")\n    end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n    log_data = {\n        'start_time': start_time,\n        'end_time': end_time,\n        'exit_status': exit_status\n    }\n\n    with open(log_file, 'w') as f:\n        json.dump(log_data, f)\n\n    return log_data", "raw_solution": "import subprocess\nimport os\nimport json\nfrom datetime import datetime\n\ndef task_func(script_name='backup.sh', log_file='/home/user/backup_log.json'):\n    if not os.path.exists(script_name):\n        raise FileNotFoundError(f\"The script file {script_name} does not exist.\")\n\n    start_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    try:\n        subprocess.check_output(['bash', script_name])\n        exit_status = 0\n    except subprocess.CalledProcessError as e:\n        exit_status = e.returncode\n        raise RuntimeError(f\"There was an error executing the script: {str(e)}\")\n    end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n    log_data = {\n        'start_time': start_time,\n        'end_time': end_time,\n        'exit_status': exit_status\n    }\n\n    with open(log_file, 'w') as f:\n        json.dump(log_data, f)\n\n    return log_data"}
{"task_id": "BigCodeBench/13", "solution": "import subprocess\nimport ftplib\nimport os\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    # List to store filenames\n    filenames = []\n\n    try:\n        # Connect to FTP server\n        ftp = ftplib.FTP(ftp_server)\n    except Exception as e:\n        print(f\"Failed to connect to FTP server {ftp_server}: {str(e)}\")\n        return filenames\n\n    try:\n        # Login to FTP server\n        ftp.login(ftp_user, ftp_password)\n    except Exception as e:\n        print(f\"Failed to log into FTP server {ftp_server} with user {ftp_user}: {str(e)}\")\n        return filenames\n\n    try:\n        # Change to the specified directory\n        ftp.cwd(ftp_dir)\n    except Exception as e:\n        print(f\"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n        return filenames\n\n    # Get a list of files in the directory\n    try:\n        ftp.retrlines('LIST', filenames.append)\n    except Exception as e:\n        print(f\"Failed to list files in directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n        return filenames\n\n    # Download files\n    for filename in filenames:\n        try:\n            with open(filename, 'wb') as file:\n                ftp.retrbinary('RETR ' + filename, file.write)\n        except Exception as e:\n            print(f\"Failed to download file {filename} from server {ftp_server}: {str(e)}\")\n\n    # Close FTP connection\n    ftp.quit()\n\n    return filenames", "raw_solution": "import subprocess\nimport ftplib\nimport os\n\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    # List to store filenames\n    filenames = []\n\n    try:\n        # Connect to FTP server\n        ftp = ftplib.FTP(ftp_server)\n    except Exception as e:\n        print(f\"Failed to connect to FTP server {ftp_server}: {str(e)}\")\n        return filenames\n\n    try:\n        # Login to FTP server\n        ftp.login(ftp_user, ftp_password)\n    except Exception as e:\n        print(f\"Failed to log into FTP server {ftp_server} with user {ftp_user}: {str(e)}\")\n        return filenames\n\n    try:\n        # Change to the specified directory\n        ftp.cwd(ftp_dir)\n    except Exception as e:\n        print(f\"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n        return filenames\n\n    # Get a list of files in the directory\n    try:\n        ftp.retrlines('LIST', filenames.append)\n    except Exception as e:\n        print(f\"Failed to list files in directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n        return filenames\n\n    # Download files\n    for filename in filenames:\n        try:\n            with open(filename, 'wb') as file:\n                ftp.retrbinary('RETR ' + filename, file.write)\n        except Exception as e:\n            print(f\"Failed to download file {filename} from server {ftp_server}: {str(e)}\")\n\n    # Close FTP connection\n    ftp.quit()\n\n    return filenames"}
{"task_id": "BigCodeBench/14", "solution": "import configparser\nimport os\nimport shutil\nimport zipfile\ndef task_func(config_file_path, archive_dir='/home/user/archive'):\n    # Check if config file exists\n    if not os.path.isfile(config_file_path):\n        raise FileNotFoundError(\"The specified config file does not exist.\")\n\n    # Parse config file\n    config = configparser.ConfigParser()\n    config.read(config_file_path)\n\n    # Check if project directory exists\n    project_dir = config['Project']['directory']\n    if not os.path.isdir(project_dir):\n        raise FileNotFoundError(\"The specified project directory does not exist.\")\n\n    # Create zip file name\n    zip_file_name = os.path.basename(project_dir) + '.zip'\n    zip_file_path = os.path.join(archive_dir, zip_file_name)\n\n    # Create zip file\n    try:\n        with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            for root, dirs, files in os.walk(project_dir):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    zipf.write(file_path, arcname=file)\n    except Exception as e:\n        raise Exception(\"Failed to create ZIP archive: \" + str(e))\n\n    return True", "raw_solution": "import configparser\nimport os\nimport shutil\nimport zipfile\n\ndef task_func(config_file_path, archive_dir='/home/user/archive'):\n    # Check if config file exists\n    if not os.path.isfile(config_file_path):\n        raise FileNotFoundError(\"The specified config file does not exist.\")\n\n    # Parse config file\n    config = configparser.ConfigParser()\n    config.read(config_file_path)\n\n    # Check if project directory exists\n    project_dir = config['Project']['directory']\n    if not os.path.isdir(project_dir):\n        raise FileNotFoundError(\"The specified project directory does not exist.\")\n\n    # Create zip file name\n    zip_file_name = os.path.basename(project_dir) + '.zip'\n    zip_file_path = os.path.join(archive_dir, zip_file_name)\n\n    # Create zip file\n    try:\n        with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            for root, dirs, files in os.walk(project_dir):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    zipf.write(file_path, arcname=file)\n    except Exception as e:\n        raise Exception(\"Failed to create ZIP archive: \" + str(e))\n\n    return True"}
{"task_id": "BigCodeBench/15", "solution": "import subprocess\nimport csv\nimport os\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(f\"The file {commands_file_path} does not exist.\")\n\n    if not os.path.exists(output_dir_path):\n        os.makedirs(output_dir_path)\n\n    output_file_paths = []\n\n    with open(commands_file_path, 'r') as commands_file:\n        reader = csv.reader(commands_file)\n        for i, row in enumerate(reader):\n            command = row[0]\n            output_file_path = os.path.join(output_dir_path, f'command_{i}_output.txt')\n            output_file_paths.append(output_file_path)\n\n            try:\n                result = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=60)\n                with open(output_file_path, 'w') as output_file:\n                    output_file.write(result.stdout)\n            except subprocess.CalledProcessError as e:\n                with open(output_file_path, 'w') as output_file:\n                    output_file.write(f\"Command execution failed with exit code {e.returncode}.\\n\")\n                    output_file.write(f\"Error message: {str(e)}\")\n\n    return output_file_paths", "raw_solution": "import subprocess\nimport csv\nimport os\n\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(f\"The file {commands_file_path} does not exist.\")\n\n    if not os.path.exists(output_dir_path):\n        os.makedirs(output_dir_path)\n\n    output_file_paths = []\n\n    with open(commands_file_path, 'r') as commands_file:\n        reader = csv.reader(commands_file)\n        for i, row in enumerate(reader):\n            command = row[0]\n            output_file_path = os.path.join(output_dir_path, f'command_{i}_output.txt')\n            output_file_paths.append(output_file_path)\n\n            try:\n                result = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=60)\n                with open(output_file_path, 'w') as output_file:\n                    output_file.write(result.stdout)\n            except subprocess.CalledProcessError as e:\n                with open(output_file_path, 'w') as output_file:\n                    output_file.write(f\"Command execution failed with exit code {e.returncode}.\\n\")\n                    output_file.write(f\"Error message: {str(e)}\")\n\n    return output_file_paths"}
{"task_id": "BigCodeBench/16", "solution": "import os\nimport glob\nimport subprocess\ndef task_func(directory, backup_dir='/path/to/backup'):\n    try:\n        if not os.path.exists(directory):\n            raise FileNotFoundError(\"The specified directory does not exist.\")\n\n        log_files = glob.glob(os.path.join(directory, '*.log'))\n\n        if not log_files:\n            return 'No logs found to backup'\n\n        backup_file = os.path.join(backup_dir, 'logs_backup.tar.gz')\n\n        with open(backup_file, 'wb') as outfile:\n            subprocess.run(['tar', '-czvf', outfile.name] + log_files, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n        # Delete original log files\n        for log_file in log_files:\n            os.remove(log_file)\n\n        return backup_file\n\n    except FileNotFoundError as fnf_error:\n        print(fnf_error)", "raw_solution": "import os\nimport glob\nimport subprocess\n\ndef task_func(directory, backup_dir='/path/to/backup'):\n    try:\n        if not os.path.exists(directory):\n            raise FileNotFoundError(\"The specified directory does not exist.\")\n\n        log_files = glob.glob(os.path.join(directory, '*.log'))\n\n        if not log_files:\n            return 'No logs found to backup'\n\n        backup_file = os.path.join(backup_dir, 'logs_backup.tar.gz')\n\n        with open(backup_file, 'wb') as outfile:\n            subprocess.run(['tar', '-czvf', outfile.name] + log_files, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n        # Delete original log files\n        for log_file in log_files:\n            os.remove(log_file)\n\n        return backup_file\n\n    except FileNotFoundError as fnf_error:\n        print(fnf_error)"}
{"task_id": "BigCodeBench/17", "solution": "import subprocess\nimport psutil\nimport time\ndef task_func(process_name: str) -> str:\n    for proc in psutil.process_iter(['pid', 'name']):\n        if proc.info['name'] == process_name:\n            # If process is running, terminate it\n            subprocess.Popen(['taskkill', '/F', '/IM', process_name])\n            return f\"Process found. Restarting {process_name}.\"\n    # If process is not running, start it\n    subprocess.Popen(process_name)\n    return f\"Process not found. Starting {process_name}.\"", "raw_solution": "import subprocess\nimport psutil\nimport time\n\ndef task_func(process_name: str) -> str:\n    for proc in psutil.process_iter(['pid', 'name']):\n        if proc.info['name'] == process_name:\n            # If process is running, terminate it\n            subprocess.Popen(['taskkill', '/F', '/IM', process_name])\n            return f\"Process found. Restarting {process_name}.\"\n    # If process is not running, start it\n    subprocess.Popen(process_name)\n    return f\"Process not found. Starting {process_name}.\"\n\n# Test the function"}
{"task_id": "BigCodeBench/18", "solution": "import subprocess\nimport csv\nimport glob\nimport random\nimport os\ndef task_func(file):\n    # Check if file exists\n    if not os.path.isfile(file):\n        print(f\"File {file} does not exist.\")\n        return []\n\n    # Check if file is a CSV file\n    if not file.endswith('.csv'):\n        print(f\"File {file} is not a CSV file.\")\n        return []\n\n    # Split the file into smaller files\n    try:\n        subprocess.run([\"split\", \"-l\", \"1000\", file, \"split_\"], check=True)\n    except subprocess.CalledProcessError as e:\n        print(f\"Error occurred while splitting the file: {e}\")\n        return []\n\n    # Get the paths to the split files\n    split_files = glob.glob(\"split_*\")\n\n    # Shuffle the rows in each of the split files\n    for split_file in split_files:\n        with open(split_file, 'r') as f:\n            lines = f.readlines()\n            random.shuffle(lines)\n        with open(split_file, 'w') as f:\n            f.writelines(lines)\n\n    return split_files", "raw_solution": "import subprocess\nimport csv\nimport glob\nimport random\nimport os\n\ndef task_func(file):\n    # Check if file exists\n    if not os.path.isfile(file):\n        print(f\"File {file} does not exist.\")\n        return []\n\n    # Check if file is a CSV file\n    if not file.endswith('.csv'):\n        print(f\"File {file} is not a CSV file.\")\n        return []\n\n    # Split the file into smaller files\n    try:\n        subprocess.run([\"split\", \"-l\", \"1000\", file, \"split_\"], check=True)\n    except subprocess.CalledProcessError as e:\n        print(f\"Error occurred while splitting the file: {e}\")\n        return []\n\n    # Get the paths to the split files\n    split_files = glob.glob(\"split_*\")\n\n    # Shuffle the rows in each of the split files\n    for split_file in split_files:\n        with open(split_file, 'r') as f:\n            lines = f.readlines()\n            random.shuffle(lines)\n        with open(split_file, 'w') as f:\n            f.writelines(lines)\n\n    return split_files"}
{"task_id": "BigCodeBench/19", "solution": "import os\nimport glob\nimport zipfile\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n\n    files = glob.glob(os.path.join(directory, '*'))\n    files = [f for f in files if os.path.isfile(f)]  # filter out directories\n\n    if not files:\n        return None\n\n    zip_path = os.path.join(directory, 'files.zip')\n\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file in files:\n            zipf.write(file, os.path.basename(file))\n\n    return zip_path", "raw_solution": "import os\nimport glob\nimport zipfile\n\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n\n    files = glob.glob(os.path.join(directory, '*'))\n    files = [f for f in files if os.path.isfile(f)]  # filter out directories\n\n    if not files:\n        return None\n\n    zip_path = os.path.join(directory, 'files.zip')\n\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file in files:\n            zipf.write(file, os.path.basename(file))\n\n    return zip_path"}
{"task_id": "BigCodeBench/20", "solution": "import ast\nimport pandas as pd\nimport seaborn as sns\ndef task_func(csv_file):\n    # Read the CSV file\n    df = pd.read_csv(csv_file)\n\n    # Convert the string representations of dictionaries in 'dict_column' to Python dictionaries\n    df['dict_column'] = df['dict_column'].apply(lambda x: ast.literal_eval(x))\n\n    # Visualize the data with Seaborn's pairplot\n    ax = sns.pairplot(df)\n\n    return df, ax", "raw_solution": "import ast\nimport pandas as pd\nimport seaborn as sns\n\ndef task_func(csv_file):\n    # Read the CSV file\n    df = pd.read_csv(csv_file)\n\n    # Convert the string representations of dictionaries in 'dict_column' to Python dictionaries\n    df['dict_column'] = df['dict_column'].apply(lambda x: ast.literal_eval(x))\n\n    # Visualize the data with Seaborn's pairplot\n    ax = sns.pairplot(df)\n\n    return df, ax"}
{"task_id": "BigCodeBench/21", "solution": "import psutil\nimport platform\ndef task_func():\n    # Get system details\n    os_name = platform.system()\n    architecture = platform.architecture()[0]\n\n    # Get memory details\n    memory = psutil.virtual_memory()\n    total_memory = memory.total / (1024.0 ** 3)  # Convert bytes to GB\n    used_memory = memory.used / (1024.0 ** 3)  # Convert bytes to GB\n\n    # Calculate memory usage\n    memory_usage = (used_memory / total_memory) * 100\n\n    # Create dictionary\n    system_details = {\n        'OS': os_name,\n        'Architecture': architecture,\n        'Memory Usage': f'{memory_usage:.2f}%'  # Format to 2 decimal places\n    }\n\n    return system_details", "raw_solution": "import psutil\nimport platform\n\ndef task_func():\n    # Get system details\n    os_name = platform.system()\n    architecture = platform.architecture()[0]\n\n    # Get memory details\n    memory = psutil.virtual_memory()\n    total_memory = memory.total / (1024.0 ** 3)  # Convert bytes to GB\n    used_memory = memory.used / (1024.0 ** 3)  # Convert bytes to GB\n\n    # Calculate memory usage\n    memory_usage = (used_memory / total_memory) * 100\n\n    # Create dictionary\n    system_details = {\n        'OS': os_name,\n        'Architecture': architecture,\n        'Memory Usage': f'{memory_usage:.2f}%'  # Format to 2 decimal places\n    }\n\n    return system_details\n\n# Test the function"}
{"task_id": "BigCodeBench/22", "solution": "import collections\nfrom itertools import zip_longest\nfrom random import choices\ndef task_func(l1, l2, K=10):\n    # Combine two lists by alternating their elements\n    combined = [item for sublist in zip_longest(l1, l2) for item in sublist if item is not None]\n    \n    # Create a random sample of size K from the combined list\n    sample = choices(combined, k=K)\n    \n    # Calculate the frequency of each element in the sample\n    freq = collections.Counter(sample)\n    \n    return freq", "raw_solution": "import collections\nfrom itertools import zip_longest\nfrom random import choices\n\ndef task_func(l1, l2, K=10):\n    # Combine two lists by alternating their elements\n    combined = [item for sublist in zip_longest(l1, l2) for item in sublist if item is not None]\n    \n    # Create a random sample of size K from the combined list\n    sample = choices(combined, k=K)\n    \n    # Calculate the frequency of each element in the sample\n    freq = collections.Counter(sample)\n    \n    return freq"}
{"task_id": "BigCodeBench/23", "solution": "import numpy as np\nfrom itertools import zip_longest\ndef task_func(l1, l2, THRESHOLD=0.5):\n    # Filter out non-numeric elements\n    l1 = [i for i in l1 if isinstance(i, (int, float))]\n    l2 = [i for i in l2 if isinstance(i, (int, float))]\n\n    # Alternate elements from the two lists\n    l1_l2 = [i for pair in zip_longest(l1, l2) for i in pair if i is not None]\n\n    # Calculate the absolute difference of each element from the threshold\n    diffs = [abs(i - THRESHOLD) for i in l1_l2]\n\n    # Return the element closest to the threshold\n    return l1_l2[np.argmin(diffs)]\nl1 = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\nl2 = [0.4, 0.3, 0.2, 0.1]", "raw_solution": "import numpy as np\nfrom itertools import zip_longest\n\ndef task_func(l1, l2, THRESHOLD=0.5):\n    # Filter out non-numeric elements\n    l1 = [i for i in l1 if isinstance(i, (int, float))]\n    l2 = [i for i in l2 if isinstance(i, (int, float))]\n\n    # Alternate elements from the two lists\n    l1_l2 = [i for pair in zip_longest(l1, l2) for i in pair if i is not None]\n\n    # Calculate the absolute difference of each element from the threshold\n    diffs = [abs(i - THRESHOLD) for i in l1_l2]\n\n    # Return the element closest to the threshold\n    return l1_l2[np.argmin(diffs)]\n\n# Test the function\nl1 = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\nl2 = [0.4, 0.3, 0.2, 0.1]"}
{"task_id": "BigCodeBench/24", "solution": "import base64\nimport hashlib\nimport os\nfrom typing import Tuple\ndef task_func(password: str, SALT_LENGTH: int = 32) -> Tuple[bytes, bytes]:\n    if not password:\n        raise ValueError(\"Password cannot be None or empty\")\n\n    # Generate a random salt\n    salt = os.urandom(SALT_LENGTH)\n\n    # Hash the password with the salt\n    hashed_password = hashlib.pbkdf2_hmac('sha256', password.encode(), salt, 100000)\n\n    # Return the salt and hashed password, base64 encoded\n    return (base64.b64encode(salt), base64.b64encode(hashed_password))", "raw_solution": "import base64\nimport hashlib\nimport os\nfrom typing import Tuple\n\ndef task_func(password: str, SALT_LENGTH: int = 32) -> Tuple[bytes, bytes]:\n    if not password:\n        raise ValueError(\"Password cannot be None or empty\")\n\n    # Generate a random salt\n    salt = os.urandom(SALT_LENGTH)\n\n    # Hash the password with the salt\n    hashed_password = hashlib.pbkdf2_hmac('sha256', password.encode(), salt, 100000)\n\n    # Return the salt and hashed password, base64 encoded\n    return (base64.b64encode(salt), base64.b64encode(hashed_password))"}
{"task_id": "BigCodeBench/25", "solution": "import base64\nimport json\nimport zlib\ndef task_func(data_dict):\n    # Convert dictionary to JSON string\n    json_str = json.dumps(data_dict)\n\n    # Compress the JSON string\n    compressed_data = zlib.compress(json_str.encode('utf-8'))\n\n    # Encode the compressed data with base64\n    base64_encoded_data = base64.b64encode(compressed_data)\n\n    # Convert the bytes to a string and return\n    return base64_encoded_data.decode('utf-8')\ndata_dict = {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}", "raw_solution": "import base64\nimport json\nimport zlib\n\ndef task_func(data_dict):\n    # Convert dictionary to JSON string\n    json_str = json.dumps(data_dict)\n\n    # Compress the JSON string\n    compressed_data = zlib.compress(json_str.encode('utf-8'))\n\n    # Encode the compressed data with base64\n    base64_encoded_data = base64.b64encode(compressed_data)\n\n    # Convert the bytes to a string and return\n    return base64_encoded_data.decode('utf-8')\n\n# Test the function\ndata_dict = {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}"}
{"task_id": "BigCodeBench/26", "solution": "import base64\nfrom cryptography.fernet import Fernet\ndef task_func(message, encryption_key):\n    # Create a Fernet object with the encryption key\n    cipher_suite = Fernet(encryption_key)\n\n    # Encrypt the message\n    encrypted_message = cipher_suite.encrypt(message.encode())\n\n    # Encode the encrypted message using base64\n    base64_encoded_message = base64.b64encode(encrypted_message)\n\n    # Return the base64 encoded encrypted message\n    return base64_encoded_message.decode()\nmessage = \"Hello, World!\"", "raw_solution": "import base64\nfrom cryptography.fernet import Fernet\n\ndef task_func(message, encryption_key):\n    # Create a Fernet object with the encryption key\n    cipher_suite = Fernet(encryption_key)\n\n    # Encrypt the message\n    encrypted_message = cipher_suite.encrypt(message.encode())\n\n    # Encode the encrypted message using base64\n    base64_encoded_message = base64.b64encode(encrypted_message)\n\n    # Return the base64 encoded encrypted message\n    return base64_encoded_message.decode()\n\n# Test the function\nmessage = \"Hello, World!\"\nkey = Fernet.generate_key()\nencoded_message = task_func(message, key)"}
{"task_id": "BigCodeBench/27", "solution": "import json\nimport base64\nfrom datetime import datetime\ndef task_func(data: dict, DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\") -> str:\n    # Add current timestamp to the dictionary\n    data['timestamp'] = datetime.now().strftime(DATE_FORMAT)\n\n    # Convert the dictionary to a JSON-formatted string\n    json_str = json.dumps(data)\n\n    # Encode the JSON string using base64 and ASCII character encoding\n    encoded_str = base64.b64encode(json_str.encode('ascii'))\n\n    # Return the base64 encoded string\n    return encoded_str.decode('ascii')\ndata = {'name': 'John', 'age': 30, 'city': 'New York'}", "raw_solution": "import json\nimport base64\nfrom datetime import datetime\n\ndef task_func(data: dict, DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\") -> str:\n    # Add current timestamp to the dictionary\n    data['timestamp'] = datetime.now().strftime(DATE_FORMAT)\n\n    # Convert the dictionary to a JSON-formatted string\n    json_str = json.dumps(data)\n\n    # Encode the JSON string using base64 and ASCII character encoding\n    encoded_str = base64.b64encode(json_str.encode('ascii'))\n\n    # Return the base64 encoded string\n    return encoded_str.decode('ascii')\n\n# Test the function\ndata = {'name': 'John', 'age': 30, 'city': 'New York'}"}
{"task_id": "BigCodeBench/28", "solution": "import requests\nimport json\nimport base64\ndef task_func(data, url=\"http://your-api-url.com\"):\n    # Convert the dictionary to a JSON-formatted string\n    json_str = json.dumps(data)\n\n    # Encode the JSON-formatted string in base64 format\n    encoded_str = base64.b64encode(json_str.encode('utf-8')).decode('utf-8')\n\n    # Create a payload with the base64-encoded string\n    payload = {'payload': encoded_str}\n\n    # Send a POST request to the API endpoint with the payload\n    response = requests.post(url, data=payload)\n\n    return response", "raw_solution": "import requests\nimport json\nimport base64\n\ndef task_func(data, url=\"http://your-api-url.com\"):\n    # Convert the dictionary to a JSON-formatted string\n    json_str = json.dumps(data)\n\n    # Encode the JSON-formatted string in base64 format\n    encoded_str = base64.b64encode(json_str.encode('utf-8')).decode('utf-8')\n\n    # Create a payload with the base64-encoded string\n    payload = {'payload': encoded_str}\n\n    # Send a POST request to the API endpoint with the payload\n    response = requests.post(url, data=payload)\n\n    return response"}
{"task_id": "BigCodeBench/29", "solution": "from sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport base64\ndef task_func(data):\n    # Standardize the data\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data)\n\n    # Convert the standardized data to a string\n    standardized_str = str(standardized_data.tolist())\n\n    # Encode the string in base64\n    base64_bytes = base64.b64encode(standardized_str.encode('ascii'))\n\n    # Convert the base64 bytes to a string\n    base64_str = base64_bytes.decode('ascii')\n\n    return base64_str\ndata = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])", "raw_solution": "from sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport base64\n\ndef task_func(data):\n    # Standardize the data\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data)\n\n    # Convert the standardized data to a string\n    standardized_str = str(standardized_data.tolist())\n\n    # Encode the string in base64\n    base64_bytes = base64.b64encode(standardized_str.encode('ascii'))\n\n    # Convert the base64 bytes to a string\n    base64_str = base64_bytes.decode('ascii')\n\n    return base64_str\n\n# Test the function\ndata = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"}
{"task_id": "BigCodeBench/30", "solution": "import json\nimport os\nimport re\ndef task_func(\n    file_path,\n    attribute,\n    INPUT_JSON={\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\"type\": \"string\"},  \n            \"age\": {\"type\": \"number\"},   \n            \"email\": {\"type\": \"string\"}  \n        },\n        \"required\": [\"name\", \"age\", \"email\"]\n    },\n    EMAIL_REGEX=r\"^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$\"):\n\n    # Check if file exists\n    if not os.path.isfile(file_path):\n        raise ValueError(\"File does not exist.\")\n\n    # Load JSON file\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n\n    # Validate JSON structure\n    if not isinstance(data, dict):\n        raise ValueError(\"JSON data is not an object.\")\n\n    # Validate JSON against schema\n    if not INPUT_JSON['type'] == 'object':\n        raise ValueError(\"Invalid JSON schema.\")\n\n    for prop, schema in INPUT_JSON['properties'].items():\n        if prop not in data:\n            raise ValueError(f\"Missing required attribute: {prop}\")\n        if not isinstance(data[prop], schema['type']):\n            raise ValueError(f\"Attribute {prop} has invalid type.\")\n\n    # Check email format\n    if not re.match(EMAIL_REGEX, data['email']):\n        raise ValueError(\"Invalid email format.\")\n\n    # Return specified attribute\n    if attribute in data:\n        return data[attribute]\n    else:\n        raise ValueError(f\"Attribute not found: {attribute}\")", "raw_solution": "import json\nimport os\nimport re\n\ndef task_func(\n    file_path,\n    attribute,\n    INPUT_JSON={\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\"type\": \"string\"},  \n            \"age\": {\"type\": \"number\"},   \n            \"email\": {\"type\": \"string\"}  \n        },\n        \"required\": [\"name\", \"age\", \"email\"]\n    },\n    EMAIL_REGEX=r\"^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$\"):\n\n    # Check if file exists\n    if not os.path.isfile(file_path):\n        raise ValueError(\"File does not exist.\")\n\n    # Load JSON file\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n\n    # Validate JSON structure\n    if not isinstance(data, dict):\n        raise ValueError(\"JSON data is not an object.\")\n\n    # Validate JSON against schema\n    if not INPUT_JSON['type'] == 'object':\n        raise ValueError(\"Invalid JSON schema.\")\n\n    for prop, schema in INPUT_JSON['properties'].items():\n        if prop not in data:\n            raise ValueError(f\"Missing required attribute: {prop}\")\n        if not isinstance(data[prop], schema['type']):\n            raise ValueError(f\"Attribute {prop} has invalid type.\")\n\n    # Check email format\n    if not re.match(EMAIL_REGEX, data['email']):\n        raise ValueError(\"Invalid email format.\")\n\n    # Return specified attribute\n    if attribute in data:\n        return data[attribute]\n    else:\n        raise ValueError(f\"Attribute not found: {attribute}\")"}
{"task_id": "BigCodeBench/31", "solution": "import nltk\nfrom string import punctuation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nPUNCTUATION = set(punctuation)\ndef task_func(text):\n    # Tokenize the text\n    words = nltk.word_tokenize(text)\n    \n    # Filter words that start with '$' and are not only punctuation\n    dollar_words = [word for word in words if word.startswith('$') and not all(char in PUNCTUATION for char in word[1:])]\n    \n    # If there are no such words, return None\n    if not dollar_words:\n        return None\n    \n    # Count the frequency of each word\n    word_freq = Counter(dollar_words)\n    \n    # Create a bar plot\n    fig, ax = plt.subplots(figsize=(10, 6))\n    sns.barplot(x=list(word_freq.keys()), y=list(word_freq.values()), ax=ax)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of words beginning with $')\n    \n    return ax", "raw_solution": "import nltk\nfrom string import punctuation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n# Constants\nPUNCTUATION = set(punctuation)\n\ndef task_func(text):\n    # Tokenize the text\n    words = nltk.word_tokenize(text)\n    \n    # Filter words that start with '$' and are not only punctuation\n    dollar_words = [word for word in words if word.startswith('$') and not all(char in PUNCTUATION for char in word[1:])]\n    \n    # If there are no such words, return None\n    if not dollar_words:\n        return None\n    \n    # Count the frequency of each word\n    word_freq = Counter(dollar_words)\n    \n    # Create a bar plot\n    fig, ax = plt.subplots(figsize=(10, 6))\n    sns.barplot(x=list(word_freq.keys()), y=list(word_freq.values()), ax=ax)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of words beginning with $')\n    \n    return ax"}
{"task_id": "BigCodeBench/32", "solution": "import requests\nfrom bs4 import BeautifulSoup\ndef task_func(url, tag):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tag_content = soup.find(tag)\n    if tag_content is not None:\n        return tag_content.text\n    else:\n        return None\nurl = 'https://www.example.com'\ntag = 'h1'", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\n\ndef task_func(url, tag):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tag_content = soup.find(tag)\n    if tag_content is not None:\n        return tag_content.text\n    else:\n        return None\n\n# Test the function\nurl = 'https://www.example.com'\ntag = 'h1'"}
{"task_id": "BigCodeBench/33", "solution": "import numpy as np\nfrom functools import reduce\ndef task_func(list_of_pairs):\n    # Extract the second elements of each tuple in the list\n    second_elements = [pair[1] for pair in list_of_pairs]\n    \n    # Calculate the product of the second elements\n    product = reduce(lambda x, y: x * y, second_elements)\n    \n    # Return the product as a numpy array\n    return np.array([product])\nlist_of_pairs = [(1, 2), (3, 4), (5, 6)]", "raw_solution": "import numpy as np\nfrom functools import reduce\n\ndef task_func(list_of_pairs):\n    # Extract the second elements of each tuple in the list\n    second_elements = [pair[1] for pair in list_of_pairs]\n    \n    # Calculate the product of the second elements\n    product = reduce(lambda x, y: x * y, second_elements)\n    \n    # Return the product as a numpy array\n    return np.array([product])\n\n# Test the function\nlist_of_pairs = [(1, 2), (3, 4), (5, 6)]"}
{"task_id": "BigCodeBench/34", "solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Remove URLs from text\n    url_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    text = re.sub(url_pattern, '', text)\n\n    # Split text into words\n    words = text.split()\n\n    # If there are no words available, raise an exception\n    if not words:\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n\n    # Join words back into a string\n    text = ' '.join(words)\n\n    # Generate word cloud\n    wordcloud = WordCloud().generate(text)\n\n    # Plot word cloud\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n\n    return wordcloud", "raw_solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Remove URLs from text\n    url_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    text = re.sub(url_pattern, '', text)\n\n    # Split text into words\n    words = text.split()\n\n    # If there are no words available, raise an exception\n    if not words:\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n\n    # Join words back into a string\n    text = ' '.join(words)\n\n    # Generate word cloud\n    wordcloud = WordCloud().generate(text)\n\n    # Plot word cloud\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n\n    return wordcloud"}
{"task_id": "BigCodeBench/35", "solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df, target_values=[1, 3, 4]):\n    # Replace all elements in DataFrame columns that do not exist in the target_values array with zeros\n    df.loc[~df.isin(target_values).all(axis=1), :] = 0\n\n    # Plot the distribution of each column after replacing\n    for col in df.columns:\n        plt.figure(figsize=(10, 6))\n        sns.histplot(df[col], kde=False, color='skyblue', bins=30)\n        plt.title(f'Distribution of {col}')\n        plt.show()\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n    'B': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n    'C': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n    'D': [1, 2, 2, 2, 3, 4, 4, 4, 5, 5]\n})", "raw_solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, target_values=[1, 3, 4]):\n    # Replace all elements in DataFrame columns that do not exist in the target_values array with zeros\n    df.loc[~df.isin(target_values).all(axis=1), :] = 0\n\n    # Plot the distribution of each column after replacing\n    for col in df.columns:\n        plt.figure(figsize=(10, 6))\n        sns.histplot(df[col], kde=False, color='skyblue', bins=30)\n        plt.title(f'Distribution of {col}')\n        plt.show()\n\n# Test the function\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n    'B': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n    'C': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n    'D': [1, 2, 2, 2, 3, 4, 4, 4, 5, 5]\n})\n\ntask_func(df, [1, 2, 3, 4])"}
{"task_id": "BigCodeBench/36", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport pandas as pd\nTARGET_VALUES = np.array([1, 3, 4])\ndef task_func(df):\n    # Replace all elements in DataFrame columns that do not exist in the TARGET_VALUES array with zeros\n    df = df.replace(set(df.values.flatten()) - set(TARGET_VALUES), 0)\n\n    # Perform a Box-Cox transformation on each column (if data is not constant, add 1 to account for zeros)\n    for col in df.columns:\n        df[col] = stats.boxcox(df[col] + 1)[0] if df[col].std() != 0 else df[col]\n\n    # Create a new figure\n    fig = plt.figure(figsize=(10, 10))\n\n    # Plot KDE plots for each column\n    for i, col in enumerate(df.columns):\n        ax = fig.add_subplot(3, 3, i+1)\n        df[col].plot(kind='kde', ax=ax)\n        ax.set_title(col)\n\n    plt.tight_layout()\n\n    return df, fig", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nTARGET_VALUES = np.array([1, 3, 4])\n\ndef task_func(df):\n    # Replace all elements in DataFrame columns that do not exist in the TARGET_VALUES array with zeros\n    df = df.replace(set(df.values.flatten()) - set(TARGET_VALUES), 0)\n\n    # Perform a Box-Cox transformation on each column (if data is not constant, add 1 to account for zeros)\n    for col in df.columns:\n        df[col] = stats.boxcox(df[col] + 1)[0] if df[col].std() != 0 else df[col]\n\n    # Create a new figure\n    fig = plt.figure(figsize=(10, 10))\n\n    # Plot KDE plots for each column\n    for i, col in enumerate(df.columns):\n        ax = fig.add_subplot(3, 3, i+1)\n        df[col].plot(kind='kde', ax=ax)\n        ax.set_title(col)\n\n    plt.tight_layout()\n\n    return df, fig"}
{"task_id": "BigCodeBench/37", "solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df, target_column):\n    # Split the data into features and target\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    # Train the random forest classifier\n    clf = RandomForestClassifier(random_state=42)\n    clf.fit(X, y)\n\n    # Get the feature importances\n    importances = clf.feature_importances_\n\n    # Create a dataframe for the feature importances\n    df_importances = pd.DataFrame({\n        'Features': X.columns,\n        'Importance': importances\n    })\n\n    # Sort the dataframe by importance\n    df_importances = df_importances.sort_values('Importance', ascending=False)\n\n    # Plot the feature importances\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Features', data=df_importances)\n    plt.xlabel('Feature Importance Score')\n    plt.ylabel('Features')\n    plt.title('Visualizing Important Features')\n    plt.tight_layout()\n\n    return clf, plt.gca()", "raw_solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, target_column):\n    # Split the data into features and target\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    # Train the random forest classifier\n    clf = RandomForestClassifier(random_state=42)\n    clf.fit(X, y)\n\n    # Get the feature importances\n    importances = clf.feature_importances_\n\n    # Create a dataframe for the feature importances\n    df_importances = pd.DataFrame({\n        'Features': X.columns,\n        'Importance': importances\n    })\n\n    # Sort the dataframe by importance\n    df_importances = df_importances.sort_values('Importance', ascending=False)\n\n    # Plot the feature importances\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Features', data=df_importances)\n    plt.xlabel('Feature Importance Score')\n    plt.ylabel('Features')\n    plt.title('Visualizing Important Features')\n    plt.tight_layout()\n\n    return clf, plt.gca()"}
{"task_id": "BigCodeBench/38", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nFEATURE_NAMES = [\"Feature 1\", \"Feature 2\", \"Feature 3\", \"Feature 4\", \"Feature 5\"]\ndef task_func(data_matrix):\n    # Standardize the data\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data_matrix)\n\n    # Calculate the mean of each row\n    means = standardized_data.mean(axis=1)\n\n    # Create a DataFrame\n    df = pd.DataFrame(standardized_data, columns=FEATURE_NAMES)\n    df['Mean'] = means\n\n    # Plot the distribution of the means\n    plt.figure(figsize=(10, 6))\n    plt.hist(means, bins=30, color='skyblue', ec='black')\n    plt.title('Distribution of Means')\n    plt.xlabel('Mean')\n    plt.ylabel('Frequency')\n    plot = plt.gca()\n\n    return df, plot", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Constants\nFEATURE_NAMES = [\"Feature 1\", \"Feature 2\", \"Feature 3\", \"Feature 4\", \"Feature 5\"]\n\ndef task_func(data_matrix):\n    # Standardize the data\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data_matrix)\n\n    # Calculate the mean of each row\n    means = standardized_data.mean(axis=1)\n\n    # Create a DataFrame\n    df = pd.DataFrame(standardized_data, columns=FEATURE_NAMES)\n    df['Mean'] = means\n\n    # Plot the distribution of the means\n    plt.figure(figsize=(10, 6))\n    plt.hist(means, bins=30, color='skyblue', ec='black')\n    plt.title('Distribution of Means')\n    plt.xlabel('Mean')\n    plt.ylabel('Frequency')\n    plot = plt.gca()\n\n    return df, plot"}
{"task_id": "BigCodeBench/39", "solution": "import numpy as np\nfrom scipy.stats import ttest_1samp\nimport matplotlib.pyplot as plt\nALPHA = 0.05\ndef task_func(data_matrix):\n    # Calculate the mean value of each row in the data matrix\n    row_means = np.mean(data_matrix, axis=1)\n\n    # Calculate the population mean\n    pop_mean = np.mean(data_matrix)\n\n    # Run a t-test from a sample against the population value\n    t_stat, p_val = ttest_1samp(row_means, pop_mean)\n\n    # Record the mean values that differ significantly\n    significant_indices = [i for i in range(len(p_val)) if p_val[i] < ALPHA]\n\n    # Create a lineplot with the mean of rows in red\n    plt.plot(row_means, color='red', label='Means')\n\n    # Create a line plot with the significant_indices on the x-axis and the corresponding means on the y-axis\n    plt.plot(significant_indices, row_means[significant_indices], color='blue', label='Significant Means')\n\n    # Create an horizontal line which represent the mean computed on the whole 2D matrix\n    plt.axhline(y=pop_mean, color='green', label='Population Mean')\n\n    plt.legend()\n    plt.show()\n\n    return significant_indices, plt.gca()", "raw_solution": "import numpy as np\nfrom scipy.stats import ttest_1samp\nimport matplotlib.pyplot as plt\n\n# Constants\nALPHA = 0.05\n\ndef task_func(data_matrix):\n    # Calculate the mean value of each row in the data matrix\n    row_means = np.mean(data_matrix, axis=1)\n\n    # Calculate the population mean\n    pop_mean = np.mean(data_matrix)\n\n    # Run a t-test from a sample against the population value\n    t_stat, p_val = ttest_1samp(row_means, pop_mean)\n\n    # Record the mean values that differ significantly\n    significant_indices = [i for i in range(len(p_val)) if p_val[i] < ALPHA]\n\n    # Create a lineplot with the mean of rows in red\n    plt.plot(row_means, color='red', label='Means')\n\n    # Create a line plot with the significant_indices on the x-axis and the corresponding means on the y-axis\n    plt.plot(significant_indices, row_means[significant_indices], color='blue', label='Significant Means')\n\n    # Create an horizontal line which represent the mean computed on the whole 2D matrix\n    plt.axhline(y=pop_mean, color='green', label='Population Mean')\n\n    plt.legend()\n    plt.show()\n\n    return significant_indices, plt.gca()"}
{"task_id": "BigCodeBench/40", "solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy.stats import zscore\nimport matplotlib.pyplot as plt\ndef task_func(data_matrix):\n    # Calculate the Z-values of a 2D data matrix\n    z_scores = pd.DataFrame(zscore(data_matrix, axis=1), columns=data_matrix.columns)\n    \n    # Calculate the mean value of each row\n    z_scores['Mean'] = z_scores.mean(axis=1)\n    \n    # Visualize the correlation matrix of the Z-values with a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(z_scores.corr(), annot=True, cmap='coolwarm')\n    plt.title('Correlation Matrix of Z-Scores')\n    plt.show()\n    \n    return z_scores, plt.gca()", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy.stats import zscore\nimport matplotlib.pyplot as plt\n\ndef task_func(data_matrix):\n    # Calculate the Z-values of a 2D data matrix\n    z_scores = pd.DataFrame(zscore(data_matrix, axis=1), columns=data_matrix.columns)\n    \n    # Calculate the mean value of each row\n    z_scores['Mean'] = z_scores.mean(axis=1)\n    \n    # Visualize the correlation matrix of the Z-values with a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(z_scores.corr(), annot=True, cmap='coolwarm')\n    plt.title('Correlation Matrix of Z-Scores')\n    plt.show()\n    \n    return z_scores, plt.gca()"}
{"task_id": "BigCodeBench/41", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\ndef task_func(data_matrix):\n    # Convert the data matrix to a pandas DataFrame\n    df = pd.DataFrame(data_matrix)\n    \n    # Calculate the skewness of each row and store it in a new column 'Skewness'\n    df['Skewness'] = df.apply(lambda row: skew(row), axis=1)\n    \n    # Plot the distribution of the skewness\n    fig, ax = plt.subplots()\n    df['Skewness'].plot(kind='hist', ax=ax)\n    ax.set_xlabel('Skewness')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution of Skewness')\n    \n    return df, ax.figure\ndata_matrix = [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15]]", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\n\ndef task_func(data_matrix):\n    # Convert the data matrix to a pandas DataFrame\n    df = pd.DataFrame(data_matrix)\n    \n    # Calculate the skewness of each row and store it in a new column 'Skewness'\n    df['Skewness'] = df.apply(lambda row: skew(row), axis=1)\n    \n    # Plot the distribution of the skewness\n    fig, ax = plt.subplots()\n    df['Skewness'].plot(kind='hist', ax=ax)\n    ax.set_xlabel('Skewness')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution of Skewness')\n    \n    return df, ax.figure\n\n# Test the function\ndata_matrix = [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15]]\ndf, fig = task_func(data_matrix)"}
{"task_id": "BigCodeBench/42", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nimport numpy as np\ndef task_func(data_matrix, n_components=2):\n    # Apply PCA\n    pca = PCA(n_components=n_components)\n    pca_result = pca.fit_transform(data_matrix)\n\n    # Create DataFrame\n    df = pd.DataFrame(pca_result, columns=['Component {}'.format(i+1) for i in range(n_components)])\n    df['Mean'] = df.mean(axis=1)\n\n    # Calculate explained variance\n    explained_variance = pca.explained_variance_ratio_\n    cumulative_explained_variance = np.cumsum(explained_variance)\n\n    # Plot explained variance\n    plt.plot(range(1, n_components+1), cumulative_explained_variance)\n    plt.xlabel('Number of Components')\n    plt.ylabel('Cumulative Explained Variance')\n    plt.grid(True)\n\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nimport numpy as np\n\ndef task_func(data_matrix, n_components=2):\n    # Apply PCA\n    pca = PCA(n_components=n_components)\n    pca_result = pca.fit_transform(data_matrix)\n\n    # Create DataFrame\n    df = pd.DataFrame(pca_result, columns=['Component {}'.format(i+1) for i in range(n_components)])\n    df['Mean'] = df.mean(axis=1)\n\n    # Calculate explained variance\n    explained_variance = pca.explained_variance_ratio_\n    cumulative_explained_variance = np.cumsum(explained_variance)\n\n    # Plot explained variance\n    plt.plot(range(1, n_components+1), cumulative_explained_variance)\n    plt.xlabel('Number of Components')\n    plt.ylabel('Cumulative Explained Variance')\n    plt.grid(True)\n\n    return df, plt.gca()"}
{"task_id": "BigCodeBench/43", "solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    # Calculate the mean of each column\n    mean_values = df.mean()\n\n    # Replace NaN values with the mean of the column\n    df.fillna(mean_values, inplace=True)\n\n    # Describe the dataframe\n    df_stats = df.describe()\n\n    # Initialize a list to hold the axes objects\n    axes = []\n\n    # Loop through each column in the dataframe\n    for col in df.select_dtypes(include=[np.number]):\n        # Create a new figure\n        fig, ax = plt.subplots()\n\n        # Plot a histogram of the column\n        sns.histplot(df[col], bins=10, ax=ax)\n\n        # Add the axes to the list\n        axes.append(ax)\n\n    # Return the dataframe statistics and the list of axes\n    return (df_stats, axes)", "raw_solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    # Calculate the mean of each column\n    mean_values = df.mean()\n\n    # Replace NaN values with the mean of the column\n    df.fillna(mean_values, inplace=True)\n\n    # Describe the dataframe\n    df_stats = df.describe()\n\n    # Initialize a list to hold the axes objects\n    axes = []\n\n    # Loop through each column in the dataframe\n    for col in df.select_dtypes(include=[np.number]):\n        # Create a new figure\n        fig, ax = plt.subplots()\n\n        # Plot a histogram of the column\n        sns.histplot(df[col], bins=10, ax=ax)\n\n        # Add the axes to the list\n        axes.append(ax)\n\n    # Return the dataframe statistics and the list of axes\n    return (df_stats, axes)"}
{"task_id": "BigCodeBench/44", "solution": "from sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\ndef task_func(df):\n    # Normalize numeric columns in a DataFrame\n    scaler = MinMaxScaler()\n    df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    # Replace missing values with column's average\n    df_normalized.fillna(df_normalized.mean(), inplace=True)\n\n    # Create a figure and a set of subplots\n    fig, axes = plt.subplots(nrows=df.shape[1], ncols=1, figsize=(10, 15))\n\n    # Draw a box plot for each column\n    for i, column in enumerate(df.columns):\n        sns.boxplot(df_normalized[column], ax=axes[i])\n        axes[i].set_title(f'Box plot of {column}')\n\n    # Return the normalized DataFrame and the Axes\n    return df_normalized, axes", "raw_solution": "from sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef task_func(df):\n    # Normalize numeric columns in a DataFrame\n    scaler = MinMaxScaler()\n    df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    # Replace missing values with column's average\n    df_normalized.fillna(df_normalized.mean(), inplace=True)\n\n    # Create a figure and a set of subplots\n    fig, axes = plt.subplots(nrows=df.shape[1], ncols=1, figsize=(10, 15))\n\n    # Draw a box plot for each column\n    for i, column in enumerate(df.columns):\n        sns.boxplot(df_normalized[column], ax=axes[i])\n        axes[i].set_title(f'Box plot of {column}')\n\n    # Return the normalized DataFrame and the Axes\n    return df_normalized, axes"}
{"task_id": "BigCodeBench/45", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame):\n    # Replace non-numeric columns with their mean\n    df = df.apply(lambda x: x.fillna(x.mean()) if x.dtype=='float64' else x)\n\n    # Perform PCA\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(df)\n\n    # Create a DataFrame for the first two principal components\n    principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n\n    # Create a scatter plot of the first two principal components\n    fig, ax = plt.subplots()\n    sns.scatterplot(x='principal component 1', y='principal component 2', data=principalDf, ax=ax)\n    ax.set_xlabel('principal component 1')\n    ax.set_ylabel('principal component 2')\n\n    return principalDf, ax", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame):\n    # Replace non-numeric columns with their mean\n    df = df.apply(lambda x: x.fillna(x.mean()) if x.dtype=='float64' else x)\n\n    # Perform PCA\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(df)\n\n    # Create a DataFrame for the first two principal components\n    principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n\n    # Create a scatter plot of the first two principal components\n    fig, ax = plt.subplots()\n    sns.scatterplot(x='principal component 1', y='principal component 2', data=principalDf, ax=ax)\n    ax.set_xlabel('principal component 1')\n    ax.set_ylabel('principal component 2')\n\n    return principalDf, ax"}
{"task_id": "BigCodeBench/46", "solution": "from scipy.stats import zscore\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\ndef task_func(df):\n    # Calculate Z-scores for numeric columns in a DataFrame\n    df_z_scores = df.select_dtypes(include=[np.number]).apply(zscore)\n\n    # Replace missing values with the column's average\n    df_z_scores.fillna(df_z_scores.mean(), inplace=True)\n\n    # Initialize a list to store the histogram plots\n    hist_plots = []\n\n    # Draw a histogram for each column\n    for col in df_z_scores.columns:\n        fig, ax = plt.subplots()\n        ax.hist(df_z_scores[col], bins=10)\n        ax.set_title(f'Histogram of {col}')\n        hist_plots.append(ax)\n\n    return df_z_scores, hist_plots", "raw_solution": "from scipy.stats import zscore\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef task_func(df):\n    # Calculate Z-scores for numeric columns in a DataFrame\n    df_z_scores = df.select_dtypes(include=[np.number]).apply(zscore)\n\n    # Replace missing values with the column's average\n    df_z_scores.fillna(df_z_scores.mean(), inplace=True)\n\n    # Initialize a list to store the histogram plots\n    hist_plots = []\n\n    # Draw a histogram for each column\n    for col in df_z_scores.columns:\n        fig, ax = plt.subplots()\n        ax.hist(df_z_scores[col], bins=10)\n        ax.set_title(f'Histogram of {col}')\n        hist_plots.append(ax)\n\n    return df_z_scores, hist_plots"}
{"task_id": "BigCodeBench/47", "solution": "from sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\ndef task_func(df):\n    # Fill missing values with the column's average\n    df.fillna(df.mean(), inplace=True)\n\n    # Standardize numeric columns\n    scaler = StandardScaler()\n    df[df.columns] = scaler.fit_transform(df[df.columns])\n\n    # Compute the correlation matrix\n    corr = df.corr()\n\n    # Plot the heatmap of the correlation matrix\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, fmt=\".2f\")\n    plt.show()\n\n    return df, corr\ndf = pd.DataFrame({\n    'A': [1, 2, np.nan, 4],\n    'B': [5, np.nan, 7, 8],\n    'C': [9, 10, 11, 12],\n    'D': [13, 14, 15, np.nan]\n})", "raw_solution": "from sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef task_func(df):\n    # Fill missing values with the column's average\n    df.fillna(df.mean(), inplace=True)\n\n    # Standardize numeric columns\n    scaler = StandardScaler()\n    df[df.columns] = scaler.fit_transform(df[df.columns])\n\n    # Compute the correlation matrix\n    corr = df.corr()\n\n    # Plot the heatmap of the correlation matrix\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, fmt=\".2f\")\n    plt.show()\n\n    return df, corr\n\n# Test the function\ndf = pd.DataFrame({\n    'A': [1, 2, np.nan, 4],\n    'B': [5, np.nan, 7, 8],\n    'C': [9, 10, 11, 12],\n    'D': [13, 14, 15, np.nan]\n})\n\ndf, corr = task_func(df)"}
{"task_id": "BigCodeBench/48", "solution": "import time\nfrom datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\ndef task_func(n, output_path=None):\n    timestamps = [time.mktime(datetime.utcnow().timetuple()) for _ in range(n)]\n    formatted_timestamps = [time.strftime(DATE_FORMAT, time.localtime(t)) for t in timestamps]\n\n    # Plotting histogram\n    plt.hist([datetime.strptime(d, DATE_FORMAT) for d in formatted_timestamps], bins=10)\n    plt.xlabel('Date')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Generated Timestamps')\n\n    if output_path:\n        plt.savefig(output_path)\n    else:\n        plt.show()\n\n    return formatted_timestamps", "raw_solution": "import time\nfrom datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\n\n# Constants\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n\ndef task_func(n, output_path=None):\n    timestamps = [time.mktime(datetime.utcnow().timetuple()) for _ in range(n)]\n    formatted_timestamps = [time.strftime(DATE_FORMAT, time.localtime(t)) for t in timestamps]\n\n    # Plotting histogram\n    plt.hist([datetime.strptime(d, DATE_FORMAT) for d in formatted_timestamps], bins=10)\n    plt.xlabel('Date')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Generated Timestamps')\n\n    if output_path:\n        plt.savefig(output_path)\n    else:\n        plt.show()\n\n    return formatted_timestamps"}
{"task_id": "BigCodeBench/49", "solution": "from datetime import datetime\nimport pandas as pd\nimport matplotlib.pyplot as plt\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\ndef task_func(timestamps):\n    if not timestamps:\n        raise ValueError(\"Input list of timestamps is empty\")\n\n    # Convert Unix timestamps to datetime objects\n    datetime_objects = [datetime.fromtimestamp(ts) for ts in timestamps]\n\n    # Create a pandas DataFrame\n    df = pd.DataFrame({\n        'Timestamp': timestamps,\n        'Datetime': datetime_objects\n    })\n\n    # Convert 'Datetime' column to string format\n    df['Datetime'] = df['Datetime'].dt.strftime(DATE_FORMAT)\n\n    # Draw a histogram\n    ax = df['Timestamp'].plot(kind='hist', bins=10)\n\n    return df, ax.figure\ntimestamps = [1609459200, 1612137600, 1614557140]", "raw_solution": "from datetime import datetime\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n\ndef task_func(timestamps):\n    if not timestamps:\n        raise ValueError(\"Input list of timestamps is empty\")\n\n    # Convert Unix timestamps to datetime objects\n    datetime_objects = [datetime.fromtimestamp(ts) for ts in timestamps]\n\n    # Create a pandas DataFrame\n    df = pd.DataFrame({\n        'Timestamp': timestamps,\n        'Datetime': datetime_objects\n    })\n\n    # Convert 'Datetime' column to string format\n    df['Datetime'] = df['Datetime'].dt.strftime(DATE_FORMAT)\n\n    # Draw a histogram\n    ax = df['Timestamp'].plot(kind='hist', bins=10)\n\n    return df, ax.figure\n\n# Test the function\ntimestamps = [1609459200, 1612137600, 1614557140]\ndf, fig = task_func(timestamps)"}
{"task_id": "BigCodeBench/50", "solution": "from datetime import datetime\nimport pandas as pd\nimport pytz\nimport matplotlib.pyplot as plt\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\nTIMEZONES = [\n    \"America/New_York\",\n    \"Europe/London\",\n    \"Asia/Shanghai\",\n    \"Asia/Tokyo\",\n    \"Australia/Sydney\",\n]\ndef task_func(timestamp):\n    # Convert Unix timestamp to datetime object\n    dt_object = datetime.fromtimestamp(timestamp)\n\n    # Create a DataFrame\n    df = pd.DataFrame(columns=['Timezone', 'Datetime'])\n\n    for tz in TIMEZONES:\n        # Convert datetime object to different timezones\n        tz_object = pytz.timezone(tz)\n        dt_tz = dt_object.astimezone(tz_object)\n        df = df.append({'Timezone': tz, 'Datetime': dt_tz.strftime(DATE_FORMAT)}, ignore_index=True)\n\n    # Draw a bar chart\n    ax = df.plot(x='Timezone', y='Datetime', kind='bar', legend=False)\n    ax.set_xlabel('Timezone')\n    ax.set_ylabel('Datetime')\n    ax.set_title('Datetime = f(Timezone)')\n\n    return df, ax\ntimestamp = 1630454400", "raw_solution": "from datetime import datetime\nimport pandas as pd\nimport pytz\nimport matplotlib.pyplot as plt\n\n# Constants\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\nTIMEZONES = [\n    \"America/New_York\",\n    \"Europe/London\",\n    \"Asia/Shanghai\",\n    \"Asia/Tokyo\",\n    \"Australia/Sydney\",\n]\n\ndef task_func(timestamp):\n    # Convert Unix timestamp to datetime object\n    dt_object = datetime.fromtimestamp(timestamp)\n\n    # Create a DataFrame\n    df = pd.DataFrame(columns=['Timezone', 'Datetime'])\n\n    for tz in TIMEZONES:\n        # Convert datetime object to different timezones\n        tz_object = pytz.timezone(tz)\n        dt_tz = dt_object.astimezone(tz_object)\n        df = df.append({'Timezone': tz, 'Datetime': dt_tz.strftime(DATE_FORMAT)}, ignore_index=True)\n\n    # Draw a bar chart\n    ax = df.plot(x='Timezone', y='Datetime', kind='bar', legend=False)\n    ax.set_xlabel('Timezone')\n    ax.set_ylabel('Datetime')\n    ax.set_title('Datetime = f(Timezone)')\n\n    return df, ax\n\n# Test the function\ntimestamp = 1630454400  # 2021-09-01 00:00:00\ndf, ax = task_func(timestamp)\nplt.show()"}
{"task_id": "BigCodeBench/51", "solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df, age: int, height: int):\n    # Filter the dataframe based on specified 'Age' and 'Height' conditions\n    df_filtered = df[(df['Age'] >= age) & (df['Height'] >= height)]\n\n    # If the filtered dataframe has less than 3 columns, add a column 'Cluster' with 0 for each row\n    if len(df_filtered.columns) < 3:\n        df_filtered['Cluster'] = 0\n        return df_filtered, None\n\n    # Otherwise, do a KMeans clustering (by Age and Height) with 3 clusters\n    kmeans = KMeans(n_clusters=3)\n    df_filtered['Cluster'] = kmeans.fit_predict(df_filtered[['Age', 'Height']])\n\n    # Plot a scatter plot of the 'Age' and 'Height' and colored by the cluster indices\n    plt.scatter(df_filtered['Age'], df_filtered['Height'], c=df_filtered['Cluster'])\n    plt.xlabel('Age')\n    plt.ylabel('Height')\n    plt.title('KMeans Clustering based on Age and Height')\n    plt.show()\n\n    return df_filtered, plt.gca()", "raw_solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, age: int, height: int):\n    # Filter the dataframe based on specified 'Age' and 'Height' conditions\n    df_filtered = df[(df['Age'] >= age) & (df['Height'] >= height)]\n\n    # If the filtered dataframe has less than 3 columns, add a column 'Cluster' with 0 for each row\n    if len(df_filtered.columns) < 3:\n        df_filtered['Cluster'] = 0\n        return df_filtered, None\n\n    # Otherwise, do a KMeans clustering (by Age and Height) with 3 clusters\n    kmeans = KMeans(n_clusters=3)\n    df_filtered['Cluster'] = kmeans.fit_predict(df_filtered[['Age', 'Height']])\n\n    # Plot a scatter plot of the 'Age' and 'Height' and colored by the cluster indices\n    plt.scatter(df_filtered['Age'], df_filtered['Height'], c=df_filtered['Cluster'])\n    plt.xlabel('Age')\n    plt.ylabel('Height')\n    plt.title('KMeans Clustering based on Age and Height')\n    plt.show()\n\n    return df_filtered, plt.gca()"}
{"task_id": "BigCodeBench/52", "solution": "import pandas as pd\nfrom collections import Counter\nSTOPWORDS = [\"a\", \"an\", \"the\", \"in\", \"is\", \"are\"]\ndef task_func(text):\n    # Remove punctuation and convert to lower case\n    text = ''.join(c for c in text if c.isalnum() or c.isspace()).lower()\n\n    # Split the text into words\n    words = text.split()\n\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n\n    # Count the frequency of each word\n    word_counts = Counter(words)\n\n    # Convert the Counter to a pandas Series\n    series = pd.Series(word_counts)\n\n    return series\ntext = \"The sun is shining in the sky. The birds are singing in the trees.\"", "raw_solution": "import pandas as pd\nfrom collections import Counter\n\n# Constants\nSTOPWORDS = [\"a\", \"an\", \"the\", \"in\", \"is\", \"are\"]\n\ndef task_func(text):\n    # Remove punctuation and convert to lower case\n    text = ''.join(c for c in text if c.isalnum() or c.isspace()).lower()\n\n    # Split the text into words\n    words = text.split()\n\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n\n    # Count the frequency of each word\n    word_counts = Counter(words)\n\n    # Convert the Counter to a pandas Series\n    series = pd.Series(word_counts)\n\n    return series\n\n# Test the function\ntext = \"The sun is shining in the sky. The birds are singing in the trees.\""}
{"task_id": "BigCodeBench/53", "solution": "import pandas as pd\nimport re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nCOLUMN_NAMES = [\"Name\", \"Email\", \"Age\", \"Country\"]\ndef task_func(text):\n    # Extract data using regex\n    data = re.findall(r\"Name: (.*?), Email: (.*?), Age: (.*?), Country: (.*?)($|\\n)\", text)\n\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=COLUMN_NAMES)\n\n    # Convert Age to integer\n    df['Age'] = df['Age'].astype(int)\n\n    # Plot age distribution\n    plt.figure(figsize=(10,6))\n    sns.histplot(df, x='Age', bins=30, kde=False)\n    plt.title('Age Distribution')\n    plt.show()\n\n    return df", "raw_solution": "import pandas as pd\nimport re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nCOLUMN_NAMES = [\"Name\", \"Email\", \"Age\", \"Country\"]\n\ndef task_func(text):\n    # Extract data using regex\n    data = re.findall(r\"Name: (.*?), Email: (.*?), Age: (.*?), Country: (.*?)($|\\n)\", text)\n\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=COLUMN_NAMES)\n\n    # Convert Age to integer\n    df['Age'] = df['Age'].astype(int)\n\n    # Plot age distribution\n    plt.figure(figsize=(10,6))\n    sns.histplot(df, x='Age', bins=30, kde=False)\n    plt.title('Age Distribution')\n    plt.show()\n\n    return df"}
{"task_id": "BigCodeBench/54", "solution": "import pandas as pd\nimport regex as re\nfrom sklearn.feature_extraction.text import CountVectorizer\ndef task_func(text):\n    # Split the text into sentences\n    sentences = [s for s in re.split(r'(?<=[.!?])\\s', text) if s]\n\n    # Initialize CountVectorizer\n    vectorizer = CountVectorizer()\n\n    # Fit and transform the sentences\n    dtm = vectorizer.fit_transform(sentences)\n\n    # Create a DataFrame from the document-term matrix\n    df = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n\n    return df\ntext = \"This is the first sentence. This is another sentence. This is yet another sentence.\"", "raw_solution": "import pandas as pd\nimport regex as re\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef task_func(text):\n    # Split the text into sentences\n    sentences = [s for s in re.split(r'(?<=[.!?])\\s', text) if s]\n\n    # Initialize CountVectorizer\n    vectorizer = CountVectorizer()\n\n    # Fit and transform the sentences\n    dtm = vectorizer.fit_transform(sentences)\n\n    # Create a DataFrame from the document-term matrix\n    df = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n\n    return df\n\n# Test the function\ntext = \"This is the first sentence. This is another sentence. This is yet another sentence.\""}
{"task_id": "BigCodeBench/55", "solution": "import re\nimport pandas as pd\nfrom nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(text):\n    # Split the text into sentences\n    sentences = re.split('[.!?]', text)\n    sentences = [s.strip() for s in sentences if s.strip()]  # Remove empty sentences\n\n    # Build a dictionary where each key is a sentence and the value is the number of words in the sentence\n    sentence_word_counts = {}\n    for i, sentence in enumerate(sentences, 1):\n        words = re.findall(r'\\b\\w+\\b', sentence)  # Split the sentence into words\n        words = [word for word in words if word.lower() not in STOPWORDS]  # Remove stopwords\n        sentence_word_counts[f\"Sentence {i}\"] = len(words)\n\n    # Build a pandas Series from the dictionary\n    series = pd.Series(sentence_word_counts)\n\n    return series", "raw_solution": "import re\nimport pandas as pd\nfrom nltk.corpus import stopwords\n\nSTOPWORDS = set(stopwords.words('english'))\nSTOPWORDS.update([\"Those\", \"are\", \"the\", \"words\", \"to\", \"ignore\"])\n\ndef task_func(text):\n    # Split the text into sentences\n    sentences = re.split('[.!?]', text)\n    sentences = [s.strip() for s in sentences if s.strip()]  # Remove empty sentences\n\n    # Build a dictionary where each key is a sentence and the value is the number of words in the sentence\n    sentence_word_counts = {}\n    for i, sentence in enumerate(sentences, 1):\n        words = re.findall(r'\\b\\w+\\b', sentence)  # Split the sentence into words\n        words = [word for word in words if word.lower() not in STOPWORDS]  # Remove stopwords\n        sentence_word_counts[f\"Sentence {i}\"] = len(words)\n\n    # Build a pandas Series from the dictionary\n    series = pd.Series(sentence_word_counts)\n\n    return series"}
{"task_id": "BigCodeBench/56", "solution": "import pandas as pd\nimport re\ndef task_func(text):\n    # Split the text into lines\n    lines = text.split('\\n')\n\n    # Initialize lists to store the scores and categories\n    scores = []\n    categories = []\n\n    # Loop over each line\n    for line in lines:\n        # Use regex to extract the score and category\n        match = re.search('Score: (\\d+), Category: (\\w+)', line)\n        if match:\n            scores.append(int(match.group(1)))\n            categories.append(match.group(2))\n\n    # Create a pandas DataFrame from the scores and categories\n    df = pd.DataFrame({\n        'Score': scores,\n        'Category': categories\n    })\n\n    return df\ntext = \"\"\"\nScore: 85, Category: Math\nScore: 90, Category: Science\nScore: 78, Category: English\n\"\"\"", "raw_solution": "import pandas as pd\nimport re\n\ndef task_func(text):\n    # Split the text into lines\n    lines = text.split('\\n')\n\n    # Initialize lists to store the scores and categories\n    scores = []\n    categories = []\n\n    # Loop over each line\n    for line in lines:\n        # Use regex to extract the score and category\n        match = re.search('Score: (\\d+), Category: (\\w+)', line)\n        if match:\n            scores.append(int(match.group(1)))\n            categories.append(match.group(2))\n\n    # Create a pandas DataFrame from the scores and categories\n    df = pd.DataFrame({\n        'Score': scores,\n        'Category': categories\n    })\n\n    return df\n\n# Test the function\ntext = \"\"\"\nScore: 85, Category: Math\nScore: 90, Category: Science\nScore: 78, Category: English\n\"\"\"\n"}
{"task_id": "BigCodeBench/57", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(csv_file_path: str, title: str):\n    # Read the CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Calculate the correlation matrix\n    corr = df.corr().round(2)\n\n    # Create a mask for the upper triangle of the correlation matrix\n    mask = np.triu(np.ones_like(corr, dtype=bool))\n\n    # Set up the matplotlib figure\n    f, ax = plt.subplots(figsize=(11, 9))\n\n    # Generate a custom diverging colormap\n    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n    # Draw the heatmap with the mask and correct aspect ratio\n    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\n    plt.title(title)\n    plt.show()\n\n    return corr, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(csv_file_path: str, title: str):\n    # Read the CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Calculate the correlation matrix\n    corr = df.corr().round(2)\n\n    # Create a mask for the upper triangle of the correlation matrix\n    mask = np.triu(np.ones_like(corr, dtype=bool))\n\n    # Set up the matplotlib figure\n    f, ax = plt.subplots(figsize=(11, 9))\n\n    # Generate a custom diverging colormap\n    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n    # Draw the heatmap with the mask and correct aspect ratio\n    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\n    plt.title(title)\n    plt.show()\n\n    return corr, ax"}
{"task_id": "BigCodeBench/58", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(mu, sigma, num_samples):\n    # Generate a range of x values\n    x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)\n\n    # Calculate the y values for the normal distribution\n    y = stats.norm.pdf(x, mu, sigma)\n\n    # Generate random samples from the normal distribution\n    samples = np.random.normal(mu, sigma, num_samples)\n\n    # Create the plot\n    fig, ax = plt.subplots()\n\n    # Plot the normal distribution\n    ax.plot(x, y, 'r-', label='Normal Distribution')\n\n    # Plot the histogram of the samples\n    ax.hist(samples, bins=30, density=True, alpha=0.5, label='Histogram of Samples')\n\n    # Set the plot title and labels\n    ax.set_title('Normal Distribution')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    # Add a legend\n    ax.legend()\n\n    # Return the figure\n    return fig", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(mu, sigma, num_samples):\n    # Generate a range of x values\n    x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)\n\n    # Calculate the y values for the normal distribution\n    y = stats.norm.pdf(x, mu, sigma)\n\n    # Generate random samples from the normal distribution\n    samples = np.random.normal(mu, sigma, num_samples)\n\n    # Create the plot\n    fig, ax = plt.subplots()\n\n    # Plot the normal distribution\n    ax.plot(x, y, 'r-', label='Normal Distribution')\n\n    # Plot the histogram of the samples\n    ax.hist(samples, bins=30, density=True, alpha=0.5, label='Histogram of Samples')\n\n    # Set the plot title and labels\n    ax.set_title('Normal Distribution')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    # Add a legend\n    ax.legend()\n\n    # Return the figure\n    return fig"}
{"task_id": "BigCodeBench/59", "solution": "import wikipedia\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ndef task_func(page_title):\n    try:\n        # Get the page content\n        page_content = wikipedia.page(page_title).content\n\n        # Generate word cloud\n        wordcloud = WordCloud().generate(page_content)\n\n        # Display the word cloud\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis('off')\n        plt.show()\n\n        return plt.gca()\n    except wikipedia.exceptions.PageError:\n        # If there is no wikipedia page with the title given as input\n        return None", "raw_solution": "import wikipedia\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(page_title):\n    try:\n        # Get the page content\n        page_content = wikipedia.page(page_title).content\n\n        # Generate word cloud\n        wordcloud = WordCloud().generate(page_content)\n\n        # Display the word cloud\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis('off')\n        plt.show()\n\n        return plt.gca()\n    except wikipedia.exceptions.PageError:\n        # If there is no wikipedia page with the title given as input\n        return None"}
{"task_id": "BigCodeBench/60", "solution": "import json\nimport pandas as pd\ndef task_func(result, csv_file_path=\"test.csv\", json_file_path=\"test.json\"):\n    # Convert the list of dictionaries to a pandas DataFrame\n    df = pd.DataFrame(result)\n\n    # Save the DataFrame to a CSV file\n    df.to_csv(csv_file_path, index=False)\n\n    # Save the DataFrame to a JSON file\n    with open(json_file_path, 'w') as f:\n        json.dump(result, f)\n\n    return None", "raw_solution": "import json\nimport pandas as pd\n\ndef task_func(result, csv_file_path=\"test.csv\", json_file_path=\"test.json\"):\n    # Convert the list of dictionaries to a pandas DataFrame\n    df = pd.DataFrame(result)\n\n    # Save the DataFrame to a CSV file\n    df.to_csv(csv_file_path, index=False)\n\n    # Save the DataFrame to a JSON file\n    with open(json_file_path, 'w') as f:\n        json.dump(result, f)\n\n    return None"}
{"task_id": "BigCodeBench/61", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nPLOT_TITLE = 'Square root plot'\nX_LABEL = 'x'\nY_LABEL = 'sqrt(x)'\nTIME_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(input_list, plot_title=PLOT_TITLE, x_label=X_LABEL, y_label=Y_LABEL):\n    # Extract 'from_user' values\n    x_values = [d['from_user'] for d in input_list if 'from_user' in d]\n\n    # Calculate square root values\n    y_values = np.sqrt(x_values)\n    y_values = [round(val, 2) for val in y_values]\n\n    # Create plot\n    fig, ax = plt.subplots()\n    ax.plot(x_values, y_values)\n\n    # Annotate with current date and time\n    current_time = datetime.now().strftime(TIME_FORMAT)\n    ax.annotate(current_time, xy=(0.05, 0.95), xycoords='axes fraction', ha='left', va='top')\n\n    # Set plot title, x and y labels\n    ax.set_title(plot_title)\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(y_label)\n\n    return y_values, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n# Constants\nPLOT_TITLE = 'Square root plot'\nX_LABEL = 'x'\nY_LABEL = 'sqrt(x)'\nTIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(input_list, plot_title=PLOT_TITLE, x_label=X_LABEL, y_label=Y_LABEL):\n    # Extract 'from_user' values\n    x_values = [d['from_user'] for d in input_list if 'from_user' in d]\n\n    # Calculate square root values\n    y_values = np.sqrt(x_values)\n    y_values = [round(val, 2) for val in y_values]\n\n    # Create plot\n    fig, ax = plt.subplots()\n    ax.plot(x_values, y_values)\n\n    # Annotate with current date and time\n    current_time = datetime.now().strftime(TIME_FORMAT)\n    ax.annotate(current_time, xy=(0.05, 0.95), xycoords='axes fraction', ha='left', va='top')\n\n    # Set plot title, x and y labels\n    ax.set_title(plot_title)\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(y_label)\n\n    return y_values, ax"}
{"task_id": "BigCodeBench/62", "solution": "import random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(result, colors=['b', 'g', 'r', 'c', 'm', 'y', 'k']):\n    from_user_values = [x['from_user'] for x in result]\n    color_choice = random.choice(colors)\n    sns.histplot(from_user_values, color=color_choice)\n    plt.show()\n    return None\nresult = [{'from_user': 1}, {'from_user': 2}, {'from_user': 2}, {'from_user': 3}, {'from_user': 4}]", "raw_solution": "import random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(result, colors=['b', 'g', 'r', 'c', 'm', 'y', 'k']):\n    from_user_values = [x['from_user'] for x in result]\n    color_choice = random.choice(colors)\n    sns.histplot(from_user_values, color=color_choice)\n    plt.show()\n    return None\n\n# Test the function\nresult = [{'from_user': 1}, {'from_user': 2}, {'from_user': 2}, {'from_user': 3}, {'from_user': 4}]\ntask_func(result)"}
{"task_id": "BigCodeBench/63", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(car_dict):\n    # Create a DataFrame from the dictionary\n    df = pd.DataFrame(list(car_dict.items()), columns=['Car', 'Color'])\n\n    # Count the occurrence of each color\n    color_counts = df['Color'].value_counts()\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    color_counts.plot(kind='bar', ax=ax)\n\n    # Set plot title\n    ax.set_title('Distribution of Vehicle Colors')\n\n    return df, ax.figure\ncar_dict = {'Tesla Model S': 'Red', 'Ford Mustang': 'Blue', 'Chevrolet Camaro': 'Red', 'Dodge Challenger': 'Black'}", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(car_dict):\n    # Create a DataFrame from the dictionary\n    df = pd.DataFrame(list(car_dict.items()), columns=['Car', 'Color'])\n\n    # Count the occurrence of each color\n    color_counts = df['Color'].value_counts()\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    color_counts.plot(kind='bar', ax=ax)\n\n    # Set plot title\n    ax.set_title('Distribution of Vehicle Colors')\n\n    return df, ax.figure\n\n# Test the function\ncar_dict = {'Tesla Model S': 'Red', 'Ford Mustang': 'Blue', 'Chevrolet Camaro': 'Red', 'Dodge Challenger': 'Black'}\ndf, fig = task_func(car_dict)\nplt.show()"}
{"task_id": "BigCodeBench/64", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nCOLUMNS = ['col1', 'col2', 'col3']\ndef task_func(data):\n    # Convert the input data to a pandas DataFrame\n    df = pd.DataFrame(data, columns=COLUMNS)\n\n    # Group by 'col1' and 'col2', and calculate the distribution of 'col3'\n    grouped_df = df.groupby(['col1', 'col2']).col3.value_counts().unstack(fill_value=0)\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(grouped_df, cmap='viridis', annot=True, fmt='d')\n    plt.title('Distribution of col3 by col1 and col2')\n    plt.xlabel('col2')\n    plt.ylabel('col1')\n    plt.show()\n\n    return df, plt.gca()\ndata = [['A', 'B', 1], ['A', 'B', 2], ['A', 'B', 2], ['A', 'C', 3], ['B', 'C', 1], ['B', 'C', 2]]", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['col1', 'col2', 'col3']\n\ndef task_func(data):\n    # Convert the input data to a pandas DataFrame\n    df = pd.DataFrame(data, columns=COLUMNS)\n\n    # Group by 'col1' and 'col2', and calculate the distribution of 'col3'\n    grouped_df = df.groupby(['col1', 'col2']).col3.value_counts().unstack(fill_value=0)\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(grouped_df, cmap='viridis', annot=True, fmt='d')\n    plt.title('Distribution of col3 by col1 and col2')\n    plt.xlabel('col2')\n    plt.ylabel('col1')\n    plt.show()\n\n    return df, plt.gca()\n\n# Test the function\ndata = [['A', 'B', 1], ['A', 'B', 2], ['A', 'B', 2], ['A', 'C', 3], ['B', 'C', 1], ['B', 'C', 2]]\ndf, ax = task_func(data)"}
{"task_id": "BigCodeBench/65", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nCOLUMNS = ['col1', 'col2', 'col3']\ndef task_func(data):\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data, columns=COLUMNS)\n\n    # Group by all columns except the last one and get unique values\n    grouped = df.groupby(COLUMNS[:-1].copy())[COLUMNS[-1]].apply(list).apply(lambda x: list(set(x)))\n\n    # Create a line chart\n    fig, ax = plt.subplots()\n    grouped.plot(kind='line', ax=ax)\n\n    # Set x-label and y-label\n    ax.set_xlabel('-'.join(COLUMNS[:-1]))\n    ax.set_ylabel(COLUMNS[-1])\n\n    return df, ax.figure\ndata = [['a', 'b', 1], ['a', 'b', 2], ['a', 'c', 3], ['b', 'c', 4], ['b', 'c', 5]]", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\nCOLUMNS = ['col1', 'col2', 'col3']\n\ndef task_func(data):\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data, columns=COLUMNS)\n\n    # Group by all columns except the last one and get unique values\n    grouped = df.groupby(COLUMNS[:-1].copy())[COLUMNS[-1]].apply(list).apply(lambda x: list(set(x)))\n\n    # Create a line chart\n    fig, ax = plt.subplots()\n    grouped.plot(kind='line', ax=ax)\n\n    # Set x-label and y-label\n    ax.set_xlabel('-'.join(COLUMNS[:-1]))\n    ax.set_ylabel(COLUMNS[-1])\n\n    return df, ax.figure\n\n# Test the function\ndata = [['a', 'b', 1], ['a', 'b', 2], ['a', 'c', 3], ['b', 'c', 4], ['b', 'c', 5]]\ndf, fig = task_func(data)\nplt.show()"}
{"task_id": "BigCodeBench/66", "solution": "import pandas as pd\nimport seaborn as sns\nCOLUMNS = ['col1', 'col2', 'col3']\ndef task_func(data):\n    # 1. Build a pandas DataFrame by using list of elements.\n    df = pd.DataFrame(data, columns=COLUMNS)\n\n    # 2. Create a new dataframe by grouping the values in the column 'col3' by ['col1', 'col2']\n    grouped_df = df.groupby(['col1', 'col2']).sum().reset_index()\n\n    # 3. Reset the index of the newly created dataframe\n    grouped_df.reset_index(inplace=True)\n\n    # 4. Create a distribution plot of the 'col3' column of the previous dataframe using seaborn\n    plot = sns.distplot(grouped_df['col3'])\n\n    # Set the xlabel (label for the x-axis) to the 'col3'\n    plot.set_xlabel('col3')\n\n    return grouped_df, plot.figure", "raw_solution": "import pandas as pd\nimport seaborn as sns\n\n# Constants\nCOLUMNS = ['col1', 'col2', 'col3']\n\ndef task_func(data):\n    # 1. Build a pandas DataFrame by using list of elements.\n    df = pd.DataFrame(data, columns=COLUMNS)\n\n    # 2. Create a new dataframe by grouping the values in the column 'col3' by ['col1', 'col2']\n    grouped_df = df.groupby(['col1', 'col2']).sum().reset_index()\n\n    # 3. Reset the index of the newly created dataframe\n    grouped_df.reset_index(inplace=True)\n\n    # 4. Create a distribution plot of the 'col3' column of the previous dataframe using seaborn\n    plot = sns.distplot(grouped_df['col3'])\n\n    # Set the xlabel (label for the x-axis) to the 'col3'\n    plot.set_xlabel('col3')\n\n    return grouped_df, plot.figure"}
{"task_id": "BigCodeBench/67", "solution": "import pandas as pd\nimport re\nimport os\ndef task_func(dir_path: str, pattern: str = '^EMP'):\n    # Initialize an empty list to store file names and sizes\n    files_sizes = []\n\n    # Walk through the directory\n    for root, dirs, files in os.walk(dir_path):\n        for file in files:\n            # Check if the file name starts with the given pattern and is sorted in ascending order\n            if re.match(pattern, file) and all(file[i] <= file[i+1] for i in range(len(file)-1)):\n                # Get the file size\n                file_size = os.path.getsize(os.path.join(root, file))\n                # Append the file name and size to the list\n                files_sizes.append((file, file_size))\n\n    # Convert the list to a pandas DataFrame\n    df = pd.DataFrame(files_sizes, columns=['File', 'Size'])\n\n    return df", "raw_solution": "import pandas as pd\nimport re\nimport os\n\ndef task_func(dir_path: str, pattern: str = '^EMP'):\n    # Initialize an empty list to store file names and sizes\n    files_sizes = []\n\n    # Walk through the directory\n    for root, dirs, files in os.walk(dir_path):\n        for file in files:\n            # Check if the file name starts with the given pattern and is sorted in ascending order\n            if re.match(pattern, file) and all(file[i] <= file[i+1] for i in range(len(file)-1)):\n                # Get the file size\n                file_size = os.path.getsize(os.path.join(root, file))\n                # Append the file name and size to the list\n                files_sizes.append((file, file_size))\n\n    # Convert the list to a pandas DataFrame\n    df = pd.DataFrame(files_sizes, columns=['File', 'Size'])\n\n    return df"}
{"task_id": "BigCodeBench/68", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(data='/path/to/data.csv', emp_prefix='EMP'):\n    # Load CSV file into a DataFrame\n    df = pd.read_csv(data)\n\n    # Filter lines where employee ID begins with a prefix\n    df = df[df['Employee ID'].str.startswith(emp_prefix)]\n\n    # Draw a histogram of its age\n    plt.figure(figsize=(10, 6))\n    sns.histplot(data=df, x='Age', kde=True, color='skyblue')\n    plt.title(f'Histogram of Age for Employees with ID starting with {emp_prefix}')\n    plt.xlabel('Age')\n    plt.ylabel('Frequency')\n    plt.show()\n\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data='/path/to/data.csv', emp_prefix='EMP'):\n    # Load CSV file into a DataFrame\n    df = pd.read_csv(data)\n\n    # Filter lines where employee ID begins with a prefix\n    df = df[df['Employee ID'].str.startswith(emp_prefix)]\n\n    # Draw a histogram of its age\n    plt.figure(figsize=(10, 6))\n    sns.histplot(data=df, x='Age', kde=True, color='skyblue')\n    plt.title(f'Histogram of Age for Employees with ID starting with {emp_prefix}')\n    plt.xlabel('Age')\n    plt.ylabel('Frequency')\n    plt.show()\n\n    return df, plt.gca()\n\n# Test the function\ndf, ax = task_func(data='employee_data.csv', emp_prefix='EMP')"}
{"task_id": "BigCodeBench/69", "solution": "import random\nimport matplotlib.pyplot as plt\nSALARY_RANGE = (20000, 100000)\ndef task_func(dict1):\n    # Check if the department exists\n    if 'EMPXX' not in dict1:\n        raise ValueError(\"Department 'EMPXX' not found in the dictionary.\")\n\n    # Generate random salaries\n    salaries = [random.randint(SALARY_RANGE[0], SALARY_RANGE[1]) for _ in range(dict1['EMPXX'])]\n\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(salaries, bins='auto', color='#1f77b4')\n\n    # Set title and labels\n    ax.set_title('Salary Distribution in EMPXX Department')\n    ax.set_xlabel('Salary')\n    ax.set_ylabel('Number of Employees')\n\n    return ax\ndict1 = {'EMP01': 100, 'EMP02': 200, 'EMP03': 300}", "raw_solution": "import random\nimport matplotlib.pyplot as plt\n\n# Constants\nSALARY_RANGE = (20000, 100000)\n\ndef task_func(dict1):\n    # Check if the department exists\n    if 'EMPXX' not in dict1:\n        raise ValueError(\"Department 'EMPXX' not found in the dictionary.\")\n\n    # Generate random salaries\n    salaries = [random.randint(SALARY_RANGE[0], SALARY_RANGE[1]) for _ in range(dict1['EMPXX'])]\n\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(salaries, bins='auto', color='#1f77b4')\n\n    # Set title and labels\n    ax.set_title('Salary Distribution in EMPXX Department')\n    ax.set_xlabel('Salary')\n    ax.set_ylabel('Number of Employees')\n\n    return ax\n\n# Test the function\ndict1 = {'EMP01': 100, 'EMP02': 200, 'EMP03': 300}\nax = task_func(dict1)\nplt.show()"}
{"task_id": "BigCodeBench/70", "solution": "import pandas as pd\nimport json\nimport matplotlib.pyplot as plt\nCOLUMNS = ['email', 'list', 'sum', 'mean']\ndef task_func(json_file):\n    try:\n        # Load JSON data\n        with open(json_file, 'r') as f:\n            data = json.load(f)\n\n        # Convert to DataFrame\n        df = pd.DataFrame(data)\n\n        # Calculate sum and mean\n        df['sum'] = df['list'].apply(sum)\n        df['mean'] = df['list'].apply(lambda x: sum(x)/len(x))\n\n        # Plot sum and mean\n        fig, ax = plt.subplots()\n        df.plot(x='email', y=['sum', 'mean'], ax=ax)\n\n        return (df[COLUMNS], ax)\n\n    except FileNotFoundError:\n        print(f\"File {json_file} not found.\")\n        return (pd.DataFrame(columns=COLUMNS), None)\n    except json.JSONDecodeError:\n        print(f\"File {json_file} is not a valid JSON file.\")\n        return (pd.DataFrame(columns=COLUMNS), None)\n    except KeyError:\n        print(f\"File {json_file} does not contain the expected keys.\")\n        return (pd.DataFrame(columns=COLUMNS), None)", "raw_solution": "import pandas as pd\nimport json\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['email', 'list', 'sum', 'mean']\n\ndef task_func(json_file):\n    try:\n        # Load JSON data\n        with open(json_file, 'r') as f:\n            data = json.load(f)\n\n        # Convert to DataFrame\n        df = pd.DataFrame(data)\n\n        # Calculate sum and mean\n        df['sum'] = df['list'].apply(sum)\n        df['mean'] = df['list'].apply(lambda x: sum(x)/len(x))\n\n        # Plot sum and mean\n        fig, ax = plt.subplots()\n        df.plot(x='email', y=['sum', 'mean'], ax=ax)\n\n        return (df[COLUMNS], ax)\n\n    except FileNotFoundError:\n        print(f\"File {json_file} not found.\")\n        return (pd.DataFrame(columns=COLUMNS), None)\n    except json.JSONDecodeError:\n        print(f\"File {json_file} is not a valid JSON file.\")\n        return (pd.DataFrame(columns=COLUMNS), None)\n    except KeyError:\n        print(f\"File {json_file} does not contain the expected keys.\")\n        return (pd.DataFrame(columns=COLUMNS), None)\n\n# Test the function\ndf, ax = task_func('emails.json')"}
{"task_id": "BigCodeBench/71", "solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport ast\ndef task_func(csv_file):\n    # Load e-mail data from a CSV file\n    df = pd.read_csv(csv_file)\n\n    # Convert the 'list' column from string to list\n    df['list'] = df['list'].apply(ast.literal_eval)\n\n    # Calculate the sum, mean, and standard deviation of the list associated with each e-mail\n    df['sum'] = df['list'].apply(np.sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['std'] = df['list'].apply(np.std)\n\n    # Draw a histogram of the mean values\n    plot = sns.histplot(df['mean'], kde=False)\n\n    return (df, plot)", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport ast\n\ndef task_func(csv_file):\n    # Load e-mail data from a CSV file\n    df = pd.read_csv(csv_file)\n\n    # Convert the 'list' column from string to list\n    df['list'] = df['list'].apply(ast.literal_eval)\n\n    # Calculate the sum, mean, and standard deviation of the list associated with each e-mail\n    df['sum'] = df['list'].apply(np.sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['std'] = df['list'].apply(np.std)\n\n    # Draw a histogram of the mean values\n    plot = sns.histplot(df['mean'], kde=False)\n\n    return (df, plot)"}
{"task_id": "BigCodeBench/72", "solution": "import pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ast\ndef task_func(directory):\n    # Initialize variables\n    max_len = 0\n    max_file = None\n    # Traverse directory for CSV files\n    for file in os.listdir(directory):\n        if file.endswith('.csv'):\n            if len(file) > max_len:\n                max_len = len(file)\n                max_file = file\n\n    # If no CSV file found, return empty dataframe\n    if max_file is None:\n        return pd.DataFrame(columns=['email', 'list', 'sum', 'mean', 'median']), None\n\n    # Load CSV file\n    df = pd.read_csv(os.path.join(directory, max_file))\n\n    # Convert 'list' column from string to list\n    df['list'] = df['list'].apply(ast.literal_eval)\n\n    # Calculate sum, mean and median\n    df['sum'] = df['list'].apply(np.sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['median'] = df['list'].apply(np.median)\n\n    # Draw histogram of the median\n    fig, ax = plt.subplots()\n    df['median'].plot(kind='hist', ax=ax)\n    ax.set_title('Histogram of Median')\n\n    return df, ax.figure", "raw_solution": "import pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ast\n\ndef task_func(directory):\n    # Initialize variables\n    max_len = 0\n    max_file = None\n    # Traverse directory for CSV files\n    for file in os.listdir(directory):\n        if file.endswith('.csv'):\n            if len(file) > max_len:\n                max_len = len(file)\n                max_file = file\n\n    # If no CSV file found, return empty dataframe\n    if max_file is None:\n        return pd.DataFrame(columns=['email', 'list', 'sum', 'mean', 'median']), None\n\n    # Load CSV file\n    df = pd.read_csv(os.path.join(directory, max_file))\n\n    # Convert 'list' column from string to list\n    df['list'] = df['list'].apply(ast.literal_eval)\n\n    # Calculate sum, mean and median\n    df['sum'] = df['list'].apply(np.sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['median'] = df['list'].apply(np.median)\n\n    # Draw histogram of the median\n    fig, ax = plt.subplots()\n    df['median'].plot(kind='hist', ax=ax)\n    ax.set_title('Histogram of Median')\n\n    return df, ax.figure"}
{"task_id": "BigCodeBench/73", "solution": "import pandas as pd\nimport sqlite3\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ast\ndef task_func(db_file):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_file)\n\n    # Query the database\n    df = pd.read_sql_query(\"SELECT * from EmailData\", conn)\n\n    # Convert the 'list' column from string to list\n    df['list'] = df['list'].apply(ast.literal_eval)\n\n    # Calculate sum, mean, and variance\n    df['sum'] = df['list'].apply(np.sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['var'] = df['list'].apply(np.var)\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    df[['sum', 'mean', 'var']].plot(kind='bar', ax=ax)\n    ax.set_xlabel('Email')\n    ax.set_ylabel('Value')\n\n    return (df, ax.figure)", "raw_solution": "import pandas as pd\nimport sqlite3\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ast\n\ndef task_func(db_file):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_file)\n\n    # Query the database\n    df = pd.read_sql_query(\"SELECT * from EmailData\", conn)\n\n    # Convert the 'list' column from string to list\n    df['list'] = df['list'].apply(ast.literal_eval)\n\n    # Calculate sum, mean, and variance\n    df['sum'] = df['list'].apply(np.sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['var'] = df['list'].apply(np.var)\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    df[['sum', 'mean', 'var']].plot(kind='bar', ax=ax)\n    ax.set_xlabel('Email')\n    ax.set_ylabel('Value')\n\n    return (df, ax.figure)"}
{"task_id": "BigCodeBench/74", "solution": "import socket\nimport requests\nfrom requests.exceptions import ConnectionError\ndef task_func(host):\n    if host is None or host == '':\n        raise ValueError(\"'host' cannot be None or an empty string\")\n\n    try:\n        ip_address = socket.gethostbyname(host)\n    except socket.gaierror:\n        raise ConnectionError(\"There was a problem connecting to the geolocation service\")\n\n    try:\n        response = requests.get(f'https://ipinfo.io/{ip_address}')\n        response.raise_for_status()\n    except (requests.exceptions.HTTPError, requests.exceptions.ConnectionError):\n        raise ConnectionError(\"There was a problem connecting to the geolocation service\")\n\n    geolocation_info = response.json()\n    return {'IP Address': ip_address, 'Geolocation Information': geolocation_info}", "raw_solution": "import socket\nimport requests\nfrom requests.exceptions import ConnectionError\n\ndef task_func(host):\n    if host is None or host == '':\n        raise ValueError(\"'host' cannot be None or an empty string\")\n\n    try:\n        ip_address = socket.gethostbyname(host)\n    except socket.gaierror:\n        raise ConnectionError(\"There was a problem connecting to the geolocation service\")\n\n    try:\n        response = requests.get(f'https://ipinfo.io/{ip_address}')\n        response.raise_for_status()\n    except (requests.exceptions.HTTPError, requests.exceptions.ConnectionError):\n        raise ConnectionError(\"There was a problem connecting to the geolocation service\")\n\n    geolocation_info = response.json()\n    return {'IP Address': ip_address, 'Geolocation Information': geolocation_info}"}
{"task_id": "BigCodeBench/75", "solution": "import pandas as pd\nimport numpy as np\nimport itertools\nfrom datetime import datetime, timedelta\nimport seaborn as sns\ndef task_func(df, fruits=None, days=None, seed=None, sales_lower_bound=1, sales_upper_bound=50):\n    # Check if df is a pandas DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"'df' should be a pandas DataFrame\")\n\n    # Check if df is not empty\n    if df.empty:\n        raise ValueError(\"'df' should not be empty\")\n\n    # Check if sales_lower_bound is less than sales_upper_bound\n    if not sales_lower_bound < sales_upper_bound:\n        raise ValueError(\"'sales_lower_bound' should be less than 'sales_upper_bound'\")\n\n    # If fruits and days are not provided, use default values\n    fruits = fruits if fruits else ['Apple', 'Banana', 'Cherry', 'Date', 'Elderberry']\n    days = days if days else 30\n\n    # Set seed for reproducibility\n    np.random.seed(seed)\n\n    # Generate dates\n    date_range = pd.date_range(start=datetime.now(), periods=days)\n\n    # Generate sales data\n    sales_data = {\n        'Date': date_range,\n        'Fruit': np.random.choice(fruits, days),\n        'Sales': np.random.randint(sales_lower_bound, sales_upper_bound, days)\n    }\n\n    # Append sales data to df\n    df = df.append(pd.DataFrame(sales_data))\n\n    # Create a seaborn boxplot\n    g = sns.boxplot(x='Fruit', y='Sales', data=df)\n\n    return df, g", "raw_solution": "import pandas as pd\nimport numpy as np\nimport itertools\nfrom datetime import datetime, timedelta\nimport seaborn as sns\n\ndef task_func(df, fruits=None, days=None, seed=None, sales_lower_bound=1, sales_upper_bound=50):\n    # Check if df is a pandas DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"'df' should be a pandas DataFrame\")\n\n    # Check if df is not empty\n    if df.empty:\n        raise ValueError(\"'df' should not be empty\")\n\n    # Check if sales_lower_bound is less than sales_upper_bound\n    if not sales_lower_bound < sales_upper_bound:\n        raise ValueError(\"'sales_lower_bound' should be less than 'sales_upper_bound'\")\n\n    # If fruits and days are not provided, use default values\n    fruits = fruits if fruits else ['Apple', 'Banana', 'Cherry', 'Date', 'Elderberry']\n    days = days if days else 30\n\n    # Set seed for reproducibility\n    np.random.seed(seed)\n\n    # Generate dates\n    date_range = pd.date_range(start=datetime.now(), periods=days)\n\n    # Generate sales data\n    sales_data = {\n        'Date': date_range,\n        'Fruit': np.random.choice(fruits, days),\n        'Sales': np.random.randint(sales_lower_bound, sales_upper_bound, days)\n    }\n\n    # Append sales data to df\n    df = df.append(pd.DataFrame(sales_data))\n\n    # Create a seaborn boxplot\n    g = sns.boxplot(x='Fruit', y='Sales', data=df)\n\n    return df, g"}
{"task_id": "BigCodeBench/76", "solution": "import random\nimport string\nfrom django.http import HttpResponse\ndef task_func(request, session_expire_time):\n    # Generate a random session key\n    session_key = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(20))\n\n    # Check if the session key contains both letters and digits\n    if not any(c.isdigit() for c in session_key) or not any(c.isalpha() for c in session_key):\n        raise ValueError(\"Session key must contain both letters and digits\")\n\n    # Check if the session key length is 20\n    if len(session_key) != 20:\n        raise ValueError(\"Session key length must be 20\")\n\n    # Set the session key in a cookie with the specified expiration time\n    response = HttpResponse(\"Session key generated successfully.\")\n    response.set_cookie('session_key', session_key, max_age=session_expire_time)\n\n    return response", "raw_solution": "import random\nimport string\nfrom django.http import HttpResponse\n\ndef task_func(request, session_expire_time):\n    # Generate a random session key\n    session_key = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(20))\n\n    # Check if the session key contains both letters and digits\n    if not any(c.isdigit() for c in session_key) or not any(c.isalpha() for c in session_key):\n        raise ValueError(\"Session key must contain both letters and digits\")\n\n    # Check if the session key length is 20\n    if len(session_key) != 20:\n        raise ValueError(\"Session key length must be 20\")\n\n    # Set the session key in a cookie with the specified expiration time\n    response = HttpResponse(\"Session key generated successfully.\")\n    response.set_cookie('session_key', session_key, max_age=session_expire_time)\n\n    return response"}
{"task_id": "BigCodeBench/77", "solution": "import hashlib\nimport base64\nimport binascii\nfrom django.http import HttpResponseBadRequest, HttpResponse\ndef task_func(data):\n    try:\n        username = data['username']\n        password = data['password']\n    except KeyError:\n        return HttpResponseBadRequest('Bad Request.')\n\n    try:\n        decoded_password = base64.b64decode(password)\n    except (binascii.Error, TypeError, UnicodeDecodeError):\n        return HttpResponseBadRequest('Bad Request.')\n\n    expected_password = hashlib.sha256('password'.encode()).digest()\n\n    if username == 'admin' and decoded_password == expected_password:\n        return HttpResponse('Login successful.', status=400)\n    else:\n        return HttpResponse('Login failed.', status=401)", "raw_solution": "import hashlib\nimport base64\nimport binascii\nfrom django.http import HttpResponseBadRequest, HttpResponse\n\ndef task_func(data):\n    try:\n        username = data['username']\n        password = data['password']\n    except KeyError:\n        return HttpResponseBadRequest('Bad Request.')\n\n    try:\n        decoded_password = base64.b64decode(password)\n    except (binascii.Error, TypeError, UnicodeDecodeError):\n        return HttpResponseBadRequest('Bad Request.')\n\n    expected_password = hashlib.sha256('password'.encode()).digest()\n\n    if username == 'admin' and decoded_password == expected_password:\n        return HttpResponse('Login successful.', status=400)\n    else:\n        return HttpResponse('Login failed.', status=401)"}
{"task_id": "BigCodeBench/78", "solution": "import csv\nimport io\nfrom django.http import HttpRequest, FileResponse\ndef task_func(request, header, csv_data):\n    # Create a StringIO object\n    output = io.StringIO()\n\n    # Create a writer object\n    writer = csv.writer(output)\n\n    # Write the header\n    writer.writerow(header)\n\n    # Write the CSV data\n    for row in csv_data:\n        writer.writerow(row)\n\n    # Reset the file pointer to the start of the file\n    output.seek(0)\n\n    # Create a FileResponse object\n    response = FileResponse(output, content_type='text/csv')\n    response['Content-Disposition'] = 'attachment; filename=\"output.csv\"'\n\n    return response", "raw_solution": "import csv\nimport io\nfrom django.http import HttpRequest, FileResponse\n\ndef task_func(request, header, csv_data):\n    # Create a StringIO object\n    output = io.StringIO()\n\n    # Create a writer object\n    writer = csv.writer(output)\n\n    # Write the header\n    writer.writerow(header)\n\n    # Write the CSV data\n    for row in csv_data:\n        writer.writerow(row)\n\n    # Reset the file pointer to the start of the file\n    output.seek(0)\n\n    # Create a FileResponse object\n    response = FileResponse(output, content_type='text/csv')\n    response['Content-Disposition'] = 'attachment; filename=\"output.csv\"'\n\n    return response"}
{"task_id": "BigCodeBench/79", "solution": "import zipfile\nimport io\nfrom django.http import FileResponse, HttpRequest\nfrom django.conf import settings\ndef task_func(request, file_paths):\n    \"\"\"\n    Generates a ZIP file response for a Django HttpRequest, zipping the specified files.\n\n    Args:\n        request (HttpRequest): The Django HttpRequest object.\n        file_paths (list): A list of file paths to be zipped.\n\n    Returns:\n        FileResponse: A Django FileResponse object containing the ZIP file as an attachment.\n    \"\"\"\n    # Create a file-like object to store the zip file\n    zip_buffer = io.BytesIO()\n\n    # Create a zip file object\n    with zipfile.ZipFile(zip_buffer, \"a\", zipfile.ZIP_DEFLATED, False) as zip_file:\n        # Loop through each file path\n        for file_path in file_paths:\n            # Get the file name from the file path\n            file_name = file_path.split('/')[-1]\n            # Add the file to the zip file\n            zip_file.write(file_path, file_name)\n\n    # Reset the file pointer to the start of the file\n    zip_buffer.seek(0)\n\n    # Create a FileResponse object with the zip file\n    response = FileResponse(zip_buffer, content_type='application/zip')\n    # Set the content disposition to indicate that this is a downloadable file\n    response['Content-Disposition'] = 'attachment; filename=\"files.zip\"'\n\n    return response", "raw_solution": "import zipfile\nimport io\nfrom django.http import FileResponse, HttpRequest\nfrom django.conf import settings\n\ndef task_func(request, file_paths):\n    \"\"\"\n    Generates a ZIP file response for a Django HttpRequest, zipping the specified files.\n\n    Args:\n        request (HttpRequest): The Django HttpRequest object.\n        file_paths (list): A list of file paths to be zipped.\n\n    Returns:\n        FileResponse: A Django FileResponse object containing the ZIP file as an attachment.\n    \"\"\"\n    # Create a file-like object to store the zip file\n    zip_buffer = io.BytesIO()\n\n    # Create a zip file object\n    with zipfile.ZipFile(zip_buffer, \"a\", zipfile.ZIP_DEFLATED, False) as zip_file:\n        # Loop through each file path\n        for file_path in file_paths:\n            # Get the file name from the file path\n            file_name = file_path.split('/')[-1]\n            # Add the file to the zip file\n            zip_file.write(file_path, file_name)\n\n    # Reset the file pointer to the start of the file\n    zip_buffer.seek(0)\n\n    # Create a FileResponse object with the zip file\n    response = FileResponse(zip_buffer, content_type='application/zip')\n    # Set the content disposition to indicate that this is a downloadable file\n    response['Content-Disposition'] = 'attachment; filename=\"files.zip\"'\n\n    return response"}
{"task_id": "BigCodeBench/80", "solution": "from flask import Flask, render_template, request\nimport json\nimport logging", "raw_solution": "from flask import Flask, render_template, request\nimport json\nimport logging\nlogging.basicConfig(filename=\"out.log\", level=logging.INFO)\n\ndef create_app(template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n\n    @app.route('/', methods=['POST'])\n    def root():\n        data = request.get_json()\n        logging.info(json.dumps(data))\n        return render_template('index.html', data=data)\n\n    return app\n\n# Test the function"}
{"task_id": "BigCodeBench/81", "solution": "from flask import Flask\nfrom flask_restful import Resource, Api\nimport requests\ndef task_func(api_url, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    api = Api(app)\n\n    class ExternalApi(Resource):\n        def get(self):\n            response = requests.get(api_url)\n            return response.json(), 200\n\n    api.add_resource(ExternalApi, '/api')\n\n    return app", "raw_solution": "from flask import Flask\nfrom flask_restful import Resource, Api\nimport requests\n\ndef task_func(api_url, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    api = Api(app)\n\n    class ExternalApi(Resource):\n        def get(self):\n            response = requests.get(api_url)\n            return response.json(), 200\n\n    api.add_resource(ExternalApi, '/api')\n\n    return app\n\n# Test the function"}
{"task_id": "BigCodeBench/82", "solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash", "raw_solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\n\nclass User(UserMixin):\n    def __init__(self, username, password):\n        self.id = username\n        self.password_hash = generate_password_hash(password)\n\n    def check_password(self, password):\n        return check_password_hash(self.password_hash, password)\n\nclass LoginForm(FlaskForm):\n    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n    password = PasswordField('Password', validators=[DataRequired(), Length(min=8, max=80)])\n    submit = SubmitField('Log In')\n\nlogin_manager = LoginManager()\n\n@login_manager.user_loader\ndef load_user(user_id):\n    return User('admin', 'admin')\n\napp = Flask(__name__, template_folder='templates')\napp.config['SECRET_KEY'] = 'secret'\nlogin_manager.init_app(app)\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    form = LoginForm()\n    if form.validate_on_submit():\n        user = User(form.username.data, form.password.data)\n        if user.id == 'admin' and user.check_password(form.password.data):\n            login_user(user)\n            return redirect(url_for('protected'))\n    return render_template('login.html', form=form)\n\n@app.route('/logout')\n@login_required\ndef logout():\n    logout_user()\n    return redirect(url_for('login'))\n\n@app.route('/protected')\n@login_required\ndef protected():\n    return 'Logged in as: ' + current_user.id\n"}
{"task_id": "BigCodeBench/83", "solution": "from flask import Flask\nfrom flask_mail import Mail, Message\ndef task_func(smtp_server, smtp_port, smtp_user, smtp_password, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    mail = Mail(app)\n\n    app.config['MAIL_SERVER'] = smtp_server\n    app.config['MAIL_PORT'] = smtp_port\n    app.config['MAIL_USERNAME'] = smtp_user\n    app.config['MAIL_PASSWORD'] = smtp_password\n    app.config['MAIL_USE_TLS'] = False\n    app.config['MAIL_USE_SSL'] = True\n\n    mail = Mail(app)\n\n    @app.route(\"/send_email\")\n    def send_email():\n        msg = Message('Hello', sender=smtp_user, recipients=['recipient@example.com'])\n        msg.body = \"This is the email body\"\n        mail.send(msg)\n        return \"Email sent\"\n\n    return app", "raw_solution": "from flask import Flask\nfrom flask_mail import Mail, Message\n\ndef task_func(smtp_server, smtp_port, smtp_user, smtp_password, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    mail = Mail(app)\n\n    app.config['MAIL_SERVER'] = smtp_server\n    app.config['MAIL_PORT'] = smtp_port\n    app.config['MAIL_USERNAME'] = smtp_user\n    app.config['MAIL_PASSWORD'] = smtp_password\n    app.config['MAIL_USE_TLS'] = False\n    app.config['MAIL_USE_SSL'] = True\n\n    mail = Mail(app)\n\n    @app.route(\"/send_email\")\n    def send_email():\n        msg = Message('Hello', sender=smtp_user, recipients=['recipient@example.com'])\n        msg.body = \"This is the email body\"\n        mail.send(msg)\n        return \"Email sent\"\n\n    return app\n\n# Test the function\napp = task_func('smtp.example.com', 465, 'user@example.com', 'password', 'templates')\n\n@app.route(\"/\")\ndef home():\n    return \"Flask: A Flask application instance configured for sending emails.\"\n"}
{"task_id": "BigCodeBench/84", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(products, n_samples=100, sales_lower=50, sales_upper=200, profit_margin_min=0.1, profit_margin_max=0.5, random_seed=42):\n    # Check for type and value errors\n    if not isinstance(products, list) or not all(isinstance(i, str) for i in products):\n        raise TypeError(\"products should be a list of strings\")\n    if not isinstance(n_samples, int) or n_samples <= 0:\n        raise ValueError(\"n_samples should be a positive integer\")\n    if not isinstance(sales_lower, (int, float)) or not isinstance(sales_upper, (int, float)):\n        raise TypeError(\"sales_lower and sales_upper should be numeric\")\n    if sales_lower > sales_upper:\n        raise ValueError(\"sales_lower should be less than or equal to sales_upper\")\n    if not isinstance(profit_margin_min, (int, float)) or not isinstance(profit_margin_max, (int, float)):\n        raise TypeError(\"profit_margin_min and profit_margin_max should be numeric\")\n    if profit_margin_min > profit_margin_max:\n        raise ValueError(\"profit_margin_min should be less than or equal to profit_margin_max\")\n\n    # Set random seed\n    np.random.seed(random_seed)\n\n    # Generate sales and profit data\n    sales = np.random.randint(sales_lower, sales_upper, n_samples)\n    profit_margins = np.random.uniform(profit_margin_min, profit_margin_max, n_samples)\n    profits = sales * profit_margins\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        \"Product\": np.random.choice(products, n_samples),\n        \"Sales\": sales,\n        \"Profit Margin\": profit_margins,\n        \"Profit\": profits\n    })\n\n    # Aggregate by product and sort by total profit\n    df = df.groupby(\"Product\").sum().sort_values(\"Profit\", ascending=False).reset_index()\n\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(products, n_samples=100, sales_lower=50, sales_upper=200, profit_margin_min=0.1, profit_margin_max=0.5, random_seed=42):\n    # Check for type and value errors\n    if not isinstance(products, list) or not all(isinstance(i, str) for i in products):\n        raise TypeError(\"products should be a list of strings\")\n    if not isinstance(n_samples, int) or n_samples <= 0:\n        raise ValueError(\"n_samples should be a positive integer\")\n    if not isinstance(sales_lower, (int, float)) or not isinstance(sales_upper, (int, float)):\n        raise TypeError(\"sales_lower and sales_upper should be numeric\")\n    if sales_lower > sales_upper:\n        raise ValueError(\"sales_lower should be less than or equal to sales_upper\")\n    if not isinstance(profit_margin_min, (int, float)) or not isinstance(profit_margin_max, (int, float)):\n        raise TypeError(\"profit_margin_min and profit_margin_max should be numeric\")\n    if profit_margin_min > profit_margin_max:\n        raise ValueError(\"profit_margin_min should be less than or equal to profit_margin_max\")\n\n    # Set random seed\n    np.random.seed(random_seed)\n\n    # Generate sales and profit data\n    sales = np.random.randint(sales_lower, sales_upper, n_samples)\n    profit_margins = np.random.uniform(profit_margin_min, profit_margin_max, n_samples)\n    profits = sales * profit_margins\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        \"Product\": np.random.choice(products, n_samples),\n        \"Sales\": sales,\n        \"Profit Margin\": profit_margins,\n        \"Profit\": profits\n    })\n\n    # Aggregate by product and sort by total profit\n    df = df.groupby(\"Product\").sum().sort_values(\"Profit\", ascending=False).reset_index()\n\n    return df"}
{"task_id": "BigCodeBench/85", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\ndef task_func(start_date, end_date, random_seed=42):\n    # Check if end_date is after start_date\n    if end_date < start_date:\n        raise ValueError(\"'end_date' should be after 'start_date'\")\n\n    # Set random seed for reproducibility\n    np.random.seed(random_seed)\n\n    # Generate dates\n    n_days = (end_date - start_date).days + 1\n    dates = [start_date + timedelta(days=x) for x in range(n_days)]\n\n    # Generate random data\n    temperatures = np.random.uniform(-10, 40, n_days)\n    humidities = np.random.uniform(20, 100, n_days)\n    wind_speeds = np.random.uniform(0, 20, n_days)\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        'Date': dates,\n        'Temperature': temperatures,\n        'Humidity': humidities,\n        'Wind Speed': wind_speeds\n    })\n\n    # Set Date as index\n    df.set_index('Date', inplace=True)\n\n    # Plot data\n    fig, ax = plt.subplots(3, figsize=(10,10))\n    df['Temperature'].plot(ax=ax[0], title='Temperature')\n    df['Humidity'].plot(ax=ax[1], title='Humidity')\n    df['Wind Speed'].plot(ax=ax[2], title='Wind Speed')\n\n    return df, ax\nstart_date = datetime.now() - timedelta(days=10)\nend_date = datetime.now()", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\n\ndef task_func(start_date, end_date, random_seed=42):\n    # Check if end_date is after start_date\n    if end_date < start_date:\n        raise ValueError(\"'end_date' should be after 'start_date'\")\n\n    # Set random seed for reproducibility\n    np.random.seed(random_seed)\n\n    # Generate dates\n    n_days = (end_date - start_date).days + 1\n    dates = [start_date + timedelta(days=x) for x in range(n_days)]\n\n    # Generate random data\n    temperatures = np.random.uniform(-10, 40, n_days)\n    humidities = np.random.uniform(20, 100, n_days)\n    wind_speeds = np.random.uniform(0, 20, n_days)\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        'Date': dates,\n        'Temperature': temperatures,\n        'Humidity': humidities,\n        'Wind Speed': wind_speeds\n    })\n\n    # Set Date as index\n    df.set_index('Date', inplace=True)\n\n    # Plot data\n    fig, ax = plt.subplots(3, figsize=(10,10))\n    df['Temperature'].plot(ax=ax[0], title='Temperature')\n    df['Humidity'].plot(ax=ax[1], title='Humidity')\n    df['Wind Speed'].plot(ax=ax[2], title='Wind Speed')\n\n    return df, ax\n\n# Test the function\nstart_date = datetime.now() - timedelta(days=10)\nend_date = datetime.now()\ndf, ax = task_func(start_date, end_date)\nplt.show()"}
{"task_id": "BigCodeBench/86", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(students=[\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"], seed=42):\n    np.random.seed(seed)\n    scores = np.random.randint(0, 100, len(students))\n    df = pd.DataFrame({'Student': students, 'Score': scores})\n    df = df.sort_values('Score')\n    fig, ax = plt.subplots()\n    ax.bar(df['Student'], df['Score'])\n    ax.set_xlabel('Student')\n    ax.set_ylabel('Score')\n    return df, ax.figure", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(students=[\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"], seed=42):\n    np.random.seed(seed)\n    scores = np.random.randint(0, 100, len(students))\n    df = pd.DataFrame({'Student': students, 'Score': scores})\n    df = df.sort_values('Score')\n    fig, ax = plt.subplots()\n    ax.bar(df['Student'], df['Score'])\n    ax.set_xlabel('Student')\n    ax.set_ylabel('Score')\n    return df, ax.figure\n\n# Test the function\ndf, fig = task_func()"}
{"task_id": "BigCodeBench/87", "solution": "import pandas as pd\nfrom random import choices, seed\ndef task_func(products, ratings, weights, random_seed=42):\n    seed(random_seed)\n    product_ratings = choices(products, weights, k=len(products))\n    ratings_df = pd.DataFrame(list(zip(products, product_ratings)), columns=['Product', 'Rating'])\n    ratings_df = ratings_df.sort_values(by='Rating', ascending=False)\n    return ratings_df\nproducts = ['Product1', 'Product2', 'Product3', 'Product4', 'Product5']\nratings = [1, 2, 3, 4, 5]\nweights = [0.1, 0.2, 0.3, 0.2, 0.2]", "raw_solution": "import pandas as pd\nfrom random import choices, seed\n\ndef task_func(products, ratings, weights, random_seed=42):\n    seed(random_seed)\n    product_ratings = choices(products, weights, k=len(products))\n    ratings_df = pd.DataFrame(list(zip(products, product_ratings)), columns=['Product', 'Rating'])\n    ratings_df = ratings_df.sort_values(by='Rating', ascending=False)\n    return ratings_df\n\n# Test the function\nproducts = ['Product1', 'Product2', 'Product3', 'Product4', 'Product5']\nratings = [1, 2, 3, 4, 5]\nweights = [0.1, 0.2, 0.3, 0.2, 0.2]\n\ndf = task_func(products, ratings, weights)"}
{"task_id": "BigCodeBench/88", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\ndef task_func(start_date, end_date, seed=42):\n    np.random.seed(seed)\n    n_days = (end_date - start_date).days + 1\n    dates = pd.date_range(start=start_date, end=end_date)\n    sales = np.random.randint(0, 501, n_days)\n    df = pd.DataFrame({'Date': dates, 'Sales': sales})\n    fig, ax = plt.subplots()\n    df.plot(x='Date', y='Sales', ax=ax)\n    ax.set_title('Sales over time')\n    return df, ax.figure\nstart_date = datetime.now() - timedelta(days=30)\nend_date = datetime.now()", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\n\ndef task_func(start_date, end_date, seed=42):\n    np.random.seed(seed)\n    n_days = (end_date - start_date).days + 1\n    dates = pd.date_range(start=start_date, end=end_date)\n    sales = np.random.randint(0, 501, n_days)\n    df = pd.DataFrame({'Date': dates, 'Sales': sales})\n    fig, ax = plt.subplots()\n    df.plot(x='Date', y='Sales', ax=ax)\n    ax.set_title('Sales over time')\n    return df, ax.figure\n\n# Test the function\nstart_date = datetime.now() - timedelta(days=30)\nend_date = datetime.now()\ndf, fig = task_func(start_date, end_date)\nplt.show()"}
{"task_id": "BigCodeBench/89", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data, column, outlier_z_score):\n    # Standardize the column\n    scaler = StandardScaler()\n    data[column] = scaler.fit_transform(data[column].values.reshape(-1,1))\n    \n    # Calculate Z-scores\n    z_scores = np.abs(stats.zscore(data[column]))\n    \n    # Identify outliers\n    outliers = np.where(z_scores > outlier_z_score)[0]\n    \n    # Remove outliers\n    data_no_outliers = data.drop(data.index[outliers])\n    \n    # Visualize data before and after outlier removal\n    plt.figure(figsize=(12,6))\n    \n    plt.subplot(1,2,1)\n    plt.scatter(range(len(data[column])), data[column])\n    plt.title('Data with Outliers')\n    \n    plt.subplot(1,2,2)\n    plt.scatter(range(len(data_no_outliers[column])), data_no_outliers[column])\n    plt.title('Data without Outliers')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return (data, data_no_outliers, outliers)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data, column, outlier_z_score):\n    # Standardize the column\n    scaler = StandardScaler()\n    data[column] = scaler.fit_transform(data[column].values.reshape(-1,1))\n    \n    # Calculate Z-scores\n    z_scores = np.abs(stats.zscore(data[column]))\n    \n    # Identify outliers\n    outliers = np.where(z_scores > outlier_z_score)[0]\n    \n    # Remove outliers\n    data_no_outliers = data.drop(data.index[outliers])\n    \n    # Visualize data before and after outlier removal\n    plt.figure(figsize=(12,6))\n    \n    plt.subplot(1,2,1)\n    plt.scatter(range(len(data[column])), data[column])\n    plt.title('Data with Outliers')\n    \n    plt.subplot(1,2,2)\n    plt.scatter(range(len(data_no_outliers[column])), data_no_outliers[column])\n    plt.title('Data without Outliers')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return (data, data_no_outliers, outliers)"}
{"task_id": "BigCodeBench/90", "solution": "import numpy as np\nimport math\ndef task_func(data, target, k):\n    # Check if k is a positive integer\n    if not isinstance(k, int) or k < 1:\n        raise ValueError(\"'k' should be a positive integer\")\n\n    # Calculate the distance between each data point and the target\n    distances = [haversine(target, point) for point in data]\n\n    # Get the indices of the k smallest distances\n    k_smallest_indices = np.argpartition(distances, k)[:k]\n\n    # Get the k smallest distances and their corresponding data points\n    k_smallest_distances = [distances[i] for i in k_smallest_indices]\n    k_smallest_points = [data[i] for i in k_smallest_indices]\n\n    # Sort the k smallest distances and their corresponding data points by distance\n    sorted_indices = np.argsort(k_smallest_distances)\n    sorted_distances = [k_smallest_distances[i] for i in sorted_indices]\n    sorted_points = [k_smallest_points[i] for i in sorted_indices]\n\n    return list(zip(sorted_points, sorted_distances))\ndef haversine(point1, point2):\n    lat1, lon1 = math.radians(point1[0]), math.radians(point1[1])\n    lat2, lon2 = math.radians(point2[0]), math.radians(point2[1])\n\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n\n    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n\n    return 6371 * c", "raw_solution": "import numpy as np\nimport math\n\ndef task_func(data, target, k):\n    # Check if k is a positive integer\n    if not isinstance(k, int) or k < 1:\n        raise ValueError(\"'k' should be a positive integer\")\n\n    # Calculate the distance between each data point and the target\n    distances = [haversine(target, point) for point in data]\n\n    # Get the indices of the k smallest distances\n    k_smallest_indices = np.argpartition(distances, k)[:k]\n\n    # Get the k smallest distances and their corresponding data points\n    k_smallest_distances = [distances[i] for i in k_smallest_indices]\n    k_smallest_points = [data[i] for i in k_smallest_indices]\n\n    # Sort the k smallest distances and their corresponding data points by distance\n    sorted_indices = np.argsort(k_smallest_distances)\n    sorted_distances = [k_smallest_distances[i] for i in sorted_indices]\n    sorted_points = [k_smallest_points[i] for i in sorted_indices]\n\n    return list(zip(sorted_points, sorted_distances))\n\ndef haversine(point1, point2):\n    lat1, lon1 = math.radians(point1[0]), math.radians(point1[1])\n    lat2, lon2 = math.radians(point2[0]), math.radians(point2[1])\n\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n\n    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n\n    return 6371 * c"}
{"task_id": "BigCodeBench/91", "solution": "from scipy.stats import linregress\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(data, column1, column2):\n    if column1 not in data.columns or column2 not in data.columns:\n        raise ValueError(\"Specified columns do not exist in the DataFrame.\")\n\n    slope, intercept, r_value, p_value, std_err = linregress(data[column1], data[column2])\n\n    fig, ax = plt.subplots()\n    ax.scatter(data[column1], data[column2])\n    ax.plot(data[column1], slope*data[column1] + intercept, color='red')\n    ax.set_xlabel(column1)\n    ax.set_ylabel(column2)\n    ax.set_title(f'Linear Regression: {column1} vs {column2}')\n\n    return (slope, intercept, r_value, p_value, std_err), ax", "raw_solution": "from scipy.stats import linregress\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(data, column1, column2):\n    if column1 not in data.columns or column2 not in data.columns:\n        raise ValueError(\"Specified columns do not exist in the DataFrame.\")\n\n    slope, intercept, r_value, p_value, std_err = linregress(data[column1], data[column2])\n\n    fig, ax = plt.subplots()\n    ax.scatter(data[column1], data[column2])\n    ax.plot(data[column1], slope*data[column1] + intercept, color='red')\n    ax.set_xlabel(column1)\n    ax.set_ylabel(column2)\n    ax.set_title(f'Linear Regression: {column1} vs {column2}')\n\n    return (slope, intercept, r_value, p_value, std_err), ax"}
{"task_id": "BigCodeBench/92", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nimport numpy as np\ndef task_func(data, n_clusters=3):\n    # Check if data is a pandas DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' should be a pandas DataFrame\")\n\n    # Check if n_clusters is an integer greater than 1\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"'n_clusters' should be an integer greater than 1\")\n\n    # Perform K-means clustering\n    kmeans = KMeans(n_clusters=n_clusters)\n    labels = kmeans.fit_predict(data)\n\n    # Generate scatter plot\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels)\n\n    # Plot centroids\n    centroids = kmeans.cluster_centers_\n    ax.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=169, linewidths=3,\n                color='r', zorder=10)\n\n    plt.title('K-Means Clustering')\n    plt.xlabel('Feature 1')\n    plt.ylabel('Feature 2')\n\n    return labels, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nimport numpy as np\n\ndef task_func(data, n_clusters=3):\n    # Check if data is a pandas DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' should be a pandas DataFrame\")\n\n    # Check if n_clusters is an integer greater than 1\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"'n_clusters' should be an integer greater than 1\")\n\n    # Perform K-means clustering\n    kmeans = KMeans(n_clusters=n_clusters)\n    labels = kmeans.fit_predict(data)\n\n    # Generate scatter plot\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels)\n\n    # Plot centroids\n    centroids = kmeans.cluster_centers_\n    ax.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=169, linewidths=3,\n                color='r', zorder=10)\n\n    plt.title('K-Means Clustering')\n    plt.xlabel('Feature 1')\n    plt.ylabel('Feature 2')\n\n    return labels, ax"}
{"task_id": "BigCodeBench/93", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(data, n_components=2):\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError(\"n_components must be a positive integer\")\n\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n\n    transformed_df = pd.DataFrame(transformed_data, columns=[f'PC{i+1}' for i in range(n_components)])\n\n    fig, ax = plt.subplots()\n    ax.scatter(transformed_df.iloc[:, 0], transformed_df.iloc[:, 1])\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    ax.set_title('Scatter plot of the transformed data')\n\n    return transformed_df, ax.figure", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError(\"n_components must be a positive integer\")\n\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n\n    transformed_df = pd.DataFrame(transformed_data, columns=[f'PC{i+1}' for i in range(n_components)])\n\n    fig, ax = plt.subplots()\n    ax.scatter(transformed_df.iloc[:, 0], transformed_df.iloc[:, 1])\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    ax.set_title('Scatter plot of the transformed data')\n\n    return transformed_df, ax.figure"}
{"task_id": "BigCodeBench/94", "solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(mean, std_dev, num_samples):\n    # Set the random seed for reproducibility\n    np.random.seed(0)\n\n    # Generate samples from a normal distribution\n    samples = np.random.normal(mean, std_dev, num_samples)\n\n    # Create a histogram of the samples\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.hist(samples, bins=30, density=True, color='skyblue', edgecolor='black', label='Histogram')\n\n    # Generate x values for the PDF\n    x = np.linspace(samples.min(), samples.max(), 100)\n\n    # Overlay the PDF on the histogram\n    ax.plot(x, norm.pdf(x, mean, std_dev), color='red', label='PDF')\n\n    # Set plot title\n    plt.title(f\"Fit results: mean = {mean:.2f}, std = {std_dev:.2f}\")\n\n    # Add legend\n    plt.legend()\n\n    # Return the plot and the samples\n    return fig, samples", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(mean, std_dev, num_samples):\n    # Set the random seed for reproducibility\n    np.random.seed(0)\n\n    # Generate samples from a normal distribution\n    samples = np.random.normal(mean, std_dev, num_samples)\n\n    # Create a histogram of the samples\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.hist(samples, bins=30, density=True, color='skyblue', edgecolor='black', label='Histogram')\n\n    # Generate x values for the PDF\n    x = np.linspace(samples.min(), samples.max(), 100)\n\n    # Overlay the PDF on the histogram\n    ax.plot(x, norm.pdf(x, mean, std_dev), color='red', label='PDF')\n\n    # Set plot title\n    plt.title(f\"Fit results: mean = {mean:.2f}, std = {std_dev:.2f}\")\n\n    # Add legend\n    plt.legend()\n\n    # Return the plot and the samples\n    return fig, samples"}
{"task_id": "BigCodeBench/95", "solution": "import pandas as pd\nfrom random import randint, uniform, seed\ndef task_func(categories=None, months=None, random_seed=42):\n    # Check if categories or months is not provided as a list or is an empty list\n    if not isinstance(categories, list) or not isinstance(months, list) or not categories or not months:\n        raise ValueError(\"Both 'categories' and 'months' must be provided as lists and cannot be empty.\")\n\n    # Set the random seed\n    seed(random_seed)\n\n    # Generate sales data\n    data = []\n    for category in categories:\n        for month in months:\n            sales = randint(100, 500) + uniform(0, 1)\n            data.append([month, category, sales])\n\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=['Month', 'Category', 'Sales'])\n\n    return df", "raw_solution": "import pandas as pd\nfrom random import randint, uniform, seed\n\ndef task_func(categories=None, months=None, random_seed=42):\n    # Check if categories or months is not provided as a list or is an empty list\n    if not isinstance(categories, list) or not isinstance(months, list) or not categories or not months:\n        raise ValueError(\"Both 'categories' and 'months' must be provided as lists and cannot be empty.\")\n\n    # Set the random seed\n    seed(random_seed)\n\n    # Generate sales data\n    data = []\n    for category in categories:\n        for month in months:\n            sales = randint(100, 500) + uniform(0, 1)\n            data.append([month, category, sales])\n\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=['Month', 'Category', 'Sales'])\n\n    return df"}
{"task_id": "BigCodeBench/96", "solution": "import csv\nfrom collections import Counter\nimport operator\ndef task_func(csv_file, csv_delimiter):\n    with open(csv_file, 'r') as file:\n        reader = csv.reader(file, delimiter=csv_delimiter)\n        data = [word for row in reader for word in row]\n    counter = Counter(data)\n    sorted_words = sorted(counter.items(), key=operator.itemgetter(1), reverse=True)\n    return sorted_words\ncsv_file = 'test.csv'\ncsv_delimiter = ','", "raw_solution": "import csv\nfrom collections import Counter\nimport operator\n\ndef task_func(csv_file, csv_delimiter):\n    with open(csv_file, 'r') as file:\n        reader = csv.reader(file, delimiter=csv_delimiter)\n        data = [word for row in reader for word in row]\n    counter = Counter(data)\n    sorted_words = sorted(counter.items(), key=operator.itemgetter(1), reverse=True)\n    return sorted_words\n\n# Test the function\ncsv_file = 'test.csv'\ncsv_delimiter = ','"}
{"task_id": "BigCodeBench/97", "solution": "import math\nimport itertools\nfrom functools import reduce\nfrom operator import mul\ndef task_func(numbers):\n    log_sum = 0\n    for r in range(1, len(numbers) + 1):\n        for subset in itertools.combinations(numbers, r):\n            product = reduce(mul, subset)\n            log_sum += math.log(product)\n    return log_sum\nnumbers = [1, 2, 3, 4]", "raw_solution": "import math\nimport itertools\nfrom functools import reduce\nfrom operator import mul\n\ndef task_func(numbers):\n    log_sum = 0\n    for r in range(1, len(numbers) + 1):\n        for subset in itertools.combinations(numbers, r):\n            product = reduce(mul, subset)\n            log_sum += math.log(product)\n    return log_sum\n\n# Test the function\nnumbers = [1, 2, 3, 4]"}
{"task_id": "BigCodeBench/98", "solution": "import random\nimport string\nfrom collections import Counter\ndef task_func(num_strings, string_length):\n    # Generate a list of random strings\n    random_strings = [''.join(random.choices(string.ascii_lowercase, k=string_length)) for _ in range(num_strings)]\n\n    # Flatten the list of strings and count the frequency of each character\n    char_counts = Counter(''.join(random_strings))\n\n    # Return the characters and their frequencies sorted by frequency in descending order\n    return sorted(char_counts.items(), key=lambda x: x[1], reverse=True)", "raw_solution": "import random\nimport string\nfrom collections import Counter\n\ndef task_func(num_strings, string_length):\n    # Generate a list of random strings\n    random_strings = [''.join(random.choices(string.ascii_lowercase, k=string_length)) for _ in range(num_strings)]\n\n    # Flatten the list of strings and count the frequency of each character\n    char_counts = Counter(''.join(random_strings))\n\n    # Return the characters and their frequencies sorted by frequency in descending order\n    return sorted(char_counts.items(), key=lambda x: x[1], reverse=True)\n\n# Test the function"}
{"task_id": "BigCodeBench/99", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\ndef task_func():\n    # Load iris dataset\n    iris = load_iris()\n    iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    iris_df['species'] = iris.target\n\n    # Set Arial font\n    plt.rcParams['font.family'] = 'Arial'\n\n    # Create pair plot\n    g = sns.pairplot(iris_df, hue='species', diag_kind='kde', plot_kws={'alpha': 0.6, 's': 80, 'edgecolor': 'k'})\n    g.fig.suptitle(\"Iris Dataset Pair Plot\", y=1.08)\n\n    return g.fig", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\n\ndef task_func():\n    # Load iris dataset\n    iris = load_iris()\n    iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    iris_df['species'] = iris.target\n\n    # Set Arial font\n    plt.rcParams['font.family'] = 'Arial'\n\n    # Create pair plot\n    g = sns.pairplot(iris_df, hue='species', diag_kind='kde', plot_kws={'alpha': 0.6, 's': 80, 'edgecolor': 'k'})\n    g.fig.suptitle(\"Iris Dataset Pair Plot\", y=1.08)\n\n    return g.fig\n\n# Test the function\nfig = task_func()\nplt.show()"}
{"task_id": "BigCodeBench/100", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\ndef task_func(seed=42):\n    try:\n        # Set the seed for reproducibility\n        random.seed(seed)\n\n        # Generate a DataFrame with dates and random values\n        dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(30)]\n        values = [random.random() for _ in range(30)]\n        df = pd.DataFrame({'Date': dates, 'Value': values})\n        df['Date'] = pd.to_datetime(df['Date'])\n\n        # Create the plot\n        plt.figure(figsize=(10, 6))\n        plt.plot(df['Date'], df['Value'])\n        plt.xlabel('Date')\n        plt.ylabel('Value')\n        plt.title('Random Time Series Data')\n        plt.xticks(rotation=45)\n        plt.grid(True)\n        plt.rcParams[\"font.family\"] = \"Arial\"\n\n        return plt.gca()\n\n    except Exception as e:\n        raise ValueError('Issue generating the data or plot: {}'.format(e))", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\n\ndef task_func(seed=42):\n    try:\n        # Set the seed for reproducibility\n        random.seed(seed)\n\n        # Generate a DataFrame with dates and random values\n        dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(30)]\n        values = [random.random() for _ in range(30)]\n        df = pd.DataFrame({'Date': dates, 'Value': values})\n        df['Date'] = pd.to_datetime(df['Date'])\n\n        # Create the plot\n        plt.figure(figsize=(10, 6))\n        plt.plot(df['Date'], df['Value'])\n        plt.xlabel('Date')\n        plt.ylabel('Value')\n        plt.title('Random Time Series Data')\n        plt.xticks(rotation=45)\n        plt.grid(True)\n        plt.rcParams[\"font.family\"] = \"Arial\"\n\n        return plt.gca()\n\n    except Exception as e:\n        raise ValueError('Issue generating the data or plot: {}'.format(e))\n\n# Test the function\nax = task_func()\nplt.show()"}
{"task_id": "BigCodeBench/101", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42, save_to=None):\n    try:\n        np.random.seed(seed)\n        data = pd.read_csv(data_url, delimiter=\"\\s+\", skiprows=22, header=None)\n        data.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n        correlation = data.corr()\n        plt.figure(figsize=(12, 10))\n        sns.heatmap(correlation, annot=True, cmap='coolwarm')\n        if save_to:\n            plt.savefig(save_to)\n        return plt.gca()\n    except Exception as e:\n        raise ValueError(f\"An error occurred: {e}\")", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42, save_to=None):\n    try:\n        np.random.seed(seed)\n        data = pd.read_csv(data_url, delimiter=\"\\s+\", skiprows=22, header=None)\n        data.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n        correlation = data.corr()\n        plt.figure(figsize=(12, 10))\n        sns.heatmap(correlation, annot=True, cmap='coolwarm')\n        if save_to:\n            plt.savefig(save_to)\n        return plt.gca()\n    except Exception as e:\n        raise ValueError(f\"An error occurred: {e}\")\n\n# Test the function\ntask_func(save_to='correlation_heatmap.png')"}
{"task_id": "BigCodeBench/102", "solution": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.datasets import load_diabetes\ndef task_func():\n    # Load the diabetes dataset\n    diabetes = load_diabetes()\n\n    # Convert the dataset into a DataFrame\n    df = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)\n    df['target'] = diabetes.target\n\n    # Set the font to Arial\n    plt.rcParams['font.family'] = 'Arial'\n\n    # Create a pairplot\n    fig = sns.pairplot(df)\n\n    return fig, df", "raw_solution": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.datasets import load_diabetes\n\ndef task_func():\n    # Load the diabetes dataset\n    diabetes = load_diabetes()\n\n    # Convert the dataset into a DataFrame\n    df = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)\n    df['target'] = diabetes.target\n\n    # Set the font to Arial\n    plt.rcParams['font.family'] = 'Arial'\n\n    # Create a pairplot\n    fig = sns.pairplot(df)\n\n    return fig, df\n\n# Test the function\nfig, df = task_func()\nfig.show()"}
{"task_id": "BigCodeBench/103", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(temperatures):\n    if not isinstance(temperatures, pd.DataFrame):\n        raise ValueError(\"Input DataFrame is not in the expected format.\")\n    if temperatures.empty:\n        raise ValueError(\"Input DataFrame is empty.\")\n    if 'Date' not in temperatures.columns or 'Temperature (\u00b0C)' not in temperatures.columns:\n        raise ValueError(\"Input DataFrame does not have the expected columns.\")\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(temperatures['Date'], temperatures['Temperature (\u00b0C)'])\n    plt.xlabel('Date')\n    plt.ylabel('Temperature (\u00b0C)')\n    plt.title('Daily Temperatures in New York')\n    plt.xticks(rotation=45)\n    plt.rcParams[\"font.family\"] = \"Arial\"\n\n    return plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(temperatures):\n    if not isinstance(temperatures, pd.DataFrame):\n        raise ValueError(\"Input DataFrame is not in the expected format.\")\n    if temperatures.empty:\n        raise ValueError(\"Input DataFrame is empty.\")\n    if 'Date' not in temperatures.columns or 'Temperature (\u00b0C)' not in temperatures.columns:\n        raise ValueError(\"Input DataFrame does not have the expected columns.\")\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(temperatures['Date'], temperatures['Temperature (\u00b0C)'])\n    plt.xlabel('Date')\n    plt.ylabel('Temperature (\u00b0C)')\n    plt.title('Daily Temperatures in New York')\n    plt.xticks(rotation=45)\n    plt.rcParams[\"font.family\"] = \"Arial\"\n\n    return plt.gca()"}
{"task_id": "BigCodeBench/104", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\ndef task_func(df, groups=['A', 'B', 'C', 'D', 'E']):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n    if 'Date' not in df.columns or 'Value' not in df.columns or 'Group' not in df.columns:\n        raise ValueError(\"DataFrame lacks required columns\")\n\n    fig, ax = plt.subplots()\n    colors = cycle('rgbcmy')\n\n    for group, color in zip(groups, colors):\n        df_group = df[df['Group'] == group]\n        ax.scatter(df_group['Date'], df_group['Value'], color=color, label=group)\n\n    ax.set_title('Scatterplot of Values for Each Group Over Time')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\n\ndef task_func(df, groups=['A', 'B', 'C', 'D', 'E']):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n    if 'Date' not in df.columns or 'Value' not in df.columns or 'Group' not in df.columns:\n        raise ValueError(\"DataFrame lacks required columns\")\n\n    fig, ax = plt.subplots()\n    colors = cycle('rgbcmy')\n\n    for group, color in zip(groups, colors):\n        df_group = df[df['Group'] == group]\n        ax.scatter(df_group['Date'], df_group['Value'], color=color, label=group)\n\n    ax.set_title('Scatterplot of Values for Each Group Over Time')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    return ax"}
{"task_id": "BigCodeBench/105", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\ndef task_func(df):\n    # Check if dataframe is empty\n    if df.empty:\n        raise ValueError(\"Dataframe is empty\")\n\n    # Check if 'date' column exists\n    if 'date' not in df.columns:\n        raise ValueError(\"'date' column is missing\")\n\n    # Check if 'date' column is in datetime format\n    try:\n        df['date'] = pd.to_datetime(df['date'])\n    except ValueError:\n        raise ValueError(\"'date' column is not in datetime format\")\n\n    # Convert 'date' column to ordinal\n    df['date'] = df['date'].map(datetime.datetime.toordinal)\n\n    # Create correlation matrix\n    corr = df.corr()\n\n    # Create a figure for the correlation matrix heatmap\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, square=True, ax=ax)\n    plt.title('Correlation Matrix')\n\n    # Create pair plot\n    pair_grid = sns.pairplot(df)\n\n    return fig, pair_grid", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\ndef task_func(df):\n    # Check if dataframe is empty\n    if df.empty:\n        raise ValueError(\"Dataframe is empty\")\n\n    # Check if 'date' column exists\n    if 'date' not in df.columns:\n        raise ValueError(\"'date' column is missing\")\n\n    # Check if 'date' column is in datetime format\n    try:\n        df['date'] = pd.to_datetime(df['date'])\n    except ValueError:\n        raise ValueError(\"'date' column is not in datetime format\")\n\n    # Convert 'date' column to ordinal\n    df['date'] = df['date'].map(datetime.datetime.toordinal)\n\n    # Create correlation matrix\n    corr = df.corr()\n\n    # Create a figure for the correlation matrix heatmap\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, square=True, ax=ax)\n    plt.title('Correlation Matrix')\n\n    # Create pair plot\n    pair_grid = sns.pairplot(df)\n\n    return fig, pair_grid"}
{"task_id": "BigCodeBench/106", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(df):\n    # Check if df is a valid DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a valid DataFrame\")\n\n    # Check if df has the required columns\n    if not all(col in df.columns for col in ['date', 'value']):\n        raise ValueError(\"'df' lacks the required columns\")\n\n    # Check if 'date' column is in datetime format\n    if not pd.api.types.is_datetime64_any_dtype(df['date']):\n        raise ValueError(\"'date' column is not in datetime format\")\n\n    # Convert 'date' to ordinal\n    df['date'] = df['date'].apply(lambda x: x.toordinal())\n\n    # Prepare data for the model\n    X = df[['date']]\n    y = df['value']\n\n    # Create and fit the model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Make predictions\n    predictions = model.predict(X)\n\n    # Create the plot\n    fig, ax = plt.subplots()\n    ax.scatter(df['date'], df['value'], color='blue', label='Original')\n    ax.scatter(df['date'], predictions, color='red', label='Predicted')\n    ax.set_title('Value vs Date (Linear Regression Prediction)')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    return model, predictions, ax.figure", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(df):\n    # Check if df is a valid DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a valid DataFrame\")\n\n    # Check if df has the required columns\n    if not all(col in df.columns for col in ['date', 'value']):\n        raise ValueError(\"'df' lacks the required columns\")\n\n    # Check if 'date' column is in datetime format\n    if not pd.api.types.is_datetime64_any_dtype(df['date']):\n        raise ValueError(\"'date' column is not in datetime format\")\n\n    # Convert 'date' to ordinal\n    df['date'] = df['date'].apply(lambda x: x.toordinal())\n\n    # Prepare data for the model\n    X = df[['date']]\n    y = df['value']\n\n    # Create and fit the model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Make predictions\n    predictions = model.predict(X)\n\n    # Create the plot\n    fig, ax = plt.subplots()\n    ax.scatter(df['date'], df['value'], color='blue', label='Original')\n    ax.scatter(df['date'], predictions, color='red', label='Predicted')\n    ax.set_title('Value vs Date (Linear Regression Prediction)')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    return model, predictions, ax.figure"}
{"task_id": "BigCodeBench/107", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(df, n_clusters=3, random_state=0):\n    # Check if DataFrame is empty or lacks required columns\n    if df.empty or not all(col in df.columns for col in ['date', 'value']):\n        raise ValueError(\"DataFrame is empty or lacks required columns\")\n\n    # Convert 'date' column to ordinal\n    df['date'] = df['date'].apply(lambda date: date.toordinal())\n\n    # Perform KMeans clustering on 'date' and 'value' columns\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    df['cluster'] = kmeans.fit_predict(df[['date', 'value']])\n\n    # Plot the clusters\n    plt.figure(figsize=(10, 6))\n    plt.scatter(df['date'], df['value'], c=df['cluster'], cmap='viridis')\n    plt.xlabel('Date (ordinal)')\n    plt.ylabel('Value')\n    plt.title('KMeans Clustering of Value vs Date')\n    plt.show()\n\n    return plt.gca()", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(df, n_clusters=3, random_state=0):\n    # Check if DataFrame is empty or lacks required columns\n    if df.empty or not all(col in df.columns for col in ['date', 'value']):\n        raise ValueError(\"DataFrame is empty or lacks required columns\")\n\n    # Convert 'date' column to ordinal\n    df['date'] = df['date'].apply(lambda date: date.toordinal())\n\n    # Perform KMeans clustering on 'date' and 'value' columns\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    df['cluster'] = kmeans.fit_predict(df[['date', 'value']])\n\n    # Plot the clusters\n    plt.figure(figsize=(10, 6))\n    plt.scatter(df['date'], df['value'], c=df['cluster'], cmap='viridis')\n    plt.xlabel('Date (ordinal)')\n    plt.ylabel('Value')\n    plt.title('KMeans Clustering of Value vs Date')\n    plt.show()\n\n    return plt.gca()"}
{"task_id": "BigCodeBench/108", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' should be a pandas DataFrame\")\n\n    # Check if df has 'value' column\n    if 'value' not in df.columns:\n        raise ValueError(\"'df' should have a 'value' column\")\n\n    # Check if 'value' column has numeric data\n    if not pd.api.types.is_numeric_dtype(df['value']):\n        raise ValueError(\"'value' column should have numeric data\")\n\n    # Check if freq is a valid frequency string\n    if freq not in ['D', 'M', 'A', 'Q', 'Y']:\n        raise ValueError(\"'freq' should be a valid frequency string\")\n\n    # Check if decomposition_model is valid\n    if decomposition_model not in ['additive', 'multiplicative']:\n        raise ValueError(\"'decomposition_model' should be either 'additive' or 'multiplicative'\")\n\n    # Decompose the time series\n    decomposition = seasonal_decompose(df['value'], model=decomposition_model, freq=freq)\n\n    # Plot the decomposition\n    fig, ax = plt.subplots(4, 1, figsize=(10,10))\n    decomposition.trend.plot(ax=ax[0])\n    ax[0].set_title('Trend')\n    decomposition.seasonal.plot(ax=ax[1])\n    ax[1].set_title('Seasonality')\n    decomposition.resid.plot(ax=ax[2])\n    ax[2].set_title('Residuals')\n    plt.tight_layout()\n\n    return (decomposition, ax[-1])", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' should be a pandas DataFrame\")\n\n    # Check if df has 'value' column\n    if 'value' not in df.columns:\n        raise ValueError(\"'df' should have a 'value' column\")\n\n    # Check if 'value' column has numeric data\n    if not pd.api.types.is_numeric_dtype(df['value']):\n        raise ValueError(\"'value' column should have numeric data\")\n\n    # Check if freq is a valid frequency string\n    if freq not in ['D', 'M', 'A', 'Q', 'Y']:\n        raise ValueError(\"'freq' should be a valid frequency string\")\n\n    # Check if decomposition_model is valid\n    if decomposition_model not in ['additive', 'multiplicative']:\n        raise ValueError(\"'decomposition_model' should be either 'additive' or 'multiplicative'\")\n\n    # Decompose the time series\n    decomposition = seasonal_decompose(df['value'], model=decomposition_model, freq=freq)\n\n    # Plot the decomposition\n    fig, ax = plt.subplots(4, 1, figsize=(10,10))\n    decomposition.trend.plot(ax=ax[0])\n    ax[0].set_title('Trend')\n    decomposition.seasonal.plot(ax=ax[1])\n    ax[1].set_title('Seasonality')\n    decomposition.resid.plot(ax=ax[2])\n    ax[2].set_title('Residuals')\n    plt.tight_layout()\n\n    return (decomposition, ax[-1])"}
{"task_id": "BigCodeBench/109", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, items=None, locations=None):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n\n    # Check if 'Item' and 'Location' columns exist\n    if 'Item' not in df.columns or 'Location' not in df.columns:\n        raise ValueError(\"'Item' or 'Location' columns are missing\")\n\n    # If items and locations are not provided, use a predefined list\n    if items is None and locations is None:\n        items = ['Item1', 'Item2', 'Item3']\n        locations = ['Location1', 'Location2', 'Location3']\n\n    # Filter DataFrame based on provided items and locations\n    df = df[df['Item'].isin(items) & df['Location'].isin(locations)]\n\n    # Group by 'Item' and 'Location' and count occurrences\n    df_grouped = df.groupby(['Item', 'Location']).size().reset_index(name='Count')\n\n    # Create a pivot table for plotting\n    df_pivot = df_grouped.pivot(index='Item', columns='Location', values='Count')\n\n    # Plot the bar chart\n    ax = df_pivot.plot(kind='bar', figsize=(12, 8))\n\n    # Set plot title and labels\n    plt.title('Item Distribution Across Locations')\n    plt.xlabel('Item')\n    plt.ylabel('Count')\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, items=None, locations=None):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n\n    # Check if 'Item' and 'Location' columns exist\n    if 'Item' not in df.columns or 'Location' not in df.columns:\n        raise ValueError(\"'Item' or 'Location' columns are missing\")\n\n    # If items and locations are not provided, use a predefined list\n    if items is None and locations is None:\n        items = ['Item1', 'Item2', 'Item3']\n        locations = ['Location1', 'Location2', 'Location3']\n\n    # Filter DataFrame based on provided items and locations\n    df = df[df['Item'].isin(items) & df['Location'].isin(locations)]\n\n    # Group by 'Item' and 'Location' and count occurrences\n    df_grouped = df.groupby(['Item', 'Location']).size().reset_index(name='Count')\n\n    # Create a pivot table for plotting\n    df_pivot = df_grouped.pivot(index='Item', columns='Location', values='Count')\n\n    # Plot the bar chart\n    ax = df_pivot.plot(kind='bar', figsize=(12, 8))\n\n    # Set plot title and labels\n    plt.title('Item Distribution Across Locations')\n    plt.xlabel('Item')\n    plt.ylabel('Count')\n\n    return ax"}
{"task_id": "BigCodeBench/110", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n\n    # Check if df has 'Date' and 'Sales' columns\n    if 'Date' not in df.columns or 'Sales' not in df.columns:\n        raise ValueError(\"'df' lacks 'Date' or 'Sales' columns\")\n\n    # Check if df has data to plot\n    if df.empty:\n        raise ValueError(\"'df' has no data to plot\")\n\n    # Convert 'Date' column to datetime\n    df['Date'] = pd.to_datetime(df['Date'])\n\n    # Set 'Date' as index\n    df.set_index('Date', inplace=True)\n\n    # Plot 'Sales' data\n    ax = df['Sales'].plot(kind='line', title='Daily Turnover')\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n\n    # Check if df has 'Date' and 'Sales' columns\n    if 'Date' not in df.columns or 'Sales' not in df.columns:\n        raise ValueError(\"'df' lacks 'Date' or 'Sales' columns\")\n\n    # Check if df has data to plot\n    if df.empty:\n        raise ValueError(\"'df' has no data to plot\")\n\n    # Convert 'Date' column to datetime\n    df['Date'] = pd.to_datetime(df['Date'])\n\n    # Set 'Date' as index\n    df.set_index('Date', inplace=True)\n\n    # Plot 'Sales' data\n    ax = df['Sales'].plot(kind='line', title='Daily Turnover')\n\n    return ax"}
{"task_id": "BigCodeBench/111", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n\n    # Check if df has 'Date', 'Time', and 'Temperature' columns\n    required_columns = ['Date', 'Time', 'Temperature']\n    if not all(col in df.columns for col in required_columns):\n        raise ValueError(\"'df' lacks 'Date', 'Time', or 'Temperature' columns\")\n\n    # Convert 'Date' and 'Time' to datetime and set as index\n    df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n    df.set_index('DateTime', inplace=True)\n\n    # Pivot 'Temperature' data to create a heatmap\n    df_pivot = df.pivot('Date', 'Time', 'Temperature')\n\n    # Create heatmap\n    ax = sns.heatmap(df_pivot)\n\n    return ax", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n\n    # Check if df has 'Date', 'Time', and 'Temperature' columns\n    required_columns = ['Date', 'Time', 'Temperature']\n    if not all(col in df.columns for col in required_columns):\n        raise ValueError(\"'df' lacks 'Date', 'Time', or 'Temperature' columns\")\n\n    # Convert 'Date' and 'Time' to datetime and set as index\n    df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n    df.set_index('DateTime', inplace=True)\n\n    # Pivot 'Temperature' data to create a heatmap\n    df_pivot = df.pivot('Date', 'Time', 'Temperature')\n\n    # Create heatmap\n    ax = sns.heatmap(df_pivot)\n\n    return ax"}
{"task_id": "BigCodeBench/112", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a pandas DataFrame\")\n    if 'Status' not in df.columns:\n        raise ValueError(\"DataFrame does not contain the 'Status' column\")\n\n    status_counts = df['Status'].value_counts()\n    fig, ax = plt.subplots()\n    ax.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%')\n    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a pandas DataFrame\")\n    if 'Status' not in df.columns:\n        raise ValueError(\"DataFrame does not contain the 'Status' column\")\n\n    status_counts = df['Status'].value_counts()\n    fig, ax = plt.subplots()\n    ax.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%')\n    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n    return ax"}
{"task_id": "BigCodeBench/113", "solution": "import json\nfrom collections import Counter\nimport random\nimport os\ndef task_func(my_dict, keys):\n    if len(set(keys)) != 10:\n        raise ValueError(\"'keys' must contain exactly 10 unique elements.\")\n\n    for key in keys:\n        my_dict[key] = random.randint(1, 100)\n\n    # Save the updated dictionary to a JSON file\n    json_file_path = 'updated_dictionary.json'\n    with open(json_file_path, 'w') as json_file:\n        json.dump(my_dict, json_file)\n\n    # Count the frequency of each key\n    counter = Counter(my_dict)\n\n    # Save the key frequencies to a text file\n    txt_file_path = 'key_frequencies.txt'\n    with open(txt_file_path, 'w') as txt_file:\n        for key, count in counter.items():\n            txt_file.write(f'{key}: {count}\\n')\n\n    return (my_dict, json_file_path, txt_file_path)\nmy_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10}\nkeys = ['k1', 'k2', 'k3', 'k4', 'k5', 'k6', 'k7', 'k8', 'k9', 'k10']", "raw_solution": "import json\nfrom collections import Counter\nimport random\nimport os\n\ndef task_func(my_dict, keys):\n    if len(set(keys)) != 10:\n        raise ValueError(\"'keys' must contain exactly 10 unique elements.\")\n\n    for key in keys:\n        my_dict[key] = random.randint(1, 100)\n\n    # Save the updated dictionary to a JSON file\n    json_file_path = 'updated_dictionary.json'\n    with open(json_file_path, 'w') as json_file:\n        json.dump(my_dict, json_file)\n\n    # Count the frequency of each key\n    counter = Counter(my_dict)\n\n    # Save the key frequencies to a text file\n    txt_file_path = 'key_frequencies.txt'\n    with open(txt_file_path, 'w') as txt_file:\n        for key, count in counter.items():\n            txt_file.write(f'{key}: {count}\\n')\n\n    return (my_dict, json_file_path, txt_file_path)\n\n# Test the function\nmy_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10}\nkeys = ['k1', 'k2', 'k3', 'k4', 'k5', 'k6', 'k7', 'k8', 'k9', 'k10']"}
{"task_id": "BigCodeBench/114", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(my_dict):\n    if not isinstance(my_dict, dict):\n        raise TypeError(\"Input should be a dictionary\")\n    if 'array' not in my_dict:\n        raise KeyError(\"'array' key not found in the dictionary\")\n    if not isinstance(my_dict['array'], np.ndarray):\n        raise TypeError(\"The value of 'array' key should be a numpy array\")\n\n    array = my_dict['array']\n    if len(array.shape) != 1:\n        raise ValueError(\"The numpy array should be 1-dimensional\")\n\n    scaler = MinMaxScaler()\n    normalized_array = scaler.fit_transform(array.reshape(-1, 1))\n    my_dict['normalized_array'] = normalized_array.flatten()\n\n    return my_dict", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(my_dict):\n    if not isinstance(my_dict, dict):\n        raise TypeError(\"Input should be a dictionary\")\n    if 'array' not in my_dict:\n        raise KeyError(\"'array' key not found in the dictionary\")\n    if not isinstance(my_dict['array'], np.ndarray):\n        raise TypeError(\"The value of 'array' key should be a numpy array\")\n\n    array = my_dict['array']\n    if len(array.shape) != 1:\n        raise ValueError(\"The numpy array should be 1-dimensional\")\n\n    scaler = MinMaxScaler()\n    normalized_array = scaler.fit_transform(array.reshape(-1, 1))\n    my_dict['normalized_array'] = normalized_array.flatten()\n\n    return my_dict"}
{"task_id": "BigCodeBench/115", "solution": "import numpy as np\nfrom scipy.stats import mode\nfrom scipy.stats import entropy\ndef task_func(numbers):\n    if not numbers:\n        raise ValueError(\"Input list 'numbers' is empty\")\n    arr = np.array(numbers)\n    result = {}\n    result['mode'] = mode(arr)[0][0]\n    result['entropy'] = entropy(arr, base=2)\n    return result", "raw_solution": "import numpy as np\nfrom scipy.stats import mode\nfrom scipy.stats import entropy\n\ndef task_func(numbers):\n    if not numbers:\n        raise ValueError(\"Input list 'numbers' is empty\")\n    arr = np.array(numbers)\n    result = {}\n    result['mode'] = mode(arr)[0][0]\n    result['entropy'] = entropy(arr, base=2)\n    return result"}
{"task_id": "BigCodeBench/116", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(mu, sigma, sample_size):\n    # Generate samples\n    samples = np.random.normal(mu, sigma, sample_size)\n\n    # Plot histogram\n    plt.hist(samples, bins=30, alpha=0.75, color='blue')\n    plt.xlabel(\"Sample values\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Histogram of Generated Samples\")\n    plt.show()\n\n    return samples", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(mu, sigma, sample_size):\n    # Generate samples\n    samples = np.random.normal(mu, sigma, sample_size)\n\n    # Plot histogram\n    plt.hist(samples, bins=30, alpha=0.75, color='blue')\n    plt.xlabel(\"Sample values\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Histogram of Generated Samples\")\n    plt.show()\n\n    return samples\n\n# Test the function\nsamples = task_func(0, 1, 1000)"}
{"task_id": "BigCodeBench/117", "solution": "import pandas as pd\nimport numpy as np\nfrom random import choice, seed as set_seed\ndef task_func(num_of_students, seed=42, name_list=None, gender_list=None, age_range=(15, 20), score_range=(50, 100)):\n    if num_of_students <= 0:\n        raise ValueError(\"num_of_students must be positive\")\n\n    if name_list is None:\n        name_list = ['John', 'Jane', 'Mary', 'James', 'Jennifer', 'Mike', 'Emily', 'Lisa', 'Jacob', 'Sophia']\n    if gender_list is None:\n        gender_list = ['Male', 'Female']\n\n    set_seed(seed)\n\n    data = {\n        'Name': [choice(name_list) for _ in range(num_of_students)],\n        'Age': [np.random.randint(*age_range) for _ in range(num_of_students)],\n        'Gender': [choice(gender_list) for _ in range(num_of_students)],\n        'Score': [np.random.randint(*score_range) for _ in range(num_of_students)]\n    }\n\n    return pd.DataFrame(data)", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom random import choice, seed as set_seed\n\ndef task_func(num_of_students, seed=42, name_list=None, gender_list=None, age_range=(15, 20), score_range=(50, 100)):\n    if num_of_students <= 0:\n        raise ValueError(\"num_of_students must be positive\")\n\n    if name_list is None:\n        name_list = ['John', 'Jane', 'Mary', 'James', 'Jennifer', 'Mike', 'Emily', 'Lisa', 'Jacob', 'Sophia']\n    if gender_list is None:\n        gender_list = ['Male', 'Female']\n\n    set_seed(seed)\n\n    data = {\n        'Name': [choice(name_list) for _ in range(num_of_students)],\n        'Age': [np.random.randint(*age_range) for _ in range(num_of_students)],\n        'Gender': [choice(gender_list) for _ in range(num_of_students)],\n        'Score': [np.random.randint(*score_range) for _ in range(num_of_students)]\n    }\n\n    return pd.DataFrame(data)\n\n# Test the function"}
{"task_id": "BigCodeBench/118", "solution": "import os\nimport shutil\ndef task_func(directory, backup_directory):\n    # Check if backup directory exists, if not create it\n    if not os.path.exists(backup_directory):\n        os.makedirs(backup_directory)\n\n    # Get a list of all files in the directory\n    files = os.listdir(directory)\n\n    # Filter the list to only include JSON files\n    json_files = [file for file in files if file.endswith('.json')]\n\n    # Copy each JSON file to the backup directory\n    copied_files = []\n    for file in json_files:\n        shutil.copy(os.path.join(directory, file), backup_directory)\n        copied_files.append(os.path.join(backup_directory, file))\n\n    return copied_files", "raw_solution": "import os\nimport shutil\n\ndef task_func(directory, backup_directory):\n    # Check if backup directory exists, if not create it\n    if not os.path.exists(backup_directory):\n        os.makedirs(backup_directory)\n\n    # Get a list of all files in the directory\n    files = os.listdir(directory)\n\n    # Filter the list to only include JSON files\n    json_files = [file for file in files if file.endswith('.json')]\n\n    # Copy each JSON file to the backup directory\n    copied_files = []\n    for file in json_files:\n        shutil.copy(os.path.join(directory, file), backup_directory)\n        copied_files.append(os.path.join(backup_directory, file))\n\n    return copied_files"}
{"task_id": "BigCodeBench/119", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func():\n    x = np.linspace(-10, 10, 400)\n    y = x**2\n\n    plt.plot(x, y)\n    plt.title('y = x^2')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.grid(True)\n    plt.show()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    x = np.linspace(-10, 10, 400)\n    y = x**2\n\n    plt.plot(x, y)\n    plt.title('y = x^2')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.grid(True)\n    plt.show()\n\n# Test the function\ntask_func()"}
{"task_id": "BigCodeBench/120", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    # Check if start_date and end_date are datetime instances\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"'start_date' and 'end_date' should be datetime instances\")\n\n    # Check if start_date is not later than end_date\n    if start_date > end_date:\n        raise ValueError(\"'start_date' should not be later than 'end_date'\")\n\n    # Set the seed for the random number generator\n    random_seed(seed)\n\n    # Calculate the number of days between start_date and end_date\n    delta = end_date - start_date\n    days = [start_date + timedelta(days=i) for i in range(delta.days + 1)]\n\n    # Generate a pandas Series of random dates\n    random_dates = pd.Series(days).sample(frac=1, random_state=seed)\n\n    return random_dates", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    # Check if start_date and end_date are datetime instances\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"'start_date' and 'end_date' should be datetime instances\")\n\n    # Check if start_date is not later than end_date\n    if start_date > end_date:\n        raise ValueError(\"'start_date' should not be later than 'end_date'\")\n\n    # Set the seed for the random number generator\n    random_seed(seed)\n\n    # Calculate the number of days between start_date and end_date\n    delta = end_date - start_date\n    days = [start_date + timedelta(days=i) for i in range(delta.days + 1)]\n\n    # Generate a pandas Series of random dates\n    random_dates = pd.Series(days).sample(frac=1, random_state=seed)\n\n    return random_dates\n\n# Test the function"}
{"task_id": "BigCodeBench/121", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(my_list, seed=42):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' should be a list\")\n\n    np.random.seed(seed)\n\n    categories = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n    sales_data = pd.DataFrame(np.random.randint(100, 500, size=(12, len(categories))), columns=categories)\n    sales_data['Month'] = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n\n    fig, ax = plt.subplots()\n    sales_data.set_index('Month', inplace=True)\n    sales_data.plot(kind='bar', ax=ax)\n    ax.set_title('Monthly Sales Data')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Sales')\n\n    return (sales_data, ax)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, seed=42):\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' should be a list\")\n\n    np.random.seed(seed)\n\n    categories = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n    sales_data = pd.DataFrame(np.random.randint(100, 500, size=(12, len(categories))), columns=categories)\n    sales_data['Month'] = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n\n    fig, ax = plt.subplots()\n    sales_data.set_index('Month', inplace=True)\n    sales_data.plot(kind='bar', ax=ax)\n    ax.set_title('Monthly Sales Data')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Sales')\n\n    return (sales_data, ax)"}
{"task_id": "BigCodeBench/122", "solution": "import numpy as np\nimport random\ndef task_func(my_list):\n    # Append a random integer between 0 and 100 to the list\n    my_list.append(random.randint(0, 100))\n\n    # Generate a numpy array of random floating-point numbers\n    # The size of the array is equal to the sum of the numbers in the list\n    return np.random.random(sum(my_list))\nmy_list = [1, 2, 3, 4, 5]", "raw_solution": "import numpy as np\nimport random\n\ndef task_func(my_list):\n    # Append a random integer between 0 and 100 to the list\n    my_list.append(random.randint(0, 100))\n\n    # Generate a numpy array of random floating-point numbers\n    # The size of the array is equal to the sum of the numbers in the list\n    return np.random.random(sum(my_list))\n\n# Test the function\nmy_list = [1, 2, 3, 4, 5]"}
{"task_id": "BigCodeBench/123", "solution": "import pandas as pd\nimport os\nimport glob\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    # Check if my_list is a list\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' should be a list\")\n\n    # Add '12' to the list\n    my_list.append('12')\n\n    # Check if files exist in the directory\n    files = glob.glob(os.path.join(file_dir, '*'+file_ext))\n    if not files:\n        raise FileNotFoundError(\"No files found in the specified directory\")\n\n    # Concatenate CSV files into a single DataFrame\n    df = pd.DataFrame()\n    for file in files[:sum(my_list)]:\n        df = pd.concat([df, pd.read_csv(file)])\n\n    return df", "raw_solution": "import pandas as pd\nimport os\nimport glob\n\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    # Check if my_list is a list\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' should be a list\")\n\n    # Add '12' to the list\n    my_list.append('12')\n\n    # Check if files exist in the directory\n    files = glob.glob(os.path.join(file_dir, '*'+file_ext))\n    if not files:\n        raise FileNotFoundError(\"No files found in the specified directory\")\n\n    # Concatenate CSV files into a single DataFrame\n    df = pd.DataFrame()\n    for file in files[:sum(my_list)]:\n        df = pd.concat([df, pd.read_csv(file)])\n\n    return df"}
{"task_id": "BigCodeBench/124", "solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\ndef task_func(my_list, size=100, seed=100):\n    # Check if my_list is a list\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' should be a list\")\n\n    # Check if my_list contains only numeric elements\n    if not all(isinstance(i, (int, float)) for i in my_list):\n        raise ValueError(\"'my_list' should contain only numeric elements\")\n\n    # Append 12 to my_list\n    my_list.append(12)\n\n    # Calculate the sum of elements in my_list\n    sum_list = sum(my_list)\n\n    # Set the seed for random number generation\n    random_seed(seed)\n\n    # Start timer\n    start_time = time.time()\n\n    # Generate a list of random integers\n    random_list = [randint(1, 100) for _ in range(sum_list)]\n\n    # End timer\n    end_time = time.time()\n\n    # Calculate time taken\n    time_taken = end_time - start_time\n\n    # Plot histogram\n    ax = plt.hist(random_list, bins=range(1, 102), edgecolor='black')\n    plt.xlabel('Number')\n    plt.ylabel('Frequency')\n\n    return (time_taken, ax)", "raw_solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, size=100, seed=100):\n    # Check if my_list is a list\n    if not isinstance(my_list, list):\n        raise TypeError(\"'my_list' should be a list\")\n\n    # Check if my_list contains only numeric elements\n    if not all(isinstance(i, (int, float)) for i in my_list):\n        raise ValueError(\"'my_list' should contain only numeric elements\")\n\n    # Append 12 to my_list\n    my_list.append(12)\n\n    # Calculate the sum of elements in my_list\n    sum_list = sum(my_list)\n\n    # Set the seed for random number generation\n    random_seed(seed)\n\n    # Start timer\n    start_time = time.time()\n\n    # Generate a list of random integers\n    random_list = [randint(1, 100) for _ in range(sum_list)]\n\n    # End timer\n    end_time = time.time()\n\n    # Calculate time taken\n    time_taken = end_time - start_time\n\n    # Plot histogram\n    ax = plt.hist(random_list, bins=range(1, 102), edgecolor='black')\n    plt.xlabel('Number')\n    plt.ylabel('Frequency')\n\n    return (time_taken, ax)"}
{"task_id": "BigCodeBench/125", "solution": "from collections import defaultdict\nimport itertools\nimport json\nimport random\ndef task_func(LETTERS, n):\n    # Generate all possible combinations of a given set of letters of length 'n'\n    combinations = [''.join(p) for p in itertools.product(LETTERS, repeat=n)]\n\n    # Count the occurrences of each letter in these combinations\n    letter_counts = defaultdict(int)\n    for combination in combinations:\n        for letter in combination:\n            letter_counts[letter] += 1\n\n    # Generate a random number between 0 and 100\n    random_number = random.randint(0, 100)\n\n    # Save the results in a JSON file\n    filename = f\"prefix_{random_number}.json\"\n    with open(filename, 'w') as f:\n        json.dump(letter_counts, f)\n\n    return filename", "raw_solution": "from collections import defaultdict\nimport itertools\nimport json\nimport random\n\ndef task_func(LETTERS, n):\n    # Generate all possible combinations of a given set of letters of length 'n'\n    combinations = [''.join(p) for p in itertools.product(LETTERS, repeat=n)]\n\n    # Count the occurrences of each letter in these combinations\n    letter_counts = defaultdict(int)\n    for combination in combinations:\n        for letter in combination:\n            letter_counts[letter] += 1\n\n    # Generate a random number between 0 and 100\n    random_number = random.randint(0, 100)\n\n    # Save the results in a JSON file\n    filename = f\"prefix_{random_number}.json\"\n    with open(filename, 'w') as f:\n        json.dump(letter_counts, f)\n\n    return filename"}
{"task_id": "BigCodeBench/126", "solution": "import pandas as pd\nfrom random import randint, seed as random_seed\nimport statistics\nimport matplotlib.pyplot as plt\ndef task_func(animals=None, seed=42):\n    if animals is None:\n        animals = ['Lion', 'Tiger', 'Bear', 'Monkey', 'Elephant', 'Hippo', 'Gorilla', 'Rhino', 'Ostrich', 'Penguin']\n\n    random_seed(seed)\n\n    data = {animal: [randint(1, 100) for _ in range(10)] for animal in animals}\n\n    df = pd.DataFrame(data)\n\n    stats = {\n        'Animal': [],\n        'Mean': [],\n        'Median': [],\n        'Standard Deviation': [],\n    }\n\n    for animal in animals:\n        counts = df[animal]\n        stats['Animal'].append(animal)\n        stats['Mean'].append(statistics.mean(counts))\n        stats['Median'].append(statistics.median(counts))\n        stats['Standard Deviation'].append(statistics.stdev(counts))\n\n    stats_df = pd.DataFrame(stats)\n\n    df.plot(kind='bar', figsize=(12, 8))\n    plt.ylabel('Count')\n    plt.title('Counts of Animals')\n    plt.show()\n\n    return stats_df", "raw_solution": "import pandas as pd\nfrom random import randint, seed as random_seed\nimport statistics\nimport matplotlib.pyplot as plt\n\ndef task_func(animals=None, seed=42):\n    if animals is None:\n        animals = ['Lion', 'Tiger', 'Bear', 'Monkey', 'Elephant', 'Hippo', 'Gorilla', 'Rhino', 'Ostrich', 'Penguin']\n\n    random_seed(seed)\n\n    data = {animal: [randint(1, 100) for _ in range(10)] for animal in animals}\n\n    df = pd.DataFrame(data)\n\n    stats = {\n        'Animal': [],\n        'Mean': [],\n        'Median': [],\n        'Standard Deviation': [],\n    }\n\n    for animal in animals:\n        counts = df[animal]\n        stats['Animal'].append(animal)\n        stats['Mean'].append(statistics.mean(counts))\n        stats['Median'].append(statistics.median(counts))\n        stats['Standard Deviation'].append(statistics.stdev(counts))\n\n    stats_df = pd.DataFrame(stats)\n\n    df.plot(kind='bar', figsize=(12, 8))\n    plt.ylabel('Count')\n    plt.title('Counts of Animals')\n    plt.show()\n\n    return stats_df"}
{"task_id": "BigCodeBench/127", "solution": "import os\nimport shutil\nimport glob\nimport hashlib\ndef task_func(ROOT_DIR, DEST_DIR, SPECIFIC_HASH):\n    if not os.path.exists(ROOT_DIR):\n        raise ValueError(\"Root directory does not exist.\")\n    if not os.path.exists(DEST_DIR):\n        os.makedirs(DEST_DIR)\n\n    count = 0\n    for file in glob.glob(ROOT_DIR + '/*'):\n        if os.path.isfile(file):\n            with open(file, 'rb') as f:\n                data = f.read()\n                md5_hash = hashlib.md5(data).hexdigest()\n                if md5_hash == SPECIFIC_HASH:\n                    shutil.move(file, DEST_DIR)\n                    count += 1\n    return count", "raw_solution": "import os\nimport shutil\nimport glob\nimport hashlib\n\ndef task_func(ROOT_DIR, DEST_DIR, SPECIFIC_HASH):\n    if not os.path.exists(ROOT_DIR):\n        raise ValueError(\"Root directory does not exist.\")\n    if not os.path.exists(DEST_DIR):\n        os.makedirs(DEST_DIR)\n\n    count = 0\n    for file in glob.glob(ROOT_DIR + '/*'):\n        if os.path.isfile(file):\n            with open(file, 'rb') as f:\n                data = f.read()\n                md5_hash = hashlib.md5(data).hexdigest()\n                if md5_hash == SPECIFIC_HASH:\n                    shutil.move(file, DEST_DIR)\n                    count += 1\n    return count"}
{"task_id": "BigCodeBench/128", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randint\ndef task_func(POINTS=100):\n    # Define the directions\n    directions = ['up', 'down', 'left', 'right']\n\n    # Initialize the position\n    x, y = 0, 0\n\n    # Initialize the lists to store the positions\n    x_positions, y_positions = [x], [y]\n\n    # Perform the random walk\n    for _ in range(POINTS):\n        direction = directions[randint(0, 3)]\n        if direction == 'up':\n            y += 1\n        elif direction == 'down':\n            y -= 1\n        elif direction == 'left':\n            x -= 1\n        elif direction == 'right':\n            x += 1\n        x_positions.append(x)\n        y_positions.append(y)\n\n    # Convert the lists to numpy arrays\n    x_positions = np.array(x_positions)\n    y_positions = np.array(y_positions)\n\n    # Plot the path\n    plt.plot(x_positions, y_positions)\n    plt.show()\n\n    return plt.gcf()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randint\n\ndef task_func(POINTS=100):\n    # Define the directions\n    directions = ['up', 'down', 'left', 'right']\n\n    # Initialize the position\n    x, y = 0, 0\n\n    # Initialize the lists to store the positions\n    x_positions, y_positions = [x], [y]\n\n    # Perform the random walk\n    for _ in range(POINTS):\n        direction = directions[randint(0, 3)]\n        if direction == 'up':\n            y += 1\n        elif direction == 'down':\n            y -= 1\n        elif direction == 'left':\n            x -= 1\n        elif direction == 'right':\n            x += 1\n        x_positions.append(x)\n        y_positions.append(y)\n\n    # Convert the lists to numpy arrays\n    x_positions = np.array(x_positions)\n    y_positions = np.array(y_positions)\n\n    # Plot the path\n    plt.plot(x_positions, y_positions)\n    plt.show()\n\n    return plt.gcf()\n\n# Test the function\nfig = task_func(100)\nassert isinstance(fig, plt.Figure), \"The function should return a matplotlib figure object\""}
{"task_id": "BigCodeBench/129", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\ndef task_func(url='http://example.com'):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        print (\"HTTP Error:\",errh)\n        return None\n    except requests.exceptions.ConnectionError as errc:\n        print (\"Error Connecting:\",errc)\n        return None\n    except requests.exceptions.Timeout as errt:\n        print (\"Timeout Error:\",errt)\n        return None\n    except requests.exceptions.RequestException as err:\n        print (\"Something went wrong\",err)\n        return None\n\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    table = soup.find_all('table')\n    if not table:\n        raise ValueError(\"No table data found on the page\")\n\n    table = table[0]\n    df = pd.DataFrame(data=[[td.get_text(strip=True) for td in tr.find_all('td')] for tr in table.find_all('tr')])\n\n    header = [th.get_text(strip=True) for th in table.find_all('th')]\n    if header:\n        df.columns = header\n\n    return df", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef task_func(url='http://example.com'):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        print (\"HTTP Error:\",errh)\n        return None\n    except requests.exceptions.ConnectionError as errc:\n        print (\"Error Connecting:\",errc)\n        return None\n    except requests.exceptions.Timeout as errt:\n        print (\"Timeout Error:\",errt)\n        return None\n    except requests.exceptions.RequestException as err:\n        print (\"Something went wrong\",err)\n        return None\n\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    table = soup.find_all('table')\n    if not table:\n        raise ValueError(\"No table data found on the page\")\n\n    table = table[0]\n    df = pd.DataFrame(data=[[td.get_text(strip=True) for td in tr.find_all('td')] for tr in table.find_all('tr')])\n\n    header = [th.get_text(strip=True) for th in table.find_all('th')]\n    if header:\n        df.columns = header\n\n    return df"}
{"task_id": "BigCodeBench/130", "solution": "import base64\nimport binascii\nimport os\nimport hashlib\ndef task_func(hex_str, salt_size):\n    # Convert hex string to bytes\n    byte_str = binascii.unhexlify(hex_str)\n\n    # Generate a random salt of the specified size\n    salt = os.urandom(salt_size)\n\n    # Append the salt to the byte representation of the hex string\n    salted_data = byte_str + salt\n\n    # Compute the SHA256 hash of the salted data\n    hash_obj = hashlib.sha256()\n    hash_obj.update(salted_data)\n    hash_str = hash_obj.hexdigest()\n\n    # Base64 encode the salt and the hash\n    b64_salt = base64.b64encode(salt).decode('utf-8')\n    b64_hash = base64.b64encode(hash_str.encode('utf-8')).decode('utf-8')\n\n    return (b64_salt, b64_hash)\nhex_str = \"deadbeef\"\nsalt_size = 16", "raw_solution": "import base64\nimport binascii\nimport os\nimport hashlib\n\ndef task_func(hex_str, salt_size):\n    # Convert hex string to bytes\n    byte_str = binascii.unhexlify(hex_str)\n\n    # Generate a random salt of the specified size\n    salt = os.urandom(salt_size)\n\n    # Append the salt to the byte representation of the hex string\n    salted_data = byte_str + salt\n\n    # Compute the SHA256 hash of the salted data\n    hash_obj = hashlib.sha256()\n    hash_obj.update(salted_data)\n    hash_str = hash_obj.hexdigest()\n\n    # Base64 encode the salt and the hash\n    b64_salt = base64.b64encode(salt).decode('utf-8')\n    b64_hash = base64.b64encode(hash_str.encode('utf-8')).decode('utf-8')\n\n    return (b64_salt, b64_hash)\n\n# Test the function\nhex_str = \"deadbeef\"\nsalt_size = 16"}
{"task_id": "BigCodeBench/131", "solution": "import base64\nimport binascii\nimport os\nimport hashlib\ndef task_func(hex_str, salt_size):\n    # Convert hex string to bytes\n    byte_str = binascii.unhexlify(hex_str)\n\n    # Generate a random salt of the given size\n    salt = os.urandom(salt_size)\n\n    # Append the salt to the byte representation of the hex string\n    salted_data = byte_str + salt\n\n    # Compute the SHA256 hash of the salted data\n    hash_obj = hashlib.sha256()\n    hash_obj.update(salted_data)\n    hash_str = hash_obj.hexdigest()\n\n    # Base64 encode the salt and the hash\n    b64_salt = base64.b64encode(salt).decode('utf-8')\n    b64_hash = base64.b64encode(hash_str.encode('utf-8')).decode('utf-8')\n\n    return (b64_salt, b64_hash)\nhex_str = \"deadbeef\"\nsalt_size = 16", "raw_solution": "import base64\nimport binascii\nimport os\nimport hashlib\n\ndef task_func(hex_str, salt_size):\n    # Convert hex string to bytes\n    byte_str = binascii.unhexlify(hex_str)\n\n    # Generate a random salt of the given size\n    salt = os.urandom(salt_size)\n\n    # Append the salt to the byte representation of the hex string\n    salted_data = byte_str + salt\n\n    # Compute the SHA256 hash of the salted data\n    hash_obj = hashlib.sha256()\n    hash_obj.update(salted_data)\n    hash_str = hash_obj.hexdigest()\n\n    # Base64 encode the salt and the hash\n    b64_salt = base64.b64encode(salt).decode('utf-8')\n    b64_hash = base64.b64encode(hash_str.encode('utf-8')).decode('utf-8')\n\n    return (b64_salt, b64_hash)\n\n# Test the function\nhex_str = \"deadbeef\"\nsalt_size = 16"}
{"task_id": "BigCodeBench/132", "solution": "import binascii\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(hex_str):\n    # Remove '\\\\x' prefix if exists\n    if hex_str.startswith('\\\\x'):\n        hex_str = hex_str[2:]\n\n    # Check if hex_str is a valid hex string\n    try:\n        binascii.unhexlify(hex_str)\n    except binascii.Error:\n        raise ValueError(\"Invalid hex string\")\n\n    # Convert hex string to bytes\n    bytes_obj = binascii.unhexlify(hex_str)\n\n    # Calculate frequency of each byte value\n    byte_freq = np.bincount(bytes_obj)\n\n    # Create DataFrame\n    df = pd.DataFrame({'Byte Value': range(256), 'Frequency': byte_freq})\n    df = df[df['Frequency'] > 0]  # Remove rows with zero frequency\n\n    # Create plot\n    fig, ax = plt.subplots()\n    ax.bar(df['Byte Value'], df['Frequency'])\n    ax.set_xlabel('Byte Value')\n    ax.set_ylabel('Frequency')\n\n    return (df, ax.figure)", "raw_solution": "import binascii\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(hex_str):\n    # Remove '\\\\x' prefix if exists\n    if hex_str.startswith('\\\\x'):\n        hex_str = hex_str[2:]\n\n    # Check if hex_str is a valid hex string\n    try:\n        binascii.unhexlify(hex_str)\n    except binascii.Error:\n        raise ValueError(\"Invalid hex string\")\n\n    # Convert hex string to bytes\n    bytes_obj = binascii.unhexlify(hex_str)\n\n    # Calculate frequency of each byte value\n    byte_freq = np.bincount(bytes_obj)\n\n    # Create DataFrame\n    df = pd.DataFrame({'Byte Value': range(256), 'Frequency': byte_freq})\n    df = df[df['Frequency'] > 0]  # Remove rows with zero frequency\n\n    # Create plot\n    fig, ax = plt.subplots()\n    ax.bar(df['Byte Value'], df['Frequency'])\n    ax.set_xlabel('Byte Value')\n    ax.set_ylabel('Frequency')\n\n    return (df, ax.figure)"}
{"task_id": "BigCodeBench/133", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n\n    # Get the last column name\n    last_column = df.columns[-1]\n\n    # Normalize the last column\n    scaler = MinMaxScaler()\n    df[last_column] = scaler.fit_transform(df[[last_column]])\n\n    # Plot the normalized data\n    fig, ax = plt.subplots()\n    ax.plot(df[last_column])\n    ax.set_title(f'Normalized Data of {last_column}')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Normalized Value')\n\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n\n    # Get the last column name\n    last_column = df.columns[-1]\n\n    # Normalize the last column\n    scaler = MinMaxScaler()\n    df[last_column] = scaler.fit_transform(df[[last_column]])\n\n    # Plot the normalized data\n    fig, ax = plt.subplots()\n    ax.plot(df[last_column])\n    ax.set_title(f'Normalized Data of {last_column}')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Normalized Value')\n\n    return df, ax"}
{"task_id": "BigCodeBench/134", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, bins=20):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if df.columns.empty:\n        raise ValueError(\"DataFrame has no columns\")\n\n    last_column = df.columns[-1]\n    plt.figure(figsize=(10, 6))\n    plt.hist(df[last_column], bins=bins, edgecolor='black')\n    plt.title(f'Histogram of {last_column}')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.tight_layout()\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, bins=20):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if df.columns.empty:\n        raise ValueError(\"DataFrame has no columns\")\n\n    last_column = df.columns[-1]\n    plt.figure(figsize=(10, 6))\n    plt.hist(df[last_column], bins=bins, edgecolor='black')\n    plt.title(f'Histogram of {last_column}')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.tight_layout()\n    return plt.gca()"}
{"task_id": "BigCodeBench/135", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input should be a pandas DataFrame\")\n    if df.shape[1] == 0:\n        raise ValueError(\"DataFrame has no columns\")\n\n    # Impute missing values in the last column using mean imputation\n    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n    df.iloc[:, -1] = imp.fit_transform(df.iloc[:, -1].values.reshape(-1, 1))\n\n    # Create a box plot to visualize the distribution of data in the last column\n    fig, ax = plt.subplots(1, 1)\n    sns.boxplot(df.iloc[:, -1], ax=ax)\n\n    return df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input should be a pandas DataFrame\")\n    if df.shape[1] == 0:\n        raise ValueError(\"DataFrame has no columns\")\n\n    # Impute missing values in the last column using mean imputation\n    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n    df.iloc[:, -1] = imp.fit_transform(df.iloc[:, -1].values.reshape(-1, 1))\n\n    # Create a box plot to visualize the distribution of data in the last column\n    fig, ax = plt.subplots(1, 1)\n    sns.boxplot(df.iloc[:, -1], ax=ax)\n\n    return df, ax"}
{"task_id": "BigCodeBench/136", "solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(df)\n\n    principalDf = pd.DataFrame(data = principalComponents, columns = ['Principal Component 1', 'Principal Component 2'])\n\n    fig, ax = plt.subplots()\n    ax.scatter(principalDf['Principal Component 1'], principalDf['Principal Component 2'])\n    ax.set_title('2 Component PCA')\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n\n    return principalDf, ax", "raw_solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(df)\n\n    principalDf = pd.DataFrame(data = principalComponents, columns = ['Principal Component 1', 'Principal Component 2'])\n\n    fig, ax = plt.subplots()\n    ax.scatter(principalDf['Principal Component 1'], principalDf['Principal Component 2'])\n    ax.set_title('2 Component PCA')\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n\n    return principalDf, ax"}
{"task_id": "BigCodeBench/137", "solution": "import pandas as pd\nfrom scipy.stats import skew\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.shape[1] == 0:\n        raise ValueError(\"DataFrame has no columns\")\n    return skew(df.iloc[:, -1])\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500]\n})", "raw_solution": "import pandas as pd\nfrom scipy.stats import skew\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.shape[1] == 0:\n        raise ValueError(\"DataFrame has no columns\")\n    return skew(df.iloc[:, -1])\n\n# Testing the function\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500]\n})\n\ntry:\n    print(task_func(df))\nexcept ValueError as e:\n    print(e)\n\ndf2 = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50]\n})\n\ntry:\n    print(task_func(df2))\nexcept ValueError as e:\n    print(e)\n\ndf3 = pd.DataFrame()\n\ntry:\n    print(task_func(df3))\nexcept ValueError as e:\n    print(e)"}
{"task_id": "BigCodeBench/138", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, letters=list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n    if 'Letters' not in df.columns:\n        raise ValueError(\"DataFrame lacks the 'Letters' column\")\n\n    # Count the frequency of each letter\n    freq = df['Letters'].value_counts()\n\n    # Filter the frequency to only include the letters we're interested in\n    freq = freq[freq.index.isin(letters)]\n\n    # Create the bar chart\n    fig, ax = plt.subplots()\n    ax.bar(freq.index, freq.values)\n\n    # Label the axes and set the title\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Letter Frequency')\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, letters=list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n    if 'Letters' not in df.columns:\n        raise ValueError(\"DataFrame lacks the 'Letters' column\")\n\n    # Count the frequency of each letter\n    freq = df['Letters'].value_counts()\n\n    # Filter the frequency to only include the letters we're interested in\n    freq = freq[freq.index.isin(letters)]\n\n    # Create the bar chart\n    fig, ax = plt.subplots()\n    ax.bar(freq.index, freq.values)\n\n    # Label the axes and set the title\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Letter Frequency')\n\n    return ax"}
{"task_id": "BigCodeBench/139", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"Input should be a non-empty DataFrame\")\n\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if not numeric_cols.any():\n        raise ValueError(\"There are no numeric columns in the DataFrame\")\n\n    axes_list = []\n    for col in numeric_cols:\n        ax = df[col].plot(kind='hist', rwidth=0.8, color='green')\n        ax.set_title(col)\n        ax.set_xlabel('Value')\n        ax.set_ylabel('Frequency')\n        axes_list.append(ax)\n\n    plt.tight_layout()\n    return axes_list", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"Input should be a non-empty DataFrame\")\n\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if not numeric_cols.any():\n        raise ValueError(\"There are no numeric columns in the DataFrame\")\n\n    axes_list = []\n    for col in numeric_cols:\n        ax = df[col].plot(kind='hist', rwidth=0.8, color='green')\n        ax.set_title(col)\n        ax.set_xlabel('Value')\n        ax.set_ylabel('Frequency')\n        axes_list.append(ax)\n\n    plt.tight_layout()\n    return axes_list"}
{"task_id": "BigCodeBench/140", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, cols):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n    if not isinstance(cols, list):\n        raise ValueError(\"'cols' is not a list\")\n    for col in cols:\n        if col not in df.columns:\n            raise ValueError(f\"Column '{col}' does not exist in 'df'\")\n    \n    scaler = StandardScaler()\n    df[cols] = scaler.fit_transform(df[cols])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, cols):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"'df' is not a DataFrame\")\n    if not isinstance(cols, list):\n        raise ValueError(\"'cols' is not a list\")\n    for col in cols:\n        if col not in df.columns:\n            raise ValueError(f\"Column '{col}' does not exist in 'df'\")\n    \n    scaler = StandardScaler()\n    df[cols] = scaler.fit_transform(df[cols])\n    return df"}
{"task_id": "BigCodeBench/141", "solution": "import numpy as np\nimport pandas as pd\nimport statistics\ndef task_func(rows, columns=['A', 'B', 'C', 'D', 'E', 'F'], seed=42):\n    if not isinstance(rows, int) or rows <= 0:\n        raise ValueError(\"'rows' should be a positive integer greater than 0.\")\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.randint(1, 101, size=(rows, len(columns))), columns=columns)\n    result = {}\n    for col in df.columns:\n        result[col] = {\n            'mean': df[col].mean(),\n            'median': df[col].median()\n        }\n    return df, result", "raw_solution": "import numpy as np\nimport pandas as pd\nimport statistics\n\ndef task_func(rows, columns=['A', 'B', 'C', 'D', 'E', 'F'], seed=42):\n    if not isinstance(rows, int) or rows <= 0:\n        raise ValueError(\"'rows' should be a positive integer greater than 0.\")\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.randint(1, 101, size=(rows, len(columns))), columns=columns)\n    result = {}\n    for col in df.columns:\n        result[col] = {\n            'mean': df[col].mean(),\n            'median': df[col].median()\n        }\n    return df, result\n\n# Test the function\ndf, result = task_func(10)"}
{"task_id": "BigCodeBench/142", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func():\n    x = np.linspace(0, 2*np.pi, 100)\n    y_sin = np.sin(x)\n    y_cos = np.cos(x)\n\n    fig, axs = plt.subplots(2)\n    fig.suptitle('Sine and Cosine Functions')\n\n    axs[0].plot(x, y_sin)\n    axs[0].set_title('Sine function')\n    axs[0].set_xlabel('x')\n    axs[0].set_ylabel('sin(x)')\n\n    axs[1].plot(x, y_cos)\n    axs[1].set_title('Cosine function')\n    axs[1].set_xlabel('x')\n    axs[1].set_ylabel('cos(x)')\n\n    plt.tight_layout()\n    plt.show()\n\n    return fig, axs", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    x = np.linspace(0, 2*np.pi, 100)\n    y_sin = np.sin(x)\n    y_cos = np.cos(x)\n\n    fig, axs = plt.subplots(2)\n    fig.suptitle('Sine and Cosine Functions')\n\n    axs[0].plot(x, y_sin)\n    axs[0].set_title('Sine function')\n    axs[0].set_xlabel('x')\n    axs[0].set_ylabel('sin(x)')\n\n    axs[1].plot(x, y_cos)\n    axs[1].set_title('Cosine function')\n    axs[1].set_xlabel('x')\n    axs[1].set_ylabel('cos(x)')\n\n    plt.tight_layout()\n    plt.show()\n\n    return fig, axs\n\n# Test the function\nfig, axs = task_func()\nassert isinstance(fig, plt.Figure)\nassert isinstance(axs, np.ndarray)\nassert len(axs) == 2"}
{"task_id": "BigCodeBench/143", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func():\n    # Define the x values\n    x = np.linspace(-10, 10, 400)\n\n    # Define the y values\n    y = 2*x + 1\n\n    # Create the plot\n    fig, ax = plt.subplots()\n\n    # Plot the equation y = 2x + 1\n    ax.plot(x, y, 'r', label='y=2x+1')\n\n    # Mark the solution at x = 2, y = 5\n    ax.plot(2, 5, 'go', label='solution')\n\n    # Set the title\n    ax.set_title('Solution of the equation y=2x+1 at x=2')\n\n    # Set the x-axis label\n    ax.set_xlabel('x')\n\n    # Set the y-axis label\n    ax.set_ylabel('y')\n\n    # Set the y-axis range automatically\n    ax.set_ylim(bottom=min(y)-1, top=max(y)+1)\n\n    # Add a legend\n    ax.legend()\n\n    # Return the plot\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    # Define the x values\n    x = np.linspace(-10, 10, 400)\n\n    # Define the y values\n    y = 2*x + 1\n\n    # Create the plot\n    fig, ax = plt.subplots()\n\n    # Plot the equation y = 2x + 1\n    ax.plot(x, y, 'r', label='y=2x+1')\n\n    # Mark the solution at x = 2, y = 5\n    ax.plot(2, 5, 'go', label='solution')\n\n    # Set the title\n    ax.set_title('Solution of the equation y=2x+1 at x=2')\n\n    # Set the x-axis label\n    ax.set_xlabel('x')\n\n    # Set the y-axis label\n    ax.set_ylabel('y')\n\n    # Set the y-axis range automatically\n    ax.set_ylim(bottom=min(y)-1, top=max(y)+1)\n\n    # Add a legend\n    ax.legend()\n\n    # Return the plot\n    return ax\n\n# Call the function\ntask_func()\n\n# Display the plot\nplt.show()"}
{"task_id": "BigCodeBench/144", "solution": "import ipaddress\nimport requests\ndef task_func(ip_range, timeout):\n    try:\n        network = ipaddress.IPv4Network(ip_range)\n    except ValueError:\n        raise ValueError(\"Invalid IP range provided\")\n\n    active_ips = []\n\n    for host in network.hosts():\n        url = f\"http://{str(host)}\"\n        try:\n            response = requests.get(url, timeout=timeout)\n            if response.status_code == 200:\n                active_ips.append(str(host))\n        except requests.RequestException:\n            continue\n\n    return active_ips", "raw_solution": "import ipaddress\nimport requests\n\ndef task_func(ip_range, timeout):\n    try:\n        network = ipaddress.IPv4Network(ip_range)\n    except ValueError:\n        raise ValueError(\"Invalid IP range provided\")\n\n    active_ips = []\n\n    for host in network.hosts():\n        url = f\"http://{str(host)}\"\n        try:\n            response = requests.get(url, timeout=timeout)\n            if response.status_code == 200:\n                active_ips.append(str(host))\n        except requests.RequestException:\n            continue\n\n    return active_ips"}
{"task_id": "BigCodeBench/145", "solution": "import csv\nfrom ipaddress import IPv4Network\ndef task_func(ip_range, csv_path):\n    # Create an IPv4Network object from the input IP range\n    network = IPv4Network(ip_range)\n\n    # Open the CSV file for writing\n    with open(csv_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n\n        # Iterate over all IP addresses in the network\n        for ip in network.hosts():\n            # Write each IP address as a row in the CSV file\n            writer.writerow([str(ip)])\n\n    # Return the path to the generated CSV file\n    return csv_path", "raw_solution": "import csv\nfrom ipaddress import IPv4Network\n\ndef task_func(ip_range, csv_path):\n    # Create an IPv4Network object from the input IP range\n    network = IPv4Network(ip_range)\n\n    # Open the CSV file for writing\n    with open(csv_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n\n        # Iterate over all IP addresses in the network\n        for ip in network.hosts():\n            # Write each IP address as a row in the CSV file\n            writer.writerow([str(ip)])\n\n    # Return the path to the generated CSV file\n    return csv_path"}
{"task_id": "BigCodeBench/146", "solution": "import subprocess\nfrom ipaddress import IPv4Network\ndef task_func(ip_range):\n    network = IPv4Network(ip_range)\n    result = {}\n    for host in network.hosts():\n        ip = str(host)\n        try:\n            output = subprocess.check_output([\"ping\", \"-c\", \"1\", ip], stderr=subprocess.STDOUT)\n            result[ip] = True\n        except subprocess.CalledProcessError:\n            result[ip] = False\n    return result", "raw_solution": "import subprocess\nfrom ipaddress import IPv4Network\n\ndef task_func(ip_range):\n    network = IPv4Network(ip_range)\n    result = {}\n    for host in network.hosts():\n        ip = str(host)\n        try:\n            output = subprocess.check_output([\"ping\", \"-c\", \"1\", ip], stderr=subprocess.STDOUT)\n            result[ip] = True\n        except subprocess.CalledProcessError:\n            result[ip] = False\n    return result\n\n# Test the function"}
{"task_id": "BigCodeBench/147", "solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\ndef check_port(ip, port):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.settimeout(5)\n    result = sock.connect_ex((str(ip), port))\n    sock.close()\n    return result == 0\ndef task_func(ip_range, port):\n    ip_dict = {}\n    for ip in IPv4Network(ip_range):\n        Thread(target=lambda ip=ip: ip_dict.update({ip: check_port(ip, port)})).start()\n    return ip_dict\nip_range = \"192.168.1.0/29\"\nport = 80", "raw_solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\n\ndef check_port(ip, port):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.settimeout(5)\n    result = sock.connect_ex((str(ip), port))\n    sock.close()\n    return result == 0\n\ndef task_func(ip_range, port):\n    ip_dict = {}\n    for ip in IPv4Network(ip_range):\n        Thread(target=lambda ip=ip: ip_dict.update({ip: check_port(ip, port)})).start()\n    return ip_dict\n\n# Test the function\nip_range = \"192.168.1.0/29\"\nport = 80"}
{"task_id": "BigCodeBench/148", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n    if column_name in df.columns:\n        le = LabelEncoder()\n        df[column_name] = le.fit_transform(df[column_name])\n        return df\n    else:\n        raise ValueError(f\"Column {column_name} not found in DataFrame\")\ndf = pd.DataFrame({'Category': ['cat', 'dog', 'cat', 'bird', 'dog', 'bird']})", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n    if column_name in df.columns:\n        le = LabelEncoder()\n        df[column_name] = le.fit_transform(df[column_name])\n        return df\n    else:\n        raise ValueError(f\"Column {column_name} not found in DataFrame\")\n\n# Test the function\ndf = pd.DataFrame({'Category': ['cat', 'dog', 'cat', 'bird', 'dog', 'bird']})"}
{"task_id": "BigCodeBench/149", "solution": "import pandas as pd\nimport numpy as np\nDEFAULT_COLUMNS = ['Element', 'Count']\ndef task_func(elements, include_index=False):\n    if include_index:\n        DEFAULT_COLUMNS.insert(0, 'Index')\n    df = pd.DataFrame(data=elements, columns=[DEFAULT_COLUMNS[0]])\n    df[DEFAULT_COLUMNS[1]] = df[DEFAULT_COLUMNS[0]].apply(lambda x: len(x))\n    if include_index:\n        df.reset_index(inplace=True)\n        df.rename(columns={'index': DEFAULT_COLUMNS[0]}, inplace=True)\n    return df[DEFAULT_COLUMNS]\nelements = ['Hello', 'World', 'Python', 'Pandas']", "raw_solution": "import pandas as pd\nimport numpy as np\n\nDEFAULT_COLUMNS = ['Element', 'Count']\n\ndef task_func(elements, include_index=False):\n    if include_index:\n        DEFAULT_COLUMNS.insert(0, 'Index')\n    df = pd.DataFrame(data=elements, columns=[DEFAULT_COLUMNS[0]])\n    df[DEFAULT_COLUMNS[1]] = df[DEFAULT_COLUMNS[0]].apply(lambda x: len(x))\n    if include_index:\n        df.reset_index(inplace=True)\n        df.rename(columns={'index': DEFAULT_COLUMNS[0]}, inplace=True)\n    return df[DEFAULT_COLUMNS]\n\n# Test the function\nelements = ['Hello', 'World', 'Python', 'Pandas']"}
{"task_id": "BigCodeBench/150", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(product_dict, product_keys):\n    if not product_dict or not product_keys:\n        return None, None\n\n    data = []\n    total_price = 0\n    total_profit = 0\n\n    for key in product_keys:\n        if key in product_dict:\n            product_data = product_dict[key]\n            quantity = product_data['quantity']\n            price = product_data['price']\n            profit = product_data['profit']\n            data.append([key, quantity, price, profit])\n\n            total_price += price * quantity\n            total_profit += profit * quantity\n\n    if not data:\n        return None, None\n\n    df = pd.DataFrame(data, columns=['Product', 'Quantity', 'Price', 'Profit'])\n\n    average_price = total_price / sum(df['Quantity'])\n    average_profit = total_profit / sum(df['Quantity'])\n\n    df['Average Price'] = average_price\n    df['Average Profit'] = average_profit\n\n    fig, ax = plt.subplots()\n    df.plot(x='Product', y='Profit', kind='bar', ax=ax)\n    ax.set_title('Profit for each product')\n\n    return (df, ax)", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(product_dict, product_keys):\n    if not product_dict or not product_keys:\n        return None, None\n\n    data = []\n    total_price = 0\n    total_profit = 0\n\n    for key in product_keys:\n        if key in product_dict:\n            product_data = product_dict[key]\n            quantity = product_data['quantity']\n            price = product_data['price']\n            profit = product_data['profit']\n            data.append([key, quantity, price, profit])\n\n            total_price += price * quantity\n            total_profit += profit * quantity\n\n    if not data:\n        return None, None\n\n    df = pd.DataFrame(data, columns=['Product', 'Quantity', 'Price', 'Profit'])\n\n    average_price = total_price / sum(df['Quantity'])\n    average_profit = total_profit / sum(df['Quantity'])\n\n    df['Average Price'] = average_price\n    df['Average Profit'] = average_profit\n\n    fig, ax = plt.subplots()\n    df.plot(x='Product', y='Profit', kind='bar', ax=ax)\n    ax.set_title('Profit for each product')\n\n    return (df, ax)"}
{"task_id": "BigCodeBench/151", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data_dict, data_keys):\n    # Check if all keys in data_keys are in data_dict\n    if not all(key in data_dict.keys() for key in data_keys):\n        raise ValueError(\"One or more keys in data_keys are not in data_dict\")\n\n    # Create a DataFrame from the data_dict using only the keys in data_keys\n    df = pd.DataFrame(data_dict, columns=data_keys)\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the data\n    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=data_keys)\n\n    # Create a plot\n    fig, ax = plt.subplots()\n    df_scaled.plot(kind='line', ax=ax)\n\n    return (df_scaled, ax.figure)", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data_dict, data_keys):\n    # Check if all keys in data_keys are in data_dict\n    if not all(key in data_dict.keys() for key in data_keys):\n        raise ValueError(\"One or more keys in data_keys are not in data_dict\")\n\n    # Create a DataFrame from the data_dict using only the keys in data_keys\n    df = pd.DataFrame(data_dict, columns=data_keys)\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the data\n    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=data_keys)\n\n    # Create a plot\n    fig, ax = plt.subplots()\n    df_scaled.plot(kind='line', ax=ax)\n\n    return (df_scaled, ax.figure)"}
{"task_id": "BigCodeBench/152", "solution": "import pandas as pd\nimport numpy as np\nimport random\nSTUDENTS = ['Joe', 'Amy', 'Mark', 'Sara', 'John', 'Emily', 'Zoe', 'Matt']\nCOURSES = ['Math', 'Physics', 'Chemistry', 'Biology', 'English', 'History', 'Geography', 'Computer Science']\ndef task_func():\n    # Create a DataFrame with students and courses\n    df = pd.DataFrame(STUDENTS, columns=['Student'])\n    df['Courses'] = COURSES\n\n    # Generate random grades for each student in each course\n    for course in COURSES:\n        df[course] = df.apply(lambda row: random.uniform(0, 100), axis=1)\n\n    # Calculate average grade for each student\n    df['Average'] = df[COURSES].mean(axis=1)\n\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport random\n\n# Constants\nSTUDENTS = ['Joe', 'Amy', 'Mark', 'Sara', 'John', 'Emily', 'Zoe', 'Matt']\nCOURSES = ['Math', 'Physics', 'Chemistry', 'Biology', 'English', 'History', 'Geography', 'Computer Science']\n\ndef task_func():\n    # Create a DataFrame with students and courses\n    df = pd.DataFrame(STUDENTS, columns=['Student'])\n    df['Courses'] = COURSES\n\n    # Generate random grades for each student in each course\n    for course in COURSES:\n        df[course] = df.apply(lambda row: random.uniform(0, 100), axis=1)\n\n    # Calculate average grade for each student\n    df['Average'] = df[COURSES].mean(axis=1)\n\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/153", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(data):\n    le = LabelEncoder()\n    data_encoded = le.fit_transform(data)\n    df = pd.DataFrame({'Category': data, 'Encoded': data_encoded})\n    return df\ndata = ['cat', 'dog', 'cat', 'bird', 'dog', 'bird', 'cat', 'dog']", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(data):\n    le = LabelEncoder()\n    data_encoded = le.fit_transform(data)\n    df = pd.DataFrame({'Category': data, 'Encoded': data_encoded})\n    return df\n\n# Test the function\ndata = ['cat', 'dog', 'cat', 'bird', 'dog', 'bird', 'cat', 'dog']"}
{"task_id": "BigCodeBench/154", "solution": "import re\nimport os\nimport glob\nimport mimetypes\ndef task_func(directory, file_pattern, suffix):\n    # Create a dictionary to store the file names and their MIME types\n    file_dict = {}\n\n    # Use glob to get a list of files matching the pattern\n    for file in glob.glob(os.path.join(directory, file_pattern)):\n        # Check if the file has the specified suffix\n        if file.endswith(suffix):\n            # Use mimetypes to get the MIME type of the file\n            mime_type = mimetypes.guess_type(file)[0]\n            # Add the file name and MIME type to the dictionary\n            file_dict[file] = mime_type\n\n    return file_dict", "raw_solution": "import re\nimport os\nimport glob\nimport mimetypes\n\ndef task_func(directory, file_pattern, suffix):\n    # Create a dictionary to store the file names and their MIME types\n    file_dict = {}\n\n    # Use glob to get a list of files matching the pattern\n    for file in glob.glob(os.path.join(directory, file_pattern)):\n        # Check if the file has the specified suffix\n        if file.endswith(suffix):\n            # Use mimetypes to get the MIME type of the file\n            mime_type = mimetypes.guess_type(file)[0]\n            # Add the file name and MIME type to the dictionary\n            file_dict[file] = mime_type\n\n    return file_dict\n\n# Test the function"}
{"task_id": "BigCodeBench/155", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nCOLUMN_NAMES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\ndef task_func(data):\n    # Convert the input data to a pandas DataFrame\n    df = pd.DataFrame(data, columns=COLUMN_NAMES)\n\n    # Compute the average of each row and append it as a new column\n    df['Average'] = df.mean(axis=1)\n\n    # Create a plot of the averages against their respective row indices\n    fig, ax = plt.subplots()\n    ax.plot(df['Average'])\n    ax.set_xlabel('Row Index')\n    ax.set_ylabel('Average')\n    ax.set_title('Average of each row')\n\n    return (df, ax.figure)\ndata = np.random.rand(5, 8)", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Constants\nCOLUMN_NAMES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n\ndef task_func(data):\n    # Convert the input data to a pandas DataFrame\n    df = pd.DataFrame(data, columns=COLUMN_NAMES)\n\n    # Compute the average of each row and append it as a new column\n    df['Average'] = df.mean(axis=1)\n\n    # Create a plot of the averages against their respective row indices\n    fig, ax = plt.subplots()\n    ax.plot(df['Average'])\n    ax.set_xlabel('Row Index')\n    ax.set_ylabel('Average')\n    ax.set_title('Average of each row')\n\n    return (df, ax.figure)\n\n# Test the function\ndata = np.random.rand(5, 8)\ndf, fig = task_func(data)\nplt.show()"}
{"task_id": "BigCodeBench/156", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Normalize the data using MinMaxScaler\n    scaler = MinMaxScaler()\n    data_normalized = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n    # Calculate the average of each row and add it as a new column 'Average'\n    data_normalized['Average'] = data_normalized.mean(axis=1)\n\n    # Create a bar plot of the average values\n    fig, ax = plt.subplots()\n    data_normalized['Average'].plot(kind='bar', ax=ax)\n    ax.set_ylabel('Average')\n    ax.set_title('Average values across the dataset')\n\n    return data_normalized, ax.figure", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Normalize the data using MinMaxScaler\n    scaler = MinMaxScaler()\n    data_normalized = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n    # Calculate the average of each row and add it as a new column 'Average'\n    data_normalized['Average'] = data_normalized.mean(axis=1)\n\n    # Create a bar plot of the average values\n    fig, ax = plt.subplots()\n    data_normalized['Average'].plot(kind='bar', ax=ax)\n    ax.set_ylabel('Average')\n    ax.set_title('Average values across the dataset')\n\n    return data_normalized, ax.figure"}
{"task_id": "BigCodeBench/157", "solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Check if data is a 2D array\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data should be a pandas DataFrame\")\n    if len(data.shape) != 2:\n        raise ValueError(\"Input data should be a 2D array\")\n    \n    # Check if data contains non-numeric data\n    if pd.api.types.is_numeric_dtype(data) == False:\n        raise ValueError(\"Input data should contain only numeric data\")\n\n    # Calculate the average of values across each row\n    data['Average'] = data.mean(axis=1)\n\n    # Calculate the correlation matrix\n    corr = data.corr()\n\n    # Create a figure and a set of subplots\n    fig, ax = plt.subplots(figsize=(10, 10))\n\n    # Generate a heatmap\n    sns.heatmap(corr, annot=True, fmt=\".2f\", linewidths=.5, cmap='coolwarm', ax=ax)\n\n    return (data, ax)", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Check if data is a 2D array\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data should be a pandas DataFrame\")\n    if len(data.shape) != 2:\n        raise ValueError(\"Input data should be a 2D array\")\n    \n    # Check if data contains non-numeric data\n    if pd.api.types.is_numeric_dtype(data) == False:\n        raise ValueError(\"Input data should contain only numeric data\")\n\n    # Calculate the average of values across each row\n    data['Average'] = data.mean(axis=1)\n\n    # Calculate the correlation matrix\n    corr = data.corr()\n\n    # Create a figure and a set of subplots\n    fig, ax = plt.subplots(figsize=(10, 10))\n\n    # Generate a heatmap\n    sns.heatmap(corr, annot=True, fmt=\".2f\", linewidths=.5, cmap='coolwarm', ax=ax)\n\n    return (data, ax)"}
{"task_id": "BigCodeBench/158", "solution": "import json\nimport urllib.request\nimport urllib.parse\nimport gzip\nimport os\ndef task_func(url_str, file_path):\n    # Fetch JSON data from URL\n    with urllib.request.urlopen(url_str) as url:\n        data = json.loads(url.read().decode())\n\n    # Compress JSON data into gzip file\n    with gzip.open(file_path, 'wb') as f:\n        f.write(json.dumps(data).encode())\n\n    # Return the path to the compressed gzip file\n    return file_path\nurl = \"https://jsonplaceholder.typicode.com/posts\"\nfile_path = \"./data.json.gz\"", "raw_solution": "import json\nimport urllib.request\nimport urllib.parse\nimport gzip\nimport os\n\ndef task_func(url_str, file_path):\n    # Fetch JSON data from URL\n    with urllib.request.urlopen(url_str) as url:\n        data = json.loads(url.read().decode())\n\n    # Compress JSON data into gzip file\n    with gzip.open(file_path, 'wb') as f:\n        f.write(json.dumps(data).encode())\n\n    # Return the path to the compressed gzip file\n    return file_path\n\n# Test the function\nurl = \"https://jsonplaceholder.typicode.com/posts\"\nfile_path = \"./data.json.gz\""}
{"task_id": "BigCodeBench/159", "solution": "import struct\nimport io\nimport gzip\nimport numpy as np\ndef task_func(newArray):\n    # Convert the numpy array to bytes\n    newArray = newArray.tobytes()\n\n    # Compress the bytes using gzip\n    s = io.BytesIO()\n    with gzip.GzipFile(fileobj=s, mode='w') as f:\n        f.write(newArray)\n\n    return s.getvalue()", "raw_solution": "import struct\nimport io\nimport gzip\nimport numpy as np\n\ndef task_func(newArray):\n    # Convert the numpy array to bytes\n    newArray = newArray.tobytes()\n\n    # Compress the bytes using gzip\n    s = io.BytesIO()\n    with gzip.GzipFile(fileobj=s, mode='w') as f:\n        f.write(newArray)\n\n    return s.getvalue()\n\n# Test the function\narr = np.array([1, 2, 3, 4, 5])\ncompressed_data = task_func(arr)"}
{"task_id": "BigCodeBench/160", "solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nCOLUMN_NAMES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\ndef task_func(data):\n    # Check if the data has exactly eight columns\n    if len(data.columns) != len(COLUMN_NAMES):\n        raise ValueError(\"The input data does not have exactly eight columns.\")\n\n    # Compute the average of each row\n    data['Average'] = data[COLUMN_NAMES].mean(axis=1)\n\n    # Plot the distribution of these averages\n    plot = sns.distplot(data['Average'])\n    plt.title('Distribution of Averages')\n\n    p_value = None\n    # Evaluate their normality if there are at least 20 data points\n    if len(data) >= 20:\n        _, p_value = stats.normaltest(data['Average'])\n\n    return data, plot, p_value", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMN_NAMES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n\ndef task_func(data):\n    # Check if the data has exactly eight columns\n    if len(data.columns) != len(COLUMN_NAMES):\n        raise ValueError(\"The input data does not have exactly eight columns.\")\n\n    # Compute the average of each row\n    data['Average'] = data[COLUMN_NAMES].mean(axis=1)\n\n    # Plot the distribution of these averages\n    plot = sns.distplot(data['Average'])\n    plt.title('Distribution of Averages')\n\n    p_value = None\n    # Evaluate their normality if there are at least 20 data points\n    if len(data) >= 20:\n        _, p_value = stats.normaltest(data['Average'])\n\n    return data, plot, p_value"}
{"task_id": "BigCodeBench/161", "solution": "import re\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(log_file):\n    # Define the regular expression pattern\n    pattern = r\"(?P<type>\\w+): \\[(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\] - (?P<message>.*)\"\n\n    # Initialize lists to store the data\n    types = []\n    timestamps = []\n    messages = []\n\n    # Open the log file and read it line by line\n    with open(log_file, 'r') as f:\n        lines = f.readlines()\n\n    # Iterate over the lines\n    for line in lines:\n        # Use the regular expression to match the line\n        match = re.match(pattern, line)\n\n        # If a match is found, append the data to the corresponding lists\n        if match:\n            types.append(match.group('type'))\n            timestamps.append(match.group('timestamp'))\n            messages.append(match.group('message'))\n        else:\n            raise ValueError(\"Invalid log entry: \" + line)\n\n    # If no valid log entries are found, raise an exception\n    if not types:\n        raise ValueError(\"No valid log entries found\")\n\n    # Create a pandas DataFrame from the data\n    df = pd.DataFrame({\n        'Type': types,\n        'Timestamp': timestamps,\n        'Message': messages\n    })\n\n    # Convert the Timestamp column to datetime format\n    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n\n    # Save the DataFrame to a CSV file\n    csv_file = log_file.split('.')[0] + '.csv'\n    df.to_csv(csv_file, index=False)\n\n    return csv_file", "raw_solution": "import re\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(log_file):\n    # Define the regular expression pattern\n    pattern = r\"(?P<type>\\w+): \\[(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\] - (?P<message>.*)\"\n\n    # Initialize lists to store the data\n    types = []\n    timestamps = []\n    messages = []\n\n    # Open the log file and read it line by line\n    with open(log_file, 'r') as f:\n        lines = f.readlines()\n\n    # Iterate over the lines\n    for line in lines:\n        # Use the regular expression to match the line\n        match = re.match(pattern, line)\n\n        # If a match is found, append the data to the corresponding lists\n        if match:\n            types.append(match.group('type'))\n            timestamps.append(match.group('timestamp'))\n            messages.append(match.group('message'))\n        else:\n            raise ValueError(\"Invalid log entry: \" + line)\n\n    # If no valid log entries are found, raise an exception\n    if not types:\n        raise ValueError(\"No valid log entries found\")\n\n    # Create a pandas DataFrame from the data\n    df = pd.DataFrame({\n        'Type': types,\n        'Timestamp': timestamps,\n        'Message': messages\n    })\n\n    # Convert the Timestamp column to datetime format\n    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n\n    # Save the DataFrame to a CSV file\n    csv_file = log_file.split('.')[0] + '.csv'\n    df.to_csv(csv_file, index=False)\n\n    return csv_file"}
{"task_id": "BigCodeBench/162", "solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(text, rwidth=0.8):\n    # Filter out non-alphabetic characters and split the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # If there are no words or all words are filtered out, return an empty histogram\n    if not words:\n        return plt.hist([], rwidth=rwidth)\n\n    # Calculate the length of each word and create a histogram\n    word_lengths = [len(word) for word in words]\n    return plt.hist(word_lengths, bins='auto', rwidth=rwidth)\ntext = \"The quick brown fox jumps over the lazy dog\"", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(text, rwidth=0.8):\n    # Filter out non-alphabetic characters and split the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # If there are no words or all words are filtered out, return an empty histogram\n    if not words:\n        return plt.hist([], rwidth=rwidth)\n\n    # Calculate the length of each word and create a histogram\n    word_lengths = [len(word) for word in words]\n    return plt.hist(word_lengths, bins='auto', rwidth=rwidth)\n\n# Test the function\ntext = \"The quick brown fox jumps over the lazy dog\"\nax = task_func(text)\nplt.show()"}
{"task_id": "BigCodeBench/163", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(rows=5, cols=5):\n    if cols > rows:\n        raise ValueError(\"Number of columns cannot exceed the number of rows.\")\n\n    np.random.seed(0)\n    data = np.random.randint(10, size=(rows, cols))\n    df = pd.DataFrame(data, columns=[f'Category {i+1}' for i in range(cols)])\n\n    ax = df.plot(kind='barh', stacked=True, figsize=(10, 6))\n    plt.title('Stacked Bar Chart')\n    plt.xlabel('Values')\n    plt.ylabel('Categories')\n    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n\n    return ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(rows=5, cols=5):\n    if cols > rows:\n        raise ValueError(\"Number of columns cannot exceed the number of rows.\")\n\n    np.random.seed(0)\n    data = np.random.randint(10, size=(rows, cols))\n    df = pd.DataFrame(data, columns=[f'Category {i+1}' for i in range(cols)])\n\n    ax = df.plot(kind='barh', stacked=True, figsize=(10, 6))\n    plt.title('Stacked Bar Chart')\n    plt.xlabel('Values')\n    plt.ylabel('Categories')\n    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n\n    return ax\n\n# Test the function\nax = task_func(10, 4)\nplt.show()"}
{"task_id": "BigCodeBench/164", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(num_labels=5, data_range=(0, 1)):\n    # Generate random numeric data across a specified range for a given number of categories\n    data = pd.DataFrame(np.random.randint(low=data_range[0], high=data_range[1], size=(num_labels, 4)), \n                        columns=['Jan', 'Feb', 'Mar', 'Apr'])\n    data['Month'] = ['Jan', 'Feb', 'Mar', 'Apr']\n    data = data.set_index('Month')\n\n    # Create a stacked bar chart\n    fig, ax = plt.subplots()\n    data.plot(kind='bar', stacked=True, ax=ax)\n\n    # Set title and labels\n    ax.set_title('Stacked Bar Chart of Random Numeric Data')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n\n    return fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(num_labels=5, data_range=(0, 1)):\n    # Generate random numeric data across a specified range for a given number of categories\n    data = pd.DataFrame(np.random.randint(low=data_range[0], high=data_range[1], size=(num_labels, 4)), \n                        columns=['Jan', 'Feb', 'Mar', 'Apr'])\n    data['Month'] = ['Jan', 'Feb', 'Mar', 'Apr']\n    data = data.set_index('Month')\n\n    # Create a stacked bar chart\n    fig, ax = plt.subplots()\n    data.plot(kind='bar', stacked=True, ax=ax)\n\n    # Set title and labels\n    ax.set_title('Stacked Bar Chart of Random Numeric Data')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n\n    return fig\n\n# Test the function\nfig = task_func(num_labels=3, data_range=(1, 10))\nfig.show()"}
{"task_id": "BigCodeBench/165", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\ndef task_func(num_rows=5, rand_range=(0, 100)):\n    # Create a DataFrame with random integer values within a specified range\n    df = pd.DataFrame({\n        'A': [randint(*rand_range) for _ in range(num_rows)],\n        'B': [randint(*rand_range) for _ in range(num_rows)],\n        'C': [randint(*rand_range) for _ in range(num_rows)],\n        'D': [randint(*rand_range) for _ in range(num_rows)],\n        'E': [randint(*rand_range) for _ in range(num_rows)],\n    }, index=[i for i in range(1, num_rows+1)])\n\n    # Plot the DataFrame as a stacked bar chart\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', stacked=True, ax=ax)\n\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.legend(loc='upper left')\n\n    return fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\n\ndef task_func(num_rows=5, rand_range=(0, 100)):\n    # Create a DataFrame with random integer values within a specified range\n    df = pd.DataFrame({\n        'A': [randint(*rand_range) for _ in range(num_rows)],\n        'B': [randint(*rand_range) for _ in range(num_rows)],\n        'C': [randint(*rand_range) for _ in range(num_rows)],\n        'D': [randint(*rand_range) for _ in range(num_rows)],\n        'E': [randint(*rand_range) for _ in range(num_rows)],\n    }, index=[i for i in range(1, num_rows+1)])\n\n    # Plot the DataFrame as a stacked bar chart\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', stacked=True, ax=ax)\n\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.legend(loc='upper left')\n\n    return fig\n\n# Test the function\nfig = task_func(10, (0, 100))\nplt.show()"}
{"task_id": "BigCodeBench/166", "solution": "import pandas as pd\nfrom datetime import datetime\nimport holidays\ndef task_func(start_date=datetime(2023, 1, 1), end_date=datetime(2023, 12, 31), country='US'):\n    if not isinstance(start_date, datetime):\n        raise ValueError(\"start_date is not a datetime object\")\n    if not isinstance(end_date, datetime):\n        raise ValueError(\"end_date is not a datetime object\")\n    if start_date > end_date:\n        raise ValueError(\"start_date is after end_date\")\n    if end_date < start_date:\n        raise ValueError(\"end_date is before start_date\")\n\n    country_holidays = holidays.CountryHoliday(country)\n    all_dates = pd.date_range(start=start_date, end=end_date)\n    business_days = all_dates[all_dates.weekday < 5]\n    business_days = business_days[~business_days.isin(country_holidays)]\n    return business_days.tolist()", "raw_solution": "import pandas as pd\nfrom datetime import datetime\nimport holidays\n\ndef task_func(start_date=datetime(2023, 1, 1), end_date=datetime(2023, 12, 31), country='US'):\n    if not isinstance(start_date, datetime):\n        raise ValueError(\"start_date is not a datetime object\")\n    if not isinstance(end_date, datetime):\n        raise ValueError(\"end_date is not a datetime object\")\n    if start_date > end_date:\n        raise ValueError(\"start_date is after end_date\")\n    if end_date < start_date:\n        raise ValueError(\"end_date is before start_date\")\n\n    country_holidays = holidays.CountryHoliday(country)\n    all_dates = pd.date_range(start=start_date, end=end_date)\n    business_days = all_dates[all_dates.weekday < 5]\n    business_days = business_days[~business_days.isin(country_holidays)]\n    return business_days.tolist()\n\n# Test the function"}
{"task_id": "BigCodeBench/167", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\ndef task_func(num_types=5, integer_range=(0, 100)):\n    # Generate a DataFrame with random integer values\n    df = pd.DataFrame({\n        'Category': [f'Category_{i+1}' for i in range(num_types)],\n        'Value': [randint(*integer_range) for _ in range(num_types)]\n    })\n\n    # Create a horizontal stacked bar chart\n    fig, ax = plt.subplots()\n    ax.barh(df['Category'], df['Value'], color='skyblue')\n\n    # Set labels and title\n    ax.set_xlabel('Value')\n    ax.set_title('Horizontal Stacked Bar Chart')\n\n    return (fig, ax)", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\n\ndef task_func(num_types=5, integer_range=(0, 100)):\n    # Generate a DataFrame with random integer values\n    df = pd.DataFrame({\n        'Category': [f'Category_{i+1}' for i in range(num_types)],\n        'Value': [randint(*integer_range) for _ in range(num_types)]\n    })\n\n    # Create a horizontal stacked bar chart\n    fig, ax = plt.subplots()\n    ax.barh(df['Category'], df['Value'], color='skyblue')\n\n    # Set labels and title\n    ax.set_xlabel('Value')\n    ax.set_title('Horizontal Stacked Bar Chart')\n\n    return (fig, ax)\n\n# Test the function\nfig, ax = task_func(num_types=5, integer_range=(0, 100))\nplt.show()"}
{"task_id": "BigCodeBench/168", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(num_groups=5, data_size=5, labels=None):\n    np.random.seed(0)\n    data = np.random.randint(0,10,size=(data_size, num_groups))\n    df = pd.DataFrame(data, columns=labels)\n\n    fig, ax = plt.subplots()\n    ax.bar(range(data_size), df.sum(axis=1), bottom=np.zeros(data_size))\n\n    for i in range(num_groups):\n        ax.bar(range(data_size), df.iloc[:,i], bottom=df.iloc[:,:i].sum(axis=1))\n\n    ax.set_xlabel('Data Points')\n    ax.set_ylabel('Values')\n    ax.legend(labels, title='Groups', loc='upper left')\n    plt.savefig('test_plot.png')\n\n    return (fig, df, 'test_plot.png')\nlabels = ['Group '+str(i+1) for i in range(5)]", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(num_groups=5, data_size=5, labels=None):\n    np.random.seed(0)\n    data = np.random.randint(0,10,size=(data_size, num_groups))\n    df = pd.DataFrame(data, columns=labels)\n\n    fig, ax = plt.subplots()\n    ax.bar(range(data_size), df.sum(axis=1), bottom=np.zeros(data_size))\n\n    for i in range(num_groups):\n        ax.bar(range(data_size), df.iloc[:,i], bottom=df.iloc[:,:i].sum(axis=1))\n\n    ax.set_xlabel('Data Points')\n    ax.set_ylabel('Values')\n    ax.legend(labels, title='Groups', loc='upper left')\n    plt.savefig('test_plot.png')\n\n    return (fig, df, 'test_plot.png')\n\nlabels = ['Group '+str(i+1) for i in range(5)]\nfig, df, filename = task_func(5, 5, labels)"}
{"task_id": "BigCodeBench/169", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import gaussian_filter\ndef task_func(image, sigma=2):\n    if not isinstance(image, np.ndarray):\n        raise TypeError(\"Input image should be a numpy array.\")\n    if not isinstance(sigma, (int, float)):\n        raise TypeError(\"Sigma should be a number.\")\n    if sigma <= 0:\n        raise ValueError(\"Sigma should be positive.\")\n\n    filtered_image = gaussian_filter(image, sigma=sigma)\n\n    fig, ax = plt.subplots(1, 2)\n    ax[0].imshow(image, cmap=plt.cm.gray)\n    ax[0].set_title('Original')\n    ax[1].imshow(filtered_image, cmap=plt.cm.gray)\n    ax[1].set_title('Filtered')\n\n    return ax, filtered_image", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import gaussian_filter\n\ndef task_func(image, sigma=2):\n    if not isinstance(image, np.ndarray):\n        raise TypeError(\"Input image should be a numpy array.\")\n    if not isinstance(sigma, (int, float)):\n        raise TypeError(\"Sigma should be a number.\")\n    if sigma <= 0:\n        raise ValueError(\"Sigma should be positive.\")\n\n    filtered_image = gaussian_filter(image, sigma=sigma)\n\n    fig, ax = plt.subplots(1, 2)\n    ax[0].imshow(image, cmap=plt.cm.gray)\n    ax[0].set_title('Original')\n    ax[1].imshow(filtered_image, cmap=plt.cm.gray)\n    ax[1].set_title('Filtered')\n\n    return ax, filtered_image"}
{"task_id": "BigCodeBench/170", "solution": "import pandas as pd\nimport requests\nfrom io import StringIO\ndef task_func(csv_url, sort_by_column=\"title\"):\n    response = requests.get(csv_url)\n\n    if response.status_code != 200:\n        raise Exception(f\"Response status code is not 200. Code: {response.status_code}\")\n\n    data = response.text\n    df = pd.read_csv(StringIO(data))\n    sorted_df = df.sort_values(by=[sort_by_column])\n\n    return sorted_df", "raw_solution": "import pandas as pd\nimport requests\nfrom io import StringIO\n\ndef task_func(csv_url, sort_by_column=\"title\"):\n    response = requests.get(csv_url)\n\n    if response.status_code != 200:\n        raise Exception(f\"Response status code is not 200. Code: {response.status_code}\")\n\n    data = response.text\n    df = pd.read_csv(StringIO(data))\n    sorted_df = df.sort_values(by=[sort_by_column])\n\n    return sorted_df\n\n# Test the function\ntry:\n    df = task_func(\"http://example.com/data.csv\", sort_by_column=\"price\")\n    print(\"DataFrame:\")\n    print(df)\nexcept Exception as e:\n    print(e)"}
{"task_id": "BigCodeBench/171", "solution": "import random\nimport pandas as pd\nfrom collections import Counter\ndef task_func(vegetable_dict, seed=0):\n    random.seed(seed)\n\n    # Reverse the dictionary to map vegetables to people\n    rev_dict = {v: k for k, vs in vegetable_dict.items() for v in vs}\n\n    # Assign random counts to these vegetables\n    counts = {v: random.randint(1, 10) for v in rev_dict.keys()}\n\n    # Calculate the total counts\n    total_counts = sum(counts.values())\n\n    # Calculate the occurrences of each vegetable as a percentage of the total counts\n    percentages = {v: (counts[v] / total_counts) * 100 for v in counts.keys()}\n\n    # Create a DataFrame\n    df = pd.DataFrame(list(counts.items()), columns=['Vegetable', 'Count'])\n    df['Percentage'] = df['Vegetable'].map(percentages)\n\n    return df", "raw_solution": "import random\nimport pandas as pd\nfrom collections import Counter\n\n# Constants\nVEGETABLES = ['Carrot', 'Potato', 'Tomato', 'Cabbage', 'Spinach']\n\ndef task_func(vegetable_dict, seed=0):\n    random.seed(seed)\n\n    # Reverse the dictionary to map vegetables to people\n    rev_dict = {v: k for k, vs in vegetable_dict.items() for v in vs}\n\n    # Assign random counts to these vegetables\n    counts = {v: random.randint(1, 10) for v in rev_dict.keys()}\n\n    # Calculate the total counts\n    total_counts = sum(counts.values())\n\n    # Calculate the occurrences of each vegetable as a percentage of the total counts\n    percentages = {v: (counts[v] / total_counts) * 100 for v in counts.keys()}\n\n    # Create a DataFrame\n    df = pd.DataFrame(list(counts.items()), columns=['Vegetable', 'Count'])\n    df['Percentage'] = df['Vegetable'].map(percentages)\n\n    return df\n\n# Test the function\nveg_dict = {'Alice': ['Carrot', 'Potato'], 'Bob': ['Tomato', 'Cabbage'], 'Charlie': ['Spinach', 'Potato']}"}
{"task_id": "BigCodeBench/172", "solution": "import json\nfrom datetime import datetime\ndef task_func(json_data):\n    # Parse the JSON data\n    data = json.loads(json_data)\n\n    # Extract the datetime from the JSON data\n    utc_datetime_str = data['utc_datetime']\n    utc_datetime = datetime.strptime(utc_datetime_str, '%Y-%m-%d %H:%M:%S')\n\n    # Determine if the date is a weekend\n    return utc_datetime.weekday() > 4\njson_data = '{\"utc_datetime\": \"2022-01-01 12:00:00\"}'", "raw_solution": "import json\nfrom datetime import datetime\n\ndef task_func(json_data):\n    # Parse the JSON data\n    data = json.loads(json_data)\n\n    # Extract the datetime from the JSON data\n    utc_datetime_str = data['utc_datetime']\n    utc_datetime = datetime.strptime(utc_datetime_str, '%Y-%m-%d %H:%M:%S')\n\n    # Determine if the date is a weekend\n    return utc_datetime.weekday() > 4\n\n# Test the function\njson_data = '{\"utc_datetime\": \"2022-01-01 12:00:00\"}'"}
{"task_id": "BigCodeBench/173", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(country_dict):\n    gdp_values = np.random.randint(1000000000, 10000000000, len(country_dict))\n    df = pd.DataFrame(list(country_dict.items()), columns=['Country', 'Presence'])\n    df.set_index('Country', inplace=True)\n    df['GDP'] = gdp_values\n    return df\ncountry_dict = {'USA': 'Present', 'China': 'Present', 'India': 'Absent', 'UK': 'Present', 'Germany': 'Present'}", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(country_dict):\n    gdp_values = np.random.randint(1000000000, 10000000000, len(country_dict))\n    df = pd.DataFrame(list(country_dict.items()), columns=['Country', 'Presence'])\n    df.set_index('Country', inplace=True)\n    df['GDP'] = gdp_values\n    return df\n\n# Test the function\ncountry_dict = {'USA': 'Present', 'China': 'Present', 'India': 'Absent', 'UK': 'Present', 'Germany': 'Present'}"}
{"task_id": "BigCodeBench/174", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(data, key, min_value, max_value):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data is not a pandas DataFrame\")\n    data[key] = np.random.randint(min_value, max_value, data.shape[0])\n    return data\ndata = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(data, key, min_value, max_value):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data is not a pandas DataFrame\")\n    data[key] = np.random.randint(min_value, max_value, data.shape[0])\n    return data\n\n# Test the function\ndata = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})"}
{"task_id": "BigCodeBench/175", "solution": "import re\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df):\n    # Check if the DataFrame is empty\n    if df.empty:\n        return plt.subplot(111)\n\n    # Check if the DataFrame has the necessary columns\n    if not all(col in df.columns for col in ['Title', 'Views', 'Likes']):\n        return plt.subplot(111)\n\n    # Filter the DataFrame to include only videos with titles containing \"how\" or \"what\"\n    filtered_df = df[df['Title'].apply(lambda x: re.search(r'\\b(how|what)\\b', str(x), re.I) is not None)]\n\n    # If there are no videos matching the search criteria, return an empty subplot\n    if filtered_df.empty:\n        return plt.subplot(111)\n\n    # Calculate the like ratio for each video\n    filtered_df['Like Ratio'] = filtered_df['Likes'] / filtered_df['Views']\n\n    # Generate a bar plot of the like ratios for these specific videos\n    ax = filtered_df.plot(x='Title', y='Like Ratio', kind='bar', legend=False)\n\n    return ax", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df):\n    # Check if the DataFrame is empty\n    if df.empty:\n        return plt.subplot(111)\n\n    # Check if the DataFrame has the necessary columns\n    if not all(col in df.columns for col in ['Title', 'Views', 'Likes']):\n        return plt.subplot(111)\n\n    # Filter the DataFrame to include only videos with titles containing \"how\" or \"what\"\n    filtered_df = df[df['Title'].apply(lambda x: re.search(r'\\b(how|what)\\b', str(x), re.I) is not None)]\n\n    # If there are no videos matching the search criteria, return an empty subplot\n    if filtered_df.empty:\n        return plt.subplot(111)\n\n    # Calculate the like ratio for each video\n    filtered_df['Like Ratio'] = filtered_df['Likes'] / filtered_df['Views']\n\n    # Generate a bar plot of the like ratios for these specific videos\n    ax = filtered_df.plot(x='Title', y='Like Ratio', kind='bar', legend=False)\n\n    return ax"}
{"task_id": "BigCodeBench/176", "solution": "import re\nimport socket\ndef task_func(ip_addresses: list) -> dict:\n    ip_dict = {}\n    for ip in ip_addresses:\n        try:\n            hostname = socket.gethostbyaddr(ip)[0]\n            ip_dict[ip] = hostname\n        except socket.herror:\n            ip_dict[ip] = None\n    return ip_dict\nip_addresses = ['127.0.0.1', '8.8.8.8', '256.256.256.256']", "raw_solution": "import re\nimport socket\n\ndef task_func(ip_addresses: list) -> dict:\n    ip_dict = {}\n    for ip in ip_addresses:\n        try:\n            hostname = socket.gethostbyaddr(ip)[0]\n            ip_dict[ip] = hostname\n        except socket.herror:\n            ip_dict[ip] = None\n    return ip_dict\n\n# Test the function\nip_addresses = ['127.0.0.1', '8.8.8.8', '256.256.256.256']"}
{"task_id": "BigCodeBench/177", "solution": "import re\nimport nltk\nfrom string import punctuation\nfrom collections import Counter\ndef task_func(df):\n    # Check if DataFrame is empty or does not contain necessary columns\n    if df.empty or 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError(\"DataFrame is empty or does not contain necessary columns\")\n\n    # Extract articles whose titles contain specific case-insensitive keywords\n    df = df[df['Title'].str.contains(r'(?i)like|(?i)what')]\n\n    # If no articles found, return an empty dictionary\n    if df.empty:\n        return {}\n\n    # Analyze the frequency of each word in the content of these articles\n    words = df['Content'].str.cat(sep=' ').split()\n    words = [''.join(c for c in w if c not in punctuation) for w in words]\n    words = [w for w in words if w]  # remove empty strings\n    words = [w.lower() for w in words]  # convert to lower case\n\n    # Return a dictionary with words as keys and their frequencies as values\n    return dict(Counter(words))", "raw_solution": "import re\nimport nltk\nfrom string import punctuation\nfrom collections import Counter\n\ndef task_func(df):\n    # Check if DataFrame is empty or does not contain necessary columns\n    if df.empty or 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError(\"DataFrame is empty or does not contain necessary columns\")\n\n    # Extract articles whose titles contain specific case-insensitive keywords\n    df = df[df['Title'].str.contains(r'(?i)like|(?i)what')]\n\n    # If no articles found, return an empty dictionary\n    if df.empty:\n        return {}\n\n    # Analyze the frequency of each word in the content of these articles\n    words = df['Content'].str.cat(sep=' ').split()\n    words = [''.join(c for c in w if c not in punctuation) for w in words]\n    words = [w for w in words if w]  # remove empty strings\n    words = [w.lower() for w in words]  # convert to lower case\n\n    # Return a dictionary with words as keys and their frequencies as values\n    return dict(Counter(words))"}
{"task_id": "BigCodeBench/178", "solution": "import re\nimport json\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\ndef task_func(ip_address):\n    # Check if the IP address is valid\n    if re.fullmatch(IP_REGEX, ip_address):\n        return ip_address\n    else:\n        return 'Invalid IP address received'", "raw_solution": "import re\nimport json\n\n# Constants\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\n\ndef task_func(ip_address):\n    # Check if the IP address is valid\n    if re.fullmatch(IP_REGEX, ip_address):\n        return ip_address\n    else:\n        return 'Invalid IP address received'\n\n# Testing"}
{"task_id": "BigCodeBench/179", "solution": "import re\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\ndef task_func(df):\n    # Check if 'Title' and 'Content' columns exist in the DataFrame\n    if 'Title' not in df.columns or 'Content' not in df.columns:\n        return plt.figure()\n\n    # Filter articles with titles containing 'how' or 'what'\n    df = df[df['Title'].apply(lambda x: bool(re.search(r'\\b(how|what)\\b', x, re.I)))]\n\n    # Check if there are any articles left\n    if df.empty:\n        return plt.figure()\n\n    # Calculate TF-IDF scores\n    vectorizer = TfidfVectorizer(stop_words='english')\n    tfidf_matrix = vectorizer.fit_transform(df['Content'])\n    feature_names = vectorizer.get_feature_names_out()\n\n    # Calculate average TF-IDF scores for each article\n    avg_tfidf_scores = np.mean(tfidf_matrix, axis=0).tolist()[0]\n\n    # Create bar plot\n    fig, ax = plt.subplots()\n    ax.bar(feature_names, avg_tfidf_scores)\n    ax.set_ylabel('TF-IDF Score')\n    ax.set_xticklabels(feature_names, rotation=90)\n\n    return ax", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\n\ndef task_func(df):\n    # Check if 'Title' and 'Content' columns exist in the DataFrame\n    if 'Title' not in df.columns or 'Content' not in df.columns:\n        return plt.figure()\n\n    # Filter articles with titles containing 'how' or 'what'\n    df = df[df['Title'].apply(lambda x: bool(re.search(r'\\b(how|what)\\b', x, re.I)))]\n\n    # Check if there are any articles left\n    if df.empty:\n        return plt.figure()\n\n    # Calculate TF-IDF scores\n    vectorizer = TfidfVectorizer(stop_words='english')\n    tfidf_matrix = vectorizer.fit_transform(df['Content'])\n    feature_names = vectorizer.get_feature_names_out()\n\n    # Calculate average TF-IDF scores for each article\n    avg_tfidf_scores = np.mean(tfidf_matrix, axis=0).tolist()[0]\n\n    # Create bar plot\n    fig, ax = plt.subplots()\n    ax.bar(feature_names, avg_tfidf_scores)\n    ax.set_ylabel('TF-IDF Score')\n    ax.set_xticklabels(feature_names, rotation=90)\n\n    return ax"}
{"task_id": "BigCodeBench/180", "solution": "from PIL import Image\nimport numpy as np\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(img_path, scale_factors=[0.5, 0.75, 1.5, 2.0]):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"The image file cannot be found.\")\n\n    img = Image.open(img_path)\n    img_array = np.array(img)\n\n    result = []\n    for scale in scale_factors:\n        scaled_img_array = resize(img_array, (int(img_array.shape[0]*scale), int(img_array.shape[1]*scale)))\n        fig, ax = plt.subplots(1, 1)\n        ax.imshow(scaled_img_array)\n        plt.show()\n        result.append((ax, scaled_img_array))\n\n    return result", "raw_solution": "from PIL import Image\nimport numpy as np\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(img_path, scale_factors=[0.5, 0.75, 1.5, 2.0]):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"The image file cannot be found.\")\n\n    img = Image.open(img_path)\n    img_array = np.array(img)\n\n    result = []\n    for scale in scale_factors:\n        scaled_img_array = resize(img_array, (int(img_array.shape[0]*scale), int(img_array.shape[1]*scale)))\n        fig, ax = plt.subplots(1, 1)\n        ax.imshow(scaled_img_array)\n        plt.show()\n        result.append((ax, scaled_img_array))\n\n    return result"}
{"task_id": "BigCodeBench/181", "solution": "from django.http import HttpResponse\nfrom django.conf import settings\nimport random\nimport time\nimport json\ndef task_func(data, min_delay, max_delay):\n    delay = random.randint(min_delay, max_delay)\n    time.sleep(delay)\n    json_data = json.dumps(data)\n    return HttpResponse(json_data, content_type='application/json')", "raw_solution": "from django.http import HttpResponse\nfrom django.conf import settings\nimport random\nimport time\nimport json\n\ndef task_func(data, min_delay, max_delay):\n    delay = random.randint(min_delay, max_delay)\n    time.sleep(delay)\n    json_data = json.dumps(data)\n    return HttpResponse(json_data, content_type='application/json')"}
{"task_id": "BigCodeBench/182", "solution": "import re\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import CountVectorizer\ndef task_func(df):\n    # Filter articles that start with \"how\" or \"what\"\n    df = df[df['title'].str.lower().str.startswith('how') | df['title'].str.lower().str.startswith('what')]\n\n    # Vectorize the content using CountVectorizer\n    vectorizer = CountVectorizer(stop_words='english')\n    X = vectorizer.fit_transform(df['content'])\n\n    # Group articles into clusters using KMeans clustering\n    kmeans = KMeans(n_clusters=3)\n    kmeans.fit(X)\n\n    # Get the cluster labels for the filtered articles\n    labels = kmeans.labels_\n\n    return labels.tolist()\ndf = pd.DataFrame({\n    'title': ['How to code', 'What is AI', 'Why is the sky blue', 'How to draw', 'What is the weather like'],\n    'content': ['Code in Python', 'Introduction to AI', 'The sky is blue due to...', 'Draw with a pencil', 'Weather report: Cold and windy']\n})", "raw_solution": "import re\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef task_func(df):\n    # Filter articles that start with \"how\" or \"what\"\n    df = df[df['title'].str.lower().str.startswith('how') | df['title'].str.lower().str.startswith('what')]\n\n    # Vectorize the content using CountVectorizer\n    vectorizer = CountVectorizer(stop_words='english')\n    X = vectorizer.fit_transform(df['content'])\n\n    # Group articles into clusters using KMeans clustering\n    kmeans = KMeans(n_clusters=3)\n    kmeans.fit(X)\n\n    # Get the cluster labels for the filtered articles\n    labels = kmeans.labels_\n\n    return labels.tolist()\n\n# Test the function\ndf = pd.DataFrame({\n    'title': ['How to code', 'What is AI', 'Why is the sky blue', 'How to draw', 'What is the weather like'],\n    'content': ['Code in Python', 'Introduction to AI', 'The sky is blue due to...', 'Draw with a pencil', 'Weather report: Cold and windy']\n})"}
{"task_id": "BigCodeBench/183", "solution": "from django.http import HttpResponse\nimport uuid\nimport json\ndef task_func(data):\n    # Generate a UUID\n    uid = uuid.uuid4()\n\n    # Convert data to JSON\n    json_data = json.dumps(data)\n\n    # Create HttpResponse with JSON data\n    response = HttpResponse(json_data, content_type='application/json')\n\n    # Add UUID to HTTP headers\n    response['UUID'] = str(uid)\n\n    return response", "raw_solution": "from django.http import HttpResponse\nimport uuid\nimport json\n\ndef task_func(data):\n    # Generate a UUID\n    uid = uuid.uuid4()\n\n    # Convert data to JSON\n    json_data = json.dumps(data)\n\n    # Create HttpResponse with JSON data\n    response = HttpResponse(json_data, content_type='application/json')\n\n    # Add UUID to HTTP headers\n    response['UUID'] = str(uid)\n\n    return response"}
{"task_id": "BigCodeBench/184", "solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\ndef task_func(dataframe, text_column):\n    # Remove stopwords, numbers, and punctuation\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: ' '.join(\n        [word for word in x.split() if word not in STOPWORDS and not word.isdigit() and word.isalpha()]))\n\n    # Initialize CountVectorizer\n    vectorizer = CountVectorizer()\n\n    # Fit and transform the data\n    X = vectorizer.fit_transform(dataframe[text_column])\n\n    # Create a DataFrame from the matrix\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n\n    return df", "raw_solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Constants\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\n\ndef task_func(dataframe, text_column):\n    # Remove stopwords, numbers, and punctuation\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: ' '.join(\n        [word for word in x.split() if word not in STOPWORDS and not word.isdigit() and word.isalpha()]))\n\n    # Initialize CountVectorizer\n    vectorizer = CountVectorizer()\n\n    # Fit and transform the data\n    X = vectorizer.fit_transform(dataframe[text_column])\n\n    # Create a DataFrame from the matrix\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n\n    return df"}
{"task_id": "BigCodeBench/185", "solution": "import pandas as pd\nimport numpy as np\nimport folium\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    # Check if 'Lon' and 'Lat' keys are present in the dictionary\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"'Lon' and 'Lat' keys are required in the dictionary\")\n\n    # Check if 'Lon' and 'Lat' values are tuples\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples\")\n\n    # Generate random coordinates for each city\n    np.random.seed(0)  # for reproducibility\n    lons = np.random.uniform(dic['Lon'][0], dic['Lon'][1], len(cities))\n    lats = np.random.uniform(dic['Lat'][0], dic['Lat'][1], len(cities))\n\n    # Create a DataFrame\n    df = pd.DataFrame({'City': cities, 'Longitude': lons, 'Latitude': lats})\n\n    # Create a map\n    m = folium.Map(location=[np.mean(lats), np.mean(lons)], zoom_start=2)\n\n    # Add markers to the map\n    for i in range(0,len(df)):\n        folium.Marker([df.iloc[i]['Latitude'], df.iloc[i]['Longitude']], popup=df.iloc[i]['City']).add_to(m)\n\n    return (m, df)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport folium\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    # Check if 'Lon' and 'Lat' keys are present in the dictionary\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"'Lon' and 'Lat' keys are required in the dictionary\")\n\n    # Check if 'Lon' and 'Lat' values are tuples\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples\")\n\n    # Generate random coordinates for each city\n    np.random.seed(0)  # for reproducibility\n    lons = np.random.uniform(dic['Lon'][0], dic['Lon'][1], len(cities))\n    lats = np.random.uniform(dic['Lat'][0], dic['Lat'][1], len(cities))\n\n    # Create a DataFrame\n    df = pd.DataFrame({'City': cities, 'Longitude': lons, 'Latitude': lats})\n\n    # Create a map\n    m = folium.Map(location=[np.mean(lats), np.mean(lons)], zoom_start=2)\n\n    # Add markers to the map\n    for i in range(0,len(df)):\n        folium.Marker([df.iloc[i]['Latitude'], df.iloc[i]['Longitude']], popup=df.iloc[i]['City']).add_to(m)\n\n    return (m, df)\n\n# Test the function\nm, df = task_func()"}
{"task_id": "BigCodeBench/186", "solution": "from geopy.distance import geodesic\nimport folium\ndef task_func(dic):\n    if not dic:\n        raise ValueError(\"Input dictionary is empty\")\n\n    # Create a Folium map object\n    m = folium.Map(location=[45.523, -122.675], zoom_start=13)\n\n    # List to hold location names and coordinates\n    locations = []\n\n    # Add markers to the map and collect location names and coordinates\n    for name, (lat, lon) in dic.items():\n        folium.Marker(location=[lat, lon], popup=name).add_to(m)\n        locations.append((name, (lat, lon)))\n\n    # Calculate distances between each pair of locations\n    distances = {}\n    for i in range(len(locations)):\n        for j in range(i+1, len(locations)):\n            loc1 = locations[i][1]\n            loc2 = locations[j][1]\n            distance = geodesic(loc1, loc2).km\n            distances[f\"{locations[i][0]}-{locations[j][0]}\"] = distance\n\n    return m, distances\ndic = {\n    'Location1': (45.523, -122.675),\n    'Location2': (45.524, -122.676),\n    'Location3': (45.525, -122.677)\n}", "raw_solution": "from geopy.distance import geodesic\nimport folium\n\ndef task_func(dic):\n    if not dic:\n        raise ValueError(\"Input dictionary is empty\")\n\n    # Create a Folium map object\n    m = folium.Map(location=[45.523, -122.675], zoom_start=13)\n\n    # List to hold location names and coordinates\n    locations = []\n\n    # Add markers to the map and collect location names and coordinates\n    for name, (lat, lon) in dic.items():\n        folium.Marker(location=[lat, lon], popup=name).add_to(m)\n        locations.append((name, (lat, lon)))\n\n    # Calculate distances between each pair of locations\n    distances = {}\n    for i in range(len(locations)):\n        for j in range(i+1, len(locations)):\n            loc1 = locations[i][1]\n            loc2 = locations[j][1]\n            distance = geodesic(loc1, loc2).km\n            distances[f\"{locations[i][0]}-{locations[j][0]}\"] = distance\n\n    return m, distances\n\n# Test the function\ndic = {\n    'Location1': (45.523, -122.675),\n    'Location2': (45.524, -122.676),\n    'Location3': (45.525, -122.677)\n}\n\nmap_obj, dist_dict = task_func(dic)\nmap_obj.save('map.html')  # Save the map to an HTML file"}
{"task_id": "BigCodeBench/187", "solution": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if not isinstance(dic, dict):\n        raise ValueError(\"Input should be a dictionary\")\n    if not isinstance(cities, list):\n        raise ValueError(\"Cities should be a list\")\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"'Lon' and 'Lat' keys are required\")\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples\")\n\n    # Generate random coordinates\n    np.random.seed(0)\n    lon = np.random.uniform(dic['Lon'][0], dic['Lon'][1], len(cities))\n    lat = np.random.uniform(dic['Lat'][0], dic['Lat'][1], len(cities))\n\n    # Create Points\n    points = [Point(xy) for xy in zip(lon, lat)]\n\n    # Create GeoDataFrame\n    df = gpd.GeoDataFrame(cities, geometry=points, crs=4326)\n    df.columns = ['City', 'Coordinates']\n\n    return df", "raw_solution": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if not isinstance(dic, dict):\n        raise ValueError(\"Input should be a dictionary\")\n    if not isinstance(cities, list):\n        raise ValueError(\"Cities should be a list\")\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"'Lon' and 'Lat' keys are required\")\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"'Lon' and 'Lat' values should be tuples\")\n\n    # Generate random coordinates\n    np.random.seed(0)\n    lon = np.random.uniform(dic['Lon'][0], dic['Lon'][1], len(cities))\n    lat = np.random.uniform(dic['Lat'][0], dic['Lat'][1], len(cities))\n\n    # Create Points\n    points = [Point(xy) for xy in zip(lon, lat)]\n\n    # Create GeoDataFrame\n    df = gpd.GeoDataFrame(cities, geometry=points, crs=4326)\n    df.columns = ['City', 'Coordinates']\n\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/188", "solution": "import pandas as pd\nimport folium\nfrom geopy.geocoders import Photon\ndef task_func(dic):\n    geolocator = Photon(user_agent=\"geoapiExercises\")\n\n    # Create a dataframe from the dictionary\n    df = pd.DataFrame(dic)\n\n    # Create a new column 'coordinates' to store the latitude and longitude\n    df['coordinates'] = df.apply(lambda row: get_coordinates(geolocator, row['location']), axis=1)\n\n    # Create a map\n    m = folium.Map(location=[df['coordinates'].mean().latitude, df['coordinates'].mean().longitude], zoom_start=13)\n\n    # Add markers to the map\n    for i in range(0,len(df)):\n        folium.Marker(location=[df.iloc[i]['coordinates'].latitude, df.iloc[i]['coordinates'].longitude], \n                      popup=df.iloc[i]['location']).add_to(m)\n\n    return m\ndef get_coordinates(geolocator, location):\n    try:\n        # If location is a string, get its coordinates\n        location = geolocator.geocode(location)\n    except:\n        pass\n    return location.latitude, location.longitude", "raw_solution": "import pandas as pd\nimport folium\nfrom geopy.geocoders import Photon\n\ndef task_func(dic):\n    geolocator = Photon(user_agent=\"geoapiExercises\")\n\n    # Create a dataframe from the dictionary\n    df = pd.DataFrame(dic)\n\n    # Create a new column 'coordinates' to store the latitude and longitude\n    df['coordinates'] = df.apply(lambda row: get_coordinates(geolocator, row['location']), axis=1)\n\n    # Create a map\n    m = folium.Map(location=[df['coordinates'].mean().latitude, df['coordinates'].mean().longitude], zoom_start=13)\n\n    # Add markers to the map\n    for i in range(0,len(df)):\n        folium.Marker(location=[df.iloc[i]['coordinates'].latitude, df.iloc[i]['coordinates'].longitude], \n                      popup=df.iloc[i]['location']).add_to(m)\n\n    return m\n\ndef get_coordinates(geolocator, location):\n    try:\n        # If location is a string, get its coordinates\n        location = geolocator.geocode(location)\n    except:\n        pass\n    return location.latitude, location.longitude"}
{"task_id": "BigCodeBench/189", "solution": "import re\nimport json\nimport requests\ndef task_func(data_url: str) -> list:\n    try:\n        response = requests.get(data_url)\n        data = json.loads(response.text)\n        names = re.findall(r'\"name\":\\s*\"([^\"]+)\"', json.dumps(data))\n        return names\n    except Exception:\n        return \"Invalid url input\"", "raw_solution": "import re\nimport json\nimport requests\n\ndef task_func(data_url: str) -> list:\n    try:\n        response = requests.get(data_url)\n        data = json.loads(response.text)\n        names = re.findall(r'\"name\":\\s*\"([^\"]+)\"', json.dumps(data))\n        return names\n    except Exception:\n        return \"Invalid url input\"\n\n# Test the function"}
{"task_id": "BigCodeBench/190", "solution": "import sqlite3\nimport pandas as pd\nimport csv\nfrom io import StringIO\nDATABASE_NAME = 'test.db'\nTABLE_NAME = 'test_table'\ndef task_func(csv_input):\n    # Connect to SQLite database\n    conn = sqlite3.connect(DATABASE_NAME)\n    cur = conn.cursor()\n\n    # Create table if it doesn't exist\n    cur.execute(f'CREATE TABLE IF NOT EXISTS {TABLE_NAME} ({\",\".join([\"col\"+str(i) for i in range(100)])})')\n\n    # Delete existing data in the table\n    cur.execute(f'DELETE FROM {TABLE_NAME}')\n\n    # If csv_input is a file path, read the file\n    if isinstance(csv_input, str):\n        with open(csv_input, 'r') as file:\n            csv_data = csv.reader(file)\n    # If csv_input is a StringIO, read from it\n    elif isinstance(csv_input, StringIO):\n        csv_data = csv.reader(csv_input)\n    else:\n        raise TypeError(\"csv_input must be a file path or StringIO\")\n\n    # Insert data into the table\n    for row in csv_data:\n        cur.execute(f'INSERT INTO {TABLE_NAME} VALUES ({\",\".join([\"?\" for _ in range(len(row))])})', row)\n\n    # Commit changes and close connection\n    conn.commit()\n    conn.close()\n\n    # Query the table and return the data as a pandas DataFrame\n    return pd.read_sql_query(f'SELECT * FROM {TABLE_NAME}', DATABASE_NAME)", "raw_solution": "import sqlite3\nimport pandas as pd\nimport csv\nfrom io import StringIO\n\n# Constants\nDATABASE_NAME = 'test.db'\nTABLE_NAME = 'test_table'\n\ndef task_func(csv_input):\n    # Connect to SQLite database\n    conn = sqlite3.connect(DATABASE_NAME)\n    cur = conn.cursor()\n\n    # Create table if it doesn't exist\n    cur.execute(f'CREATE TABLE IF NOT EXISTS {TABLE_NAME} ({\",\".join([\"col\"+str(i) for i in range(100)])})')\n\n    # Delete existing data in the table\n    cur.execute(f'DELETE FROM {TABLE_NAME}')\n\n    # If csv_input is a file path, read the file\n    if isinstance(csv_input, str):\n        with open(csv_input, 'r') as file:\n            csv_data = csv.reader(file)\n    # If csv_input is a StringIO, read from it\n    elif isinstance(csv_input, StringIO):\n        csv_data = csv.reader(csv_input)\n    else:\n        raise TypeError(\"csv_input must be a file path or StringIO\")\n\n    # Insert data into the table\n    for row in csv_data:\n        cur.execute(f'INSERT INTO {TABLE_NAME} VALUES ({\",\".join([\"?\" for _ in range(len(row))])})', row)\n\n    # Commit changes and close connection\n    conn.commit()\n    conn.close()\n\n    # Query the table and return the data as a pandas DataFrame\n    return pd.read_sql_query(f'SELECT * FROM {TABLE_NAME}', DATABASE_NAME)"}
{"task_id": "BigCodeBench/191", "solution": "import random\nfrom scipy import stats\ndef task_func(animals, mean):\n    # Generate a random number of customers following a Poisson distribution\n    num_customers = int(stats.poisson.rvs(mean))\n\n    # Initialize a dictionary to store the sales\n    sales = {animal: 0 for animal in animals}\n\n    # Simulate each customer's purchase\n    for _ in range(num_customers):\n        # Randomly select an animal for the customer to buy\n        animal = random.choice(animals)\n\n        # Increment the count of the selected animal in the sales dictionary\n        sales[animal] += 1\n\n    # Print the sales summary\n    print(\"Sales Summary:\")\n    for animal, count in sales.items():\n        print(f\"{animal}: {count}\")\n\n    # Return the sales dictionary\n    return sales", "raw_solution": "import random\nfrom scipy import stats\n\ndef task_func(animals, mean):\n    # Generate a random number of customers following a Poisson distribution\n    num_customers = int(stats.poisson.rvs(mean))\n\n    # Initialize a dictionary to store the sales\n    sales = {animal: 0 for animal in animals}\n\n    # Simulate each customer's purchase\n    for _ in range(num_customers):\n        # Randomly select an animal for the customer to buy\n        animal = random.choice(animals)\n\n        # Increment the count of the selected animal in the sales dictionary\n        sales[animal] += 1\n\n    # Print the sales summary\n    print(\"Sales Summary:\")\n    for animal, count in sales.items():\n        print(f\"{animal}: {count}\")\n\n    # Return the sales dictionary\n    return sales"}
{"task_id": "BigCodeBench/192", "solution": "import re\nimport smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nTEXT = \"Josie Smith [3996 COLLEGE AVENUE, SOMETOWN, MD 21003]Mugsy Dog Smith [2560 OAK ST, GLENMEADE, WI 14098]\"\nRECEPIENT_ADDRESS = \"names@gmail.com\"\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\ndef task_func(text=TEXT, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, recepient_address=RECEPIENT_ADDRESS, smtp=None):\n    # Extract names\n    names = re.findall(r'\\[.*?\\]', text)\n    names = [name.split()[0] for name in names]\n\n    # Send email\n    if smtp is None:\n        smtp = smtplib.SMTP(smtp_server, smtp_port)\n        smtp.ehlo()\n        smtp.starttls()\n        smtp.login(email_address, email_password)\n\n    msg = MIMEMultipart()\n    msg['From'] = email_address\n    msg['To'] = recepient_address\n    msg['Subject'] = 'Extracted Names'\n    msg.attach(MIMEText('\\n'.join(names)))\n\n    smtp.send_message(msg)\n    smtp.quit()\n\n    return names", "raw_solution": "import re\nimport smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\n\n# Constants\nTEXT = \"Josie Smith [3996 COLLEGE AVENUE, SOMETOWN, MD 21003]Mugsy Dog Smith [2560 OAK ST, GLENMEADE, WI 14098]\"\nRECEPIENT_ADDRESS = \"names@gmail.com\"\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\n\ndef task_func(text=TEXT, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, recepient_address=RECEPIENT_ADDRESS, smtp=None):\n    # Extract names\n    names = re.findall(r'\\[.*?\\]', text)\n    names = [name.split()[0] for name in names]\n\n    # Send email\n    if smtp is None:\n        smtp = smtplib.SMTP(smtp_server, smtp_port)\n        smtp.ehlo()\n        smtp.starttls()\n        smtp.login(email_address, email_password)\n\n    msg = MIMEMultipart()\n    msg['From'] = email_address\n    msg['To'] = recepient_address\n    msg['Subject'] = 'Extracted Names'\n    msg.attach(MIMEText('\\n'.join(names)))\n\n    smtp.send_message(msg)\n    smtp.quit()\n\n    return names"}
{"task_id": "BigCodeBench/193", "solution": "import pandas as pd\nimport numpy as np\nfrom random import choice, randint, sample\nDATA_TYPES = [str, int, float, list, tuple, dict, set]\ndef task_func(rows, columns):\n    data = {}\n    for i in range(columns):\n        column_data = []\n        for j in range(rows):\n            data_type = choice(DATA_TYPES)\n            if data_type == str:\n                column_data.append(''.join(choice('abcdefghijklmnopqrstuvwxyz') for _ in range(5)))\n            elif data_type == int:\n                column_data.append(randint(0, 9))\n            elif data_type == float:\n                column_data.append(float(randint(0, 9)))\n            elif data_type == list:\n                column_data.append(sample(range(0, 10), randint(1, 5)))\n            elif data_type == tuple:\n                column_data.append(tuple(sample(range(0, 10), randint(1, 5))))\n            elif data_type == dict:\n                column_data.append({str(k): v for k, v in enumerate(sample(range(0, 10), randint(1, 5)))} )\n            elif data_type == set:\n                column_data.append(set(sample(range(0, 10), randint(1, 5))))\n        data['col'+str(i)] = column_data\n    return pd.DataFrame(data)", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom random import choice, randint, sample\n\n# Constants\nDATA_TYPES = [str, int, float, list, tuple, dict, set]\n\ndef task_func(rows, columns):\n    data = {}\n    for i in range(columns):\n        column_data = []\n        for j in range(rows):\n            data_type = choice(DATA_TYPES)\n            if data_type == str:\n                column_data.append(''.join(choice('abcdefghijklmnopqrstuvwxyz') for _ in range(5)))\n            elif data_type == int:\n                column_data.append(randint(0, 9))\n            elif data_type == float:\n                column_data.append(float(randint(0, 9)))\n            elif data_type == list:\n                column_data.append(sample(range(0, 10), randint(1, 5)))\n            elif data_type == tuple:\n                column_data.append(tuple(sample(range(0, 10), randint(1, 5))))\n            elif data_type == dict:\n                column_data.append({str(k): v for k, v in enumerate(sample(range(0, 10), randint(1, 5)))} )\n            elif data_type == set:\n                column_data.append(set(sample(range(0, 10), randint(1, 5))))\n        data['col'+str(i)] = column_data\n    return pd.DataFrame(data)\n\n# Test the function\ndf = task_func(5, 3)"}
{"task_id": "BigCodeBench/194", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nBAR_COLOR = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black']\ndef task_func(data_size):\n    # Generate random data\n    data = np.random.rand(data_size)\n\n    # Select a random color from the list\n    bar_color = np.random.choice(BAR_COLOR)\n\n    # Plot the histogram\n    plt.hist(data, color=bar_color)\n    plt.show()\n\n    return data, bar_color", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nBAR_COLOR = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black']\n\ndef task_func(data_size):\n    # Generate random data\n    data = np.random.rand(data_size)\n\n    # Select a random color from the list\n    bar_color = np.random.choice(BAR_COLOR)\n\n    # Plot the histogram\n    plt.hist(data, color=bar_color)\n    plt.show()\n\n    return data, bar_color\n\n# Test the function\ndata, color = task_func(1000)"}
{"task_id": "BigCodeBench/195", "solution": "import subprocess\nimport platform\nimport time\ndef task_func(url):\n    # Check the operating system\n    os = platform.system()\n\n    if os == \"Windows\":\n        # For Windows, use the start command to open the URL in the default browser\n        command = [\"start\", url]\n    elif os == \"Darwin\":\n        # For MacOS, use the open command to open the URL in the default browser\n        command = [\"open\", url]\n    else:\n        # For Linux, use the xdg-open command to open the URL in the default browser\n        command = [\"xdg-open\", url]\n\n    # Run the command in a subprocess\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    # Wait for the process to finish\n    stdout, stderr = process.communicate()\n\n    # Return the return code of the subprocess\n    return process.returncode", "raw_solution": "import subprocess\nimport platform\nimport time\n\ndef task_func(url):\n    # Check the operating system\n    os = platform.system()\n\n    if os == \"Windows\":\n        # For Windows, use the start command to open the URL in the default browser\n        command = [\"start\", url]\n    elif os == \"Darwin\":\n        # For MacOS, use the open command to open the URL in the default browser\n        command = [\"open\", url]\n    else:\n        # For Linux, use the xdg-open command to open the URL in the default browser\n        command = [\"xdg-open\", url]\n\n    # Run the command in a subprocess\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    # Wait for the process to finish\n    stdout, stderr = process.communicate()\n\n    # Return the return code of the subprocess\n    return process.returncode"}
{"task_id": "BigCodeBench/196", "solution": "import random\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom typing import Tuple\ndef task_func(length: int, range_limit: int = 100, seed: int = 0) -> Tuple[object, list]:\n    if range_limit <= 1:\n        raise ValueError(\"range_limit should be greater than 1\")\n\n    random.seed(seed)\n    numbers = [random.randint(0, range_limit) for _ in range(length)]\n\n    plt.figure(figsize=(10, 6))\n    ax = sns.histplot(numbers, bins=range_limit, kde=False)\n\n    return ax, numbers", "raw_solution": "import random\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom typing import Tuple\n\ndef task_func(length: int, range_limit: int = 100, seed: int = 0) -> Tuple[object, list]:\n    if range_limit <= 1:\n        raise ValueError(\"range_limit should be greater than 1\")\n\n    random.seed(seed)\n    numbers = [random.randint(0, range_limit) for _ in range(length)]\n\n    plt.figure(figsize=(10, 6))\n    ax = sns.histplot(numbers, bins=range_limit, kde=False)\n\n    return ax, numbers"}
{"task_id": "BigCodeBench/197", "solution": "import heapq\nimport math\nimport matplotlib.pyplot as plt\ndef task_func(l1, l2, N=10):\n    if len(l1) != len(l2):\n        raise ValueError(\"Both lists must have the same length\")\n    diffs = [(abs(a-b), (a, b)) for a, b in zip(l1, l2)]\n    N = min(N, len(diffs))\n    N_largest_diffs = heapq.nlargest(N, diffs)\n    sq_roots = [math.sqrt(d[0]) for d in N_largest_diffs]\n    plt.plot(sq_roots)\n    return plt.gca()", "raw_solution": "import heapq\nimport math\nimport matplotlib.pyplot as plt\n\ndef task_func(l1, l2, N=10):\n    if len(l1) != len(l2):\n        raise ValueError(\"Both lists must have the same length\")\n    diffs = [(abs(a-b), (a, b)) for a, b in zip(l1, l2)]\n    N = min(N, len(diffs))\n    N_largest_diffs = heapq.nlargest(N, diffs)\n    sq_roots = [math.sqrt(d[0]) for d in N_largest_diffs]\n    plt.plot(sq_roots)\n    return plt.gca()"}
{"task_id": "BigCodeBench/198", "solution": "import numpy as np\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\ndef task_func(data, value):\n    if not data:\n        return np.array([]), 0\n\n    avg = statistics.mean(data)\n    data_above_avg = [x for x in data if x > avg]\n    count = bisect.bisect_right(data, value)\n\n    plt.hist(sorted(data), bins='auto')\n    plt.show()\n\n    return np.array(data_above_avg), count", "raw_solution": "import numpy as np\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\n\ndef task_func(data, value):\n    if not data:\n        return np.array([]), 0\n\n    avg = statistics.mean(data)\n    data_above_avg = [x for x in data if x > avg]\n    count = bisect.bisect_right(data, value)\n\n    plt.hist(sorted(data), bins='auto')\n    plt.show()\n\n    return np.array(data_above_avg), count"}
{"task_id": "BigCodeBench/199", "solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    # Check if utc_datetime is a datetime object\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime should be a datetime object\")\n\n    # Check if all parameters are in the expected format\n    if not all(isinstance(city, str) for city in cities):\n        raise ValueError(\"All cities should be strings\")\n    if not all(isinstance(condition, str) for condition in weather_conditions):\n        raise ValueError(\"All weather conditions should be strings\")\n    if not all(isinstance(timezone, str) for timezone in timezones.values()):\n        raise ValueError(\"All timezones should be strings\")\n\n    # Set the seed for the random number generator\n    set_seed(seed)\n\n    # Generate the weather report for each city\n    data = []\n    for city in cities:\n        # Convert the utc_datetime to the local time of the city\n        local_time = utc_datetime.replace(tzinfo=pytz.utc).astimezone(pytz.timezone(timezones[city]))\n\n        # Generate a random weather condition\n        condition = weather_conditions[randint(0, len(weather_conditions) - 1)]\n\n        # Add the data to the list\n        data.append({\n            'City': city,\n            'Local Time': local_time.strftime('%Y-%m-%d %H:%M:%S %Z'),\n            'Weather Condition': condition\n        })\n\n    # Create a DataFrame from the data\n    df = pd.DataFrame(data)\n\n    return df", "raw_solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\n\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    # Check if utc_datetime is a datetime object\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime should be a datetime object\")\n\n    # Check if all parameters are in the expected format\n    if not all(isinstance(city, str) for city in cities):\n        raise ValueError(\"All cities should be strings\")\n    if not all(isinstance(condition, str) for condition in weather_conditions):\n        raise ValueError(\"All weather conditions should be strings\")\n    if not all(isinstance(timezone, str) for timezone in timezones.values()):\n        raise ValueError(\"All timezones should be strings\")\n\n    # Set the seed for the random number generator\n    set_seed(seed)\n\n    # Generate the weather report for each city\n    data = []\n    for city in cities:\n        # Convert the utc_datetime to the local time of the city\n        local_time = utc_datetime.replace(tzinfo=pytz.utc).astimezone(pytz.timezone(timezones[city]))\n\n        # Generate a random weather condition\n        condition = weather_conditions[randint(0, len(weather_conditions) - 1)]\n\n        # Add the data to the list\n        data.append({\n            'City': city,\n            'Local Time': local_time.strftime('%Y-%m-%d %H:%M:%S %Z'),\n            'Weather Condition': condition\n        })\n\n    # Create a DataFrame from the data\n    df = pd.DataFrame(data)\n\n    return df"}
{"task_id": "BigCodeBench/200", "solution": "import random\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\ndef task_func(n, value):\n    # Generate 'n' random numbers between 0 and 1\n    numbers = [random.random() for _ in range(n)]\n\n    # Calculate the average of the generated numbers\n    avg = statistics.mean(numbers)\n\n    # Find those greater than their average\n    numbers_greater_than_avg = [num for num in numbers if num > avg]\n\n    # Count how many are greater than or equal to the specified value\n    count = sum(1 for num in numbers_greater_than_avg if num >= value)\n\n    # Sort the numbers\n    numbers_greater_than_avg.sort()\n\n    # Plot the sorted numbers\n    plt.plot(numbers_greater_than_avg)\n    plt.show()\n\n    return numbers_greater_than_avg, count", "raw_solution": "import random\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\n\ndef task_func(n, value):\n    # Generate 'n' random numbers between 0 and 1\n    numbers = [random.random() for _ in range(n)]\n\n    # Calculate the average of the generated numbers\n    avg = statistics.mean(numbers)\n\n    # Find those greater than their average\n    numbers_greater_than_avg = [num for num in numbers if num > avg]\n\n    # Count how many are greater than or equal to the specified value\n    count = sum(1 for num in numbers_greater_than_avg if num >= value)\n\n    # Sort the numbers\n    numbers_greater_than_avg.sort()\n\n    # Plot the sorted numbers\n    plt.plot(numbers_greater_than_avg)\n    plt.show()\n\n    return numbers_greater_than_avg, count\n\n# Test the function\nnumbers, count = task_func(100, 0.5)"}
{"task_id": "BigCodeBench/201", "solution": "import bisect\nimport statistics\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(df, column, value):\n    if column not in df.columns:\n        raise ValueError(\"Column does not exist in the DataFrame\")\n    if not pd.api.types.is_numeric_dtype(df[column]):\n        raise ValueError(\"Value is not a number\")\n\n    avg = statistics.mean(df[column].dropna())\n    values_greater_than_avg = df[df[column] > avg]\n    values_greater_than_value = df[df[column] > value]\n\n    fig, ax = plt.subplots()\n    ax.hist(values_greater_than_avg[column], alpha=0.5, bins='auto', label='Values greater than average')\n    ax.hist(values_greater_than_value[column], alpha=0.5, bins='auto', label=f'Values greater than {value}')\n    ax.legend(loc='upper right')\n\n    return (np.array(values_greater_than_avg[column]), len(values_greater_than_value), ax)", "raw_solution": "import bisect\nimport statistics\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df, column, value):\n    if column not in df.columns:\n        raise ValueError(\"Column does not exist in the DataFrame\")\n    if not pd.api.types.is_numeric_dtype(df[column]):\n        raise ValueError(\"Value is not a number\")\n\n    avg = statistics.mean(df[column].dropna())\n    values_greater_than_avg = df[df[column] > avg]\n    values_greater_than_value = df[df[column] > value]\n\n    fig, ax = plt.subplots()\n    ax.hist(values_greater_than_avg[column], alpha=0.5, bins='auto', label='Values greater than average')\n    ax.hist(values_greater_than_value[column], alpha=0.5, bins='auto', label=f'Values greater than {value}')\n    ax.legend(loc='upper right')\n\n    return (np.array(values_greater_than_avg[column]), len(values_greater_than_value), ax)"}
{"task_id": "BigCodeBench/202", "solution": "import re\nimport json\nfrom collections import Counter\ndef task_func(json_str, top_n=10):\n    # Regular expression pattern to match URLs\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n\n    # Load JSON string into a Python dict\n    json_dict = json.loads(json_str)\n\n    # Flatten the dict into a list of strings\n    flat_list = [str(item) for sublist in json_dict.values() for item in sublist]\n\n    # Find all URLs in the flattened list\n    urls = url_pattern.findall(' '.join(flat_list))\n\n    # Count the occurrences of each URL\n    url_counts = dict(Counter(urls))\n\n    # Sort the URLs by their counts in descending order and return the top n\n    top_urls = dict(sorted(url_counts.items(), key=lambda item: item[1], reverse=True)[:top_n])\n\n    return top_urls", "raw_solution": "import re\nimport json\nfrom collections import Counter\n\ndef task_func(json_str, top_n=10):\n    # Regular expression pattern to match URLs\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n\n    # Load JSON string into a Python dict\n    json_dict = json.loads(json_str)\n\n    # Flatten the dict into a list of strings\n    flat_list = [str(item) for sublist in json_dict.values() for item in sublist]\n\n    # Find all URLs in the flattened list\n    urls = url_pattern.findall(' '.join(flat_list))\n\n    # Count the occurrences of each URL\n    url_counts = dict(Counter(urls))\n\n    # Sort the URLs by their counts in descending order and return the top n\n    top_urls = dict(sorted(url_counts.items(), key=lambda item: item[1], reverse=True)[:top_n])\n\n    return top_urls"}
{"task_id": "BigCodeBench/203", "solution": "import json\nimport smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\ndef task_func(input_data=None, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, smtp=None):\n    # Parse JSON data\n    data = json.loads(input_data)\n\n    # Extract names and email addresses\n    names = [item['name'] for item in data['items']]\n    email_addresses = [item['email'] for item in data['items']]\n\n    # Create SMTP server\n    if smtp is None:\n        smtp = smtplib.SMTP(smtp_server, smtp_port)\n        smtp.ehlo()\n        smtp.starttls()\n        smtp.login(email_address, email_password)\n\n    # Send emails\n    for name, email in zip(names, email_addresses):\n        msg = MIMEMultipart()\n        msg['From'] = email_address\n        msg['To'] = email\n        msg['Subject'] = 'Extracted Names'\n        msg.attach(MIMEText(name))\n        smtp.send_message(msg)\n\n    # Close SMTP server\n    smtp.quit()\n\n    return names", "raw_solution": "import json\nimport smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\n\n# Constants\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\n\ndef task_func(input_data=None, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, smtp=None):\n    # Parse JSON data\n    data = json.loads(input_data)\n\n    # Extract names and email addresses\n    names = [item['name'] for item in data['items']]\n    email_addresses = [item['email'] for item in data['items']]\n\n    # Create SMTP server\n    if smtp is None:\n        smtp = smtplib.SMTP(smtp_server, smtp_port)\n        smtp.ehlo()\n        smtp.starttls()\n        smtp.login(email_address, email_password)\n\n    # Send emails\n    for name, email in zip(names, email_addresses):\n        msg = MIMEMultipart()\n        msg['From'] = email_address\n        msg['To'] = email\n        msg['Subject'] = 'Extracted Names'\n        msg.attach(MIMEText(name))\n        smtp.send_message(msg)\n\n    # Close SMTP server\n    smtp.quit()\n\n    return names"}
{"task_id": "BigCodeBench/204", "solution": "import numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(L):\n    # Calculate mean\n    mean = np.mean(L)\n    \n    # Calculate median\n    median = np.median(L)\n    \n    # Calculate mode\n    n = len(L)\n    data = Counter(L)\n    get_mode = dict(data)\n    mode = [k for k, v in get_mode.items() if v == max(list(data.values()))]\n    \n    # Calculate standard deviation\n    std_dev = np.std(L)\n    \n    # Create histogram plot\n    fig, ax = plt.subplots()\n    ax.hist(L, bins='auto')\n    ax.set_title('Histogram of L')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    \n    # Return dictionary\n    result = {'mean': mean, 'median': median, 'mode': mode, 'std_dev': std_dev, 'plot': ax}\n    return result", "raw_solution": "import numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    # Calculate mean\n    mean = np.mean(L)\n    \n    # Calculate median\n    median = np.median(L)\n    \n    # Calculate mode\n    n = len(L)\n    data = Counter(L)\n    get_mode = dict(data)\n    mode = [k for k, v in get_mode.items() if v == max(list(data.values()))]\n    \n    # Calculate standard deviation\n    std_dev = np.std(L)\n    \n    # Create histogram plot\n    fig, ax = plt.subplots()\n    ax.hist(L, bins='auto')\n    ax.set_title('Histogram of L')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    \n    # Return dictionary\n    result = {'mean': mean, 'median': median, 'mode': mode, 'std_dev': std_dev, 'plot': ax}\n    return result"}
{"task_id": "BigCodeBench/205", "solution": "import subprocess\nfrom multiprocessing import Pool\ndef execute_command(command):\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    output, _ = process.communicate()\n    return output\ndef task_func(commands):\n    if not commands:\n        return []\n    with Pool(len(commands)) as p:\n        return p.map(execute_command, commands)\ncommands = ['ls', 'pwd', 'echo \"Hello, World!\"']", "raw_solution": "import subprocess\nfrom multiprocessing import Pool\n\ndef execute_command(command):\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    output, _ = process.communicate()\n    return output\n\ndef task_func(commands):\n    if not commands:\n        return []\n    with Pool(len(commands)) as p:\n        return p.map(execute_command, commands)\n\n# Test the function\ncommands = ['ls', 'pwd', 'echo \"Hello, World!\"']\noutputs = task_func(commands)\nfor output in outputs:\n    print(output.decode())"}
{"task_id": "BigCodeBench/206", "solution": "import csv\nimport json\nimport os\ndef task_func(file_name):\n    try:\n        if not os.path.exists(file_name):\n            raise FileNotFoundError(\"The file does not exist.\")\n        \n        with open(file_name, 'r') as csv_file:\n            csv_data = csv.DictReader(csv_file)\n            json_data = json.dumps([row for row in csv_data])\n            \n        new_file_name = file_name.replace('.csv', '.json')\n        \n        with open(new_file_name, 'w') as json_file:\n            json_file.write(json_data)\n            \n        return new_file_name\n    \n    except FileNotFoundError as fnf_error:\n        print(fnf_error)", "raw_solution": "import csv\nimport json\nimport os\n\ndef task_func(file_name):\n    try:\n        if not os.path.exists(file_name):\n            raise FileNotFoundError(\"The file does not exist.\")\n        \n        with open(file_name, 'r') as csv_file:\n            csv_data = csv.DictReader(csv_file)\n            json_data = json.dumps([row for row in csv_data])\n            \n        new_file_name = file_name.replace('.csv', '.json')\n        \n        with open(new_file_name, 'w') as json_file:\n            json_file.write(json_data)\n            \n        return new_file_name\n    \n    except FileNotFoundError as fnf_error:\n        print(fnf_error)"}
{"task_id": "BigCodeBench/207", "solution": "import re\nimport requests\ndef task_func(input_string):\n    # Extract API endpoint using regex\n    api_endpoint = re.search(r'https?://[^\\s]+', input_string)\n    if api_endpoint:\n        api_endpoint = api_endpoint.group()\n    else:\n        return \"No API endpoint found in the input string\"\n\n    # Send GET request\n    try:\n        response = requests.get(api_endpoint)\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {e}\"\n\n    # Check if the request was successful\n    if response.status_code == 200:\n        # Return the response data in JSON format\n        return response.json()\n    else:\n        return f\"Request failed with status code: {response.status_code}\"", "raw_solution": "import re\nimport requests\n\ndef task_func(input_string):\n    # Extract API endpoint using regex\n    api_endpoint = re.search(r'https?://[^\\s]+', input_string)\n    if api_endpoint:\n        api_endpoint = api_endpoint.group()\n    else:\n        return \"No API endpoint found in the input string\"\n\n    # Send GET request\n    try:\n        response = requests.get(api_endpoint)\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {e}\"\n\n    # Check if the request was successful\n    if response.status_code == 200:\n        # Return the response data in JSON format\n        return response.json()\n    else:\n        return f\"Request failed with status code: {response.status_code}\"\n\n# Test the function"}
{"task_id": "BigCodeBench/208", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError(\"elements must be a positive integer\")\n\n    np.random.seed(seed)\n    random_walk = np.random.choice([-1, 1], size=elements)\n    random_walk_cumulative = np.cumsum(random_walk)\n\n    stats = {\n        'count': elements,\n        'mean': np.mean(random_walk),\n        'std': np.std(random_walk),\n        'min': np.min(random_walk),\n        '5th percentile': np.percentile(random_walk, 5),\n        '25th percentile': np.percentile(random_walk, 25),\n        'median': np.median(random_walk),\n        '75th percentile': np.percentile(random_walk, 75),\n        '95th percentile': np.percentile(random_walk, 95),\n        'max': np.max(random_walk),\n    }\n\n    fig, ax = plt.subplots()\n    ax.plot(random_walk_cumulative)\n    ax.set_title('Random Walk')\n    ax.set_xlabel('Steps')\n    ax.set_ylabel('Cumulative Sum')\n\n    return stats, ax.figure", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError(\"elements must be a positive integer\")\n\n    np.random.seed(seed)\n    random_walk = np.random.choice([-1, 1], size=elements)\n    random_walk_cumulative = np.cumsum(random_walk)\n\n    stats = {\n        'count': elements,\n        'mean': np.mean(random_walk),\n        'std': np.std(random_walk),\n        'min': np.min(random_walk),\n        '5th percentile': np.percentile(random_walk, 5),\n        '25th percentile': np.percentile(random_walk, 25),\n        'median': np.median(random_walk),\n        '75th percentile': np.percentile(random_walk, 75),\n        '95th percentile': np.percentile(random_walk, 95),\n        'max': np.max(random_walk),\n    }\n\n    fig, ax = plt.subplots()\n    ax.plot(random_walk_cumulative)\n    ax.set_title('Random Walk')\n    ax.set_xlabel('Steps')\n    ax.set_ylabel('Cumulative Sum')\n\n    return stats, ax.figure\n\n# Test the function\nstats, fig = task_func(1000)"}
{"task_id": "BigCodeBench/209", "solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Find the tuple with the maximum value at index 1\n    max_tuple = max(data, key=itemgetter(1))\n\n    # Separate the x and y coordinates\n    x, y = zip(*data)\n\n    # Create the scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(x, y)\n\n    # Highlight the maximum tuple\n    ax.scatter(max_tuple[0], max_tuple[1], color='r', s=100)\n\n    # Set the title and labels\n    ax.set_title('Max Tuple Highlighted')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n\n    # Add a legend\n    ax.legend(['Tuples', 'Max Tuple'])\n\n    return ax\ndata = [(1, 2), (2, 3), (3, 4), (4, 5), (5, 6)]", "raw_solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Find the tuple with the maximum value at index 1\n    max_tuple = max(data, key=itemgetter(1))\n\n    # Separate the x and y coordinates\n    x, y = zip(*data)\n\n    # Create the scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(x, y)\n\n    # Highlight the maximum tuple\n    ax.scatter(max_tuple[0], max_tuple[1], color='r', s=100)\n\n    # Set the title and labels\n    ax.set_title('Max Tuple Highlighted')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n\n    # Add a legend\n    ax.legend(['Tuples', 'Max Tuple'])\n\n    return ax\n\n# Test the function\ndata = [(1, 2), (2, 3), (3, 4), (4, 5), (5, 6)]\nax = task_func(data)\nplt.show()"}
{"task_id": "BigCodeBench/210", "solution": "import collections\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Count the frequency of each letter in the data\n    counter = collections.Counter(data)\n\n    # Sort the counter by the count in descending order\n    sorted_counter = sorted(counter.items(), key=itemgetter(1), reverse=True)\n\n    # Get the letter with the maximum count\n    max_letter = sorted_counter[0][0]\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    letters, counts = zip(*sorted_counter)\n    ax.bar(letters, counts)\n\n    # Highlight the letter with the maximum count\n    ax.bar(max_letter, counter[max_letter], color='r')\n\n    # Set labels and title\n    ax.set_xlabel('Letter')\n    ax.set_ylabel('Count')\n    ax.set_title('Letter Counts with Max Value Letter Highlighted')\n    ax.legend(['Letter Counts', 'Max Value Letter'])\n\n    return ax", "raw_solution": "import collections\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Count the frequency of each letter in the data\n    counter = collections.Counter(data)\n\n    # Sort the counter by the count in descending order\n    sorted_counter = sorted(counter.items(), key=itemgetter(1), reverse=True)\n\n    # Get the letter with the maximum count\n    max_letter = sorted_counter[0][0]\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    letters, counts = zip(*sorted_counter)\n    ax.bar(letters, counts)\n\n    # Highlight the letter with the maximum count\n    ax.bar(max_letter, counter[max_letter], color='r')\n\n    # Set labels and title\n    ax.set_xlabel('Letter')\n    ax.set_ylabel('Count')\n    ax.set_title('Letter Counts with Max Value Letter Highlighted')\n    ax.legend(['Letter Counts', 'Max Value Letter'])\n\n    return ax"}
{"task_id": "BigCodeBench/211", "solution": "import requests\nimport os\nimport zipfile\nfrom io import BytesIO\ndef task_func(url, destination_directory, headers=None):\n    # Send a GET request to the URL\n    response = requests.get(url, headers=headers)\n\n    # Raise an exception if the GET request is unsuccessful\n    response.raise_for_status()\n\n    # Create a BytesIO object from the content of the response\n    zip_file = zipfile.ZipFile(BytesIO(response.content))\n\n    # Extract all files in the zip file to the destination directory\n    zip_file.extractall(destination_directory)\n\n    # Get a list of all files in the destination directory\n    extracted_files = os.listdir(destination_directory)\n\n    return extracted_files", "raw_solution": "import requests\nimport os\nimport zipfile\nfrom io import BytesIO\n\ndef task_func(url, destination_directory, headers=None):\n    # Send a GET request to the URL\n    response = requests.get(url, headers=headers)\n\n    # Raise an exception if the GET request is unsuccessful\n    response.raise_for_status()\n\n    # Create a BytesIO object from the content of the response\n    zip_file = zipfile.ZipFile(BytesIO(response.content))\n\n    # Extract all files in the zip file to the destination directory\n    zip_file.extractall(destination_directory)\n\n    # Get a list of all files in the destination directory\n    extracted_files = os.listdir(destination_directory)\n\n    return extracted_files"}
{"task_id": "BigCodeBench/212", "solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Generate x and y values from the data\n    x, y = zip(*data)\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(x, y)\n\n    # Mark the point with the maximum y-value\n    max_y_point = max(data, key=itemgetter(1))\n    ax.scatter(*max_y_point, color='r')\n\n    # Label the axes and set the title\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title('Points with Max Y Point Highlighted')\n\n    return ax, max_y_point\ndata = [(1, 2), (2, 3), (3, 4), (4, 5), (5, 6)]", "raw_solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Generate x and y values from the data\n    x, y = zip(*data)\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(x, y)\n\n    # Mark the point with the maximum y-value\n    max_y_point = max(data, key=itemgetter(1))\n    ax.scatter(*max_y_point, color='r')\n\n    # Label the axes and set the title\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title('Points with Max Y Point Highlighted')\n\n    return ax, max_y_point\n\n# Test the function\ndata = [(1, 2), (2, 3), (3, 4), (4, 5), (5, 6)]\nax, max_y_point = task_func(data)\nplt.show()"}
{"task_id": "BigCodeBench/213", "solution": "import time\nimport random\nimport matplotlib.pyplot as plt\nfrom scipy.stats import kurtosis\ndef task_func(intervals=100, seed=0):\n    random.seed(seed)\n    numbers = []\n    for i in range(intervals):\n        numbers.append(random.random())\n        time.sleep(1)\n\n    elapsed_time = [i for i in range(1, intervals+1)]\n\n    fig, ax = plt.subplots()\n    ax.plot(elapsed_time, numbers)\n\n    ax.set(xlabel='Elapsed Time (intervals)', ylabel='Random Number',\n           title='Random Number Generation Over Time')\n    ax.grid()\n\n    kurt = kurtosis(numbers)\n\n    return ax, kurt", "raw_solution": "import time\nimport random\nimport matplotlib.pyplot as plt\nfrom scipy.stats import kurtosis\n\ndef task_func(intervals=100, seed=0):\n    random.seed(seed)\n    numbers = []\n    for i in range(intervals):\n        numbers.append(random.random())\n        time.sleep(1)\n\n    elapsed_time = [i for i in range(1, intervals+1)]\n\n    fig, ax = plt.subplots()\n    ax.plot(elapsed_time, numbers)\n\n    ax.set(xlabel='Elapsed Time (intervals)', ylabel='Random Number',\n           title='Random Number Generation Over Time')\n    ax.grid()\n\n    kurt = kurtosis(numbers)\n\n    return ax, kurt"}
{"task_id": "BigCodeBench/214", "solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low >= range_high:\n        raise ValueError(\"range_low should be less than range_high\")\n\n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, image_size)\n\n    fig, ax = plt.subplots(1, 1)\n    ax.imshow(image)\n    plt.show()\n\n    return ax, image", "raw_solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low >= range_high:\n        raise ValueError(\"range_low should be less than range_high\")\n\n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, image_size)\n\n    fig, ax = plt.subplots(1, 1)\n    ax.imshow(image)\n    plt.show()\n\n    return ax, image"}
{"task_id": "BigCodeBench/215", "solution": "import requests\nimport json\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nHEADERS = {\n    'accept': 'application/json'\n}\ndef task_func(url, parameters):\n    try:\n        # Make a GET request to the API\n        response = requests.get(url, headers=HEADERS, params=parameters)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        raise Exception(\"HTTP Error:\", errh)\n    except requests.exceptions.ConnectionError as errc:\n        raise Exception(\"Error Connecting:\", errc)\n    except requests.exceptions.Timeout as errt:\n        raise Exception(\"Timeout Error:\", errt)\n    except requests.exceptions.RequestException as err:\n        raise Exception(\"Something went wrong\", err)\n\n    # Check if the response is empty\n    if not response.text:\n        raise Exception(\"Empty data\")\n\n    # Convert the response to JSON\n    data = response.json()\n\n    # Check if the data is valid\n    if not data:\n        raise Exception(\"Invalid data\")\n\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Compute the correlation matrix\n    corr = df.corr()\n\n    # Create a heatmap\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", linewidths=.5, cmap='coolwarm', ax=ax)\n    plt.show()\n\n    return (df, ax)", "raw_solution": "import requests\nimport json\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Constants\nHEADERS = {\n    'accept': 'application/json'\n}\n\ndef task_func(url, parameters):\n    try:\n        # Make a GET request to the API\n        response = requests.get(url, headers=HEADERS, params=parameters)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        raise Exception(\"HTTP Error:\", errh)\n    except requests.exceptions.ConnectionError as errc:\n        raise Exception(\"Error Connecting:\", errc)\n    except requests.exceptions.Timeout as errt:\n        raise Exception(\"Timeout Error:\", errt)\n    except requests.exceptions.RequestException as err:\n        raise Exception(\"Something went wrong\", err)\n\n    # Check if the response is empty\n    if not response.text:\n        raise Exception(\"Empty data\")\n\n    # Convert the response to JSON\n    data = response.json()\n\n    # Check if the data is valid\n    if not data:\n        raise Exception(\"Invalid data\")\n\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Compute the correlation matrix\n    corr = df.corr()\n\n    # Create a heatmap\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", linewidths=.5, cmap='coolwarm', ax=ax)\n    plt.show()\n\n    return (df, ax)"}
{"task_id": "BigCodeBench/216", "solution": "import pandas as pd\nimport os\nimport json\nfrom collections import Counter\nimport re\ndef task_func(json_dir_path, word_count):\n    # Initialize an empty list to store the text content\n    text_content = []\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(json_dir_path):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the file and load its content\n            with open(os.path.join(json_dir_path, filename), 'r') as f:\n                data = json.load(f)\n            # Extract the text content from the JSON file and append it to the list\n            text_content.append(data.get('text', ''))\n\n    # Join all the text content into a single string\n    text_content = ' '.join(text_content)\n\n    # Remove punctuation and convert the text to lowercase\n    text_content = re.sub(r'[^\\w\\s]', '', text_content).lower()\n\n    # Split the text into words\n    words = text_content.split()\n\n    # Use the Counter class to count the occurrences of each word\n    word_counter = Counter(words)\n\n    # Return the most common words and their counts\n    return word_counter.most_common(word_count)", "raw_solution": "import pandas as pd\nimport os\nimport json\nfrom collections import Counter\nimport re\n\ndef task_func(json_dir_path, word_count):\n    # Initialize an empty list to store the text content\n    text_content = []\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(json_dir_path):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the file and load its content\n            with open(os.path.join(json_dir_path, filename), 'r') as f:\n                data = json.load(f)\n            # Extract the text content from the JSON file and append it to the list\n            text_content.append(data.get('text', ''))\n\n    # Join all the text content into a single string\n    text_content = ' '.join(text_content)\n\n    # Remove punctuation and convert the text to lowercase\n    text_content = re.sub(r'[^\\w\\s]', '', text_content).lower()\n\n    # Split the text into words\n    words = text_content.split()\n\n    # Use the Counter class to count the occurrences of each word\n    word_counter = Counter(words)\n\n    # Return the most common words and their counts\n    return word_counter.most_common(word_count)"}
{"task_id": "BigCodeBench/217", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(mu=0, sigma=1, sample_size=1000, seed=0):\n    np.random.seed(seed)\n    sample = np.random.normal(mu, sigma, sample_size)\n\n    fig, ax = plt.subplots()\n\n    # Plot histogram\n    ax.hist(sample, bins=30, density=True, alpha=0.6, color='g', label='Histogram')\n\n    # Plot PDF\n    x_axis = np.linspace(min(sample), max(sample), 100)\n    ax.plot(x_axis, stats.norm.pdf(x_axis, mu, sigma), color='k', label='PDF')\n\n    ax.set_title(f'Normal Distribution with $\\\\mu = {mu:.2f}, \\\\sigma = {sigma:.2f}$')\n    ax.legend()\n\n    empirical_mean = np.mean(sample)\n    empirical_std_dev = np.std(sample)\n\n    return ax, empirical_mean, empirical_std_dev", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(mu=0, sigma=1, sample_size=1000, seed=0):\n    np.random.seed(seed)\n    sample = np.random.normal(mu, sigma, sample_size)\n\n    fig, ax = plt.subplots()\n\n    # Plot histogram\n    ax.hist(sample, bins=30, density=True, alpha=0.6, color='g', label='Histogram')\n\n    # Plot PDF\n    x_axis = np.linspace(min(sample), max(sample), 100)\n    ax.plot(x_axis, stats.norm.pdf(x_axis, mu, sigma), color='k', label='PDF')\n\n    ax.set_title(f'Normal Distribution with $\\\\mu = {mu:.2f}, \\\\sigma = {sigma:.2f}$')\n    ax.legend()\n\n    empirical_mean = np.mean(sample)\n    empirical_std_dev = np.std(sample)\n\n    return ax, empirical_mean, empirical_std_dev\n\n# Test the function\nax, empirical_mean, empirical_std_dev = task_func(mu=0, sigma=1, sample_size=1000, seed=0)"}
{"task_id": "BigCodeBench/218", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\nTARGET = 'target'\ndef task_func(df, dict_mapping, plot_histogram=False):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame.\")\n\n    # Check if FEATURES and TARGET columns exist in df\n    if not all(item in df.columns for item in [*FEATURES, TARGET]):\n        raise ValueError(\"FEATURES or TARGET columns not in the input DataFrame.\")\n\n    # Replace values according to dict_mapping\n    df.replace(dict_mapping, inplace=True)\n\n    # Standardize specified features\n    scaler = StandardScaler()\n    df[FEATURES] = scaler.fit_transform(df[FEATURES])\n\n    histogram = None\n    if plot_histogram:\n        # Draw histogram of the target variable\n        histogram = df[TARGET].hist(bins=30)\n        plt.title('Histogram of the target variable')\n        plt.xlabel(TARGET)\n        plt.ylabel('Frequency')\n\n    return df, histogram", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Constants\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\nTARGET = 'target'\n\ndef task_func(df, dict_mapping, plot_histogram=False):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame.\")\n\n    # Check if FEATURES and TARGET columns exist in df\n    if not all(item in df.columns for item in [*FEATURES, TARGET]):\n        raise ValueError(\"FEATURES or TARGET columns not in the input DataFrame.\")\n\n    # Replace values according to dict_mapping\n    df.replace(dict_mapping, inplace=True)\n\n    # Standardize specified features\n    scaler = StandardScaler()\n    df[FEATURES] = scaler.fit_transform(df[FEATURES])\n\n    histogram = None\n    if plot_histogram:\n        # Draw histogram of the target variable\n        histogram = df[TARGET].hist(bins=30)\n        plt.title('Histogram of the target variable')\n        plt.xlabel(TARGET)\n        plt.ylabel('Frequency')\n\n    return df, histogram"}
{"task_id": "BigCodeBench/219", "solution": "import math\nimport statistics\nimport numpy as np\nfrom scipy import fft\ndef task_func(input_list):\n    # Sort the input list in ascending order based on the degree value of its elements\n    sorted_list = sorted(input_list, key=lambda x: math.degrees(x))\n\n    # Calculate the mean, median, and mode of the sorted list\n    mean_sorted = round(statistics.mean(sorted_list), 2)\n    median_sorted = round(statistics.median(sorted_list), 2)\n    mode_sorted = round(statistics.mode(sorted_list), 2)\n\n    # Calculate the magnitude of the fast fourier transform of the degree values upto the nearest integer\n    fft_list = [math.floor(abs(x)) for x in fft.fft(sorted_list)]\n    mean_fft = round(statistics.mean(fft_list), 2)\n    median_fft = round(statistics.median(fft_list), 2)\n    mode_fft = round(statistics.mode(fft_list), 2)\n\n    return (mean_sorted, median_sorted, mode_sorted, mean_fft, median_fft, mode_fft)", "raw_solution": "import math\nimport statistics\nimport numpy as np\nfrom scipy import fft\n\ndef task_func(input_list):\n    # Sort the input list in ascending order based on the degree value of its elements\n    sorted_list = sorted(input_list, key=lambda x: math.degrees(x))\n\n    # Calculate the mean, median, and mode of the sorted list\n    mean_sorted = round(statistics.mean(sorted_list), 2)\n    median_sorted = round(statistics.median(sorted_list), 2)\n    mode_sorted = round(statistics.mode(sorted_list), 2)\n\n    # Calculate the magnitude of the fast fourier transform of the degree values upto the nearest integer\n    fft_list = [math.floor(abs(x)) for x in fft.fft(sorted_list)]\n    mean_fft = round(statistics.mean(fft_list), 2)\n    median_fft = round(statistics.median(fft_list), 2)\n    mode_fft = round(statistics.mode(fft_list), 2)\n\n    return (mean_sorted, median_sorted, mode_sorted, mean_fft, median_fft, mode_fft)\n\n# Test the function"}
{"task_id": "BigCodeBench/220", "solution": "from random import choice\nimport turtle\nimport time\ndef task_func(colors):\n    # Set up the Turtle Graphics window\n    window = turtle.Screen()\n    window.title(\"Random Squares\")\n\n    # Create a Turtle object\n    t = turtle.Turtle()\n\n    # Draw five squares of random colors\n    for _ in range(5):\n        # Choose a random color from the provided list\n        color = choice(colors)\n\n        # Set the color for the Turtle\n        t.color(color)\n\n        # Draw a square\n        for _ in range(4):\n            t.forward(100)\n            t.right(90)\n\n        # Pause for 1 second\n        time.sleep(1)\n\n        # Clear the drawing for the next square\n        t.clear()\n\n    # Close the Turtle Graphics window\n    window.mainloop()\ncolors = [\"red\", \"green\", \"blue\", \"yellow\", \"purple\"]", "raw_solution": "from random import choice\nimport turtle\nimport time\n\ndef task_func(colors):\n    # Set up the Turtle Graphics window\n    window = turtle.Screen()\n    window.title(\"Random Squares\")\n\n    # Create a Turtle object\n    t = turtle.Turtle()\n\n    # Draw five squares of random colors\n    for _ in range(5):\n        # Choose a random color from the provided list\n        color = choice(colors)\n\n        # Set the color for the Turtle\n        t.color(color)\n\n        # Draw a square\n        for _ in range(4):\n            t.forward(100)\n            t.right(90)\n\n        # Pause for 1 second\n        time.sleep(1)\n\n        # Clear the drawing for the next square\n        t.clear()\n\n    # Close the Turtle Graphics window\n    window.mainloop()\n\n# Test the function\ncolors = [\"red\", \"green\", \"blue\", \"yellow\", \"purple\"]\ntask_func(colors)"}
{"task_id": "BigCodeBench/221", "solution": "import numpy as np\nfrom scipy import stats\nimport pandas as pd\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\ndef task_func(df, dct):\n    # Check if the DataFrame contains the required features\n    for feature in FEATURES:\n        if feature not in df.columns:\n            return \"Invalid input\"\n\n    # Replace values in the DataFrame based on the provided dictionary\n    df.replace(dct, inplace=True)\n\n    # Calculate and return the mean, median, mode, and variance for each feature\n    try:\n        stats_dict = {}\n        for feature in FEATURES:\n            feature_stats = df[feature].describe()\n            stats_dict[feature] = {\n                'mean': feature_stats['mean'],\n                'median': feature_stats['50%'],\n                'mode': stats.mode(df[feature])[0][0],\n                'variance': feature_stats['std']**2\n            }\n        return stats_dict\n    except Exception as e:\n        return \"Invalid input\"\ndf = pd.DataFrame({\n    'feature1': [1, 2, 3, 4, 5],\n    'feature2': [2, 2, 3, 4, 5],\n    'feature3': [3, 3, 3, 4, 5],\n    'feature4': [4, 4, 4, 4, 5],\n    'feature5': [5, 5, 5, 5, 5]\n})\ndct = {1: 10, 2: 20, 3: 30, 4: 40, 5: 50}", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport pandas as pd\n\n# Constants\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\n\ndef task_func(df, dct):\n    # Check if the DataFrame contains the required features\n    for feature in FEATURES:\n        if feature not in df.columns:\n            return \"Invalid input\"\n\n    # Replace values in the DataFrame based on the provided dictionary\n    df.replace(dct, inplace=True)\n\n    # Calculate and return the mean, median, mode, and variance for each feature\n    try:\n        stats_dict = {}\n        for feature in FEATURES:\n            feature_stats = df[feature].describe()\n            stats_dict[feature] = {\n                'mean': feature_stats['mean'],\n                'median': feature_stats['50%'],\n                'mode': stats.mode(df[feature])[0][0],\n                'variance': feature_stats['std']**2\n            }\n        return stats_dict\n    except Exception as e:\n        return \"Invalid input\"\n\n# Test the function\ndf = pd.DataFrame({\n    'feature1': [1, 2, 3, 4, 5],\n    'feature2': [2, 2, 3, 4, 5],\n    'feature3': [3, 3, 3, 4, 5],\n    'feature4': [4, 4, 4, 4, 5],\n    'feature5': [5, 5, 5, 5, 5]\n})\n\ndct = {1: 10, 2: 20, 3: 30, 4: 40, 5: 50}\n"}
{"task_id": "BigCodeBench/222", "solution": "import math\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(list_input):\n    # Sort the list based on the degree value of its elements\n    sorted_list = sorted(list_input, key=lambda x: math.degrees(x))\n\n    # Calculate the cumulative sum of the sorted list\n    cumulative_sum = np.cumsum(sorted_list)\n\n    # Plot the cumulative sum\n    fig, ax = plt.subplots()\n    ax.plot(cumulative_sum)\n\n    return cumulative_sum, ax\nlist_input = [0.1, 0.2, 0.3, 0.4, 0.5]", "raw_solution": "import math\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(list_input):\n    # Sort the list based on the degree value of its elements\n    sorted_list = sorted(list_input, key=lambda x: math.degrees(x))\n\n    # Calculate the cumulative sum of the sorted list\n    cumulative_sum = np.cumsum(sorted_list)\n\n    # Plot the cumulative sum\n    fig, ax = plt.subplots()\n    ax.plot(cumulative_sum)\n\n    return cumulative_sum, ax\n\n# Test the function\nlist_input = [0.1, 0.2, 0.3, 0.4, 0.5]\ncumulative_sum, ax = task_func(list_input)"}
{"task_id": "BigCodeBench/223", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport numpy as np\ndef task_func(df, dct, columns=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    if columns is not None:\n        df = df[columns]\n\n    for col in df.columns:\n        if df[col].dtype == 'object':\n            le = LabelEncoder()\n            df[col] = le.fit_transform(df[col])\n        elif df[col].dtype in ['int64', 'float64']:\n            ss = StandardScaler()\n            df[col] = ss.fit_transform(df[col].values.reshape(-1,1))\n\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport numpy as np\n\ndef task_func(df, dct, columns=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    if columns is not None:\n        df = df[columns]\n\n    for col in df.columns:\n        if df[col].dtype == 'object':\n            le = LabelEncoder()\n            df[col] = le.fit_transform(df[col])\n        elif df[col].dtype in ['int64', 'float64']:\n            ss = StandardScaler()\n            df[col] = ss.fit_transform(df[col].values.reshape(-1,1))\n\n    return df"}
{"task_id": "BigCodeBench/224", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\ndef task_func(range_start=-10, range_end=10, step=0.1):\n    x_values = np.arange(range_start, range_end, step)\n    sin_values = np.sin(x_values)\n    cos_values = np.cos(x_values)\n    abs_diff_values = np.abs(sin_values - cos_values)\n\n    # Generator\n    def generator():\n        for x, sin_x, cos_x, abs_diff in zip(x_values, sin_values, cos_values, abs_diff_values):\n            yield (x, sin_x, cos_x, abs_diff)\n\n    # Plot\n    fig, ax = plt.subplots()\n    ax.plot(x_values, sin_values, label='sin(x)')\n    ax.plot(x_values, cos_values, label='cos(x)')\n    ax.plot(x_values, abs_diff_values, label='abs(sin(x) - cos(x))')\n    ax.legend()\n\n    # FFT\n    fft_values = fft(abs_diff_values)\n    fft_magnitude = np.abs(fft_values)\n    mean_fft_magnitude = np.mean(fft_magnitude)\n    median_fft_magnitude = np.median(fft_magnitude)\n\n    return generator(), ax, mean_fft_magnitude, median_fft_magnitude", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\n\ndef task_func(range_start=-10, range_end=10, step=0.1):\n    x_values = np.arange(range_start, range_end, step)\n    sin_values = np.sin(x_values)\n    cos_values = np.cos(x_values)\n    abs_diff_values = np.abs(sin_values - cos_values)\n\n    # Generator\n    def generator():\n        for x, sin_x, cos_x, abs_diff in zip(x_values, sin_values, cos_values, abs_diff_values):\n            yield (x, sin_x, cos_x, abs_diff)\n\n    # Plot\n    fig, ax = plt.subplots()\n    ax.plot(x_values, sin_values, label='sin(x)')\n    ax.plot(x_values, cos_values, label='cos(x)')\n    ax.plot(x_values, abs_diff_values, label='abs(sin(x) - cos(x))')\n    ax.legend()\n\n    # FFT\n    fft_values = fft(abs_diff_values)\n    fft_magnitude = np.abs(fft_values)\n    mean_fft_magnitude = np.mean(fft_magnitude)\n    median_fft_magnitude = np.median(fft_magnitude)\n\n    return generator(), ax, mean_fft_magnitude, median_fft_magnitude"}
{"task_id": "BigCodeBench/225", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, dct, columns=None, plot_histograms=False):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    df = df.copy()  # create a copy to avoid changing the original DataFrame\n\n    if columns is not None:\n        if not isinstance(columns, list):\n            raise ValueError(\"columns should be a list of column names\")\n        for col in columns:\n            if col not in df.columns:\n                raise ValueError(f\"Column {col} not found in DataFrame\")\n\n    for key, value in dct.items():\n        if columns is None:\n            df.loc[:, df.columns == key] = value\n        else:\n            for col in columns:\n                df[col] = df[col].replace(key, value)\n\n    if plot_histograms and columns is not None:\n        for col in columns:\n            df[col].hist()\n            plt.title(f\"Histogram of {col}\")\n            plt.show()\n\n    return df", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, dct, columns=None, plot_histograms=False):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    df = df.copy()  # create a copy to avoid changing the original DataFrame\n\n    if columns is not None:\n        if not isinstance(columns, list):\n            raise ValueError(\"columns should be a list of column names\")\n        for col in columns:\n            if col not in df.columns:\n                raise ValueError(f\"Column {col} not found in DataFrame\")\n\n    for key, value in dct.items():\n        if columns is None:\n            df.loc[:, df.columns == key] = value\n        else:\n            for col in columns:\n                df[col] = df[col].replace(key, value)\n\n    if plot_histograms and columns is not None:\n        for col in columns:\n            df[col].hist()\n            plt.title(f\"Histogram of {col}\")\n            plt.show()\n\n    return df"}
{"task_id": "BigCodeBench/226", "solution": "import numpy as np\nimport math\nimport matplotlib.pyplot as plt\ndef task_func(range_start=0, range_end=10, step=0.1):\n    def generator():\n        for x in np.arange(range_start, range_end, step):\n            yield (x, math.exp(x))\n    data = list(generator())\n    x_values = [x[0] for x in data]\n    y_values = [x[1] for x in data]\n\n    fig, ax = plt.subplots()\n    ax.plot(x_values, y_values)\n    ax.set_xlabel('x')\n    ax.set_ylabel('exp(x)')\n    ax.set_title('Exponential Function')\n\n    return generator(), ax", "raw_solution": "import numpy as np\nimport math\nimport matplotlib.pyplot as plt\n\ndef task_func(range_start=0, range_end=10, step=0.1):\n    def generator():\n        for x in np.arange(range_start, range_end, step):\n            yield (x, math.exp(x))\n    data = list(generator())\n    x_values = [x[0] for x in data]\n    y_values = [x[1] for x in data]\n\n    fig, ax = plt.subplots()\n    ax.plot(x_values, y_values)\n    ax.set_xlabel('x')\n    ax.set_ylabel('exp(x)')\n    ax.set_title('Exponential Function')\n\n    return generator(), ax\n\n# Test the function\ngen, ax = task_func(0, 10, 0.1)\nfor _ in range(10):\n    print(next(gen))\n\nplt.show()"}
{"task_id": "BigCodeBench/227", "solution": "import numpy as np\nimport os\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\ndef task_func(L, M, N, audio_file):\n    # Check if the audio file exists\n    if not os.path.isfile(audio_file):\n        raise FileNotFoundError(\"The specified audio file does not exist.\")\n\n    # Read the audio file\n    data, sample_rate = sf.read(audio_file)\n\n    # Calculate the sound pressure level (SPL)\n    SPL = 20 * np.log10(np.sqrt(np.mean(data**2)))\n\n    # Create the MxN matrix from the list L\n    matrix = np.array(L).reshape(M, N)\n\n    # Normalize the matrix based on the SPL\n    normalized_matrix = matrix / (10 ** (SPL / 20))\n\n    # Generate the spectrogram\n    spectrogram = np.abs(librosa.stft(normalized_matrix.flatten()))\n\n    # Create the figure for the spectrogram\n    fig, ax = plt.subplots()\n\n    # Display the spectrogram with a logarithmic scale for frequency and a linear scale for time\n    img = ax.imshow(librosa.amplitude_to_db(spectrogram, ref=np.max), origin='lower', aspect='auto', extent=[0, len(data)/sample_rate, 0, sample_rate/2])\n\n    return normalized_matrix, fig", "raw_solution": "import numpy as np\nimport os\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\n\ndef task_func(L, M, N, audio_file):\n    # Check if the audio file exists\n    if not os.path.isfile(audio_file):\n        raise FileNotFoundError(\"The specified audio file does not exist.\")\n\n    # Read the audio file\n    data, sample_rate = sf.read(audio_file)\n\n    # Calculate the sound pressure level (SPL)\n    SPL = 20 * np.log10(np.sqrt(np.mean(data**2)))\n\n    # Create the MxN matrix from the list L\n    matrix = np.array(L).reshape(M, N)\n\n    # Normalize the matrix based on the SPL\n    normalized_matrix = matrix / (10 ** (SPL / 20))\n\n    # Generate the spectrogram\n    spectrogram = np.abs(librosa.stft(normalized_matrix.flatten()))\n\n    # Create the figure for the spectrogram\n    fig, ax = plt.subplots()\n\n    # Display the spectrogram with a logarithmic scale for frequency and a linear scale for time\n    img = ax.imshow(librosa.amplitude_to_db(spectrogram, ref=np.max), origin='lower', aspect='auto', extent=[0, len(data)/sample_rate, 0, sample_rate/2])\n\n    return normalized_matrix, fig"}
{"task_id": "BigCodeBench/228", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(df, dct):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    df = df.replace(dct)\n    corr_matrix = df.corr(method='pearson')\n\n    return corr_matrix", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(df, dct):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    df = df.replace(dct)\n    corr_matrix = df.corr(method='pearson')\n\n    return corr_matrix"}
{"task_id": "BigCodeBench/229", "solution": "import json\nimport random\nfrom datetime import datetime, timedelta\nUSERS = ['Alice', 'Bob', 'Charlie', 'Dave', 'Eve']\nACTIONS = ['login', 'logout', 'upload', 'download', 'delete']\ndef task_func(file_path, num_entries, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    data = []\n    for _ in range(num_entries):\n        user = random.choice(USERS)\n        action = random.choice(ACTIONS)\n        timestamp = (datetime.now() - timedelta(minutes=random.randint(1, 60*24*30))).isoformat()\n        data.append({'user': user, 'action': action, 'timestamp': timestamp})\n\n    with open(file_path, 'w') as f:\n        json.dump(data, f)\n\n    return file_path", "raw_solution": "import json\nimport random\nfrom datetime import datetime, timedelta\n\n# Constants\nUSERS = ['Alice', 'Bob', 'Charlie', 'Dave', 'Eve']\nACTIONS = ['login', 'logout', 'upload', 'download', 'delete']\n\ndef task_func(file_path, num_entries, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    data = []\n    for _ in range(num_entries):\n        user = random.choice(USERS)\n        action = random.choice(ACTIONS)\n        timestamp = (datetime.now() - timedelta(minutes=random.randint(1, 60*24*30))).isoformat()\n        data.append({'user': user, 'action': action, 'timestamp': timestamp})\n\n    with open(file_path, 'w') as f:\n        json.dump(data, f)\n\n    return file_path"}
{"task_id": "BigCodeBench/230", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nCOLUMNS = ['Name', 'Age', 'Country', 'Score']\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        return \"Invalid input\"\n    if not all(col in df.columns for col in COLUMNS):\n        return \"Invalid input\"\n\n    # Remove duplicates based on 'Name'\n    df = df.drop_duplicates(subset='Name')\n\n    # Histogram of Scores\n    plt.figure()\n    sns.histplot(df, x='Score', kde=True, color='blue', bins=30)\n    plt.title('Histogram of Scores')\n\n    # Boxplot of Scores by Country\n    plt.figure()\n    sns.boxplot(x='Country', y='Score', data=df, width=0.5)\n    plt.title('Boxplot of Scores by Country')\n\n    return plt.gcf()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nCOLUMNS = ['Name', 'Age', 'Country', 'Score']\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        return \"Invalid input\"\n    if not all(col in df.columns for col in COLUMNS):\n        return \"Invalid input\"\n\n    # Remove duplicates based on 'Name'\n    df = df.drop_duplicates(subset='Name')\n\n    # Histogram of Scores\n    plt.figure()\n    sns.histplot(df, x='Score', kde=True, color='blue', bins=30)\n    plt.title('Histogram of Scores')\n\n    # Boxplot of Scores by Country\n    plt.figure()\n    sns.boxplot(x='Country', y='Score', data=df, width=0.5)\n    plt.title('Boxplot of Scores by Country')\n\n    return plt.gcf()"}
{"task_id": "BigCodeBench/231", "solution": "import numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport random\nfrom matplotlib.axes import Axes\ndef task_func(obj_list) -> Axes:\n    values = [obj.value for obj in obj_list]\n    mean = np.mean(values) if values else 0\n    std_dev = np.std(values) if values else 0\n\n    # Generate x values for the normal distribution line\n    x = np.linspace(mean - 3.5*std_dev, mean + 3.5*std_dev, 100)\n    # Generate y values for the normal distribution line\n    y = stats.norm.pdf(x, mean, std_dev)\n\n    # Create a new figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot histogram\n    ax.hist(values, bins=20, density=True, alpha=0.75, color='g', label='Histogram')\n    # Plot normal distribution curve\n    ax.plot(x, y, 'r-', label='Normal Distribution')\n\n    ax.legend(loc='best', frameon=False)\n    plt.title('Histogram and Normal Distribution Curve')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n\n    return ax", "raw_solution": "import numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport random\nfrom matplotlib.axes import Axes\n\nclass ValueObject:\n    value = 0\n    def __init__(self, mu=0, std=1, seed=77):\n        random.seed(seed)\n        self.value = random.gauss(mu, std)\n\ndef task_func(obj_list) -> Axes:\n    values = [obj.value for obj in obj_list]\n    mean = np.mean(values) if values else 0\n    std_dev = np.std(values) if values else 0\n\n    # Generate x values for the normal distribution line\n    x = np.linspace(mean - 3.5*std_dev, mean + 3.5*std_dev, 100)\n    # Generate y values for the normal distribution line\n    y = stats.norm.pdf(x, mean, std_dev)\n\n    # Create a new figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot histogram\n    ax.hist(values, bins=20, density=True, alpha=0.75, color='g', label='Histogram')\n    # Plot normal distribution curve\n    ax.plot(x, y, 'r-', label='Normal Distribution')\n\n    ax.legend(loc='best', frameon=False)\n    plt.title('Histogram and Normal Distribution Curve')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n\n    return ax"}
{"task_id": "BigCodeBench/232", "solution": "import pandas as pd\nfrom collections import Counter\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    # Ensure the DataFrame has the correct columns\n    if not all(col in df.columns for col in ['Customer Name', 'Sales', 'Category']):\n        raise ValueError(\"DataFrame does not have the correct columns\")\n\n    # Remove duplicates based on 'Customer Name'\n    df = df.drop_duplicates(subset=['Customer Name'])\n\n    # Calculate total sales\n    total_sales = df['Sales'].sum()\n\n    # Find the most popular category\n    category_counts = Counter(df['Category'])\n    most_popular_category = category_counts.most_common(1)[0][0]\n\n    return {'Total Sales': total_sales, 'Most Popular Category': most_popular_category}", "raw_solution": "import pandas as pd\nfrom collections import Counter\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    # Ensure the DataFrame has the correct columns\n    if not all(col in df.columns for col in ['Customer Name', 'Sales', 'Category']):\n        raise ValueError(\"DataFrame does not have the correct columns\")\n\n    # Remove duplicates based on 'Customer Name'\n    df = df.drop_duplicates(subset=['Customer Name'])\n\n    # Calculate total sales\n    total_sales = df['Sales'].sum()\n\n    # Find the most popular category\n    category_counts = Counter(df['Category'])\n    most_popular_category = category_counts.most_common(1)[0][0]\n\n    return {'Total Sales': total_sales, 'Most Popular Category': most_popular_category}"}
{"task_id": "BigCodeBench/233", "solution": "import random\nimport matplotlib.pyplot as plt\ndef task_func(obj_list, attr, num_bins=30, seed=0):\n    # Set the seed for reproducibility\n    random.seed(seed)\n\n    # Extract the attribute values from the objects\n    attr_values = [getattr(obj, attr) for obj in obj_list]\n\n    # Create the histogram\n    plt.hist(attr_values, bins=num_bins)\n\n    # Set the title and labels\n    plt.title('Histogram of attribute values')\n    plt.xlabel('Attribute Value')\n    plt.ylabel('Count')\n\n    return plt.gca()", "raw_solution": "import random\nimport matplotlib.pyplot as plt\n\n# Sample data\nclass Object:\n    value = 0\n    def __init__(self, value=None):\n        if value is None:\n            self.value = random.gauss(0, 1)\n        else:\n            self.value = value\n\ndef task_func(obj_list, attr, num_bins=30, seed=0):\n    # Set the seed for reproducibility\n    random.seed(seed)\n\n    # Extract the attribute values from the objects\n    attr_values = [getattr(obj, attr) for obj in obj_list]\n\n    # Create the histogram\n    plt.hist(attr_values, bins=num_bins)\n\n    # Set the title and labels\n    plt.title('Histogram of attribute values')\n    plt.xlabel('Attribute Value')\n    plt.ylabel('Count')\n\n    return plt.gca()\n\n# Test the function"}
{"task_id": "BigCodeBench/234", "solution": "import pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    df = df.drop_duplicates(subset='name')\n    slope, intercept, r_value, p_value, std_err = stats.linregress(df['age'],df['score'])\n\n    fig, ax = plt.subplots()\n    ax.scatter(df['age'], df['score'])\n    ax.plot(df['age'], slope*df['age'] + intercept, color='red')\n    ax.set_xlabel('Age')\n    ax.set_ylabel('Score')\n    ax.set_title('Linear Regression')\n\n    return (plt, ax)", "raw_solution": "import pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    df = df.drop_duplicates(subset='name')\n    slope, intercept, r_value, p_value, std_err = stats.linregress(df['age'],df['score'])\n\n    fig, ax = plt.subplots()\n    ax.scatter(df['age'], df['score'])\n    ax.plot(df['age'], slope*df['age'] + intercept, color='red')\n    ax.set_xlabel('Age')\n    ax.set_ylabel('Score')\n    ax.set_title('Linear Regression')\n\n    return (plt, ax)"}
{"task_id": "BigCodeBench/235", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nfrom statsmodels.formula.api import ols\ndef task_func(mu, sigma, seed=0, num_samples=1000, num_bins=30):\n    np.random.seed(seed)\n    # Generate samples from a normal distribution\n    samples = np.random.normal(mu, sigma, num_samples)\n\n    # Create bins for the histogram\n    bins = np.linspace(samples.min(), samples.max(), num_bins)\n\n    # Create the histogram\n    plt.hist(samples, bins=bins, density=True, alpha=0.5, label='Histogram')\n\n    # Calculate the PDF values\n    pdf_x = np.linspace(samples.min(), samples.max(), 100)\n    pdf_y = norm.pdf(pdf_x, mu, sigma)\n\n    # Plot the PDF\n    plt.plot(pdf_x, pdf_y, color='red', label='PDF')\n\n    # Perform OLS regression\n    df = pd.DataFrame({'x': samples, 'y': norm.pdf(samples, mu, sigma)})\n    model = ols('y ~ x', df).fit()\n    ols_y = model.predict(df)\n\n    # Plot the OLS line\n    plt.plot(samples, ols_y, color='green', label='OLS')\n\n    plt.legend()\n    plt.show()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nfrom statsmodels.formula.api import ols\n\ndef task_func(mu, sigma, seed=0, num_samples=1000, num_bins=30):\n    np.random.seed(seed)\n    # Generate samples from a normal distribution\n    samples = np.random.normal(mu, sigma, num_samples)\n\n    # Create bins for the histogram\n    bins = np.linspace(samples.min(), samples.max(), num_bins)\n\n    # Create the histogram\n    plt.hist(samples, bins=bins, density=True, alpha=0.5, label='Histogram')\n\n    # Calculate the PDF values\n    pdf_x = np.linspace(samples.min(), samples.max(), 100)\n    pdf_y = norm.pdf(pdf_x, mu, sigma)\n\n    # Plot the PDF\n    plt.plot(pdf_x, pdf_y, color='red', label='PDF')\n\n    # Perform OLS regression\n    df = pd.DataFrame({'x': samples, 'y': norm.pdf(samples, mu, sigma)})\n    model = ols('y ~ x', df).fit()\n    ols_y = model.predict(df)\n\n    # Plot the OLS line\n    plt.plot(samples, ols_y, color='green', label='OLS')\n\n    plt.legend()\n    plt.show()\n\n# Test the function\ntask_func(0, 1)"}
{"task_id": "BigCodeBench/236", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\ndef task_func(df, test_size=0.2, random_state=42):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    # Drop rows with duplicate 'Name' entries\n    df = df.drop_duplicates(subset='Name')\n\n    # Split the data into features (X) and target (y)\n    X = df[['Age', 'Score']]\n    y = df['Category']\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    # Initialize the Random Forest Classifier\n    clf = RandomForestClassifier(random_state=random_state)\n\n    # Fit the model to the training data\n    clf.fit(X_train, y_train)\n\n    # Make predictions on the testing set\n    y_pred = clf.predict(X_test)\n\n    # Calculate the accuracy of the predictions\n    accuracy = accuracy_score(y_test, y_pred)\n\n    return accuracy", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\ndef task_func(df, test_size=0.2, random_state=42):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    # Drop rows with duplicate 'Name' entries\n    df = df.drop_duplicates(subset='Name')\n\n    # Split the data into features (X) and target (y)\n    X = df[['Age', 'Score']]\n    y = df['Category']\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    # Initialize the Random Forest Classifier\n    clf = RandomForestClassifier(random_state=random_state)\n\n    # Fit the model to the training data\n    clf.fit(X_train, y_train)\n\n    # Make predictions on the testing set\n    y_pred = clf.predict(X_test)\n\n    # Calculate the accuracy of the predictions\n    accuracy = accuracy_score(y_test, y_pred)\n\n    return accuracy"}
{"task_id": "BigCodeBench/237", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(data, save_plot=False, plot_path=None):\n    # Unzip the data\n    objects, coordinates_3d = zip(*data)\n    coordinates_3d = np.array(coordinates_3d)\n\n    # Apply PCA\n    pca = PCA(n_components=2)\n    coordinates_2d = pca.fit_transform(coordinates_3d)\n\n    if save_plot:\n        if plot_path is None:\n            raise ValueError(\"If save_plot is True, plot_path must be provided.\")\n        # Plot the data\n        fig, ax = plt.subplots()\n        ax.scatter(coordinates_2d[:, 0], coordinates_2d[:, 1])\n        ax.set_title('PCA of 3D data')\n        # Save the plot\n        plt.savefig(plot_path)\n        plt.close(fig)\n        return coordinates_2d, ax\n    else:\n        return coordinates_2d", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(data, save_plot=False, plot_path=None):\n    # Unzip the data\n    objects, coordinates_3d = zip(*data)\n    coordinates_3d = np.array(coordinates_3d)\n\n    # Apply PCA\n    pca = PCA(n_components=2)\n    coordinates_2d = pca.fit_transform(coordinates_3d)\n\n    if save_plot:\n        if plot_path is None:\n            raise ValueError(\"If save_plot is True, plot_path must be provided.\")\n        # Plot the data\n        fig, ax = plt.subplots()\n        ax.scatter(coordinates_2d[:, 0], coordinates_2d[:, 1])\n        ax.set_title('PCA of 3D data')\n        # Save the plot\n        plt.savefig(plot_path)\n        plt.close(fig)\n        return coordinates_2d, ax\n    else:\n        return coordinates_2d"}
{"task_id": "BigCodeBench/238", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    # Standardize 'Age' and 'Score' columns\n    scaler = StandardScaler()\n    df[['Age', 'Score']] = scaler.fit_transform(df[['Age', 'Score']])\n\n    # Remove duplicate entries based on 'Name'\n    df = df.drop_duplicates(subset='Name')\n\n    # Plot a scatter plot of standardized 'Age' and 'Score'\n    fig, ax = plt.subplots()\n    ax.scatter(df['Age'], df['Score'])\n    ax.set_title('Scatter Plot of Standardized Age and Score')\n    ax.set_xlabel('Age (standardized)')\n    ax.set_ylabel('Score (standardized)')\n\n    return df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    # Standardize 'Age' and 'Score' columns\n    scaler = StandardScaler()\n    df[['Age', 'Score']] = scaler.fit_transform(df[['Age', 'Score']])\n\n    # Remove duplicate entries based on 'Name'\n    df = df.drop_duplicates(subset='Name')\n\n    # Plot a scatter plot of standardized 'Age' and 'Score'\n    fig, ax = plt.subplots()\n    ax.scatter(df['Age'], df['Score'])\n    ax.set_title('Scatter Plot of Standardized Age and Score')\n    ax.set_xlabel('Age (standardized)')\n    ax.set_ylabel('Score (standardized)')\n\n    return df, ax"}
{"task_id": "BigCodeBench/239", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(original):\n    # Extract numeric values\n    numeric_values = [val for sublist in original for val in sublist if isinstance(val, (int, float))]\n    numeric_values = np.array(numeric_values)\n\n    # Compute basic statistics\n    stats_dict = {\n        'mean': np.mean(numeric_values),\n        'standard deviation': np.std(numeric_values),\n        'minimum': np.min(numeric_values),\n        'maximum': np.max(numeric_values)\n    }\n\n    # Generate histogram with overlaid PDF\n    fig, ax = plt.subplots()\n    ax.hist(numeric_values, density=True, alpha=0.6, bins='auto')\n\n    # Generate PDF\n    x_values = np.linspace(np.min(numeric_values), np.max(numeric_values), 1000)\n    y_values = stats.norm.pdf(x_values, np.mean(numeric_values), np.std(numeric_values))\n\n    ax.plot(x_values, y_values, label='PDF')\n    ax.legend()\n\n    return numeric_values, stats_dict, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(original):\n    # Extract numeric values\n    numeric_values = [val for sublist in original for val in sublist if isinstance(val, (int, float))]\n    numeric_values = np.array(numeric_values)\n\n    # Compute basic statistics\n    stats_dict = {\n        'mean': np.mean(numeric_values),\n        'standard deviation': np.std(numeric_values),\n        'minimum': np.min(numeric_values),\n        'maximum': np.max(numeric_values)\n    }\n\n    # Generate histogram with overlaid PDF\n    fig, ax = plt.subplots()\n    ax.hist(numeric_values, density=True, alpha=0.6, bins='auto')\n\n    # Generate PDF\n    x_values = np.linspace(np.min(numeric_values), np.max(numeric_values), 1000)\n    y_values = stats.norm.pdf(x_values, np.mean(numeric_values), np.std(numeric_values))\n\n    ax.plot(x_values, y_values, label='PDF')\n    ax.legend()\n\n    return numeric_values, stats_dict, ax"}
{"task_id": "BigCodeBench/240", "solution": "import pandas as pd\nfrom random import uniform\ndef task_func(n_data_points=1000, min_value=0.0, max_value=10.0, column_name='Value'):\n    data = [round(uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n    df = pd.DataFrame(data, columns=[column_name])\n    return df", "raw_solution": "import pandas as pd\nfrom random import uniform\n\ndef task_func(n_data_points=1000, min_value=0.0, max_value=10.0, column_name='Value'):\n    data = [round(uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n    df = pd.DataFrame(data, columns=[column_name])\n    return df\n\n# Test the function\ndf = task_func(n_data_points=5, min_value=-5.0, max_value=5.0, column_name='Random_Values')"}
{"task_id": "BigCodeBench/241", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\ndef task_func(original):\n    # Convert the original list to a numpy array\n    original_array = np.array(original)\n\n    # Normalize the array\n    normalized_array = preprocessing.normalize([original_array], norm='l2')[0]\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot the original and normalized arrays\n    ax.plot(original_array, label='Original Data')\n    ax.plot(normalized_array, label='Normalized Data')\n\n    # Set the title and labels\n    ax.set_title('Original vs. Normalized Data')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n\n    # Add a legend\n    ax.legend()\n\n    # Return the arrays and the axes\n    return original_array, normalized_array, ax\noriginal = [1, 2, 3, 4, 5]", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\n\ndef task_func(original):\n    # Convert the original list to a numpy array\n    original_array = np.array(original)\n\n    # Normalize the array\n    normalized_array = preprocessing.normalize([original_array], norm='l2')[0]\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot the original and normalized arrays\n    ax.plot(original_array, label='Original Data')\n    ax.plot(normalized_array, label='Normalized Data')\n\n    # Set the title and labels\n    ax.set_title('Original vs. Normalized Data')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n\n    # Add a legend\n    ax.legend()\n\n    # Return the arrays and the axes\n    return original_array, normalized_array, ax\n\n# Test the function\noriginal = [1, 2, 3, 4, 5]\noriginal_array, normalized_array, ax = task_func(original)"}
{"task_id": "BigCodeBench/242", "solution": "import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(image_path, kernel_size):\n    # Check if the image file exists\n    try:\n        image = cv2.imread(image_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(\"The specified image file does not exist.\")\n\n    # Check if kernel_size is a positive integer\n    if not isinstance(kernel_size, int) or kernel_size <= 0:\n        raise ValueError(\"Kernel size should be a positive integer.\")\n\n    # Apply blur effect\n    blur = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n\n    # Create a figure with two subplots\n    fig, axs = plt.subplots(1, 2)\n\n    # Display the original and blurred images\n    axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    axs[0].set_title('Original Image')\n    axs[1].imshow(cv2.cvtColor(blur, cv2.COLOR_BGR2RGB))\n    axs[1].set_title('Blurred Image')\n\n    # Return the blurred image and the figure\n    return blur, axs", "raw_solution": "import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(image_path, kernel_size):\n    # Check if the image file exists\n    try:\n        image = cv2.imread(image_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(\"The specified image file does not exist.\")\n\n    # Check if kernel_size is a positive integer\n    if not isinstance(kernel_size, int) or kernel_size <= 0:\n        raise ValueError(\"Kernel size should be a positive integer.\")\n\n    # Apply blur effect\n    blur = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n\n    # Create a figure with two subplots\n    fig, axs = plt.subplots(1, 2)\n\n    # Display the original and blurred images\n    axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    axs[0].set_title('Original Image')\n    axs[1].imshow(cv2.cvtColor(blur, cv2.COLOR_BGR2RGB))\n    axs[1].set_title('Blurred Image')\n\n    # Return the blurred image and the figure\n    return blur, axs"}
{"task_id": "BigCodeBench/243", "solution": "import pandas as pd\nimport random\nN_DATA_POINTS = 10000\nMIN_VALUE = 0.0\nMAX_VALUE = 10.0\ndef task_func(n_data_points=N_DATA_POINTS):\n    if n_data_points == 0:\n        return pd.DataFrame()\n    else:\n        data = [round(random.uniform(MIN_VALUE, MAX_VALUE), 3) for _ in range(n_data_points)]\n        df = pd.DataFrame(data, columns=['Value'])\n        return df", "raw_solution": "import pandas as pd\nimport random\n\n# Constants\nN_DATA_POINTS = 10000\nMIN_VALUE = 0.0\nMAX_VALUE = 10.0\n\ndef task_func(n_data_points=N_DATA_POINTS):\n    if n_data_points == 0:\n        return pd.DataFrame()\n    else:\n        data = [round(random.uniform(MIN_VALUE, MAX_VALUE), 3) for _ in range(n_data_points)]\n        df = pd.DataFrame(data, columns=['Value'])\n        return df\n\n# Test the function"}
{"task_id": "BigCodeBench/244", "solution": "import numpy as np\nfrom scipy.fft import fft\nfrom matplotlib import pyplot as plt\ndef task_func(original):\n    # Convert the original list to a numpy array\n    original_array = np.array(original)\n    \n    # Calculate the Fast Fourier Transform (FFT)\n    fft_data = fft(original_array)\n    \n    # If the original list is not empty, plot the histogram of the magnitude of the FFT data\n    if original:\n        # Calculate the magnitude of the FFT data\n        fft_magnitude = np.abs(fft_data)\n        \n        # Create a new figure\n        plt.figure()\n        \n        # Plot the histogram\n        axes = plt.hist(fft_magnitude, bins='auto')\n        \n        # Return the axes object of the plot\n        return original_array, fft_data, axes\n    else:\n        # If the original list is empty, return an empty array for the FFT data and None for the axes object\n        return original_array, np.array([]), None", "raw_solution": "import numpy as np\nfrom scipy.fft import fft\nfrom matplotlib import pyplot as plt\n\ndef task_func(original):\n    # Convert the original list to a numpy array\n    original_array = np.array(original)\n    \n    # Calculate the Fast Fourier Transform (FFT)\n    fft_data = fft(original_array)\n    \n    # If the original list is not empty, plot the histogram of the magnitude of the FFT data\n    if original:\n        # Calculate the magnitude of the FFT data\n        fft_magnitude = np.abs(fft_data)\n        \n        # Create a new figure\n        plt.figure()\n        \n        # Plot the histogram\n        axes = plt.hist(fft_magnitude, bins='auto')\n        \n        # Return the axes object of the plot\n        return original_array, fft_data, axes\n    else:\n        # If the original list is empty, return an empty array for the FFT data and None for the axes object\n        return original_array, np.array([]), None"}
{"task_id": "BigCodeBench/245", "solution": "import pandas as pd\nimport random\nfrom scipy import stats\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    # Generate a random dataset of floating-point numbers within a specified range\n    data = [round(random.uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n\n    # Calculate statistical measures (mean, median, mode) of the data\n    mean_val = round(stats.tmean(data), 3)\n    median_val = round(stats.tmedian(data), 3)\n    mode_val = round(stats.mode(data)[0][0], 3)\n\n    # Return the results in a dictionary\n    return {'mean': mean_val, 'median': median_val, 'mode': mode_val}", "raw_solution": "import pandas as pd\nimport random\nfrom scipy import stats\n\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    # Generate a random dataset of floating-point numbers within a specified range\n    data = [round(random.uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n\n    # Calculate statistical measures (mean, median, mode) of the data\n    mean_val = round(stats.tmean(data), 3)\n    median_val = round(stats.tmedian(data), 3)\n    mode_val = round(stats.mode(data)[0][0], 3)\n\n    # Return the results in a dictionary\n    return {'mean': mean_val, 'median': median_val, 'mode': mode_val}\n\n# Test the function"}
{"task_id": "BigCodeBench/246", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\nANGLES = np.arange(0, 2*np.pi, 0.01)\ndef task_func(n_waves, seed=0):\n    if n_waves < 1:\n        return [], [], None\n    \n    np.random.seed(seed)\n    freqs = np.random.uniform(0, 1, n_waves)\n    phases = np.random.uniform(0, 2*np.pi, n_waves)\n    \n    waves = [np.sin(freq*ANGLES + phase) for freq, phase in zip(freqs, phases)]\n    mixed_signal = np.sum(waves, axis=0)\n    \n    fft_data = fft(mixed_signal)\n    fft_magnitudes = np.abs(fft_data)\n    \n    fig, ax = plt.subplots()\n    ax.hist(fft_magnitudes, bins=30, color='blue', edgecolor='black')\n    ax.set_title('FFT Magnitude Histogram')\n    ax.set_xlabel('Frequency Bins')\n    ax.set_ylabel('Count')\n    \n    return waves, fft_data, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\n\nANGLES = np.arange(0, 2*np.pi, 0.01)\n\ndef task_func(n_waves, seed=0):\n    if n_waves < 1:\n        return [], [], None\n    \n    np.random.seed(seed)\n    freqs = np.random.uniform(0, 1, n_waves)\n    phases = np.random.uniform(0, 2*np.pi, n_waves)\n    \n    waves = [np.sin(freq*ANGLES + phase) for freq, phase in zip(freqs, phases)]\n    mixed_signal = np.sum(waves, axis=0)\n    \n    fft_data = fft(mixed_signal)\n    fft_magnitudes = np.abs(fft_data)\n    \n    fig, ax = plt.subplots()\n    ax.hist(fft_magnitudes, bins=30, color='blue', edgecolor='black')\n    ax.set_title('FFT Magnitude Histogram')\n    ax.set_xlabel('Frequency Bins')\n    ax.set_ylabel('Count')\n    \n    return waves, fft_data, ax"}
{"task_id": "BigCodeBench/247", "solution": "import pandas as pd\nimport random\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nN_DATA_POINTS = 5000\nMIN_VALUE = 0.0\nMAX_VALUE = 10.0\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    # Check if max_value is greater than min_value\n    if max_value < min_value:\n        raise ValueError(\"max_value should be greater than min_value\")\n\n    # Generate a random dataset of floating point numbers\n    data = [random.uniform(min_value, max_value) for _ in range(n_data_points)]\n\n    # Truncate each value to 3 decimal places\n    data = [round(num, 3) for num in data]\n\n    # Convert the list to a numpy array\n    data = np.array(data).reshape(-1, 1)\n\n    # Normalize the data using standard scaling\n    scaler = StandardScaler()\n    data = scaler.fit_transform(data)\n\n    # Create a pandas DataFrame\n    df = pd.DataFrame(data, columns=[\"Normalized Value\"])\n\n    return df", "raw_solution": "import pandas as pd\nimport random\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Constants\nN_DATA_POINTS = 5000\nMIN_VALUE = 0.0\nMAX_VALUE = 10.0\n\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    # Check if max_value is greater than min_value\n    if max_value < min_value:\n        raise ValueError(\"max_value should be greater than min_value\")\n\n    # Generate a random dataset of floating point numbers\n    data = [random.uniform(min_value, max_value) for _ in range(n_data_points)]\n\n    # Truncate each value to 3 decimal places\n    data = [round(num, 3) for num in data]\n\n    # Convert the list to a numpy array\n    data = np.array(data).reshape(-1, 1)\n\n    # Normalize the data using standard scaling\n    scaler = StandardScaler()\n    data = scaler.fit_transform(data)\n\n    # Create a pandas DataFrame\n    df = pd.DataFrame(data, columns=[\"Normalized Value\"])\n\n    return df\n\n# Test the function\ndf = task_func(N_DATA_POINTS, MIN_VALUE, MAX_VALUE)"}
{"task_id": "BigCodeBench/248", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"The data_list is empty\")\n\n    unzipped_data = list(itertools.zip_longest(*data_list, fillvalue=None))\n    x = np.arange(len(unzipped_data))\n\n    fig, ax = plt.subplots()\n    for i, data in enumerate(unzipped_data):\n        ax.plot(x, data, label=f'Position {i+1}')\n\n    ax.legend()\n    plt.show()\ndata_list = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"The data_list is empty\")\n\n    unzipped_data = list(itertools.zip_longest(*data_list, fillvalue=None))\n    x = np.arange(len(unzipped_data))\n\n    fig, ax = plt.subplots()\n    for i, data in enumerate(unzipped_data):\n        ax.plot(x, data, label=f'Position {i+1}')\n\n    ax.legend()\n    plt.show()\n\n# Test the function\ndata_list = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]\ntask_func(data_list)"}
{"task_id": "BigCodeBench/249", "solution": "import pandas as pd\nimport random\nfrom sklearn.model_selection import train_test_split\ndef task_func(n_data_points=10000, min_value=0.0, max_value=10.0, test_size=0.2):\n    # Generate a random set of floating-point numbers within a specified range\n    data = [round(random.uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n\n    # Create a pandas DataFrame\n    df = pd.DataFrame(data, columns=[\"Value\"])\n\n    # Split the data into train and test sets\n    train, test = train_test_split(df, test_size=test_size, random_state=42)\n\n    return (train, test)", "raw_solution": "import pandas as pd\nimport random\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(n_data_points=10000, min_value=0.0, max_value=10.0, test_size=0.2):\n    # Generate a random set of floating-point numbers within a specified range\n    data = [round(random.uniform(min_value, max_value), 3) for _ in range(n_data_points)]\n\n    # Create a pandas DataFrame\n    df = pd.DataFrame(data, columns=[\"Value\"])\n\n    # Split the data into train and test sets\n    train, test = train_test_split(df, test_size=test_size, random_state=42)\n\n    return (train, test)\n\n# Test the function\ntrain_set, test_set = task_func()"}
{"task_id": "BigCodeBench/250", "solution": "import numpy as np\nimport itertools\nimport json\ndef task_func(data_list, json_file_name=\"mean_values.json\"):\n    # Create an empty dictionary to store the mean values\n    mean_values = {}\n\n    # Iterate over the positions in the data list\n    for i in range(len(data_list[0])):\n        # Extract the numeric values at position i\n        values = [row[i] for row in data_list]\n        \n        # Calculate the mean of the numeric values\n        mean_value = np.mean(values)\n        \n        # Store the mean value in the dictionary\n        mean_values[f'Position {i}'] = mean_value\n\n    # Optionally, export the results to a JSON file\n    with open(json_file_name, 'w') as f:\n        json.dump(mean_values, f)\n\n    return mean_values", "raw_solution": "import numpy as np\nimport itertools\nimport json\n\ndef task_func(data_list, json_file_name=\"mean_values.json\"):\n    # Create an empty dictionary to store the mean values\n    mean_values = {}\n\n    # Iterate over the positions in the data list\n    for i in range(len(data_list[0])):\n        # Extract the numeric values at position i\n        values = [row[i] for row in data_list]\n        \n        # Calculate the mean of the numeric values\n        mean_value = np.mean(values)\n        \n        # Store the mean value in the dictionary\n        mean_values[f'Position {i}'] = mean_value\n\n    # Optionally, export the results to a JSON file\n    with open(json_file_name, 'w') as f:\n        json.dump(mean_values, f)\n\n    return mean_values"}
{"task_id": "BigCodeBench/251", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data should be a pandas DataFrame\")\n\n    # Assuming the data has a column named 'Job'\n    if 'Job' not in data.columns:\n        raise ValueError(\"Input data should have a column named 'Job'\")\n\n    job_distribution = data['Job'].value_counts()\n\n    fig, ax = plt.subplots()\n    ax.pie(job_distribution, labels=job_distribution.index, autopct='%1.1f%%')\n    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n    return fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data should be a pandas DataFrame\")\n\n    # Assuming the data has a column named 'Job'\n    if 'Job' not in data.columns:\n        raise ValueError(\"Input data should have a column named 'Job'\")\n\n    job_distribution = data['Job'].value_counts()\n\n    fig, ax = plt.subplots()\n    ax.pie(job_distribution, labels=job_distribution.index, autopct='%1.1f%%')\n    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n    return fig"}
{"task_id": "BigCodeBench/252", "solution": "import matplotlib.pyplot as plt\nfrom itertools import cycle\nCOLORS = ['red', 'green', 'blue', 'yellow', 'purple']\ndef task_func(data, labels):\n    # Create a color cycle\n    color_cycle = cycle(COLORS)\n\n    # Create a figure and an axes\n    fig, ax = plt.subplots()\n\n    # Plot the data with different colors\n    for i, (data_series, label) in enumerate(zip(data, labels)):\n        color = next(color_cycle)\n        ax.plot(data_series, label=label, color=color)\n\n    # If there are more data series than colors, use black\n    if len(data) > len(COLORS):\n        for _ in range(len(data) - len(COLORS)):\n            ax.plot([], [], color='black', label='Extra Data')\n\n    # Add legend\n    ax.legend()\n\n    return ax\ndata = [[1, 2, 3, 4, 5], [2, 3, 4, 5, 6], [3, 4, 5, 6, 7]]\nlabels = ['Data 1', 'Data 2', 'Data 3']", "raw_solution": "import matplotlib.pyplot as plt\nfrom itertools import cycle\n\n# Constants\nCOLORS = ['red', 'green', 'blue', 'yellow', 'purple']\n\ndef task_func(data, labels):\n    # Create a color cycle\n    color_cycle = cycle(COLORS)\n\n    # Create a figure and an axes\n    fig, ax = plt.subplots()\n\n    # Plot the data with different colors\n    for i, (data_series, label) in enumerate(zip(data, labels)):\n        color = next(color_cycle)\n        ax.plot(data_series, label=label, color=color)\n\n    # If there are more data series than colors, use black\n    if len(data) > len(COLORS):\n        for _ in range(len(data) - len(COLORS)):\n            ax.plot([], [], color='black', label='Extra Data')\n\n    # Add legend\n    ax.legend()\n\n    return ax\n\n# Test the function\ndata = [[1, 2, 3, 4, 5], [2, 3, 4, 5, 6], [3, 4, 5, 6, 7]]\nlabels = ['Data 1', 'Data 2', 'Data 3']\nax = task_func(data, labels)\nplt.show()"}
{"task_id": "BigCodeBench/253", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nCOLORS = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\ndef task_func(ax):\n    # Generate random parameters\n    freq = random.uniform(0.1, 10)\n    amp = random.uniform(0.1, 10)\n    phase = random.uniform(0, np.pi)\n    color = random.choice(COLORS)\n\n    # Generate x and y data\n    theta = np.linspace(0, 2*np.pi, 1000)\n    r = amp * np.sin(freq*theta + phase)\n\n    # Plot the data\n    ax.plot(theta, r, color=color)\n\n    # Randomly place radial labels\n    for i in range(10):\n        angle = random.uniform(0, 2*np.pi)\n        radius = random.uniform(0, amp)\n        ax.text(angle, radius, str(radius), ha='center', va='center')\n\n    # Return the color code\n    return color", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\n# Constants\nCOLORS = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n\ndef task_func(ax):\n    # Generate random parameters\n    freq = random.uniform(0.1, 10)\n    amp = random.uniform(0.1, 10)\n    phase = random.uniform(0, np.pi)\n    color = random.choice(COLORS)\n\n    # Generate x and y data\n    theta = np.linspace(0, 2*np.pi, 1000)\n    r = amp * np.sin(freq*theta + phase)\n\n    # Plot the data\n    ax.plot(theta, r, color=color)\n\n    # Randomly place radial labels\n    for i in range(10):\n        angle = random.uniform(0, 2*np.pi)\n        radius = random.uniform(0, amp)\n        ax.text(angle, radius, str(radius), ha='center', va='center')\n\n    # Return the color code\n    return color\n\n# Create a new figure and subplot\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n\n# Call the function\ncolor = task_func(ax)\n\n# Show the plot\nplt.show()\n\n# Print the color code"}
{"task_id": "BigCodeBench/254", "solution": "import json\nimport math\ndef task_func(decimal_value, precision=2):\n    # Calculate the square root of the decimal value\n    sqrt_value = round(math.sqrt(decimal_value), precision)\n\n    # Encode the result as a JSON string\n    json_string = json.dumps({\"square_root\": sqrt_value})\n\n    return json_string", "raw_solution": "import json\nimport math\n\ndef task_func(decimal_value, precision=2):\n    # Calculate the square root of the decimal value\n    sqrt_value = round(math.sqrt(decimal_value), precision)\n\n    # Encode the result as a JSON string\n    json_string = json.dumps({\"square_root\": sqrt_value})\n\n    return json_string\n\n# Test the function"}
{"task_id": "BigCodeBench/255", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nFUNCTIONS = [np.sin, np.cos, np.tan]\ndef task_func(ax, func_index):\n    if not isinstance(ax, plt.Axes):\n        raise ValueError(\"Input ax is not a matplotlib.axes._axes.Axes instance\")\n    if not isinstance(func_index, int) or func_index not in [0, 1, 2]:\n        raise ValueError(\"Invalid function index. Choose from 0 (sin), 1 (cos), or 2 (tan)\")\n\n    theta = np.linspace(0, np.pi, 1000)\n    r = np.sin(theta)\n\n    ax.plot(theta, r, label=f'{FUNCTIONS[func_index].__name__}')\n    ax.set_theta_zero_location('N')\n    ax.set_theta_direction(-1)\n    ax.set_rticks([0.5, 1, 1.5, 2])\n    ax.grid(True)\n    ax.legend()\n\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\n# Constants\nFUNCTIONS = [np.sin, np.cos, np.tan]\n\ndef task_func(ax, func_index):\n    if not isinstance(ax, plt.Axes):\n        raise ValueError(\"Input ax is not a matplotlib.axes._axes.Axes instance\")\n    if not isinstance(func_index, int) or func_index not in [0, 1, 2]:\n        raise ValueError(\"Invalid function index. Choose from 0 (sin), 1 (cos), or 2 (tan)\")\n\n    theta = np.linspace(0, np.pi, 1000)\n    r = np.sin(theta)\n\n    ax.plot(theta, r, label=f'{FUNCTIONS[func_index].__name__}')\n    ax.set_theta_zero_location('N')\n    ax.set_theta_direction(-1)\n    ax.set_rticks([0.5, 1, 1.5, 2])\n    ax.grid(True)\n    ax.legend()\n\n    return ax\n\n# Testing\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\ntask_func(ax, 0)\nplt.show()"}
{"task_id": "BigCodeBench/256", "solution": "import json\nimport random\nimport hashlib\nimport string\nfrom datetime import datetime\ndef task_func(utc_datetime, salt='salt', password_length=10, seed=0):\n    # Check if utc_datetime is a datetime object\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime should be a datetime object\")\n\n    # Check if salt is a string\n    if not isinstance(salt, str):\n        raise ValueError(\"salt should be a string\")\n\n    # Set the seed for the random number generator\n    random.seed(seed)\n\n    # Generate a random lowercase alphanumeric password\n    password = ''.join(random.choices(string.ascii_lowercase + string.digits, k=password_length))\n\n    # Combine the user provided salt and the complete conventional string representation of the user provided UTC datetime\n    hash_input = salt + utc_datetime.strftime('%Y-%m-%d %H:%M:%S.%f')\n\n    # Hash the password using SHA-256\n    hashed_password = hashlib.sha256(hash_input.encode()).hexdigest()\n\n    # Encrypt the hashed password as a JSON string\n    json_string = json.dumps({'hashed_password': hashed_password})\n\n    return json_string", "raw_solution": "import json\nimport random\nimport hashlib\nimport string\nfrom datetime import datetime\n\ndef task_func(utc_datetime, salt='salt', password_length=10, seed=0):\n    # Check if utc_datetime is a datetime object\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime should be a datetime object\")\n\n    # Check if salt is a string\n    if not isinstance(salt, str):\n        raise ValueError(\"salt should be a string\")\n\n    # Set the seed for the random number generator\n    random.seed(seed)\n\n    # Generate a random lowercase alphanumeric password\n    password = ''.join(random.choices(string.ascii_lowercase + string.digits, k=password_length))\n\n    # Combine the user provided salt and the complete conventional string representation of the user provided UTC datetime\n    hash_input = salt + utc_datetime.strftime('%Y-%m-%d %H:%M:%S.%f')\n\n    # Hash the password using SHA-256\n    hashed_password = hashlib.sha256(hash_input.encode()).hexdigest()\n\n    # Encrypt the hashed password as a JSON string\n    json_string = json.dumps({'hashed_password': hashed_password})\n\n    return json_string"}
{"task_id": "BigCodeBench/257", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(ax, num_turns):\n    theta = np.linspace(0, 2*np.pi*num_turns, 1000)\n    r = theta\n    x = r * np.cos(theta)\n    y = r * np.sin(theta)\n    ax.plot(x, y)\n    ax.set_aspect('equal')\n    ax.xaxis.set_ticks([])\n    ax.yaxis.set_ticks([])\n    ax.spines['left'].set_color('none')\n    ax.spines['right'].set_color('none')\n    ax.spines['top'].set_color('none')\n    ax.spines['bottom'].set_color('none')\n    ax.set_xticks([-1, 1])\n    ax.set_yticks([-1, 1])\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(ax, num_turns):\n    theta = np.linspace(0, 2*np.pi*num_turns, 1000)\n    r = theta\n    x = r * np.cos(theta)\n    y = r * np.sin(theta)\n    ax.plot(x, y)\n    ax.set_aspect('equal')\n    ax.xaxis.set_ticks([])\n    ax.yaxis.set_ticks([])\n    ax.spines['left'].set_color('none')\n    ax.spines['right'].set_color('none')\n    ax.spines['top'].set_color('none')\n    ax.spines['bottom'].set_color('none')\n    ax.set_xticks([-1, 1])\n    ax.set_yticks([-1, 1])\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    return ax\n\nfig, ax = plt.subplots(1, 1)\nax = task_func(ax, 1)\nplt.show()"}
{"task_id": "BigCodeBench/258", "solution": "import json\nimport random\nfrom datetime import datetime\nDATA = [\n    {'name': 'John', 'age': 30, 'city': 'New York'},\n    {'name': 'Peter', 'age': 35, 'city': 'London'},\n    {'name': 'Susan', 'age': 25, 'city': 'Sydney'},\n    {'name': 'Alice', 'age': 28, 'city': 'Paris'},\n    {'name': 'Bob', 'age': 40, 'city': 'Tokyo'},\n    {'name': 'Charlie', 'age': 22, 'city': 'Beijing'},\n    {'name': 'David', 'age': 33, 'city': 'Mumbai'},\n    {'name': 'Eve', 'age': 27, 'city': 'Berlin'},\n    {'name': 'Frank', 'age': 32, 'city': 'Moscow'},\n    {'name': 'Grace', 'age': 29, 'city': 'Rome'}\n]\ndef task_func(utc_datetime, seed=0):\n    random.seed(seed)\n    person = random.choice(DATA)\n    person['timestamp'] = utc_datetime.strftime('%Y-%m-%dT%H:%M:%SZ')\n    return json.dumps(person)\nutc_datetime = datetime.utcnow()", "raw_solution": "import json\nimport random\nfrom datetime import datetime\n\n# Constants\nDATA = [\n    {'name': 'John', 'age': 30, 'city': 'New York'},\n    {'name': 'Peter', 'age': 35, 'city': 'London'},\n    {'name': 'Susan', 'age': 25, 'city': 'Sydney'},\n    {'name': 'Alice', 'age': 28, 'city': 'Paris'},\n    {'name': 'Bob', 'age': 40, 'city': 'Tokyo'},\n    {'name': 'Charlie', 'age': 22, 'city': 'Beijing'},\n    {'name': 'David', 'age': 33, 'city': 'Mumbai'},\n    {'name': 'Eve', 'age': 27, 'city': 'Berlin'},\n    {'name': 'Frank', 'age': 32, 'city': 'Moscow'},\n    {'name': 'Grace', 'age': 29, 'city': 'Rome'}\n]\n\ndef task_func(utc_datetime, seed=0):\n    random.seed(seed)\n    person = random.choice(DATA)\n    person['timestamp'] = utc_datetime.strftime('%Y-%m-%dT%H:%M:%SZ')\n    return json.dumps(person)\n\n# Testing\nutc_datetime = datetime.utcnow()"}
{"task_id": "BigCodeBench/259", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(ax, num_points):\n    if not isinstance(ax, plt.Axes):\n        raise ValueError(\"Input ax is not a matplotlib Axes object.\")\n    if not isinstance(num_points, int) or num_points < 0:\n        raise ValueError(\"num_points should be a non-negative integer.\")\n\n    theta = np.random.rand(num_points) * 2 * np.pi\n    radii = np.random.rand(num_points)\n\n    ax.plot(theta, radii, 'o')\n\n    # Set radial ticks\n    rad_ticks = np.arange(0, 1.1, 0.1)\n    ax.set_rticks(rad_ticks)\n    ax.set_rlabel_position(rad_ticks * 180 / np.pi - 90)\n\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(ax, num_points):\n    if not isinstance(ax, plt.Axes):\n        raise ValueError(\"Input ax is not a matplotlib Axes object.\")\n    if not isinstance(num_points, int) or num_points < 0:\n        raise ValueError(\"num_points should be a non-negative integer.\")\n\n    theta = np.random.rand(num_points) * 2 * np.pi\n    radii = np.random.rand(num_points)\n\n    ax.plot(theta, radii, 'o')\n\n    # Set radial ticks\n    rad_ticks = np.arange(0, 1.1, 0.1)\n    ax.set_rticks(rad_ticks)\n    ax.set_rlabel_position(rad_ticks * 180 / np.pi - 90)\n\n    return ax\n\n# Test the function\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\nax = task_func(ax, 100)\nplt.show()"}
{"task_id": "BigCodeBench/260", "solution": "import json\nimport os\nimport glob\nKEY = 'mynewkey'\nVALUE = 'mynewvalue'\ndef task_func(directory):\n    # Initialize counter\n    count = 0\n\n    # Get all JSON files in the directory\n    json_files = glob.glob(os.path.join(directory, '*.json'))\n\n    # Iterate over each JSON file\n    for file in json_files:\n        with open(file, 'r+') as f:\n            data = json.load(f)\n\n            # If the key doesn't exist, add it\n            if KEY not in data:\n                data[KEY] = VALUE\n                f.seek(0)\n                json.dump(data, f, indent=4)\n                f.truncate()\n                count += 1\n\n    return count", "raw_solution": "import json\nimport os\nimport glob\n\n# Constants\nKEY = 'mynewkey'\nVALUE = 'mynewvalue'\n\ndef task_func(directory):\n    # Initialize counter\n    count = 0\n\n    # Get all JSON files in the directory\n    json_files = glob.glob(os.path.join(directory, '*.json'))\n\n    # Iterate over each JSON file\n    for file in json_files:\n        with open(file, 'r+') as f:\n            data = json.load(f)\n\n            # If the key doesn't exist, add it\n            if KEY not in data:\n                data[KEY] = VALUE\n                f.seek(0)\n                json.dump(data, f, indent=4)\n                f.truncate()\n                count += 1\n\n    return count"}
{"task_id": "BigCodeBench/261", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(ax, radius):\n    if not isinstance(ax, plt.Axes):\n        raise TypeError(\"'ax' must be a matplotlib.axes._axes.Axes instance\")\n    if radius < 0:\n        raise ValueError(\"Radius cannot be negative\")\n\n    # Generate data for the circle\n    theta = np.linspace(0, 2*np.pi, 1000)\n    x = radius * np.cos(theta)\n    y = radius * np.sin(theta)\n\n    # Plot the circle\n    ax.plot(x, y)\n\n    # Set radial ticks\n    ax.set_rticks([0.5, 1, 1.5, 2])\n    ax.set_rlabel_position(225)  # Move radial labels away from plotted line\n\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(ax, radius):\n    if not isinstance(ax, plt.Axes):\n        raise TypeError(\"'ax' must be a matplotlib.axes._axes.Axes instance\")\n    if radius < 0:\n        raise ValueError(\"Radius cannot be negative\")\n\n    # Generate data for the circle\n    theta = np.linspace(0, 2*np.pi, 1000)\n    x = radius * np.cos(theta)\n    y = radius * np.sin(theta)\n\n    # Plot the circle\n    ax.plot(x, y)\n\n    # Set radial ticks\n    ax.set_rticks([0.5, 1, 1.5, 2])\n    ax.set_rlabel_position(225)  # Move radial labels away from plotted line\n\n    return ax\n\n# Test the function\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\ntask_func(ax, 1)\nplt.show()"}
{"task_id": "BigCodeBench/262", "solution": "import collections\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(dictionary, new_key, new_value):\n    # Add new key-value pair to the dictionary\n    dictionary[new_key] = new_value\n\n    # Create a counter from the dictionary values\n    counter = collections.Counter(dictionary.values())\n\n    # Plot the distribution of the values\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Values')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution of Values')\n\n    return dictionary, ax\ndictionary = {'a': 1, 'b': 2, 'c': 2, 'd': 3, 'e': 3, 'f': 3}\nnew_key = 'g'\nnew_value = 4", "raw_solution": "import collections\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(dictionary, new_key, new_value):\n    # Add new key-value pair to the dictionary\n    dictionary[new_key] = new_value\n\n    # Create a counter from the dictionary values\n    counter = collections.Counter(dictionary.values())\n\n    # Plot the distribution of the values\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Values')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution of Values')\n\n    return dictionary, ax\n\n# Test the function\ndictionary = {'a': 1, 'b': 2, 'c': 2, 'd': 3, 'e': 3, 'f': 3}\nnew_key = 'g'\nnew_value = 4\nupdated_dict, ax = task_func(dictionary, new_key, new_value)\nplt.show()"}
{"task_id": "BigCodeBench/263", "solution": "import os\nimport glob\nimport shutil\nimport time\nFILE_EXTENSIONS = ['.txt', '.csv', '.xlsx', '.docx', '.pdf']\ndef task_func(my_path: str, days_old: int) -> str:\n    # Check if the directory exists\n    if not os.path.isdir(my_path):\n        raise ValueError(f\"The directory {my_path} does not exist.\")\n\n    # Create the archive directory if it does not exist\n    archive_path = os.path.join(my_path, 'archive')\n    if not os.path.isdir(archive_path):\n        os.mkdir(archive_path)\n\n    # Get the current time\n    now = time.time()\n\n    # Iterate over all files in the directory\n    for file_path in glob.glob(os.path.join(my_path, '*')):\n        # Check if the file is a regular file and has one of the specified extensions\n        if os.path.isfile(file_path) and os.path.splitext(file_path)[1] in FILE_EXTENSIONS:\n            # Check if the file is older than 'days_old' days\n            if os.stat(file_path).st_mtime < now - days_old * 86400:\n                # Move the file to the archive directory\n                shutil.move(file_path, os.path.join(archive_path, os.path.basename(file_path)))\n\n    return archive_path", "raw_solution": "import os\nimport glob\nimport shutil\nimport time\n\n# Constants\nFILE_EXTENSIONS = ['.txt', '.csv', '.xlsx', '.docx', '.pdf']\n\ndef task_func(my_path: str, days_old: int) -> str:\n    # Check if the directory exists\n    if not os.path.isdir(my_path):\n        raise ValueError(f\"The directory {my_path} does not exist.\")\n\n    # Create the archive directory if it does not exist\n    archive_path = os.path.join(my_path, 'archive')\n    if not os.path.isdir(archive_path):\n        os.mkdir(archive_path)\n\n    # Get the current time\n    now = time.time()\n\n    # Iterate over all files in the directory\n    for file_path in glob.glob(os.path.join(my_path, '*')):\n        # Check if the file is a regular file and has one of the specified extensions\n        if os.path.isfile(file_path) and os.path.splitext(file_path)[1] in FILE_EXTENSIONS:\n            # Check if the file is older than 'days_old' days\n            if os.stat(file_path).st_mtime < now - days_old * 86400:\n                # Move the file to the archive directory\n                shutil.move(file_path, os.path.join(archive_path, os.path.basename(file_path)))\n\n    return archive_path"}
{"task_id": "BigCodeBench/264", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(dictionary, key, value, n=100, bins=30, seed=0):\n    if not isinstance(value, (int, float)):\n        raise ValueError(\"The provided value is not a number.\")\n\n    dictionary[key] = value\n\n    np.random.seed(seed)\n    data = pd.Series(np.random.normal(value, 1, n))\n\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=bins)\n    ax.set_title('Histogram of Generated Dataset')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return dictionary, data, fig", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(dictionary, key, value, n=100, bins=30, seed=0):\n    if not isinstance(value, (int, float)):\n        raise ValueError(\"The provided value is not a number.\")\n\n    dictionary[key] = value\n\n    np.random.seed(seed)\n    data = pd.Series(np.random.normal(value, 1, n))\n\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=bins)\n    ax.set_title('Histogram of Generated Dataset')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n    return dictionary, data, fig"}
{"task_id": "BigCodeBench/265", "solution": "import collections\nimport json\nimport os\ndef task_func(data, json_file_name='data.json'):\n    # Add a new key \"a\" with the value 1 to the input dictionary\n    data['a'] = 1\n\n    # Calculate the frequency of its values\n    freq = collections.Counter(data.values())\n\n    # Save the updated dictionary along with its frequency distribution to a JSON file\n    with open(json_file_name, 'w') as f:\n        json.dump({'data': data, 'freq': dict(freq)}, f)\n\n    # Return the path of the JSON file\n    return os.path.abspath(json_file_name)\ndata = {'b': 2, 'c': 3, 'd': 2}", "raw_solution": "import collections\nimport json\nimport os\n\ndef task_func(data, json_file_name='data.json'):\n    # Add a new key \"a\" with the value 1 to the input dictionary\n    data['a'] = 1\n\n    # Calculate the frequency of its values\n    freq = collections.Counter(data.values())\n\n    # Save the updated dictionary along with its frequency distribution to a JSON file\n    with open(json_file_name, 'w') as f:\n        json.dump({'data': data, 'freq': dict(freq)}, f)\n\n    # Return the path of the JSON file\n    return os.path.abspath(json_file_name)\n\n# Test the function\ndata = {'b': 2, 'c': 3, 'd': 2}"}
{"task_id": "BigCodeBench/266", "solution": "import os\nimport csv\nimport collections\nFILE_NAME = 'file_sizes.csv'\ndef task_func(my_path):\n    # Check if the path exists\n    if not os.path.exists(my_path):\n        return \"The provided path does not exist.\"\n\n    # Create a dictionary to store file sizes\n    file_sizes = collections.defaultdict(int)\n\n    # Walk through the directory\n    for dirpath, dirs, files in os.walk(my_path):\n        for file in files:\n            # Get the full path of the file\n            file_path = os.path.join(dirpath, file)\n            # Get the size of the file\n            file_size = os.path.getsize(file_path)\n            # Add the size to the dictionary\n            file_sizes[file_path] = file_size\n\n    # Write the file sizes to a CSV file\n    with open(FILE_NAME, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow([\"File Path\", \"File Size\"])\n        for file_path, file_size in file_sizes.items():\n            writer.writerow([file_path, file_size])\n\n    return FILE_NAME", "raw_solution": "import os\nimport csv\nimport collections\n\n# Constants\nFILE_NAME = 'file_sizes.csv'\n\ndef task_func(my_path):\n    # Check if the path exists\n    if not os.path.exists(my_path):\n        return \"The provided path does not exist.\"\n\n    # Create a dictionary to store file sizes\n    file_sizes = collections.defaultdict(int)\n\n    # Walk through the directory\n    for dirpath, dirs, files in os.walk(my_path):\n        for file in files:\n            # Get the full path of the file\n            file_path = os.path.join(dirpath, file)\n            # Get the size of the file\n            file_size = os.path.getsize(file_path)\n            # Add the size to the dictionary\n            file_sizes[file_path] = file_size\n\n    # Write the file sizes to a CSV file\n    with open(FILE_NAME, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow([\"File Path\", \"File Size\"])\n        for file_path, file_size in file_sizes.items():\n            writer.writerow([file_path, file_size])\n\n    return FILE_NAME\n\n# Test the function"}
{"task_id": "BigCodeBench/267", "solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\ndef task_func(data, sample_rate=8000):\n    # Add a new key \"a\" with the value 1 to the dictionary\n    data['a'] = 1\n\n    # Generate a signal based on the values in \"data\"\n    signal = list(data.values())\n\n    # Run a Fast Fourier Transform (FFT) on the signal\n    fft_signal = fftpack.fft(signal)\n    freqs = fftpack.fftfreq(len(signal), d=1/sample_rate)\n\n    # Plot and return the FFT of the signal with a title of 'FFT of the signal'\n    plt.figure(figsize=(10, 5))\n    plt.plot(freqs, np.abs(fft_signal))\n    plt.title('FFT of the signal')\n    plt.xlabel('Frequency (Hz)')\n    plt.ylabel('Amplitude')\n    plt.grid(True)\n\n    return (fft_signal, plt.gca())", "raw_solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\n\ndef task_func(data, sample_rate=8000):\n    # Add a new key \"a\" with the value 1 to the dictionary\n    data['a'] = 1\n\n    # Generate a signal based on the values in \"data\"\n    signal = list(data.values())\n\n    # Run a Fast Fourier Transform (FFT) on the signal\n    fft_signal = fftpack.fft(signal)\n    freqs = fftpack.fftfreq(len(signal), d=1/sample_rate)\n\n    # Plot and return the FFT of the signal with a title of 'FFT of the signal'\n    plt.figure(figsize=(10, 5))\n    plt.plot(freqs, np.abs(fft_signal))\n    plt.title('FFT of the signal')\n    plt.xlabel('Frequency (Hz)')\n    plt.ylabel('Amplitude')\n    plt.grid(True)\n\n    return (fft_signal, plt.gca())"}
{"task_id": "BigCodeBench/268", "solution": "import random\nLETTERS = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\ndef task_func(n_keys, n_values):\n    # Randomly select keys from LETTERS\n    keys = random.sample(LETTERS, n_keys)\n    # Create a dictionary with keys and consecutive integers as values\n    dict_out = {key: list(range(1, n_values+1)) for key in keys}\n    return dict_out", "raw_solution": "import random\n\n# Constants\nLETTERS = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n\ndef task_func(n_keys, n_values):\n    # Randomly select keys from LETTERS\n    keys = random.sample(LETTERS, n_keys)\n    # Create a dictionary with keys and consecutive integers as values\n    dict_out = {key: list(range(1, n_values+1)) for key in keys}\n    return dict_out\n\n# Test the function"}
{"task_id": "BigCodeBench/269", "solution": "import numpy as np\nfrom scipy import stats\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(data_dict):\n    # Add key \"a\" with a value of 1\n    data_dict[\"a\"] = 1\n\n    # Conduct statistical analysis on its values\n    values = np.array(list(data_dict.values()))\n    mean = round(np.mean(values), 2)\n    median = round(np.median(values), 2)\n    mode = round(stats.mode(values)[0][0], 2)\n    stats_dict = {\"mean\": mean, \"median\": median, \"mode\": mode}\n\n    # Normalize the values using MinMaxScaler\n    scaler = MinMaxScaler()\n    normalized_values = scaler.fit_transform(values.reshape(-1, 1))\n\n    # Plot a histogram of the normalized values\n    plt.hist(normalized_values, bins='auto')\n    plt.title(\"Histogram of Normalized Values\")\n    plt.xlabel(\"Value\")\n    plt.ylabel(\"Frequency\")\n    hist_plot = plt.gca()\n\n    return data_dict, stats_dict, hist_plot", "raw_solution": "import numpy as np\nfrom scipy import stats\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict):\n    # Add key \"a\" with a value of 1\n    data_dict[\"a\"] = 1\n\n    # Conduct statistical analysis on its values\n    values = np.array(list(data_dict.values()))\n    mean = round(np.mean(values), 2)\n    median = round(np.median(values), 2)\n    mode = round(stats.mode(values)[0][0], 2)\n    stats_dict = {\"mean\": mean, \"median\": median, \"mode\": mode}\n\n    # Normalize the values using MinMaxScaler\n    scaler = MinMaxScaler()\n    normalized_values = scaler.fit_transform(values.reshape(-1, 1))\n\n    # Plot a histogram of the normalized values\n    plt.hist(normalized_values, bins='auto')\n    plt.title(\"Histogram of Normalized Values\")\n    plt.xlabel(\"Value\")\n    plt.ylabel(\"Frequency\")\n    hist_plot = plt.gca()\n\n    return data_dict, stats_dict, hist_plot"}
{"task_id": "BigCodeBench/270", "solution": "import re\nfrom collections import Counter\ndef task_func(sentence):\n    words = re.findall(r'\\b\\w+\\b', sentence)\n    return dict(Counter(words))", "raw_solution": "import re\nfrom collections import Counter\n\ndef task_func(sentence):\n    words = re.findall(r'\\b\\w+\\b', sentence)\n    return dict(Counter(words))\n\n# Test the function"}
{"task_id": "BigCodeBench/271", "solution": "import random\nimport string\nimport hashlib\nimport time\ndef task_func(data_dict: dict, seed=0) -> dict:\n    random.seed(seed)\n    salt = ''.join(random.choices(string.ascii_lowercase, k=5))\n    data_dict['a'] = 1\n    for key in data_dict.keys():\n        data_dict[key] = hashlib.sha256((data_dict[key] + salt).encode()).hexdigest()\n    data_dict['timestamp'] = int(time.time())\n    return data_dict", "raw_solution": "import random\nimport string\nimport hashlib\nimport time\n\ndef task_func(data_dict: dict, seed=0) -> dict:\n    random.seed(seed)\n    salt = ''.join(random.choices(string.ascii_lowercase, k=5))\n    data_dict['a'] = 1\n    for key in data_dict.keys():\n        data_dict[key] = hashlib.sha256((data_dict[key] + salt).encode()).hexdigest()\n    data_dict['timestamp'] = int(time.time())\n    return data_dict"}
{"task_id": "BigCodeBench/272", "solution": "import cgi\nimport http.server\nimport json", "raw_solution": "import cgi\nimport http.server\nimport json\n\nclass MyHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n\n        if self.headers['Content-Type'] != 'application/json':\n            self.send_response(400)\n            self.end_headers()\n            self.wfile.write(json.dumps({\"status\": \"error\", \"message\": \"Content-Type header is not application/json\"}).encode())\n            return\n\n        try:\n            data = json.loads(post_data)\n        except json.JSONDecodeError:\n            self.send_response(400)\n            self.end_headers()\n            self.wfile.write(json.dumps({\"status\": \"error\", \"message\": \"Invalid JSON\"}).encode())\n            return\n\n        if 'data' not in data:\n            self.send_response(400)\n            self.end_headers()\n            self.wfile.write(json.dumps({\"status\": \"error\", \"message\": \"No data received\"}).encode())\n            return\n\n        self.send_response(200)\n        self.end_headers()\n        self.wfile.write(json.dumps({\"status\": \"success\", \"message\": \"Data received successfully.\"}).encode())\n"}
{"task_id": "BigCodeBench/273", "solution": "import cgi\nimport http.server\nimport json", "raw_solution": "import cgi\nimport http.server\nimport json\n\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\n\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\n\nclass PostHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers.get('content-length', 0))\n        content_type = self.headers.get('content-type')\n\n        if content_type != 'application/json':\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'error': 'Content-Type header is not application/json'}).encode())\n            return\n\n        post_data = self.rfile.read(content_length)\n\n        try:\n            data = json.loads(post_data)\n        except json.JSONDecodeError:\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'error': 'Invalid JSON'}).encode())\n            return\n\n        if 'data' not in data:\n            self.send_response(400)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'error': 'No data key in request'}).encode())\n            return\n\n        self.send_response(200)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        self.wfile.write(json.dumps(SUCCESS_RESPONSE).encode())\n"}
{"task_id": "BigCodeBench/274", "solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json", "raw_solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\n\nclass EmailHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        try:\n            content_length = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n            email_data = json.loads(post_data)\n\n            if 'subject' not in email_data or 'message' not in email_data or 'to' not in email_data:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Missing subject, message, or to keys in the email data')\n                return\n\n            msg = MIMEText(email_data['message'])\n            msg['Subject'] = email_data['subject']\n            msg['From'] = smtp_username\n            msg['To'] = email_data['to']\n\n            smtp = smtplib.SMTP(smtp_server, smtp_port)\n            smtp.login(smtp_username, smtp_password)\n            smtp.send_message(msg)\n            smtp.quit()\n\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'Email sent successfully')\n\n        except json.JSONDecodeError:\n            self.send_response(400)\n            self.end_headers()\n            self.wfile.write(b'Invalid JSON')\n\n        except (smtplib.SMTPAuthenticationError, smtplib.SMTPException) as e:\n            self.send_response(535)\n            self.end_headers()\n            self.wfile.write(b'Authentication failed: ' + str(e).encode())\n\ndef run_server(smtp_server, smtp_port, smtp_username, smtp_password, server_class=http.server.HTTPServer, handler_class=EmailHandler):\n    server_address = ('', 8000)\n    httpd = server_class(server_address, handler_class)\n    httpd.smtp_server = smtp_server\n    httpd.smtp_port = smtp_port\n    httpd.smtp_username = smtp_username\n    httpd.smtp_password = smtp_password\n    print('Starting httpd...')\n    httpd.serve_forever()\n"}
{"task_id": "BigCodeBench/275", "solution": "import numpy as np\nfrom itertools import combinations\ndef task_func(n):\n    if n < 1:\n        raise ValueError(\"Input n should be greater than 0\")\n    numbers = list(range(1, n+1))\n    return list(combinations(numbers, 2))", "raw_solution": "import numpy as np\nfrom itertools import combinations\n\ndef task_func(n):\n    if n < 1:\n        raise ValueError(\"Input n should be greater than 0\")\n    numbers = list(range(1, n+1))\n    return list(combinations(numbers, 2))\n\n# Test the function\ntry:\n    print(task_func(5))\nexcept ValueError as e:\n    print(e)\n\ntry:\n    print(task_func(-1))\nexcept ValueError as e:\n    print(e)"}
{"task_id": "BigCodeBench/276", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(matrix):\n    # Calculate the maximum values of each row in the matrix\n    max_values = np.max(matrix, axis=1)\n\n    # Calculate the histogram and the estimate of the core density of the distribution\n    hist, bins = np.histogram(max_values, bins='auto', density=True)\n    bin_centers = (bins[1:]+bins[:-1])*0.5\n\n    # Fit a normal distribution to the histogram\n    mu, sigma = stats.norm.fit(max_values)\n    pdf = stats.norm.pdf(bin_centers, mu, sigma)\n\n    # Calculate skewness and kurtosis\n    skewness = stats.skew(max_values)\n    kurtosis = stats.kurtosis(max_values)\n\n    # Plot the histogram\n    fig, ax = plt.subplots()\n    ax.bar(bin_centers, hist, width=(bins[1]-bins[0]), align='center')\n    ax.plot(bin_centers, pdf, 'r--')\n    ax.set_xlabel('Max values')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of maximum values')\n\n    return skewness, kurtosis, ax", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(matrix):\n    # Calculate the maximum values of each row in the matrix\n    max_values = np.max(matrix, axis=1)\n\n    # Calculate the histogram and the estimate of the core density of the distribution\n    hist, bins = np.histogram(max_values, bins='auto', density=True)\n    bin_centers = (bins[1:]+bins[:-1])*0.5\n\n    # Fit a normal distribution to the histogram\n    mu, sigma = stats.norm.fit(max_values)\n    pdf = stats.norm.pdf(bin_centers, mu, sigma)\n\n    # Calculate skewness and kurtosis\n    skewness = stats.skew(max_values)\n    kurtosis = stats.kurtosis(max_values)\n\n    # Plot the histogram\n    fig, ax = plt.subplots()\n    ax.bar(bin_centers, hist, width=(bins[1]-bins[0]), align='center')\n    ax.plot(bin_centers, pdf, 'r--')\n    ax.set_xlabel('Max values')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of maximum values')\n\n    return skewness, kurtosis, ax"}
{"task_id": "BigCodeBench/277", "solution": "import random\nfrom itertools import combinations\nimport math\ndef task_func(n):\n    if n < 2:\n        return None\n    points = [(random.random(), random.random()) for _ in range(n)]\n    min_distance = float('inf')\n    closest_pair = None\n    for pair in combinations(points, 2):\n        distance = math.sqrt((pair[0][0] - pair[1][0])**2 + (pair[0][1] - pair[1][1])**2)\n        if distance < min_distance:\n            min_distance = distance\n            closest_pair = pair\n    return closest_pair", "raw_solution": "import random\nfrom itertools import combinations\nimport math\n\ndef task_func(n):\n    if n < 2:\n        return None\n    points = [(random.random(), random.random()) for _ in range(n)]\n    min_distance = float('inf')\n    closest_pair = None\n    for pair in combinations(points, 2):\n        distance = math.sqrt((pair[0][0] - pair[1][0])**2 + (pair[0][1] - pair[1][1])**2)\n        if distance < min_distance:\n            min_distance = distance\n            closest_pair = pair\n    return closest_pair\n\n# Test the function"}
{"task_id": "BigCodeBench/278", "solution": "import numpy as np\nfrom sympy import symbols, solve\ndef task_func(precision=2, seed=0):\n    np.random.seed(seed)\n    a, b, c = np.random.randint(-10, 11, 3)\n    x = symbols('x')\n    solutions = solve(a*x**2 + b*x + c, x)\n    solutions = [complex(round(s.evalf(precision), precision) if isinstance(s, complex) else s.evalf(precision)) for s in solutions]\n    return tuple(solutions)", "raw_solution": "import numpy as np\nfrom sympy import symbols, solve\n\ndef task_func(precision=2, seed=0):\n    np.random.seed(seed)\n    a, b, c = np.random.randint(-10, 11, 3)\n    x = symbols('x')\n    solutions = solve(a*x**2 + b*x + c, x)\n    solutions = [complex(round(s.evalf(precision), precision) if isinstance(s, complex) else s.evalf(precision)) for s in solutions]\n    return tuple(solutions)\n\n# Test the function"}
{"task_id": "BigCodeBench/279", "solution": "import random\nfrom collections import Counter\nCARDS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\ndef task_func(x=1):\n    # Initialize an empty list to store the hands\n    hands = []\n    # Initialize an empty Counter to count the drawn cards\n    card_counter = Counter()\n\n    for _ in range(x):\n        # Draw a random 5-card hand\n        hand = random.sample(CARDS, 5)\n        hands.append(hand)\n        # Update the counter with the drawn cards\n        card_counter.update(hand)\n\n    return (hands, card_counter)", "raw_solution": "import random\nfrom collections import Counter\n\n# Constants\nCARDS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\n\ndef task_func(x=1):\n    # Initialize an empty list to store the hands\n    hands = []\n    # Initialize an empty Counter to count the drawn cards\n    card_counter = Counter()\n\n    for _ in range(x):\n        # Draw a random 5-card hand\n        hand = random.sample(CARDS, 5)\n        hands.append(hand)\n        # Update the counter with the drawn cards\n        card_counter.update(hand)\n\n    return (hands, card_counter)\n\n# Test the function\nhands, card_counter = task_func(5)"}
{"task_id": "BigCodeBench/280", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\ndef task_func(signal, precision=2, seed=777):\n    np.random.seed(seed)\n    # Calculate the one-dimensional discrete N-point Fourier Transform (DFT)\n    transformed_signal = fft(signal)\n    # Round the transformed signal values to the specified accuracy\n    transformed_signal = np.round(np.real(transformed_signal), precision)\n\n    # Create a figure and a set of subplots\n    fig, axs = plt.subplots(2)\n\n    # Plot the original signal\n    axs[0].plot(signal)\n    axs[0].set_title('Original Signal')\n\n    # Plot the transformed signal\n    axs[1].plot(transformed_signal)\n    axs[1].set_title('Transformed Signal')\n\n    # Return the transformed signal and the Axes objects\n    return transformed_signal, axs", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\n\ndef task_func(signal, precision=2, seed=777):\n    np.random.seed(seed)\n    # Calculate the one-dimensional discrete N-point Fourier Transform (DFT)\n    transformed_signal = fft(signal)\n    # Round the transformed signal values to the specified accuracy\n    transformed_signal = np.round(np.real(transformed_signal), precision)\n\n    # Create a figure and a set of subplots\n    fig, axs = plt.subplots(2)\n\n    # Plot the original signal\n    axs[0].plot(signal)\n    axs[0].set_title('Original Signal')\n\n    # Plot the transformed signal\n    axs[1].plot(transformed_signal)\n    axs[1].set_title('Transformed Signal')\n\n    # Return the transformed signal and the Axes objects\n    return transformed_signal, axs"}
{"task_id": "BigCodeBench/281", "solution": "import re\nimport os\nfrom collections import Counter\ndef task_func(folder_path: str) -> dict:\n    ip_pattern = r\"\\b(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\b\"\n    ip_counter = Counter()\n\n    for filename in os.listdir(folder_path):\n        if filename.endswith(\".log\"):\n            with open(os.path.join(folder_path, filename), 'r') as f:\n                for line in f:\n                    ips = re.findall(ip_pattern, line)\n                    ip_counter.update(ips)\n\n    return ip_counter", "raw_solution": "import re\nimport os\nfrom collections import Counter\n\ndef task_func(folder_path: str) -> dict:\n    ip_pattern = r\"\\b(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\b\"\n    ip_counter = Counter()\n\n    for filename in os.listdir(folder_path):\n        if filename.endswith(\".log\"):\n            with open(os.path.join(folder_path, filename), 'r') as f:\n                for line in f:\n                    ips = re.findall(ip_pattern, line)\n                    ip_counter.update(ips)\n\n    return ip_counter"}
{"task_id": "BigCodeBench/282", "solution": "import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport cv2\nimport os\ndef task_func(file_path, onpick):\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(\"The image file does not exist.\")\n\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    # Calculate color histogram\n    hist = cv2.calcHist([img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n    hist = hist.flatten()\n\n    # Create 3D plot\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    xs = np.arange(8)\n    ys = np.arange(8)\n    zs = np.arange(8)\n    xs, ys, zs = np.meshgrid(xs, ys, zs)\n    ax.scatter(xs, ys, zs, c=hist.reshape((8, 8, 8, 3)), picker=True)\n\n    # Connect to onclick event\n    ax.on_pick = onpick\n\n    plt.show()\n\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport cv2\nimport os\n\ndef task_func(file_path, onpick):\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(\"The image file does not exist.\")\n\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    # Calculate color histogram\n    hist = cv2.calcHist([img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n    hist = hist.flatten()\n\n    # Create 3D plot\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    xs = np.arange(8)\n    ys = np.arange(8)\n    zs = np.arange(8)\n    xs, ys, zs = np.meshgrid(xs, ys, zs)\n    ax.scatter(xs, ys, zs, c=hist.reshape((8, 8, 8, 3)), picker=True)\n\n    # Connect to onclick event\n    ax.on_pick = onpick\n\n    plt.show()\n\n    return ax"}
{"task_id": "BigCodeBench/283", "solution": "import os\nimport json\nfrom collections import Counter\ndef task_func(json_files_path='./json_files/', key='name'):\n    key_counts = Counter()\n\n    for filename in os.listdir(json_files_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(json_files_path, filename), 'r') as f:\n                data = json.load(f)\n                if key in data:\n                    key_counts.update([data[key]])\n\n    return dict(key_counts)", "raw_solution": "import os\nimport json\nfrom collections import Counter\n\ndef task_func(json_files_path='./json_files/', key='name'):\n    key_counts = Counter()\n\n    for filename in os.listdir(json_files_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(json_files_path, filename), 'r') as f:\n                data = json.load(f)\n                if key in data:\n                    key_counts.update([data[key]])\n\n    return dict(key_counts)\n\n# Test the function"}
{"task_id": "BigCodeBench/284", "solution": "import mechanize\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\ndef task_func(url):\n    br = mechanize.Browser()\n    br.set_handle_robots(False)\n    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n\n    html = br.open(url).read()\n    soup = BeautifulSoup(html, 'html.parser')\n\n    base_url = url\n    hyperlinks = []\n\n    for link in soup.find_all('a'):\n        href = link.get('href')\n        if href:\n            absolute_url = urljoin(base_url, href)\n            hyperlinks.append(absolute_url)\n\n    return hyperlinks\nurl = \"https://www.example.com\"", "raw_solution": "import mechanize\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\n\ndef task_func(url):\n    br = mechanize.Browser()\n    br.set_handle_robots(False)\n    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n\n    html = br.open(url).read()\n    soup = BeautifulSoup(html, 'html.parser')\n\n    base_url = url\n    hyperlinks = []\n\n    for link in soup.find_all('a'):\n        href = link.get('href')\n        if href:\n            absolute_url = urljoin(base_url, href)\n            hyperlinks.append(absolute_url)\n\n    return hyperlinks\n\n# Test the function\nurl = \"https://www.example.com\"\nhyperlinks = task_func(url)\nfor link in hyperlinks:\n    print(link)"}
{"task_id": "BigCodeBench/285", "solution": "import mechanize\nfrom bs4 import BeautifulSoup\ndef task_func(url, form_id, data):\n    browser = mechanize.Browser()\n    browser.set_handle_robots(False)\n    browser.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n\n    try:\n        response = browser.open(url)\n        html = response.read()\n        soup = BeautifulSoup(html, 'html.parser')\n        form = soup.form(id=form_id)\n        browser.select_form(form)\n\n        for key, value in data.items():\n            browser.form[key] = value\n        response = browser.submit()\n        html = response.read()\n        soup = BeautifulSoup(html, 'html.parser')\n        title = soup.title.string if soup.title else 'No Title'\n        return title\n    except Exception as e:\n        return str(e)\nurl = \"http://example.com\"\nform_id = \"form1\"\ndata = {\"field1\": \"value1\", \"field2\": \"value2\"}", "raw_solution": "import mechanize\nfrom bs4 import BeautifulSoup\n\ndef task_func(url, form_id, data):\n    browser = mechanize.Browser()\n    browser.set_handle_robots(False)\n    browser.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n\n    try:\n        response = browser.open(url)\n        html = response.read()\n        soup = BeautifulSoup(html, 'html.parser')\n        form = soup.form(id=form_id)\n        browser.select_form(form)\n\n        for key, value in data.items():\n            browser.form[key] = value\n        response = browser.submit()\n        html = response.read()\n        soup = BeautifulSoup(html, 'html.parser')\n        title = soup.title.string if soup.title else 'No Title'\n        return title\n    except Exception as e:\n        return str(e)\n\n# Test the function\nurl = \"http://example.com\"\nform_id = \"form1\"\ndata = {\"field1\": \"value1\", \"field2\": \"value2\"}"}
{"task_id": "BigCodeBench/286", "solution": "from collections import Counter\nimport os\nimport csv\ndef task_func(output_file, test_directory):\n    try:\n        # Initialize a counter\n        word_counter = Counter()\n\n        # Get a list of all .txt files in the directory\n        txt_files = [f for f in os.listdir(test_directory) if f.endswith('.txt')]\n\n        # Iterate over each .txt file\n        for txt_file in txt_files:\n            with open(os.path.join(test_directory, txt_file), 'r') as f:\n                # Split the file's content into words and update the counter\n                word_counter.update(f.read().split())\n\n        # Write the counter to the output CSV file\n        with open(output_file, 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(['Word', 'Count'])\n            writer.writerows(word_counter.items())\n\n        # Return the total number of words\n        return sum(word_counter.values())\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return 0", "raw_solution": "from collections import Counter\nimport os\nimport csv\n\n# Constants\nFILE_DIR = './yourdictfiles/'\n\ndef task_func(output_file, test_directory):\n    try:\n        # Initialize a counter\n        word_counter = Counter()\n\n        # Get a list of all .txt files in the directory\n        txt_files = [f for f in os.listdir(test_directory) if f.endswith('.txt')]\n\n        # Iterate over each .txt file\n        for txt_file in txt_files:\n            with open(os.path.join(test_directory, txt_file), 'r') as f:\n                # Split the file's content into words and update the counter\n                word_counter.update(f.read().split())\n\n        # Write the counter to the output CSV file\n        with open(output_file, 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(['Word', 'Count'])\n            writer.writerows(word_counter.items())\n\n        # Return the total number of words\n        return sum(word_counter.values())\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return 0\n\n# Test the function\ntotal_words = task_func('output.csv', FILE_DIR)"}
{"task_id": "BigCodeBench/287", "solution": "from collections import Counter\nimport os\nimport json\ndef task_func(directory):\n    word_counts = Counter()\n    total_words = 0\n\n    for filename in os.listdir(directory):\n        if filename.endswith('.txt'):\n            with open(os.path.join(directory, filename), 'r') as file:\n                words = file.read().split()\n                word_counts[filename] = len(words)\n                total_words += len(words)\n\n    with open('word_counts.json', 'w') as json_file:\n        json.dump(word_counts, json_file)\n\n    return total_words", "raw_solution": "from collections import Counter\nimport os\nimport json\n\ndef task_func(directory):\n    word_counts = Counter()\n    total_words = 0\n\n    for filename in os.listdir(directory):\n        if filename.endswith('.txt'):\n            with open(os.path.join(directory, filename), 'r') as file:\n                words = file.read().split()\n                word_counts[filename] = len(words)\n                total_words += len(words)\n\n    with open('word_counts.json', 'w') as json_file:\n        json.dump(word_counts, json_file)\n\n    return total_words"}
{"task_id": "BigCodeBench/288", "solution": "import collections\nimport json\nimport os\ndef task_func(directory_path: str) -> dict:\n    # Initialize an empty dictionary\n    key_counts = collections.defaultdict(int)\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory_path):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the file\n            with open(os.path.join(directory_path, filename), 'r') as file:\n                # Load the JSON data\n                data = json.load(file)\n\n                # Recursively count keys in the JSON data\n                def count_keys(data):\n                    if isinstance(data, dict):\n                        for key, value in data.items():\n                            key_counts[key] += 1\n                            count_keys(value)\n                    elif isinstance(data, list):\n                        for item in data:\n                            count_keys(item)\n\n                count_keys(data)\n\n    return dict(key_counts)", "raw_solution": "import collections\nimport json\nimport os\n\ndef task_func(directory_path: str) -> dict:\n    # Initialize an empty dictionary\n    key_counts = collections.defaultdict(int)\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory_path):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the file\n            with open(os.path.join(directory_path, filename), 'r') as file:\n                # Load the JSON data\n                data = json.load(file)\n\n                # Recursively count keys in the JSON data\n                def count_keys(data):\n                    if isinstance(data, dict):\n                        for key, value in data.items():\n                            key_counts[key] += 1\n                            count_keys(value)\n                    elif isinstance(data, list):\n                        for item in data:\n                            count_keys(item)\n\n                count_keys(data)\n\n    return dict(key_counts)"}
{"task_id": "BigCodeBench/289", "solution": "import tensorflow as tf\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(X, y, n_splits, batch_size, epochs):\n    # Preprocessing\n    scaler = MinMaxScaler()\n    X = scaler.fit_transform(X)\n\n    # KFold\n    kf = KFold(n_splits=n_splits)\n\n    # Lists to store history\n    histories = []\n\n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n\n        # Model\n        model = tf.keras.models.Sequential([\n            tf.keras.layers.Dense(20, activation='relu', input_shape=(X_train.shape[1],)),\n            tf.keras.layers.Dense(1, activation='sigmoid')\n        ])\n\n        # Compile\n        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n        # Train\n        history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n\n        # Append history\n        histories.append(history)\n\n    return histories", "raw_solution": "import tensorflow as tf\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(X, y, n_splits, batch_size, epochs):\n    # Preprocessing\n    scaler = MinMaxScaler()\n    X = scaler.fit_transform(X)\n\n    # KFold\n    kf = KFold(n_splits=n_splits)\n\n    # Lists to store history\n    histories = []\n\n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n\n        # Model\n        model = tf.keras.models.Sequential([\n            tf.keras.layers.Dense(20, activation='relu', input_shape=(X_train.shape[1],)),\n            tf.keras.layers.Dense(1, activation='sigmoid')\n        ])\n\n        # Compile\n        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n        # Train\n        history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n\n        # Append history\n        histories.append(history)\n\n    return histories"}
{"task_id": "BigCodeBench/290", "solution": "import nltk\nfrom collections import Counter\nimport os\nfrom nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(directory_path):\n    # Initialize a counter\n    word_counter = Counter()\n\n    # Walk through the directory\n    for root, dirs, files in os.walk(directory_path):\n        for file in files:\n            # Only process '.txt' files\n            if file.endswith('.txt'):\n                with open(os.path.join(root, file), 'r') as f:\n                    # Tokenize the file\n                    words = nltk.word_tokenize(f.read())\n                    # Count the words\n                    word_counter.update(words)\n\n    # Remove stopwords\n    word_counter = {word: count for word, count in word_counter.items() if word not in STOPWORDS}\n\n    # Return the total count of unique non-stop words\n    return sum(word_counter.values())", "raw_solution": "import nltk\nnltk.download('stopwords')\nfrom collections import Counter\nimport os\nfrom nltk.corpus import stopwords\n# Constants\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(directory_path):\n    # Initialize a counter\n    word_counter = Counter()\n\n    # Walk through the directory\n    for root, dirs, files in os.walk(directory_path):\n        for file in files:\n            # Only process '.txt' files\n            if file.endswith('.txt'):\n                with open(os.path.join(root, file), 'r') as f:\n                    # Tokenize the file\n                    words = nltk.word_tokenize(f.read())\n                    # Count the words\n                    word_counter.update(words)\n\n    # Remove stopwords\n    word_counter = {word: count for word, count in word_counter.items() if word not in STOPWORDS}\n\n    # Return the total count of unique non-stop words\n    return sum(word_counter.values())\n\n# Test the function"}
{"task_id": "BigCodeBench/291", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\ndef task_func(mu, sigma, seed=0):\n    np.random.seed(seed)\n    data = np.random.normal(mu, sigma, 1000)\n\n    fig, ax = plt.subplots()\n    sns.histplot(data, bins=30, kde=True, color=\"skyblue\", ax=ax)\n    ax.set_title(f\"Normal Distribution with Mean: {mu} and Standard Deviation: {sigma}\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\ndef task_func(mu, sigma, seed=0):\n    np.random.seed(seed)\n    data = np.random.normal(mu, sigma, 1000)\n\n    fig, ax = plt.subplots()\n    sns.histplot(data, bins=30, kde=True, color=\"skyblue\", ax=ax)\n    ax.set_title(f\"Normal Distribution with Mean: {mu} and Standard Deviation: {sigma}\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n\n    return ax\n\n# Test the function\nax = task_func(0, 1)\nplt.show()"}
{"task_id": "BigCodeBench/292", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    # Group by 'id'\n    grouped = df.groupby('id')\n\n    # Apply MinMaxScaler to 'Age' and 'Income' columns\n    scaled_df = grouped.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n    scaled_df.columns = ['Age', 'Income']\n\n    # Reset index\n    scaled_df.reset_index(drop=True, inplace=True)\n\n    # Create histogram data\n    hist_data = scaled_df['Income']\n\n    # Plot histogram\n    plt.hist(hist_data, bins=10)\n    plt.title('Histogram of Income after Scaling')\n    plt.xlabel('Income')\n    plt.ylabel('Frequency')\n    hist_plot = plt.gcf()\n\n    return (scaled_df, hist_plot)", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    # Group by 'id'\n    grouped = df.groupby('id')\n\n    # Apply MinMaxScaler to 'Age' and 'Income' columns\n    scaled_df = grouped.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n    scaled_df.columns = ['Age', 'Income']\n\n    # Reset index\n    scaled_df.reset_index(drop=True, inplace=True)\n\n    # Create histogram data\n    hist_data = scaled_df['Income']\n\n    # Plot histogram\n    plt.hist(hist_data, bins=10)\n    plt.title('Histogram of Income after Scaling')\n    plt.xlabel('Income')\n    plt.ylabel('Frequency')\n    hist_plot = plt.gcf()\n\n    return (scaled_df, hist_plot)"}
{"task_id": "BigCodeBench/293", "solution": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(elements, subset_size):\n    # Generate all subsets of a given size from a tuple\n    subsets = list(itertools.combinations(elements, subset_size))\n    \n    # Calculate the sums of the subsets\n    sums_subsets = [sum(subset) for subset in subsets]\n    \n    # Draw a histogram of the sums of the subsets\n    ax = plt.hist(sums_subsets, bins='auto')\n    \n    return ax, subsets, sums_subsets\nelements = (1, 2, 3, 4, 5)\nsubset_size = 3", "raw_solution": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(elements, subset_size):\n    # Generate all subsets of a given size from a tuple\n    subsets = list(itertools.combinations(elements, subset_size))\n    \n    # Calculate the sums of the subsets\n    sums_subsets = [sum(subset) for subset in subsets]\n    \n    # Draw a histogram of the sums of the subsets\n    ax = plt.hist(sums_subsets, bins='auto')\n    \n    return ax, subsets, sums_subsets\n\n# Test the function\nelements = (1, 2, 3, 4, 5)\nsubset_size = 3\nax, subsets, sums_subsets = task_func(elements, subset_size)\n\n# Print the subsets and their sums"}
{"task_id": "BigCodeBench/294", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    # Check if the DataFrame has the required columns\n    if not all(col in df.columns for col in ['id', 'age', 'income']):\n        raise ValueError(\"The DataFrame does not have the 'id', 'age', and 'income' columns.\")\n\n    # Group the DataFrame by 'id' and standardize 'age' and 'income'\n    grouped = df.groupby('id')\n    df[['age', 'income']] = grouped[['age', 'income']].transform(lambda x: (x - x.mean()) / x.std())\n\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    # Check if the DataFrame has the required columns\n    if not all(col in df.columns for col in ['id', 'age', 'income']):\n        raise ValueError(\"The DataFrame does not have the 'id', 'age', and 'income' columns.\")\n\n    # Group the DataFrame by 'id' and standardize 'age' and 'income'\n    grouped = df.groupby('id')\n    df[['age', 'income']] = grouped[['age', 'income']].transform(lambda x: (x - x.mean()) / x.std())\n\n    return df"}
{"task_id": "BigCodeBench/295", "solution": "import itertools\nimport statistics\nfrom collections import Counter\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n\n    mean = statistics.mean(sums)\n    median = statistics.median(sums)\n    mode = statistics.mode(sums)\n\n    return {'mean': mean, 'median': median, 'mode': mode}", "raw_solution": "import itertools\nimport statistics\nfrom collections import Counter\n\n# Refined function after importing required libraries\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n\n    mean = statistics.mean(sums)\n    median = statistics.median(sums)\n    mode = statistics.mode(sums)\n\n    return {'mean': mean, 'median': median, 'mode': mode}\n\n# Testing the function"}
{"task_id": "BigCodeBench/296", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    if df.empty:\n        fig, ax = plt.subplots()\n        ax.set_title(\"Value Distribution\")\n        ax.set_xlabel(\"Value\")\n        ax.set_ylabel(\"Count\")\n        return ax\n\n    counts = df['value'].value_counts()\n    ax = counts.plot(kind='bar', title=\"Value Distribution\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Count\")\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    if df.empty:\n        fig, ax = plt.subplots()\n        ax.set_title(\"Value Distribution\")\n        ax.set_xlabel(\"Value\")\n        ax.set_ylabel(\"Count\")\n        return ax\n\n    counts = df['value'].value_counts()\n    ax = counts.plot(kind='bar', title=\"Value Distribution\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Count\")\n    return ax"}
{"task_id": "BigCodeBench/297", "solution": "import itertools\nimport collections\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums_dict = collections.Counter(sum(subset) for subset in subsets)\n    return sums_dict\nelements = (1, 2, 3, 4)\nsubset_size = 2", "raw_solution": "import itertools\nimport collections\n\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums_dict = collections.Counter(sum(subset) for subset in subsets)\n    return sums_dict\n\n# Test the function\nelements = (1, 2, 3, 4)\nsubset_size = 2"}
{"task_id": "BigCodeBench/298", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nCOLUMNS = ['Date', 'Value']\ndef task_func(df, plot=False):\n    # Check if the DataFrame has the required columns\n    if not all(col in df.columns for col in COLUMNS):\n        raise KeyError(\"DataFrame does not have the 'Date' and 'Value' columns\")\n\n    # Convert 'Date' to datetime and set it as the index\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n\n    # Split the 'Value' column into multiple columns\n    value_list = df['Value'].apply(pd.Series)\n    value_list.columns = ['Value_' + str(col) for col in value_list.columns]\n\n    # Scale the values\n    scaler = StandardScaler()\n    scaled_values = scaler.fit_transform(value_list)\n    scaled_df = pd.DataFrame(scaled_values, index=value_list.index, columns=value_list.columns)\n\n    # If plot is True, create a bar chart\n    if plot:\n        fig, ax = plt.subplots(figsize=(10, 6))\n        scaled_df.plot(kind='bar', ax=ax)\n        ax.set_title('Scaled Values Over Time')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Scaled Value')\n        plt.show()\n\n    return scaled_df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['Date', 'Value']\n\ndef task_func(df, plot=False):\n    # Check if the DataFrame has the required columns\n    if not all(col in df.columns for col in COLUMNS):\n        raise KeyError(\"DataFrame does not have the 'Date' and 'Value' columns\")\n\n    # Convert 'Date' to datetime and set it as the index\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n\n    # Split the 'Value' column into multiple columns\n    value_list = df['Value'].apply(pd.Series)\n    value_list.columns = ['Value_' + str(col) for col in value_list.columns]\n\n    # Scale the values\n    scaler = StandardScaler()\n    scaled_values = scaler.fit_transform(value_list)\n    scaled_df = pd.DataFrame(scaled_values, index=value_list.index, columns=value_list.columns)\n\n    # If plot is True, create a bar chart\n    if plot:\n        fig, ax = plt.subplots(figsize=(10, 6))\n        scaled_df.plot(kind='bar', ax=ax)\n        ax.set_title('Scaled Values Over Time')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Scaled Value')\n        plt.show()\n\n    return scaled_df"}
{"task_id": "BigCodeBench/299", "solution": "import itertools\nimport math\nfrom pandas import Series\ndef task_func(elements, subset_size, top_n=2):\n    if subset_size > len(elements) or subset_size == 0:\n        return 1\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n    product = math.prod(sums)\n    series = Series(sums).nlargest(top_n)\n    return product, series", "raw_solution": "import itertools\nimport math\nfrom pandas import Series\n\ndef task_func(elements, subset_size, top_n=2):\n    if subset_size > len(elements) or subset_size == 0:\n        return 1\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n    product = math.prod(sums)\n    series = Series(sums).nlargest(top_n)\n    return product, series"}
{"task_id": "BigCodeBench/300", "solution": "import pandas as pd\nfrom scipy.stats import zscore\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    # Check if 'Date' and 'Value' columns exist in the DataFrame\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise KeyError(\"The DataFrame does not have the 'Date' and 'Value' columns.\")\n\n    # Convert 'Date' to datetime\n    df['Date'] = pd.to_datetime(df['Date'])\n\n    # Split 'Value' lists into separate columns\n    df = df['Value'].apply(pd.Series)\n\n    # Calculate Z-scores\n    df = df.apply(zscore)\n\n    # Create a box plot for Z-scores over time\n    fig, ax = plt.subplots(figsize=(10, 6))\n    df.boxplot(ax=ax)\n    ax.set_title('Z-Scores Over Time')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Z-Score')\n\n    return df, fig", "raw_solution": "import pandas as pd\nfrom scipy.stats import zscore\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    # Check if 'Date' and 'Value' columns exist in the DataFrame\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise KeyError(\"The DataFrame does not have the 'Date' and 'Value' columns.\")\n\n    # Convert 'Date' to datetime\n    df['Date'] = pd.to_datetime(df['Date'])\n\n    # Split 'Value' lists into separate columns\n    df = df['Value'].apply(pd.Series)\n\n    # Calculate Z-scores\n    df = df.apply(zscore)\n\n    # Create a box plot for Z-scores over time\n    fig, ax = plt.subplots(figsize=(10, 6))\n    df.boxplot(ax=ax)\n    ax.set_title('Z-Scores Over Time')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Z-Score')\n\n    return df, fig"}
{"task_id": "BigCodeBench/301", "solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\nSOLAR_CYCLE_YEARS = np.array([1986, 1996, 2008, 2019])\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the date string into a datetime object\n    date = parse(date_str)\n\n    # Convert the date to the desired timezone\n    date = date.replace(tzinfo=pytz.timezone(from_tz))\n    date = date.astimezone(pytz.timezone(to_tz))\n\n    # Calculate the years since the closest solar cycle year\n    years_since_solar_cycle = date.year - SOLAR_CYCLE_YEARS.min()\n\n    # Calculate the solar activity using a cosine function\n    solar_activity = 0.5 * (1 + math.cos(2 * math.pi * years_since_solar_cycle / 11))\n\n    return solar_activity", "raw_solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\n\nSOLAR_CYCLE_YEARS = np.array([1986, 1996, 2008, 2019])\n\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the date string into a datetime object\n    date = parse(date_str)\n\n    # Convert the date to the desired timezone\n    date = date.replace(tzinfo=pytz.timezone(from_tz))\n    date = date.astimezone(pytz.timezone(to_tz))\n\n    # Calculate the years since the closest solar cycle year\n    years_since_solar_cycle = date.year - SOLAR_CYCLE_YEARS.min()\n\n    # Calculate the solar activity using a cosine function\n    solar_activity = 0.5 * (1 + math.cos(2 * math.pi * years_since_solar_cycle / 11))\n\n    return solar_activity\n\n# Test the function"}
{"task_id": "BigCodeBench/302", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nCOLUMNS = ['Date', 'Value']\ndef task_func(df, plot=False):\n    # Check if DataFrame is empty\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n\n    # Check if DataFrame has the correct columns\n    if not all(col in df.columns for col in COLUMNS):\n        raise ValueError(\"DataFrame does not have the correct columns\")\n\n    # Check if 'Value' column contains valid lists\n    for value in df['Value']:\n        if not isinstance(value, list):\n            raise ValueError(\"'Value' column contains invalid data\")\n\n    # Split lists in the 'Value' column into separate columns\n    df = df['Value'].apply(pd.Series)\n    df.columns = [f'Value_{i}' for i in range(df.shape[1])]\n\n    # Calculate the Pearson correlation coefficient\n    corr = df.corr(method='pearson')\n\n    if plot:\n        # Visualize the correlation matrix using a heatmap\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n        plt.title(\"Correlation Heatmap\")\n        plt.show()\n\n    return corr", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Constants\nCOLUMNS = ['Date', 'Value']\n\ndef task_func(df, plot=False):\n    # Check if DataFrame is empty\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n\n    # Check if DataFrame has the correct columns\n    if not all(col in df.columns for col in COLUMNS):\n        raise ValueError(\"DataFrame does not have the correct columns\")\n\n    # Check if 'Value' column contains valid lists\n    for value in df['Value']:\n        if not isinstance(value, list):\n            raise ValueError(\"'Value' column contains invalid data\")\n\n    # Split lists in the 'Value' column into separate columns\n    df = df['Value'].apply(pd.Series)\n    df.columns = [f'Value_{i}' for i in range(df.shape[1])]\n\n    # Calculate the Pearson correlation coefficient\n    corr = df.corr(method='pearson')\n\n    if plot:\n        # Visualize the correlation matrix using a heatmap\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n        plt.title(\"Correlation Heatmap\")\n        plt.show()\n\n    return corr"}
{"task_id": "BigCodeBench/303", "solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\nMOON_PHASES_YEARS = np.array([1987, 1994, 2001, 2008, 2015, 2022])\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the date string into a datetime object\n    date = parse(date_str)\n\n    # Convert the date to the target timezone\n    date = date.replace(tzinfo=pytz.timezone(from_tz))\n    date = date.astimezone(pytz.timezone(to_tz))\n\n    # Calculate the number of days since the first year\n    days_since_first_year = (date - pytz.utc.localize(datetime.datetime(MOON_PHASES_YEARS[0], 1, 1))).days\n\n    # Calculate the lunar phase\n    lunar_phase = (days_since_first_year % 29.53058867) / 29.53058867\n\n    return lunar_phase", "raw_solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\n\nMOON_PHASES_YEARS = np.array([1987, 1994, 2001, 2008, 2015, 2022])\n\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the date string into a datetime object\n    date = parse(date_str)\n\n    # Convert the date to the target timezone\n    date = date.replace(tzinfo=pytz.timezone(from_tz))\n    date = date.astimezone(pytz.timezone(to_tz))\n\n    # Calculate the number of days since the first year\n    days_since_first_year = (date - pytz.utc.localize(datetime.datetime(MOON_PHASES_YEARS[0], 1, 1))).days\n\n    # Calculate the lunar phase\n    lunar_phase = (days_since_first_year % 29.53058867) / 29.53058867\n\n    return lunar_phase\n\n# Test the function"}
{"task_id": "BigCodeBench/304", "solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(df):\n    if df.empty:\n        return (np.array([0.0]), None)\n\n    # Convert lists to separate columns\n    df = pd.concat([df.drop(['numbers'], axis=1), df['numbers'].apply(pd.Series)], axis=1)\n\n    # Perform PCA\n    pca = PCA()\n    df_pca = pca.fit_transform(df.drop(['date'], axis=1))\n\n    # Get explained variance ratio\n    explained_variance_ratio = pca.explained_variance_ratio_\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    ax.bar(range(1, len(explained_variance_ratio)+1), explained_variance_ratio)\n    ax.set_title('Explained Variance Ratio of Principal Components')\n    ax.set_xlabel('Principal Component')\n    ax.set_ylabel('Explained Variance Ratio')\n\n    return (explained_variance_ratio, ax)", "raw_solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(df):\n    if df.empty:\n        return (np.array([0.0]), None)\n\n    # Convert lists to separate columns\n    df = pd.concat([df.drop(['numbers'], axis=1), df['numbers'].apply(pd.Series)], axis=1)\n\n    # Perform PCA\n    pca = PCA()\n    df_pca = pca.fit_transform(df.drop(['date'], axis=1))\n\n    # Get explained variance ratio\n    explained_variance_ratio = pca.explained_variance_ratio_\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    ax.bar(range(1, len(explained_variance_ratio)+1), explained_variance_ratio)\n    ax.set_title('Explained Variance Ratio of Principal Components')\n    ax.set_xlabel('Principal Component')\n    ax.set_ylabel('Explained Variance Ratio')\n\n    return (explained_variance_ratio, ax)"}
{"task_id": "BigCodeBench/305", "solution": "from collections import Counter\nimport itertools\nimport random\nALPHABET = 'abcdefghijklmnopqrstuvwxyz'\ndef task_func(list_of_lists, seed=0):\n    random.seed(seed)\n    for i, lst in enumerate(list_of_lists):\n        if not lst:\n            list_of_lists[i] = random.sample(ALPHABET, len(ALPHABET))\n    flat_list = list(itertools.chain.from_iterable(list_of_lists))\n    counter = Counter(flat_list)\n    return counter\nlist_of_lists = [['a', 'b', 'c'], ['d', 'e', 'f'], ['g', 'h', 'i']]", "raw_solution": "from collections import Counter\nimport itertools\nimport random\n\n# Constants\nALPHABET = 'abcdefghijklmnopqrstuvwxyz'\n\ndef task_func(list_of_lists, seed=0):\n    random.seed(seed)\n    for i, lst in enumerate(list_of_lists):\n        if not lst:\n            list_of_lists[i] = random.sample(ALPHABET, len(ALPHABET))\n    flat_list = list(itertools.chain.from_iterable(list_of_lists))\n    counter = Counter(flat_list)\n    return counter\n\n# Test the function\nlist_of_lists = [['a', 'b', 'c'], ['d', 'e', 'f'], ['g', 'h', 'i']]"}
{"task_id": "BigCodeBench/306", "solution": "import os\nimport logging\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(f\"The specified directory {directory} does not exist.\")\n\n    removed_files = []\n    count = 0\n    for filename in os.listdir(directory):\n        if 'jquery' in filename:\n            file_path = os.path.join(directory, filename)\n            os.remove(file_path)\n            removed_files.append(filename)\n            count += 1\n\n    logging.basicConfig(filename='jquery_removal.log', level=logging.INFO)\n    logging.info(f\"Number of files removed: {count}, Files: {removed_files}\")\n\n    return (count, removed_files)", "raw_solution": "import os\nimport logging\n\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(f\"The specified directory {directory} does not exist.\")\n\n    removed_files = []\n    count = 0\n    for filename in os.listdir(directory):\n        if 'jquery' in filename:\n            file_path = os.path.join(directory, filename)\n            os.remove(file_path)\n            removed_files.append(filename)\n            count += 1\n\n    logging.basicConfig(filename='jquery_removal.log', level=logging.INFO)\n    logging.info(f\"Number of files removed: {count}, Files: {removed_files}\")\n\n    return (count, removed_files)"}
{"task_id": "BigCodeBench/307", "solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\ndef task_func(list_of_lists, seed=0):\n    # Set the seed for reproducibility\n    random.seed(seed)\n\n    # Fill empty sublists with 5 random integers\n    for i in range(len(list_of_lists)):\n        if not list_of_lists[i]:\n            list_of_lists[i] = [random.randint(0, 100) for _ in range(5)]\n\n    # Flatten the list of lists\n    flat_list = [item for sublist in list_of_lists for item in sublist]\n\n    # Create the histogram\n    ax = sns.histplot(flat_list, bins=10, kde=False)\n\n    return ax\nlist_of_lists = [[10, 20, 30, 40, 50], [], [60, 70, 80, 90, 100], [15, 25, 35, 45, 55]]", "raw_solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n\ndef task_func(list_of_lists, seed=0):\n    # Set the seed for reproducibility\n    random.seed(seed)\n\n    # Fill empty sublists with 5 random integers\n    for i in range(len(list_of_lists)):\n        if not list_of_lists[i]:\n            list_of_lists[i] = [random.randint(0, 100) for _ in range(5)]\n\n    # Flatten the list of lists\n    flat_list = [item for sublist in list_of_lists for item in sublist]\n\n    # Create the histogram\n    ax = sns.histplot(flat_list, bins=10, kde=False)\n\n    return ax\n\n# Test the function\nlist_of_lists = [[10, 20, 30, 40, 50], [], [60, 70, 80, 90, 100], [15, 25, 35, 45, 55]]\nax = task_func(list_of_lists)\nplt.show()"}
{"task_id": "BigCodeBench/308", "solution": "import pandas as pd\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\ndef task_func(additional_fields = []):\n    # Generate random grades for each student in each subject\n    data = {field: [random.randint(0, 100) for _ in range(100)] for field in FIELDS}\n    # Add additional fields if any\n    for field in additional_fields:\n        data[field] = [random.randint(0, 100) for _ in range(100)]\n    # Create DataFrame\n    df = pd.DataFrame(data, index=STUDENTS)\n    # Add average column for each student\n    df['Average'] = df.mean(axis=1)\n    # Add average grade for each subject\n    df.loc['Average Grade'] = df.mean()\n    return df", "raw_solution": "import pandas as pd\nimport random\n\n# Constants for generating the report data\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\n\ndef task_func(additional_fields = []):\n    # Generate random grades for each student in each subject\n    data = {field: [random.randint(0, 100) for _ in range(100)] for field in FIELDS}\n    # Add additional fields if any\n    for field in additional_fields:\n        data[field] = [random.randint(0, 100) for _ in range(100)]\n    # Create DataFrame\n    df = pd.DataFrame(data, index=STUDENTS)\n    # Add average column for each student\n    df['Average'] = df.mean(axis=1)\n    # Add average grade for each subject\n    df.loc['Average Grade'] = df.mean()\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/309", "solution": "import numpy as np\nimport random\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(list_of_lists, seed=42):\n    random.seed(seed)\n    for i in range(len(list_of_lists)):\n        if not list_of_lists[i]:\n            list_of_lists[i] = [random.randint(0, 100) for _ in range(5)]\n\n    scaler = MinMaxScaler()\n    for i in range(len(list_of_lists)):\n        list_of_lists[i] = scaler.fit_transform(np.array(list_of_lists[i]).reshape(-1, 1)).flatten().tolist()\n\n    return list_of_lists", "raw_solution": "import numpy as np\nimport random\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(list_of_lists, seed=42):\n    random.seed(seed)\n    for i in range(len(list_of_lists)):\n        if not list_of_lists[i]:\n            list_of_lists[i] = [random.randint(0, 100) for _ in range(5)]\n\n    scaler = MinMaxScaler()\n    for i in range(len(list_of_lists)):\n        list_of_lists[i] = scaler.fit_transform(np.array(list_of_lists[i]).reshape(-1, 1)).flatten().tolist()\n\n    return list_of_lists"}
{"task_id": "BigCodeBench/310", "solution": "import os\nimport csv\nimport random\nfrom statistics import mean\nimport string\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\ndef generate_random_data():\n    return [\n        ''.join(random.choices(string.ascii_uppercase, k=5)),  # Random name\n        random.randint(18, 80),  # Random age\n        random.randint(150, 200),  # Random height\n        random.randint(40, 150),  # Random weight\n    ]\ndef task_func(filename):\n    # Create a CSV file\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n\n        # Write column names\n        writer.writerow(COLUMNS)\n\n        # Write simulated data for 100 people\n        people_data = [generate_random_data() for _ in range(PEOPLE_COUNT)]\n        writer.writerows(people_data)\n\n    # Calculate and append the average age, height, and weight\n    with open(filename, 'a', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n\n        # Calculate averages\n        avg_age = mean(row[1] for row in people_data)\n        avg_height = mean(row[2] for row in people_data)\n        avg_weight = mean(row[3] for row in people_data)\n\n        # Append averages\n        writer.writerow(['Average', avg_age, avg_height, avg_weight])\n\n    return filename", "raw_solution": "import os\nimport csv\nimport random\nfrom statistics import mean\nimport string\n\n# Constants\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\n\ndef generate_random_data():\n    return [\n        ''.join(random.choices(string.ascii_uppercase, k=5)),  # Random name\n        random.randint(18, 80),  # Random age\n        random.randint(150, 200),  # Random height\n        random.randint(40, 150),  # Random weight\n    ]\n\ndef task_func(filename):\n    # Create a CSV file\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n\n        # Write column names\n        writer.writerow(COLUMNS)\n\n        # Write simulated data for 100 people\n        people_data = [generate_random_data() for _ in range(PEOPLE_COUNT)]\n        writer.writerows(people_data)\n\n    # Calculate and append the average age, height, and weight\n    with open(filename, 'a', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n\n        # Calculate averages\n        avg_age = mean(row[1] for row in people_data)\n        avg_height = mean(row[2] for row in people_data)\n        avg_weight = mean(row[3] for row in people_data)\n\n        # Append averages\n        writer.writerow(['Average', avg_age, avg_height, avg_weight])\n\n    return filename"}
{"task_id": "BigCodeBench/311", "solution": "import numpy as np\nimport random\nfrom scipy import stats\ndef task_func(list_of_lists, size=5, seed=0):\n    random.seed(seed)\n    result = {}\n    for i, lst in enumerate(list_of_lists):\n        if not lst:\n            list_of_lists[i] = random.sample(range(0, 101), size)\n        mean_val = np.mean(lst)\n        median_val, mode_val = np.median(lst), stats.mode(lst)[0][0]\n        result[i] = {'mean': mean_val, 'median': median_val, 'mode': mode_val}\n    return result", "raw_solution": "import numpy as np\nimport random\nfrom scipy import stats\n\ndef task_func(list_of_lists, size=5, seed=0):\n    random.seed(seed)\n    result = {}\n    for i, lst in enumerate(list_of_lists):\n        if not lst:\n            list_of_lists[i] = random.sample(range(0, 101), size)\n        mean_val = np.mean(lst)\n        median_val, mode_val = np.median(lst), stats.mode(lst)[0][0]\n        result[i] = {'mean': mean_val, 'median': median_val, 'mode': mode_val}\n    return result"}
{"task_id": "BigCodeBench/312", "solution": "import random\nimport matplotlib.pyplot as plt\nimport numpy as np\nDISTRIBUTION_SIZE = 1000\ndef task_func(bins=30):\n    # Generate a Gaussian distribution\n    distribution = np.random.normal(0, 1, DISTRIBUTION_SIZE)\n\n    # Create a histogram\n    fig, ax = plt.subplots()\n    ax.hist(distribution, bins=bins)\n\n    # Return the distribution and the Axes patch object\n    return (distribution, ax)", "raw_solution": "import random\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Constants\nDISTRIBUTION_SIZE = 1000\n\ndef task_func(bins=30):\n    # Generate a Gaussian distribution\n    distribution = np.random.normal(0, 1, DISTRIBUTION_SIZE)\n\n    # Create a histogram\n    fig, ax = plt.subplots()\n    ax.hist(distribution, bins=bins)\n\n    # Return the distribution and the Axes patch object\n    return (distribution, ax)\n\n# Test the function\ndistribution, ax = task_func()\nplt.show()"}
{"task_id": "BigCodeBench/313", "solution": "import re\nimport os\nimport shutil\nfrom datetime import datetime\ndef task_func(directory):\n    if not os.path.isdir(directory):\n        return \"Invalid directory path\"\n\n    subdirs = {}\n    for filename in os.listdir(directory):\n        match = re.search(r'\\[([^\\]]+)\\]', filename)\n        if match:\n            subdir_name = match.group(1)\n            if not os.path.isdir(os.path.join(directory, subdir_name)):\n                os.mkdir(os.path.join(directory, subdir_name))\n            if subdir_name not in subdirs:\n                subdirs[subdir_name] = []\n            shutil.move(os.path.join(directory, filename), os.path.join(directory, subdir_name))\n            subdirs[subdir_name].append(filename)\n\n    return directory, subdirs", "raw_solution": "import re\nimport os\nimport shutil\nfrom datetime import datetime\n\ndef task_func(directory):\n    if not os.path.isdir(directory):\n        return \"Invalid directory path\"\n\n    subdirs = {}\n    for filename in os.listdir(directory):\n        match = re.search(r'\\[([^\\]]+)\\]', filename)\n        if match:\n            subdir_name = match.group(1)\n            if not os.path.isdir(os.path.join(directory, subdir_name)):\n                os.mkdir(os.path.join(directory, subdir_name))\n            if subdir_name not in subdirs:\n                subdirs[subdir_name] = []\n            shutil.move(os.path.join(directory, filename), os.path.join(directory, subdir_name))\n            subdirs[subdir_name].append(filename)\n\n    return directory, subdirs\n\n# Test the function"}
{"task_id": "BigCodeBench/314", "solution": "import socket\nimport ssl\nimport http.client\ndef task_func(SERVER_NAME, SERVER_PORT, path):\n    try:\n        context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n        conn = http.client.HTTPSConnection(SERVER_NAME, SERVER_PORT, context=context)\n        conn.request(\"GET\", path)\n        response = conn.getresponse()\n        response_body = response.read().decode()\n        conn.close()\n        return response_body\n    except ssl.SSLError as e:\n        print(f\"SSL Error: {e}\")\n        return None", "raw_solution": "import socket\nimport ssl\nimport http.client\n\ndef task_func(SERVER_NAME, SERVER_PORT, path):\n    try:\n        context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n        conn = http.client.HTTPSConnection(SERVER_NAME, SERVER_PORT, context=context)\n        conn.request(\"GET\", path)\n        response = conn.getresponse()\n        response_body = response.read().decode()\n        conn.close()\n        return response_body\n    except ssl.SSLError as e:\n        print(f\"SSL Error: {e}\")\n        return None\n\n# Test the function"}
{"task_id": "BigCodeBench/315", "solution": "import os\nfrom sendgrid import SendGridAPIClient\nfrom sendgrid.helpers.mail import Mail\nfrom python_http_client.exceptions import HTTPError\ndef task_func(dir, api_key, recipient_email):\n    try:\n        # Check if directory exists\n        if not os.path.isdir(dir):\n            raise FileNotFoundError(f\"Directory {dir} does not exist.\")\n\n        # Get list of files in directory\n        files = os.listdir(dir)\n\n        # Create email content\n        message = Mail(\n            from_email='from_email@example.com',\n            to_emails=recipient_email,\n            subject='List of files',\n            plain_text_content='Here is the list of files: ' + ', '.join(files))\n\n        # Send email\n        sg = SendGridAPIClient(api_key)\n        response = sg.send(message)\n\n        # Check if email was sent successfully\n        if 200 <= response.status_code < 300:\n            return True\n        else:\n            return False\n\n    except FileNotFoundError as fnf_error:\n        print(fnf_error)\n        return False\n\n    except HTTPError as http_error:\n        print(f\"HTTP error occurred: {http_error}\")\n        return False\n\n    except Exception as error:\n        print(f\"An error occurred: {error}\")\n        return False", "raw_solution": "import os\nfrom sendgrid import SendGridAPIClient\nfrom sendgrid.helpers.mail import Mail\nfrom python_http_client.exceptions import HTTPError\n\ndef task_func(dir, api_key, recipient_email):\n    try:\n        # Check if directory exists\n        if not os.path.isdir(dir):\n            raise FileNotFoundError(f\"Directory {dir} does not exist.\")\n\n        # Get list of files in directory\n        files = os.listdir(dir)\n\n        # Create email content\n        message = Mail(\n            from_email='from_email@example.com',\n            to_emails=recipient_email,\n            subject='List of files',\n            plain_text_content='Here is the list of files: ' + ', '.join(files))\n\n        # Send email\n        sg = SendGridAPIClient(api_key)\n        response = sg.send(message)\n\n        # Check if email was sent successfully\n        if 200 <= response.status_code < 300:\n            return True\n        else:\n            return False\n\n    except FileNotFoundError as fnf_error:\n        print(fnf_error)\n        return False\n\n    except HTTPError as http_error:\n        print(f\"HTTP error occurred: {http_error}\")\n        return False\n\n    except Exception as error:\n        print(f\"An error occurred: {error}\")\n        return False"}
{"task_id": "BigCodeBench/316", "solution": "import pandas as pd\nimport random\nCATEGORIES = ['A', 'B', 'C', 'D', 'E']\ndef task_func(value_range=(0, 100)):\n    # Generate random values within the specified range\n    values = [random.randint(value_range[0], value_range[1]) for _ in range(100)]\n\n    # Map the values to categories\n    categories = [CATEGORIES[i % len(CATEGORIES)] for i in values]\n\n    # Create a DataFrame from the categories\n    df = pd.DataFrame(categories, columns=['Category'])\n\n    # Count the occurrences of each category\n    df = df['Category'].value_counts().reset_index().rename(columns={'index': 'Category', 'Category': 'Count'})\n\n    return df", "raw_solution": "import pandas as pd\nimport random\n\n# Constants\nCATEGORIES = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(value_range=(0, 100)):\n    # Generate random values within the specified range\n    values = [random.randint(value_range[0], value_range[1]) for _ in range(100)]\n\n    # Map the values to categories\n    categories = [CATEGORIES[i % len(CATEGORIES)] for i in values]\n\n    # Create a DataFrame from the categories\n    df = pd.DataFrame(categories, columns=['Category'])\n\n    # Count the occurrences of each category\n    df = df['Category'].value_counts().reset_index().rename(columns={'index': 'Category', 'Category': 'Count'})\n\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/317", "solution": "import numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport re\ndef task_func(example_str):\n    # Extract texts not enclosed in square brackets\n    text = re.sub(r'\\[.*?\\]', '', example_str)\n\n    # Calculate TF-IDF values\n    vectorizer = TfidfVectorizer()\n    tfidf_matrix = vectorizer.fit_transform([text])\n\n    # Convert sparse matrix to dense matrix and get TF-IDF scores\n    tfidf_scores = tfidf_matrix.toarray()[0]\n\n    # Create a dictionary with words as keys and TF-IDF scores as values\n    tfidf_dict = dict(zip(vectorizer.get_feature_names_out(), tfidf_scores))\n\n    return tfidf_dict\nexample_str = \"This is an [example] string with some words [in brackets] that should be [ignored].\"", "raw_solution": "import numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport re\n\ndef task_func(example_str):\n    # Extract texts not enclosed in square brackets\n    text = re.sub(r'\\[.*?\\]', '', example_str)\n\n    # Calculate TF-IDF values\n    vectorizer = TfidfVectorizer()\n    tfidf_matrix = vectorizer.fit_transform([text])\n\n    # Convert sparse matrix to dense matrix and get TF-IDF scores\n    tfidf_scores = tfidf_matrix.toarray()[0]\n\n    # Create a dictionary with words as keys and TF-IDF scores as values\n    tfidf_dict = dict(zip(vectorizer.get_feature_names_out(), tfidf_scores))\n\n    return tfidf_dict\n\n# Test the function\nexample_str = \"This is an [example] string with some words [in brackets] that should be [ignored].\""}
{"task_id": "BigCodeBench/318", "solution": "import random\nimport math\nimport matplotlib.pyplot as plt\ndef task_func(points_count=1000, radius=1):\n    # Generate points_count random points within a circle of given radius\n    points = [(radius * math.cos(theta), radius * math.sin(theta)) for theta in [random.uniform(0, 2*math.pi) for _ in range(points_count)]]\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(*zip(*points))\n\n    # Set aspect ratio to 'equal'\n    ax.set_aspect('equal')\n\n    return ax", "raw_solution": "import random\nimport math\nimport matplotlib.pyplot as plt\n\ndef task_func(points_count=1000, radius=1):\n    # Generate points_count random points within a circle of given radius\n    points = [(radius * math.cos(theta), radius * math.sin(theta)) for theta in [random.uniform(0, 2*math.pi) for _ in range(points_count)]]\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(*zip(*points))\n\n    # Set aspect ratio to 'equal'\n    ax.set_aspect('equal')\n\n    return ax\n\n# Test the function\nax = task_func(points_count=500, radius=2)\nplt.show()"}
{"task_id": "BigCodeBench/319", "solution": "import re\nimport matplotlib.pyplot as plt\nfrom nltk import word_tokenize\nfrom nltk.probability import FreqDist\ndef task_func(example_str, top_n=30):\n    # Extract all texts that are not enclosed in square brackets\n    text = re.sub(r'\\[.*?\\]', '', example_str)\n\n    # Tokenize the text\n    words = word_tokenize(text)\n\n    # Calculate the frequency distribution\n    fdist = FreqDist(words)\n\n    # Get the top_n most common words\n    top_words = fdist.most_common(top_n)\n\n    # Convert the top_words list to a dictionary\n    top_words_dict = dict(top_words)\n\n    # Plot the frequency distribution\n    fdist.plot(top_n)\n\n    return plt.gca(), top_words_dict", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nfrom nltk import word_tokenize\nfrom nltk.probability import FreqDist\n\ndef task_func(example_str, top_n=30):\n    # Extract all texts that are not enclosed in square brackets\n    text = re.sub(r'\\[.*?\\]', '', example_str)\n\n    # Tokenize the text\n    words = word_tokenize(text)\n\n    # Calculate the frequency distribution\n    fdist = FreqDist(words)\n\n    # Get the top_n most common words\n    top_words = fdist.most_common(top_n)\n\n    # Convert the top_words list to a dictionary\n    top_words_dict = dict(top_words)\n\n    # Plot the frequency distribution\n    fdist.plot(top_n)\n\n    return plt.gca(), top_words_dict"}
{"task_id": "BigCodeBench/320", "solution": "import subprocess\nimport os\nimport random\ndef task_func(directory, file_list):\n    if not file_list:\n        return None\n    random_file = random.choice(file_list)\n    file_path = os.path.join(directory, random_file)\n    if not os.path.isfile(file_path):\n        return None\n    process = subprocess.Popen(['python', file_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n    return process.returncode", "raw_solution": "import subprocess\nimport os\nimport random\n\ndef task_func(directory, file_list):\n    if not file_list:\n        return None\n    random_file = random.choice(file_list)\n    file_path = os.path.join(directory, random_file)\n    if not os.path.isfile(file_path):\n        return None\n    process = subprocess.Popen(['python', file_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n    return process.returncode"}
{"task_id": "BigCodeBench/321", "solution": "import pandas as pd\nimport re\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(text):\n    # Extract names not surrounded by square brackets\n    names = re.findall(r'\\[[^\\]]*\\]|([^\\s\\[\\]]+)', text)\n    names = [name for name in names if name]  # Remove empty strings\n\n    # Count the frequency of each name\n    freqs = pd.Series(names).value_counts()\n\n    # Create a bar chart of the name frequencies\n    if len(freqs) > 0:\n        ax = freqs.plot(kind='bar')\n    else:\n        ax = None\n\n    # Calculate skewness and kurtosis\n    skewness = freqs.skew() if len(freqs) > 0 else None\n    kurtosis = freqs.kurt() if len(freqs) > 0 else None\n\n    return freqs, ax, skewness, kurtosis", "raw_solution": "import pandas as pd\nimport re\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(text):\n    # Extract names not surrounded by square brackets\n    names = re.findall(r'\\[[^\\]]*\\]|([^\\s\\[\\]]+)', text)\n    names = [name for name in names if name]  # Remove empty strings\n\n    # Count the frequency of each name\n    freqs = pd.Series(names).value_counts()\n\n    # Create a bar chart of the name frequencies\n    if len(freqs) > 0:\n        ax = freqs.plot(kind='bar')\n    else:\n        ax = None\n\n    # Calculate skewness and kurtosis\n    skewness = freqs.skew() if len(freqs) > 0 else None\n    kurtosis = freqs.kurt() if len(freqs) > 0 else None\n\n    return freqs, ax, skewness, kurtosis"}
{"task_id": "BigCodeBench/322", "solution": "import subprocess\nimport os\nimport shutil\nimport sys\nDIRECTORY = 'c:\\Program Files\\VMware\\VMware Server'\nBACKUP_DIRECTORY = 'c:\\Program Files\\VMware\\VMware Server\\Backup'\ndef task_func(filename):\n    # Check if the file exists in the directory\n    if not os.path.isfile(os.path.join(DIRECTORY, filename)):\n        print(f\"File {filename} does not exist in the directory {DIRECTORY}\")\n        return -1\n\n    # Check if the backup directory exists, if not create it\n    if not os.path.exists(BACKUP_DIRECTORY):\n        os.makedirs(BACKUP_DIRECTORY)\n\n    # Backup the file\n    try:\n        shutil.copy2(os.path.join(DIRECTORY, filename), BACKUP_DIRECTORY)\n    except Exception as e:\n        print(f\"Backup failed: {str(e)}\")\n        return -1\n\n    # Execute the file as a subprocess\n    try:\n        process = subprocess.Popen([os.path.join(BACKUP_DIRECTORY, filename)], stdout=subprocess.PIPE)\n        output, _ = process.communicate()\n        return process.returncode\n    except Exception as e:\n        print(f\"Execution failed: {str(e)}\")\n        return -1", "raw_solution": "import subprocess\nimport os\nimport shutil\nimport sys\n\n# Constants\nDIRECTORY = 'c:\\Program Files\\VMware\\VMware Server'\nBACKUP_DIRECTORY = 'c:\\Program Files\\VMware\\VMware Server\\Backup'\n\ndef task_func(filename):\n    # Check if the file exists in the directory\n    if not os.path.isfile(os.path.join(DIRECTORY, filename)):\n        print(f\"File {filename} does not exist in the directory {DIRECTORY}\")\n        return -1\n\n    # Check if the backup directory exists, if not create it\n    if not os.path.exists(BACKUP_DIRECTORY):\n        os.makedirs(BACKUP_DIRECTORY)\n\n    # Backup the file\n    try:\n        shutil.copy2(os.path.join(DIRECTORY, filename), BACKUP_DIRECTORY)\n    except Exception as e:\n        print(f\"Backup failed: {str(e)}\")\n        return -1\n\n    # Execute the file as a subprocess\n    try:\n        process = subprocess.Popen([os.path.join(BACKUP_DIRECTORY, filename)], stdout=subprocess.PIPE)\n        output, _ = process.communicate()\n        return process.returncode\n    except Exception as e:\n        print(f\"Execution failed: {str(e)}\")\n        return -1\n\n# Test the function"}
{"task_id": "BigCodeBench/323", "solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.mixture import GaussianMixture\ndef task_func(text, num_gaussians=1, seed=42):\n    if num_gaussians <= 0:\n        raise ValueError(\"num_gaussians should be greater than 0\")\n\n    words = re.findall(r'\\b\\w+\\b', text)\n    words = [word for word in words if word[0]!='[' and word[-1]!=']']\n\n    word_freq = Counter(words)\n    words = list(word_freq.keys())\n    freqs = list(word_freq.values())\n\n    if num_gaussians > len(words):\n        raise Exception(\"num_gaussians should be less than or equal to the number of unique words\")\n\n    np.random.seed(seed)\n    gmm = GaussianMixture(n_components=num_gaussians)\n    gmm.fit(np.array(freqs).reshape(-1, 1))\n\n    means = gmm.means_.flatten()\n    variances = gmm.covariances_.flatten()\n\n    result = {\n        'word_freq': word_freq,\n        'means': means.tolist(),\n        'variances': variances.tolist()\n    }\n\n    return result", "raw_solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.mixture import GaussianMixture\n\ndef task_func(text, num_gaussians=1, seed=42):\n    if num_gaussians <= 0:\n        raise ValueError(\"num_gaussians should be greater than 0\")\n\n    words = re.findall(r'\\b\\w+\\b', text)\n    words = [word for word in words if word[0]!='[' and word[-1]!=']']\n\n    word_freq = Counter(words)\n    words = list(word_freq.keys())\n    freqs = list(word_freq.values())\n\n    if num_gaussians > len(words):\n        raise Exception(\"num_gaussians should be less than or equal to the number of unique words\")\n\n    np.random.seed(seed)\n    gmm = GaussianMixture(n_components=num_gaussians)\n    gmm.fit(np.array(freqs).reshape(-1, 1))\n\n    means = gmm.means_.flatten()\n    variances = gmm.covariances_.flatten()\n\n    result = {\n        'word_freq': word_freq,\n        'means': means.tolist(),\n        'variances': variances.tolist()\n    }\n\n    return result"}
{"task_id": "BigCodeBench/324", "solution": "import subprocess\nimport time\nimport threading\ndef task_func(file_list):\n    # Create a list to store the results\n    results = []\n\n    # Define a function to run a file as a subprocess\n    def run_file(file):\n        result = subprocess.run([file], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        results.append(result.returncode)\n\n    # Create a list to store the threads\n    threads = []\n\n    # Start each file as a subprocess in a new thread\n    for file in file_list:\n        thread = threading.Thread(target=run_file, args=(file,))\n        thread.start()\n        threads.append(thread)\n\n    # Wait for all threads to finish\n    for thread in threads:\n        thread.join()\n\n    # Return the results\n    return results\nfile_list = ['ls', 'pwd', 'echo', 'nonexistent_file']", "raw_solution": "import subprocess\nimport time\nimport threading\n\ndef task_func(file_list):\n    # Create a list to store the results\n    results = []\n\n    # Define a function to run a file as a subprocess\n    def run_file(file):\n        result = subprocess.run([file], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        results.append(result.returncode)\n\n    # Create a list to store the threads\n    threads = []\n\n    # Start each file as a subprocess in a new thread\n    for file in file_list:\n        thread = threading.Thread(target=run_file, args=(file,))\n        thread.start()\n        threads.append(thread)\n\n    # Wait for all threads to finish\n    for thread in threads:\n        thread.join()\n\n    # Return the results\n    return results\n\n# Test the function\nfile_list = ['ls', 'pwd', 'echo', 'nonexistent_file']"}
{"task_id": "BigCodeBench/325", "solution": "import re\nimport os\nfrom pathlib import Path\nimport glob\ndef task_func(directory_path: str, regex_pattern: str = r'(?<=\\().+?(?=\\))|\\w+') -> dict:\n    result = {}\n    files = glob.glob(os.path.join(directory_path, '*.txt'))\n    for file in files:\n        with open(file, 'r') as f:\n            content = f.read()\n            matches = re.findall(regex_pattern, content)\n            result[Path(file).name] = matches\n    return result", "raw_solution": "import re\nimport os\nfrom pathlib import Path\nimport glob\n\ndef task_func(directory_path: str, regex_pattern: str = r'(?<=\\().+?(?=\\))|\\w+') -> dict:\n    result = {}\n    files = glob.glob(os.path.join(directory_path, '*.txt'))\n    for file in files:\n        with open(file, 'r') as f:\n            content = f.read()\n            matches = re.findall(regex_pattern, content)\n            result[Path(file).name] = matches\n    return result\n\n# Test the function"}
{"task_id": "BigCodeBench/326", "solution": "import subprocess\nimport os\nimport sys\nimport glob\ndef task_func(directory_path):\n    # Check if the directory exists\n    if not os.path.isdir(directory_path):\n        print(f\"Directory {directory_path} does not exist.\")\n        return None\n\n    # Get all .bat files in the directory\n    bat_files = glob.glob(os.path.join(directory_path, \"*.bat\"))\n\n    # List to store the file names and exit codes\n    results = []\n\n    # Run each .bat file\n    for file in bat_files:\n        try:\n            # Run the file and get the exit code\n            exit_code = subprocess.call([\"cmd.exe\", \"/c\", file])\n            results.append((file, exit_code))\n        except Exception as e:\n            print(f\"Error running file {file}: {str(e)}\")\n            results.append((file, None))\n\n    return results", "raw_solution": "import subprocess\nimport os\nimport sys\nimport glob\n\ndef task_func(directory_path):\n    # Check if the directory exists\n    if not os.path.isdir(directory_path):\n        print(f\"Directory {directory_path} does not exist.\")\n        return None\n\n    # Get all .bat files in the directory\n    bat_files = glob.glob(os.path.join(directory_path, \"*.bat\"))\n\n    # List to store the file names and exit codes\n    results = []\n\n    # Run each .bat file\n    for file in bat_files:\n        try:\n            # Run the file and get the exit code\n            exit_code = subprocess.call([\"cmd.exe\", \"/c\", file])\n            results.append((file, exit_code))\n        except Exception as e:\n            print(f\"Error running file {file}: {str(e)}\")\n            results.append((file, None))\n\n    return results\n\n# Test the function"}
{"task_id": "BigCodeBench/327", "solution": "import csv\nimport re\nfrom collections import Counter\ndef task_func(file_path, regex_pattern=r'\\(.+?\\)|\\w+|[\\W_]+'):\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n\n    matches = []\n    for row in data:\n        for cell in row:\n            matches.extend(re.findall(regex_pattern, cell))\n\n    return dict(Counter(matches))", "raw_solution": "import csv\nimport re\nfrom collections import Counter\n\ndef task_func(file_path, regex_pattern=r'\\(.+?\\)|\\w+|[\\W_]+'):\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n\n    matches = []\n    for row in data:\n        for cell in row:\n            matches.extend(re.findall(regex_pattern, cell))\n\n    return dict(Counter(matches))\n\n# Test the function"}
{"task_id": "BigCodeBench/328", "solution": "import collections\nimport random\ndef task_func(number_teams=5):\n    # Create a dictionary to store team names and points\n    teams = {f\"Team {i}\": random.randint(1, 100) for i in range(1, number_teams + 1)}\n\n    # Sort the dictionary by points in descending order\n    sorted_teams = collections.OrderedDict(sorted(teams.items(), key=lambda x: x[1], reverse=True))\n\n    return sorted_teams", "raw_solution": "import collections\nimport random\n\ndef task_func(number_teams=5):\n    # Create a dictionary to store team names and points\n    teams = {f\"Team {i}\": random.randint(1, 100) for i in range(1, number_teams + 1)}\n\n    # Sort the dictionary by points in descending order\n    sorted_teams = collections.OrderedDict(sorted(teams.items(), key=lambda x: x[1], reverse=True))\n\n    return sorted_teams\n\n# Test the function\nfor rank in task_func(10):\n    print(f\"{rank}: {teams[rank]}\")"}
{"task_id": "BigCodeBench/329", "solution": "import re\nimport json\nimport os\ndef task_func(file_path: str, regex_pattern=r'\\(.+?\\)|\\w') -> dict:\n    result = {}\n    if os.path.isfile(file_path):\n        with open(file_path, 'r') as file:\n            data = file.read()\n            matches = re.findall(regex_pattern, data)\n            result[file_path] = matches\n    return result", "raw_solution": "import re\nimport json\nimport os\n\ndef task_func(file_path: str, regex_pattern=r'\\(.+?\\)|\\w') -> dict:\n    result = {}\n    if os.path.isfile(file_path):\n        with open(file_path, 'r') as file:\n            data = file.read()\n            matches = re.findall(regex_pattern, data)\n            result[file_path] = matches\n    return result\n\n# Test the function"}
{"task_id": "BigCodeBench/330", "solution": "import heapq\nimport random\ndef task_func(list_length:int, k:int):\n    # Generate a list of random integers\n    random_list = [random.randint(0, 100) for _ in range(list_length)]\n    \n    # Use heapq to find the k largest numbers\n    k_largest = heapq.nlargest(k, random_list)\n    \n    return random_list, k_largest", "raw_solution": "import heapq\nimport random\n\ndef task_func(list_length:int, k:int):\n    # Generate a list of random integers\n    random_list = [random.randint(0, 100) for _ in range(list_length)]\n    \n    # Use heapq to find the k largest numbers\n    k_largest = heapq.nlargest(k, random_list)\n    \n    return random_list, k_largest\n\n# Test the function\nrandom_list, k_largest = task_func(10, 5)"}
{"task_id": "BigCodeBench/331", "solution": "import bisect\nimport random\ndef task_func(num, list_length = 5, min_value = 0, max_value = 100):\n    if min_value > max_value:\n        raise ValueError(\"Minimum value should be less than or equal to maximum value\")\n    if num < min_value or num > max_value:\n        raise ValueError(\"Number to be inserted should be within the range of min_value and max_value\")\n\n    # Generate a list of random integers\n    random_list = [random.randint(min_value, max_value) for _ in range(list_length)]\n\n    # Sort the list\n    random_list.sort()\n\n    # Insert the number into the list using bisect\n    bisect.insort(random_list, num)\n\n    return (random_list, random_list)", "raw_solution": "import bisect\nimport random\n\ndef task_func(num, list_length = 5, min_value = 0, max_value = 100):\n    if min_value > max_value:\n        raise ValueError(\"Minimum value should be less than or equal to maximum value\")\n    if num < min_value or num > max_value:\n        raise ValueError(\"Number to be inserted should be within the range of min_value and max_value\")\n\n    # Generate a list of random integers\n    random_list = [random.randint(min_value, max_value) for _ in range(list_length)]\n\n    # Sort the list\n    random_list.sort()\n\n    # Insert the number into the list using bisect\n    bisect.insort(random_list, num)\n\n    return (random_list, random_list)\n\n# Test the function"}
{"task_id": "BigCodeBench/332", "solution": "import re\nfrom collections import Counter\nfrom nltk.corpus import stopwords\ndef task_func(text: str) -> dict:\n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n\n    # Convert to lowercase and split into words\n    words = text.lower().split()\n\n    # Remove stop words\n    stop_words = set(stopwords.words('english'))\n    words = [word for word in words if word not in stop_words]\n\n    # Count the words\n    word_counts = Counter(words)\n\n    return word_counts\ntext = \"This is a sample sentence. It contains several words, some of which are repeated.\"", "raw_solution": "import re\nfrom collections import Counter\nfrom nltk.corpus import stopwords\n\ndef task_func(text: str) -> dict:\n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n\n    # Convert to lowercase and split into words\n    words = text.lower().split()\n\n    # Remove stop words\n    stop_words = set(stopwords.words('english'))\n    words = [word for word in words if word not in stop_words]\n\n    # Count the words\n    word_counts = Counter(words)\n\n    return word_counts\n\n# Test the function\ntext = \"This is a sample sentence. It contains several words, some of which are repeated.\""}
{"task_id": "BigCodeBench/333", "solution": "import heapq\nimport random\ndef task_func(k, list_length = 5, min_value = 0, max_value = 100):\n    # Generate a list of random integers\n    random_list = [random.randint(min_value, max_value) for _ in range(list_length)]\n    \n    # Use heapq to find the k smallest numbers\n    k_smallest = heapq.nsmallest(k, random_list)\n    \n    return random_list, k_smallest", "raw_solution": "import heapq\nimport random\n\ndef task_func(k, list_length = 5, min_value = 0, max_value = 100):\n    # Generate a list of random integers\n    random_list = [random.randint(min_value, max_value) for _ in range(list_length)]\n    \n    # Use heapq to find the k smallest numbers\n    k_smallest = heapq.nsmallest(k, random_list)\n    \n    return random_list, k_smallest\n\n# Test the function\nrandom_list, k_smallest = task_func(3)"}
{"task_id": "BigCodeBench/334", "solution": "from nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\ndef task_func(documents):\n    vectorizer = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n    tfidf_matrix = vectorizer.fit_transform(documents)\n    df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out(), index=documents)\n    return df\ndocuments = [\n    'This is the first document.',\n    'This document is the second document.',\n    'And this is the third one.',\n    'Is this the first document?'\n]", "raw_solution": "from nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\n\ndef task_func(documents):\n    vectorizer = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n    tfidf_matrix = vectorizer.fit_transform(documents)\n    df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out(), index=documents)\n    return df\n\n# Test the function\ndocuments = [\n    'This is the first document.',\n    'This document is the second document.',\n    'And this is the third one.',\n    'Is this the first document?'\n]\n"}
{"task_id": "BigCodeBench/335", "solution": "import collections\nimport random\nLETTERS = ['a', 'b', 'c', 'd', 'e']\ndef task_func(string_length=100):\n    # Generate a random string of given length from the predefined list of letters\n    random_string = ''.join(random.choice(LETTERS) for _ in range(string_length))\n\n    # Count the frequency of each letter in the string\n    frequency_dict = collections.Counter(random_string)\n\n    # Sort the dictionary by frequency in descending order\n    sorted_dict = collections.OrderedDict(sorted(frequency_dict.items(), key=lambda x: x[1], reverse=True))\n\n    return sorted_dict", "raw_solution": "import collections\nimport random\n\n# Constants\nLETTERS = ['a', 'b', 'c', 'd', 'e']\n\ndef task_func(string_length=100):\n    # Generate a random string of given length from the predefined list of letters\n    random_string = ''.join(random.choice(LETTERS) for _ in range(string_length))\n\n    # Count the frequency of each letter in the string\n    frequency_dict = collections.Counter(random_string)\n\n    # Sort the dictionary by frequency in descending order\n    sorted_dict = collections.OrderedDict(sorted(frequency_dict.items(), key=lambda x: x[1], reverse=True))\n\n    return sorted_dict\n\n# Test the function"}
{"task_id": "BigCodeBench/336", "solution": "import re\nimport os\nimport glob\nfrom pathlib import Path\ndef task_func(pattern, directory, extensions):\n    # Compile the regex pattern\n    pattern = re.compile(pattern, re.IGNORECASE)\n\n    # Get all files with the specified extensions in the directory\n    files = glob.glob(os.path.join(directory, f'*.{extensions}'))\n\n    # List to store the files that contain the pattern\n    matching_files = []\n\n    # Iterate over each file\n    for file in files:\n        # Open the file and read its content\n        with open(file, 'r', encoding='utf-8') as f:\n            content = f.read()\n\n            # If the pattern is found in the content, add the file to the list\n            if pattern.search(content):\n                matching_files.append(os.path.abspath(file))\n\n    # Return the list of matching files\n    return matching_files", "raw_solution": "import re\nimport os\nimport glob\nfrom pathlib import Path\n\ndef task_func(pattern, directory, extensions):\n    # Compile the regex pattern\n    pattern = re.compile(pattern, re.IGNORECASE)\n\n    # Get all files with the specified extensions in the directory\n    files = glob.glob(os.path.join(directory, f'*.{extensions}'))\n\n    # List to store the files that contain the pattern\n    matching_files = []\n\n    # Iterate over each file\n    for file in files:\n        # Open the file and read its content\n        with open(file, 'r', encoding='utf-8') as f:\n            content = f.read()\n\n            # If the pattern is found in the content, add the file to the list\n            if pattern.search(content):\n                matching_files.append(os.path.abspath(file))\n\n    # Return the list of matching files\n    return matching_files"}
{"task_id": "BigCodeBench/337", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nCOLORS = ['r', 'g', 'b']\ndef task_func(df, group_col, value_col):\n    # Check if columns exist in the dataframe\n    if group_col not in df.columns or value_col not in df.columns:\n        raise ValueError(\"One or both of the columns do not exist in the dataframe\")\n\n    # Check if the 'Value' has non-numeric values\n    if not pd.api.types.is_numeric_dtype(df[value_col]):\n        raise TypeError(\"The 'Value' has non-numeric values\")\n\n    # Get unique groups\n    groups = df[group_col].unique()\n\n    # Create a new figure\n    fig, ax = plt.subplots()\n\n    # Create a bar chart for each group\n    for i, group in enumerate(groups):\n        # Get the data for this group\n        data = df[df[group_col] == group][value_col]\n\n        # Create the bar\n        ax.bar(group, data.mean(), yerr=data.std(), color=COLORS[i % len(COLORS)])\n\n    # Set the title\n    ax.set_title(f\"Bar chart of {value_col} by {group_col}\")\n\n    # Set the xlabel and ylabel\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nCOLORS = ['r', 'g', 'b']\n\ndef task_func(df, group_col, value_col):\n    # Check if columns exist in the dataframe\n    if group_col not in df.columns or value_col not in df.columns:\n        raise ValueError(\"One or both of the columns do not exist in the dataframe\")\n\n    # Check if the 'Value' has non-numeric values\n    if not pd.api.types.is_numeric_dtype(df[value_col]):\n        raise TypeError(\"The 'Value' has non-numeric values\")\n\n    # Get unique groups\n    groups = df[group_col].unique()\n\n    # Create a new figure\n    fig, ax = plt.subplots()\n\n    # Create a bar chart for each group\n    for i, group in enumerate(groups):\n        # Get the data for this group\n        data = df[df[group_col] == group][value_col]\n\n        # Create the bar\n        ax.bar(group, data.mean(), yerr=data.std(), color=COLORS[i % len(COLORS)])\n\n    # Set the title\n    ax.set_title(f\"Bar chart of {value_col} by {group_col}\")\n\n    # Set the xlabel and ylabel\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n\n    return ax"}
{"task_id": "BigCodeBench/338", "solution": "import random\nimport string\nfrom matplotlib import pyplot as plt\nfrom collections import Counter\ndef task_func(elements, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    char_counts = Counter()\n\n    for element in elements:\n        pattern = \"% \" + ''.join(random.choices(string.ascii_letters + string.digits, k=5)) + \"%\"\n        formatted_element = pattern.replace(' ', element)\n        formatted_elements.append(formatted_element)\n\n        char_counts.update(formatted_element)\n\n    # Plotting histogram\n    ax = plt.figure().gca()\n    ax.bar(char_counts.keys(), char_counts.values())\n    plt.show()\n\n    return formatted_elements, ax, char_counts\nelements = ['hello', 'world', 'this', 'is', 'a', 'test']", "raw_solution": "import random\nimport string\nfrom matplotlib import pyplot as plt\nfrom collections import Counter\n\ndef task_func(elements, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    char_counts = Counter()\n\n    for element in elements:\n        pattern = \"% \" + ''.join(random.choices(string.ascii_letters + string.digits, k=5)) + \"%\"\n        formatted_element = pattern.replace(' ', element)\n        formatted_elements.append(formatted_element)\n\n        char_counts.update(formatted_element)\n\n    # Plotting histogram\n    ax = plt.figure().gca()\n    ax.bar(char_counts.keys(), char_counts.values())\n    plt.show()\n\n    return formatted_elements, ax, char_counts\n\n# Testing the function\nelements = ['hello', 'world', 'this', 'is', 'a', 'test']\nformatted_elements, ax, char_counts = task_func(elements)\n"}
{"task_id": "BigCodeBench/339", "solution": "import json\nimport urllib.parse\nimport hmac\nimport hashlib\ndef task_func(req_data, secret_key):\n    if not isinstance(req_data, dict):\n        raise TypeError(\"req_data must be a dictionary\")\n\n    json_data = json.dumps(req_data, sort_keys=True)\n    signature = hmac.new(\n        key=secret_key.encode(),\n        msg=json_data.encode(),\n        digestmod=hashlib.sha256\n    ).hexdigest()\n\n    url_encoded_signature = urllib.parse.quote(signature.replace(' ', '+'))\n\n    return url_encoded_signature", "raw_solution": "import json\nimport urllib.parse\nimport hmac\nimport hashlib\n\ndef task_func(req_data, secret_key):\n    if not isinstance(req_data, dict):\n        raise TypeError(\"req_data must be a dictionary\")\n\n    json_data = json.dumps(req_data, sort_keys=True)\n    signature = hmac.new(\n        key=secret_key.encode(),\n        msg=json_data.encode(),\n        digestmod=hashlib.sha256\n    ).hexdigest()\n\n    url_encoded_signature = urllib.parse.quote(signature.replace(' ', '+'))\n\n    return url_encoded_signature"}
{"task_id": "BigCodeBench/340", "solution": "import json\nimport hashlib\nimport blake3\ndef task_func(req_data):\n    # Convert the request data to a JSON string\n    json_str = json.dumps(req_data)\n\n    # Hash the JSON string with BLAKE3\n    blake3_hash = blake3.hash(json_str.encode())\n\n    # Convert the BLAKE3 hash to hexadecimal\n    blake3_hex = blake3_hash.hexdigest()\n\n    # Generate an MD5 hash of the BLAKE3 hexadecimal representation\n    md5_hash = hashlib.md5(blake3_hex.encode())\n\n    # Return the BLAKE3 hexadecimal hash and the MD5 hash\n    return (blake3_hex, md5_hash.hexdigest())\nreq_data = {\"message\": \"Hello, World!\"}", "raw_solution": "import json\nimport hashlib\nimport blake3\n\ndef task_func(req_data):\n    # Convert the request data to a JSON string\n    json_str = json.dumps(req_data)\n\n    # Hash the JSON string with BLAKE3\n    blake3_hash = blake3.hash(json_str.encode())\n\n    # Convert the BLAKE3 hash to hexadecimal\n    blake3_hex = blake3_hash.hexdigest()\n\n    # Generate an MD5 hash of the BLAKE3 hexadecimal representation\n    md5_hash = hashlib.md5(blake3_hex.encode())\n\n    # Return the BLAKE3 hexadecimal hash and the MD5 hash\n    return (blake3_hex, md5_hash.hexdigest())\n\n# Test the function\nreq_data = {\"message\": \"Hello, World!\"}"}
{"task_id": "BigCodeBench/341", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"The input df must be DataFrame, not be empty\")\n    if df.empty:\n        raise ValueError(\"The input df must be DataFrame, not be empty\")\n    if col not in df.columns:\n        raise ValueError(f\"The input df must contain the specified column: {col}\")\n\n    fig, axes = plt.subplots(2, figsize=(10,10))\n\n    if df[col].dtype in ['int64', 'float64']:\n        sns.histplot(df[col], kde=True, ax=axes[0])\n    else:\n        sns.countplot(df[col], ax=axes[0])\n    axes[0].set_title(f'Histogram of {col}')\n\n    sns.boxplot(df[col], ax=axes[1])\n    axes[1].set_title(f'Box plot of {col}')\n\n    plt.tight_layout()\n    return fig", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"The input df must be DataFrame, not be empty\")\n    if df.empty:\n        raise ValueError(\"The input df must be DataFrame, not be empty\")\n    if col not in df.columns:\n        raise ValueError(f\"The input df must contain the specified column: {col}\")\n\n    fig, axes = plt.subplots(2, figsize=(10,10))\n\n    if df[col].dtype in ['int64', 'float64']:\n        sns.histplot(df[col], kde=True, ax=axes[0])\n    else:\n        sns.countplot(df[col], ax=axes[0])\n    axes[0].set_title(f'Histogram of {col}')\n\n    sns.boxplot(df[col], ax=axes[1])\n    axes[1].set_title(f'Box plot of {col}')\n\n    plt.tight_layout()\n    return fig"}
{"task_id": "BigCodeBench/342", "solution": "import string\nimport random\nimport re\ndef task_func(elements, pattern, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    for element in elements:\n        replaced_element = \"\".join(random.choice(string.ascii_letters) if char == \"%\" else char for char in element)\n        formatted_element = f\"%{replaced_element}%\"\n        formatted_elements.append(formatted_element)\n    search_result = any(re.search(pattern, fe) for fe in formatted_elements)\n    return formatted_elements, search_result\nelements = [\"%hello%\", \"world%\"]\npattern = \"\\%.*\\%\"", "raw_solution": "import string\nimport random\nimport re\n\ndef task_func(elements, pattern, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    for element in elements:\n        replaced_element = \"\".join(random.choice(string.ascii_letters) if char == \"%\" else char for char in element)\n        formatted_element = f\"%{replaced_element}%\"\n        formatted_elements.append(formatted_element)\n    search_result = any(re.search(pattern, fe) for fe in formatted_elements)\n    return formatted_elements, search_result\n\n# Test the function\nelements = [\"%hello%\", \"world%\"]\npattern = \"\\%.*\\%\"\nformatted_elements, search_result = task_func(elements, pattern)"}
{"task_id": "BigCodeBench/343", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nCOLORS = ['r', 'g', 'b', 'y', 'm']\ndef task_func(df, col, title=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be a pandas DataFrame.\")\n    if df.empty:\n        raise ValueError(\"The input DataFrame must not be empty.\")\n    if col not in df.columns:\n        raise ValueError(f\"The DataFrame does not contain the column '{col}'.\")\n\n    # Get the unique values and their counts\n    values, counts = df[col].value_counts().items()\n\n    # Create the pie chart\n    fig, ax = plt.subplots()\n    ax.pie(counts, labels=values, colors=COLORS[:len(counts)], autopct='%1.1f%%')\n    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n    if title:\n        ax.set_title(title)\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants for pie chart colors\nCOLORS = ['r', 'g', 'b', 'y', 'm']\n\ndef task_func(df, col, title=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be a pandas DataFrame.\")\n    if df.empty:\n        raise ValueError(\"The input DataFrame must not be empty.\")\n    if col not in df.columns:\n        raise ValueError(f\"The DataFrame does not contain the column '{col}'.\")\n\n    # Get the unique values and their counts\n    values, counts = df[col].value_counts().items()\n\n    # Create the pie chart\n    fig, ax = plt.subplots()\n    ax.pie(counts, labels=values, colors=COLORS[:len(counts)], autopct='%1.1f%%')\n    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n    if title:\n        ax.set_title(title)\n\n    return ax"}
{"task_id": "BigCodeBench/344", "solution": "import os\nimport shutil\ndef task_func(src_folder, backup_dir):\n    if not os.path.exists(src_folder):\n        raise ValueError(\"Source folder does not exist.\")\n\n    try:\n        shutil.make_archive(os.path.join(backup_dir, 'backup'), 'zip', src_folder)\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        return False\n\n    try:\n        shutil.rmtree(src_folder)\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        return False\n\n    return True", "raw_solution": "import os\nimport shutil\n\ndef task_func(src_folder, backup_dir):\n    if not os.path.exists(src_folder):\n        raise ValueError(\"Source folder does not exist.\")\n\n    try:\n        shutil.make_archive(os.path.join(backup_dir, 'backup'), 'zip', src_folder)\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        return False\n\n    try:\n        shutil.rmtree(src_folder)\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        return False\n\n    return True"}
{"task_id": "BigCodeBench/345", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(df, col1, col2):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    # Check if df is empty\n    if df.empty:\n        raise ValueError(\"Input df is empty\")\n    # Check if df contains the specified columns\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"Input df does not contain the specified columns\")\n    # Check if df use non-numeric data\n    if not pd.api.types.is_numeric_dtype(df[col1]) or not pd.api.types.is_numeric_dtype(df[col2]):\n        raise TypeError(\"df uses non-numeric data\")\n    # Draw a scatter plot with a regression line\n    ax = sns.regplot(x=df[col1], y=df[col2])\n    return ax", "raw_solution": "import pandas as pd\nimport seaborn as sns\n\ndef task_func(df, col1, col2):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    # Check if df is empty\n    if df.empty:\n        raise ValueError(\"Input df is empty\")\n    # Check if df contains the specified columns\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"Input df does not contain the specified columns\")\n    # Check if df use non-numeric data\n    if not pd.api.types.is_numeric_dtype(df[col1]) or not pd.api.types.is_numeric_dtype(df[col2]):\n        raise TypeError(\"df uses non-numeric data\")\n    # Draw a scatter plot with a regression line\n    ax = sns.regplot(x=df[col1], y=df[col2])\n    return ax"}
{"task_id": "BigCodeBench/346", "solution": "import subprocess\nimport os\nimport sys\nimport time\ndef task_func(script_path, wait=True, *args):\n    if not os.path.exists(script_path):\n        raise ValueError(\"The script does not exist.\")\n\n    if wait:\n        try:\n            process = subprocess.run(['python', script_path] + list(args), capture_output=True, text=True, check=True)\n            return process.returncode\n        except subprocess.CalledProcessError as e:\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output=e.output)\n    else:\n        subprocess.Popen(['python', script_path] + list(args))\n        return None", "raw_solution": "import subprocess\nimport os\nimport sys\nimport time\n\ndef task_func(script_path, wait=True, *args):\n    if not os.path.exists(script_path):\n        raise ValueError(\"The script does not exist.\")\n\n    if wait:\n        try:\n            process = subprocess.run(['python', script_path] + list(args), capture_output=True, text=True, check=True)\n            return process.returncode\n        except subprocess.CalledProcessError as e:\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output=e.output)\n    else:\n        subprocess.Popen(['python', script_path] + list(args))\n        return None\n\n# Test the function"}
{"task_id": "BigCodeBench/347", "solution": "import pandas as pd\nimport re\nimport numpy as np\nPATTERN = r\"([a-fA-F\\d]{32})\"\ndef task_func(df, column):\n    if column not in df.columns:\n        raise KeyError(f\"Column '{column}' does not exist in the DataFrame\")\n    \n    # Find all matches of the regex pattern in the column\n    matches = df[column].str.findall(PATTERN)\n\n    # Flatten the list of matches and create a Series with counts of each unique match\n    matches_series = pd.Series(np.concatenate(matches).flat).value_counts()\n\n    return matches_series", "raw_solution": "import pandas as pd\nimport re\nimport numpy as np\n\n# Constants\nPATTERN = r\"([a-fA-F\\d]{32})\"\n\ndef task_func(df, column):\n    if column not in df.columns:\n        raise KeyError(f\"Column '{column}' does not exist in the DataFrame\")\n    \n    # Find all matches of the regex pattern in the column\n    matches = df[column].str.findall(PATTERN)\n\n    # Flatten the list of matches and create a Series with counts of each unique match\n    matches_series = pd.Series(np.concatenate(matches).flat).value_counts()\n\n    return matches_series"}
{"task_id": "BigCodeBench/348", "solution": "import subprocess\nimport os\nimport signal\nimport time\ndef task_func(process_name: str) -> int:\n    # Get a list of all running processes\n    output = subprocess.Popen(\"ps -A\", shell=True, stdout=subprocess.PIPE)\n    info = output.stdout.read().decode('utf-8').strip().split('\\n')[1:]\n\n    # Filter the list to get only the processes with the given name\n    processes = [i for i in info if process_name in i]\n\n    # If no processes are found, return 0\n    if not processes:\n        return 0\n\n    # Send a termination signal to each process and wait for 1 second\n    for process in processes:\n        pid = int(process.split()[0])\n        try:\n            os.kill(pid, signal.SIGTERM)\n            time.sleep(1)\n        except:\n            pass\n\n    # Return the number of processes stopped\n    return len(processes)", "raw_solution": "import subprocess\nimport os\nimport signal\nimport time\n\ndef task_func(process_name: str) -> int:\n    # Get a list of all running processes\n    output = subprocess.Popen(\"ps -A\", shell=True, stdout=subprocess.PIPE)\n    info = output.stdout.read().decode('utf-8').strip().split('\\n')[1:]\n\n    # Filter the list to get only the processes with the given name\n    processes = [i for i in info if process_name in i]\n\n    # If no processes are found, return 0\n    if not processes:\n        return 0\n\n    # Send a termination signal to each process and wait for 1 second\n    for process in processes:\n        pid = int(process.split()[0])\n        try:\n            os.kill(pid, signal.SIGTERM)\n            time.sleep(1)\n        except:\n            pass\n\n    # Return the number of processes stopped\n    return len(processes)"}
{"task_id": "BigCodeBench/349", "solution": "import pandas as pd\nimport random\ndef task_func(product_list, categories):\n    data = {'Product': [], 'Category': [], 'Quantity Sold': [], 'Revenue': []}\n    for i in range(len(product_list)):\n        data['Product'].append(product_list[i])\n        data['Category'].append(categories[i % len(categories)])  # Repeat categories if necessary\n        quantity_sold = random.randint(1, 100)\n        data['Quantity Sold'].append(quantity_sold)\n        data['Revenue'].append(quantity_sold * random.randint(10, 100))\n    df = pd.DataFrame(data)\n    return df\nproduct_list = ['Product 1', 'Product 2', 'Product 3', 'Product 4', 'Product 5']\ncategories = ['Category 1', 'Category 2', 'Category 3']", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(product_list, categories):\n    data = {'Product': [], 'Category': [], 'Quantity Sold': [], 'Revenue': []}\n    for i in range(len(product_list)):\n        data['Product'].append(product_list[i])\n        data['Category'].append(categories[i % len(categories)])  # Repeat categories if necessary\n        quantity_sold = random.randint(1, 100)\n        data['Quantity Sold'].append(quantity_sold)\n        data['Revenue'].append(quantity_sold * random.randint(10, 100))\n    df = pd.DataFrame(data)\n    return df\n\n# Test the function\nproduct_list = ['Product 1', 'Product 2', 'Product 3', 'Product 4', 'Product 5']\ncategories = ['Category 1', 'Category 2', 'Category 3']\ndf = task_func(product_list, categories)"}
{"task_id": "BigCodeBench/350", "solution": "import subprocess\nimport os\nimport shutil\nfrom glob import glob\ndef task_func(src_folder, dst_folder):\n    if not os.path.exists(src_folder):\n        return {'success': False, 'message': f'Source folder {src_folder} does not exist.', 'failed_files': []}\n\n    if not os.path.exists(dst_folder):\n        return {'success': False, 'message': f'Destination folder {dst_folder} does not exist.', 'failed_files': []}\n\n    failed_files = []\n    for file in glob(os.path.join(src_folder, '*')):\n        if os.path.isfile(file):\n            try:\n                # Compress the file using gzip\n                subprocess.run(['gzip', file], check=True)\n\n                # Move the compressed file to the destination folder\n                shutil.move(file + '.gz', dst_folder)\n            except Exception as e:\n                failed_files.append(file)\n\n    success = len(failed_files) == 0\n    message = 'All files were compressed and moved successfully.' if success else 'Some files failed to compress or move.'\n\n    return {'success': success, 'message': message, 'failed_files': failed_files}", "raw_solution": "import subprocess\nimport os\nimport shutil\nfrom glob import glob\n\ndef task_func(src_folder, dst_folder):\n    if not os.path.exists(src_folder):\n        return {'success': False, 'message': f'Source folder {src_folder} does not exist.', 'failed_files': []}\n\n    if not os.path.exists(dst_folder):\n        return {'success': False, 'message': f'Destination folder {dst_folder} does not exist.', 'failed_files': []}\n\n    failed_files = []\n    for file in glob(os.path.join(src_folder, '*')):\n        if os.path.isfile(file):\n            try:\n                # Compress the file using gzip\n                subprocess.run(['gzip', file], check=True)\n\n                # Move the compressed file to the destination folder\n                shutil.move(file + '.gz', dst_folder)\n            except Exception as e:\n                failed_files.append(file)\n\n    success = len(failed_files) == 0\n    message = 'All files were compressed and moved successfully.' if success else 'Some files failed to compress or move.'\n\n    return {'success': success, 'message': message, 'failed_files': failed_files}"}
{"task_id": "BigCodeBench/351", "solution": "import pandas as pd\nimport random\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    data = {'Product': [], 'Category': [], 'Quantity Sold': [], 'Revenue': []}\n    for category in categories:\n        for product in product_list:\n            quantity_sold = random.randint(min_value, max_value)\n            revenue = quantity_sold * random.randint(min_value, max_value)\n            data['Product'].append(product)\n            data['Category'].append(category)\n            data['Quantity Sold'].append(quantity_sold)\n            data['Revenue'].append(revenue)\n    df = pd.DataFrame(data)\n    return df\nproduct_list = ['Product1', 'Product2', 'Product3']\ncategories = ['Category1', 'Category2', 'Category3']", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    data = {'Product': [], 'Category': [], 'Quantity Sold': [], 'Revenue': []}\n    for category in categories:\n        for product in product_list:\n            quantity_sold = random.randint(min_value, max_value)\n            revenue = quantity_sold * random.randint(min_value, max_value)\n            data['Product'].append(product)\n            data['Category'].append(category)\n            data['Quantity Sold'].append(quantity_sold)\n            data['Revenue'].append(revenue)\n    df = pd.DataFrame(data)\n    return df\n\n# Test the function\nproduct_list = ['Product1', 'Product2', 'Product3']\ncategories = ['Category1', 'Category2', 'Category3']\ndf = task_func(product_list, categories)"}
{"task_id": "BigCodeBench/352", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nfrom collections import Counter\ndef task_func(text_dict, word_keys, top_k=2):\n    if top_k < 0:\n        raise ValueError(\"top_k cannot be a negative integer\")\n\n    # Create a Counter object from the text_dict\n    counter = Counter(text_dict)\n\n    # Get the frequencies of the words in word_keys\n    word_freqs = {word: counter[word] for word in word_keys}\n\n    # Create a DataFrame from the word_freqs dictionary\n    df = pd.DataFrame(list(word_freqs.items()), columns=['Word', 'Frequency'])\n\n    # Sort the DataFrame by frequency in descending order\n    df = df.sort_values(by='Frequency', ascending=False)\n\n    # Get the top_k most common words\n    top_words = df.head(top_k)\n\n    # Create a bar chart of the top_k most common words\n    ax = top_words.plot(kind='bar', x='Word', y='Frequency', legend=False)\n\n    return ax, word_freqs", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nfrom collections import Counter\n\ndef task_func(text_dict, word_keys, top_k=2):\n    if top_k < 0:\n        raise ValueError(\"top_k cannot be a negative integer\")\n\n    # Create a Counter object from the text_dict\n    counter = Counter(text_dict)\n\n    # Get the frequencies of the words in word_keys\n    word_freqs = {word: counter[word] for word in word_keys}\n\n    # Create a DataFrame from the word_freqs dictionary\n    df = pd.DataFrame(list(word_freqs.items()), columns=['Word', 'Frequency'])\n\n    # Sort the DataFrame by frequency in descending order\n    df = df.sort_values(by='Frequency', ascending=False)\n\n    # Get the top_k most common words\n    top_words = df.head(top_k)\n\n    # Create a bar chart of the top_k most common words\n    ax = top_words.plot(kind='bar', x='Word', y='Frequency', legend=False)\n\n    return ax, word_freqs"}
{"task_id": "BigCodeBench/353", "solution": "import pandas as pd\nimport random\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    data = {'Product': [], 'Category': [], 'Quantity Sold': [], 'Revenue': [], 'Total Revenue': []}\n    for product in product_list:\n        for category in categories:\n            quantity_sold = random.randint(min_value, max_value)\n            revenue = round(random.uniform(min_value, max_value), 2)\n            total_revenue = round(quantity_sold * revenue, 2)\n            data['Product'].append(product)\n            data['Category'].append(category)\n            data['Quantity Sold'].append(quantity_sold)\n            data['Revenue'].append(revenue)\n            data['Total Revenue'].append(total_revenue)\n    df = pd.DataFrame(data)\n    return df\nproduct_list = ['Product1', 'Product2', 'Product3']\ncategories = ['Category1', 'Category2', 'Category3']", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    data = {'Product': [], 'Category': [], 'Quantity Sold': [], 'Revenue': [], 'Total Revenue': []}\n    for product in product_list:\n        for category in categories:\n            quantity_sold = random.randint(min_value, max_value)\n            revenue = round(random.uniform(min_value, max_value), 2)\n            total_revenue = round(quantity_sold * revenue, 2)\n            data['Product'].append(product)\n            data['Category'].append(category)\n            data['Quantity Sold'].append(quantity_sold)\n            data['Revenue'].append(revenue)\n            data['Total Revenue'].append(total_revenue)\n    df = pd.DataFrame(data)\n    return df\n\n# Test the function\nproduct_list = ['Product1', 'Product2', 'Product3']\ncategories = ['Category1', 'Category2', 'Category3']\ndf = task_func(product_list, categories)"}
{"task_id": "BigCodeBench/354", "solution": "import collections\nimport matplotlib.pyplot as plt\nimport pandas as pd\nWORDS = ['the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have', 'I']\ndef task_func(sentences_dict, word_keys):\n    word_counts = collections.defaultdict(int)\n    for key in word_keys:\n        if key in sentences_dict:\n            words = sentences_dict[key].split()\n            for word in words:\n                word_counts[word.lower()] += 1\n    df = pd.DataFrame(list(word_counts.items()), columns=['Word', 'Frequency'])\n    df = df[df['Word'].isin(WORDS)]\n    df.plot(x='Word', y='Frequency', kind='bar', legend=False)\n    plt.ylabel('Frequency')\n    plt.title('Frequency of Words in Sentences')\n    return plt.gca()\nsentences_dict = {\n    'sentence1': 'The sun sets in the east',\n    'sentence2': 'Beatiful is the night',\n    'sentence3': 'To err is human',\n    'sentence4': 'Of all things I like apples',\n    'sentence5': 'That is the way'\n}\nword_keys = ['sentence1', 'sentence2', 'sentence3', 'sentence4', 'sentence5']", "raw_solution": "import collections\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nWORDS = ['the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have', 'I']\n\ndef task_func(sentences_dict, word_keys):\n    word_counts = collections.defaultdict(int)\n    for key in word_keys:\n        if key in sentences_dict:\n            words = sentences_dict[key].split()\n            for word in words:\n                word_counts[word.lower()] += 1\n    df = pd.DataFrame(list(word_counts.items()), columns=['Word', 'Frequency'])\n    df = df[df['Word'].isin(WORDS)]\n    df.plot(x='Word', y='Frequency', kind='bar', legend=False)\n    plt.ylabel('Frequency')\n    plt.title('Frequency of Words in Sentences')\n    return plt.gca()\n\n# Test the function\nsentences_dict = {\n    'sentence1': 'The sun sets in the east',\n    'sentence2': 'Beatiful is the night',\n    'sentence3': 'To err is human',\n    'sentence4': 'Of all things I like apples',\n    'sentence5': 'That is the way'\n}\n\nword_keys = ['sentence1', 'sentence2', 'sentence3', 'sentence4', 'sentence5']\nax = task_func(sentences_dict, word_keys)\nplt.show()"}
{"task_id": "BigCodeBench/355", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import get_window\ndef task_func(amplitude, frequency, time):\n    # Generate the complex wave\n    complex_wave = amplitude * np.exp(2j * np.pi * frequency * time)\n\n    # Apply a Hann window\n    window = get_window('hann', len(time))\n    complex_wave_windowed = complex_wave * window\n\n    # Create the plot\n    fig, ax = plt.subplots()\n    ax.plot(time, np.real(complex_wave_windowed), label='Real')\n    ax.plot(time, np.imag(complex_wave_windowed), label='Imaginary')\n    ax.set_title('Complex Wave with Hann Window')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n    ax.legend()\n\n    return complex_wave, fig, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import get_window\n\ndef task_func(amplitude, frequency, time):\n    # Generate the complex wave\n    complex_wave = amplitude * np.exp(2j * np.pi * frequency * time)\n\n    # Apply a Hann window\n    window = get_window('hann', len(time))\n    complex_wave_windowed = complex_wave * window\n\n    # Create the plot\n    fig, ax = plt.subplots()\n    ax.plot(time, np.real(complex_wave_windowed), label='Real')\n    ax.plot(time, np.imag(complex_wave_windowed), label='Imaginary')\n    ax.set_title('Complex Wave with Hann Window')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n    ax.legend()\n\n    return complex_wave, fig, ax"}
{"task_id": "BigCodeBench/356", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport cmath\ndef task_func(x, y):\n    # Check if x and y are numpy.ndarray\n    if not isinstance(x, np.ndarray) or not isinstance(y, np.ndarray):\n        raise TypeError(\"Both x and y should be numpy.ndarray\")\n\n    # Check if x and y have the same length\n    if len(x) != len(y):\n        raise ValueError(\"x and y should have the same length\")\n\n    # Calculate phase values\n    phase_values = np.angle(x + y*1j)\n\n    # Create a figure and an axes\n    fig, ax = plt.subplots()\n\n    # Plot phase values\n    cax = ax.imshow(phase_values, extent=[np.min(x), np.max(x), np.min(y), np.max(y)])\n    fig.colorbar(cax)\n\n    return ax, phase_values", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport cmath\n\ndef task_func(x, y):\n    # Check if x and y are numpy.ndarray\n    if not isinstance(x, np.ndarray) or not isinstance(y, np.ndarray):\n        raise TypeError(\"Both x and y should be numpy.ndarray\")\n\n    # Check if x and y have the same length\n    if len(x) != len(y):\n        raise ValueError(\"x and y should have the same length\")\n\n    # Calculate phase values\n    phase_values = np.angle(x + y*1j)\n\n    # Create a figure and an axes\n    fig, ax = plt.subplots()\n\n    # Plot phase values\n    cax = ax.imshow(phase_values, extent=[np.min(x), np.max(x), np.min(y), np.max(y)])\n    fig.colorbar(cax)\n\n    return ax, phase_values"}
{"task_id": "BigCodeBench/357", "solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(x):\n    if not isinstance(x, np.ndarray):\n        raise TypeError(\"Input x should be a numpy.ndarray\")\n\n    real_part = norm.rvs(loc=0, scale=1, size=x.shape[0])\n    imag_part = norm.rvs(loc=2, scale=2, size=x.shape[0])\n    complex_distribution = real_part + imag_part * 1j\n\n    plt.figure(figsize=(10, 6))\n    plt.hist(complex_distribution.real, bins=30, density=True, alpha=0.6, color='b', label='Real part')\n    plt.hist(complex_distribution.imag, bins=30, density=True, alpha=0.6, color='r', label='Imaginary part')\n    plt.legend(loc='upper right')\n    plt.show()\n\n    return complex_distribution\nx = np.linspace(-10, 10, 1000)", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(x):\n    if not isinstance(x, np.ndarray):\n        raise TypeError(\"Input x should be a numpy.ndarray\")\n\n    real_part = norm.rvs(loc=0, scale=1, size=x.shape[0])\n    imag_part = norm.rvs(loc=2, scale=2, size=x.shape[0])\n    complex_distribution = real_part + imag_part * 1j\n\n    plt.figure(figsize=(10, 6))\n    plt.hist(complex_distribution.real, bins=30, density=True, alpha=0.6, color='b', label='Real part')\n    plt.hist(complex_distribution.imag, bins=30, density=True, alpha=0.6, color='r', label='Imaginary part')\n    plt.legend(loc='upper right')\n    plt.show()\n\n    return complex_distribution\n\n# Test the function\nx = np.linspace(-10, 10, 1000)\ntry:\n    result = task_func(x)\n    print(f\"The type of result is: {type(result)}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")"}
{"task_id": "BigCodeBench/358", "solution": "import itertools\nimport json\ndef task_func(json_list, r):\n    try:\n        data = json.loads(json_list)\n        if 'number_list' not in data:\n            raise Exception(\"'number_list' key not found in JSON data\")\n        number_list = data['number_list']\n        if not number_list:\n            raise Exception(\"'number_list' is empty\")\n        return list(itertools.combinations(number_list, r))\n    except json.JSONDecodeError:\n        raise Exception(\"Invalid JSON\")\nr = 2", "raw_solution": "import itertools\nimport json\n\ndef task_func(json_list, r):\n    try:\n        data = json.loads(json_list)\n        if 'number_list' not in data:\n            raise Exception(\"'number_list' key not found in JSON data\")\n        number_list = data['number_list']\n        if not number_list:\n            raise Exception(\"'number_list' is empty\")\n        return list(itertools.combinations(number_list, r))\n    except json.JSONDecodeError:\n        raise Exception(\"Invalid JSON\")\n\n# Test the function\njson_data = '{\"number_list\": [1, 2, 3, 4]}'\nr = 2"}
{"task_id": "BigCodeBench/359", "solution": "from scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(data_dict, data_keys):\n    if len(data_keys) != 2:\n        raise ValueError(\"Exactly two data series are required\")\n    if not all(key in data_dict.keys() for key in data_keys):\n        raise ValueError(\"All keys must be in the data dictionary\")\n    \n    data1 = data_dict[data_keys[0]]\n    data2 = data_dict[data_keys[1]]\n    \n    if len(data1) != len(data2):\n        raise ValueError(\"Both data series must have the same length\")\n    \n    correlation, _ = stats.pearsonr(data1, data2)\n    \n    fig, ax = plt.subplots()\n    ax.scatter(data1, data2)\n    ax.set_xlabel(data_keys[0])\n    ax.set_ylabel(data_keys[1])\n    ax.set_title(f\"Scatter plot of {data_keys[0]} and {data_keys[1]}\\nCorrelation: {correlation:.2f}\")\n    \n    return correlation, ax.figure", "raw_solution": "from scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict, data_keys):\n    if len(data_keys) != 2:\n        raise ValueError(\"Exactly two data series are required\")\n    if not all(key in data_dict.keys() for key in data_keys):\n        raise ValueError(\"All keys must be in the data dictionary\")\n    \n    data1 = data_dict[data_keys[0]]\n    data2 = data_dict[data_keys[1]]\n    \n    if len(data1) != len(data2):\n        raise ValueError(\"Both data series must have the same length\")\n    \n    correlation, _ = stats.pearsonr(data1, data2)\n    \n    fig, ax = plt.subplots()\n    ax.scatter(data1, data2)\n    ax.set_xlabel(data_keys[0])\n    ax.set_ylabel(data_keys[1])\n    ax.set_title(f\"Scatter plot of {data_keys[0]} and {data_keys[1]}\\nCorrelation: {correlation:.2f}\")\n    \n    return correlation, ax.figure"}
{"task_id": "BigCodeBench/360", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(file_location, sheet_name):\n    # Check if file exists\n    if not os.path.isfile(file_location):\n        raise FileNotFoundError(\"The specified file does not exist.\")\n\n    # Load data from Excel\n    try:\n        data = pd.read_excel(file_location, sheet_name=sheet_name)\n    except ValueError:\n        raise ValueError(\"The specified sheet does not exist in the workbook.\")\n\n    # Calculate mean and standard deviation\n    stats_dict = data.agg(['mean', 'std']).to_dict()\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    ax.bar(range(len(stats_dict['mean'])), stats_dict['mean'].values(), tick_label=stats_dict['mean'].keys())\n    ax.set_title('Mean and Standard Deviation')\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Values')\n\n    return stats_dict, fig", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(file_location, sheet_name):\n    # Check if file exists\n    if not os.path.isfile(file_location):\n        raise FileNotFoundError(\"The specified file does not exist.\")\n\n    # Load data from Excel\n    try:\n        data = pd.read_excel(file_location, sheet_name=sheet_name)\n    except ValueError:\n        raise ValueError(\"The specified sheet does not exist in the workbook.\")\n\n    # Calculate mean and standard deviation\n    stats_dict = data.agg(['mean', 'std']).to_dict()\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    ax.bar(range(len(stats_dict['mean'])), stats_dict['mean'].values(), tick_label=stats_dict['mean'].keys())\n    ax.set_title('Mean and Standard Deviation')\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Values')\n\n    return stats_dict, fig"}
{"task_id": "BigCodeBench/361", "solution": "import pandas as pd\nimport logging\ndef task_func(sheet_name, excel_file_location=\"test.xlsx\", csv_file_location=\"test.csv\"):\n    try:\n        # Read data from Excel file\n        df = pd.read_excel(excel_file_location, sheet_name=sheet_name)\n    except FileNotFoundError:\n        logging.error(f\"Excel file {excel_file_location} does not exist.\")\n        return\n    except ValueError:\n        logging.error(f\"Sheet {sheet_name} not found in the Excel file {excel_file_location}.\")\n        return\n\n    # Convert data to CSV file\n    df.to_csv(csv_file_location, index=False)\n    logging.info(f\"Data saved to CSV file {csv_file_location}.\")\n\n    # Calculate sum of each column\n    column_sums = df.sum().to_dict()\n\n    return column_sums", "raw_solution": "import pandas as pd\nimport logging\n\n# Set up basic configuration for logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\ndef task_func(sheet_name, excel_file_location=\"test.xlsx\", csv_file_location=\"test.csv\"):\n    try:\n        # Read data from Excel file\n        df = pd.read_excel(excel_file_location, sheet_name=sheet_name)\n    except FileNotFoundError:\n        logging.error(f\"Excel file {excel_file_location} does not exist.\")\n        return\n    except ValueError:\n        logging.error(f\"Sheet {sheet_name} not found in the Excel file {excel_file_location}.\")\n        return\n\n    # Convert data to CSV file\n    df.to_csv(csv_file_location, index=False)\n    logging.info(f\"Data saved to CSV file {csv_file_location}.\")\n\n    # Calculate sum of each column\n    column_sums = df.sum().to_dict()\n\n    return column_sums"}
{"task_id": "BigCodeBench/362", "solution": "import pandas as pd\nimport os\ndef task_func(original_file_location=\"test.xlsx\", new_file_location=\"new_test.xlsx\", sheet_name=\"Sheet1\"):\n    # Check if original file exists\n    if not os.path.isfile(original_file_location):\n        raise FileNotFoundError(f\"The file {original_file_location} does not exist.\")\n\n    # Copy data from original file to new file\n    try:\n        reader = pd.ExcelFile(original_file_location)\n        sheets = reader.sheet_names\n        if sheet_name not in sheets:\n            raise ValueError(f\"The sheet {sheet_name} does not exist in the workbook.\")\n        df = reader.parse(sheet_name)\n        df.to_excel(new_file_location, index=False)\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None\n\n    # Read new file\n    try:\n        df = pd.read_excel(new_file_location)\n        return df\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None", "raw_solution": "import pandas as pd\nimport os\n\ndef task_func(original_file_location=\"test.xlsx\", new_file_location=\"new_test.xlsx\", sheet_name=\"Sheet1\"):\n    # Check if original file exists\n    if not os.path.isfile(original_file_location):\n        raise FileNotFoundError(f\"The file {original_file_location} does not exist.\")\n\n    # Copy data from original file to new file\n    try:\n        reader = pd.ExcelFile(original_file_location)\n        sheets = reader.sheet_names\n        if sheet_name not in sheets:\n            raise ValueError(f\"The sheet {sheet_name} does not exist in the workbook.\")\n        df = reader.parse(sheet_name)\n        df.to_excel(new_file_location, index=False)\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None\n\n    # Read new file\n    try:\n        df = pd.read_excel(new_file_location)\n        return df\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None\n\n# Test the function\ndf = task_func(original_file_location=\"test.xlsx\", new_file_location=\"new_test.xlsx\", sheet_name=\"Sheet1\")\nif df is not None:\n    print(df)"}
{"task_id": "BigCodeBench/363", "solution": "from multiprocessing import Pool\nimport math\ndef calculate_factorial(number: int) -> tuple:\n    if not isinstance(number, int) or number < 0:\n        raise ValueError(\"Input must be a non-negative integer\")\n    return number, math.factorial(number)\ndef task_func(numbers: list) -> dict:\n    with Pool(processes=len(numbers)) as pool:\n        result = pool.map(calculate_factorial, numbers)\n    return dict(result)\nnumbers = [1, 5, 10]", "raw_solution": "from multiprocessing import Pool\nimport math\n\ndef calculate_factorial(number: int) -> tuple:\n    if not isinstance(number, int) or number < 0:\n        raise ValueError(\"Input must be a non-negative integer\")\n    return number, math.factorial(number)\n\ndef task_func(numbers: list) -> dict:\n    with Pool(processes=len(numbers)) as pool:\n        result = pool.map(calculate_factorial, numbers)\n    return dict(result)\n\n# Testing\nnumbers = [1, 5, 10]"}
{"task_id": "BigCodeBench/364", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nFEATURES = ['feature '+str(i) for i in range(1, 11)]\nTARGET = 'target'\ndef task_func(df):\n    # Check if input is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    # Split the data into features and target\n    X = df[FEATURES]\n    y = df[TARGET]\n\n    # Train the Linear Regression model\n    lr = LinearRegression()\n    lr.fit(X, y)\n\n    return lr", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# Constants\nFEATURES = ['feature '+str(i) for i in range(1, 11)]\nTARGET = 'target'\n\ndef task_func(df):\n    # Check if input is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n\n    # Split the data into features and target\n    X = df[FEATURES]\n    y = df[TARGET]\n\n    # Train the Linear Regression model\n    lr = LinearRegression()\n    lr.fit(X, y)\n\n    return lr"}
{"task_id": "BigCodeBench/365", "solution": "from collections import Counter\nimport json\nimport random\nWORDS = ['apple', 'banana', 'cherry', 'date', 'elderberry', 'fig', 'grape', 'honeydew']\ndef task_func(n, file_name, seed=77):\n    # Set the seed for the random number generator\n    random.seed(seed)\n\n    # Select n random words from the list\n    selected_words = random.sample(WORDS, n)\n\n    # Write the selected words to a json file\n    with open(file_name, 'w') as f:\n        json.dump(selected_words, f)\n\n    # Return the name of the json file\n    return file_name", "raw_solution": "from collections import Counter\nimport json\nimport random\n\n# Constants\nWORDS = ['apple', 'banana', 'cherry', 'date', 'elderberry', 'fig', 'grape', 'honeydew']\n\ndef task_func(n, file_name, seed=77):\n    # Set the seed for the random number generator\n    random.seed(seed)\n\n    # Select n random words from the list\n    selected_words = random.sample(WORDS, n)\n\n    # Write the selected words to a json file\n    with open(file_name, 'w') as f:\n        json.dump(selected_words, f)\n\n    # Return the name of the json file\n    return file_name\n\n# Test the function"}
{"task_id": "BigCodeBench/366", "solution": "import matplotlib.pyplot as plt\nimport random\nCOLORS = ['#00bfbf', '#000000', '#0000ff']\ndef task_func(number_list, bins):\n    # Generate a histogram subplot of a list of numbers\n    fig, ax = plt.subplots()\n    ax.hist(number_list, bins=bins, color=random.choice(COLORS))\n\n    # Set plot title, x-axis label, and y-axis label\n    ax.set_title('Histogram')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n\n    return ax\nnumbers = [random.randint(1, 100) for _ in range(1000)]", "raw_solution": "import matplotlib.pyplot as plt\nimport random\n\n# Constants\nCOLORS = ['#00bfbf', '#000000', '#0000ff']\n\ndef task_func(number_list, bins):\n    # Generate a histogram subplot of a list of numbers\n    fig, ax = plt.subplots()\n    ax.hist(number_list, bins=bins, color=random.choice(COLORS))\n\n    # Set plot title, x-axis label, and y-axis label\n    ax.set_title('Histogram')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n\n    return ax\n\n# Test the function\nnumbers = [random.randint(1, 100) for _ in range(1000)]\nax = task_func(numbers, 10)\nplt.show()"}
{"task_id": "BigCodeBench/367", "solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\ndef task_func(activities):\n    if not all(isinstance(i, datetime) for i in activities):\n        raise TypeError(\"All elements in the list must be datetime objects\")\n\n    day_counts = defaultdict(int)\n    for activity in activities:\n        day_counts[activity.strftime('%A')] += 1\n\n    days = list(day_counts.keys())\n    counts = list(day_counts.values())\n\n    fig, ax = plt.subplots()\n    ax.bar(days, counts)\n    ax.set_xlabel('Day of the Week')\n    ax.set_ylabel('Number of Activities')\n    ax.set_title('Weekly Activity')\n\n    return ax", "raw_solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef task_func(activities):\n    if not all(isinstance(i, datetime) for i in activities):\n        raise TypeError(\"All elements in the list must be datetime objects\")\n\n    day_counts = defaultdict(int)\n    for activity in activities:\n        day_counts[activity.strftime('%A')] += 1\n\n    days = list(day_counts.keys())\n    counts = list(day_counts.values())\n\n    fig, ax = plt.subplots()\n    ax.bar(days, counts)\n    ax.set_xlabel('Day of the Week')\n    ax.set_ylabel('Number of Activities')\n    ax.set_title('Weekly Activity')\n\n    return ax"}
{"task_id": "BigCodeBench/368", "solution": "import os\nimport shutil\nimport random\ndef task_func(src_dir: str, dest_dir: str, seed:int = 100) -> str:\n    # Seed the random number generator\n    random.seed(seed)\n\n    # Check if source directory exists\n    if not os.path.isdir(src_dir):\n        raise ValueError(f\"Source directory {src_dir} does not exist.\")\n\n    # Check if destination directory exists\n    if not os.path.isdir(dest_dir):\n        raise ValueError(f\"Destination directory {dest_dir} does not exist.\")\n\n    # Get a list of files in the source directory\n    files = os.listdir(src_dir)\n\n    # If there are no files in the source directory, raise an error\n    if not files:\n        raise ValueError(f\"Source directory {src_dir} is empty.\")\n\n    # Select a random file\n    file = random.choice(files)\n\n    # Construct the full path to the file\n    src_file_path = os.path.join(src_dir, file)\n\n    # Construct the full path to the destination directory\n    dest_file_path = os.path.join(dest_dir, file)\n\n    # Move the file\n    shutil.move(src_file_path, dest_file_path)\n\n    # Return the name of the file\n    return file", "raw_solution": "import os\nimport shutil\nimport random\n\ndef task_func(src_dir: str, dest_dir: str, seed:int = 100) -> str:\n    # Seed the random number generator\n    random.seed(seed)\n\n    # Check if source directory exists\n    if not os.path.isdir(src_dir):\n        raise ValueError(f\"Source directory {src_dir} does not exist.\")\n\n    # Check if destination directory exists\n    if not os.path.isdir(dest_dir):\n        raise ValueError(f\"Destination directory {dest_dir} does not exist.\")\n\n    # Get a list of files in the source directory\n    files = os.listdir(src_dir)\n\n    # If there are no files in the source directory, raise an error\n    if not files:\n        raise ValueError(f\"Source directory {src_dir} is empty.\")\n\n    # Select a random file\n    file = random.choice(files)\n\n    # Construct the full path to the file\n    src_file_path = os.path.join(src_dir, file)\n\n    # Construct the full path to the destination directory\n    dest_file_path = os.path.join(dest_dir, file)\n\n    # Move the file\n    shutil.move(src_file_path, dest_file_path)\n\n    # Return the name of the file\n    return file"}
{"task_id": "BigCodeBench/369", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(l):\n    # Convert list to numpy array\n    arr = np.array(l)\n\n    # Calculate mean and standard deviation\n    mu, std = stats.norm.fit(arr)\n\n    # Create histogram\n    plt.hist(arr, bins='auto', alpha=0.7, rwidth=0.85, color='#003f5c', density=True)\n\n    # Generate x values for the fitted line\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n\n    # Generate y values for the fitted line\n    p = stats.norm.pdf(x, mu, std)\n\n    # Plot the fitted line\n    plt.plot(x, p, 'k', linewidth=2)\n\n    # Set title\n    title = \"Fit results: mu = {:.2f},  std = {:.2f}\".format(mu, std)\n    plt.title(title)\n\n    return plt.gca()\nl = [1, 2, 2, 3, 4, 4, 4, 5, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 9, 9]", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(l):\n    # Convert list to numpy array\n    arr = np.array(l)\n\n    # Calculate mean and standard deviation\n    mu, std = stats.norm.fit(arr)\n\n    # Create histogram\n    plt.hist(arr, bins='auto', alpha=0.7, rwidth=0.85, color='#003f5c', density=True)\n\n    # Generate x values for the fitted line\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n\n    # Generate y values for the fitted line\n    p = stats.norm.pdf(x, mu, std)\n\n    # Plot the fitted line\n    plt.plot(x, p, 'k', linewidth=2)\n\n    # Set title\n    title = \"Fit results: mu = {:.2f},  std = {:.2f}\".format(mu, std)\n    plt.title(title)\n\n    return plt.gca()\n\n# Test the function\nl = [1, 2, 2, 3, 4, 4, 4, 5, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 9, 9]\nax = task_func(l)\nplt.show()"}
{"task_id": "BigCodeBench/370", "solution": "import os\nimport re\nimport json\nimport glob\ndef task_func(directory_path: str) -> list:\n    if not os.path.exists(directory_path):\n        raise FileNotFoundError(f\"The specified directory {directory_path} does not exist.\")\n\n    json_files = glob.glob(os.path.join(directory_path, \"*.json\"))\n    processed_files = []\n\n    for json_file in json_files:\n        with open(json_file, 'r') as file:\n            data = json.load(file)\n\n        # Convert the data to a string and escape double quotes\n        data_str = json.dumps(data).replace('\"', '\\\\\"')\n\n        with open(json_file, 'w') as file:\n            file.write(data_str)\n\n        processed_files.append(json_file)\n\n    return processed_files", "raw_solution": "import os\nimport re\nimport json\nimport glob\n\ndef task_func(directory_path: str) -> list:\n    if not os.path.exists(directory_path):\n        raise FileNotFoundError(f\"The specified directory {directory_path} does not exist.\")\n\n    json_files = glob.glob(os.path.join(directory_path, \"*.json\"))\n    processed_files = []\n\n    for json_file in json_files:\n        with open(json_file, 'r') as file:\n            data = json.load(file)\n\n        # Convert the data to a string and escape double quotes\n        data_str = json.dumps(data).replace('\"', '\\\\\"')\n\n        with open(json_file, 'w') as file:\n            file.write(data_str)\n\n        processed_files.append(json_file)\n\n    return processed_files"}
{"task_id": "BigCodeBench/371", "solution": "from sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\ndef task_func(l):\n    # Convert the list to a numpy array\n    l = np.array(l).reshape(-1, 1)\n    \n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n    \n    # Fit and transform the data\n    l_scaled = scaler.fit_transform(l)\n    \n    # Create a pandas DataFrame\n    df = pd.DataFrame(l_scaled, columns=['Scaled Values'])\n    \n    return df", "raw_solution": "from sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndef task_func(l):\n    # Convert the list to a numpy array\n    l = np.array(l).reshape(-1, 1)\n    \n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n    \n    # Fit and transform the data\n    l_scaled = scaler.fit_transform(l)\n    \n    # Create a pandas DataFrame\n    df = pd.DataFrame(l_scaled, columns=['Scaled Values'])\n    \n    return df"}
{"task_id": "BigCodeBench/372", "solution": "import re\nimport glob\nfrom docx import Document\ndef task_func(directory_path: str) -> int:\n    # Get all .docx files in the directory\n    docx_files = glob.glob(directory_path + '/**/*.docx', recursive=True)\n\n    # Initialize counter\n    count = 0\n\n    # Process each .docx file\n    for file in docx_files:\n        # Open the document\n        doc = Document(file)\n\n        # Process each paragraph in the document\n        for para in doc.paragraphs:\n            # If the paragraph contains a double quote, add a backslash before it\n            para.text = re.sub(r'\"', r'\\\\\"', para.text)\n\n        # Save the document\n        doc.save(file)\n\n        # Increment the counter\n        count += 1\n\n    # Return the number of .docx files processed\n    return count", "raw_solution": "import re\nimport glob\nfrom docx import Document\n\ndef task_func(directory_path: str) -> int:\n    # Get all .docx files in the directory\n    docx_files = glob.glob(directory_path + '/**/*.docx', recursive=True)\n\n    # Initialize counter\n    count = 0\n\n    # Process each .docx file\n    for file in docx_files:\n        # Open the document\n        doc = Document(file)\n\n        # Process each paragraph in the document\n        for para in doc.paragraphs:\n            # If the paragraph contains a double quote, add a backslash before it\n            para.text = re.sub(r'\"', r'\\\\\"', para.text)\n\n        # Save the document\n        doc.save(file)\n\n        # Increment the counter\n        count += 1\n\n    # Return the number of .docx files processed\n    return count"}
{"task_id": "BigCodeBench/373", "solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(x_data, plot=False):\n    # Define the quadratic function\n    def func(x, a, b, c):\n        return a * x**2 + b * x + c\n\n    # Define the initial guess for the parameters\n    p0 = [1, 1, 1]\n\n    # Perform the curve fitting\n    popt, _ = curve_fit(func, x_data, y_data, p0)\n\n    # Generate the fitted values\n    fitted_values = func(x_data, *popt)\n\n    if plot:\n        # Plot the original data\n        plt.scatter(x_data, y_data, color='red', label='Original data')\n\n        # Plot the fitted curve\n        plt.plot(x_data, fitted_values, color='blue', label='Fitted curve')\n\n        plt.legend()\n        plt.show()\n\n        return popt, fitted_values, plt.gca()\n    else:\n        return popt, fitted_values\nx_data = np.linspace(-10, 10, 50)\ny_data = x_data**2 + 2*x_data + 1 + np.random.normal(0, 10, 50)", "raw_solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(x_data, plot=False):\n    # Define the quadratic function\n    def func(x, a, b, c):\n        return a * x**2 + b * x + c\n\n    # Define the initial guess for the parameters\n    p0 = [1, 1, 1]\n\n    # Perform the curve fitting\n    popt, _ = curve_fit(func, x_data, y_data, p0)\n\n    # Generate the fitted values\n    fitted_values = func(x_data, *popt)\n\n    if plot:\n        # Plot the original data\n        plt.scatter(x_data, y_data, color='red', label='Original data')\n\n        # Plot the fitted curve\n        plt.plot(x_data, fitted_values, color='blue', label='Fitted curve')\n\n        plt.legend()\n        plt.show()\n\n        return popt, fitted_values, plt.gca()\n    else:\n        return popt, fitted_values\n\n# Test the function\nx_data = np.linspace(-10, 10, 50)\ny_data = x_data**2 + 2*x_data + 1 + np.random.normal(0, 10, 50)\n\nparams, fitted_values, ax = task_func(x_data, plot=True)"}
{"task_id": "BigCodeBench/374", "solution": "import re\nimport glob\nimport os\nfrom openpyxl import load_workbook\ndef task_func(directory_path='./xlsx_files/'):\n    # Get all .xlsx files in the directory\n    files = glob.glob(os.path.join(directory_path, '*.xlsx'))\n\n    # Initialize counter\n    count = 0\n\n    # Process each file\n    for file in files:\n        # Load the workbook\n        wb = load_workbook(filename=file, read_only=False, keep_vba=True)\n\n        # Iterate over each worksheet\n        for ws in wb.worksheets:\n            # Iterate over each cell\n            for row in ws.iter_rows():\n                for cell in row:\n                    # If the cell contains a double quote, replace it with a double backslash\n                    if cell.value and '\"' in str(cell.value):\n                        cell.value = re.sub(r'\"', '\\\\\"', str(cell.value))\n\n        # Save the workbook\n        wb.save(file)\n\n        # Increment the counter\n        count += 1\n\n    return count", "raw_solution": "import re\nimport glob\nimport os\nfrom openpyxl import load_workbook\n\ndef task_func(directory_path='./xlsx_files/'):\n    # Get all .xlsx files in the directory\n    files = glob.glob(os.path.join(directory_path, '*.xlsx'))\n\n    # Initialize counter\n    count = 0\n\n    # Process each file\n    for file in files:\n        # Load the workbook\n        wb = load_workbook(filename=file, read_only=False, keep_vba=True)\n\n        # Iterate over each worksheet\n        for ws in wb.worksheets:\n            # Iterate over each cell\n            for row in ws.iter_rows():\n                for cell in row:\n                    # If the cell contains a double quote, replace it with a double backslash\n                    if cell.value and '\"' in str(cell.value):\n                        cell.value = re.sub(r'\"', '\\\\\"', str(cell.value))\n\n        # Save the workbook\n        wb.save(file)\n\n        # Increment the counter\n        count += 1\n\n    return count"}
{"task_id": "BigCodeBench/375", "solution": "from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(l):\n    # Convert list to numpy array\n    l = np.array(l)\n\n    # Perform PCA\n    pca = PCA(n_components=2)\n    pca.fit(l)\n\n    # Get the first two components\n    first_component = pca.components_[0]\n    second_component = pca.components_[1]\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(first_component, second_component)\n\n    # Set labels\n    ax.set_xlabel('First Principal Component')\n    ax.set_ylabel('Second Principal Component')\n    plt.title('PCA Result')\n\n    return ax", "raw_solution": "from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(l):\n    # Convert list to numpy array\n    l = np.array(l)\n\n    # Perform PCA\n    pca = PCA(n_components=2)\n    pca.fit(l)\n\n    # Get the first two components\n    first_component = pca.components_[0]\n    second_component = pca.components_[1]\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(first_component, second_component)\n\n    # Set labels\n    ax.set_xlabel('First Principal Component')\n    ax.set_ylabel('Second Principal Component')\n    plt.title('PCA Result')\n\n    return ax"}
{"task_id": "BigCodeBench/376", "solution": "import nltk\nimport re\nfrom collections import Counter\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(text):\n    # Split the text into words, convert to lowercase, remove punctuation and common stopwords\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    words = [word for word in words if word not in STOPWORDS]\n\n    # Calculate the frequency of each word\n    word_freq = dict(Counter(words))\n\n    return word_freq\ntext = \"This is a sample text. It contains several words, some of which are repeated.\"", "raw_solution": "import nltk\nimport re\nfrom collections import Counter\n\n# Constants\nSTOPWORDS = nltk.corpus.stopwords.words('english')\n\ndef task_func(text):\n    # Split the text into words, convert to lowercase, remove punctuation and common stopwords\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    words = [word for word in words if word not in STOPWORDS]\n\n    # Calculate the frequency of each word\n    word_freq = dict(Counter(words))\n\n    return word_freq\n\n# Test the function\ntext = \"This is a sample text. It contains several words, some of which are repeated.\""}
{"task_id": "BigCodeBench/377", "solution": "from texttable import Texttable\nimport psutil\ndef task_func():\n    # Initialize the table\n    t = Texttable()\n    t.add_rows([[\"Item\", \"Value\"],\n                [\"CPU Usage (%)\", psutil.cpu_percent()],\n                [\"Memory Usage (%)\", psutil.virtual_memory().percent],\n                [\"Disk Usage (%)\", psutil.disk_usage('/').percent]])\n    return t.draw()", "raw_solution": "from texttable import Texttable\nimport psutil\n\ndef task_func():\n    # Initialize the table\n    t = Texttable()\n    t.add_rows([[\"Item\", \"Value\"],\n                [\"CPU Usage (%)\", psutil.cpu_percent()],\n                [\"Memory Usage (%)\", psutil.virtual_memory().percent],\n                [\"Disk Usage (%)\", psutil.disk_usage('/').percent]])\n    return t.draw()\n"}
{"task_id": "BigCodeBench/378", "solution": "import pandas as pd\nfrom texttable import Texttable\nimport os\nimport glob\ndef task_func(data_dir='./data/'):\n    # Check if directory exists\n    if not os.path.isdir(data_dir):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n\n    # Get all CSV files in the directory\n    csv_files = glob.glob(os.path.join(data_dir, '*.csv'))\n\n    # Check if there are CSV files in the directory\n    if not csv_files:\n        raise ValueError(\"There are no CSV files in the specified directory.\")\n\n    # Initialize Texttable\n    t = Texttable()\n    t.add_rows([[\"File Name\", \"Number of Rows\", \"Number of Columns\"]])\n\n    # Iterate over CSV files\n    for csv_file in csv_files:\n        try:\n            # Read CSV file\n            df = pd.read_csv(csv_file)\n        except pd.errors.EmptyDataError:\n            raise pd.errors.EmptyDataError(\"An empty CSV file was encountered.\")\n\n        # Add file name, number of rows, and number of columns to the table\n        t.add_row([os.path.basename(csv_file), df.shape[0], df.shape[1]])\n\n    # Return the table as a string\n    return t.draw()", "raw_solution": "import pandas as pd\nfrom texttable import Texttable\nimport os\nimport glob\n\ndef task_func(data_dir='./data/'):\n    # Check if directory exists\n    if not os.path.isdir(data_dir):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n\n    # Get all CSV files in the directory\n    csv_files = glob.glob(os.path.join(data_dir, '*.csv'))\n\n    # Check if there are CSV files in the directory\n    if not csv_files:\n        raise ValueError(\"There are no CSV files in the specified directory.\")\n\n    # Initialize Texttable\n    t = Texttable()\n    t.add_rows([[\"File Name\", \"Number of Rows\", \"Number of Columns\"]])\n\n    # Iterate over CSV files\n    for csv_file in csv_files:\n        try:\n            # Read CSV file\n            df = pd.read_csv(csv_file)\n        except pd.errors.EmptyDataError:\n            raise pd.errors.EmptyDataError(\"An empty CSV file was encountered.\")\n\n        # Add file name, number of rows, and number of columns to the table\n        t.add_row([os.path.basename(csv_file), df.shape[0], df.shape[1]])\n\n    # Return the table as a string\n    return t.draw()"}
{"task_id": "BigCodeBench/379", "solution": "import pandas as pd\nimport numpy as np\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(length):\n    # Generate a DataFrame with random data\n    data = np.random.randint(0, 100, size=(length, len(COLUMNS)))\n    df = pd.DataFrame(data, columns=COLUMNS)\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(length):\n    # Generate a DataFrame with random data\n    data = np.random.randint(0, 100, size=(length, len(COLUMNS)))\n    df = pd.DataFrame(data, columns=COLUMNS)\n    return df\n\n# Test the function\ndf = task_func(10)"}
{"task_id": "BigCodeBench/380", "solution": "import os\nimport shutil\ndef task_func(directory):\n    # Check if the directory exists\n    if not os.path.isdir(directory):\n        print(f\"Directory {directory} does not exist.\")\n        return\n\n    # Get a list of all files in the directory\n    files = os.listdir(directory)\n\n    # Create a dictionary to store files by extension\n    files_by_ext = {}\n\n    for file in files:\n        # Get the extension of the file\n        ext = os.path.splitext(file)[1]\n\n        # If the extension is not in the dictionary, create a new list for it\n        if ext not in files_by_ext:\n            files_by_ext[ext] = []\n\n        # Add the file to the list for its extension\n        files_by_ext[ext].append(file)\n\n    # Create a new directory for each extension\n    for ext in files_by_ext.keys():\n        new_dir = os.path.join(directory, ext)\n        if not os.path.exists(new_dir):\n            os.makedirs(new_dir)\n\n        # Move the files to the corresponding directories\n        for file in files_by_ext[ext]:\n            old_path = os.path.join(directory, file)\n            new_path = os.path.join(new_dir, file)\n            shutil.move(old_path, new_path)\n\n    return None", "raw_solution": "import os\nimport shutil\n\ndef task_func(directory):\n    # Check if the directory exists\n    if not os.path.isdir(directory):\n        print(f\"Directory {directory} does not exist.\")\n        return\n\n    # Get a list of all files in the directory\n    files = os.listdir(directory)\n\n    # Create a dictionary to store files by extension\n    files_by_ext = {}\n\n    for file in files:\n        # Get the extension of the file\n        ext = os.path.splitext(file)[1]\n\n        # If the extension is not in the dictionary, create a new list for it\n        if ext not in files_by_ext:\n            files_by_ext[ext] = []\n\n        # Add the file to the list for its extension\n        files_by_ext[ext].append(file)\n\n    # Create a new directory for each extension\n    for ext in files_by_ext.keys():\n        new_dir = os.path.join(directory, ext)\n        if not os.path.exists(new_dir):\n            os.makedirs(new_dir)\n\n        # Move the files to the corresponding directories\n        for file in files_by_ext[ext]:\n            old_path = os.path.join(directory, file)\n            new_path = os.path.join(new_dir, file)\n            shutil.move(old_path, new_path)\n\n    return None"}
{"task_id": "BigCodeBench/381", "solution": "import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\ndef task_func(file_path='arena.csv', target_column='Index', seed=42):\n    # Check if file exists\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n\n    # Load data\n    df = pd.read_csv(file_path)\n\n    # Check if target column exists\n    if target_column not in df.columns:\n        raise ValueError(f\"The target column {target_column} does not exist in the data.\")\n\n    # Drop rows with NaN values\n    df = df.dropna()\n\n    # Check for infinite values\n    if np.isinf(df).any().any():\n        raise ValueError(\"The data contains infinite values.\")\n\n    # Check for values too large for dtype('float32')\n    if (df > np.finfo(np.float32).max).any().any():\n        raise ValueError(\"The data contains values too large for dtype('float32').\")\n\n    # Prepare data\n    y = df[target_column]\n    X = df.drop(columns=[target_column])\n\n    # Train random forest model\n    rf = RandomForestClassifier(random_state=seed)\n    rf.fit(X, y)\n\n    # Get feature importances\n    importances = rf.feature_importances_\n\n    # Create bar plot\n    plt.figure(figsize=(10, 5))\n    sns.barplot(x=X.columns, y=importances)\n    plt.title('Feature Importances')\n    plt.xlabel('Features')\n    plt.ylabel('Importance')\n    ax = plt.gca()\n\n    return ax, importances", "raw_solution": "import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\n\ndef task_func(file_path='arena.csv', target_column='Index', seed=42):\n    # Check if file exists\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n\n    # Load data\n    df = pd.read_csv(file_path)\n\n    # Check if target column exists\n    if target_column not in df.columns:\n        raise ValueError(f\"The target column {target_column} does not exist in the data.\")\n\n    # Drop rows with NaN values\n    df = df.dropna()\n\n    # Check for infinite values\n    if np.isinf(df).any().any():\n        raise ValueError(\"The data contains infinite values.\")\n\n    # Check for values too large for dtype('float32')\n    if (df > np.finfo(np.float32).max).any().any():\n        raise ValueError(\"The data contains values too large for dtype('float32').\")\n\n    # Prepare data\n    y = df[target_column]\n    X = df.drop(columns=[target_column])\n\n    # Train random forest model\n    rf = RandomForestClassifier(random_state=seed)\n    rf.fit(X, y)\n\n    # Get feature importances\n    importances = rf.feature_importances_\n\n    # Create bar plot\n    plt.figure(figsize=(10, 5))\n    sns.barplot(x=X.columns, y=importances)\n    plt.title('Feature Importances')\n    plt.xlabel('Features')\n    plt.ylabel('Importance')\n    ax = plt.gca()\n\n    return ax, importances"}
{"task_id": "BigCodeBench/382", "solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(length):\n    # Define the mean and standard deviation\n    mu, sigma = 0, 1\n\n    # Generate the normal distribution\n    distribution = norm.rvs(mu, sigma, length)\n\n    # Create the plot\n    fig, ax = plt.subplots()\n\n    # Plot the histogram\n    ax.hist(distribution, bins=30, density=True, alpha=0.6, color='g', label='Histogram')\n\n    # Plot the probability density function\n    x_values = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    ax.plot(x_values, norm.pdf(x_values, mu, sigma), color='r', label='PDF')\n\n    # Add legend and labels\n    ax.legend(loc='best', frameon=False)\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency/Probability Density')\n    ax.set_title('Normal Distribution with PDF')\n\n    plt.show()\n\n    return distribution, ax", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(length):\n    # Define the mean and standard deviation\n    mu, sigma = 0, 1\n\n    # Generate the normal distribution\n    distribution = norm.rvs(mu, sigma, length)\n\n    # Create the plot\n    fig, ax = plt.subplots()\n\n    # Plot the histogram\n    ax.hist(distribution, bins=30, density=True, alpha=0.6, color='g', label='Histogram')\n\n    # Plot the probability density function\n    x_values = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    ax.plot(x_values, norm.pdf(x_values, mu, sigma), color='r', label='PDF')\n\n    # Add legend and labels\n    ax.legend(loc='best', frameon=False)\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency/Probability Density')\n    ax.set_title('Normal Distribution with PDF')\n\n    plt.show()\n\n    return distribution, ax"}
{"task_id": "BigCodeBench/383", "solution": "import pandas as pd\nimport seaborn as sns\nfrom collections import Counter\nfrom textblob import TextBlob\nfrom matplotlib import pyplot as plt\ndef task_func(text, n, top_k):\n    # Generate n-grams\n    ngrams = zip(*[text[i:] for i in range(n)])\n    ngrams = [' '.join(ngram) for ngram in ngrams]\n\n    # Count n-grams\n    counter = Counter(ngrams)\n\n    # Get top k n-grams\n    top_ngrams = counter.most_common(top_k)\n\n    # Create a dataframe for visualization\n    df = pd.DataFrame(top_ngrams, columns=['n-gram', 'count'])\n\n    # Visualize the top k n-grams\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='count', y='n-gram', data=df, palette='viridis')\n    plt.title(f'Top {top_k} {n}-grams')\n    plt.show()\ntext = \"This is a sample text. It is used to test the function.\"\nn = 2\ntop_k = 5", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom collections import Counter\nfrom textblob import TextBlob\nfrom matplotlib import pyplot as plt\n\ndef task_func(text, n, top_k):\n    # Generate n-grams\n    ngrams = zip(*[text[i:] for i in range(n)])\n    ngrams = [' '.join(ngram) for ngram in ngrams]\n\n    # Count n-grams\n    counter = Counter(ngrams)\n\n    # Get top k n-grams\n    top_ngrams = counter.most_common(top_k)\n\n    # Create a dataframe for visualization\n    df = pd.DataFrame(top_ngrams, columns=['n-gram', 'count'])\n\n    # Visualize the top k n-grams\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='count', y='n-gram', data=df, palette='viridis')\n    plt.title(f'Top {top_k} {n}-grams')\n    plt.show()\n\n# Test the function\ntext = \"This is a sample text. It is used to test the function.\"\nn = 2\ntop_k = 5\ntask_func(text, n, top_k)"}
{"task_id": "BigCodeBench/384", "solution": "import collections\nimport random\nimport itertools\nANIMALS = ['Cat', 'Dog', 'Elephant', 'Lion', 'Tiger', 'Bear', 'Giraffe', 'Horse', 'Rabbit', 'Snake', 'Zebra']\ndef task_func(animal_dict, max_count=10, seed=0):\n    random.seed(seed)\n    reversed_dict = collections.defaultdict(list)\n    counter = collections.Counter()\n\n    for key, value in animal_dict.items():\n        reversed_dict[value].append(key)\n        if value in ANIMALS:\n            counter[value] = random.randint(1, max_count)\n\n    return (dict(reversed_dict), counter)\nanimal_dict = {'Alice': 'Cat', 'Bob': 'Dog', 'Charlie': 'Elephant', 'David': 'Lion', 'Eva': 'Tiger', 'Frank': 'Bear', 'George': 'Giraffe', 'Harry': 'Horse', 'Isla': 'Rabbit', 'John': 'Snake', 'Kevin': 'Zebra'}", "raw_solution": "import collections\nimport random\nimport itertools\n\nANIMALS = ['Cat', 'Dog', 'Elephant', 'Lion', 'Tiger', 'Bear', 'Giraffe', 'Horse', 'Rabbit', 'Snake', 'Zebra']\n\ndef task_func(animal_dict, max_count=10, seed=0):\n    random.seed(seed)\n    reversed_dict = collections.defaultdict(list)\n    counter = collections.Counter()\n\n    for key, value in animal_dict.items():\n        reversed_dict[value].append(key)\n        if value in ANIMALS:\n            counter[value] = random.randint(1, max_count)\n\n    return (dict(reversed_dict), counter)\n\n# Test the function\nanimal_dict = {'Alice': 'Cat', 'Bob': 'Dog', 'Charlie': 'Elephant', 'David': 'Lion', 'Eva': 'Tiger', 'Frank': 'Bear', 'George': 'Giraffe', 'Harry': 'Horse', 'Isla': 'Rabbit', 'John': 'Snake', 'Kevin': 'Zebra'}"}
{"task_id": "BigCodeBench/385", "solution": "import matplotlib.pyplot as plt\nfrom collections import Counter\ndef task_func(fruit_dict):\n    # Count the frequency of each fruit\n    fruit_counts = Counter(fruit_dict.values())\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(fruit_counts.keys(), fruit_counts.values())\n    ax.set_xlabel('Fruit')\n    ax.set_ylabel('Count')\n    ax.set_title('Fruit Counts')\n\n    return fruit_counts, ax\nfruit_dict = {'Alice': 'Apple', 'Bob': 'Banana', 'Charlie': 'Cherry', 'David': 'Date', 'Eve': 'Elderberry', \n              'Frank': 'Fig', 'Grace': 'Grape', 'Harry': 'Honeydew', 'Isla': 'Indian Prune', 'John': 'Jackfruit'}", "raw_solution": "import matplotlib.pyplot as plt\nfrom collections import Counter\n\nFRUITS = ['Apple', 'Banana', 'Cherry', 'Date', 'Elderberry', 'Fig', 'Grape', 'Honeydew', 'Indian Prune', 'Jackfruit']\n\ndef task_func(fruit_dict):\n    # Count the frequency of each fruit\n    fruit_counts = Counter(fruit_dict.values())\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(fruit_counts.keys(), fruit_counts.values())\n    ax.set_xlabel('Fruit')\n    ax.set_ylabel('Count')\n    ax.set_title('Fruit Counts')\n\n    return fruit_counts, ax\n\n# Test the function\nfruit_dict = {'Alice': 'Apple', 'Bob': 'Banana', 'Charlie': 'Cherry', 'David': 'Date', 'Eve': 'Elderberry', \n              'Frank': 'Fig', 'Grace': 'Grape', 'Harry': 'Honeydew', 'Isla': 'Indian Prune', 'John': 'Jackfruit'}\nfruit_counts, ax = task_func(fruit_dict)\nplt.show()"}
{"task_id": "BigCodeBench/386", "solution": "import numpy as np\nimport pandas as pd\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(length, min_value = 0, max_value = 100):\n    # Generate a pandas DataFrame with specified ranges and length\n    df = pd.DataFrame(np.random.randint(min_value, max_value, size=(length, len(COLUMNS))), columns=COLUMNS)\n\n    # Calculate the cumulative distribution function (CDF)\n    cdf = df.apply(lambda x: x.sort_values().values)\n\n    return cdf", "raw_solution": "import numpy as np\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(length, min_value = 0, max_value = 100):\n    # Generate a pandas DataFrame with specified ranges and length\n    df = pd.DataFrame(np.random.randint(min_value, max_value, size=(length, len(COLUMNS))), columns=COLUMNS)\n\n    # Calculate the cumulative distribution function (CDF)\n    cdf = df.apply(lambda x: x.sort_values().values)\n\n    return cdf\n\n# Test the function"}
{"task_id": "BigCodeBench/387", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nCITIES = ['New York', 'London', 'Beijing', 'Tokyo', 'Sydney', 'Paris', 'Berlin', 'Moscow', 'Madrid', 'Rome']\ndef task_func(city_dict, max_range=1000000, seed=0):\n    np.random.seed(seed)\n    city_pop_dict = {}\n    for name, city in city_dict.items():\n        if city in CITIES:\n            city_pop_dict[city] = np.random.randint(1, max_range)\n        else:\n            city_pop_dict[city] = -1\n\n    # Plotting\n    fig, ax = plt.subplots()\n    ax.bar(city_pop_dict.keys(), city_pop_dict.values())\n    ax.set_xlabel('Cities')\n    ax.set_ylabel('Population')\n    ax.set_title('City Population')\n    plt.show()\n\n    return city_pop_dict, ax\ncity_dict = {'John': 'New York', 'Emily': 'London', 'Michael': 'Beijing', 'Sarah': 'Tokyo', 'David': 'Sydney', \n             'Jessica': 'Paris', 'Jacob': 'Berlin', 'Emma': 'Moscow', 'Daniel': 'Madrid', 'Olivia': 'Rome'}", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nCITIES = ['New York', 'London', 'Beijing', 'Tokyo', 'Sydney', 'Paris', 'Berlin', 'Moscow', 'Madrid', 'Rome']\n\ndef task_func(city_dict, max_range=1000000, seed=0):\n    np.random.seed(seed)\n    city_pop_dict = {}\n    for name, city in city_dict.items():\n        if city in CITIES:\n            city_pop_dict[city] = np.random.randint(1, max_range)\n        else:\n            city_pop_dict[city] = -1\n\n    # Plotting\n    fig, ax = plt.subplots()\n    ax.bar(city_pop_dict.keys(), city_pop_dict.values())\n    ax.set_xlabel('Cities')\n    ax.set_ylabel('Population')\n    ax.set_title('City Population')\n    plt.show()\n\n    return city_pop_dict, ax\n\n# Testing\ncity_dict = {'John': 'New York', 'Emily': 'London', 'Michael': 'Beijing', 'Sarah': 'Tokyo', 'David': 'Sydney', \n             'Jessica': 'Paris', 'Jacob': 'Berlin', 'Emma': 'Moscow', 'Daniel': 'Madrid', 'Olivia': 'Rome'}\npop_dict, ax = task_func(city_dict, max_range=1000000, seed=0)"}
{"task_id": "BigCodeBench/388", "solution": "import collections\nimport pandas as pd\ndef task_func(my_tuple, path_csv_files):\n    result = {}\n    for csv_file in path_csv_files:\n        df = pd.read_csv(csv_file)\n        for col in my_tuple:\n            if col in df.columns:\n                counts = df[col].value_counts()\n                result[col] = counts.to_dict()\n    return result\npath_csv_files = ['file1.csv', 'file2.csv']\nmy_tuple = ('column1', 'column2')", "raw_solution": "import collections\nimport pandas as pd\n\ndef task_func(my_tuple, path_csv_files):\n    result = {}\n    for csv_file in path_csv_files:\n        df = pd.read_csv(csv_file)\n        for col in my_tuple:\n            if col in df.columns:\n                counts = df[col].value_counts()\n                result[col] = counts.to_dict()\n    return result\n\n# Test the function\npath_csv_files = ['file1.csv', 'file2.csv']  # replace with your actual file paths\nmy_tuple = ('column1', 'column2')  # replace with your actual column names"}
{"task_id": "BigCodeBench/389", "solution": "import re\nimport os\nimport shutil\ndef task_func(directory):\n    # Create a new subdirectory if it doesn't exist\n    new_dir = os.path.join(directory, \"Interesting Files\")\n    if not os.path.exists(new_dir):\n        os.makedirs(new_dir)\n\n    # List to store the files moved\n    files_moved = []\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the filename contains \"like\" or \"what\"\n        if re.search(r'like|what', filename):\n            # Move the file to the new subdirectory\n            shutil.move(os.path.join(directory, filename), new_dir)\n            # Add the filename to the list of files moved\n            files_moved.append(filename)\n\n    # Print the list of files moved\n    print(\"List of files moved:\", files_moved)", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(directory):\n    # Create a new subdirectory if it doesn't exist\n    new_dir = os.path.join(directory, \"Interesting Files\")\n    if not os.path.exists(new_dir):\n        os.makedirs(new_dir)\n\n    # List to store the files moved\n    files_moved = []\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the filename contains \"like\" or \"what\"\n        if re.search(r'like|what', filename):\n            # Move the file to the new subdirectory\n            shutil.move(os.path.join(directory, filename), new_dir)\n            # Add the filename to the list of files moved\n            files_moved.append(filename)\n\n    # Print the list of files moved\n    print(\"List of files moved:\", files_moved)\n\n# Test the function\ntask_func(\"/path/to/directory\")"}
{"task_id": "BigCodeBench/390", "solution": "import pandas as pd\nimport requests\nfrom io import StringIO\ndef task_func(csv_url_dict, sort_by_column=\"title\"):\n    if not csv_url_dict:\n        raise ValueError(\"The dictionary is empty\")\n    elif \"URL\" not in csv_url_dict:\n        raise ValueError('The key \"URL\" does not exist in the dictionary')\n\n    url = csv_url_dict[\"URL\"]\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        print (\"HTTP Error:\",errh)\n    except requests.exceptions.ConnectionError as errc:\n        print (\"Error Connecting:\",errc)\n    except requests.exceptions.Timeout as errt:\n        print (\"Timeout Error:\",errt)\n    except requests.exceptions.RequestException as err:\n        print (\"Something went wrong\",err)\n\n    data = response.content.decode('utf-8')\n    df = pd.read_csv(StringIO(data))\n    sorted_df = df.sort_values(by=[sort_by_column])\n\n    return sorted_df", "raw_solution": "import pandas as pd\nimport requests\nfrom io import StringIO\n\ndef task_func(csv_url_dict, sort_by_column=\"title\"):\n    if not csv_url_dict:\n        raise ValueError(\"The dictionary is empty\")\n    elif \"URL\" not in csv_url_dict:\n        raise ValueError('The key \"URL\" does not exist in the dictionary')\n\n    url = csv_url_dict[\"URL\"]\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        print (\"HTTP Error:\",errh)\n    except requests.exceptions.ConnectionError as errc:\n        print (\"Error Connecting:\",errc)\n    except requests.exceptions.Timeout as errt:\n        print (\"Timeout Error:\",errt)\n    except requests.exceptions.RequestException as err:\n        print (\"Something went wrong\",err)\n\n    data = response.content.decode('utf-8')\n    df = pd.read_csv(StringIO(data))\n    sorted_df = df.sort_values(by=[sort_by_column])\n\n    return sorted_df"}
{"task_id": "BigCodeBench/391", "solution": "import os\nimport glob\nimport shutil\ndef task_func(directory, archive_dir='archive'):\n    # Create archive directory if it doesn't exist\n    if not os.path.exists(archive_dir):\n        os.makedirs(archive_dir)\n\n    # Get all JSON files in the directory\n    json_files = glob.glob(os.path.join(directory, '*.json'))\n\n    # Initialize error messages list\n    error_messages = []\n\n    # Move each JSON file to the archive directory\n    for json_file in json_files:\n        try:\n            shutil.move(json_file, os.path.join(archive_dir, os.path.basename(json_file)))\n        except Exception as e:\n            error_messages.append(f\"Failed to move {json_file} to {archive_dir}: {str(e)}\")\n\n    # Return a tuple with a boolean indicating success and a list of error messages\n    return (len(error_messages) == 0, error_messages)", "raw_solution": "import os\nimport glob\nimport shutil\n\ndef task_func(directory, archive_dir='archive'):\n    # Create archive directory if it doesn't exist\n    if not os.path.exists(archive_dir):\n        os.makedirs(archive_dir)\n\n    # Get all JSON files in the directory\n    json_files = glob.glob(os.path.join(directory, '*.json'))\n\n    # Initialize error messages list\n    error_messages = []\n\n    # Move each JSON file to the archive directory\n    for json_file in json_files:\n        try:\n            shutil.move(json_file, os.path.join(archive_dir, os.path.basename(json_file)))\n        except Exception as e:\n            error_messages.append(f\"Failed to move {json_file} to {archive_dir}: {str(e)}\")\n\n    # Return a tuple with a boolean indicating success and a list of error messages\n    return (len(error_messages) == 0, error_messages)"}
{"task_id": "BigCodeBench/392", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nCOLORS = ['r', 'g', 'b']\ndef task_func(df, group_col, value_col, group_name):\n    if group_name not in df[group_col].values:\n        raise ValueError(f\"The group_name {group_name} does not exist in df.\")\n\n    group_data = df[df[group_col] == group_name][value_col]\n    ax = group_data.plot(kind='bar', color=COLORS[0])\n\n    ax.set_title(f'Bar chart of {value_col} for {group_name}')\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n\n    return ax\ndf = pd.DataFrame({\n    'group': ['A', 'B', 'A', 'B', 'A'],\n    'value': [1, 2, 3, 4, 5],\n})", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nCOLORS = ['r', 'g', 'b']\n\ndef task_func(df, group_col, value_col, group_name):\n    if group_name not in df[group_col].values:\n        raise ValueError(f\"The group_name {group_name} does not exist in df.\")\n\n    group_data = df[df[group_col] == group_name][value_col]\n    ax = group_data.plot(kind='bar', color=COLORS[0])\n\n    ax.set_title(f'Bar chart of {value_col} for {group_name}')\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n\n    return ax\n\n# Test the function\ndf = pd.DataFrame({\n    'group': ['A', 'B', 'A', 'B', 'A'],\n    'value': [1, 2, 3, 4, 5],\n})\n\nax = task_func(df, 'group', 'value', 'A')\nplt.show()"}
{"task_id": "BigCodeBench/393", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(mu, sigma, num_samples=1000, seed=77):\n    np.random.seed(seed)\n    # Generate samples from a normal distribution\n    samples = np.random.normal(mu, sigma, num_samples)\n\n    # Create a figure\n    fig, ax = plt.subplots(2, 1, figsize=(10, 10))\n\n    # Histogram\n    ax[0].hist(samples, bins=30, density=True)\n    ax[0].set_title('Histogram')\n    ax[0].set_xlabel('Value')\n    ax[0].set_ylabel('Frequency')\n\n    # Q-Q plot\n    stats.probplot(samples, plot=ax[1])\n    ax[1].set_title('Q-Q plot')\n\n    return fig", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(mu, sigma, num_samples=1000, seed=77):\n    np.random.seed(seed)\n    # Generate samples from a normal distribution\n    samples = np.random.normal(mu, sigma, num_samples)\n\n    # Create a figure\n    fig, ax = plt.subplots(2, 1, figsize=(10, 10))\n\n    # Histogram\n    ax[0].hist(samples, bins=30, density=True)\n    ax[0].set_title('Histogram')\n    ax[0].set_xlabel('Value')\n    ax[0].set_ylabel('Frequency')\n\n    # Q-Q plot\n    stats.probplot(samples, plot=ax[1])\n    ax[1].set_title('Q-Q plot')\n\n    return fig"}
{"task_id": "BigCodeBench/394", "solution": "import collections\nimport string\nimport random\ndef task_func(length, seed=0):\n    random.seed(seed)\n    random_string = ''.join(random.choices(string.ascii_letters, k=length))\n    frequency = collections.Counter(random_string)\n    return frequency", "raw_solution": "import collections\nimport string\nimport random\n\ndef task_func(length, seed=0):\n    random.seed(seed)\n    random_string = ''.join(random.choices(string.ascii_letters, k=length))\n    frequency = collections.Counter(random_string)\n    return frequency\n\n# Test the function"}
{"task_id": "BigCodeBench/395", "solution": "import re\nimport os\nimport glob\nimport natsort\nimport pandas as pd\ndef task_func(directory='./', file_pattern='*.txt', regex=r'([0-9]+)'):\n    # Check if directory exists\n    if not os.path.isdir(directory):\n        raise FileNotFoundError(f\"The specified directory {directory} does not exist.\")\n\n    # Get a list of all files matching the pattern\n    files = glob.glob(os.path.join(directory, file_pattern))\n\n    # Sort the files naturally\n    files = natsort.natsorted(files)\n\n    # Check if any files were found\n    if not files:\n        raise ValueError(f\"No files matching the pattern {file_pattern} were found in the directory {directory}.\")\n\n    # Initialize an empty list to store the data\n    data = []\n\n    # Loop over each file\n    for file in files:\n        # Open the file and read its content\n        with open(file, 'r') as f:\n            content = f.read()\n\n        # Extract numeric data using regex\n        numeric_data = re.findall(regex, content)\n\n        # If numeric data was found, add it to the data list\n        if numeric_data:\n            data.append({'Filename': file, 'Numeric Data': numeric_data})\n\n    # Convert the data list to a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Return the DataFrame\n    return df", "raw_solution": "import re\nimport os\nimport glob\nimport natsort\nimport pandas as pd\n\ndef task_func(directory='./', file_pattern='*.txt', regex=r'([0-9]+)'):\n    # Check if directory exists\n    if not os.path.isdir(directory):\n        raise FileNotFoundError(f\"The specified directory {directory} does not exist.\")\n\n    # Get a list of all files matching the pattern\n    files = glob.glob(os.path.join(directory, file_pattern))\n\n    # Sort the files naturally\n    files = natsort.natsorted(files)\n\n    # Check if any files were found\n    if not files:\n        raise ValueError(f\"No files matching the pattern {file_pattern} were found in the directory {directory}.\")\n\n    # Initialize an empty list to store the data\n    data = []\n\n    # Loop over each file\n    for file in files:\n        # Open the file and read its content\n        with open(file, 'r') as f:\n            content = f.read()\n\n        # Extract numeric data using regex\n        numeric_data = re.findall(regex, content)\n\n        # If numeric data was found, add it to the data list\n        if numeric_data:\n            data.append({'Filename': file, 'Numeric Data': numeric_data})\n\n    # Convert the data list to a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Return the DataFrame\n    return df"}
{"task_id": "BigCodeBench/396", "solution": "import matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(mu, sigma, sample_size, seed=0):\n    np.random.seed(seed)\n    # Generate a random sample from a normal distribution\n    sample = np.random.normal(mu, sigma, sample_size)\n\n    # Create a range of values for the x-axis\n    x = np.linspace(min(sample), max(sample), 1000)\n\n    # Calculate the Gaussian kernel density estimate\n    kde = stats.gaussian_kde(sample)\n\n    # Evaluate the kernel density estimate at the x-values\n    y = kde(x)\n\n    # Create a new figure and plot the KDE\n    plt.figure(figsize=(10, 6))\n    plt.plot(x, y, label=f'KDE of sample (mean={mu}, std={sigma})')\n    plt.title(f'Gaussian Kernel Density Estimate (sample size={sample_size})')\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    plt.legend()\n\n    # Return the axes object\n    return plt.gca()", "raw_solution": "import matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(mu, sigma, sample_size, seed=0):\n    np.random.seed(seed)\n    # Generate a random sample from a normal distribution\n    sample = np.random.normal(mu, sigma, sample_size)\n\n    # Create a range of values for the x-axis\n    x = np.linspace(min(sample), max(sample), 1000)\n\n    # Calculate the Gaussian kernel density estimate\n    kde = stats.gaussian_kde(sample)\n\n    # Evaluate the kernel density estimate at the x-values\n    y = kde(x)\n\n    # Create a new figure and plot the KDE\n    plt.figure(figsize=(10, 6))\n    plt.plot(x, y, label=f'KDE of sample (mean={mu}, std={sigma})')\n    plt.title(f'Gaussian Kernel Density Estimate (sample size={sample_size})')\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    plt.legend()\n\n    # Return the axes object\n    return plt.gca()\n\n# Test the function\naxes = task_func(0, 1, 1000)\nplt.show()"}
{"task_id": "BigCodeBench/397", "solution": "import re\nimport urllib.request\nimport json\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\ndef task_func(API_URL):\n    try:\n        response = urllib.request.urlopen(API_URL)\n        data = response.read()\n        json_data = json.loads(data)\n\n        ip_address = json_data['ip']\n\n        if re.match(IP_REGEX, ip_address):\n            return ip_address\n        else:\n            return \"Invalid IP address\"\n    except Exception as e:\n        return str(e)\nAPI_URL = 'https://api.ipify.org?format=json'", "raw_solution": "import re\nimport urllib.request\nimport json\n\n# Constants\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\n\ndef task_func(API_URL):\n    try:\n        response = urllib.request.urlopen(API_URL)\n        data = response.read()\n        json_data = json.loads(data)\n\n        ip_address = json_data['ip']\n\n        if re.match(IP_REGEX, ip_address):\n            return ip_address\n        else:\n            return \"Invalid IP address\"\n    except Exception as e:\n        return str(e)\n\n# Test the function\nAPI_URL = 'https://api.ipify.org?format=json'"}
{"task_id": "BigCodeBench/398", "solution": "import json\nimport os\ndef task_func(file_path):\n    if not os.path.exists(file_path):\n        return False\n\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n\n    if not isinstance(data, list):\n        return False\n\n    for item in data:\n        if not isinstance(item, dict):\n            return False\n\n    return True", "raw_solution": "import json\nimport os\n\ndef task_func(file_path):\n    if not os.path.exists(file_path):\n        return False\n\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n\n    if not isinstance(data, list):\n        return False\n\n    for item in data:\n        if not isinstance(item, dict):\n            return False\n\n    return True\n\n# Test the function"}
{"task_id": "BigCodeBench/399", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency cannot be negative\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be positive\")\n\n    time = np.linspace(0, 1, sample_size, False)\n    sine_wave = np.sin(2 * np.pi * frequency * time)\n    cosine_wave = np.cos(2 * np.pi * frequency * time)\n\n    fig, ax = plt.subplots()\n    ax.plot(time, sine_wave, label='Sine Wave')\n    ax.plot(time, cosine_wave, label='Cosine Wave')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n    ax.legend()\n\n    return fig, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency cannot be negative\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be positive\")\n\n    time = np.linspace(0, 1, sample_size, False)\n    sine_wave = np.sin(2 * np.pi * frequency * time)\n    cosine_wave = np.cos(2 * np.pi * frequency * time)\n\n    fig, ax = plt.subplots()\n    ax.plot(time, sine_wave, label='Sine Wave')\n    ax.plot(time, cosine_wave, label='Cosine Wave')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n    ax.legend()\n\n    return fig, ax"}
{"task_id": "BigCodeBench/400", "solution": "import json\nimport glob\ndef task_func(directory, string):\n    # Recursively find all JSON files in the directory\n    json_files = glob.glob(directory + '/**/*.json', recursive=True)\n\n    # List to store file paths containing the string\n    file_paths = []\n\n    # Iterate over each JSON file\n    for file in json_files:\n        # Open the file and load the JSON data\n        with open(file, 'r') as f:\n            data = json.load(f)\n\n            # Use the json.dumps method to convert the data to a string\n            # This is necessary because the json.load method returns a Python object\n            data_str = json.dumps(data)\n\n            # Check if the string is present in the JSON data\n            if string in data_str:\n                # If the string is present, add the file path to the list\n                file_paths.append(file)\n\n    # Return the list of file paths\n    return file_paths", "raw_solution": "import json\nimport glob\n\ndef task_func(directory, string):\n    # Recursively find all JSON files in the directory\n    json_files = glob.glob(directory + '/**/*.json', recursive=True)\n\n    # List to store file paths containing the string\n    file_paths = []\n\n    # Iterate over each JSON file\n    for file in json_files:\n        # Open the file and load the JSON data\n        with open(file, 'r') as f:\n            data = json.load(f)\n\n            # Use the json.dumps method to convert the data to a string\n            # This is necessary because the json.load method returns a Python object\n            data_str = json.dumps(data)\n\n            # Check if the string is present in the JSON data\n            if string in data_str:\n                # If the string is present, add the file path to the list\n                file_paths.append(file)\n\n    # Return the list of file paths\n    return file_paths"}
{"task_id": "BigCodeBench/401", "solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\ndef task_func(app_name):\n    app = Flask(app_name)\n\n    # Set default configuration values\n    app.config['MAIL_SERVER'] = 'localhost'\n    app.config['MAIL_PORT'] = 25\n    app.config['MAIL_USE_TLS'] = False\n    app.config['MAIL_USERNAME'] = None\n    app.config['MAIL_PASSWORD'] = None\n\n    # Override with environment variables if they exist\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', app.config['MAIL_SERVER'])\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', app.config['MAIL_PORT']))\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', app.config['MAIL_USE_TLS']) == 'True'\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', app.config['MAIL_USERNAME'])\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', app.config['MAIL_PASSWORD'])\n\n    mail = Mail(app)\n\n    return mail, app.config['MAIL_SERVER'], app.config['MAIL_PORT'], app.config['MAIL_USE_TLS'], app.config['MAIL_USERNAME'], app.config['MAIL_PASSWORD']", "raw_solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\n\ndef task_func(app_name):\n    app = Flask(app_name)\n\n    # Set default configuration values\n    app.config['MAIL_SERVER'] = 'localhost'\n    app.config['MAIL_PORT'] = 25\n    app.config['MAIL_USE_TLS'] = False\n    app.config['MAIL_USERNAME'] = None\n    app.config['MAIL_PASSWORD'] = None\n\n    # Override with environment variables if they exist\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', app.config['MAIL_SERVER'])\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', app.config['MAIL_PORT']))\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', app.config['MAIL_USE_TLS']) == 'True'\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', app.config['MAIL_USERNAME'])\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', app.config['MAIL_PASSWORD'])\n\n    mail = Mail(app)\n\n    return mail, app.config['MAIL_SERVER'], app.config['MAIL_PORT'], app.config['MAIL_USE_TLS'], app.config['MAIL_USERNAME'], app.config['MAIL_PASSWORD']\n\n# Test the function\nmail, server, port, use_tls, username, password = task_func('test_app')"}
{"task_id": "BigCodeBench/402", "solution": "import re\nimport requests\nimport json\nimport csv\nimport os\nAPI_URL = 'https://api.example.com/data'\ndef task_func(pattern):\n    # Make a GET request to the API\n    response = requests.get(API_URL)\n\n    # Check if the request was successful\n    if response.status_code != 200:\n        print(f\"Failed to get data from API. Status code: {response.status_code}\")\n        return None\n\n    # Extract the data from the JSON response\n    data = response.json().get('data', [])\n\n    # Find data that matches the pattern\n    matched_data = [d for d in data if re.search(pattern, d)]\n\n    # Get the absolute path to the CSV file\n    csv_file_path = os.path.abspath('matched_data.csv')\n\n    # Write the matched data to a CSV file\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow(['Matched Data'])\n        for row in matched_data:\n            writer.writerow([row])\n\n    return csv_file_path", "raw_solution": "import re\nimport requests\nimport json\nimport csv\nimport os  \n\n# Constants\nAPI_URL = 'https://api.example.com/data'\n\ndef task_func(pattern):\n    # Make a GET request to the API\n    response = requests.get(API_URL)\n\n    # Check if the request was successful\n    if response.status_code != 200:\n        print(f\"Failed to get data from API. Status code: {response.status_code}\")\n        return None\n\n    # Extract the data from the JSON response\n    data = response.json().get('data', [])\n\n    # Find data that matches the pattern\n    matched_data = [d for d in data if re.search(pattern, d)]\n\n    # Get the absolute path to the CSV file\n    csv_file_path = os.path.abspath('matched_data.csv')\n\n    # Write the matched data to a CSV file\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow(['Matched Data'])\n        for row in matched_data:\n            writer.writerow([row])\n\n    return csv_file_path"}
{"task_id": "BigCodeBench/403", "solution": "from PIL import Image, ImageFilter\nimport cv2\nimport numpy as np\nimport os\ndef task_func(img_path, blur_radius=5):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n    # Open the image\n    img_pil = Image.open(img_path)\n    img_cv = cv2.imread(img_path)\n\n    # Convert the image to grayscale\n    img_pil = img_pil.convert('L')\n    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n\n    # Apply a blur filter\n    img_pil = img_pil.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n    img_cv = cv2.GaussianBlur(img_cv, (blur_radius, blur_radius), 0)\n\n    # Convert the image to numpy arrays\n    img_pil = np.array(img_pil)\n    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_GRAY2BGR)\n\n    # Display the original and the edited images side by side\n    cv2.imshow('Original Image', img_cv)\n    cv2.imshow('Blurred and Grayscaled Image', img_pil)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n\n    return (img_cv, img_pil)", "raw_solution": "from PIL import Image, ImageFilter\nimport cv2\nimport numpy as np\nimport os\n\ndef task_func(img_path, blur_radius=5):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n    # Open the image\n    img_pil = Image.open(img_path)\n    img_cv = cv2.imread(img_path)\n\n    # Convert the image to grayscale\n    img_pil = img_pil.convert('L')\n    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n\n    # Apply a blur filter\n    img_pil = img_pil.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n    img_cv = cv2.GaussianBlur(img_cv, (blur_radius, blur_radius), 0)\n\n    # Convert the image to numpy arrays\n    img_pil = np.array(img_pil)\n    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_GRAY2BGR)\n\n    # Display the original and the edited images side by side\n    cv2.imshow('Original Image', img_cv)\n    cv2.imshow('Blurred and Grayscaled Image', img_pil)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n\n    return (img_cv, img_pil)"}
{"task_id": "BigCodeBench/404", "solution": "import cv2\nimport numpy as np\nimport os\ndef task_func(img_path):\n    if not os.path.isfile(img_path):\n        raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n    img = cv2.imread(img_path)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n    contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n\n    return img, contours", "raw_solution": "import cv2\nimport numpy as np\nimport os\n\ndef task_func(img_path):\n    if not os.path.isfile(img_path):\n        raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n    img = cv2.imread(img_path)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n    contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n\n    return img, contours"}
{"task_id": "BigCodeBench/405", "solution": "import random\nimport matplotlib.pyplot as plt\ndef task_func(points: int):\n    random_numbers = [random.random() for _ in range(points)]\n    fig, ax = plt.subplots()\n    ax.plot(range(points), random_numbers)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Random Number')\n    ax.set_title('Random Numbers vs Index')\n    return random_numbers, ax.figure", "raw_solution": "import random\nimport matplotlib.pyplot as plt\n\ndef task_func(points: int):\n    random_numbers = [random.random() for _ in range(points)]\n    fig, ax = plt.subplots()\n    ax.plot(range(points), random_numbers)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Random Number')\n    ax.set_title('Random Numbers vs Index')\n    return random_numbers, ax.figure\n\n# Test the function\nrandom_numbers, fig = task_func(100)\nplt.show()"}
{"task_id": "BigCodeBench/406", "solution": "from PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\ndef task_func(img_path, angle):\n    try:\n        if not os.path.exists(img_path):\n            raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n        img = Image.open(img_path)\n        img_array = np.array(img)\n\n        rotated_img = img.rotate(angle, expand=True)\n        rotated_img_array = np.array(rotated_img)\n\n        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n        axs[0].imshow(img)\n        axs[0].set_title('Original Image')\n        axs[1].imshow(rotated_img)\n        axs[1].set_title('Rotated Image')\n        for ax in axs:\n            ax.axis('off')\n        plt.show()\n\n        return img_array, rotated_img_array\n\n    except FileNotFoundError as fnf_error:\n        print(fnf_error)", "raw_solution": "from PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\ndef task_func(img_path, angle):\n    try:\n        if not os.path.exists(img_path):\n            raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n        img = Image.open(img_path)\n        img_array = np.array(img)\n\n        rotated_img = img.rotate(angle, expand=True)\n        rotated_img_array = np.array(rotated_img)\n\n        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n        axs[0].imshow(img)\n        axs[0].set_title('Original Image')\n        axs[1].imshow(rotated_img)\n        axs[1].set_title('Rotated Image')\n        for ax in axs:\n            ax.axis('off')\n        plt.show()\n\n        return img_array, rotated_img_array\n\n    except FileNotFoundError as fnf_error:\n        print(fnf_error)"}
{"task_id": "BigCodeBench/407", "solution": "import os\nimport csv\nfrom openpyxl import load_workbook\ndef task_func(file_name, excel_file_path, csv_file_path) -> str:\n    # Load the workbook\n    workbook = load_workbook(filename=os.path.join(excel_file_path, file_name), read_only=True)\n\n    # Get the active worksheet\n    worksheet = workbook.active\n\n    # Create the CSV file path\n    csv_file_name = f\"{file_name.split('.')[0]}.csv\"\n    csv_file_path = os.path.join(csv_file_path, csv_file_name)\n\n    # Open the CSV file for writing\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n\n        # Write each row to the CSV file\n        for row in worksheet.iter_rows(values_only=True):\n            writer.writerow(row)\n\n    return csv_file_name", "raw_solution": "import os\nimport csv\nfrom openpyxl import load_workbook\n\ndef task_func(file_name, excel_file_path, csv_file_path) -> str:\n    # Load the workbook\n    workbook = load_workbook(filename=os.path.join(excel_file_path, file_name), read_only=True)\n\n    # Get the active worksheet\n    worksheet = workbook.active\n\n    # Create the CSV file path\n    csv_file_name = f\"{file_name.split('.')[0]}.csv\"\n    csv_file_path = os.path.join(csv_file_path, csv_file_name)\n\n    # Open the CSV file for writing\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n\n        # Write each row to the CSV file\n        for row in worksheet.iter_rows(values_only=True):\n            writer.writerow(row)\n\n    return csv_file_name"}
{"task_id": "BigCodeBench/408", "solution": "import sqlite3\nimport pandas as pd\ndef task_func(db_file: str, query: str) -> pd.DataFrame:\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_file)\n\n    # Execute the query\n    df = pd.read_sql_query(query, conn)\n\n    # Close the connection\n    conn.close()\n\n    # Return the results as a pandas DataFrame\n    return df", "raw_solution": "import sqlite3\nimport pandas as pd\n\ndef task_func(db_file: str, query: str) -> pd.DataFrame:\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_file)\n\n    # Execute the query\n    df = pd.read_sql_query(query, conn)\n\n    # Close the connection\n    conn.close()\n\n    # Return the results as a pandas DataFrame\n    return df"}
{"task_id": "BigCodeBench/409", "solution": "import os\nimport pandas as pd\nimport numpy as np\ndef task_func(excel_file_path, file_name, column_name):\n    # Check if file exists\n    if not os.path.isfile(os.path.join(excel_file_path, file_name)):\n        raise FileNotFoundError(f\"The file {file_name} does not exist at the specified path.\")\n\n    # Load the excel file\n    df = pd.read_excel(os.path.join(excel_file_path, file_name))\n\n    # Check if column exists\n    if column_name not in df.columns:\n        raise ValueError(f\"The column {column_name} does not exist in the file.\")\n\n    # Calculate mean, median, and standard deviation\n    mean = df[column_name].mean()\n    median = df[column_name].median()\n    std_dev = df[column_name].std()\n\n    # Return as a dictionary\n    return {'mean': mean, 'median': median, 'std_dev': std_dev}", "raw_solution": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(excel_file_path, file_name, column_name):\n    # Check if file exists\n    if not os.path.isfile(os.path.join(excel_file_path, file_name)):\n        raise FileNotFoundError(f\"The file {file_name} does not exist at the specified path.\")\n\n    # Load the excel file\n    df = pd.read_excel(os.path.join(excel_file_path, file_name))\n\n    # Check if column exists\n    if column_name not in df.columns:\n        raise ValueError(f\"The column {column_name} does not exist in the file.\")\n\n    # Calculate mean, median, and standard deviation\n    mean = df[column_name].mean()\n    median = df[column_name].median()\n    std_dev = df[column_name].std()\n\n    # Return as a dictionary\n    return {'mean': mean, 'median': median, 'std_dev': std_dev}"}
{"task_id": "BigCodeBench/410", "solution": "import os\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(excel_directory: str, file_name: str, column_name: str, start_date: str, end_date: str) -> pd.DataFrame:\n    # Check if file exists\n    if not os.path.isfile(os.path.join(excel_directory, file_name)):\n        raise FileNotFoundError(f\"The specified Excel file {file_name} does not exist.\")\n\n    # Check if start_date and end_date are in correct format\n    try:\n        start_date = datetime.strptime(start_date, '%Y-%m-%d')\n        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n    except ValueError:\n        raise ValueError(\"start_date and end_date should be in 'YYYY-MM-DD' format.\")\n\n    # Load the Excel file\n    df = pd.read_excel(os.path.join(excel_directory, file_name))\n\n    # Check if column_name exists in the DataFrame\n    if column_name not in df.columns:\n        raise ValueError(f\"The specified column {column_name} does not exist in the DataFrame.\")\n\n    # Filter data in the specific date range\n    mask = (df[column_name] > start_date) & (df[column_name] <= end_date)\n    df_filtered = df.loc[mask]\n\n    return df_filtered", "raw_solution": "import os\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(excel_directory: str, file_name: str, column_name: str, start_date: str, end_date: str) -> pd.DataFrame:\n    # Check if file exists\n    if not os.path.isfile(os.path.join(excel_directory, file_name)):\n        raise FileNotFoundError(f\"The specified Excel file {file_name} does not exist.\")\n\n    # Check if start_date and end_date are in correct format\n    try:\n        start_date = datetime.strptime(start_date, '%Y-%m-%d')\n        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n    except ValueError:\n        raise ValueError(\"start_date and end_date should be in 'YYYY-MM-DD' format.\")\n\n    # Load the Excel file\n    df = pd.read_excel(os.path.join(excel_directory, file_name))\n\n    # Check if column_name exists in the DataFrame\n    if column_name not in df.columns:\n        raise ValueError(f\"The specified column {column_name} does not exist in the DataFrame.\")\n\n    # Filter data in the specific date range\n    mask = (df[column_name] > start_date) & (df[column_name] <= end_date)\n    df_filtered = df.loc[mask]\n\n    return df_filtered"}
{"task_id": "BigCodeBench/411", "solution": "import pandas as pd\nimport json\nimport os\ndef task_func(data: dict, output_path: str = \"./default_data_output.json\") -> str:\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame(data)\n\n    # Drop the column named 'c' if it exists\n    df = df.drop('c', axis=1, errors='ignore')\n\n    # Convert the DataFrame to a dictionary\n    df_dict = df.to_dict(orient='records')\n\n    # Save the dictionary as a JSON file\n    with open(output_path, 'w') as f:\n        json.dump(df_dict, f)\n\n    # Return the path where the JSON file was saved\n    return os.path.abspath(output_path)\ndata = {'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]}", "raw_solution": "import pandas as pd\nimport json\nimport os\n\ndef task_func(data: dict, output_path: str = \"./default_data_output.json\") -> str:\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame(data)\n\n    # Drop the column named 'c' if it exists\n    df = df.drop('c', axis=1, errors='ignore')\n\n    # Convert the DataFrame to a dictionary\n    df_dict = df.to_dict(orient='records')\n\n    # Save the dictionary as a JSON file\n    with open(output_path, 'w') as f:\n        json.dump(df_dict, f)\n\n    # Return the path where the JSON file was saved\n    return os.path.abspath(output_path)\n\n# Test the function\ndata = {'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]}"}
{"task_id": "BigCodeBench/412", "solution": "import json\nimport base64\nimport unicodedata\ndef task_func(json_file: str) -> dict:\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n\n    decoded_data = {}\n    for key, value in data.items():\n        decoded_value = base64.b64decode(value).decode('utf-8')\n        normalized_value = unicodedata.normalize('NFC', decoded_value)\n        decoded_data[key] = normalized_value\n\n    return decoded_data", "raw_solution": "import json\nimport base64\nimport unicodedata\n\ndef task_func(json_file: str) -> dict:\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n\n    decoded_data = {}\n    for key, value in data.items():\n        decoded_value = base64.b64decode(value).decode('utf-8')\n        normalized_value = unicodedata.normalize('NFC', decoded_value)\n        decoded_data[key] = normalized_value\n\n    return decoded_data"}
{"task_id": "BigCodeBench/413", "solution": "import os\nfrom flask import Flask\nfrom flask_mail import Mail\ndef task_func(app):\n    mail = Mail(app)\n\n    app.config['MAIL_SERVER'] = os.environ.get('MAIL_SERVER', 'smtp.example.com')\n    app.config['MAIL_PORT'] = int(os.environ.get('MAIL_PORT', '587'))\n    app.config['MAIL_USE_TLS'] = os.environ.get('MAIL_USE_TLS', True)\n    app.config['MAIL_USERNAME'] = os.environ.get('MAIL_USERNAME', 'your-username')\n    app.config['MAIL_PASSWORD'] = os.environ.get('MAIL_PASSWORD', 'your-password')\n    app.config['MAIL_DEFAULT_SENDER'] = os.environ.get('MAIL_DEFAULT_SENDER', 'your-email@example.com')\n\n    return mail, app.config['MAIL']\napp = Flask(__name__)", "raw_solution": "import os\nfrom flask import Flask\nfrom flask_mail import Mail\n\ndef task_func(app):\n    mail = Mail(app)\n\n    app.config['MAIL_SERVER'] = os.environ.get('MAIL_SERVER', 'smtp.example.com')\n    app.config['MAIL_PORT'] = int(os.environ.get('MAIL_PORT', '587'))\n    app.config['MAIL_USE_TLS'] = os.environ.get('MAIL_USE_TLS', True)\n    app.config['MAIL_USERNAME'] = os.environ.get('MAIL_USERNAME', 'your-username')\n    app.config['MAIL_PASSWORD'] = os.environ.get('MAIL_PASSWORD', 'your-password')\n    app.config['MAIL_DEFAULT_SENDER'] = os.environ.get('MAIL_DEFAULT_SENDER', 'your-email@example.com')\n\n    return mail, app.config['MAIL']\n\n# Test the function\napp = Flask(__name__)\nmail, mail_config = task_func(app)"}
{"task_id": "BigCodeBench/414", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(data, column=\"c\"):\n    if column in data.columns:\n        df = data.drop(column, axis=1)\n    else:\n        df = data.copy()\n\n    numeric_columns = df.select_dtypes(include=[np.number]).columns\n\n    if len(numeric_columns) > 0:\n        ax = df[numeric_columns].plot(kind='line')\n    else:\n        ax = None\n\n    return df, ax\ndata = pd.DataFrame({\n    'a': [1, 2, 3, 4, 5],\n    'b': ['a', 'b', 'c', 'd', 'e'],\n    'c': [10, 20, 30, 40, 50],\n    'd': [100, 200, 300, 400, 500]\n})", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(data, column=\"c\"):\n    if column in data.columns:\n        df = data.drop(column, axis=1)\n    else:\n        df = data.copy()\n\n    numeric_columns = df.select_dtypes(include=[np.number]).columns\n\n    if len(numeric_columns) > 0:\n        ax = df[numeric_columns].plot(kind='line')\n    else:\n        ax = None\n\n    return df, ax\n\n# Test the function\ndata = pd.DataFrame({\n    'a': [1, 2, 3, 4, 5],\n    'b': ['a', 'b', 'c', 'd', 'e'],\n    'c': [10, 20, 30, 40, 50],\n    'd': [100, 200, 300, 400, 500]\n})\n\ndf, ax = task_func(data, column=\"c\")"}
{"task_id": "BigCodeBench/415", "solution": "import pandas as pd\nimport codecs\ndef task_func(dataframe: pd.DataFrame) -> pd.DataFrame:\n    if not isinstance(dataframe, pd.DataFrame):\n        raise TypeError(\"Input should be a pandas DataFrame\")\n    if \"UnicodeString\" not in dataframe.columns:\n        raise KeyError(\"Column 'UnicodeString' does not exist in the DataFrame\")\n    dataframe['UnicodeString'] = dataframe['UnicodeString'].apply(lambda x: codecs.decode(x.encode(), 'unicode_escape'))\n    return dataframe", "raw_solution": "import pandas as pd\nimport codecs\n\ndef task_func(dataframe: pd.DataFrame) -> pd.DataFrame:\n    if not isinstance(dataframe, pd.DataFrame):\n        raise TypeError(\"Input should be a pandas DataFrame\")\n    if \"UnicodeString\" not in dataframe.columns:\n        raise KeyError(\"Column 'UnicodeString' does not exist in the DataFrame\")\n    dataframe['UnicodeString'] = dataframe['UnicodeString'].apply(lambda x: codecs.decode(x.encode(), 'unicode_escape'))\n    return dataframe"}
{"task_id": "BigCodeBench/416", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(data, column=\"c\"):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data should be a pandas DataFrame\")\n    if not isinstance(column, str):\n        raise ValueError(\"Column should be a string\")\n\n    if data.empty or data.select_dtypes(include=[np.number]).empty:\n        return None\n\n    data = data.drop(column, axis=1)\n\n    corr = data.corr()\n\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n\n    return ax", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data, column=\"c\"):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data should be a pandas DataFrame\")\n    if not isinstance(column, str):\n        raise ValueError(\"Column should be a string\")\n\n    if data.empty or data.select_dtypes(include=[np.number]).empty:\n        return None\n\n    data = data.drop(column, axis=1)\n\n    corr = data.corr()\n\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n\n    return ax"}
{"task_id": "BigCodeBench/417", "solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\ndef task_func(X, Y, learning_rate=0.01):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n\n    # Construct the Sequential model\n    model = Sequential()\n    model.add(Dense(1, input_dim=2, activation='sigmoid'))\n\n    # Compile the model\n    sgd = SGD(lr=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\n    # Fit the model\n    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=0)\n\n    # Plot the training and validation loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    ax = plt.gca()\n\n    return model, ax", "raw_solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\n\ndef task_func(X, Y, learning_rate=0.01):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n\n    # Construct the Sequential model\n    model = Sequential()\n    model.add(Dense(1, input_dim=2, activation='sigmoid'))\n\n    # Compile the model\n    sgd = SGD(lr=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\n    # Fit the model\n    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=0)\n\n    # Plot the training and validation loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    ax = plt.gca()\n\n    return model, ax"}
{"task_id": "BigCodeBench/418", "solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(X, Y):\n    # Split the data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    # Create a Keras Sequential model\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(1, input_dim=X_train.shape[1], activation='sigmoid'))\n\n    # Compile the model\n    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.01), metrics=['accuracy'])\n\n    # Fit the model\n    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n\n    # Predict probabilities\n    y_pred_prob = model.predict_proba(X_test)\n\n    # Compute ROC curve and ROC area for each class\n    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n    roc_auc = auc(fpr, tpr)\n\n    # Plot ROC curve\n    plt.figure()\n    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return model, plt.gca()", "raw_solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(X, Y):\n    # Split the data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    # Create a Keras Sequential model\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(1, input_dim=X_train.shape[1], activation='sigmoid'))\n\n    # Compile the model\n    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.01), metrics=['accuracy'])\n\n    # Fit the model\n    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n\n    # Predict probabilities\n    y_pred_prob = model.predict_proba(X_test)\n\n    # Compute ROC curve and ROC area for each class\n    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n    roc_auc = auc(fpr, tpr)\n\n    # Plot ROC curve\n    plt.figure()\n    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return model, plt.gca()"}
{"task_id": "BigCodeBench/419", "solution": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(X, Y):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    # Construct the model\n    model = keras.Sequential()\n    model.add(keras.layers.Dense(1, input_dim=X.shape[1], activation='sigmoid'))\n\n    # Compile the model\n    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n\n    # Fit the model\n    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=0)\n\n    # Predict probabilities\n    Y_pred_prob = model.predict_proba(X_test)\n\n    # Compute Precision-Recall curve\n    precision, recall, _ = precision_recall_curve(Y_test, Y_pred_prob)\n\n    # Plot the Precision-Recall curve\n    plt.plot(recall, precision)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    ax = plt.gca()\n\n    return model, ax", "raw_solution": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(X, Y):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n    # Construct the model\n    model = keras.Sequential()\n    model.add(keras.layers.Dense(1, input_dim=X.shape[1], activation='sigmoid'))\n\n    # Compile the model\n    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n\n    # Fit the model\n    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=0)\n\n    # Predict probabilities\n    Y_pred_prob = model.predict_proba(X_test)\n\n    # Compute Precision-Recall curve\n    precision, recall, _ = precision_recall_curve(Y_test, Y_pred_prob)\n\n    # Plot the Precision-Recall curve\n    plt.plot(recall, precision)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    ax = plt.gca()\n\n    return model, ax"}
{"task_id": "BigCodeBench/420", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data):\n    # Create a copy of the dataframe to avoid changing the original data\n    data_copy = data.copy(deep=True)\n\n    # Initialize the StandardScaler\n    scaler = StandardScaler()\n\n    # Iterate over each column in the dataframe\n    for col in data_copy.columns:\n        # Try to convert the column to float\n        try:\n            data_copy[col] = data_copy[col].astype(float)\n        except ValueError:\n            # If a ValueError is raised, this means that the column cannot be converted to float\n            # So, we skip this column\n            continue\n\n        # If the column can be converted to float, we scale it\n        data_copy[col] = scaler.fit_transform(data_copy[col].values.reshape(-1, 1))\n\n    return data_copy", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data):\n    # Create a copy of the dataframe to avoid changing the original data\n    data_copy = data.copy(deep=True)\n\n    # Initialize the StandardScaler\n    scaler = StandardScaler()\n\n    # Iterate over each column in the dataframe\n    for col in data_copy.columns:\n        # Try to convert the column to float\n        try:\n            data_copy[col] = data_copy[col].astype(float)\n        except ValueError:\n            # If a ValueError is raised, this means that the column cannot be converted to float\n            # So, we skip this column\n            continue\n\n        # If the column can be converted to float, we scale it\n        data_copy[col] = scaler.fit_transform(data_copy[col].values.reshape(-1, 1))\n\n    return data_copy"}
{"task_id": "BigCodeBench/421", "solution": "import requests\nimport os\nimport json\nimport time\nHEADERS = {\n    'accept': 'text/json',\n    'Content-Type': 'application/json'\n}\ndef task_func(url, directory, metadata):\n    # Check if the directory exists\n    if not os.path.isdir(directory):\n        raise FileNotFoundError(f\"Directory {directory} does not exist.\")\n\n    # Check if the url is valid\n    try:\n        requests.get(url)\n    except requests.exceptions.RequestException:\n        raise TypeError(f\"Invalid URL: {url}\")\n\n    # List to store status codes\n    status_codes = []\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n\n        # Check if the file is a regular file (not a directory or symbolic link)\n        if os.path.isfile(file_path):\n            with open(file_path, 'rb') as file:\n                file_data = file.read()\n\n            # Combine metadata and file data\n            upload_data = {\n                'metadata': metadata,\n                'file': file_data\n            }\n\n            # Send a POST request to the server\n            response = requests.post(url, headers=HEADERS, data=json.dumps(upload_data))\n\n            # Add the status code to the list\n            status_codes.append(response.status_code)\n\n            # Pause for one second\n            time.sleep(1)\n\n    return status_codes", "raw_solution": "import requests\nimport os\nimport json\nimport time\n\n# Redefining the function in the current context\nHEADERS = {\n    'accept': 'text/json',\n    'Content-Type': 'application/json'\n}\n\ndef task_func(url, directory, metadata):\n    # Check if the directory exists\n    if not os.path.isdir(directory):\n        raise FileNotFoundError(f\"Directory {directory} does not exist.\")\n\n    # Check if the url is valid\n    try:\n        requests.get(url)\n    except requests.exceptions.RequestException:\n        raise TypeError(f\"Invalid URL: {url}\")\n\n    # List to store status codes\n    status_codes = []\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n\n        # Check if the file is a regular file (not a directory or symbolic link)\n        if os.path.isfile(file_path):\n            with open(file_path, 'rb') as file:\n                file_data = file.read()\n\n            # Combine metadata and file data\n            upload_data = {\n                'metadata': metadata,\n                'file': file_data\n            }\n\n            # Send a POST request to the server\n            response = requests.post(url, headers=HEADERS, data=json.dumps(upload_data))\n\n            # Add the status code to the list\n            status_codes.append(response.status_code)\n\n            # Pause for one second\n            time.sleep(1)\n\n    return status_codes"}
{"task_id": "BigCodeBench/422", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\ndef task_func(df, target_column, column_to_remove=\"c\", test_size=0.2):\n    if column_to_remove in df.columns:\n        df = df.drop(column_to_remove, axis=1)\n    X = df.drop(target_column, axis=1)\n    y = df[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n    return X_train, X_test, y_train, y_test\ndf = pd.DataFrame({\n    'a': [1, 2, 3, 4, 5],\n    'b': [10, 20, 30, 40, 50],\n    'c': [100, 200, 300, 400, 500],\n    'target': [1000, 2000, 3000, 4000, 5000]\n})", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(df, target_column, column_to_remove=\"c\", test_size=0.2):\n    if column_to_remove in df.columns:\n        df = df.drop(column_to_remove, axis=1)\n    X = df.drop(target_column, axis=1)\n    y = df[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n    return X_train, X_test, y_train, y_test\n\n# Test the function\ndf = pd.DataFrame({\n    'a': [1, 2, 3, 4, 5],\n    'b': [10, 20, 30, 40, 50],\n    'c': [100, 200, 300, 400, 500],\n    'target': [1000, 2000, 3000, 4000, 5000]\n})\n\nX_train, X_test, y_train, y_test = task_func(df, 'target', 'c', 0.2)\n"}
{"task_id": "BigCodeBench/423", "solution": "import numpy as np\nimport cv2\nimport os\ndef task_func(image_path='image.jpg', threshold=128):\n    # Check if the image file exists\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(f\"The image file {image_path} does not exist.\")\n\n    # Check if the threshold is an integer and in the range 0-255\n    if not isinstance(threshold, int) or threshold < 0 or threshold > 255:\n        raise ValueError(\"The threshold should be an integer in the range 0-255.\")\n\n    # Read the image\n    image = cv2.imread(image_path)\n\n    # Convert the image to grayscale\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Binarize the image using the given threshold\n    _, binary_image = cv2.threshold(gray_image, threshold, 255, cv2.THRESH_BINARY)\n\n    return gray_image, binary_image", "raw_solution": "import numpy as np\nimport cv2\nimport os\n\ndef task_func(image_path='image.jpg', threshold=128):\n    # Check if the image file exists\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(f\"The image file {image_path} does not exist.\")\n\n    # Check if the threshold is an integer and in the range 0-255\n    if not isinstance(threshold, int) or threshold < 0 or threshold > 255:\n        raise ValueError(\"The threshold should be an integer in the range 0-255.\")\n\n    # Read the image\n    image = cv2.imread(image_path)\n\n    # Convert the image to grayscale\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Binarize the image using the given threshold\n    _, binary_image = cv2.threshold(gray_image, threshold, 255, cv2.THRESH_BINARY)\n\n    return gray_image, binary_image"}
{"task_id": "BigCodeBench/424", "solution": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    # Check if the image file exists\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n    # Check if n_clusters is a positive integer\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"'n_clusters' should be a positive integer.\")\n\n    # Read the image\n    img = cv2.imread(image_path)\n\n    # Reshape the image to be a list of RGB pixels\n    img_reshape = img.reshape((-1, 3))\n\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(img_reshape)\n\n    # Get the cluster labels for each pixel\n    labels = kmeans.labels_\n\n    # Replace each pixel's color with the centroid of the cluster it belongs to\n    segmented_img = kmeans.cluster_centers_[labels].reshape(img.shape)\n\n    # Convert the segmented image to uint8\n    segmented_img = np.uint8(segmented_img)\n\n    return img, segmented_img", "raw_solution": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    # Check if the image file exists\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n    # Check if n_clusters is a positive integer\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"'n_clusters' should be a positive integer.\")\n\n    # Read the image\n    img = cv2.imread(image_path)\n\n    # Reshape the image to be a list of RGB pixels\n    img_reshape = img.reshape((-1, 3))\n\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(img_reshape)\n\n    # Get the cluster labels for each pixel\n    labels = kmeans.labels_\n\n    # Replace each pixel's color with the centroid of the cluster it belongs to\n    segmented_img = kmeans.cluster_centers_[labels].reshape(img.shape)\n\n    # Convert the segmented image to uint8\n    segmented_img = np.uint8(segmented_img)\n\n    return img, segmented_img"}
{"task_id": "BigCodeBench/425", "solution": "import cv2\nimport os\nfrom matplotlib import pyplot as plt\ndef task_func(image_path='image.jpg', histogram_path='histogram.png'):\n    # Check if the image file exists\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n    # Read the image\n    image = cv2.imread(image_path, 0)\n\n    # Create a histogram\n    histogram, bins = np.histogram(image.flatten(), 256, [0,256])\n\n    # Plot the original image and its histogram\n    plt.subplot(121), plt.imshow(image, 'gray')\n    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n    plt.subplot(122), plt.plot(histogram)\n    plt.title('Histogram'), plt.xticks([]), plt.yticks([])\n\n    # Save the histogram plot as a PNG file\n    plt.savefig(histogram_path)\n\n    # Display the histogram plot\n    plt.show()\n\n    # Return the histogram plot object\n    return plt.gca()", "raw_solution": "import cv2\nimport os\nfrom matplotlib import pyplot as plt\n\ndef task_func(image_path='image.jpg', histogram_path='histogram.png'):\n    # Check if the image file exists\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n    # Read the image\n    image = cv2.imread(image_path, 0)\n\n    # Create a histogram\n    histogram, bins = np.histogram(image.flatten(), 256, [0,256])\n\n    # Plot the original image and its histogram\n    plt.subplot(121), plt.imshow(image, 'gray')\n    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n    plt.subplot(122), plt.plot(histogram)\n    plt.title('Histogram'), plt.xticks([]), plt.yticks([])\n\n    # Save the histogram plot as a PNG file\n    plt.savefig(histogram_path)\n\n    # Display the histogram plot\n    plt.show()\n\n    # Return the histogram plot object\n    return plt.gca()"}
{"task_id": "BigCodeBench/426", "solution": "import numpy as np\nimport cv2\nimport os\ndef task_func(image_path='image.jpg', threshold=128):\n    # Check if the image file exists\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n    # Check if the threshold is an integer and in the range 0-255\n    if not isinstance(threshold, int) or threshold < 0 or threshold > 255:\n        raise ValueError(\"The threshold should be an integer in the range 0-255.\")\n\n    # Read the image\n    image = cv2.imread(image_path)\n\n    # Convert the image to grayscale\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Binarize the image using the given threshold\n    _, binary_image = cv2.threshold(gray_image, threshold, 255, cv2.THRESH_BINARY)\n\n    # Save the binary image\n    cv2.imwrite('binary_image.jpg', binary_image)\n\n    return gray_image, binary_image", "raw_solution": "import numpy as np\nimport cv2\nimport os\n\ndef task_func(image_path='image.jpg', threshold=128):\n    # Check if the image file exists\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(\"The image file does not exist at the specified path.\")\n\n    # Check if the threshold is an integer and in the range 0-255\n    if not isinstance(threshold, int) or threshold < 0 or threshold > 255:\n        raise ValueError(\"The threshold should be an integer in the range 0-255.\")\n\n    # Read the image\n    image = cv2.imread(image_path)\n\n    # Convert the image to grayscale\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Binarize the image using the given threshold\n    _, binary_image = cv2.threshold(gray_image, threshold, 255, cv2.THRESH_BINARY)\n\n    # Save the binary image\n    cv2.imwrite('binary_image.jpg', binary_image)\n\n    return gray_image, binary_image"}
{"task_id": "BigCodeBench/427", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\ndef task_func(df1, df2, features=[\"feature1\", \"feature2\", \"feature3\"], target=\"target\"):\n    # Merge the two dataframes based on 'id' column\n    df = pd.merge(df1, df2, on='id')\n\n    # Perform linear regression\n    lm = LinearRegression()\n    lm.fit(df[features], df[target])\n\n    # Get regression coefficients and intercept\n    coefficients = lm.coef_.tolist()\n    intercept = lm.intercept_\n\n    # Predict the target values\n    df['predicted'] = lm.predict(df[features])\n\n    # Calculate residuals\n    df['residuals'] = df[target] - df['predicted']\n\n    # Plot the residuals\n    plt.figure(figsize=(10, 6))\n    plt.scatter(df['predicted'], df['residuals'])\n    plt.title('Residuals Plot')\n    plt.xlabel('Predicted Values')\n    plt.ylabel('Residuals')\n    residuals_plot = plt.gca()\n\n    # Return the results as a dictionary\n    result = {\n        'coefficients': coefficients,\n        'intercept': intercept,\n        'residuals_plot': residuals_plot\n    }\n\n    return result", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\ndef task_func(df1, df2, features=[\"feature1\", \"feature2\", \"feature3\"], target=\"target\"):\n    # Merge the two dataframes based on 'id' column\n    df = pd.merge(df1, df2, on='id')\n\n    # Perform linear regression\n    lm = LinearRegression()\n    lm.fit(df[features], df[target])\n\n    # Get regression coefficients and intercept\n    coefficients = lm.coef_.tolist()\n    intercept = lm.intercept_\n\n    # Predict the target values\n    df['predicted'] = lm.predict(df[features])\n\n    # Calculate residuals\n    df['residuals'] = df[target] - df['predicted']\n\n    # Plot the residuals\n    plt.figure(figsize=(10, 6))\n    plt.scatter(df['predicted'], df['residuals'])\n    plt.title('Residuals Plot')\n    plt.xlabel('Predicted Values')\n    plt.ylabel('Residuals')\n    residuals_plot = plt.gca()\n\n    # Return the results as a dictionary\n    result = {\n        'coefficients': coefficients,\n        'intercept': intercept,\n        'residuals_plot': residuals_plot\n    }\n\n    return result"}
{"task_id": "BigCodeBench/428", "solution": "import pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df1, df2):\n    # Merge the two dataframes on 'id' column\n    merged_df = pd.merge(df1, df2, on='id', how='outer')\n\n    # Scale the numeric features\n    scaler = StandardScaler()\n    merged_df[merged_df.columns[merged_df.dtypes != 'object']] = scaler.fit_transform(merged_df[merged_df.columns[merged_df.dtypes != 'object']])\n\n    # Create a pair plot of the scaled features\n    pair_plot = sns.pairplot(merged_df[merged_df.columns[merged_df.dtypes != 'object']])\n\n    return merged_df, pair_plot", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df1, df2):\n    # Merge the two dataframes on 'id' column\n    merged_df = pd.merge(df1, df2, on='id', how='outer')\n\n    # Scale the numeric features\n    scaler = StandardScaler()\n    merged_df[merged_df.columns[merged_df.dtypes != 'object']] = scaler.fit_transform(merged_df[merged_df.columns[merged_df.dtypes != 'object']])\n\n    # Create a pair plot of the scaled features\n    pair_plot = sns.pairplot(merged_df[merged_df.columns[merged_df.dtypes != 'object']])\n\n    return merged_df, pair_plot"}
{"task_id": "BigCodeBench/429", "solution": "import pandas as pd\nfrom sklearn.feature_selection import SelectKBest, f_classif\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df1, df2):\n    # Perform feature selection\n    selector = SelectKBest(score_func=f_classif, k=2)\n    selector.fit(df1, df2)\n    selected_features = selector.get_support(indices=True)\n    selected_features_names = df1.columns[selected_features]\n\n    # Create a correlation matrix\n    corr_matrix = df1[selected_features_names].corr()\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n    plt.title('Heatmap of the correlation between the selected features')\n    plt.show()\n\n    return (list(selected_features_names), plt.gca())", "raw_solution": "import pandas as pd\nfrom sklearn.feature_selection import SelectKBest, f_classif\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df1, df2):\n    # Perform feature selection\n    selector = SelectKBest(score_func=f_classif, k=2)\n    selector.fit(df1, df2)\n    selected_features = selector.get_support(indices=True)\n    selected_features_names = df1.columns[selected_features]\n\n    # Create a correlation matrix\n    corr_matrix = df1[selected_features_names].corr()\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n    plt.title('Heatmap of the correlation between the selected features')\n    plt.show()\n\n    return (list(selected_features_names), plt.gca())"}
{"task_id": "BigCodeBench/430", "solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    # Merge datasets\n    df = pd.concat([df1, df2])\n\n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=2, n_init=10)\n    labels = kmeans.fit_predict(df[[column1, column2]])\n\n    # Create scatterplot\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(df[column1], df[column2], c=labels)\n\n    return labels, ax", "raw_solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    # Merge datasets\n    df = pd.concat([df1, df2])\n\n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=2, n_init=10)\n    labels = kmeans.fit_predict(df[[column1, column2]])\n\n    # Create scatterplot\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(df[column1], df[column2], c=labels)\n\n    return labels, ax"}
{"task_id": "BigCodeBench/431", "solution": "import cv2\nimport os\nimport numpy as np\ndef task_func(image_file: str) -> np.ndarray:\n    if not os.path.isfile(image_file):\n        raise FileNotFoundError(\"The specified image file does not exist.\")\n\n    try:\n        img = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n    except:\n        raise ValueError(\"The image file is not a valid image.\")\n\n    hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n    return hist.flatten()", "raw_solution": "import cv2\nimport os\nimport numpy as np\n\ndef task_func(image_file: str) -> np.ndarray:\n    if not os.path.isfile(image_file):\n        raise FileNotFoundError(\"The specified image file does not exist.\")\n\n    try:\n        img = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n    except:\n        raise ValueError(\"The image file is not a valid image.\")\n\n    hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n    return hist.flatten()\n\n# Test the function\ntry:\n    hist = task_func('test_image.jpg')\n    print(hist)\nexcept Exception as e:\n    print(e)"}
{"task_id": "BigCodeBench/432", "solution": "import seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chi2_contingency\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    # Merge the dataframes based on 'id' column\n    merged_df = pd.merge(df1, df2, on='id')\n\n    # Create a contingency table\n    contingency_table = pd.crosstab(merged_df[column1], merged_df[column2])\n\n    # Perform chi-square test\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(contingency_table, annot=True, cmap='YlGnBu')\n    plt.title('Heatmap of Contingency Table')\n    plt.xlabel(column2)\n    plt.ylabel(column1)\n    plt.show()\n\n    return p, plt.gca()", "raw_solution": "import seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chi2_contingency\n\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    # Merge the dataframes based on 'id' column\n    merged_df = pd.merge(df1, df2, on='id')\n\n    # Create a contingency table\n    contingency_table = pd.crosstab(merged_df[column1], merged_df[column2])\n\n    # Perform chi-square test\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(contingency_table, annot=True, cmap='YlGnBu')\n    plt.title('Heatmap of Contingency Table')\n    plt.xlabel(column2)\n    plt.ylabel(column1)\n    plt.show()\n\n    return p, plt.gca()"}
{"task_id": "BigCodeBench/433", "solution": "import base64\nimport hashlib\nimport hmac\nimport binascii\ndef task_func(s, signature, secret_key):\n    # Decode the base64-encoded message\n    message = base64.b64decode(s)\n\n    # Compute the HMAC SHA-1 hash of the message using the secret key\n    secret_key = bytes(secret_key, 'utf-8')\n    computed_signature = hmac.new(secret_key, msg=message, digestmod=hashlib.sha1).digest()\n\n    # Convert the provided signature from hex to bytes\n    provided_signature = binascii.unhexlify(signature)\n\n    # Compare the computed and provided signatures\n    return hmac.compare_digest(computed_signature, provided_signature)", "raw_solution": "import base64\nimport hashlib\nimport hmac\nimport binascii\n\ndef task_func(s, signature, secret_key):\n    # Decode the base64-encoded message\n    message = base64.b64decode(s)\n\n    # Compute the HMAC SHA-1 hash of the message using the secret key\n    secret_key = bytes(secret_key, 'utf-8')\n    computed_signature = hmac.new(secret_key, msg=message, digestmod=hashlib.sha1).digest()\n\n    # Convert the provided signature from hex to bytes\n    provided_signature = binascii.unhexlify(signature)\n\n    # Compare the computed and provided signatures\n    return hmac.compare_digest(computed_signature, provided_signature)\n\n# Test the function"}
{"task_id": "BigCodeBench/434", "solution": "import pandas as pd\nimport re\nimport random\ndef task_func(s: str, seed: int = 0) -> pd.DataFrame:\n    random.seed(seed)\n    product_names = ['Apple', 'Banana', 'Orange', 'Pear', 'Grape']\n    product_dict = {}\n    data = []\n    for line in s.split('\\n'):\n        id, quantity, code, price, *description = line.split()\n        description = ' '.join(description)\n        if code not in product_dict:\n            product_dict[code] = random.choice(product_names)\n        data.append([id, int(quantity), code, int(price), product_dict[code], description])\n    data_df = pd.DataFrame(data, columns=['ID', 'Quantity', 'Code', 'Price', 'Product', 'Description'])\n    return data_df\ns = '1 10 A10B 100 This is a description with spaces\\n2 20 B20C 200 Another description example'", "raw_solution": "import pandas as pd\nimport re\nimport random\n\ndef task_func(s: str, seed: int = 0) -> pd.DataFrame:\n    random.seed(seed)\n    product_names = ['Apple', 'Banana', 'Orange', 'Pear', 'Grape']\n    product_dict = {}\n    data = []\n    for line in s.split('\\n'):\n        id, quantity, code, price, *description = line.split()\n        description = ' '.join(description)\n        if code not in product_dict:\n            product_dict[code] = random.choice(product_names)\n        data.append([id, int(quantity), code, int(price), product_dict[code], description])\n    data_df = pd.DataFrame(data, columns=['ID', 'Quantity', 'Code', 'Price', 'Product', 'Description'])\n    return data_df\n\ns = '1 10 A10B 100 This is a description with spaces\\n2 20 B20C 200 Another description example'\ndf = task_func(s)"}
{"task_id": "BigCodeBench/435", "solution": "import pandas as pd\nfrom random import randint\ndef task_func(name: str, age: int, code: str, salary: float, bio: str) -> pd.DataFrame:\n    job_titles = ['Engineer', 'Manager', 'Analyst', 'Developer', 'Tester']\n    job_title = job_titles[randint(0, len(job_titles)-1)]\n    data = {'Name': name, 'Age': age, 'Code': code, 'Salary': salary, 'Bio': bio, 'Job Title': job_title}\n    data_df = pd.DataFrame(data, index=[0])\n    return data_df", "raw_solution": "import pandas as pd\nfrom random import randint\n\ndef task_func(name: str, age: int, code: str, salary: float, bio: str) -> pd.DataFrame:\n    job_titles = ['Engineer', 'Manager', 'Analyst', 'Developer', 'Tester']\n    job_title = job_titles[randint(0, len(job_titles)-1)]\n    data = {'Name': name, 'Age': age, 'Code': code, 'Salary': salary, 'Bio': bio, 'Job Title': job_title}\n    data_df = pd.DataFrame(data, index=[0])\n    return data_df\n\n# Test the function"}
{"task_id": "BigCodeBench/436", "solution": "import string\nimport matplotlib.pyplot as plt\ndef task_func(s):\n    if not isinstance(s, str):\n        raise TypeError(\"Input must be a string\")\n\n    freq_dict = {}\n    for char in s.lower():\n        if char in string.ascii_lowercase:\n            if char in freq_dict:\n                freq_dict[char] += 1\n            else:\n                freq_dict[char] = 1\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    ax.bar(freq_dict.keys(), freq_dict.values())\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Letter Frequencies')\n\n    return (freq_dict, ax)", "raw_solution": "import string\nimport matplotlib.pyplot as plt\n\ndef task_func(s):\n    if not isinstance(s, str):\n        raise TypeError(\"Input must be a string\")\n\n    freq_dict = {}\n    for char in s.lower():\n        if char in string.ascii_lowercase:\n            if char in freq_dict:\n                freq_dict[char] += 1\n            else:\n                freq_dict[char] = 1\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    ax.bar(freq_dict.keys(), freq_dict.values())\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Letter Frequencies')\n\n    return (freq_dict, ax)\n\n# Test the function\nfreq_dict, ax = task_func('Hello World')\nplt.show()"}
{"task_id": "BigCodeBench/437", "solution": "import pickle\nimport os\nimport pandas as pd\ndef task_func(df, file_name=\"save.pkl\"):\n    # Save the DataFrame to a pickle file\n    df.to_pickle(file_name)\n\n    # Load the DataFrame from the pickle file\n    loaded_df = pd.read_pickle(file_name)\n\n    # Delete the intermediate file\n    os.remove(file_name)\n\n    return loaded_df", "raw_solution": "import pickle\nimport os\nimport pandas as pd\n\ndef task_func(df, file_name=\"save.pkl\"):\n    # Save the DataFrame to a pickle file\n    df.to_pickle(file_name)\n\n    # Load the DataFrame from the pickle file\n    loaded_df = pd.read_pickle(file_name)\n\n    # Delete the intermediate file\n    os.remove(file_name)\n\n    return loaded_df"}
{"task_id": "BigCodeBench/438", "solution": "import pickle\nimport os\nimport matplotlib.pyplot as plt\ndef task_func(numbers, file_path=\"save.pkl\"):\n    if not isinstance(numbers, list) or not all(isinstance(i, (int, float)) for i in numbers):\n        raise TypeError(\"Input should be a list of numbers\")\n\n    # Create a figure and plot the numbers\n    fig, ax = plt.subplots()\n    ax.plot(numbers)\n\n    # Save the figure to a pickle file\n    with open(file_path, 'wb') as f:\n        pickle.dump(fig, f)\n\n    # Load the figure from the pickle file\n    with open(file_path, 'rb') as f:\n        loaded_fig = pickle.load(f)\n\n    # Delete the pickle file\n    os.remove(file_path)\n\n    return loaded_fig", "raw_solution": "import pickle\nimport os\nimport matplotlib.pyplot as plt\n\ndef task_func(numbers, file_path=\"save.pkl\"):\n    if not isinstance(numbers, list) or not all(isinstance(i, (int, float)) for i in numbers):\n        raise TypeError(\"Input should be a list of numbers\")\n\n    # Create a figure and plot the numbers\n    fig, ax = plt.subplots()\n    ax.plot(numbers)\n\n    # Save the figure to a pickle file\n    with open(file_path, 'wb') as f:\n        pickle.dump(fig, f)\n\n    # Load the figure from the pickle file\n    with open(file_path, 'rb') as f:\n        loaded_fig = pickle.load(f)\n\n    # Delete the pickle file\n    os.remove(file_path)\n\n    return loaded_fig"}
{"task_id": "BigCodeBench/439", "solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(P, T):\n    # Check if inputs are numpy arrays\n    if not isinstance(P, np.ndarray) or not isinstance(T, np.ndarray):\n        raise ValueError(\"Both inputs must be numpy arrays.\")\n\n    # Check if P is a 2D matrix\n    if P.ndim != 2:\n        raise ValueError(\"P must be a 2D matrix.\")\n\n    # Check if T is a 3D tensor\n    if T.ndim != 3:\n        raise ValueError(\"T must be a 3D tensor.\")\n\n    # Check if the dimensions of P and T are compatible for multiplication\n    if P.shape[1] != T.shape[0]:\n        raise ValueError(\"The dimensions of P and T are not compatible for multiplication.\")\n\n    # Perform matrix-tensor multiplication\n    result = np.matmul(P, T)\n\n    # Create a heatmap of the result\n    fig, ax = plt.subplots()\n    sns.heatmap(result, ax=ax)\n\n    return result, ax", "raw_solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(P, T):\n    # Check if inputs are numpy arrays\n    if not isinstance(P, np.ndarray) or not isinstance(T, np.ndarray):\n        raise ValueError(\"Both inputs must be numpy arrays.\")\n\n    # Check if P is a 2D matrix\n    if P.ndim != 2:\n        raise ValueError(\"P must be a 2D matrix.\")\n\n    # Check if T is a 3D tensor\n    if T.ndim != 3:\n        raise ValueError(\"T must be a 3D tensor.\")\n\n    # Check if the dimensions of P and T are compatible for multiplication\n    if P.shape[1] != T.shape[0]:\n        raise ValueError(\"The dimensions of P and T are not compatible for multiplication.\")\n\n    # Perform matrix-tensor multiplication\n    result = np.matmul(P, T)\n\n    # Create a heatmap of the result\n    fig, ax = plt.subplots()\n    sns.heatmap(result, ax=ax)\n\n    return result, ax"}
{"task_id": "BigCodeBench/440", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(P, T):\n    # Check if shapes are compatible for multiplication\n    if P.shape[1] != T.shape[0]:\n        raise ValueError(\"Shapes are not compatible for multiplication\")\n\n    # Perform matrix-tensor multiplication\n    result = np.matmul(P, T)\n\n    # Flatten the result\n    result = result.flatten()\n\n    # Normalize the result\n    scaler = StandardScaler()\n    result = scaler.fit_transform(result.reshape(-1, 1))\n\n    # Convert the result to a DataFrame\n    df = pd.DataFrame(result, columns=['feature_' + str(i) for i in range(result.shape[1])])\n\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(P, T):\n    # Check if shapes are compatible for multiplication\n    if P.shape[1] != T.shape[0]:\n        raise ValueError(\"Shapes are not compatible for multiplication\")\n\n    # Perform matrix-tensor multiplication\n    result = np.matmul(P, T)\n\n    # Flatten the result\n    result = result.flatten()\n\n    # Normalize the result\n    scaler = StandardScaler()\n    result = scaler.fit_transform(result.reshape(-1, 1))\n\n    # Convert the result to a DataFrame\n    df = pd.DataFrame(result, columns=['feature_' + str(i) for i in range(result.shape[1])])\n\n    return df"}
{"task_id": "BigCodeBench/441", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\ndef task_func(P, T):\n    # Check if inputs are numpy arrays\n    if not isinstance(P, np.ndarray) or not isinstance(T, np.ndarray):\n        raise ValueError(\"Both inputs must be numpy arrays.\")\n\n    # Check if inputs are of correct shapes\n    if P.ndim != 2 or T.ndim != 3:\n        raise ValueError(\"Matrix P must be 2D and tensor T must be 3D.\")\n\n    # Check if the last dimension of P matches the second dimension of T\n    if P.shape[1] != T.shape[1]:\n        raise ValueError(\"The last dimension of P must match the second dimension of T.\")\n\n    # Calculate the product of P and T using Einstein summation\n    result = np.einsum('ij,ajk->aij', P, T)\n\n    # Create a new figure and 3D axes\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n\n    # Plot the result\n    ax.scatter(result[:, 0], result[:, 1], result[:, 2])\n\n    return result, ax\nP = np.array([[1, 2], [3, 4], [5, 6]])\nT = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]], [[13, 14, 15], [16, 17, 18]]])", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef task_func(P, T):\n    # Check if inputs are numpy arrays\n    if not isinstance(P, np.ndarray) or not isinstance(T, np.ndarray):\n        raise ValueError(\"Both inputs must be numpy arrays.\")\n\n    # Check if inputs are of correct shapes\n    if P.ndim != 2 or T.ndim != 3:\n        raise ValueError(\"Matrix P must be 2D and tensor T must be 3D.\")\n\n    # Check if the last dimension of P matches the second dimension of T\n    if P.shape[1] != T.shape[1]:\n        raise ValueError(\"The last dimension of P must match the second dimension of T.\")\n\n    # Calculate the product of P and T using Einstein summation\n    result = np.einsum('ij,ajk->aij', P, T)\n\n    # Create a new figure and 3D axes\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n\n    # Plot the result\n    ax.scatter(result[:, 0], result[:, 1], result[:, 2])\n\n    return result, ax\n\n# Test the function\nP = np.array([[1, 2], [3, 4], [5, 6]])\nT = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]], [[13, 14, 15], [16, 17, 18]]])\nresult, ax = task_func(P, T)\nplt.show()"}
{"task_id": "BigCodeBench/442", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(P, T, tensor_shape=(3, 3, 3)):\n    # Calculate the product of a matrix \"P\" and a 3D tensor \"T\"\n    product = np.matmul(P, T.reshape(-1, tensor_shape[0]*tensor_shape[1]*tensor_shape[2]))\n\n    # Apply PCA to reduce the dimensionality of the result\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(product)\n\n    # Visualize the 2D data\n    fig, ax = plt.subplots()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1])\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    ax.set_title('PCA Result Visualization')\n\n    return pca_result, ax", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(P, T, tensor_shape=(3, 3, 3)):\n    # Calculate the product of a matrix \"P\" and a 3D tensor \"T\"\n    product = np.matmul(P, T.reshape(-1, tensor_shape[0]*tensor_shape[1]*tensor_shape[2]))\n\n    # Apply PCA to reduce the dimensionality of the result\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(product)\n\n    # Visualize the 2D data\n    fig, ax = plt.subplots()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1])\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    ax.set_title('PCA Result Visualization')\n\n    return pca_result, ax"}
{"task_id": "BigCodeBench/443", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    \n    # Calculate the product of a matrix 'P' and a 3D tensor 'T'\n    product = np.matmul(P, T)\n    \n    # Flatten the result\n    flattened = product.flatten()\n    \n    # Apply KMeans clustering to the flattened data\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    cluster_result = kmeans.fit_predict(flattened.reshape(-1, 1))\n    \n    # Visualize it\n    fig, ax = plt.subplots()\n    ax.scatter(range(len(flattened)), flattened, c=cluster_result)\n    ax.set_title('KMeans Clustering Visualization')\n    \n    return cluster_result, ax", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    \n    # Calculate the product of a matrix 'P' and a 3D tensor 'T'\n    product = np.matmul(P, T)\n    \n    # Flatten the result\n    flattened = product.flatten()\n    \n    # Apply KMeans clustering to the flattened data\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    cluster_result = kmeans.fit_predict(flattened.reshape(-1, 1))\n    \n    # Visualize it\n    fig, ax = plt.subplots()\n    ax.scatter(range(len(flattened)), flattened, c=cluster_result)\n    ax.set_title('KMeans Clustering Visualization')\n    \n    return cluster_result, ax"}
{"task_id": "BigCodeBench/444", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\ndef task_func(n_points=100, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    points = np.random.sample((n_points, 3))\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(points[:,0], points[:,1], points[:,2])\n\n    return (points, ax)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef task_func(n_points=100, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    points = np.random.sample((n_points, 3))\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(points[:,0], points[:,1], points[:,2])\n\n    return (points, ax)\n\n# Test the function\npoints, plot = task_func(100, 0)"}
{"task_id": "BigCodeBench/445", "solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\ndef task_func(points, seed=0):\n    # Check if points is a numpy array and of shape (n, 2)\n    if not isinstance(points, np.ndarray) or points.shape[1] != 2:\n        raise ValueError(\"Points should be a numpy array of shape (n, 2)\")\n\n    # Check if seed is an integer\n    if not isinstance(seed, int):\n        raise ValueError(\"Seed should be an integer\")\n\n    # Set the seed for the random number generator\n    np.random.seed(seed)\n\n    # Apply jitter to the points\n    points = points + np.random.rand(*points.shape)\n\n    # Compute the Voronoi diagram\n    vor = Voronoi(points)\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot the Voronoi diagram\n    voronoi_plot_2d(vor, ax=ax)\n\n    # Return the Voronoi object and the axes\n    return vor, ax", "raw_solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\n\ndef task_func(points, seed=0):\n    # Check if points is a numpy array and of shape (n, 2)\n    if not isinstance(points, np.ndarray) or points.shape[1] != 2:\n        raise ValueError(\"Points should be a numpy array of shape (n, 2)\")\n\n    # Check if seed is an integer\n    if not isinstance(seed, int):\n        raise ValueError(\"Seed should be an integer\")\n\n    # Set the seed for the random number generator\n    np.random.seed(seed)\n\n    # Apply jitter to the points\n    points = points + np.random.rand(*points.shape)\n\n    # Compute the Voronoi diagram\n    vor = Voronoi(points)\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot the Voronoi diagram\n    voronoi_plot_2d(vor, ax=ax)\n\n    # Return the Voronoi object and the axes\n    return vor, ax"}
{"task_id": "BigCodeBench/446", "solution": "import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nimport numpy as np\ndef task_func(n_samples=100, centers=3, n_features=2, random_seed=42):\n    # Set the random seed for reproducibility\n    np.random.seed(random_seed)\n\n    # Generate isotropic Gaussian blobs\n    X, y = make_blobs(n_samples=n_samples, centers=centers, n_features=n_features, cluster_std=1.0, random_state=random_seed)\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='viridis')\n\n    return (X, y, ax)", "raw_solution": "import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nimport numpy as np\n\ndef task_func(n_samples=100, centers=3, n_features=2, random_seed=42):\n    # Set the random seed for reproducibility\n    np.random.seed(random_seed)\n\n    # Generate isotropic Gaussian blobs\n    X, y = make_blobs(n_samples=n_samples, centers=centers, n_features=n_features, cluster_std=1.0, random_state=random_seed)\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='viridis')\n\n    return (X, y, ax)\n\n# Test the function\nX, y, ax = task_func()\nplt.show()"}
{"task_id": "BigCodeBench/447", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(data, n_components=2, random_state=None):\n    pca = PCA(n_components=n_components, random_state=random_state)\n    transformed_data = pca.fit_transform(data)\n\n    fig, ax = plt.subplots()\n    if n_components == 1:\n        ax.scatter(transformed_data, np.zeros_like(transformed_data))\n    elif n_components == 2:\n        ax.scatter(transformed_data[:, 0], transformed_data[:, 1])\n    else:\n        ax.scatter(transformed_data[:, 0], np.zeros_like(transformed_data[:, 0]))\n\n    plt.show()\n\n    return {\"transformed_data\": transformed_data, \"ax\": ax}", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(data, n_components=2, random_state=None):\n    pca = PCA(n_components=n_components, random_state=random_state)\n    transformed_data = pca.fit_transform(data)\n\n    fig, ax = plt.subplots()\n    if n_components == 1:\n        ax.scatter(transformed_data, np.zeros_like(transformed_data))\n    elif n_components == 2:\n        ax.scatter(transformed_data[:, 0], transformed_data[:, 1])\n    else:\n        ax.scatter(transformed_data[:, 0], np.zeros_like(transformed_data[:, 0]))\n\n    plt.show()\n\n    return {\"transformed_data\": transformed_data, \"ax\": ax}"}
{"task_id": "BigCodeBench/448", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(mu=0, sigma=1):\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = norm.pdf(x, mu, sigma)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    ax.set_title(f'Normal Distribution with Mean={mu} and Standard Deviation={sigma}')\n    ax.set_xlabel('x')\n    ax.set_ylabel('Probability Density')\n\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(mu=0, sigma=1):\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = norm.pdf(x, mu, sigma)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    ax.set_title(f'Normal Distribution with Mean={mu} and Standard Deviation={sigma}')\n    ax.set_xlabel('x')\n    ax.set_ylabel('Probability Density')\n\n    return ax\n\n# Test the function\nax = task_func(0, 1)\nplt.show()"}
{"task_id": "BigCodeBench/449", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, list):\n    scaler = StandardScaler()\n    standardized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n    fig, axes = plt.subplots(nrows=len(data.columns), ncols=1, figsize=(10, 3*len(data.columns)))\n    axes_list = []\n    for i, column in enumerate(data.columns):\n        axes[i].hist(standardized_data[column], bins=20, color='blue', alpha=0.7)\n        axes[i].set_title(f'Histogram of {column}')\n        axes[i].set_xlabel(f'{column}')\n        axes[i].set_ylabel('Frequency')\n        axes_list.append(axes[i])\n\n    plt.tight_layout()\n    plt.show()\n\n    return standardized_data, axes_list", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, list):\n    scaler = StandardScaler()\n    standardized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n    fig, axes = plt.subplots(nrows=len(data.columns), ncols=1, figsize=(10, 3*len(data.columns)))\n    axes_list = []\n    for i, column in enumerate(data.columns):\n        axes[i].hist(standardized_data[column], bins=20, color='blue', alpha=0.7)\n        axes[i].set_title(f'Histogram of {column}')\n        axes[i].set_xlabel(f'{column}')\n        axes[i].set_ylabel('Frequency')\n        axes_list.append(axes[i])\n\n    plt.tight_layout()\n    plt.show()\n\n    return standardized_data, axes_list"}
{"task_id": "BigCodeBench/450", "solution": "from scipy.spatial.distance import cdist\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(n_samples=200, centers=4, plot_path=None, random_seed=None):\n    # Generate synthetic 2D dataset\n    X, y = make_blobs(n_samples=n_samples, centers=centers, random_state=random_seed)\n\n    # Calculate Euclidean distance between individual samples\n    dist_matrix = cdist(X, X, metric='euclidean')\n\n    # Visualize the dataset\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(X[:,0], X[:,1], c=y)\n    ax.set_xlabel('Feature 1')\n    ax.set_ylabel('Feature 2')\n    plt.colorbar(scatter, ax=ax)\n\n    if plot_path is not None:\n        plt.savefig(plot_path)\n        return None\n    else:\n        return dist_matrix, plt.gca()", "raw_solution": "from scipy.spatial.distance import cdist\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(n_samples=200, centers=4, plot_path=None, random_seed=None):\n    # Generate synthetic 2D dataset\n    X, y = make_blobs(n_samples=n_samples, centers=centers, random_state=random_seed)\n\n    # Calculate Euclidean distance between individual samples\n    dist_matrix = cdist(X, X, metric='euclidean')\n\n    # Visualize the dataset\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(X[:,0], X[:,1], c=y)\n    ax.set_xlabel('Feature 1')\n    ax.set_ylabel('Feature 2')\n    plt.colorbar(scatter, ax=ax)\n\n    if plot_path is not None:\n        plt.savefig(plot_path)\n        return None\n    else:\n        return dist_matrix, plt.gca()"}
{"task_id": "BigCodeBench/451", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(n_components=2, N_SAMPLES=500, N_FEATURES=50, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n\n    # Generate a high-dimensional dataset\n    X = np.random.randn(N_SAMPLES, N_FEATURES)\n\n    # Run PCA to reduce its dimensionality\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(X)\n\n    # Draw a heatmap of the covariance matrix of the transformed data\n    if n_components == 1:\n        return transformed_data, None\n\n    cov_matrix = np.cov(transformed_data, rowvar=False)\n    fig, heatmap_axes = plt.subplots(1, 1)\n    sns.heatmap(cov_matrix, ax=heatmap_axes)\n    plt.show()\n\n    return transformed_data, heatmap_axes", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(n_components=2, N_SAMPLES=500, N_FEATURES=50, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n\n    # Generate a high-dimensional dataset\n    X = np.random.randn(N_SAMPLES, N_FEATURES)\n\n    # Run PCA to reduce its dimensionality\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(X)\n\n    # Draw a heatmap of the covariance matrix of the transformed data\n    if n_components == 1:\n        return transformed_data, None\n\n    cov_matrix = np.cov(transformed_data, rowvar=False)\n    fig, heatmap_axes = plt.subplots(1, 1)\n    sns.heatmap(cov_matrix, ax=heatmap_axes)\n    plt.show()\n\n    return transformed_data, heatmap_axes"}
{"task_id": "BigCodeBench/452", "solution": "import numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\ndef task_func(n_samples=100, n_features=10, random_seed=None):\n    # Generate synthetic data\n    X, y, coef = datasets.make_regression(n_samples=n_samples, n_features=n_features, coef=True, random_state=random_seed)\n\n    # Split the data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n\n    # Fit a linear regression model\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    # Get the predictions\n    predictions = model.predict(X_test)\n\n    # Get the coefficients and intercept\n    coefficients = model.coef_\n    intercept = model.intercept_\n\n    # Calculate the mean squared error\n    mse = mean_squared_error(y_test, predictions)\n\n    return (predictions, coefficients, intercept, mse)", "raw_solution": "import numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\ndef task_func(n_samples=100, n_features=10, random_seed=None):\n    # Generate synthetic data\n    X, y, coef = datasets.make_regression(n_samples=n_samples, n_features=n_features, coef=True, random_state=random_seed)\n\n    # Split the data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n\n    # Fit a linear regression model\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    # Get the predictions\n    predictions = model.predict(X_test)\n\n    # Get the coefficients and intercept\n    coefficients = model.coef_\n    intercept = model.intercept_\n\n    # Calculate the mean squared error\n    mse = mean_squared_error(y_test, predictions)\n\n    return (predictions, coefficients, intercept, mse)"}
{"task_id": "BigCodeBench/453", "solution": "import re\nimport string\nfrom random import choice\ndef task_func(n, pattern):\n    while True:\n        random_string = ''.join(choice(string.ascii_letters) for _ in range(n))\n        if re.match(pattern, random_string):\n            return random_string", "raw_solution": "import re\nimport string\nfrom random import choice\n\ndef task_func(n, pattern):\n    while True:\n        random_string = ''.join(choice(string.ascii_letters) for _ in range(n))\n        if re.match(pattern, random_string):\n            return random_string\n\n# Test the function"}
{"task_id": "BigCodeBench/454", "solution": "import os\nimport shutil\nimport glob\ndef task_func(src_dir, dest_dir, ext):\n    # Check if source and destination directories exist\n    if not os.path.isdir(src_dir):\n        raise FileNotFoundError(\"Source directory does not exist\")\n    if not os.path.isdir(dest_dir):\n        raise FileNotFoundError(\"Destination directory does not exist\")\n\n    # Get a list of files with the specified extension in the source directory\n    files = glob.glob(os.path.join(src_dir, f'*.{ext}'))\n\n    # Initialize an empty list to store the paths of successfully moved files\n    moved_files = []\n\n    # Move each file to the destination directory\n    for file in files:\n        # Get the file name and its full path\n        file_name = os.path.basename(file)\n        dest_file = os.path.join(dest_dir, file_name)\n\n        # If the file does not already exist in the destination directory, move it\n        if not os.path.isfile(dest_file):\n            shutil.move(file, dest_dir)\n            moved_files.append(dest_file)\n\n    # Return the list of successfully moved files\n    return moved_files", "raw_solution": "import os\nimport shutil\nimport glob\n\ndef task_func(src_dir, dest_dir, ext):\n    # Check if source and destination directories exist\n    if not os.path.isdir(src_dir):\n        raise FileNotFoundError(\"Source directory does not exist\")\n    if not os.path.isdir(dest_dir):\n        raise FileNotFoundError(\"Destination directory does not exist\")\n\n    # Get a list of files with the specified extension in the source directory\n    files = glob.glob(os.path.join(src_dir, f'*.{ext}'))\n\n    # Initialize an empty list to store the paths of successfully moved files\n    moved_files = []\n\n    # Move each file to the destination directory\n    for file in files:\n        # Get the file name and its full path\n        file_name = os.path.basename(file)\n        dest_file = os.path.join(dest_dir, file_name)\n\n        # If the file does not already exist in the destination directory, move it\n        if not os.path.isfile(dest_file):\n            shutil.move(file, dest_dir)\n            moved_files.append(dest_file)\n\n    # Return the list of successfully moved files\n    return moved_files"}
{"task_id": "BigCodeBench/455", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(mean, std_dev, n):\n    # Generate samples from a normal distribution\n    samples = np.random.normal(mean, std_dev, n)\n\n    # Plotting the histogram\n    plt.hist(samples, bins=30, density=True)\n\n    # Generate x values for the probability density function\n    x = np.linspace(min(samples), max(samples), 100)\n\n    # Plotting the probability density function\n    plt.plot(x, stats.norm.pdf(x, mean, std_dev))\n\n    # Show the plot\n    plt.show()\n\n    return samples", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(mean, std_dev, n):\n    # Generate samples from a normal distribution\n    samples = np.random.normal(mean, std_dev, n)\n\n    # Plotting the histogram\n    plt.hist(samples, bins=30, density=True)\n\n    # Generate x values for the probability density function\n    x = np.linspace(min(samples), max(samples), 100)\n\n    # Plotting the probability density function\n    plt.plot(x, stats.norm.pdf(x, mean, std_dev))\n\n    # Show the plot\n    plt.show()\n\n    return samples\n\n# Test the function\nsamples = task_func(5, 2, 500)"}
{"task_id": "BigCodeBench/456", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, plt.Axes):\n    # Normalize the data\n    scaler = MinMaxScaler()\n    normalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    heatmap = sns.heatmap(normalized_data, cmap='YlGnBu', cbar_kws={\"label\": \"Normalized Value\"})\n\n    return normalized_data, heatmap.figure", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, plt.Axes):\n    # Normalize the data\n    scaler = MinMaxScaler()\n    normalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    heatmap = sns.heatmap(normalized_data, cmap='YlGnBu', cbar_kws={\"label\": \"Normalized Value\"})\n\n    return normalized_data, heatmap.figure"}
{"task_id": "BigCodeBench/457", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(L):\n    if not isinstance(L, list):\n        raise TypeError(\"Input should be a list\")\n    for sublist in L:\n        if not isinstance(sublist, list):\n            raise TypeError(\"Input should be a list of lists\")\n        for item in sublist:\n            if not isinstance(item, int):\n                raise TypeError(\"All elements in the list should be integers\")\n\n    # Flatten the list and ignore empty sublists\n    flat_list = [item for sublist in L for item in sublist if sublist]\n\n    # Convert the list to a pandas Series\n    series = pd.Series(flat_list)\n\n    # Plot the histogram\n    ax = series.plot.hist(bins=series.unique().size, rwidth=0.8)\n\n    return ax\nL = [[1, 1, 2, 2, 3], [2, 3, 4, 5, 6], [3, 4, 5, 6, 7]]", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    if not isinstance(L, list):\n        raise TypeError(\"Input should be a list\")\n    for sublist in L:\n        if not isinstance(sublist, list):\n            raise TypeError(\"Input should be a list of lists\")\n        for item in sublist:\n            if not isinstance(item, int):\n                raise TypeError(\"All elements in the list should be integers\")\n\n    # Flatten the list and ignore empty sublists\n    flat_list = [item for sublist in L for item in sublist if sublist]\n\n    # Convert the list to a pandas Series\n    series = pd.Series(flat_list)\n\n    # Plot the histogram\n    ax = series.plot.hist(bins=series.unique().size, rwidth=0.8)\n\n    return ax\n\n# Test the function\nL = [[1, 1, 2, 2, 3], [2, 3, 4, 5, 6], [3, 4, 5, 6, 7]]\nax = task_func(L)\nplt.show()"}
{"task_id": "BigCodeBench/458", "solution": "import json\nimport re\nimport pandas as pd\ndef task_func(json_str):\n    # Check if the JSON string is empty\n    if not json_str:\n        return pd.DataFrame()\n\n    # Load JSON string into a dictionary\n    data_dict = json.loads(json_str)\n\n    # Normalize the dictionary by doubling the numerical values\n    def normalize_value(value):\n        if isinstance(value, (int, float)):\n            return value * 2\n        elif isinstance(value, list):\n            return [v * 2 if isinstance(v, (int, float)) else v for v in value]\n        elif isinstance(value, str):\n            # Extract numbers from the string and double them\n            numbers = re.findall(r'-?\\d+\\.?\\d*', value)\n            return [float(num) * 2 for num in numbers] if numbers else value\n        else:\n            return value\n\n    data_dict = {key: normalize_value(value) for key, value in data_dict.items()}\n\n    # Create a Pandas DataFrame from the dictionary\n    df = pd.DataFrame(data_dict)\n\n    return df", "raw_solution": "import json\nimport re\nimport pandas as pd\n\ndef task_func(json_str):\n    # Check if the JSON string is empty\n    if not json_str:\n        return pd.DataFrame()\n\n    # Load JSON string into a dictionary\n    data_dict = json.loads(json_str)\n\n    # Normalize the dictionary by doubling the numerical values\n    def normalize_value(value):\n        if isinstance(value, (int, float)):\n            return value * 2\n        elif isinstance(value, list):\n            return [v * 2 if isinstance(v, (int, float)) else v for v in value]\n        elif isinstance(value, str):\n            # Extract numbers from the string and double them\n            numbers = re.findall(r'-?\\d+\\.?\\d*', value)\n            return [float(num) * 2 for num in numbers] if numbers else value\n        else:\n            return value\n\n    data_dict = {key: normalize_value(value) for key, value in data_dict.items()}\n\n    # Create a Pandas DataFrame from the dictionary\n    df = pd.DataFrame(data_dict)\n\n    return df"}
{"task_id": "BigCodeBench/459", "solution": "import subprocess\nimport os\nimport time\nfrom datetime import datetime\ndef task_func(script_dir, scripts, delay):\n    if delay < 0:\n        raise ValueError(\"Delay cannot be negative\")\n    if not scripts:\n        raise ValueError(\"No scripts provided\")\n\n    timestamps = []\n\n    for script in scripts:\n        if not os.path.exists(os.path.join(script_dir, script)):\n            print(f\"Script {script} not found in directory {script_dir}\")\n            continue\n\n        script_path = os.path.join(script_dir, script)\n        timestamps.append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n        print(f\"Executing script {script} at {timestamps[-1]}\")\n        subprocess.run([\"bash\", script_path])\n\n        if delay > 0:\n            print(f\"Waiting for {delay} seconds before executing next script\")\n            time.sleep(delay)\n\n    return timestamps", "raw_solution": "import subprocess\nimport os\nimport time\nfrom datetime import datetime\n\ndef task_func(script_dir, scripts, delay):\n    if delay < 0:\n        raise ValueError(\"Delay cannot be negative\")\n    if not scripts:\n        raise ValueError(\"No scripts provided\")\n\n    timestamps = []\n\n    for script in scripts:\n        if not os.path.exists(os.path.join(script_dir, script)):\n            print(f\"Script {script} not found in directory {script_dir}\")\n            continue\n\n        script_path = os.path.join(script_dir, script)\n        timestamps.append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n        print(f\"Executing script {script} at {timestamps[-1]}\")\n        subprocess.run([\"bash\", script_path])\n\n        if delay > 0:\n            print(f\"Waiting for {delay} seconds before executing next script\")\n            time.sleep(delay)\n\n    return timestamps"}
{"task_id": "BigCodeBench/460", "solution": "import subprocess\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(script_path, output_file_path):\n    try:\n        # Execute the script\n        subprocess.run([\"python\", script_path, output_file_path], check=True)\n    except subprocess.CalledProcessError as e:\n        raise ValueError(f\"Script execution failed with error: {str(e)}\")\n\n    # Read the CSV into a DataFrame\n    try:\n        df = pd.read_csv(output_file_path)\n    except pd.errors.ParserError as e:\n        raise ValueError(f\"CSV is invalid with error: {str(e)}\")\n\n    # Check if the CSV has exactly 2 columns\n    if df.shape[1] != 2:\n        raise ValueError(\"CSV does not contain exactly 2 columns\")\n\n    # Plot a bar graph\n    fig, ax = plt.subplots()\n    ax.bar(df.iloc[:, 0], df.iloc[:, 1])\n\n    return df, ax.figure", "raw_solution": "import subprocess\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(script_path, output_file_path):\n    try:\n        # Execute the script\n        subprocess.run([\"python\", script_path, output_file_path], check=True)\n    except subprocess.CalledProcessError as e:\n        raise ValueError(f\"Script execution failed with error: {str(e)}\")\n\n    # Read the CSV into a DataFrame\n    try:\n        df = pd.read_csv(output_file_path)\n    except pd.errors.ParserError as e:\n        raise ValueError(f\"CSV is invalid with error: {str(e)}\")\n\n    # Check if the CSV has exactly 2 columns\n    if df.shape[1] != 2:\n        raise ValueError(\"CSV does not contain exactly 2 columns\")\n\n    # Plot a bar graph\n    fig, ax = plt.subplots()\n    ax.bar(df.iloc[:, 0], df.iloc[:, 1])\n\n    return df, ax.figure\n\n# Test the function\ndf, ax = task_func(\"path_to_your_script.py\", \"output.csv\")"}
{"task_id": "BigCodeBench/461", "solution": "import subprocess\nimport psutil\nimport time\nimport os\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.exists(script_path):\n        raise FileNotFoundError(f\"The script path {script_path} does not exist.\")\n\n    start_time = time.time()\n    process = subprocess.Popen(['python', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    cpu_percent = 0.0\n    memory_usage = 0.0\n\n    while True:\n        if time.time() - start_time > timeout:\n            process.terminate()\n            break\n\n        if process.poll() is not None:\n            break\n\n        for proc in psutil.process_iter(['pid', 'cpu_percent', 'memory_info']):\n            if proc.info['pid'] == process.pid:\n                cpu_percent += proc.info['cpu_percent'] / psutil.cpu_count()\n                memory_usage += proc.info['memory_info'].rss\n                break\n\n        time.sleep(0.1)\n\n    return {'CPU Usage': cpu_percent, 'Memory Usage': memory_usage}", "raw_solution": "import subprocess\nimport psutil\nimport time\nimport os\n\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.exists(script_path):\n        raise FileNotFoundError(f\"The script path {script_path} does not exist.\")\n\n    start_time = time.time()\n    process = subprocess.Popen(['python', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    cpu_percent = 0.0\n    memory_usage = 0.0\n\n    while True:\n        if time.time() - start_time > timeout:\n            process.terminate()\n            break\n\n        if process.poll() is not None:\n            break\n\n        for proc in psutil.process_iter(['pid', 'cpu_percent', 'memory_info']):\n            if proc.info['pid'] == process.pid:\n                cpu_percent += proc.info['cpu_percent'] / psutil.cpu_count()\n                memory_usage += proc.info['memory_info'].rss\n                break\n\n        time.sleep(0.1)\n\n    return {'CPU Usage': cpu_percent, 'Memory Usage': memory_usage}"}
{"task_id": "BigCodeBench/462", "solution": "import pandas as pd\nimport random\nimport matplotlib.pyplot as plt\ndef task_func(num_rows=100, categories=[\"a\", \"b\", \"c\", \"d\", \"e\"], random_seed=42):\n    if num_rows < 1:\n        raise ValueError(\"num_rows must be greater than 0\")\n    random.seed(random_seed)\n    df = pd.DataFrame({\n        'Category': [random.choice(categories) for _ in range(num_rows)],\n        'Value': [random.randint(1, 100) for _ in range(num_rows)]\n    })\n    counts = df['Category'].value_counts()\n    fig, ax = plt.subplots()\n    counts.plot(kind='bar', ax=ax)\n    ax.set_title('Category Counts')\n    return df, ax.figure", "raw_solution": "import pandas as pd\nimport random\nimport matplotlib.pyplot as plt\n\ndef task_func(num_rows=100, categories=[\"a\", \"b\", \"c\", \"d\", \"e\"], random_seed=42):\n    if num_rows < 1:\n        raise ValueError(\"num_rows must be greater than 0\")\n    random.seed(random_seed)\n    df = pd.DataFrame({\n        'Category': [random.choice(categories) for _ in range(num_rows)],\n        'Value': [random.randint(1, 100) for _ in range(num_rows)]\n    })\n    counts = df['Category'].value_counts()\n    fig, ax = plt.subplots()\n    counts.plot(kind='bar', ax=ax)\n    ax.set_title('Category Counts')\n    return df, ax.figure"}
{"task_id": "BigCodeBench/463", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data_str, separator=\",\", bins=20):\n    # Raise ValueError if data is empty\n    if not data_str:\n        raise ValueError(\"Data is empty\")\n\n    # Convert string to list of numerical values\n    data_list = data_str.split(separator)\n\n    # Convert list to pandas Series\n    data_series = pd.Series(data_list).astype(int)\n\n    # Plot histogram\n    fig, ax = plt.subplots()\n    ax.hist(data_series, bins=bins, grid=True, rwidth=0.9, color='#607c8e')\n\n    return (data_series, ax)\ndata_str = \"1,2,3,4,5,6,7,8,9,10\"", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data_str, separator=\",\", bins=20):\n    # Raise ValueError if data is empty\n    if not data_str:\n        raise ValueError(\"Data is empty\")\n\n    # Convert string to list of numerical values\n    data_list = data_str.split(separator)\n\n    # Convert list to pandas Series\n    data_series = pd.Series(data_list).astype(int)\n\n    # Plot histogram\n    fig, ax = plt.subplots()\n    ax.hist(data_series, bins=bins, grid=True, rwidth=0.9, color='#607c8e')\n\n    return (data_series, ax)\n\n# Test the function\ndata_str = \"1,2,3,4,5,6,7,8,9,10\"\nseries, ax = task_func(data_str)\nplt.show()"}
{"task_id": "BigCodeBench/464", "solution": "import json\nfrom datetime import datetime\nfrom decimal import Decimal\nclass CustomEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        elif isinstance(obj, Decimal):\n            return str(obj)\n        return super().default(obj)\ndef task_func(my_obj):\n    return json.dumps(my_obj, cls=CustomEncoder)", "raw_solution": "import json\nfrom datetime import datetime\nfrom decimal import Decimal\n\nclass CustomEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        elif isinstance(obj, Decimal):\n            return str(obj)\n        return super().default(obj)\n\ndef task_func(my_obj):\n    return json.dumps(my_obj, cls=CustomEncoder)\n\n# Testing"}
{"task_id": "BigCodeBench/465", "solution": "import json\nfrom datetime import datetime\nimport numpy as np\nfrom decimal import Decimal\nclass CustomEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        elif isinstance(obj, Decimal):\n            return str(obj)\n        else:\n            raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\ndef task_func(my_obj):\n    return json.dumps(my_obj, cls=CustomEncoder)", "raw_solution": "import json\nfrom datetime import datetime\nimport numpy as np\nfrom decimal import Decimal\n\nclass CustomEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        elif isinstance(obj, Decimal):\n            return str(obj)\n        else:\n            raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\n\ndef task_func(my_obj):\n    return json.dumps(my_obj, cls=CustomEncoder)\n\n# Testing"}
{"task_id": "BigCodeBench/466", "solution": "import json\nfrom enum import Enum\nclass EnumEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, Enum):\n            return obj.name\n        return super().default(obj)\ndef task_func(my_obj):\n    json_str = json.dumps(my_obj, cls=EnumEncoder)\n    return json_str", "raw_solution": "import json\nfrom enum import Enum\n\nclass Color(Enum):\n    RED = 1\n    GREEN = 2\n    BLUE = 3\n\nclass EnumEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, Enum):\n            return obj.name\n        return super().default(obj)\n\ndef task_func(my_obj):\n    json_str = json.dumps(my_obj, cls=EnumEncoder)\n    return json_str\n\n# Test the function"}
{"task_id": "BigCodeBench/467", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(n, seed=0):\n    np.random.seed(seed)\n    points = [(x, y) for x, y in np.random.rand(n, 2)]\n\n    fig, ax = plt.subplots()\n    ax.scatter([x for x, y in points], [y for x, y in points])\n    ax.set_title(\"Scatter plot of random points\")\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n\n    return fig, points", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(n, seed=0):\n    np.random.seed(seed)\n    points = [(x, y) for x, y in np.random.rand(n, 2)]\n\n    fig, ax = plt.subplots()\n    ax.scatter([x for x, y in points], [y for x, y in points])\n    ax.set_title(\"Scatter plot of random points\")\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n\n    return fig, points\n\n# Test the function\nfig, points = task_func(10)\nplt.show()"}
{"task_id": "BigCodeBench/468", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(file_path=\"data.csv\", columns=[\"A\", \"B\", \"C\"]):\n    # Read CSV file into DataFrame\n    df = pd.read_csv(file_path)\n\n    # Convert numeric values into floats\n    df[columns] = df[columns].apply(pd.to_numeric, errors='coerce')\n\n    # Draw a line chart of data in the specified columns\n    fig, ax = plt.subplots()\n    df[columns].plot(ax=ax)\n\n    # Compute the cube-root of the data\n    cube_root_series = np.cbrt(df[columns])\n\n    return df, ax.figure, cube_root_series", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path=\"data.csv\", columns=[\"A\", \"B\", \"C\"]):\n    # Read CSV file into DataFrame\n    df = pd.read_csv(file_path)\n\n    # Convert numeric values into floats\n    df[columns] = df[columns].apply(pd.to_numeric, errors='coerce')\n\n    # Draw a line chart of data in the specified columns\n    fig, ax = plt.subplots()\n    df[columns].plot(ax=ax)\n\n    # Compute the cube-root of the data\n    cube_root_series = np.cbrt(df[columns])\n\n    return df, ax.figure, cube_root_series"}
{"task_id": "BigCodeBench/469", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\ndef task_func(student_grades, possible_grades=[\"A\", \"B\", \"C\", \"D\", \"F\"]):\n    # Normalize grades to uppercase and remove leading/trailing whitespaces\n    student_grades = [grade.strip().upper() for grade in student_grades]\n\n    # Filter out grades not in possible grades\n    student_grades = [grade for grade in student_grades if grade in possible_grades]\n\n    # Count grades\n    grade_counts = Counter(student_grades)\n\n    # Create DataFrame\n    df = pd.DataFrame.from_dict(grade_counts, orient='index', columns=['Count'])\n    df.index.name = 'Grade'\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Grade')\n    ax.set_ylabel('Number of Students')\n    ax.set_title('Grade Distribution')\n\n    return df, ax.figure\nstudent_grades = ['A', 'B', 'C', 'D', 'F', 'a', ' b ', 'c', 'd', 'e', 'f', '1', '2', '3', '4', '5']", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\ndef task_func(student_grades, possible_grades=[\"A\", \"B\", \"C\", \"D\", \"F\"]):\n    # Normalize grades to uppercase and remove leading/trailing whitespaces\n    student_grades = [grade.strip().upper() for grade in student_grades]\n\n    # Filter out grades not in possible grades\n    student_grades = [grade for grade in student_grades if grade in possible_grades]\n\n    # Count grades\n    grade_counts = Counter(student_grades)\n\n    # Create DataFrame\n    df = pd.DataFrame.from_dict(grade_counts, orient='index', columns=['Count'])\n    df.index.name = 'Grade'\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Grade')\n    ax.set_ylabel('Number of Students')\n    ax.set_title('Grade Distribution')\n\n    return df, ax.figure\n\n# Test the function\nstudent_grades = ['A', 'B', 'C', 'D', 'F', 'a', ' b ', 'c', 'd', 'e', 'f', '1', '2', '3', '4', '5']\ndf, fig = task_func(student_grades)\nplt.show()"}
{"task_id": "BigCodeBench/470", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(myList):\n    # Adjust bin edges to align with integer values in myList\n    bins = np.arange(min(myList), max(myList) + 2) - 0.5\n\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(myList, bins=bins, edgecolor='black')\n\n    # Set labels and title\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Values')\n\n    return ax\nmyList = [1, 2, 2, 3, 4, 4, 4, 5, 6, 6, 6, 6, 7, 7, 8, 8, 8, 8, 9, 9]", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(myList):\n    # Adjust bin edges to align with integer values in myList\n    bins = np.arange(min(myList), max(myList) + 2) - 0.5\n\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(myList, bins=bins, edgecolor='black')\n\n    # Set labels and title\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Values')\n\n    return ax\n\n# Test the function\nmyList = [1, 2, 2, 3, 4, 4, 4, 5, 6, 6, 6, 6, 7, 7, 8, 8, 8, 8, 9, 9]\nax = task_func(myList)\nplt.show()"}
{"task_id": "BigCodeBench/471", "solution": "from collections import Counter\nimport pandas as pd\ndef task_func(myList):\n    # Count the frequency of each word in the list\n    word_counts = Counter(myList)\n\n    # Create a DataFrame from the Counter object\n    df = pd.DataFrame(list(word_counts.items()), columns=['Word', 'Count'])\n\n    return df\nmyList = ['apple', 'banana', 'apple', 'orange', 'banana', 'banana']", "raw_solution": "from collections import Counter\nimport pandas as pd\n\ndef task_func(myList):\n    # Count the frequency of each word in the list\n    word_counts = Counter(myList)\n\n    # Create a DataFrame from the Counter object\n    df = pd.DataFrame(list(word_counts.items()), columns=['Word', 'Count'])\n\n    return df\n\n# Test the function\nmyList = ['apple', 'banana', 'apple', 'orange', 'banana', 'banana']"}
{"task_id": "BigCodeBench/472", "solution": "import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nimport numpy as np\ndef task_func(myList, n_clusters):\n    if not isinstance(myList, list):\n        raise ValueError(\"Input myList should be a list of 2D points\")\n    if not all(isinstance(i, list) and len(i) == 2 for i in myList):\n        raise ValueError(\"All elements in myList should be 2D points\")\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"n_clusters should be a positive integer\")\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n    kmeans.fit(myList)\n\n    fig, ax = plt.subplots()\n    ax.scatter(np.array(myList)[:, 0], np.array(myList)[:, 1], c=kmeans.labels_)\n    ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='x', c='r')\n\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nimport numpy as np\n\ndef task_func(myList, n_clusters):\n    if not isinstance(myList, list):\n        raise ValueError(\"Input myList should be a list of 2D points\")\n    if not all(isinstance(i, list) and len(i) == 2 for i in myList):\n        raise ValueError(\"All elements in myList should be 2D points\")\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"n_clusters should be a positive integer\")\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n    kmeans.fit(myList)\n\n    fig, ax = plt.subplots()\n    ax.scatter(np.array(myList)[:, 0], np.array(myList)[:, 1], c=kmeans.labels_)\n    ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='x', c='r')\n\n    return ax"}
{"task_id": "BigCodeBench/473", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\ndef task_func(n_walks, n_steps, seed=None):\n    # Check for valid n_walks and n_steps\n    if n_walks < 1 or n_steps < 1:\n        raise ValueError(\"n_walks and n_steps must be greater than 0\")\n\n    # Set seed for reproducibility\n    if seed is not None:\n        np.random.seed(seed)\n\n    # Define the step sizes\n    step_sizes = [-1, 1]\n\n    # Generate the random walks\n    walks = np.random.choice(step_sizes, size=(n_walks, n_steps))\n\n    # Calculate the cumulative sum of the walks to get the position at each step\n    positions = np.cumsum(walks, axis=1)\n\n    # Define the colors\n    colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n\n    # Create the plot\n    fig, ax = plt.subplots()\n\n    # Plot each walk in a different color\n    for walk in positions.T:\n        ax.plot(walk, color=next(colors))\n\n    # Return the plot\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef task_func(n_walks, n_steps, seed=None):\n    # Check for valid n_walks and n_steps\n    if n_walks < 1 or n_steps < 1:\n        raise ValueError(\"n_walks and n_steps must be greater than 0\")\n\n    # Set seed for reproducibility\n    if seed is not None:\n        np.random.seed(seed)\n\n    # Define the step sizes\n    step_sizes = [-1, 1]\n\n    # Generate the random walks\n    walks = np.random.choice(step_sizes, size=(n_walks, n_steps))\n\n    # Calculate the cumulative sum of the walks to get the position at each step\n    positions = np.cumsum(walks, axis=1)\n\n    # Define the colors\n    colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n\n    # Create the plot\n    fig, ax = plt.subplots()\n\n    # Plot each walk in a different color\n    for walk in positions.T:\n        ax.plot(walk, color=next(colors))\n\n    # Return the plot\n    return ax"}
{"task_id": "BigCodeBench/474", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(n_samples=1000, mu=0, sigma=1, random_seed=0):\n    np.random.seed(random_seed)\n    samples = np.random.normal(mu, sigma, n_samples)\n\n    fig, ax = plt.subplots(1, 1)\n\n    # Histogram\n    ax.hist(samples, bins=30, density=True, alpha=0.5, color='b', label='Histogram')\n\n    # PDF\n    xmin, xmax = ax.get_xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, sigma)\n    ax.plot(x, p, 'r', linewidth=2, label='PDF')\n\n    ax.legend()\n    plt.show()\n\n    return ax, samples", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(n_samples=1000, mu=0, sigma=1, random_seed=0):\n    np.random.seed(random_seed)\n    samples = np.random.normal(mu, sigma, n_samples)\n\n    fig, ax = plt.subplots(1, 1)\n\n    # Histogram\n    ax.hist(samples, bins=30, density=True, alpha=0.5, color='b', label='Histogram')\n\n    # PDF\n    xmin, xmax = ax.get_xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, sigma)\n    ax.plot(x, p, 'r', linewidth=2, label='PDF')\n\n    ax.legend()\n    plt.show()\n\n    return ax, samples\n\n# Test the function\nax, samples = task_func(n_samples=1000, mu=0, sigma=1, random_seed=0)"}
{"task_id": "BigCodeBench/475", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\ndef task_func(data, date_format, country, country_codes=None):\n    # Check if data is a DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' should be a pandas DataFrame\")\n\n    # Check if date_format is a string\n    if not isinstance(date_format, str):\n        raise ValueError(\"'date_format' should be a string\")\n\n    # Check if country is in data\n    if country not in data.columns:\n        raise ValueError(\"'country' should be a column in the DataFrame\")\n\n    # Check if country_codes is a dictionary\n    if country_codes is not None and not isinstance(country_codes, dict):\n        raise ValueError(\"'country_codes' should be a dictionary\")\n\n    # Convert the date column to datetime\n    data['date'] = pd.to_datetime(data[country], format=date_format)\n\n    # Plot the histogram\n    ax = data['date'].hist(bins=30)\n\n    # Set the title and y label\n    plt.title('Date Distribution')\n    plt.ylabel('Frequency')\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\ndef task_func(data, date_format, country, country_codes=None):\n    # Check if data is a DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' should be a pandas DataFrame\")\n\n    # Check if date_format is a string\n    if not isinstance(date_format, str):\n        raise ValueError(\"'date_format' should be a string\")\n\n    # Check if country is in data\n    if country not in data.columns:\n        raise ValueError(\"'country' should be a column in the DataFrame\")\n\n    # Check if country_codes is a dictionary\n    if country_codes is not None and not isinstance(country_codes, dict):\n        raise ValueError(\"'country_codes' should be a dictionary\")\n\n    # Convert the date column to datetime\n    data['date'] = pd.to_datetime(data[country], format=date_format)\n\n    # Plot the histogram\n    ax = data['date'].hist(bins=30)\n\n    # Set the title and y label\n    plt.title('Date Distribution')\n    plt.ylabel('Frequency')\n\n    return ax"}
{"task_id": "BigCodeBench/476", "solution": "import matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\nimport numpy as np\ndef task_func(X, Y):\n    def func(x, a, b, c):\n        return a*x**2 + b*x + c\n\n    popt, _ = curve_fit(func, X, Y)\n    return popt, plt.plot(X, Y, 'o', color='red', label='data') + plt.plot(X, func(X, *popt), color='blue', label='fit')\nX = np.array([1, 2, 3, 4, 5])\nY = np.array([1, 3, 5, 7, 9])", "raw_solution": "import matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\nimport numpy as np\n\ndef task_func(X, Y):\n    def func(x, a, b, c):\n        return a*x**2 + b*x + c\n\n    popt, _ = curve_fit(func, X, Y)\n    return popt, plt.plot(X, Y, 'o', color='red', label='data') + plt.plot(X, func(X, *popt), color='blue', label='fit')\n\n# Test the function\nX = np.array([1, 2, 3, 4, 5])\nY = np.array([1, 3, 5, 7, 9])\n\na, b, c = task_func(X, Y)[0]\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.set_title('Quadratic Fit')\nax.legend()\nplt.show()"}
{"task_id": "BigCodeBench/477", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n\n    # Generate DataFrame\n    df = pd.DataFrame({\n        \"x\": np.random.rand(N),\n        \"y\": np.random.rand(N),\n    })\n\n    # Generate categories\n    if N >= len(CATEGORIES):\n        df[\"category\"] = np.random.choice(CATEGORIES, N)\n    else:\n        df[\"category\"] = np.random.choice(CATEGORIES, N, replace=False)\n\n    # Create scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(df[\"x\"], df[\"y\"], c=df[\"category\"])\n\n    return (df, ax)", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n\n    # Generate DataFrame\n    df = pd.DataFrame({\n        \"x\": np.random.rand(N),\n        \"y\": np.random.rand(N),\n    })\n\n    # Generate categories\n    if N >= len(CATEGORIES):\n        df[\"category\"] = np.random.choice(CATEGORIES, N)\n    else:\n        df[\"category\"] = np.random.choice(CATEGORIES, N, replace=False)\n\n    # Create scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(df[\"x\"], df[\"y\"], c=df[\"category\"])\n\n    return (df, ax)\n\n# Test the function\ndf, ax = task_func()\nplt.show()"}
{"task_id": "BigCodeBench/478", "solution": "import pandas as pd\nimport re\nimport random\ndef task_func(data_list, seed=None):\n    random.seed(seed)\n    original_strings = []\n    modified_strings = []\n\n    for string in data_list:\n        original_strings.append(string)\n        comma_index = string.find(',')\n        if comma_index != -1:\n            modified_string = string[:comma_index] + string[comma_index+1:]\n            modified_strings.append(modified_string)\n        else:\n            modified_strings.append(string)\n\n    df = pd.DataFrame({'Original String': original_strings, 'Modified String': modified_strings})\n    return df", "raw_solution": "import pandas as pd\nimport re\nimport random\n\ndef task_func(data_list, seed=None):\n    random.seed(seed)\n    original_strings = []\n    modified_strings = []\n\n    for string in data_list:\n        original_strings.append(string)\n        comma_index = string.find(',')\n        if comma_index != -1:\n            modified_string = string[:comma_index] + string[comma_index+1:]\n            modified_strings.append(modified_string)\n        else:\n            modified_strings.append(string)\n\n    df = pd.DataFrame({'Original String': original_strings, 'Modified String': modified_strings})\n    return df"}
{"task_id": "BigCodeBench/479", "solution": "import random\nimport string\nimport pandas as pd\ndef task_func(data_list, seed=0):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        if len(data) < 2:\n            continue\n        start = random.randint(0, len(data) - 1)\n        end = random.randint(start, len(data))\n        substring = data[start:end]\n        replacement = ''.join(random.choices(string.ascii_lowercase, k=len(substring)))\n        modified_data = data.replace(substring, replacement)\n        result.append({'Original String': data, 'Modified String': modified_data})\n    return pd.DataFrame(result)\ndata_list = ['hello', 'world', 'python', 'is', 'awesome']", "raw_solution": "import random\nimport string\nimport pandas as pd\n\ndef task_func(data_list, seed=0):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        if len(data) < 2:\n            continue\n        start = random.randint(0, len(data) - 1)\n        end = random.randint(start, len(data))\n        substring = data[start:end]\n        replacement = ''.join(random.choices(string.ascii_lowercase, k=len(substring)))\n        modified_data = data.replace(substring, replacement)\n        result.append({'Original String': data, 'Modified String': modified_data})\n    return pd.DataFrame(result)\n\n# Test the function\ndata_list = ['hello', 'world', 'python', 'is', 'awesome']\ndf = task_func(data_list)"}
{"task_id": "BigCodeBench/480", "solution": "import re\nimport random\nimport pandas as pd\ndef task_func(data_list, seed=None):\n    # Set the seed for the random number generator\n    if seed is not None:\n        random.seed(seed)\n\n    # Initialize an empty list to store the results\n    results = []\n\n    # Iterate over each string in the list\n    for string in data_list:\n        # Split the string into substrings based on commas\n        substrings = [s.strip() for s in re.split(',', string)]\n\n        # Shuffle the substrings\n        random.shuffle(substrings)\n\n        # Join the substrings back into a string\n        shuffled_string = ', '.join(substrings)\n\n        # Append the original string and the shuffled string to the results list\n        results.append({'Original String': string, 'Shuffled String': shuffled_string})\n\n    # Convert the results list to a pandas DataFrame\n    df = pd.DataFrame(results)\n\n    return df", "raw_solution": "import re\nimport random\nimport pandas as pd\n\ndef task_func(data_list, seed=None):\n    # Set the seed for the random number generator\n    if seed is not None:\n        random.seed(seed)\n\n    # Initialize an empty list to store the results\n    results = []\n\n    # Iterate over each string in the list\n    for string in data_list:\n        # Split the string into substrings based on commas\n        substrings = [s.strip() for s in re.split(',', string)]\n\n        # Shuffle the substrings\n        random.shuffle(substrings)\n\n        # Join the substrings back into a string\n        shuffled_string = ', '.join(substrings)\n\n        # Append the original string and the shuffled string to the results list\n        results.append({'Original String': string, 'Shuffled String': shuffled_string})\n\n    # Convert the results list to a pandas DataFrame\n    df = pd.DataFrame(results)\n\n    return df"}
{"task_id": "BigCodeBench/481", "solution": "import pandas as pd\nimport random\nimport re\ndef task_func(data_list, seed=42):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        # Split the string into substrings\n        substrings = data.split(',')\n        # Randomize the order of the substrings\n        random.shuffle(substrings)\n        # Normalize spaces and join the substrings back into a string\n        randomized_data = ' '.join(substrings)\n        # Append the original and randomized strings to the result list\n        result.append({'Original String': data, 'Randomized String': randomized_data})\n    # Convert the result list to a DataFrame and return it\n    return pd.DataFrame(result)\ndata_list = ['apple, banana, cherry', 'dog, cat, fish', 'red, blue, green']", "raw_solution": "import pandas as pd\nimport random\nimport re\n\ndef task_func(data_list, seed=42):\n    random.seed(seed)\n    result = []\n    for data in data_list:\n        # Split the string into substrings\n        substrings = data.split(',')\n        # Randomize the order of the substrings\n        random.shuffle(substrings)\n        # Normalize spaces and join the substrings back into a string\n        randomized_data = ' '.join(substrings)\n        # Append the original and randomized strings to the result list\n        result.append({'Original String': data, 'Randomized String': randomized_data})\n    # Convert the result list to a DataFrame and return it\n    return pd.DataFrame(result)\n\n# Test the function\ndata_list = ['apple, banana, cherry', 'dog, cat, fish', 'red, blue, green']\ndf = task_func(data_list)"}
{"task_id": "BigCodeBench/482", "solution": "import pandas as pd\nimport random\nimport re\ndef task_func(data_list, seed=None):\n    random.seed(seed)\n\n    # Define operations\n    operations = ['remove', 'replace', 'shuffle', 'randomize']\n\n    # Initialize empty lists to store original and modified strings\n    original_strings = []\n    modified_strings = []\n\n    for data in data_list:\n        original_strings.append(data)\n        data = data.split(',')\n        data = [item.strip() for item in data]  # remove leading/trailing whitespace\n\n        if len(data) > 1:  # if more than one substring\n            operation = random.choice(operations)\n            if operation == 'remove':\n                data.remove(random.choice(data))\n            elif operation == 'replace':\n                replace_item = random.choice(data)\n                data[data.index(replace_item)] = 'random_string'\n            elif operation == 'shuffle':\n                random.shuffle(data)\n            elif operation == 'randomize':\n                random.shuffle(data)\n\n        modified_strings.append(', '.join(data))\n\n    # Create DataFrame\n    df = pd.DataFrame(list(zip(original_strings, modified_strings)),\n                      columns=['Original String', 'Modified String'])\n\n    return df", "raw_solution": "import pandas as pd\nimport random\nimport re\n\ndef task_func(data_list, seed=None):\n    random.seed(seed)\n\n    # Define operations\n    operations = ['remove', 'replace', 'shuffle', 'randomize']\n\n    # Initialize empty lists to store original and modified strings\n    original_strings = []\n    modified_strings = []\n\n    for data in data_list:\n        original_strings.append(data)\n        data = data.split(',')\n        data = [item.strip() for item in data]  # remove leading/trailing whitespace\n\n        if len(data) > 1:  # if more than one substring\n            operation = random.choice(operations)\n            if operation == 'remove':\n                data.remove(random.choice(data))\n            elif operation == 'replace':\n                replace_item = random.choice(data)\n                data[data.index(replace_item)] = 'random_string'\n            elif operation == 'shuffle':\n                random.shuffle(data)\n            elif operation == 'randomize':\n                random.shuffle(data)\n\n        modified_strings.append(', '.join(data))\n\n    # Create DataFrame\n    df = pd.DataFrame(list(zip(original_strings, modified_strings)),\n                      columns=['Original String', 'Modified String'])\n\n    return df"}
{"task_id": "BigCodeBench/483", "solution": "import re\nimport pandas as pd\ndef task_func(df: pd.DataFrame, column_name: str, pattern: str) -> pd.DataFrame:\n    if not pattern:\n        return df.copy()\n\n    def reverse_words(match):\n        return ' '.join(match.group(0).split(' ')[::-1])\n\n    df_copy = df.copy()\n    df_copy[column_name] = df_copy[column_name].apply(\n        lambda x: re.sub(pattern, reverse_words, x)\n    )\n    return df_copy", "raw_solution": "import re\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame, column_name: str, pattern: str) -> pd.DataFrame:\n    if not pattern:\n        return df.copy()\n\n    def reverse_words(match):\n        return ' '.join(match.group(0).split(' ')[::-1])\n\n    df_copy = df.copy()\n    df_copy[column_name] = df_copy[column_name].apply(\n        lambda x: re.sub(pattern, reverse_words, x)\n    )\n    return df_copy"}
{"task_id": "BigCodeBench/484", "solution": "import math\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport pandas as pd\ndef task_func(\n    start_time,\n    end_time,\n    step,\n    columns=[\"Timestamp\", \"Sensor1\", \"Sensor2\", \"Sensor3\", \"SensorStatus\"],\n    sensor_statuses=[\"OK\", \"MAINTENANCE_REQUIRED\", \"ERROR\"],\n    random_seed=42,\n):\n    np.random.seed(random_seed)\n\n    # Generate timestamps\n    n_steps = int((end_time - start_time).total_seconds() / step.total_seconds())\n    timestamps = [start_time + i*step for i in range(n_steps)]\n\n    # Generate sensor readings\n    sensor_readings = []\n    for timestamp in timestamps:\n        t = (timestamp - start_time).total_seconds()\n        sensor1_reading = math.sin(t) + np.random.normal(0, 0.1)\n        sensor2_reading = math.cos(t) + np.random.normal(0, 0.1)\n        sensor3_reading = math.tan(t) + np.random.normal(0, 0.1)\n        sensor_status = np.random.choice(sensor_statuses)\n        sensor_readings.append([timestamp, sensor1_reading, sensor2_reading, sensor3_reading, sensor_status])\n\n    # Create DataFrame\n    df = pd.DataFrame(sensor_readings, columns=columns)\n\n    return df\nstart_time = datetime.now()\nend_time = start_time + timedelta(hours=1)\nstep = timedelta(minutes=5)", "raw_solution": "import math\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport pandas as pd\n\ndef task_func(\n    start_time,\n    end_time,\n    step,\n    columns=[\"Timestamp\", \"Sensor1\", \"Sensor2\", \"Sensor3\", \"SensorStatus\"],\n    sensor_statuses=[\"OK\", \"MAINTENANCE_REQUIRED\", \"ERROR\"],\n    random_seed=42,\n):\n    np.random.seed(random_seed)\n\n    # Generate timestamps\n    n_steps = int((end_time - start_time).total_seconds() / step.total_seconds())\n    timestamps = [start_time + i*step for i in range(n_steps)]\n\n    # Generate sensor readings\n    sensor_readings = []\n    for timestamp in timestamps:\n        t = (timestamp - start_time).total_seconds()\n        sensor1_reading = math.sin(t) + np.random.normal(0, 0.1)\n        sensor2_reading = math.cos(t) + np.random.normal(0, 0.1)\n        sensor3_reading = math.tan(t) + np.random.normal(0, 0.1)\n        sensor_status = np.random.choice(sensor_statuses)\n        sensor_readings.append([timestamp, sensor1_reading, sensor2_reading, sensor3_reading, sensor_status])\n\n    # Create DataFrame\n    df = pd.DataFrame(sensor_readings, columns=columns)\n\n    return df\n\n# Test the function\nstart_time = datetime.now()\nend_time = start_time + timedelta(hours=1)\nstep = timedelta(minutes=5)\ndf = task_func(start_time, end_time, step)"}
{"task_id": "BigCodeBench/485", "solution": "from datetime import datetime, timedelta\nimport pytz\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_time, end_time):\n    # Define the time zones\n    time_zones = [\"UTC\", \"America/Los_Angeles\", \"Europe/Paris\", \"Asia/Kolkata\", \"Australia/Sydney\"]\n    colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\n\n    # Convert start_time and end_time to datetime objects\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d\")\n\n    # Generate a list of dates between start_time and end_time\n    dates = [start_time + timedelta(days=i) for i in range((end_time-start_time).days + 1)]\n\n    # Initialize a dictionary to store the time differences\n    time_diffs = {tz: [] for tz in time_zones}\n\n    # Calculate the time difference for each time zone for each date\n    for date in dates:\n        for i, tz in enumerate(time_zones):\n            date_tz = pytz.timezone(tz)\n            date_tz_obj = date_tz.localize(date)\n            utc_date_tz_obj = date_tz_obj.astimezone(pytz.utc)\n            time_diffs[tz].append(utc_date_tz_obj.hour)\n\n    # Plot the time differences\n    fig, ax = plt.subplots()\n    for i, tz in enumerate(time_zones):\n        ax.plot(dates, time_diffs[tz], color=colors[i % len(colors)], label=tz)\n\n    ax.legend()\n    ax.set_xlabel('Date')\n    ax.set_ylabel('UTC-Timezone Difference (hours)')\n    ax.set_title('UTC-Timezone Difference Over Time')\n\n    return ax", "raw_solution": "from datetime import datetime, timedelta\nimport pytz\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_time, end_time):\n    # Define the time zones\n    time_zones = [\"UTC\", \"America/Los_Angeles\", \"Europe/Paris\", \"Asia/Kolkata\", \"Australia/Sydney\"]\n    colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\n\n    # Convert start_time and end_time to datetime objects\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d\")\n\n    # Generate a list of dates between start_time and end_time\n    dates = [start_time + timedelta(days=i) for i in range((end_time-start_time).days + 1)]\n\n    # Initialize a dictionary to store the time differences\n    time_diffs = {tz: [] for tz in time_zones}\n\n    # Calculate the time difference for each time zone for each date\n    for date in dates:\n        for i, tz in enumerate(time_zones):\n            date_tz = pytz.timezone(tz)\n            date_tz_obj = date_tz.localize(date)\n            utc_date_tz_obj = date_tz_obj.astimezone(pytz.utc)\n            time_diffs[tz].append(utc_date_tz_obj.hour)\n\n    # Plot the time differences\n    fig, ax = plt.subplots()\n    for i, tz in enumerate(time_zones):\n        ax.plot(dates, time_diffs[tz], color=colors[i % len(colors)], label=tz)\n\n    ax.legend()\n    ax.set_xlabel('Date')\n    ax.set_ylabel('UTC-Timezone Difference (hours)')\n    ax.set_title('UTC-Timezone Difference Over Time')\n\n    return ax"}
{"task_id": "BigCodeBench/486", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n\n    # Generate a time series from start_time to end_time with specified step\n    time_range = pd.date_range(start=start_time, end=end_time, freq=step)\n\n    # Generate values from a normal distribution\n    values = np.random.normal(0, 1, len(time_range))\n\n    # Add trend to the values\n    values += np.arange(len(time_range)) * trend\n\n    # Create a DataFrame\n    df = pd.DataFrame({'Time': time_range, 'Value': values})\n\n    # Plot the time series\n    ax = df.plot(x='Time', y='Value')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n\n    return ax\nstart_time = datetime.now()\nend_time = datetime.now() + timedelta(days=10)\nstep = '1H'\ntrend = 2", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n\n    # Generate a time series from start_time to end_time with specified step\n    time_range = pd.date_range(start=start_time, end=end_time, freq=step)\n\n    # Generate values from a normal distribution\n    values = np.random.normal(0, 1, len(time_range))\n\n    # Add trend to the values\n    values += np.arange(len(time_range)) * trend\n\n    # Create a DataFrame\n    df = pd.DataFrame({'Time': time_range, 'Value': values})\n\n    # Plot the time series\n    ax = df.plot(x='Time', y='Value')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n\n    return ax\n\n# Test the function\nstart_time = datetime.now()\nend_time = datetime.now() + timedelta(days=10)\nstep = '1H'\ntrend = 2\nax = task_func(start_time, end_time, step, trend)\nplt.show()"}
{"task_id": "BigCodeBench/487", "solution": "import os\nimport pandas as pd\nimport re\ndef task_func(file_path: str) -> pd.DataFrame:\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"The specified file {file_path} does not exist.\")\n\n    pattern = r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}.\\d+) - (\\w+) - (.+)\"\n    data = []\n\n    with open(file_path, 'r') as file:\n        for line in file:\n            match = re.match(pattern, line)\n            if match:\n                data.append({\n                    'Timestamp': match.group(1),\n                    'Level': match.group(2),\n                    'Message': match.group(3)\n                })\n\n    df = pd.DataFrame(data)\n    return df", "raw_solution": "import os\nimport pandas as pd\nimport re\n\ndef task_func(file_path: str) -> pd.DataFrame:\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"The specified file {file_path} does not exist.\")\n\n    pattern = r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}.\\d+) - (\\w+) - (.+)\"\n    data = []\n\n    with open(file_path, 'r') as file:\n        for line in file:\n            match = re.match(pattern, line)\n            if match:\n                data.append({\n                    'Timestamp': match.group(1),\n                    'Level': match.group(2),\n                    'Message': match.group(3)\n                })\n\n    df = pd.DataFrame(data)\n    return df"}
{"task_id": "BigCodeBench/488", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_time, end_time, step, amplitude, period, seed=0):\n    np.random.seed(seed)\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    step = timedelta(minutes=step)\n    dates = pd.date_range(start=start_time, end=end_time, freq=step)\n    values = amplitude * np.sin(2 * np.pi * (dates.to_pydatetime() - start_time) / pd.Timedelta(period)) + np.random.normal(0, 0.1, len(dates))\n    df = pd.DataFrame({'Timestamp': dates, 'Value': values})\n    ax = df.plot(x='Timestamp', y='Value')\n    plt.show()\n    return ax\nstart_time = \"2022-01-01 00:00:00\"\nend_time = \"2022-01-02 00:00:00\"\nstep = 15\namplitude = 1.0\nperiod = 60 * 24", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_time, end_time, step, amplitude, period, seed=0):\n    np.random.seed(seed)\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    step = timedelta(minutes=step)\n    dates = pd.date_range(start=start_time, end=end_time, freq=step)\n    values = amplitude * np.sin(2 * np.pi * (dates.to_pydatetime() - start_time) / pd.Timedelta(period)) + np.random.normal(0, 0.1, len(dates))\n    df = pd.DataFrame({'Timestamp': dates, 'Value': values})\n    ax = df.plot(x='Timestamp', y='Value')\n    plt.show()\n    return ax\n\n# Test the function\nstart_time = \"2022-01-01 00:00:00\"\nend_time = \"2022-01-02 00:00:00\"\nstep = 15\namplitude = 1.0\nperiod = 60 * 24  # 1 day\nax = task_func(start_time, end_time, step, amplitude, period)"}
{"task_id": "BigCodeBench/489", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\nimport time\ndef task_func(epoch_milliseconds, seed=0):\n    # List of users and activities\n    users = ['user1', 'user2', 'user3', 'user4', 'user5']\n    activities = ['login', 'logout', 'browse', 'search', 'purchase']\n\n    # Raise ValueError if epoch_milliseconds is in the future\n    if epoch_milliseconds > int(time.time() * 1000):\n        raise ValueError(\"Start time cannot be in the future.\")\n\n    # Convert epoch_milliseconds to datetime\n    start_time = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n\n    # Initialize an empty list to store logs\n    logs = []\n\n    # Set the random seed\n    random.seed(seed)\n\n    # Generate logs\n    current_time = start_time\n    while True:\n        # Generate a random number of seconds to sleep\n        sleep_time = random.randint(1, 10)\n\n        # Increment the current time by sleep_time seconds\n        current_time += timedelta(seconds=sleep_time)\n\n        # If the current time is after the current system time, break the loop\n        if current_time > datetime.now():\n            break\n\n        # Generate a random user and activity\n        user = random.choice(users)\n        activity = random.choice(activities)\n\n        # Append the log to the list\n        logs.append({\n            'User': user,\n            'Activity': activity,\n            'Time': current_time\n        })\n\n    # Convert the list of logs to a DataFrame and return it\n    return pd.DataFrame(logs)", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\nimport time\n\ndef task_func(epoch_milliseconds, seed=0):\n    # List of users and activities\n    users = ['user1', 'user2', 'user3', 'user4', 'user5']\n    activities = ['login', 'logout', 'browse', 'search', 'purchase']\n\n    # Raise ValueError if epoch_milliseconds is in the future\n    if epoch_milliseconds > int(time.time() * 1000):\n        raise ValueError(\"Start time cannot be in the future.\")\n\n    # Convert epoch_milliseconds to datetime\n    start_time = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n\n    # Initialize an empty list to store logs\n    logs = []\n\n    # Set the random seed\n    random.seed(seed)\n\n    # Generate logs\n    current_time = start_time\n    while True:\n        # Generate a random number of seconds to sleep\n        sleep_time = random.randint(1, 10)\n\n        # Increment the current time by sleep_time seconds\n        current_time += timedelta(seconds=sleep_time)\n\n        # If the current time is after the current system time, break the loop\n        if current_time > datetime.now():\n            break\n\n        # Generate a random user and activity\n        user = random.choice(users)\n        activity = random.choice(activities)\n\n        # Append the log to the list\n        logs.append({\n            'User': user,\n            'Activity': activity,\n            'Time': current_time\n        })\n\n    # Convert the list of logs to a DataFrame and return it\n    return pd.DataFrame(logs)"}
{"task_id": "BigCodeBench/490", "solution": "import xmltodict\nimport json\ndef task_func(s, file_path):\n    # Convert XML to dictionary\n    dict_data = xmltodict.parse(s)\n\n    # Save dictionary as JSON file\n    with open(file_path, 'w') as f:\n        json.dump(dict_data, f)\n\n    return dict_data", "raw_solution": "import xmltodict\nimport json\n\ndef task_func(s, file_path):\n    # Convert XML to dictionary\n    dict_data = xmltodict.parse(s)\n\n    # Save dictionary as JSON file\n    with open(file_path, 'w') as f:\n        json.dump(dict_data, f)\n\n    return dict_data"}
{"task_id": "BigCodeBench/491", "solution": "import random\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\ndef task_func(epoch_milliseconds, seed=None):\n    # Check if the start time is negative or after the current time\n    if epoch_milliseconds < 0 or epoch_milliseconds > int(datetime.now().timestamp() * 1000):\n        raise ValueError(\"Invalid start time. It should be a positive number and not after the current time.\")\n\n    # Convert epoch milliseconds to datetime\n    start_time = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n\n    # Define categories\n    categories = ['Electronics', 'Clothing', 'Home', 'Books', 'Sports']\n\n    # Initialize sales data dictionary\n    sales_data = {category: [] for category in categories}\n\n    # Generate sales data for each day\n    for i in range((datetime.now() - start_time).days + 1):\n        current_date = (start_time + timedelta(days=i)).date()\n        for category in categories:\n            sales_data[category].append((current_date, random.randint(10, 50)))\n\n    # Create a plot\n    fig, ax = plt.subplots()\n\n    # Plot sales data\n    for category in categories:\n        ax.plot(*zip(*sales_data[category]), label=category)\n\n    ax.set_xlabel('Days since start date')\n    ax.set_ylabel('Sales (units)')\n    ax.legend()\n\n    return sales_data, ax.figure", "raw_solution": "import random\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\n\ndef task_func(epoch_milliseconds, seed=None):\n    # Check if the start time is negative or after the current time\n    if epoch_milliseconds < 0 or epoch_milliseconds > int(datetime.now().timestamp() * 1000):\n        raise ValueError(\"Invalid start time. It should be a positive number and not after the current time.\")\n\n    # Convert epoch milliseconds to datetime\n    start_time = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n\n    # Define categories\n    categories = ['Electronics', 'Clothing', 'Home', 'Books', 'Sports']\n\n    # Initialize sales data dictionary\n    sales_data = {category: [] for category in categories}\n\n    # Generate sales data for each day\n    for i in range((datetime.now() - start_time).days + 1):\n        current_date = (start_time + timedelta(days=i)).date()\n        for category in categories:\n            sales_data[category].append((current_date, random.randint(10, 50)))\n\n    # Create a plot\n    fig, ax = plt.subplots()\n\n    # Plot sales data\n    for category in categories:\n        ax.plot(*zip(*sales_data[category]), label=category)\n\n    ax.set_xlabel('Days since start date')\n    ax.set_ylabel('Sales (units)')\n    ax.legend()\n\n    return sales_data, ax.figure"}
{"task_id": "BigCodeBench/492", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\nimport time\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    # Check input validity\n    if not isinstance(epoch_milliseconds, int) or not isinstance(random_seed, int) or not isinstance(products, list) or len(products) != 5:\n        raise ValueError(\"Invalid input\")\n\n    # Set random seed\n    random.seed(random_seed)\n\n    # Convert epoch time to datetime\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    current_date = datetime.now()\n\n    # Generate sales data\n    data = []\n    for day_diff in range((current_date - start_date).days + 1):\n        date = start_date + timedelta(days=day_diff)\n        for product in products:\n            sales = random.randint(10, 50)\n            data.append([product, date, sales])\n\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=['Product', 'Date', 'Sales'])\n\n    return df\nrandom_seed = 0\nepoch_milliseconds = int(time.mktime(datetime(2022, 1, 1).timetuple()) * 1000)", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\nimport time\n\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    # Check input validity\n    if not isinstance(epoch_milliseconds, int) or not isinstance(random_seed, int) or not isinstance(products, list) or len(products) != 5:\n        raise ValueError(\"Invalid input\")\n\n    # Set random seed\n    random.seed(random_seed)\n\n    # Convert epoch time to datetime\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    current_date = datetime.now()\n\n    # Generate sales data\n    data = []\n    for day_diff in range((current_date - start_date).days + 1):\n        date = start_date + timedelta(days=day_diff)\n        for product in products:\n            sales = random.randint(10, 50)\n            data.append([product, date, sales])\n\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=['Product', 'Date', 'Sales'])\n\n    return df\n\n# Test the function\nrandom_seed = 0\nepoch_milliseconds = int(time.mktime(datetime(2022, 1, 1).timetuple()) * 1000)\ndf = task_func(epoch_milliseconds, random_seed)"}
{"task_id": "BigCodeBench/493", "solution": "from datetime import datetime, timedelta\nimport random\nimport matplotlib.pyplot as plt\ndef task_func(\n    epoch_milliseconds,\n    teams=[\"Team1\", \"Team2\", \"Team3\", \"Team4\", \"Team5\"],\n    random_seed=0,\n):\n    random.seed(random_seed)\n\n    # Convert epoch time to datetime\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    end_date = datetime.now()\n\n    # Generate performance data for each team\n    performance_data = {}\n    for team in teams:\n        performance_data[team] = [random.uniform(0.1, 1) for _ in range((end_date - start_date).days + 1)]\n\n    # Generate dates for x-axis\n    dates = [start_date + timedelta(days=i) for i in range((end_date - start_date).days + 1)]\n\n    # Plot performance data\n    fig, ax = plt.subplots()\n    for team, performance in performance_data.items():\n        ax.plot(dates, performance, label=team)\n\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Performance')\n    ax.legend()\n\n    return performance_data, fig", "raw_solution": "from datetime import datetime, timedelta\nimport random\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    epoch_milliseconds,\n    teams=[\"Team1\", \"Team2\", \"Team3\", \"Team4\", \"Team5\"],\n    random_seed=0,\n):\n    random.seed(random_seed)\n\n    # Convert epoch time to datetime\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n    end_date = datetime.now()\n\n    # Generate performance data for each team\n    performance_data = {}\n    for team in teams:\n        performance_data[team] = [random.uniform(0.1, 1) for _ in range((end_date - start_date).days + 1)]\n\n    # Generate dates for x-axis\n    dates = [start_date + timedelta(days=i) for i in range((end_date - start_date).days + 1)]\n\n    # Plot performance data\n    fig, ax = plt.subplots()\n    for team, performance in performance_data.items():\n        ax.plot(dates, performance, label=team)\n\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Performance')\n    ax.legend()\n\n    return performance_data, fig\n\n# Test the function\nperformance_data, fig = task_func(1609459200000)\nplt.show()"}
{"task_id": "BigCodeBench/494", "solution": "from datetime import datetime\nimport pytz\nimport re\nfrom faker import Faker\nimport random\ndef task_func(epoch_milliseconds, seed=0, timezones=[\"UTC\"]):\n    Faker.seed(seed)\n    fake = Faker()\n    fake_events = {}\n    valid_timezones = pytz.all_timezones\n    valid_timezone_regex = re.compile(r'^UTC[+-][0-9]{2}:[0-1][0-9]$')\n    valid_timezones_parsed = []\n\n    for timezone in timezones:\n        if timezone in valid_timezones or re.match(valid_timezone_regex, timezone):\n            valid_timezones_parsed.append(timezone)\n\n    if not valid_timezones_parsed:\n        valid_timezones_parsed.append(\"UTC\")\n\n    for epoch in epoch_milliseconds:\n        dt = datetime.fromtimestamp(epoch / 1000.0)\n        event_name = fake.bs()\n        event_timezone = random.choice(valid_timezones_parsed)\n        event_time = pytz.timezone(event_timezone).localize(dt)\n\n        event_details = {\n            'date': event_time.strftime('%Y-%m-%d'),\n            'time': event_time.strftime('%H:%M:%S'),\n            'timezone': event_timezone\n        }\n\n        fake_events[event_name] = [event_details]\n\n    return fake_events", "raw_solution": "from datetime import datetime\nimport pytz\nimport re\nfrom faker import Faker\nimport random\n\ndef task_func(epoch_milliseconds, seed=0, timezones=[\"UTC\"]):\n    Faker.seed(seed)\n    fake = Faker()\n    fake_events = {}\n    valid_timezones = pytz.all_timezones\n    valid_timezone_regex = re.compile(r'^UTC[+-][0-9]{2}:[0-1][0-9]$')\n    valid_timezones_parsed = []\n\n    for timezone in timezones:\n        if timezone in valid_timezones or re.match(valid_timezone_regex, timezone):\n            valid_timezones_parsed.append(timezone)\n\n    if not valid_timezones_parsed:\n        valid_timezones_parsed.append(\"UTC\")\n\n    for epoch in epoch_milliseconds:\n        dt = datetime.fromtimestamp(epoch / 1000.0)\n        event_name = fake.bs()\n        event_timezone = random.choice(valid_timezones_parsed)\n        event_time = pytz.timezone(event_timezone).localize(dt)\n\n        event_details = {\n            'date': event_time.strftime('%Y-%m-%d'),\n            'time': event_time.strftime('%H:%M:%S'),\n            'timezone': event_timezone\n        }\n\n        fake_events[event_name] = [event_details]\n\n    return fake_events"}
{"task_id": "BigCodeBench/495", "solution": "import pandas as pd\nimport numpy as np\nfrom faker import Faker\ndef task_func(days, random_seed=0):\n    np.random.seed(random_seed)\n    fake = Faker()\n    date_rng = pd.date_range(start='2023-01-01', periods=days)\n    data = {\n        'Groceries': np.random.randint(0, 100, days),\n        'Entertainment': np.random.randint(0, 100, days),\n        'Rent': np.random.randint(0, 100, days),\n        'Utilities': np.random.randint(0, 100, days),\n        'Miscellaneous': np.random.randint(0, 100, days)\n    }\n    df = pd.DataFrame(data, index=date_rng)\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom faker import Faker\n\ndef task_func(days, random_seed=0):\n    np.random.seed(random_seed)\n    fake = Faker()\n    date_rng = pd.date_range(start='2023-01-01', periods=days)\n    data = {\n        'Groceries': np.random.randint(0, 100, days),\n        'Entertainment': np.random.randint(0, 100, days),\n        'Rent': np.random.randint(0, 100, days),\n        'Utilities': np.random.randint(0, 100, days),\n        'Miscellaneous': np.random.randint(0, 100, days)\n    }\n    df = pd.DataFrame(data, index=date_rng)\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/496", "solution": "from datetime import datetime, timedelta\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(days_in_past=7, random_seed=0):\n    if days_in_past < 1:\n        raise ValueError(\"days_in_past should be greater than 0\")\n\n    np.random.seed(random_seed)\n\n    # Generate random temperatures\n    temperatures = np.random.randint(low=15, high=35, size=days_in_past)\n\n    # Generate dates for the past week\n    dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days_in_past)]\n\n    # Create a new figure\n    fig, ax = plt.subplots()\n\n    # Plot the temperatures\n    ax.plot(dates, temperatures, marker='o')\n\n    # Set labels and title\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Temperature (\u00b0C)')\n    ax.set_title('Temperature Trend')\n\n    return ax", "raw_solution": "from datetime import datetime, timedelta\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(days_in_past=7, random_seed=0):\n    if days_in_past < 1:\n        raise ValueError(\"days_in_past should be greater than 0\")\n\n    np.random.seed(random_seed)\n\n    # Generate random temperatures\n    temperatures = np.random.randint(low=15, high=35, size=days_in_past)\n\n    # Generate dates for the past week\n    dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days_in_past)]\n\n    # Create a new figure\n    fig, ax = plt.subplots()\n\n    # Plot the temperatures\n    ax.plot(dates, temperatures, marker='o')\n\n    # Set labels and title\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Temperature (\u00b0C)')\n    ax.set_title('Temperature Trend')\n\n    return ax"}
{"task_id": "BigCodeBench/497", "solution": "from datetime import datetime, timedelta\nimport pytz\nimport calendar\ndef task_func(days_in_past=7):\n    if days_in_past < 0:\n        raise ValueError(\"'days_in_past' cannot be negative\")\n    target_date = datetime.now(pytz.utc) - timedelta(days=days_in_past)\n    weekday = calendar.day_name[target_date.weekday()]\n    return {'weekday': weekday}", "raw_solution": "from datetime import datetime, timedelta\nimport pytz\nimport calendar\n\ndef task_func(days_in_past=7):\n    if days_in_past < 0:\n        raise ValueError(\"'days_in_past' cannot be negative\")\n    target_date = datetime.now(pytz.utc) - timedelta(days=days_in_past)\n    weekday = calendar.day_name[target_date.weekday()]\n    return {'weekday': weekday}\n\n# Testing the function"}
{"task_id": "BigCodeBench/498", "solution": "import xmltodict\nimport json\nimport os\ndef task_func(s, save_json=False, json_file_path=None):\n    if not s.strip():\n        raise ValueError(\"Input XML string is empty or contains only whitespace.\")\n\n    result = xmltodict.parse(s)\n\n    if save_json:\n        if json_file_path is None:\n            raise ValueError(\"json_file_path is required when save_json is True.\")\n        elif not os.path.splitext(json_file_path)[1] == '.json':\n            raise ValueError(\"json_file_path should have .json extension.\")\n\n        with open(json_file_path, 'w') as f:\n            json.dump(result, f)\n\n    return result", "raw_solution": "import xmltodict\nimport json\nimport os\n\ndef task_func(s, save_json=False, json_file_path=None):\n    if not s.strip():\n        raise ValueError(\"Input XML string is empty or contains only whitespace.\")\n\n    result = xmltodict.parse(s)\n\n    if save_json:\n        if json_file_path is None:\n            raise ValueError(\"json_file_path is required when save_json is True.\")\n        elif not os.path.splitext(json_file_path)[1] == '.json':\n            raise ValueError(\"json_file_path should have .json extension.\")\n\n        with open(json_file_path, 'w') as f:\n            json.dump(result, f)\n\n    return result"}
{"task_id": "BigCodeBench/499", "solution": "import xlwt\nimport os\nimport io\nimport csv\ndef task_func(csv_content, filename):\n    # Create a new workbook\n    book = xlwt.Workbook()\n\n    # Add a new sheet to the workbook\n    sheet = book.add_sheet('Sheet 1')\n\n    # If csv_content is a string, convert it to a file-like object\n    if isinstance(csv_content, str):\n        csv_content = io.StringIO(csv_content)\n\n    # Read the CSV content\n    reader = csv.reader(csv_content)\n\n    # Write the data into the workbook\n    for row_index, row in enumerate(reader):\n        for col_index, value in enumerate(row):\n            sheet.write(row_index, col_index, value)\n\n    # Save the workbook as an Excel file\n    book.save(filename)\n\n    # Return the absolute path of the created Excel file\n    return os.path.abspath(filename)\ncsv_content = 'Hello'", "raw_solution": "import xlwt\nimport os\nimport io\nimport csv\n\ndef task_func(csv_content, filename):\n    # Create a new workbook\n    book = xlwt.Workbook()\n\n    # Add a new sheet to the workbook\n    sheet = book.add_sheet('Sheet 1')\n\n    # If csv_content is a string, convert it to a file-like object\n    if isinstance(csv_content, str):\n        csv_content = io.StringIO(csv_content)\n\n    # Read the CSV content\n    reader = csv.reader(csv_content)\n\n    # Write the data into the workbook\n    for row_index, row in enumerate(reader):\n        for col_index, value in enumerate(row):\n            sheet.write(row_index, col_index, value)\n\n    # Save the workbook as an Excel file\n    book.save(filename)\n\n    # Return the absolute path of the created Excel file\n    return os.path.abspath(filename)\n\n# Test the function\ncsv_content = 'Hello'"}
{"task_id": "BigCodeBench/500", "solution": "import xlwt\nimport os\nfrom collections import OrderedDict\nFIELDS = ['ID', 'Name', 'Age']\ndef task_func(values, filename):\n    # Create a new workbook and select the active worksheet\n    wb = xlwt.Workbook()\n    ws = wb.add_sheet('Sheet 1')\n\n    # Write the column names to the first row\n    for i, field in enumerate(FIELDS):\n        ws.write(0, i, field)\n\n    # Write the data to the remaining rows\n    for i, value in enumerate(values, start=1):\n        for j, key in enumerate(FIELDS):\n            ws.write(i, j, value.get(key, ''))\n\n    # Save the workbook to the specified filename\n    wb.save(filename)\n\n    # Return the absolute path of the created file\n    return os.path.abspath(filename)\nempty_data = []", "raw_solution": "import xlwt\nimport os\nfrom collections import OrderedDict\n\n# Constants\nFIELDS = ['ID', 'Name', 'Age']\n\ndef task_func(values, filename):\n    # Create a new workbook and select the active worksheet\n    wb = xlwt.Workbook()\n    ws = wb.add_sheet('Sheet 1')\n\n    # Write the column names to the first row\n    for i, field in enumerate(FIELDS):\n        ws.write(0, i, field)\n\n    # Write the data to the remaining rows\n    for i, value in enumerate(values, start=1):\n        for j, key in enumerate(FIELDS):\n            ws.write(i, j, value.get(key, ''))\n\n    # Save the workbook to the specified filename\n    wb.save(filename)\n\n    # Return the absolute path of the created file\n    return os.path.abspath(filename)\n\n# Test the function\nempty_data = []\npath = task_func(empty_data, 'empty_data.xls')\nassert os.path.exists(path) and 'empty_data.xls' in path"}
{"task_id": "BigCodeBench/501", "solution": "import xlwt\nimport os\nimport pandas as pd\nimport json\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    if not isinstance(json_str, (str, bytes, bytearray)):\n        raise TypeError(\"json_str must be a string, bytes, or bytearray\")\n    try:\n        data = json.loads(json_str)\n    except ValueError:\n        raise ValueError(\"json_str is not valid JSON\")\n    try:\n        if isinstance(data, list) and not data:\n            # If the JSON string represents an empty array, create an Excel file with no data rows\n            workbook = xlwt.Workbook()\n            worksheet = workbook.add_sheet(sheet_name)\n            workbook.save(filename)\n        else:\n            # Convert JSON to DataFrame and save it to Excel\n            df = pd.DataFrame(data)\n            df.to_excel(filename, sheet_name=sheet_name, index=False)\n    except Exception as e:\n        raise Exception(\"Error while writing to file: {}\".format(e))\n    return os.path.abspath(filename)", "raw_solution": "import xlwt\nimport os\nimport pandas as pd\nimport json\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    if not isinstance(json_str, (str, bytes, bytearray)):\n        raise TypeError(\"json_str must be a string, bytes, or bytearray\")\n    try:\n        data = json.loads(json_str)\n    except ValueError:\n        raise ValueError(\"json_str is not valid JSON\")\n    try:\n        if isinstance(data, list) and not data:\n            # If the JSON string represents an empty array, create an Excel file with no data rows\n            workbook = xlwt.Workbook()\n            worksheet = workbook.add_sheet(sheet_name)\n            workbook.save(filename)\n        else:\n            # Convert JSON to DataFrame and save it to Excel\n            df = pd.DataFrame(data)\n            df.to_excel(filename, sheet_name=sheet_name, index=False)\n    except Exception as e:\n        raise Exception(\"Error while writing to file: {}\".format(e))\n    return os.path.abspath(filename)"}
{"task_id": "BigCodeBench/502", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(days_in_past=7, random_seed=0):\n    random.seed(random_seed)\n\n    # Define activities\n    activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n\n    # Generate data\n    data = []\n    for i in range(days_in_past):\n        date = datetime.now() - timedelta(days=i)\n        for activity in activities:\n            duration = random.randint(0, 120)\n            data.append([date, activity, duration])\n\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=[\"Date\", \"Activity\", \"Duration\"])\n    df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n\n    # Plot\n    ax = sns.lineplot(x=\"Date\", y=\"Duration\", hue=\"Activity\", data=df)\n\n    return (ax, df)", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(days_in_past=7, random_seed=0):\n    random.seed(random_seed)\n\n    # Define activities\n    activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n\n    # Generate data\n    data = []\n    for i in range(days_in_past):\n        date = datetime.now() - timedelta(days=i)\n        for activity in activities:\n            duration = random.randint(0, 120)\n            data.append([date, activity, duration])\n\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=[\"Date\", \"Activity\", \"Duration\"])\n    df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n\n    # Plot\n    ax = sns.lineplot(x=\"Date\", y=\"Duration\", hue=\"Activity\", data=df)\n\n    return (ax, df)\n\n# Test the function\nax, df = task_func(7)\nplt.show()"}
{"task_id": "BigCodeBench/503", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\ndef task_func(days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0):\n    np.random.seed(random_seed)\n    dates = pd.date_range(start=datetime.now() - timedelta(days=days_in_past), periods=days_in_past).tolist()\n    prices = np.random.rand(days_in_past, len(stock_names)).tolist()\n    data = {'Date': dates}\n    for i, stock in enumerate(stock_names):\n        data[stock] = [price[i] for price in prices]\n    df = pd.DataFrame(data)\n    df.set_index('Date', inplace=True)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\ndef task_func(days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0):\n    np.random.seed(random_seed)\n    dates = pd.date_range(start=datetime.now() - timedelta(days=days_in_past), periods=days_in_past).tolist()\n    prices = np.random.rand(days_in_past, len(stock_names)).tolist()\n    data = {'Date': dates}\n    for i, stock in enumerate(stock_names):\n        data[stock] = [price[i] for price in prices]\n    df = pd.DataFrame(data)\n    df.set_index('Date', inplace=True)\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/504", "solution": "import hashlib\nimport rsa\nimport base64\ndef task_func(file_path):\n    with open(file_path, 'rb') as file:\n        data = file.read()\n\n    # Generate SHA-256 hash of the file's contents\n    file_hash = hashlib.sha256(data).digest()\n\n    # Load the private key\n    with open('private.pem', 'rb') as private_key_file:\n        private_key = rsa.PrivateKey.load_pkcs1(private_key_file.read())\n\n    # Sign the hash\n    signed_hash = rsa.sign_hash(file_hash, private_key, 'SHA-256')\n\n    # Encode the signed hash in base64\n    base64_encoded_signed_hash = base64.b64encode(signed_hash)\n\n    return base64_encoded_signed_hash.decode()", "raw_solution": "import hashlib\nimport rsa\nimport base64\n\ndef task_func(file_path):\n    with open(file_path, 'rb') as file:\n        data = file.read()\n\n    # Generate SHA-256 hash of the file's contents\n    file_hash = hashlib.sha256(data).digest()\n\n    # Load the private key\n    with open('private.pem', 'rb') as private_key_file:\n        private_key = rsa.PrivateKey.load_pkcs1(private_key_file.read())\n\n    # Sign the hash\n    signed_hash = rsa.sign_hash(file_hash, private_key, 'SHA-256')\n\n    # Encode the signed hash in base64\n    base64_encoded_signed_hash = base64.b64encode(signed_hash)\n\n    return base64_encoded_signed_hash.decode()\n\n# Test the function"}
{"task_id": "BigCodeBench/505", "solution": "import hashlib\nimport hmac\ndef task_func(secret, message):\n    secret = secret.encode()\n    message = message.encode()\n    hmac_signature = hmac.new(secret, message, hashlib.sha256).hexdigest()\n    return hmac_signature", "raw_solution": "import hashlib\nimport hmac\n\ndef task_func(secret, message):\n    secret = secret.encode()\n    message = message.encode()\n    hmac_signature = hmac.new(secret, message, hashlib.sha256).hexdigest()\n    return hmac_signature\n\n# Test the function"}
{"task_id": "BigCodeBench/506", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    df = pd.DataFrame(data, columns=['date', 'temperature', 'humidity', 'wind speed', 'precipitation'])\n    result = {}\n\n    if df.empty:\n        result['mean'] = np.nan\n        result['min'] = np.inf\n        result['max'] = -np.inf\n    else:\n        result['sum'] = df[column].sum()\n        result['mean'] = df[column].mean()\n        result['min'] = df[column].min()\n        result['max'] = df[column].max()\n\n        # Generate histogram plot\n        plt.figure(figsize=(10, 6))\n        plt.hist(df[column], bins='auto', color='#003f5c', edgecolor='black', alpha=0.7)\n        plt.title(f'Histogram of {column}')\n        plt.xlabel(column)\n        plt.ylabel('Frequency')\n        result['plot'] = plt.gca()\n\n    return result", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    df = pd.DataFrame(data, columns=['date', 'temperature', 'humidity', 'wind speed', 'precipitation'])\n    result = {}\n\n    if df.empty:\n        result['mean'] = np.nan\n        result['min'] = np.inf\n        result['max'] = -np.inf\n    else:\n        result['sum'] = df[column].sum()\n        result['mean'] = df[column].mean()\n        result['min'] = df[column].min()\n        result['max'] = df[column].max()\n\n        # Generate histogram plot\n        plt.figure(figsize=(10, 6))\n        plt.hist(df[column], bins='auto', color='#003f5c', edgecolor='black', alpha=0.7)\n        plt.title(f'Histogram of {column}')\n        plt.xlabel(column)\n        plt.ylabel('Frequency')\n        result['plot'] = plt.gca()\n\n    return result"}
{"task_id": "BigCodeBench/507", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(column, data):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"The data should be a pandas DataFrame\")\n    if not isinstance(column, str):\n        raise ValueError(\"The column name should be a string\")\n    if column not in data.columns:\n        raise ValueError(f\"The column {column} does not exist in the data\")\n\n    if data.empty:\n        return {'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}\n\n    return {\n        'sum': data[column].sum(),\n        'mean': data[column].mean(),\n        'min': data[column].min(),\n        'max': data[column].max(),\n    }", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(column, data):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"The data should be a pandas DataFrame\")\n    if not isinstance(column, str):\n        raise ValueError(\"The column name should be a string\")\n    if column not in data.columns:\n        raise ValueError(f\"The column {column} does not exist in the data\")\n\n    if data.empty:\n        return {'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}\n\n    return {\n        'sum': data[column].sum(),\n        'mean': data[column].mean(),\n        'min': data[column].min(),\n        'max': data[column].max(),\n    }"}
{"task_id": "BigCodeBench/508", "solution": "import hashlib\nimport io\nimport os\ndef task_func(file_path1, file_path2):\n    # Check if files exist\n    if not os.path.isfile(file_path1) or not os.path.isfile(file_path2):\n        raise FileNotFoundError(\"One or both files do not exist\")\n\n    # Compute MD5 hash of the files\n    hash1 = hashlib.md5()\n    hash2 = hashlib.md5()\n\n    with io.FileIO(file_path1, 'rb') as file1, io.FileIO(file_path2, 'rb') as file2:\n        data1 = file1.read(1024)\n        data2 = file2.read(1024)\n\n        while data1 != b'':\n            hash1.update(data1)\n            data1 = file1.read(1024)\n\n        while data2 != b'':\n            hash2.update(data2)\n            data2 = file2.read(1024)\n\n    # Compare MD5 hashes\n    return hash1.hexdigest() == hash2.hexdigest()", "raw_solution": "import hashlib\nimport io\nimport os\n\ndef task_func(file_path1, file_path2):\n    # Check if files exist\n    if not os.path.isfile(file_path1) or not os.path.isfile(file_path2):\n        raise FileNotFoundError(\"One or both files do not exist\")\n\n    # Compute MD5 hash of the files\n    hash1 = hashlib.md5()\n    hash2 = hashlib.md5()\n\n    with io.FileIO(file_path1, 'rb') as file1, io.FileIO(file_path2, 'rb') as file2:\n        data1 = file1.read(1024)\n        data2 = file2.read(1024)\n\n        while data1 != b'':\n            hash1.update(data1)\n            data1 = file1.read(1024)\n\n        while data2 != b'':\n            hash2.update(data2)\n            data2 = file2.read(1024)\n\n    # Compare MD5 hashes\n    return hash1.hexdigest() == hash2.hexdigest()"}
{"task_id": "BigCodeBench/509", "solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    try:\n        with open(file_path1, 'r') as f1, open(file_path2, 'r') as f2:\n            lines1 = f1.readlines()\n            lines2 = f2.readlines()\n\n        if not lines1 or not lines2:\n            raise ValueError(\"One or both of the files are empty.\")\n\n        diff_lines = list(ndiff(lines1, lines2))\n\n        diff_data = []\n        for i, line in enumerate(diff_lines, start=1):\n            status = line[0]\n            content = line[2:]\n            diff_data.append({'Line Number': i, 'Status': status, 'Content': content})\n\n        df = pd.DataFrame(diff_data)\n        df.replace(to_replace={'-': '+', '+': '-'}, inplace=True)\n\n        return df\n\n    except FileNotFoundError:\n        raise FileNotFoundError(\"One or both of the files cannot be found.\")\n    except Exception as e:\n        raise Exception(\"An error occurred: {}\".format(e))", "raw_solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    try:\n        with open(file_path1, 'r') as f1, open(file_path2, 'r') as f2:\n            lines1 = f1.readlines()\n            lines2 = f2.readlines()\n\n        if not lines1 or not lines2:\n            raise ValueError(\"One or both of the files are empty.\")\n\n        diff_lines = list(ndiff(lines1, lines2))\n\n        diff_data = []\n        for i, line in enumerate(diff_lines, start=1):\n            status = line[0]\n            content = line[2:]\n            diff_data.append({'Line Number': i, 'Status': status, 'Content': content})\n\n        df = pd.DataFrame(diff_data)\n        df.replace(to_replace={'-': '+', '+': '-'}, inplace=True)\n\n        return df\n\n    except FileNotFoundError:\n        raise FileNotFoundError(\"One or both of the files cannot be found.\")\n    except Exception as e:\n        raise Exception(\"An error occurred: {}\".format(e))\n\n# Test the function\ndf = task_func('file1.csv', 'file2.csv')"}
{"task_id": "BigCodeBench/510", "solution": "import difflib\nimport gzip\nimport io\ndef task_func(file_path1, file_path2):\n    # Open and read the gzip files\n    with gzip.open(file_path1, 'rb') as f1, gzip.open(file_path2, 'rb') as f2:\n        file1_content = f1.read().decode('utf-8')\n        file2_content = f2.read().decode('utf-8')\n\n    # Split the content into lines\n    lines1 = file1_content.splitlines()\n    lines2 = file2_content.splitlines()\n\n    # Compute the differences\n    diff = difflib.Differ()\n    diffs = diff.compare(lines1, lines2)\n\n    # Format the differences\n    diff_str = '\\n'.join(diffs)\n\n    # Return the differences\n    return diff_str", "raw_solution": "import difflib\nimport gzip\nimport io\n\ndef task_func(file_path1, file_path2):\n    # Open and read the gzip files\n    with gzip.open(file_path1, 'rb') as f1, gzip.open(file_path2, 'rb') as f2:\n        file1_content = f1.read().decode('utf-8')\n        file2_content = f2.read().decode('utf-8')\n\n    # Split the content into lines\n    lines1 = file1_content.splitlines()\n    lines2 = file2_content.splitlines()\n\n    # Compute the differences\n    diff = difflib.Differ()\n    diffs = diff.compare(lines1, lines2)\n\n    # Format the differences\n    diff_str = '\\n'.join(diffs)\n\n    # Return the differences\n    return diff_str"}
{"task_id": "BigCodeBench/511", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if data.empty:\n        stats = {'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}\n        fig, ax = plt.subplots()\n        ax.pie([], labels=[])\n        return stats, ax\n    else:\n        stats = {\n            'sum': data[column].sum(),\n            'mean': data[column].mean(),\n            'min': data[column].min(),\n            'max': data[column].max()\n        }\n        fig, ax = plt.subplots()\n        ax.pie(data[column].value_counts(), labels=data[column].value_counts().index)\n        return stats, ax\ndata = pd.DataFrame({'Age': [25, 30, 35, 40, 45, 50],\n                     'Salary': [50000, 60000, 70000, 80000, 90000, 100000]})", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if data.empty:\n        stats = {'sum': 0, 'mean': np.nan, 'min': np.nan, 'max': np.nan}\n        fig, ax = plt.subplots()\n        ax.pie([], labels=[])\n        return stats, ax\n    else:\n        stats = {\n            'sum': data[column].sum(),\n            'mean': data[column].mean(),\n            'min': data[column].min(),\n            'max': data[column].max()\n        }\n        fig, ax = plt.subplots()\n        ax.pie(data[column].value_counts(), labels=data[column].value_counts().index)\n        return stats, ax\n\n# Test the function\ndata = pd.DataFrame({'Age': [25, 30, 35, 40, 45, 50],\n                     'Salary': [50000, 60000, 70000, 80000, 90000, 100000]})\nstats, ax = task_func('Age', data)"}
{"task_id": "BigCodeBench/512", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if not isinstance(data, pd.DataFrame):\n        raise TypeError(\"Data should be a pandas DataFrame\")\n    if not isinstance(column, str):\n        raise TypeError(\"Column should be a string\")\n    if column not in data.columns:\n        raise ValueError(\"Column not found in data\")\n    if not np.all(data[column] >= 0):\n        raise ValueError(\"Quantity sold or total sales cannot be negative\")\n\n    summary_stats = {\n        'sum': data[column].sum(),\n        'mean': data[column].mean(),\n        'min': data[column].min(),\n        'max': data[column].max()\n    }\n\n    fig, ax = plt.subplots()\n    data[column].plot(kind='bar', ax=ax)\n    ax.set_xlabel('Product')\n    ax.set_ylabel(column)\n    ax.set_title(f'Bar Chart of {column}')\n\n    return (summary_stats, ax)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if not isinstance(data, pd.DataFrame):\n        raise TypeError(\"Data should be a pandas DataFrame\")\n    if not isinstance(column, str):\n        raise TypeError(\"Column should be a string\")\n    if column not in data.columns:\n        raise ValueError(\"Column not found in data\")\n    if not np.all(data[column] >= 0):\n        raise ValueError(\"Quantity sold or total sales cannot be negative\")\n\n    summary_stats = {\n        'sum': data[column].sum(),\n        'mean': data[column].mean(),\n        'min': data[column].min(),\n        'max': data[column].max()\n    }\n\n    fig, ax = plt.subplots()\n    data[column].plot(kind='bar', ax=ax)\n    ax.set_xlabel('Product')\n    ax.set_ylabel(column)\n    ax.set_title(f'Bar Chart of {column}')\n\n    return (summary_stats, ax)"}
{"task_id": "BigCodeBench/513", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    # Check if data is empty\n    if not data:\n        raise ValueError(\"Data list is empty\")\n\n    # Convert data to pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Check if column exists in data\n    if column not in df.columns:\n        raise KeyError(f\"Specified column {column} is not valid\")\n\n    # Check if any numeric values are negative\n    if (df[column] < 0).any():\n        raise ValueError(f\"Negative values are not allowed for {column}\")\n\n    # Calculate sum, mean, min, max\n    summary_stats = {\n        'sum': df[column].sum(),\n        'mean': df[column].mean(),\n        'min': df[column].min(),\n        'max': df[column].max(),\n    }\n\n    # Plot line chart\n    plt.figure(figsize=(10, 6))\n    plt.plot(df['Date'], df[column])\n    plt.title(f'Line Chart of {column}')\n    plt.xlabel('Date')\n    plt.ylabel(column)\n    plt.grid(True)\n\n    return summary_stats, plt.gca()", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    # Check if data is empty\n    if not data:\n        raise ValueError(\"Data list is empty\")\n\n    # Convert data to pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Check if column exists in data\n    if column not in df.columns:\n        raise KeyError(f\"Specified column {column} is not valid\")\n\n    # Check if any numeric values are negative\n    if (df[column] < 0).any():\n        raise ValueError(f\"Negative values are not allowed for {column}\")\n\n    # Calculate sum, mean, min, max\n    summary_stats = {\n        'sum': df[column].sum(),\n        'mean': df[column].mean(),\n        'min': df[column].min(),\n        'max': df[column].max(),\n    }\n\n    # Plot line chart\n    plt.figure(figsize=(10, 6))\n    plt.plot(df['Date'], df[column])\n    plt.title(f'Line Chart of {column}')\n    plt.xlabel('Date')\n    plt.ylabel(column)\n    plt.grid(True)\n\n    return summary_stats, plt.gca()"}
{"task_id": "BigCodeBench/514", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(array):\n    COLUMNS = ['A', 'B', 'C', 'D', 'E']\n    df = pd.DataFrame(array, columns=COLUMNS)\n    sums = df.sum()\n    fig, ax = plt.subplots()\n    ax.bar(COLUMNS, sums)\n    ax.set_title('Sum of each column')\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Sum')\n    return df, ax\narray = [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15]]", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(array):\n    COLUMNS = ['A', 'B', 'C', 'D', 'E']\n    df = pd.DataFrame(array, columns=COLUMNS)\n    sums = df.sum()\n    fig, ax = plt.subplots()\n    ax.bar(COLUMNS, sums)\n    ax.set_title('Sum of each column')\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Sum')\n    return df, ax\n\n# Test the function\narray = [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15]]\ndf, ax = task_func(array)\nplt.show()"}
{"task_id": "BigCodeBench/515", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array):\n    if not array:\n        raise ValueError(\"Input array is empty\")\n    for sublist in array:\n        if len(sublist) != 5:\n            raise ValueError(\"Sublists of varying lengths found\")\n\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'E'])\n    print(\"DataFrame:\")\n    print(df)\n\n    correlation_matrix = df.corr()\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n    plt.title(\"Heatmap of the DataFrame's correlation matrix\")\n    plt.show()\narray = [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25]]", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(array):\n    if not array:\n        raise ValueError(\"Input array is empty\")\n    for sublist in array:\n        if len(sublist) != 5:\n            raise ValueError(\"Sublists of varying lengths found\")\n\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'E'])\n    print(\"DataFrame:\")\n    print(df)\n\n    correlation_matrix = df.corr()\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n    plt.title(\"Heatmap of the DataFrame's correlation matrix\")\n    plt.show()\n\n# Test the function\narray = [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25]]\ntask_func(array)"}
{"task_id": "BigCodeBench/516", "solution": "import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\ndef task_func(\n    array: list, random_seed: int = 0\n) -> (pd.DataFrame, sm.regression.linear_model.RegressionResultsWrapper):\n    # Validate the input list\n    if not all(len(sub_list) == 5 for sub_list in array):\n        raise ValueError(\"All sublists must have exactly 5 elements\")\n\n    # Create a DataFrame\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'Response'])\n\n    # Separate independent and dependent variables\n    X = df[['A', 'B', 'C', 'D']]\n    y = df['Response']\n\n    # Add a constant to the model\n    X = sm.add_constant(X)\n\n    # Fit a linear regression\n    model = sm.OLS(y, X)\n    results = model.fit()\n\n    return df, results", "raw_solution": "import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\ndef task_func(\n    array: list, random_seed: int = 0\n) -> (pd.DataFrame, sm.regression.linear_model.RegressionResultsWrapper):\n    # Validate the input list\n    if not all(len(sub_list) == 5 for sub_list in array):\n        raise ValueError(\"All sublists must have exactly 5 elements\")\n\n    # Create a DataFrame\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'Response'])\n\n    # Separate independent and dependent variables\n    X = df[['A', 'B', 'C', 'D']]\n    y = df['Response']\n\n    # Add a constant to the model\n    X = sm.add_constant(X)\n\n    # Fit a linear regression\n    model = sm.OLS(y, X)\n    results = model.fit()\n\n    return df, results"}
{"task_id": "BigCodeBench/517", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\ndef task_func(array: list, random_seed: int = 42) -> (pd.DataFrame, np.ndarray):\n    # Set the random seed for reproducibility\n    np.random.seed(random_seed)\n\n    # Convert the 2D list to a pandas DataFrame\n    df = pd.DataFrame(array)\n\n    # Apply PCA for dimensionality reduction\n    pca = PCA(n_components=2)\n    pca_array = pca.fit_transform(df)\n\n    return df, pca_array", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\n\ndef task_func(array: list, random_seed: int = 42) -> (pd.DataFrame, np.ndarray):\n    # Set the random seed for reproducibility\n    np.random.seed(random_seed)\n\n    # Convert the 2D list to a pandas DataFrame\n    df = pd.DataFrame(array)\n\n    # Apply PCA for dimensionality reduction\n    pca = PCA(n_components=2)\n    pca_array = pca.fit_transform(df)\n\n    return df, pca_array"}
{"task_id": "BigCodeBench/518", "solution": "import pandas as pd\nfrom scipy.spatial.distance import pdist, squareform\ndef task_func(array):\n    # Convert 2D list to DataFrame\n    df = pd.DataFrame(array)\n\n    # Assign alphabetical labels to columns\n    df.columns = [chr(65 + i) for i in range(df.shape[1])]\n\n    # Compute distance matrix\n    distance_matrix = pd.DataFrame(squareform(pdist(df)), index=df.index, columns=df.index)\n\n    return df, distance_matrix\narray = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]", "raw_solution": "import pandas as pd\nfrom scipy.spatial.distance import pdist, squareform\n\ndef task_func(array):\n    # Convert 2D list to DataFrame\n    df = pd.DataFrame(array)\n\n    # Assign alphabetical labels to columns\n    df.columns = [chr(65 + i) for i in range(df.shape[1])]\n\n    # Compute distance matrix\n    distance_matrix = pd.DataFrame(squareform(pdist(df)), index=df.index, columns=df.index)\n\n    return df, distance_matrix\n\n# Test the function\narray = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\ndf, distance_matrix = task_func(array)"}
{"task_id": "BigCodeBench/519", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Combine the dictionaries into a single dataframe\n    df = pd.DataFrame(data)\n\n    # Fill NA/NaN values with 0\n    df.fillna(0, inplace=True)\n\n    # Generate a line chart of sales\n    ax = df.plot(kind='line', title='Fruit Sales over Time', xlabel='Time', ylabel='Sales Quantity')\n\n    return ax\ndata = [{'Time': 1, 'Apple': 10, 'Banana': 20, 'Orange': 15},\n        {'Time': 2, 'Apple': 15, 'Banana': 25, 'Orange': 20},\n        {'Time': 3, 'Apple': 20, 'Banana': 30, 'Orange': 25}]", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Combine the dictionaries into a single dataframe\n    df = pd.DataFrame(data)\n\n    # Fill NA/NaN values with 0\n    df.fillna(0, inplace=True)\n\n    # Generate a line chart of sales\n    ax = df.plot(kind='line', title='Fruit Sales over Time', xlabel='Time', ylabel='Sales Quantity')\n\n    return ax\n\n# Test the function\ndata = [{'Time': 1, 'Apple': 10, 'Banana': 20, 'Orange': 15},\n        {'Time': 2, 'Apple': 15, 'Banana': 25, 'Orange': 20},\n        {'Time': 3, 'Apple': 20, 'Banana': 30, 'Orange': 25}]\n\nax = task_func(data)\nplt.show()"}
{"task_id": "BigCodeBench/520", "solution": "import collections\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not all(isinstance(i, dict) for i in data):\n        raise TypeError(\"All elements in data must be dictionaries\")\n    if not all(i.keys() == data[0].keys() for i in data if i.keys()):\n        raise ValueError(\"All dictionaries must have the same keys\")\n    if not all(isinstance(v, (int, float)) and v >= 0 for d in data for v in d.values()):\n        raise ValueError(\"Sales quantity must not be negative\")\n\n    total_sales = collections.defaultdict(int)\n    for d in data:\n        for k, v in d.items():\n            total_sales[k] += v\n\n    colors = ['red', 'yellow', 'green', 'blue', 'purple']\n    ax = None\n    if total_sales:\n        fig, ax = plt.subplots()\n        ax.bar(total_sales.keys(), total_sales.values(), color=colors)\n        ax.set_xlabel('Fruit')\n        ax.set_ylabel('Total Sales')\n        ax.set_title('Total Fruit Sales')\n\n    return total_sales, ax", "raw_solution": "import collections\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not all(isinstance(i, dict) for i in data):\n        raise TypeError(\"All elements in data must be dictionaries\")\n    if not all(i.keys() == data[0].keys() for i in data if i.keys()):\n        raise ValueError(\"All dictionaries must have the same keys\")\n    if not all(isinstance(v, (int, float)) and v >= 0 for d in data for v in d.values()):\n        raise ValueError(\"Sales quantity must not be negative\")\n\n    total_sales = collections.defaultdict(int)\n    for d in data:\n        for k, v in d.items():\n            total_sales[k] += v\n\n    colors = ['red', 'yellow', 'green', 'blue', 'purple']\n    ax = None\n    if total_sales:\n        fig, ax = plt.subplots()\n        ax.bar(total_sales.keys(), total_sales.values(), color=colors)\n        ax.set_xlabel('Fruit')\n        ax.set_ylabel('Total Sales')\n        ax.set_title('Total Fruit Sales')\n\n    return total_sales, ax"}
{"task_id": "BigCodeBench/521", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data_list):\n    # Convert the list of dictionaries to a DataFrame\n    df = pd.DataFrame(data_list)\n    df = df.set_index('Test')\n\n    # Plot the data\n    ax = df.plot(kind='line', legend='reverse', title='Student Scores Over Tests')\n    ax.set_xlabel('Test Number')\n    ax.set_ylabel('Score')\n\n    return ax\ndata_list = [{'Test': 1, 'John': 85, 'Emma': 90, 'Kelly': 92},\n             {'Test': 2, 'John': 88, 'Emma': 91, 'Kelly': 93},\n             {'Test': 3, 'John': 92, 'Emma': 93, 'Kelly': 94},\n             {'Test': 4, 'John': 90, 'Emma': 92, 'Kelly': 95}]", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data_list):\n    # Convert the list of dictionaries to a DataFrame\n    df = pd.DataFrame(data_list)\n    df = df.set_index('Test')\n\n    # Plot the data\n    ax = df.plot(kind='line', legend='reverse', title='Student Scores Over Tests')\n    ax.set_xlabel('Test Number')\n    ax.set_ylabel('Score')\n\n    return ax\n\n# Test the function\ndata_list = [{'Test': 1, 'John': 85, 'Emma': 90, 'Kelly': 92},\n             {'Test': 2, 'John': 88, 'Emma': 91, 'Kelly': 93},\n             {'Test': 3, 'John': 92, 'Emma': 93, 'Kelly': 94},\n             {'Test': 4, 'John': 90, 'Emma': 92, 'Kelly': 95}]\n\nax = task_func(data_list)\nplt.show()"}
{"task_id": "BigCodeBench/522", "solution": "import collections\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(data):\n    if not data:\n        return None\n\n    # Combine dictionaries with differing keys\n    combined_dict = collections.defaultdict(list)\n    for d in data:\n        for key, value in d.items():\n            combined_dict[key].append(value)\n\n    # Calculate average score for each student\n    avg_scores = {}\n    for key, value in combined_dict.items():\n        avg_scores[key] = sum(v for v in value if v is not None) / len(value)\n\n    # Check for negative scores and raise ValueError\n    for score in avg_scores.values():\n        if score < 0:\n            raise ValueError(\"Negative scores are not allowed\")\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    students = list(avg_scores.keys())\n    scores = list(avg_scores.values())\n    colors = ['red', 'yellow', 'green', 'blue', 'purple']\n    ax.bar(students, scores, color=colors)\n\n    ax.set_xlabel('Student')\n    ax.set_ylabel('Average Score')\n    ax.set_title('Average Student Scores')\n\n    return ax", "raw_solution": "import collections\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(data):\n    if not data:\n        return None\n\n    # Combine dictionaries with differing keys\n    combined_dict = collections.defaultdict(list)\n    for d in data:\n        for key, value in d.items():\n            combined_dict[key].append(value)\n\n    # Calculate average score for each student\n    avg_scores = {}\n    for key, value in combined_dict.items():\n        avg_scores[key] = sum(v for v in value if v is not None) / len(value)\n\n    # Check for negative scores and raise ValueError\n    for score in avg_scores.values():\n        if score < 0:\n            raise ValueError(\"Negative scores are not allowed\")\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    students = list(avg_scores.keys())\n    scores = list(avg_scores.values())\n    colors = ['red', 'yellow', 'green', 'blue', 'purple']\n    ax.bar(students, scores, color=colors)\n\n    ax.set_xlabel('Student')\n    ax.set_ylabel('Average Score')\n    ax.set_title('Average Student Scores')\n\n    return ax"}
{"task_id": "BigCodeBench/523", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not data:\n        return None\n\n    # Combine the dictionaries in the list\n    combined_dict = {}\n    for d in data:\n        combined_dict.update(d)\n\n    # Convert the combined dictionary to a DataFrame\n    df = pd.DataFrame(list(combined_dict.items()), columns=['Time', 'Data Points'])\n\n    # Convert 'Time' and 'Data Points' to numeric\n    df['Time'] = pd.to_numeric(df['Time'])\n    df['Data Points'] = pd.to_numeric(df['Data Points'])\n\n    # Create a line plot\n    plt.figure(figsize=(10, 6))\n    plt.plot(df['Time'], df['Data Points'])\n    plt.xlabel('Time')\n    plt.ylabel('Data Points')\n    plt.title('Data over Time')\n\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not data:\n        return None\n\n    # Combine the dictionaries in the list\n    combined_dict = {}\n    for d in data:\n        combined_dict.update(d)\n\n    # Convert the combined dictionary to a DataFrame\n    df = pd.DataFrame(list(combined_dict.items()), columns=['Time', 'Data Points'])\n\n    # Convert 'Time' and 'Data Points' to numeric\n    df['Time'] = pd.to_numeric(df['Time'])\n    df['Data Points'] = pd.to_numeric(df['Data Points'])\n\n    # Create a line plot\n    plt.figure(figsize=(10, 6))\n    plt.plot(df['Time'], df['Data Points'])\n    plt.xlabel('Time')\n    plt.ylabel('Data Points')\n    plt.title('Data over Time')\n\n    return plt.gca()"}
{"task_id": "BigCodeBench/524", "solution": "from collections import defaultdict\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not isinstance(data, list):\n        raise TypeError(\"Input data should be a list of dictionaries.\")\n    if not data:\n        raise ValueError(\"Input data should not be empty.\")\n\n    stats = defaultdict(list)\n    axes_list = []\n\n    for d in data:\n        if not isinstance(d, dict):\n            raise TypeError(\"All elements in the list should be dictionaries.\")\n        for k, v in d.items():\n            if not isinstance(v, (int, float, list, tuple, np.int64, np.float64)):\n                raise TypeError(\"All values in the dictionaries should be numeric.\")\n            stats[k].append(v)\n\n    for k, v in stats.items():\n        mean = np.mean(v)\n        std_dev = np.std(v)\n        stats[k] = (mean, std_dev)\n\n        fig, ax = plt.subplots()\n        ax.bar(['Mean', 'Std Dev'], [mean, std_dev], color=['blue', 'orange'])\n        ax.set_title(f'Statistics of {k}')\n        axes_list.append(ax)\n\n    return stats, axes_list", "raw_solution": "from collections import defaultdict\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not isinstance(data, list):\n        raise TypeError(\"Input data should be a list of dictionaries.\")\n    if not data:\n        raise ValueError(\"Input data should not be empty.\")\n\n    stats = defaultdict(list)\n    axes_list = []\n\n    for d in data:\n        if not isinstance(d, dict):\n            raise TypeError(\"All elements in the list should be dictionaries.\")\n        for k, v in d.items():\n            if not isinstance(v, (int, float, list, tuple, np.int64, np.float64)):\n                raise TypeError(\"All values in the dictionaries should be numeric.\")\n            stats[k].append(v)\n\n    for k, v in stats.items():\n        mean = np.mean(v)\n        std_dev = np.std(v)\n        stats[k] = (mean, std_dev)\n\n        fig, ax = plt.subplots()\n        ax.bar(['Mean', 'Std Dev'], [mean, std_dev], color=['blue', 'orange'])\n        ax.set_title(f'Statistics of {k}')\n        axes_list.append(ax)\n\n    return stats, axes_list"}
{"task_id": "BigCodeBench/525", "solution": "import json\nimport numpy as np\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\ndef task_func(input_file):\n    # Load the JSON file\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    # Initialize defaultdicts to store mean and median values\n    mean_dict = defaultdict(list)\n    median_dict = defaultdict(list)\n\n    # Calculate mean and median for each key across all dictionaries\n    for d in data:\n        for key, value in d.items():\n            mean_dict[key].append(np.mean(value))\n            median_dict[key].append(np.median(value))\n\n    # Convert lists to numpy arrays for further calculations\n    for key in mean_dict.keys():\n        mean_dict[key] = np.array(mean_dict[key])\n        median_dict[key] = np.array(median_dict[key])\n\n    # Initialize list to store plots\n    plots = []\n\n    # Create bar charts for each key\n    for key in mean_dict.keys():\n        fig, ax = plt.subplots()\n        ax.bar(range(len(mean_dict[key])), mean_dict[key], label='Mean')\n        ax.bar(range(len(median_dict[key])), median_dict[key], label='Median')\n        ax.legend()\n        ax.set_title(f'Mean and Median of {key}')\n        plots.append(ax)\n\n    # Return results and plots\n    result = {key: {'mean': np.mean(mean_dict[key]), 'median': np.mean(median_dict[key])} for key in mean_dict.keys()}\n    return result, plots", "raw_solution": "import json\nimport numpy as np\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef task_func(input_file):\n    # Load the JSON file\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    # Initialize defaultdicts to store mean and median values\n    mean_dict = defaultdict(list)\n    median_dict = defaultdict(list)\n\n    # Calculate mean and median for each key across all dictionaries\n    for d in data:\n        for key, value in d.items():\n            mean_dict[key].append(np.mean(value))\n            median_dict[key].append(np.median(value))\n\n    # Convert lists to numpy arrays for further calculations\n    for key in mean_dict.keys():\n        mean_dict[key] = np.array(mean_dict[key])\n        median_dict[key] = np.array(median_dict[key])\n\n    # Initialize list to store plots\n    plots = []\n\n    # Create bar charts for each key\n    for key in mean_dict.keys():\n        fig, ax = plt.subplots()\n        ax.bar(range(len(mean_dict[key])), mean_dict[key], label='Mean')\n        ax.bar(range(len(median_dict[key])), median_dict[key], label='Median')\n        ax.legend()\n        ax.set_title(f'Mean and Median of {key}')\n        plots.append(ax)\n\n    # Return results and plots\n    result = {key: {'mean': np.mean(mean_dict[key]), 'median': np.mean(median_dict[key])} for key in mean_dict.keys()}\n    return result, plots"}
{"task_id": "BigCodeBench/526", "solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\ndef task_func(input_file=\"data.json\"):\n    # Load data from JSON file\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    # Initialize dictionaries to store mean and median values\n    mean_dict = defaultdict(list)\n    median_dict = defaultdict(list)\n\n    # Iterate over each dictionary in the list\n    for d in data:\n        # Iterate over each key-value pair in the dictionary\n        for key, value in d.items():\n            # Ignore non-numeric or missing values\n            if isinstance(value, (int, float)):\n                mean_dict[key].append(value)\n                median_dict[key].append(value)\n\n    # Calculate mean and median for each key\n    for key in mean_dict.keys():\n        mean_dict[key] = np.mean(mean_dict[key])\n        median_dict[key] = np.median(median_dict[key])\n\n    # Convert the results into a Pandas DataFrame\n    df = pd.DataFrame(index=mean_dict.keys(), data={'mean': mean_dict.values(), 'median': median_dict.values()})\n\n    # Sort the DataFrame by the variable names\n    df.sort_index(inplace=True)\n\n    return df", "raw_solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\ndef task_func(input_file=\"data.json\"):\n    # Load data from JSON file\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    # Initialize dictionaries to store mean and median values\n    mean_dict = defaultdict(list)\n    median_dict = defaultdict(list)\n\n    # Iterate over each dictionary in the list\n    for d in data:\n        # Iterate over each key-value pair in the dictionary\n        for key, value in d.items():\n            # Ignore non-numeric or missing values\n            if isinstance(value, (int, float)):\n                mean_dict[key].append(value)\n                median_dict[key].append(value)\n\n    # Calculate mean and median for each key\n    for key in mean_dict.keys():\n        mean_dict[key] = np.mean(mean_dict[key])\n        median_dict[key] = np.median(median_dict[key])\n\n    # Convert the results into a Pandas DataFrame\n    df = pd.DataFrame(index=mean_dict.keys(), data={'mean': mean_dict.values(), 'median': median_dict.values()})\n\n    # Sort the DataFrame by the variable names\n    df.sort_index(inplace=True)\n\n    return df"}
{"task_id": "BigCodeBench/527", "solution": "import json\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\ndef task_func(input_file: str) -> dict:\n    # Read the JSON file\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    # Initialize a dictionary to store the results\n    results = defaultdict(dict)\n\n    # Convert the data into a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Calculate the mean and median for each key\n    for col in df.columns:\n        results[col]['mean'] = df[col].mean()\n        results[col]['median'] = df[col].median()\n\n    # Create a box plot\n    plt.figure(figsize=(10, 6))\n    sns.boxplot(data=df)\n    plt.title('Box plot of aggregated values for each key')\n    ax = plt.gca()\n\n    return results, ax", "raw_solution": "import json\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\ndef task_func(input_file: str) -> dict:\n    # Read the JSON file\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    # Initialize a dictionary to store the results\n    results = defaultdict(dict)\n\n    # Convert the data into a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Calculate the mean and median for each key\n    for col in df.columns:\n        results[col]['mean'] = df[col].mean()\n        results[col]['median'] = df[col].median()\n\n    # Create a box plot\n    plt.figure(figsize=(10, 6))\n    sns.boxplot(data=df)\n    plt.title('Box plot of aggregated values for each key')\n    ax = plt.gca()\n\n    return results, ax"}
{"task_id": "BigCodeBench/528", "solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(file_path):\n    if not file_path.endswith('.csv'):\n        raise ValueError(\"File should be in .csv format\")\n\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n\n    df = pd.DataFrame(data)\n    duplicates = df[df.duplicated()]\n    counts = Counter(duplicates.apply(tuple,1))\n\n    fig, ax = plt.subplots()\n    ax.bar(range(len(counts)), list(counts.values()), align='center')\n    ax.set_xticks(range(len(counts)))\n    ax.set_xticklabels(list(counts.keys()), rotation=90)\n    ax.set_xlabel('Duplicate Rows')\n    ax.set_ylabel('Counts')\n    ax.set_title('Count of Duplicate Rows')\n\n    return counts, ax", "raw_solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path):\n    if not file_path.endswith('.csv'):\n        raise ValueError(\"File should be in .csv format\")\n\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n\n    df = pd.DataFrame(data)\n    duplicates = df[df.duplicated()]\n    counts = Counter(duplicates.apply(tuple,1))\n\n    fig, ax = plt.subplots()\n    ax.bar(range(len(counts)), list(counts.values()), align='center')\n    ax.set_xticks(range(len(counts)))\n    ax.set_xticklabels(list(counts.keys()), rotation=90)\n    ax.set_xlabel('Duplicate Rows')\n    ax.set_ylabel('Counts')\n    ax.set_title('Count of Duplicate Rows')\n\n    return counts, ax"}
{"task_id": "BigCodeBench/529", "solution": "from collections import Counter\nimport random\nimport matplotlib.pyplot as plt\ndef task_func(num_rolls, num_dice, plot_path=None, random_seed=0):\n    random.seed(random_seed)\n    dice_rolls = [sum(random.randint(1, 6) for _ in range(num_dice)) for _ in range(num_rolls)]\n    counter = Counter(dice_rolls)\n\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Sum of Dice Roll')\n    ax.set_ylabel('Count')\n    ax.set_title('Distribution of Dice Roll Sums')\n\n    if plot_path is not None:\n        plt.savefig(plot_path)\n\n    return counter, ax", "raw_solution": "from collections import Counter\nimport random\nimport matplotlib.pyplot as plt\n\ndef task_func(num_rolls, num_dice, plot_path=None, random_seed=0):\n    random.seed(random_seed)\n    dice_rolls = [sum(random.randint(1, 6) for _ in range(num_dice)) for _ in range(num_rolls)]\n    counter = Counter(dice_rolls)\n\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Sum of Dice Roll')\n    ax.set_ylabel('Count')\n    ax.set_title('Distribution of Dice Roll Sums')\n\n    if plot_path is not None:\n        plt.savefig(plot_path)\n\n    return counter, ax"}
{"task_id": "BigCodeBench/530", "solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not all(df['age'] >= 0):\n        raise ValueError(\"Age cannot be negative\")\n\n    df['age'] = df['age'].apply(np.floor)\n    df['age'] = df['age'].astype(int)\n\n    name_counts = df['name'].value_counts()\n    duplicate_names = name_counts[name_counts > 1].index\n\n    if len(duplicate_names) == 0:\n        return Counter(), None\n\n    age_distribution = df[df['name'].isin(duplicate_names)]['age'].value_counts()\n\n    min_age = age_distribution.index.min()\n    max_age = age_distribution.index.max()\n\n    bins = np.arange(min_age, max_age + 1) - 0.5\n\n    plt.figure(figsize=(10, 6))\n    plt.hist(age_distribution.index, bins=bins, weights=age_distribution.values, edgecolor='black')\n    plt.xlabel('Age')\n    plt.ylabel('Count')\n    plt.title('Age Distribution for Duplicate Names')\n    plt.grid(True)\n\n    return age_distribution, plt.gca()", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not all(df['age'] >= 0):\n        raise ValueError(\"Age cannot be negative\")\n\n    df['age'] = df['age'].apply(np.floor)\n    df['age'] = df['age'].astype(int)\n\n    name_counts = df['name'].value_counts()\n    duplicate_names = name_counts[name_counts > 1].index\n\n    if len(duplicate_names) == 0:\n        return Counter(), None\n\n    age_distribution = df[df['name'].isin(duplicate_names)]['age'].value_counts()\n\n    min_age = age_distribution.index.min()\n    max_age = age_distribution.index.max()\n\n    bins = np.arange(min_age, max_age + 1) - 0.5\n\n    plt.figure(figsize=(10, 6))\n    plt.hist(age_distribution.index, bins=bins, weights=age_distribution.values, edgecolor='black')\n    plt.xlabel('Age')\n    plt.ylabel('Count')\n    plt.title('Age Distribution for Duplicate Names')\n    plt.grid(True)\n\n    return age_distribution, plt.gca()"}
{"task_id": "BigCodeBench/531", "solution": "from collections import Counter\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\ndef task_func(df, n_clusters=3, random_state=None, n_init=10):\n    # Identify duplicate points\n    duplicate_rows = df[df.duplicated()]\n    duplicate_count = Counter(duplicate_rows.index.values)\n\n    # Perform KMeans clustering on the unique points\n    unique_df = df.drop_duplicates()\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    kmeans.fit(unique_df.drop('cluster', axis=1))\n\n    # Record the clusters\n    unique_df['cluster'] = kmeans.labels_\n\n    # Plot the clustered data\n    fig, ax = plt.subplots()\n    for i in range(n_clusters):\n        ax.scatter(unique_df[unique_df['cluster']==i]['x'], unique_df[unique_df['cluster']==i]['y'], label=f'Cluster {i+1}')\n    ax.legend()\n    plt.show()\n\n    return duplicate_count, unique_df, fig.axes[0]\ndf = pd.DataFrame({'x': [1, 2, 2, 3, 4, 5], 'y': [1, 2, 2, 3, 4, 5]})", "raw_solution": "from collections import Counter\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef task_func(df, n_clusters=3, random_state=None, n_init=10):\n    # Identify duplicate points\n    duplicate_rows = df[df.duplicated()]\n    duplicate_count = Counter(duplicate_rows.index.values)\n\n    # Perform KMeans clustering on the unique points\n    unique_df = df.drop_duplicates()\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    kmeans.fit(unique_df.drop('cluster', axis=1))\n\n    # Record the clusters\n    unique_df['cluster'] = kmeans.labels_\n\n    # Plot the clustered data\n    fig, ax = plt.subplots()\n    for i in range(n_clusters):\n        ax.scatter(unique_df[unique_df['cluster']==i]['x'], unique_df[unique_df['cluster']==i]['y'], label=f'Cluster {i+1}')\n    ax.legend()\n    plt.show()\n\n    return duplicate_count, unique_df, fig.axes[0]\n\n# Test the function\ndf = pd.DataFrame({'x': [1, 2, 2, 3, 4, 5], 'y': [1, 2, 2, 3, 4, 5]})\nduplicate_count, unique_df, ax = task_func(df)"}
{"task_id": "BigCodeBench/532", "solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df, bins=4):\n    # Check if 'value' column exists in the DataFrame\n    if 'value' not in df.columns:\n        raise ValueError(\"'value' column not found in DataFrame\")\n\n    # Identify and count duplicate values\n    counter = Counter(df['value'])\n\n    # Create a histogram\n    fig, ax = plt.subplots()\n    ax.hist(df['value'], bins=bins, color='green', alpha=0.6, edgecolor='black')\n\n    # Fit a normal distribution to the data\n    mu, sigma = norm.fit(df['value'])\n\n    # Create a line for the normal distribution\n    line_x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    line_y = norm.pdf(line_x, mu, sigma)\n\n    # Plot the normal distribution line\n    ax.plot(line_x, line_y, color='black', linewidth=2)\n\n    # Set plot title and labels\n    ax.set_title(\"Distribution\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n\n    return counter, ax.figure", "raw_solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, bins=4):\n    # Check if 'value' column exists in the DataFrame\n    if 'value' not in df.columns:\n        raise ValueError(\"'value' column not found in DataFrame\")\n\n    # Identify and count duplicate values\n    counter = Counter(df['value'])\n\n    # Create a histogram\n    fig, ax = plt.subplots()\n    ax.hist(df['value'], bins=bins, color='green', alpha=0.6, edgecolor='black')\n\n    # Fit a normal distribution to the data\n    mu, sigma = norm.fit(df['value'])\n\n    # Create a line for the normal distribution\n    line_x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    line_y = norm.pdf(line_x, mu, sigma)\n\n    # Plot the normal distribution line\n    ax.plot(line_x, line_y, color='black', linewidth=2)\n\n    # Set plot title and labels\n    ax.set_title(\"Distribution\")\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Frequency\")\n\n    return counter, ax.figure"}
{"task_id": "BigCodeBench/533", "solution": "import numpy as np\nimport secrets\nimport hashlib\nimport base64\ndef task_func(num, from_base, to_base, alphabet):\n    if from_base < 2 or to_base < 2:\n        raise ValueError(\"Invalid base for conversion. Base must be greater than 1.\")\n\n    try:\n        number_in_base = int(num, from_base)\n    except ValueError:\n        raise ValueError(\"Invalid number format for conversion.\")\n\n    number_in_base = int(num, from_base)\n    number_in_decimal = int(str(number_in_base), 10)\n    number_in_new_base = np.base_repr(number_in_decimal, to_base)\n\n    salt = secrets.token_hex(16)\n    hash_object = hashlib.sha256(salt.encode() + number_in_new_base.encode())\n    hash_in_hex = hash_object.hexdigest()\n\n    custom_alphabet = ''.join(sorted(alphabet))\n    base64_alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\n    base64_table = str.maketrans(base64_alphabet, custom_alphabet)\n    number_in_base64 = base64.b64encode(hash_in_hex.encode()).decode().translate(base64_table)\n\n    return (number_in_base64, salt)\nalphabet = 'PQRSTUVWXYZABCDEFGHIJKLMNOabcdefghijklmn'", "raw_solution": "import numpy as np\nimport secrets\nimport hashlib\nimport base64\n\ndef task_func(num, from_base, to_base, alphabet):\n    if from_base < 2 or to_base < 2:\n        raise ValueError(\"Invalid base for conversion. Base must be greater than 1.\")\n\n    try:\n        number_in_base = int(num, from_base)\n    except ValueError:\n        raise ValueError(\"Invalid number format for conversion.\")\n\n    number_in_base = int(num, from_base)\n    number_in_decimal = int(str(number_in_base), 10)\n    number_in_new_base = np.base_repr(number_in_decimal, to_base)\n\n    salt = secrets.token_hex(16)\n    hash_object = hashlib.sha256(salt.encode() + number_in_new_base.encode())\n    hash_in_hex = hash_object.hexdigest()\n\n    custom_alphabet = ''.join(sorted(alphabet))\n    base64_alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\n    base64_table = str.maketrans(base64_alphabet, custom_alphabet)\n    number_in_base64 = base64.b64encode(hash_in_hex.encode()).decode().translate(base64_table)\n\n    return (number_in_base64, salt)\n\n# Testing\nalphabet = 'PQRSTUVWXYZABCDEFGHIJKLMNOabcdefghijklmn'\nresult1, salt1 = task_func('FF', 16, 8, alphabet)\nresult2, salt2 = task_func('FF', 16, 8, alphabet)"}
{"task_id": "BigCodeBench/534", "solution": "import numpy as np\nimport base64\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives.asymmetric import rsa\ndef task_func(num, from_base, to_base, private_key, alphabet):\n    # Convert number from one base to another\n    num_in_base10 = int(str(num), from_base)\n    num_in_base_to = np.base_repr(num_in_base10, to_base)\n\n    # Sign the number with RSA\n    signature = private_key.sign(\n        num_in_base_to.encode(),\n        padding.PSS(\n            mgf=padding.MGF1(hashes.SHA256()),\n            salt_length=padding.PSS.MAX_LENGTH\n        ),\n        hashes.SHA256()\n    )\n\n    # Encode the signed number in base64 with a custom alphabet\n    b64 = base64.b64encode(signature).decode()\n    b64 = b64.translate(str.maketrans('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/', alphabet))\n\n    return b64\nprivate_key = rsa.generate_private_key(\n    public_exponent=65537,\n    key_size=2048,\n)\nalphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'", "raw_solution": "import numpy as np\nimport base64\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives.asymmetric import rsa\n\ndef task_func(num, from_base, to_base, private_key, alphabet):\n    # Convert number from one base to another\n    num_in_base10 = int(str(num), from_base)\n    num_in_base_to = np.base_repr(num_in_base10, to_base)\n\n    # Sign the number with RSA\n    signature = private_key.sign(\n        num_in_base_to.encode(),\n        padding.PSS(\n            mgf=padding.MGF1(hashes.SHA256()),\n            salt_length=padding.PSS.MAX_LENGTH\n        ),\n        hashes.SHA256()\n    )\n\n    # Encode the signed number in base64 with a custom alphabet\n    b64 = base64.b64encode(signature).decode()\n    b64 = b64.translate(str.maketrans('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/', alphabet))\n\n    return b64\n\n# Generate RSA private key\nprivate_key = rsa.generate_private_key(\n    public_exponent=65537,\n    key_size=2048,\n)\n\n# Define custom alphabet\nalphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\n\n# Test the function"}
{"task_id": "BigCodeBench/535", "solution": "import sqlite3\nimport numpy as np\nfrom random import choice, seed\ndef task_func(db_path, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries cannot be negative\")\n\n    NAMES = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    AGES = list(range(18, 65))\n    HEIGHTS = list(range(150, 200))\n\n    seed(random_seed)\n\n    conn = sqlite3.connect(db_path)\n    c = conn.cursor()\n\n    c.execute(f'CREATE TABLE IF NOT EXISTS {table_name} (name text, age integer, height integer)')\n\n    for _ in range(num_entries):\n        name = choice(NAMES)\n        age = choice(AGES)\n        height = choice(HEIGHTS)\n        c.execute(f'INSERT INTO {table_name} VALUES (?, ?, ?)', (name, age, height))\n\n    conn.commit()\n    conn.close()\n\n    return num_entries", "raw_solution": "import sqlite3\nimport numpy as np\nfrom random import choice, seed\n\ndef task_func(db_path, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries cannot be negative\")\n\n    NAMES = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    AGES = list(range(18, 65))\n    HEIGHTS = list(range(150, 200))\n\n    seed(random_seed)\n\n    conn = sqlite3.connect(db_path)\n    c = conn.cursor()\n\n    c.execute(f'CREATE TABLE IF NOT EXISTS {table_name} (name text, age integer, height integer)')\n\n    for _ in range(num_entries):\n        name = choice(NAMES)\n        age = choice(AGES)\n        height = choice(HEIGHTS)\n        c.execute(f'INSERT INTO {table_name} VALUES (?, ?, ?)', (name, age, height))\n\n    conn.commit()\n    conn.close()\n\n    return num_entries"}
{"task_id": "BigCodeBench/536", "solution": "import sqlite3\nimport pandas as pd\nimport os\ndef task_func(db_name, table_name, csv_path=\"data.csv\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n\n    # Read the table from the database into a pandas DataFrame\n    df = pd.read_sql_query(f\"SELECT * from {table_name}\", conn)\n\n    # Export the DataFrame to a CSV file\n    df.to_csv(csv_path, index=False)\n\n    # Get the absolute path of the exported CSV file\n    csv_abs_path = os.path.abspath(csv_path)\n\n    return csv_abs_path", "raw_solution": "import sqlite3\nimport pandas as pd\nimport os\n\ndef task_func(db_name, table_name, csv_path=\"data.csv\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n\n    # Read the table from the database into a pandas DataFrame\n    df = pd.read_sql_query(f\"SELECT * from {table_name}\", conn)\n\n    # Export the DataFrame to a CSV file\n    df.to_csv(csv_path, index=False)\n\n    # Get the absolute path of the exported CSV file\n    csv_abs_path = os.path.abspath(csv_path)\n\n    return csv_abs_path"}
{"task_id": "BigCodeBench/537", "solution": "import sqlite3\nimport pandas as pd\nimport seaborn as sns\ndef task_func(db_name=\"test.db\", table_name=\"People\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n\n    # Execute a query to fetch data from the table\n    query = f\"SELECT * FROM {table_name}\"\n    df = pd.read_sql_query(query, conn)\n\n    # Check if there are any negative age values in the data\n    if (df['age'] < 0).any():\n        raise ValueError(\"The data contains negative age values.\")\n\n    # Draw the age distribution of the persons\n    ax = sns.distplot(df['age'], bins=30, kde=True)\n\n    return ax", "raw_solution": "import sqlite3\nimport pandas as pd\nimport seaborn as sns\n\ndef task_func(db_name=\"test.db\", table_name=\"People\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n\n    # Execute a query to fetch data from the table\n    query = f\"SELECT * FROM {table_name}\"\n    df = pd.read_sql_query(query, conn)\n\n    # Check if there are any negative age values in the data\n    if (df['age'] < 0).any():\n        raise ValueError(\"The data contains negative age values.\")\n\n    # Draw the age distribution of the persons\n    ax = sns.distplot(df['age'], bins=30, kde=True)\n\n    return ax"}
{"task_id": "BigCodeBench/538", "solution": "import sqlite3\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(db_name, table_name):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n\n    # Query the table\n    df = pd.read_sql_query(f\"SELECT * from {table_name}\", conn)\n\n    # Get the column names\n    cols = df.columns.tolist()\n\n    # Exclude 'id' column\n    if 'id' in cols:\n        cols.remove('id')\n\n    # Check if there are at least two numerical columns\n    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n    if len(numerical_cols) < 2:\n        raise ValueError(\"The table has less than two numerical columns.\")\n\n    # Plot the relationship between the first two numerical columns\n    plt.scatter(df[numerical_cols[0]], df[numerical_cols[1]])\n    plt.xlabel(numerical_cols[0])\n    plt.ylabel(numerical_cols[1])\n    plt.show()", "raw_solution": "import sqlite3\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(db_name, table_name):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n\n    # Query the table\n    df = pd.read_sql_query(f\"SELECT * from {table_name}\", conn)\n\n    # Get the column names\n    cols = df.columns.tolist()\n\n    # Exclude 'id' column\n    if 'id' in cols:\n        cols.remove('id')\n\n    # Check if there are at least two numerical columns\n    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n    if len(numerical_cols) < 2:\n        raise ValueError(\"The table has less than two numerical columns.\")\n\n    # Plot the relationship between the first two numerical columns\n    plt.scatter(df[numerical_cols[0]], df[numerical_cols[1]])\n    plt.xlabel(numerical_cols[0])\n    plt.ylabel(numerical_cols[1])\n    plt.show()"}
{"task_id": "BigCodeBench/539", "solution": "import sqlite3\nfrom random import choice, seed, randint\nimport os\ndef task_func(db_name, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries cannot be negative\")\n\n    NAMES = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    AGES = range(18, 65)\n    HEIGHTS = range(150, 200)\n\n    if random_seed is not None:\n        seed(random_seed)\n\n    conn = sqlite3.connect(db_name)\n    cursor = conn.cursor()\n\n    cursor.execute(f'CREATE TABLE {table_name} (name text, age integer, height integer)')\n\n    for _ in range(num_entries):\n        name = choice(NAMES)\n        age = randint(18, 65)\n        height = randint(150, 200)\n        cursor.execute(f'INSERT INTO {table_name} VALUES (?, ?, ?)', (name, age, height))\n\n    conn.commit()\n    conn.close()\n\n    return os.path.abspath(db_name)", "raw_solution": "import sqlite3\nfrom random import choice, seed, randint\nimport os\n\ndef task_func(db_name, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries cannot be negative\")\n\n    NAMES = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    AGES = range(18, 65)\n    HEIGHTS = range(150, 200)\n\n    if random_seed is not None:\n        seed(random_seed)\n\n    conn = sqlite3.connect(db_name)\n    cursor = conn.cursor()\n\n    cursor.execute(f'CREATE TABLE {table_name} (name text, age integer, height integer)')\n\n    for _ in range(num_entries):\n        name = choice(NAMES)\n        age = randint(18, 65)\n        height = randint(150, 200)\n        cursor.execute(f'INSERT INTO {table_name} VALUES (?, ?, ?)', (name, age, height))\n\n    conn.commit()\n    conn.close()\n\n    return os.path.abspath(db_name)"}
{"task_id": "BigCodeBench/540", "solution": "from collections import Counter\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\ndef task_func(list_of_menuitems, title=\"Menu Distribution\", color=\"blue\", width=1.0):\n    # Flatten the list using itertools.chain\n    flat_list = list(itertools.chain(*list_of_menuitems))\n\n    # Count the occurrences of each item\n    counter = Counter(flat_list)\n\n    # Sort the items alphabetically\n    items, counts = zip(*sorted(counter.items()))\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    ax.bar(items, counts, color=color, width=width)\n\n    # Set labels and title\n    ax.set_xlabel(\"Menu Items\")\n    ax.set_ylabel(\"Frequency\")\n    ax.set_title(title)\n\n    return ax", "raw_solution": "from collections import Counter\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef task_func(list_of_menuitems, title=\"Menu Distribution\", color=\"blue\", width=1.0):\n    # Flatten the list using itertools.chain\n    flat_list = list(itertools.chain(*list_of_menuitems))\n\n    # Count the occurrences of each item\n    counter = Counter(flat_list)\n\n    # Sort the items alphabetically\n    items, counts = zip(*sorted(counter.items()))\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    ax.bar(items, counts, color=color, width=width)\n\n    # Set labels and title\n    ax.set_xlabel(\"Menu Items\")\n    ax.set_ylabel(\"Frequency\")\n    ax.set_title(title)\n\n    return ax"}
{"task_id": "BigCodeBench/541", "solution": "import os\nimport sys\nimport importlib\nfrom pkgutil import iter_modules\ndef task_func(package_name):\n    try:\n        package = importlib.import_module(package_name)\n    except ImportError:\n        raise ImportError(f\"{package_name} is not installed. Please install it using pip install {package_name}\")\n\n    package_path = os.path.dirname(package.__file__)\n    module_names = [name for _, name, _ in iter_modules([package_path])]\n\n    for name in module_names:\n        if name not in sys.modules:\n            sys.path.append(os.path.join(package_path, name + '.py'))\n\n    return module_names", "raw_solution": "import os\nimport sys\nimport importlib\nfrom pkgutil import iter_modules\n\ndef task_func(package_name):\n    try:\n        package = importlib.import_module(package_name)\n    except ImportError:\n        raise ImportError(f\"{package_name} is not installed. Please install it using pip install {package_name}\")\n\n    package_path = os.path.dirname(package.__file__)\n    module_names = [name for _, name, _ in iter_modules([package_path])]\n\n    for name in module_names:\n        if name not in sys.modules:\n            sys.path.append(os.path.join(package_path, name + '.py'))\n\n    return module_names\n\n# Testing"}
{"task_id": "BigCodeBench/542", "solution": "import hashlib\nimport random\nimport struct\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_keys=KEYS, seed=42):\n    # Set the seed for deterministic random choices\n    random.seed(seed)\n\n    # Select one key at random\n    hex_key = random.choice(hex_keys)\n\n    try:\n        # Convert the hexadecimal string to a floating-point number\n        float_val = struct.unpack('>f', bytes.fromhex(hex_key))[0]\n    except (ValueError, TypeError):\n        # Raise exception if the hexadecimal string is invalid\n        raise ValueError(\"Invalid hexadecimal string\")\n\n    # Compute the MD5 hash of the floating-point number\n    md5_hash = hashlib.md5(struct.pack('>f', float_val))\n\n    # Return the MD5 hash as a string\n    return md5_hash.hexdigest()", "raw_solution": "import hashlib\nimport random\nimport struct\n\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\n\ndef task_func(hex_keys=KEYS, seed=42):\n    # Set the seed for deterministic random choices\n    random.seed(seed)\n\n    # Select one key at random\n    hex_key = random.choice(hex_keys)\n\n    try:\n        # Convert the hexadecimal string to a floating-point number\n        float_val = struct.unpack('>f', bytes.fromhex(hex_key))[0]\n    except (ValueError, TypeError):\n        # Raise exception if the hexadecimal string is invalid\n        raise ValueError(\"Invalid hexadecimal string\")\n\n    # Compute the MD5 hash of the floating-point number\n    md5_hash = hashlib.md5(struct.pack('>f', float_val))\n\n    # Return the MD5 hash as a string\n    return md5_hash.hexdigest()\n\n# Test the function"}
{"task_id": "BigCodeBench/543", "solution": "import base64\nimport os\ndef task_func():\n    # Generate a random float number\n    random_float = os.urandom(4)\n    # Convert the float to hexadecimal\n    hex_string = random_float.hex()\n    # Encode the hexadecimal string in base64\n    base64_string = base64.b64encode(bytes.fromhex(hex_string)).decode()\n    return base64_string", "raw_solution": "import base64\nimport os\n\ndef task_func():\n    # Generate a random float number\n    random_float = os.urandom(4)\n    # Convert the float to hexadecimal\n    hex_string = random_float.hex()\n    # Encode the hexadecimal string in base64\n    base64_string = base64.b64encode(bytes.fromhex(hex_string)).decode()\n    return base64_string\n\n# Test the function"}
{"task_id": "BigCodeBench/544", "solution": "import struct\nimport zlib\nKEY = '470FC614'\ndef task_func(hex_string=KEY):\n    # Convert hex string to float\n    float_num = struct.unpack('f', bytes.fromhex(hex_string))[0]\n\n    # Convert float to bytes\n    float_bytes = struct.pack('f', float_num)\n\n    # Compress the bytes\n    compressed_bytes = zlib.compress(float_bytes)\n\n    return compressed_bytes", "raw_solution": "import struct\nimport zlib\n\n# Constants\nKEY = '470FC614'\n\ndef task_func(hex_string=KEY):\n    # Convert hex string to float\n    float_num = struct.unpack('f', bytes.fromhex(hex_string))[0]\n\n    # Convert float to bytes\n    float_bytes = struct.pack('f', float_num)\n\n    # Compress the bytes\n    compressed_bytes = zlib.compress(float_bytes)\n\n    return compressed_bytes\n\n# Test the function\ncompressed_bytes = task_func()"}
{"task_id": "BigCodeBench/545", "solution": "import codecs\nimport random\nimport struct\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_keys=KEYS):\n    # Convert hex strings to float\n    float_keys = [struct.unpack('f', bytes.fromhex(key))[0] for key in hex_keys]\n\n    # Generate a random float number from the list\n    rand_float = random.choice(float_keys)\n\n    # Encode the float number in utf-8\n    bytes_float = rand_float.encode('utf-8')\n\n    return bytes_float", "raw_solution": "import codecs\nimport random\nimport struct\n\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\n\ndef task_func(hex_keys=KEYS):\n    # Convert hex strings to float\n    float_keys = [struct.unpack('f', bytes.fromhex(key))[0] for key in hex_keys]\n\n    # Generate a random float number from the list\n    rand_float = random.choice(float_keys)\n\n    # Encode the float number in utf-8\n    bytes_float = rand_float.encode('utf-8')\n\n    return bytes_float\n\n# Test the function"}
{"task_id": "BigCodeBench/546", "solution": "from collections import OrderedDict\nfrom prettytable import PrettyTable\ndef task_func(my_dict):\n    # Sort the dictionary by keys\n    sorted_dict = OrderedDict(sorted(my_dict.items()))\n\n    # Create a PrettyTable object\n    pt = PrettyTable()\n\n    # Add columns to the table\n    pt.field_names = [\"Key\", \"Value\"]\n\n    # Add rows to the table\n    for key, value in sorted_dict.items():\n        pt.add_row([key, value])\n\n    return pt", "raw_solution": "from collections import OrderedDict\nfrom prettytable import PrettyTable\n\ndef task_func(my_dict):\n    # Sort the dictionary by keys\n    sorted_dict = OrderedDict(sorted(my_dict.items()))\n\n    # Create a PrettyTable object\n    pt = PrettyTable()\n\n    # Add columns to the table\n    pt.field_names = [\"Key\", \"Value\"]\n\n    # Add rows to the table\n    for key, value in sorted_dict.items():\n        pt.add_row([key, value])\n\n    return pt\n\n# Test the function"}
{"task_id": "BigCodeBench/547", "solution": "import hashlib\nimport os\nimport base64\ndef task_func(password: str, salt_length: int = 8) -> str:\n    # Generate a random salt\n    salt = os.urandom(salt_length)\n\n    # Combine the password and salt\n    password_salt = password.encode() + salt\n\n    # Hash the password with SHA-256\n    hashed_password = hashlib.sha256(password_salt).digest()\n\n    # Encode the hashed password in base64\n    encoded_password = base64.b64encode(hashed_password)\n\n    # Return the base64 encoded password\n    return encoded_password.decode()", "raw_solution": "import hashlib\nimport os\nimport base64\n\ndef task_func(password: str, salt_length: int = 8) -> str:\n    # Generate a random salt\n    salt = os.urandom(salt_length)\n\n    # Combine the password and salt\n    password_salt = password.encode() + salt\n\n    # Hash the password with SHA-256\n    hashed_password = hashlib.sha256(password_salt).digest()\n\n    # Encode the hashed password in base64\n    encoded_password = base64.b64encode(hashed_password)\n\n    # Return the base64 encoded password\n    return encoded_password.decode()\n\n# Test the function"}
{"task_id": "BigCodeBench/548", "solution": "import random\nimport string\nimport base64\nimport zlib\ndef task_func(string_length=100):\n    # Generate a random string of uppercase letters and digits\n    random_string = ''.join(random.choices(string.ascii_uppercase + string.digits, k=string_length))\n\n    # Compress the string with zlib\n    compressed_string = zlib.compress(random_string.encode())\n\n    # Encode the compressed string in base64\n    base64_string = base64.b64encode(compressed_string)\n\n    return base64_string.decode()", "raw_solution": "import random\nimport string\nimport base64\nimport zlib\n\ndef task_func(string_length=100):\n    # Generate a random string of uppercase letters and digits\n    random_string = ''.join(random.choices(string.ascii_uppercase + string.digits, k=string_length))\n\n    # Compress the string with zlib\n    compressed_string = zlib.compress(random_string.encode())\n\n    # Encode the compressed string in base64\n    base64_string = base64.b64encode(compressed_string)\n\n    return base64_string.decode()\n\n# Test the function"}
{"task_id": "BigCodeBench/549", "solution": "import base64\nimport pandas as pd\nfrom io import StringIO\ndef task_func(d):\n    # Convert the dict to a DataFrame\n    df = pd.DataFrame(d)\n\n    # Convert the DataFrame to CSV format\n    csv_str = df.to_csv(index=False)\n\n    # Encode the CSV string to bytes\n    csv_bytes = csv_str.encode('utf-8')\n\n    # Encode the bytes to a Base64 string\n    base64_str = base64.b64encode(csv_bytes).decode('utf-8')\n\n    return base64_str\nd = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}", "raw_solution": "import base64\nimport pandas as pd\nfrom io import StringIO\n\ndef task_func(d):\n    # Convert the dict to a DataFrame\n    df = pd.DataFrame(d)\n\n    # Convert the DataFrame to CSV format\n    csv_str = df.to_csv(index=False)\n\n    # Encode the CSV string to bytes\n    csv_bytes = csv_str.encode('utf-8')\n\n    # Encode the bytes to a Base64 string\n    base64_str = base64.b64encode(csv_bytes).decode('utf-8')\n\n    return base64_str\n\n# Test the function\nd = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}"}
{"task_id": "BigCodeBench/550", "solution": "from collections import Counter\nimport pandas as pd\ndef task_func(list_of_menuitems):\n    # Flatten the list\n    flat_list = [item for sublist in list_of_menuitems for item in sublist]\n    \n    # Count the occurrences of each item\n    counter = Counter(flat_list)\n    \n    # Create a DataFrame from the Counter\n    df = pd.DataFrame.from_dict(counter, orient='index', columns=['Count'])\n    df.index.name = 'MenuItem'\n    \n    return df", "raw_solution": "from collections import Counter\nimport pandas as pd\n\ndef task_func(list_of_menuitems):\n    # Flatten the list\n    flat_list = [item for sublist in list_of_menuitems for item in sublist]\n    \n    # Count the occurrences of each item\n    counter = Counter(flat_list)\n    \n    # Create a DataFrame from the Counter\n    df = pd.DataFrame.from_dict(counter, orient='index', columns=['Count'])\n    df.index.name = 'MenuItem'\n    \n    return df\n\n# Test the function\nmenu_items = [['Pasta', 'Pizza', 'Pasta'], ['Pizza', 'Burger', 'Sandwich'], ['Sandwich', 'Pasta', 'Soup']]"}
{"task_id": "BigCodeBench/551", "solution": "from collections import Counter\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\ndef task_func(list_of_menuitems):\n    # Flatten the list\n    flat_list = [item for sublist in list_of_menuitems for item in sublist]\n    \n    # Count the frequency of each item\n    counter = Counter(flat_list)\n    \n    # Create a DataFrame from the counter\n    df = pd.DataFrame(list(counter.items()), columns=['Menu Item', 'Frequency'])\n    \n    # Sort the DataFrame by 'Frequency'\n    df = df.sort_values('Frequency', ascending=False)\n    \n    # Plot the DataFrame using seaborn\n    ax = sns.barplot(x='Menu Item', y='Frequency', data=df)\n    \n    return ax\nlist_of_menuitems = [['Item1', 'Item2'], ['Item1', 'Item3'], ['Item2', 'Item3'], ['Item1', 'Item2', 'Item3']]", "raw_solution": "from collections import Counter\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\ndef task_func(list_of_menuitems):\n    # Flatten the list\n    flat_list = [item for sublist in list_of_menuitems for item in sublist]\n    \n    # Count the frequency of each item\n    counter = Counter(flat_list)\n    \n    # Create a DataFrame from the counter\n    df = pd.DataFrame(list(counter.items()), columns=['Menu Item', 'Frequency'])\n    \n    # Sort the DataFrame by 'Frequency'\n    df = df.sort_values('Frequency', ascending=False)\n    \n    # Plot the DataFrame using seaborn\n    ax = sns.barplot(x='Menu Item', y='Frequency', data=df)\n    \n    return ax\n\n# Test the function\nlist_of_menuitems = [['Item1', 'Item2'], ['Item1', 'Item3'], ['Item2', 'Item3'], ['Item1', 'Item2', 'Item3']]\nax = task_func(list_of_menuitems)\nplt.show()"}
{"task_id": "BigCodeBench/552", "solution": "import collections\nimport itertools\nimport matplotlib.pyplot as plt\nITEMS = ['apple', 'banana']\ndef task_func(a, b, items=ITEMS):\n    # Combine two lists\n    combined = list(itertools.chain(a, b))\n\n    # Count frequency of items\n    counter = collections.Counter(combined)\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Items')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of items in the combined list')\n\n    return ax\na = ['apple', 'banana', 'apple', 'orange']\nb = ['banana', 'apple', 'peach', 'banana']", "raw_solution": "import collections\nimport itertools\nimport matplotlib.pyplot as plt\n\n# Constants\nITEMS = ['apple', 'banana']\n\ndef task_func(a, b, items=ITEMS):\n    # Combine two lists\n    combined = list(itertools.chain(a, b))\n\n    # Count frequency of items\n    counter = collections.Counter(combined)\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    ax.set_xlabel('Items')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of items in the combined list')\n\n    return ax\n\n# Test the function\na = ['apple', 'banana', 'apple', 'orange']\nb = ['banana', 'apple', 'peach', 'banana']\nax = task_func(a, b)\nplt.show()"}
{"task_id": "BigCodeBench/553", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(a, b):\n    # Create a DataFrame with random values\n    df = pd.DataFrame(np.random.rand(len(a), len(b)), index=a, columns=COLUMNS[:len(b)])\n\n    # Plot the DataFrame as a bar chart\n    ax = df.plot(kind='bar')\n\n    return ax\na = ['Row1', 'Row2', 'Row3']\nb = [1, 2, 3, 4, 5]", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(a, b):\n    # Create a DataFrame with random values\n    df = pd.DataFrame(np.random.rand(len(a), len(b)), index=a, columns=COLUMNS[:len(b)])\n\n    # Plot the DataFrame as a bar chart\n    ax = df.plot(kind='bar')\n\n    return ax\n\n# Test the function\na = ['Row1', 'Row2', 'Row3']\nb = [1, 2, 3, 4, 5]\nax = task_func(a, b)\nplt.show()"}
{"task_id": "BigCodeBench/554", "solution": "import numpy as np\nimport random\ndef task_func(MIN_WORDS, MAX_WORDS, WORDS_POOL):\n    num_words = np.random.randint(MIN_WORDS, MAX_WORDS + 1)\n    sentence = ' '.join(random.choices(WORDS_POOL, k=num_words))\n    return sentence + ' ' + ' '.join(sentence.split()[::-1])\nMIN_WORDS = 5\nMAX_WORDS = 10\nWORDS_POOL = ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']", "raw_solution": "import numpy as np\nimport random\n\ndef task_func(MIN_WORDS, MAX_WORDS, WORDS_POOL):\n    num_words = np.random.randint(MIN_WORDS, MAX_WORDS + 1)\n    sentence = ' '.join(random.choices(WORDS_POOL, k=num_words))\n    return sentence + ' ' + ' '.join(sentence.split()[::-1])\n\n# Test the function\nMIN_WORDS = 5\nMAX_WORDS = 10\nWORDS_POOL = ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n\nsentence = task_func(MIN_WORDS, MAX_WORDS, WORDS_POOL)"}
{"task_id": "BigCodeBench/555", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\ndef task_func(a, b):\n    # Check if inputs are lists\n    if not isinstance(a, list) or not isinstance(b, list):\n        raise ValueError(\"Inputs should be lists\")\n\n    # Check if lists are not empty\n    if len(a) == 0 or len(b) == 0:\n        raise ValueError(\"Lists should not be empty\")\n\n    # Check if lists have the same length\n    if len(a) != len(b):\n        raise ValueError(\"Lists should have the same length\")\n\n    # Convert lists to numpy arrays\n    a = np.array(a)\n    b = np.array(b)\n\n    # Calculate Pearson correlation coefficient\n    pearson_coef, _ = stats.pearsonr(a, b)\n\n    # Create a pandas DataFrame\n    df = pd.DataFrame({'a': a, 'b': b})\n\n    # Create a scatter plot with a regression line\n    fig, ax = plt.subplots()\n    df.plot(kind='scatter', x='a', y='b', ax=ax)\n    slope, intercept, _, _, _ = stats.linregress(a, b)\n    ax.plot(a, intercept + slope * a, color='red')\n\n    return (pearson_coef, ax)\na = [1, 2, 3, 4, 5]\nb = [2, 3, 4, 5, 6]", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndef task_func(a, b):\n    # Check if inputs are lists\n    if not isinstance(a, list) or not isinstance(b, list):\n        raise ValueError(\"Inputs should be lists\")\n\n    # Check if lists are not empty\n    if len(a) == 0 or len(b) == 0:\n        raise ValueError(\"Lists should not be empty\")\n\n    # Check if lists have the same length\n    if len(a) != len(b):\n        raise ValueError(\"Lists should have the same length\")\n\n    # Convert lists to numpy arrays\n    a = np.array(a)\n    b = np.array(b)\n\n    # Calculate Pearson correlation coefficient\n    pearson_coef, _ = stats.pearsonr(a, b)\n\n    # Create a pandas DataFrame\n    df = pd.DataFrame({'a': a, 'b': b})\n\n    # Create a scatter plot with a regression line\n    fig, ax = plt.subplots()\n    df.plot(kind='scatter', x='a', y='b', ax=ax)\n    slope, intercept, _, _, _ = stats.linregress(a, b)\n    ax.plot(a, intercept + slope * a, color='red')\n\n    return (pearson_coef, ax)\n\n# Test the function\na = [1, 2, 3, 4, 5]\nb = [2, 3, 4, 5, 6]"}
{"task_id": "BigCodeBench/556", "solution": "import numpy as np\nimport random\nfrom difflib import SequenceMatcher\ndef task_func(s, min_length, max_length, letters):\n    # Generate a random string of length between min_length and max_length\n    random_string = ''.join(random.choice(letters) for _ in range(random.randint(min_length, max_length)))\n    \n    # Calculate similarity score\n    similarity_score = SequenceMatcher(None, s, random_string).ratio()\n    \n    # Return the random string and whether it's considered similar to s\n    return (random_string, similarity_score >= 0.5)\ns = \"hello\"\nmin_length = 3\nmax_length = 5\nletters = \"abcdefghijklmnopqrstuvwxyz\"", "raw_solution": "import numpy as np\nimport random\nfrom difflib import SequenceMatcher\n\ndef task_func(s, min_length, max_length, letters):\n    # Generate a random string of length between min_length and max_length\n    random_string = ''.join(random.choice(letters) for _ in range(random.randint(min_length, max_length)))\n    \n    # Calculate similarity score\n    similarity_score = SequenceMatcher(None, s, random_string).ratio()\n    \n    # Return the random string and whether it's considered similar to s\n    return (random_string, similarity_score >= 0.5)\n\n# Test the function\ns = \"hello\"\nmin_length = 3\nmax_length = 5\nletters = \"abcdefghijklmnopqrstuvwxyz\"\n\nresult = task_func(s, min_length, max_length, letters)"}
{"task_id": "BigCodeBench/557", "solution": "import numpy as np\nfrom difflib import SequenceMatcher\nimport matplotlib.pyplot as plt\ndef task_func(s_list, plot_path=None):\n    if not isinstance(s_list, list):\n        raise ValueError(\"s_list should be a list of strings\")\n    if not all(isinstance(i, str) for i in s_list):\n        raise ValueError(\"s_list should be a list of strings\")\n    if len(s_list) == 0:\n        return np.nan\n    if len(s_list) == 1:\n        return np.nan\n\n    scores = []\n    for i in range(len(s_list)):\n        score_list = []\n        for j in range(len(s_list)):\n            if i != j:\n                score = SequenceMatcher(None, s_list[i], s_list[j]).ratio()\n                score_list.append(score)\n        scores.append(np.mean(score_list))\n\n    if plot_path:\n        plt.figure(figsize=(10, 6))\n        plt.bar(range(len(s_list)), scores)\n        plt.xlabel('Strings')\n        plt.ylabel('Average Similarity Score')\n        plt.savefig(plot_path)\n\n    return scores", "raw_solution": "import numpy as np\nfrom difflib import SequenceMatcher\nimport matplotlib.pyplot as plt\n\ndef task_func(s_list, plot_path=None):\n    if not isinstance(s_list, list):\n        raise ValueError(\"s_list should be a list of strings\")\n    if not all(isinstance(i, str) for i in s_list):\n        raise ValueError(\"s_list should be a list of strings\")\n    if len(s_list) == 0:\n        return np.nan\n    if len(s_list) == 1:\n        return np.nan\n\n    scores = []\n    for i in range(len(s_list)):\n        score_list = []\n        for j in range(len(s_list)):\n            if i != j:\n                score = SequenceMatcher(None, s_list[i], s_list[j]).ratio()\n                score_list.append(score)\n        scores.append(np.mean(score_list))\n\n    if plot_path:\n        plt.figure(figsize=(10, 6))\n        plt.bar(range(len(s_list)), scores)\n        plt.xlabel('Strings')\n        plt.ylabel('Average Similarity Score')\n        plt.savefig(plot_path)\n\n    return scores"}
{"task_id": "BigCodeBench/558", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(a, b, columns=['A', 'B']):\n    # Check if inputs are lists\n    if not isinstance(a, list) or not isinstance(b, list):\n        raise ValueError(\"Inputs should be lists\")\n\n    # Check if inputs are not empty\n    if not a or not b:\n        raise ValueError(\"Inputs should not be empty\")\n\n    # Check if inputs are of same length\n    if len(a) != len(b):\n        raise ValueError(\"Inputs should be of same length\")\n\n    # Convert lists to numpy arrays\n    a = np.array(a).reshape(-1, 1)\n    b = np.array(b).reshape(-1, 1)\n\n    # Combine into a DataFrame\n    df = pd.DataFrame(np.hstack([a, b]), columns=columns)\n\n    # Initialize StandardScaler\n    scaler = StandardScaler()\n\n    # Fit and transform the data\n    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=columns)\n\n    # Create a bar plot\n    ax = df_scaled.plot(kind='bar', figsize=(10, 6))\n\n    return df_scaled, ax.figure\na = [1, 2, 3, 4, 5]\nb = [10, 20, 30, 40, 50]", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(a, b, columns=['A', 'B']):\n    # Check if inputs are lists\n    if not isinstance(a, list) or not isinstance(b, list):\n        raise ValueError(\"Inputs should be lists\")\n\n    # Check if inputs are not empty\n    if not a or not b:\n        raise ValueError(\"Inputs should not be empty\")\n\n    # Check if inputs are of same length\n    if len(a) != len(b):\n        raise ValueError(\"Inputs should be of same length\")\n\n    # Convert lists to numpy arrays\n    a = np.array(a).reshape(-1, 1)\n    b = np.array(b).reshape(-1, 1)\n\n    # Combine into a DataFrame\n    df = pd.DataFrame(np.hstack([a, b]), columns=columns)\n\n    # Initialize StandardScaler\n    scaler = StandardScaler()\n\n    # Fit and transform the data\n    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=columns)\n\n    # Create a bar plot\n    ax = df_scaled.plot(kind='bar', figsize=(10, 6))\n\n    return df_scaled, ax.figure\n\n# Test the function\na = [1, 2, 3, 4, 5]\nb = [10, 20, 30, 40, 50]\ndf, fig = task_func(a, b)\nplt.show()"}
{"task_id": "BigCodeBench/559", "solution": "import pandas as pd\nfrom scipy.spatial import distance\nimport matplotlib.pyplot as plt\ndef task_func(a, b):\n    # Calculate Euclidean distance\n    euclidean_distance = distance.euclidean(a, b)\n\n    # Create DataFrame\n    df = pd.DataFrame({'A': a, 'B': b}, index=['A', 'B', 'C', 'D', 'E'])\n\n    # Create plot\n    fig, ax = plt.subplots()\n    ax.plot(df)\n\n    return euclidean_distance, df, ax\na = [1, 2, 3, 4, 5]\nb = [4, 5, 6, 7, 8]", "raw_solution": "import pandas as pd\nfrom scipy.spatial import distance\nimport matplotlib.pyplot as plt\n\ndef task_func(a, b):\n    # Calculate Euclidean distance\n    euclidean_distance = distance.euclidean(a, b)\n\n    # Create DataFrame\n    df = pd.DataFrame({'A': a, 'B': b}, index=['A', 'B', 'C', 'D', 'E'])\n\n    # Create plot\n    fig, ax = plt.subplots()\n    ax.plot(df)\n\n    return euclidean_distance, df, ax\n\n# Test the function\na = [1, 2, 3, 4, 5]\nb = [4, 5, 6, 7, 8]\neuclidean_distance, df, ax = task_func(a, b)"}
{"task_id": "BigCodeBench/560", "solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(data):\n    # Convert the 'date' column to datetime\n    data['date'] = pd.to_datetime(data['date'])\n\n    # Set the 'date' column as the index\n    data.set_index('date', inplace=True)\n\n    # Resample the data to monthly frequency and take the mean\n    monthly_data = data.resample('M').mean()\n\n    # Create a bar chart\n    ax = monthly_data.plot(kind='bar', figsize=(12, 6))\n\n    # Set the title and labels\n    ax.set_title(f'Monthly Data for {data.index[0].year}')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n\n    return ax\ndata = pd.DataFrame({\n    'date': pd.date_range(start='1/1/2020', periods=12),\n    'value': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n})", "raw_solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(data):\n    # Convert the 'date' column to datetime\n    data['date'] = pd.to_datetime(data['date'])\n\n    # Set the 'date' column as the index\n    data.set_index('date', inplace=True)\n\n    # Resample the data to monthly frequency and take the mean\n    monthly_data = data.resample('M').mean()\n\n    # Create a bar chart\n    ax = monthly_data.plot(kind='bar', figsize=(12, 6))\n\n    # Set the title and labels\n    ax.set_title(f'Monthly Data for {data.index[0].year}')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n\n    return ax\n\n# Test the function\ndata = pd.DataFrame({\n    'date': pd.date_range(start='1/1/2020', periods=12),\n    'value': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n})\n\nax = task_func(data)\nplt.show()"}
{"task_id": "BigCodeBench/561", "solution": "from datetime import datetime\nimport pytz\nfrom dateutil import parser\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the date string into a datetime object\n    dt = parser.parse(date_str)\n\n    # Localize the datetime object to the from_tz timezone\n    dt = dt.replace(tzinfo=pytz.timezone(from_tz))\n\n    # Convert the datetime object to the to_tz timezone\n    dt = dt.astimezone(pytz.timezone(to_tz))\n\n    # Format the datetime object into a string in \"yyyy-mm-dd hh:mm:ss\" format\n    dt_str = dt.strftime('%Y-%m-%d %H:%M:%S')\n\n    return dt_str", "raw_solution": "from datetime import datetime\nimport pytz\nfrom dateutil import parser\n\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the date string into a datetime object\n    dt = parser.parse(date_str)\n\n    # Localize the datetime object to the from_tz timezone\n    dt = dt.replace(tzinfo=pytz.timezone(from_tz))\n\n    # Convert the datetime object to the to_tz timezone\n    dt = dt.astimezone(pytz.timezone(to_tz))\n\n    # Format the datetime object into a string in \"yyyy-mm-dd hh:mm:ss\" format\n    dt_str = dt.strftime('%Y-%m-%d %H:%M:%S')\n\n    return dt_str\n\n# Test the function"}
{"task_id": "BigCodeBench/562", "solution": "import os\nimport ctypes\nimport sys\nimport subprocess\ndef task_func(filepath):\n    if not isinstance(filepath, str):\n        raise TypeError(\"Input filepath must be a string\")\n    if not filepath:\n        raise OSError(\"Input filepath is invalid or empty\")\n\n    # Load DLL file\n    try:\n        ctypes.CDLL(filepath)\n    except OSError:\n        raise OSError(\"Failed to load DLL file\")\n\n    # Retrieve system information\n    system_info = os.uname()\n    python_version = sys.version.split()[0]\n\n    # Get PIP version\n    pip_version = subprocess.run([\"pip\", \"--version\"], capture_output=True, text=True).stdout.split()[1]\n\n    # Print system information\n    print(f\"System: {system_info.sysname} Node Name: {system_info.nodename} Release: {system_info.release} Version: {system_info.version} Machine: {system_info.machine} Python Version: {python_version} PIP Version: {pip_version}\")\n\n    return f\"The name of the loaded DLL file: {filepath}\"", "raw_solution": "import os\nimport ctypes\nimport sys\nimport subprocess\n\ndef task_func(filepath):\n    if not isinstance(filepath, str):\n        raise TypeError(\"Input filepath must be a string\")\n    if not filepath:\n        raise OSError(\"Input filepath is invalid or empty\")\n\n    # Load DLL file\n    try:\n        ctypes.CDLL(filepath)\n    except OSError:\n        raise OSError(\"Failed to load DLL file\")\n\n    # Retrieve system information\n    system_info = os.uname()\n    python_version = sys.version.split()[0]\n\n    # Get PIP version\n    pip_version = subprocess.run([\"pip\", \"--version\"], capture_output=True, text=True).stdout.split()[1]\n\n    # Print system information\n    print(f\"System: {system_info.sysname} Node Name: {system_info.nodename} Release: {system_info.release} Version: {system_info.version} Machine: {system_info.machine} Python Version: {python_version} PIP Version: {pip_version}\")\n\n    return f\"The name of the loaded DLL file: {filepath}\""}
{"task_id": "BigCodeBench/563", "solution": "import ctypes\nimport os\nimport shutil\nimport glob\ndef task_func(filepath, destination_dir):\n    # Check if the filepath exists\n    if not os.path.exists(filepath):\n        return \"The specified file does not exist.\"\n\n    # Check if the file is a DLL file\n    if not filepath.lower().endswith('.dll'):\n        return \"The specified file is not a DLL file.\"\n\n    # Check if the destination directory exists\n    if not os.path.exists(destination_dir):\n        return \"The specified destination directory does not exist.\"\n\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Get the name of the loaded DLL file\n    dll_name = dll._name\n\n    # Move all DLL files in the same directory to the destination directory\n    for dll_file in glob.glob(os.path.join(os.path.dirname(filepath), '*.dll')):\n        shutil.move(dll_file, destination_dir)\n\n    return dll_name", "raw_solution": "import ctypes\nimport os\nimport shutil\nimport glob\n\ndef task_func(filepath, destination_dir):\n    # Check if the filepath exists\n    if not os.path.exists(filepath):\n        return \"The specified file does not exist.\"\n\n    # Check if the file is a DLL file\n    if not filepath.lower().endswith('.dll'):\n        return \"The specified file is not a DLL file.\"\n\n    # Check if the destination directory exists\n    if not os.path.exists(destination_dir):\n        return \"The specified destination directory does not exist.\"\n\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Get the name of the loaded DLL file\n    dll_name = dll._name\n\n    # Move all DLL files in the same directory to the destination directory\n    for dll_file in glob.glob(os.path.join(os.path.dirname(filepath), '*.dll')):\n        shutil.move(dll_file, destination_dir)\n\n    return dll_name\n\n# Test the function"}
{"task_id": "BigCodeBench/564", "solution": "import os\nimport ctypes\nfrom datetime import datetime\nimport pytz\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Get the file metadata\n    file_info = os.stat(filepath)\n\n    # Convert the file size from bytes to megabytes\n    file_size = file_info.st_size / (1024 * 1024)\n\n    # Convert the creation and modification times to UTC\n    creation_time = datetime.fromtimestamp(file_info.st_ctime).astimezone(pytz.utc)\n    modification_time = datetime.fromtimestamp(file_info.st_mtime).astimezone(pytz.utc)\n\n    # Create a dictionary to store the metadata\n    metadata = {\n        'Creation Time': creation_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Modification Time': modification_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Size': f'{file_size} MB'\n    }\n\n    return os.path.basename(filepath), metadata\nfilepath = 'path_to_your_dll_file'", "raw_solution": "import os\nimport ctypes\nfrom datetime import datetime\nimport pytz\n\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Get the file metadata\n    file_info = os.stat(filepath)\n\n    # Convert the file size from bytes to megabytes\n    file_size = file_info.st_size / (1024 * 1024)\n\n    # Convert the creation and modification times to UTC\n    creation_time = datetime.fromtimestamp(file_info.st_ctime).astimezone(pytz.utc)\n    modification_time = datetime.fromtimestamp(file_info.st_mtime).astimezone(pytz.utc)\n\n    # Create a dictionary to store the metadata\n    metadata = {\n        'Creation Time': creation_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Modification Time': modification_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Size': f'{file_size} MB'\n    }\n\n    return os.path.basename(filepath), metadata\n\n# Test the function\nfilepath = 'path_to_your_dll_file'\nfilename, metadata = task_func(filepath)"}
{"task_id": "BigCodeBench/565", "solution": "import ctypes\nimport hashlib\nimport binascii\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Get the actual name of the loaded DLL file\n    dll_name = dll._name\n\n    # Open the DLL file in binary mode\n    with open(filepath, 'rb') as f:\n        # Calculate the MD5 hash\n        md5_hash = hashlib.md5(f.read()).digest()\n\n        # Calculate the SHA256 hash\n        sha256_hash = hashlib.sha256(f.read()).digest()\n\n    # Convert the hashes to hexadecimal format\n    md5_hex = binascii.hexlify(md5_hash).decode()\n    sha256_hex = binascii.hexlify(sha256_hash).decode()\n\n    # Print the hashes\n    print(f\"MD5 hash of {dll_name}: {md5_hex}\")\n    print(f\"SHA256 hash of {dll_name}: {sha256_hex}\")\n\n    return dll_name", "raw_solution": "import ctypes\nimport hashlib\nimport binascii\n\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n\n    # Get the actual name of the loaded DLL file\n    dll_name = dll._name\n\n    # Open the DLL file in binary mode\n    with open(filepath, 'rb') as f:\n        # Calculate the MD5 hash\n        md5_hash = hashlib.md5(f.read()).digest()\n\n        # Calculate the SHA256 hash\n        sha256_hash = hashlib.sha256(f.read()).digest()\n\n    # Convert the hashes to hexadecimal format\n    md5_hex = binascii.hexlify(md5_hash).decode()\n    sha256_hex = binascii.hexlify(sha256_hash).decode()\n\n    # Print the hashes\n    print(f\"MD5 hash of {dll_name}: {md5_hex}\")\n    print(f\"SHA256 hash of {dll_name}: {sha256_hex}\")\n\n    return dll_name"}
{"task_id": "BigCodeBench/566", "solution": "import inspect\nimport types\ndef task_func(f):\n    if not inspect.isfunction(f):\n        raise ValueError(\"Input must be a function\")\n\n    result = {\n        \"name\": f.__name__,\n        \"is_lambda\": isinstance(f, types.LambdaType),\n        \"arguments\": list(inspect.signature(f).parameters.keys()),\n        \"default_values\": [val.default for val in inspect.signature(f).parameters.values() if val.default is not inspect.Parameter.empty],\n        \"annotations\": [val.annotation for val in inspect.signature(f).parameters.values() if val.annotation is not inspect.Parameter.empty]\n    }\n\n    return result", "raw_solution": "import inspect\nimport types\n\ndef task_func(f):\n    if not inspect.isfunction(f):\n        raise ValueError(\"Input must be a function\")\n\n    result = {\n        \"name\": f.__name__,\n        \"is_lambda\": isinstance(f, types.LambdaType),\n        \"arguments\": list(inspect.signature(f).parameters.keys()),\n        \"default_values\": [val.default for val in inspect.signature(f).parameters.values() if val.default is not inspect.Parameter.empty],\n        \"annotations\": [val.annotation for val in inspect.signature(f).parameters.values() if val.annotation is not inspect.Parameter.empty]\n    }\n\n    return result\n\n# Testing\ndef test_func(a, b=10, c=None):\n    \"\"\"\n    This is a test function\n    \"\"\"\n    return a + b + (c if c else 0)\n"}
{"task_id": "BigCodeBench/567", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Convert string data to numeric\n    data = pd.to_numeric(data, errors='coerce')\n\n    # Remove NaN values\n    data = data.dropna()\n\n    # Calculate bins\n    bins = np.arange(data.min(), data.max()+2) - 0.5\n\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=bins, edgecolor='black')\n\n    # Set labels and title\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Values')\n\n    return ax\ndata = pd.Series(['1', '2', '3', '2', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Convert string data to numeric\n    data = pd.to_numeric(data, errors='coerce')\n\n    # Remove NaN values\n    data = data.dropna()\n\n    # Calculate bins\n    bins = np.arange(data.min(), data.max()+2) - 0.5\n\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=bins, edgecolor='black')\n\n    # Set labels and title\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Values')\n\n    return ax\n\n# Test the function\ndata = pd.Series(['1', '2', '3', '2', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\nax = task_func(data)\nplt.show()"}
{"task_id": "BigCodeBench/568", "solution": "import inspect\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(f_list):\n    if not all(map(lambda f: not inspect.isfunction(f) or not f.__name__.startswith('<lambda>'), f_list)):\n        raise ValueError(\"Input contains lambda function\")\n\n    data = [(f.__name__, len(inspect.signature(f).parameters)) for f in f_list]\n    df = pd.DataFrame(data, columns=['Function Name', 'Number of Arguments'])\n\n    df.plot(x='Function Name', y='Number of Arguments', kind='bar', legend=None)\n    plt.xlabel('Function Name')\n    plt.ylabel('Number of Arguments')\n    plt.title('Number of Arguments per Function')\n    plt.show()\n\n    return df", "raw_solution": "import inspect\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(f_list):\n    if not all(map(lambda f: not inspect.isfunction(f) or not f.__name__.startswith('<lambda>'), f_list)):\n        raise ValueError(\"Input contains lambda function\")\n\n    data = [(f.__name__, len(inspect.signature(f).parameters)) for f in f_list]\n    df = pd.DataFrame(data, columns=['Function Name', 'Number of Arguments'])\n\n    df.plot(x='Function Name', y='Number of Arguments', kind='bar', legend=None)\n    plt.xlabel('Function Name')\n    plt.ylabel('Number of Arguments')\n    plt.title('Number of Arguments per Function')\n    plt.show()\n\n    return df"}
{"task_id": "BigCodeBench/569", "solution": "import inspect\nimport types\nimport math\ndef task_func(f):\n    sig = inspect.signature(f)\n    num_args = len(sig.parameters)\n    lambda_count = sum(1 for param in sig.parameters.values() if isinstance(param.default, types.LambdaType))\n    return {\n        'function_name': f.__name__,\n        'sqrt_num_args': math.sqrt(num_args),\n        'lambda_count': lambda_count,\n    }", "raw_solution": "import inspect\nimport types\nimport math\n\ndef task_func(f):\n    sig = inspect.signature(f)\n    num_args = len(sig.parameters)\n    lambda_count = sum(1 for param in sig.parameters.values() if isinstance(param.default, types.LambdaType))\n    return {\n        'function_name': f.__name__,\n        'sqrt_num_args': math.sqrt(num_args),\n        'lambda_count': lambda_count,\n    }\n\ndef test_task_func():\n    def f1(a, b, c=lambda: 1, d=lambda: 2):\n        pass\n\n    def f2(a, b, c=lambda: 1):\n        pass\n\n    assert task_func(f1) == {\n        'function_name': 'f1',\n        'sqrt_num_args': math.sqrt(4),\n        'lambda_count': 2,\n    }\n\n    assert task_func(f2) == {\n        'function_name': 'f2',\n        'sqrt_num_args': math.sqrt(3),\n        'lambda_count': 1,\n    }\n\n    print(\"All tests pass.\")\n\ntest_task_func()"}
{"task_id": "BigCodeBench/570", "solution": "import inspect\nimport types\nimport json\ndef task_func(f):\n    if isinstance(f, types.LambdaType):\n        is_lambda = True\n    else:\n        is_lambda = False\n\n    arg_spec = inspect.getfullargspec(f)\n    annotations = inspect.get_annotations(f)\n\n    func_specs = {\n        \"name\": f.__name__,\n        \"arguments\": arg_spec.args,\n        \"defaults\": arg_spec.defaults if arg_spec.defaults else [],\n        \"annotations\": annotations,\n        \"is_lambda\": is_lambda\n    }\n\n    return json.dumps(func_specs, indent=4)", "raw_solution": "import inspect\nimport types\nimport json\n\ndef task_func(f):\n    if isinstance(f, types.LambdaType):\n        is_lambda = True\n    else:\n        is_lambda = False\n\n    arg_spec = inspect.getfullargspec(f)\n    annotations = inspect.get_annotations(f)\n\n    func_specs = {\n        \"name\": f.__name__,\n        \"arguments\": arg_spec.args,\n        \"defaults\": arg_spec.defaults if arg_spec.defaults else [],\n        \"annotations\": annotations,\n        \"is_lambda\": is_lambda\n    }\n\n    return json.dumps(func_specs, indent=4)\n\n# Testing\ndef test_func(a, b=10, c=20):\n    \"\"\"\n    This is a test function.\n    \"\"\"\n    return a + b + c\n\nlambda_func = lambda a, b=10, c=20: a + b + c\n"}
{"task_id": "BigCodeBench/571", "solution": "import inspect\nimport pandas as pd\ndef task_func(f_list, file_path):\n    if not isinstance(f_list, list):\n        raise ValueError(\"'f_list' should be a list of functions\")\n    if not f_list:\n        raise ValueError(\"'f_list' should not be empty\")\n    if not isinstance(file_path, str):\n        raise ValueError(\"'file_path' should be a string\")\n\n    data = []\n    for func in f_list:\n        if not inspect.isfunction(func):\n            raise ValueError(\"All elements in 'f_list' should be functions\")\n        arg_spec = inspect.getfullargspec(func)\n        defaults = arg_spec.defaults if arg_spec.defaults else None\n        annotations = func.__annotations__ if func.__annotations__ else None\n        data.append({\n            'Function Name': func.__name__,\n            'Number of Arguments': len(arg_spec.args),\n            'Defaults': defaults,\n            'Annotations': annotations,\n            'Is Lambda': inspect.isfunction(func) and func.__name__ == '<lambda>'\n        })\n\n    try:\n        pd.DataFrame(data).to_csv(file_path, index=False)\n    except IOError:\n        raise IOError(\"Error in writing to the specified file path\")\n\n    return None", "raw_solution": "import inspect\nimport pandas as pd\n\ndef task_func(f_list, file_path):\n    if not isinstance(f_list, list):\n        raise ValueError(\"'f_list' should be a list of functions\")\n    if not f_list:\n        raise ValueError(\"'f_list' should not be empty\")\n    if not isinstance(file_path, str):\n        raise ValueError(\"'file_path' should be a string\")\n\n    data = []\n    for func in f_list:\n        if not inspect.isfunction(func):\n            raise ValueError(\"All elements in 'f_list' should be functions\")\n        arg_spec = inspect.getfullargspec(func)\n        defaults = arg_spec.defaults if arg_spec.defaults else None\n        annotations = func.__annotations__ if func.__annotations__ else None\n        data.append({\n            'Function Name': func.__name__,\n            'Number of Arguments': len(arg_spec.args),\n            'Defaults': defaults,\n            'Annotations': annotations,\n            'Is Lambda': inspect.isfunction(func) and func.__name__ == '<lambda>'\n        })\n\n    try:\n        pd.DataFrame(data).to_csv(file_path, index=False)\n    except IOError:\n        raise IOError(\"Error in writing to the specified file path\")\n\n    return None"}
{"task_id": "BigCodeBench/572", "solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array_length=100):\n    # Generate two arrays of random integers\n    array1 = [randint(0,100) for _ in range(array_length)]\n    array2 = [randint(0,100) for _ in range(array_length)]\n\n    # Find the maximum values of the respective elements of the two arrays\n    max_values = [max(array1[i], array2[i]) for i in range(array_length)]\n\n    # Draw a line diagram with the maximum values of the respective elements of the two arrays\n    plt.plot(max_values)\n    plt.ylabel('Maximum Values')\n    plt.show()\n\n    return plt.gca()", "raw_solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(array_length=100):\n    # Generate two arrays of random integers\n    array1 = [randint(0,100) for _ in range(array_length)]\n    array2 = [randint(0,100) for _ in range(array_length)]\n\n    # Find the maximum values of the respective elements of the two arrays\n    max_values = [max(array1[i], array2[i]) for i in range(array_length)]\n\n    # Draw a line diagram with the maximum values of the respective elements of the two arrays\n    plt.plot(max_values)\n    plt.ylabel('Maximum Values')\n    plt.show()\n\n    return plt.gca()\n\n# Test the function\naxes = task_func(50)\nassert isinstance(axes, plt.Axes)"}
{"task_id": "BigCodeBench/573", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(array_length=100):\n    # Generate two arrays of random numbers\n    array1 = np.random.rand(array_length)\n    array2 = np.random.rand(array_length)\n\n    # Calculate their mean, median, and standard deviation\n    mean1, mean2 = np.mean(array1), np.mean(array2)\n    median1, median2 = np.median(array1), np.median(array2)\n    std1, std2 = np.std(array1), np.std(array2)\n\n    # Store these results in a Panda DataFrame 'statistics'\n    statistics = pd.DataFrame({\n        'Array1': [mean1, median1, std1],\n        'Array2': [mean2, median2, std2],\n        'Statistics': ['Mean', 'Median', 'Standard Deviation']\n    }, columns=['Statistics', 'Array1', 'Array2'])\n\n    # Set the 'Statistics' column as the index\n    statistics.set_index('Statistics', inplace=True)\n\n    # Draw a bar chart to compare these statistics\n    fig, ax = plt.subplots()\n    statistics.plot(kind='bar', ax=ax)\n    ax.set_ylabel('Value')\n    ax.set_title('Comparison of Statistics of Two Arrays')\n\n    return statistics, ax.figure", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(array_length=100):\n    # Generate two arrays of random numbers\n    array1 = np.random.rand(array_length)\n    array2 = np.random.rand(array_length)\n\n    # Calculate their mean, median, and standard deviation\n    mean1, mean2 = np.mean(array1), np.mean(array2)\n    median1, median2 = np.median(array1), np.median(array2)\n    std1, std2 = np.std(array1), np.std(array2)\n\n    # Store these results in a Panda DataFrame 'statistics'\n    statistics = pd.DataFrame({\n        'Array1': [mean1, median1, std1],\n        'Array2': [mean2, median2, std2],\n        'Statistics': ['Mean', 'Median', 'Standard Deviation']\n    }, columns=['Statistics', 'Array1', 'Array2'])\n\n    # Set the 'Statistics' column as the index\n    statistics.set_index('Statistics', inplace=True)\n\n    # Draw a bar chart to compare these statistics\n    fig, ax = plt.subplots()\n    statistics.plot(kind='bar', ax=ax)\n    ax.set_ylabel('Value')\n    ax.set_title('Comparison of Statistics of Two Arrays')\n\n    return statistics, ax.figure\n\n# Test the function\nstatistics, fig = task_func(100)"}
{"task_id": "BigCodeBench/574", "solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array_length=100, noise_level=0.2):\n    def sine_func(x, a, b, c):\n        return a * np.sin(b * x) + c\n\n    x = np.linspace(0, 2 * np.pi, array_length)\n    y = np.sin(x) + np.random.normal(0, noise_level, array_length)\n\n    popt, _ = curve_fit(sine_func, x, y)\n\n    plt.figure()\n    plt.plot(x, y, 'ko', label='Noisy Sine Wave')\n    plt.plot(x, sine_func(x, *popt), 'r-', label='Adjusted Curve')\n    plt.legend()\n    plt.show()\n\n    return plt.gca()", "raw_solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(array_length=100, noise_level=0.2):\n    def sine_func(x, a, b, c):\n        return a * np.sin(b * x) + c\n\n    x = np.linspace(0, 2 * np.pi, array_length)\n    y = np.sin(x) + np.random.normal(0, noise_level, array_length)\n\n    popt, _ = curve_fit(sine_func, x, y)\n\n    plt.figure()\n    plt.plot(x, y, 'ko', label='Noisy Sine Wave')\n    plt.plot(x, sine_func(x, *popt), 'r-', label='Adjusted Curve')\n    plt.legend()\n    plt.show()\n\n    return plt.gca()"}
{"task_id": "BigCodeBench/575", "solution": "from random import shuffle\nimport pandas as pd\nimport numpy as np\ndef task_func(l, n_groups = 5):\n    # Shuffle the list\n    shuffle(l)\n\n    # Construct a dataframe using the shuffled list\n    df = pd.DataFrame(l, columns=['Value'])\n\n    # For each row in the dataframe, move the first n_groups elements to the end of the same row\n    for i in range(len(df)):\n        df.iloc[i] = np.roll(df.iloc[i], n_groups)\n\n    return df\nl = [i for i in range(10)]", "raw_solution": "from random import shuffle\nimport pandas as pd\nimport numpy as np\n\n# Constants\ndef task_func(l, n_groups = 5):\n    # Shuffle the list\n    shuffle(l)\n\n    # Construct a dataframe using the shuffled list\n    df = pd.DataFrame(l, columns=['Value'])\n\n    # For each row in the dataframe, move the first n_groups elements to the end of the same row\n    for i in range(len(df)):\n        df.iloc[i] = np.roll(df.iloc[i], n_groups)\n\n    return df\n\n# Test the function\nl = [i for i in range(10)]"}
{"task_id": "BigCodeBench/576", "solution": "from random import shuffle, randint\nimport pandas as pd\ndef task_func(l, n_groups = 5):\n    shuffle(l)\n    series = pd.Series(l)\n    for i in range(len(series)):\n        series[i] = series[i][n_groups:] + series[i][:n_groups]\n    return series\nl = ['abcdefghijklmnopqrstuvwxyz', '1234567890', 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', '!@#$%^&*()', 'Hello, World!']", "raw_solution": "from random import shuffle, randint\nimport pandas as pd\n\ndef task_func(l, n_groups = 5):\n    shuffle(l)\n    series = pd.Series(l)\n    for i in range(len(series)):\n        series[i] = series[i][n_groups:] + series[i][:n_groups]\n    return series\n\n# Test the function\nl = ['abcdefghijklmnopqrstuvwxyz', '1234567890', 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', '!@#$%^&*()', 'Hello, World!']"}
{"task_id": "BigCodeBench/577", "solution": "import os\nimport pathlib\nfrom hashlib import md5\nimport unicodedata\ndef task_func(directory):\n    result = {}\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            ascii_filename = unicodedata.normalize('NFKD', filename).encode('ASCII', 'ignore').decode()\n            with open(file_path, 'rb') as file:\n                file_data = file.read()\n                file_size = len(file_data)\n                file_hash = md5(file_data).hexdigest()\n            result[ascii_filename] = {'Size': file_size, 'MD5 Hash': file_hash}\n    return result", "raw_solution": "import os\nimport pathlib\nfrom hashlib import md5\nimport unicodedata\n\ndef task_func(directory):\n    result = {}\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            ascii_filename = unicodedata.normalize('NFKD', filename).encode('ASCII', 'ignore').decode()\n            with open(file_path, 'rb') as file:\n                file_data = file.read()\n                file_size = len(file_data)\n                file_hash = md5(file_data).hexdigest()\n            result[ascii_filename] = {'Size': file_size, 'MD5 Hash': file_hash}\n    return result"}
{"task_id": "BigCodeBench/578", "solution": "import unicodedata\nimport requests\nfrom requests.exceptions import HTTPError\nURL = 'https://api.github.com/users/'\ndef task_func(username):\n    try:\n        response = requests.get(URL + username)\n        response.raise_for_status()\n    except HTTPError as http_err:\n        print(f'HTTP error occurred: {http_err}')\n    except Exception as err:\n        print(f'Other error occurred: {err}')\n    else:\n        data = response.json()\n        normalized_data = {\n            key: unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode() \n            if isinstance(value, str) \n            else value \n            for key, value in data.items()\n        }\n        return normalized_data", "raw_solution": "import unicodedata\nimport requests\nfrom requests.exceptions import HTTPError\n\nURL = 'https://api.github.com/users/'\n\ndef task_func(username):\n    try:\n        response = requests.get(URL + username)\n        response.raise_for_status()\n    except HTTPError as http_err:\n        print(f'HTTP error occurred: {http_err}')\n    except Exception as err:\n        print(f'Other error occurred: {err}')\n    else:\n        data = response.json()\n        normalized_data = {\n            key: unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode() \n            if isinstance(value, str) \n            else value \n            for key, value in data.items()\n        }\n        return normalized_data"}
{"task_id": "BigCodeBench/579", "solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r', encoding='utf-8') as file:\n            reader = csv.reader(file)\n            data = [row[0] for row in reader]\n    except FileNotFoundError:\n        print(f\"File {csv_file} not found.\")\n        return\n    except IOError:\n        print(f\"Error reading file {csv_file}.\")\n        return\n\n    # Normalize text to ASCII\n    data = [unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore') for text in data]\n\n    # Tokenize text\n    words = ' '.join(data).split()\n\n    # Count words\n    word_counts = Counter(words)\n\n    # Get 10 most common words\n    common_words = word_counts.most_common(10)\n\n    # Create bar plot\n    words, counts = zip(*common_words)\n    fig, ax = plt.subplots()\n    ax.bar(words, counts)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('10 Most Common Words')\n\n    return ax, common_words", "raw_solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r', encoding='utf-8') as file:\n            reader = csv.reader(file)\n            data = [row[0] for row in reader]\n    except FileNotFoundError:\n        print(f\"File {csv_file} not found.\")\n        return\n    except IOError:\n        print(f\"Error reading file {csv_file}.\")\n        return\n\n    # Normalize text to ASCII\n    data = [unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore') for text in data]\n\n    # Tokenize text\n    words = ' '.join(data).split()\n\n    # Count words\n    word_counts = Counter(words)\n\n    # Get 10 most common words\n    common_words = word_counts.most_common(10)\n\n    # Create bar plot\n    words, counts = zip(*common_words)\n    fig, ax = plt.subplots()\n    ax.bar(words, counts)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('10 Most Common Words')\n\n    return ax, common_words"}
{"task_id": "BigCodeBench/580", "solution": "import pandas as pd\nimport random\nimport statistics\nimport matplotlib.pyplot as plt\nimport numpy as np\nRANGE = 10000\nSIZE = 1000\nBIN_WIDTH = 100\ndef task_func():\n    # Generate random integers\n    random_numbers = [random.randint(0, RANGE) for _ in range(SIZE)]\n\n    # Calculate moving average\n    moving_average = [sum(random_numbers[max(0, i-5):i+1])/(min(5, i+1)) for i in range(SIZE)]\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        \"Random Numbers\": random_numbers,\n        \"Moving Average\": moving_average\n    })\n\n    # Plot histogram\n    plt.hist(df[\"Random Numbers\"], bins=BIN_WIDTH)\n    plt.title(\"Histogram of Random Numbers\")\n    plt.xlabel(\"Random Number\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n\n    return df", "raw_solution": "import pandas as pd\nimport random\nimport statistics\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Constants\nRANGE = 10000  # The range within which random numbers are generated\nSIZE = 1000  # The number of random numbers to generate\nBIN_WIDTH = 100  # The width of bins for the histogram\n\ndef task_func():\n    # Generate random integers\n    random_numbers = [random.randint(0, RANGE) for _ in range(SIZE)]\n\n    # Calculate moving average\n    moving_average = [sum(random_numbers[max(0, i-5):i+1])/(min(5, i+1)) for i in range(SIZE)]\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        \"Random Numbers\": random_numbers,\n        \"Moving Average\": moving_average\n    })\n\n    # Plot histogram\n    plt.hist(df[\"Random Numbers\"], bins=BIN_WIDTH)\n    plt.title(\"Histogram of Random Numbers\")\n    plt.xlabel(\"Random Number\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n\n    return df"}
{"task_id": "BigCodeBench/581", "solution": "import math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nRANGE = 10000\nSIZE = 1000\nPI = np.pi\ndef task_func(size=SIZE, frequency=1):\n    # Create a list of random x values\n    x = np.random.rand(size) * RANGE\n\n    # Create a list of random y values\n    y = [np.sin(2 * PI * frequency * i) for i in x]\n\n    # Plot the sinusoidal wave\n    plt.plot(x, y)\n\n    # Return the plot\n    return plt", "raw_solution": "import math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\n\n# Constants\nRANGE = 10000\nSIZE = 1000\nPI = np.pi\n\ndef task_func(size=SIZE, frequency=1):\n    # Create a list of random x values\n    x = np.random.rand(size) * RANGE\n\n    # Create a list of random y values\n    y = [np.sin(2 * PI * frequency * i) for i in x]\n\n    # Plot the sinusoidal wave\n    plt.plot(x, y)\n\n    # Return the plot\n    return plt\n\n# Test the function\nplot = task_func()\nplot.show()"}
{"task_id": "BigCodeBench/582", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(size=1000):\n    # Generate normally distributed random numbers\n    data = np.random.normal(size=size)\n\n    # Create a figure\n    fig, ax = plt.subplots(2, 1, figsize=(10, 8))\n\n    # Plot histogram\n    ax[0].hist(data, bins=30, density=True)\n    ax[0].set_title('Histogram')\n\n    # Plot PDF\n    x = np.linspace(-4, 4, 1000)\n    ax[1].plot(x, stats.norm.pdf(x))\n    ax[1].hist(data, bins=30, density=True, alpha=0.2)\n    ax[1].set_title('PDF')\n\n    # Adjust layout and show plot\n    plt.tight_layout()\n    plt.show()\n\n    return fig", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(size=1000):\n    # Generate normally distributed random numbers\n    data = np.random.normal(size=size)\n\n    # Create a figure\n    fig, ax = plt.subplots(2, 1, figsize=(10, 8))\n\n    # Plot histogram\n    ax[0].hist(data, bins=30, density=True)\n    ax[0].set_title('Histogram')\n\n    # Plot PDF\n    x = np.linspace(-4, 4, 1000)\n    ax[1].plot(x, stats.norm.pdf(x))\n    ax[1].hist(data, bins=30, density=True, alpha=0.2)\n    ax[1].set_title('PDF')\n\n    # Adjust layout and show plot\n    plt.tight_layout()\n    plt.show()\n\n    return fig\n\n# Test the function\nfig = task_func()"}
{"task_id": "BigCodeBench/583", "solution": "import rsa\nimport os\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES\nfrom base64 import b64encode, b64decode\ndef task_func():\n    # Generate RSA key pair\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Generate random 8 bytes for filename\n    random_bytes = get_random_bytes(8)\n\n    # Convert bytes to hex and add to filename\n    filename = \"private_key_\" + random_bytes.hex() + \".txt\"\n\n    # Generate random 16 bytes for AES encryption\n    password = get_random_bytes(16)\n\n    # Encrypt the private key with AES\n    cipher = AES.new(password, AES.MODE_EAX)\n    ciphertext, tag = cipher.encrypt_and_digest(rsa.key.exportKey('PEM'))\n\n    # Save the encrypted private key to file\n    with open(filename, 'wb') as file:\n        [file.write(x) for x in (cipher.nonce, ciphertext, tag)]\n\n    # Return public key, filename, password and nonce\n    return pubkey, filename, password, cipher.nonce", "raw_solution": "import rsa\nimport os\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES\nfrom base64 import b64encode, b64decode\n\ndef task_func():\n    # Generate RSA key pair\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Generate random 8 bytes for filename\n    random_bytes = get_random_bytes(8)\n\n    # Convert bytes to hex and add to filename\n    filename = \"private_key_\" + random_bytes.hex() + \".txt\"\n\n    # Generate random 16 bytes for AES encryption\n    password = get_random_bytes(16)\n\n    # Encrypt the private key with AES\n    cipher = AES.new(password, AES.MODE_EAX)\n    ciphertext, tag = cipher.encrypt_and_digest(rsa.key.exportKey('PEM'))\n\n    # Save the encrypted private key to file\n    with open(filename, 'wb') as file:\n        [file.write(x) for x in (cipher.nonce, ciphertext, tag)]\n\n    # Return public key, filename, password and nonce\n    return pubkey, filename, password, cipher.nonce\n\n# Test the function\npubkey, filename, password, nonce = task_func()\n\n# Test by decrypting the private key from the file\nwith open(filename, 'rb') as file:\n    nonce, ciphertext, tag = [file.read(x) for x in (16, -1, 16)]\n    cipher = AES.new(password, AES.MODE_EAX, nonce=nonce)\n    private_key = cipher.decrypt_and_verify(ciphertext, tag)\n    private_key = rsa.key.importKey(private_key)\n\n# Print the public key and the decrypted private key"}
{"task_id": "BigCodeBench/584", "solution": "import rsa\nimport urllib.request\nfrom hashlib import sha256\ndef task_func(url):\n    try:\n        # Generate RSA public and private keys\n        (pubkey, privkey) = rsa.newkeys(512)\n\n        # Retrieve the content from the specified URL\n        response = urllib.request.urlopen(url)\n        content = response.read()\n\n        # Calculate the SHA256 hash of the content\n        content_hash = sha256(content).digest()\n\n        # Sign the hash with the private key\n        signature = rsa.sign_hash(content_hash, privkey, 'SHA-256')\n\n        # Convert the signature to a hexadecimal string\n        signature_hex = signature.hex()\n\n        return pubkey, signature_hex, content_hash\n\n    except urllib.error.URLError:\n        print(\"The server is not reachable\")\n        raise\n    except urllib.error.HTTPError as e:\n        print(\"HTTP Error: The server couldn't fulfill the request.\")\n        print(\"Error code: \", e.code)\n        raise\n    except rsa.pkcs1.VerificationError:\n        print(\"Failed to sign the hash with the RSA private key.\")\n        raise\nurl = \"http://example.com\"", "raw_solution": "import rsa\nimport urllib.request\nfrom hashlib import sha256\n\ndef task_func(url):\n    try:\n        # Generate RSA public and private keys\n        (pubkey, privkey) = rsa.newkeys(512)\n\n        # Retrieve the content from the specified URL\n        response = urllib.request.urlopen(url)\n        content = response.read()\n\n        # Calculate the SHA256 hash of the content\n        content_hash = sha256(content).digest()\n\n        # Sign the hash with the private key\n        signature = rsa.sign_hash(content_hash, privkey, 'SHA-256')\n\n        # Convert the signature to a hexadecimal string\n        signature_hex = signature.hex()\n\n        return pubkey, signature_hex, content_hash\n\n    except urllib.error.URLError:\n        print(\"The server is not reachable\")\n        raise\n    except urllib.error.HTTPError as e:\n        print(\"HTTP Error: The server couldn't fulfill the request.\")\n        print(\"Error code: \", e.code)\n        raise\n    except rsa.pkcs1.VerificationError:\n        print(\"Failed to sign the hash with the RSA private key.\")\n        raise\n\n# Test the function\nurl = \"http://example.com\"\ntry:\n    pubkey, signature, content_hash = task_func(url)\n    print(\"rsa.PublicKey: \", pubkey)\n    print(\"Signed SHA256 hash: \", signature)\n    print(\"Hashed URL content: \", content_hash)\nexcept Exception as e:\n    print(\"An error occurred: \", str(e))"}
{"task_id": "BigCodeBench/585", "solution": "import rsa\nimport os\nimport zipfile\nfrom base64 import b64encode\ndef task_func(directory):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Create a zip file\n    zip_filename = \"encrypted_files.zip\"\n    zipf = zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED)\n\n    # Iterate over all files in the directory\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # Read the file\n            with open(os.path.join(root, file), 'rb') as f:\n                file_data = f.read()\n\n            # Encrypt the file data with the public key\n            encrypted_data = rsa.encrypt(file_data, pubkey)\n\n            # Write the encrypted data to a new file in the zip\n            zipf.writestr(file, b64encode(encrypted_data).decode())\n\n    # Close the zip file\n    zipf.close()\n\n    # Return the public key and the filename of the zip file\n    return pubkey, zip_filename", "raw_solution": "import rsa\nimport os\nimport zipfile\nfrom base64 import b64encode\n\ndef task_func(directory):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Create a zip file\n    zip_filename = \"encrypted_files.zip\"\n    zipf = zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED)\n\n    # Iterate over all files in the directory\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # Read the file\n            with open(os.path.join(root, file), 'rb') as f:\n                file_data = f.read()\n\n            # Encrypt the file data with the public key\n            encrypted_data = rsa.encrypt(file_data, pubkey)\n\n            # Write the encrypted data to a new file in the zip\n            zipf.writestr(file, b64encode(encrypted_data).decode())\n\n    # Close the zip file\n    zipf.close()\n\n    # Return the public key and the filename of the zip file\n    return pubkey, zip_filename"}
{"task_id": "BigCodeBench/586", "solution": "import rsa\nfrom cryptography.fernet import Fernet\nfrom base64 import b64encode\nimport os\ndef task_func(file_path):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Read file content\n    with open(file_path, 'rb') as f:\n        file_content = f.read()\n\n    # Encrypt file content with Fernet\n    fernet_key = Fernet.generate_key()\n    cipher_suite = Fernet(fernet_key)\n    encrypted_file_content = cipher_suite.encrypt(file_content)\n\n    # Encrypt Fernet key with RSA\n    encrypted_fernet_key = rsa.encrypt(fernet_key, pubkey)\n\n    # Save encrypted file content and encrypted Fernet key\n    encrypted_file_path = 'encrypted_' + file_path\n    encrypted_key_path = 'encrypted_key_' + file_path\n\n    with open(encrypted_file_path, 'wb') as f:\n        f.write(encrypted_file_content)\n\n    with open(encrypted_key_path, 'wb') as f:\n        f.write(b64encode(encrypted_fernet_key))\n\n    return pubkey, encrypted_file_path, encrypted_key_path", "raw_solution": "import rsa\nfrom cryptography.fernet import Fernet\nfrom base64 import b64encode\nimport os\n\ndef task_func(file_path):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Read file content\n    with open(file_path, 'rb') as f:\n        file_content = f.read()\n\n    # Encrypt file content with Fernet\n    fernet_key = Fernet.generate_key()\n    cipher_suite = Fernet(fernet_key)\n    encrypted_file_content = cipher_suite.encrypt(file_content)\n\n    # Encrypt Fernet key with RSA\n    encrypted_fernet_key = rsa.encrypt(fernet_key, pubkey)\n\n    # Save encrypted file content and encrypted Fernet key\n    encrypted_file_path = 'encrypted_' + file_path\n    encrypted_key_path = 'encrypted_key_' + file_path\n\n    with open(encrypted_file_path, 'wb') as f:\n        f.write(encrypted_file_content)\n\n    with open(encrypted_key_path, 'wb') as f:\n        f.write(b64encode(encrypted_fernet_key))\n\n    return pubkey, encrypted_file_path, encrypted_key_path\n\n# Test the function\npubkey, encrypted_file_path, encrypted_key_path = task_func('test.txt')"}
{"task_id": "BigCodeBench/587", "solution": "import rsa\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\nfrom base64 import b64encode\ndef task_func(file_path):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Read file content\n    with open(file_path, 'rb') as f:\n        file_data = f.read()\n\n    # Generate AES key\n    aes_key = os.urandom(32)\n\n    # Encrypt file with AES\n    cipher = Cipher(algorithms.AES(aes_key), modes.ECB())\n    encryptor = cipher.encryptor()\n    padded_data = encryptor.update(file_data) + encryptor.finalize()\n\n    # Encrypt AES key with RSA\n    encrypted_aes_key = rsa.encrypt(aes_key, pubkey)\n\n    # Save encrypted file and encrypted AES key\n    encrypted_file_path = 'encrypted_file.bin'\n    encrypted_aes_key_path = 'encrypted_aes_key.bin'\n    with open(encrypted_file_path, 'wb') as f:\n        f.write(padded_data)\n    with open(encrypted_aes_key_path, 'wb') as f:\n        f.write(encrypted_aes_key)\n\n    return pubkey, encrypted_file_path, encrypted_aes_key_path", "raw_solution": "import rsa\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\nfrom base64 import b64encode\n\ndef task_func(file_path):\n    # Generate RSA keys\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Read file content\n    with open(file_path, 'rb') as f:\n        file_data = f.read()\n\n    # Generate AES key\n    aes_key = os.urandom(32)\n\n    # Encrypt file with AES\n    cipher = Cipher(algorithms.AES(aes_key), modes.ECB())\n    encryptor = cipher.encryptor()\n    padded_data = encryptor.update(file_data) + encryptor.finalize()\n\n    # Encrypt AES key with RSA\n    encrypted_aes_key = rsa.encrypt(aes_key, pubkey)\n\n    # Save encrypted file and encrypted AES key\n    encrypted_file_path = 'encrypted_file.bin'\n    encrypted_aes_key_path = 'encrypted_aes_key.bin'\n    with open(encrypted_file_path, 'wb') as f:\n        f.write(padded_data)\n    with open(encrypted_aes_key_path, 'wb') as f:\n        f.write(encrypted_aes_key)\n\n    return pubkey, encrypted_file_path, encrypted_aes_key_path"}
{"task_id": "BigCodeBench/588", "solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nRANGE = 100\nSIZE = 1000\ndef task_func():\n    # Generate a DataFrame with 'X' and 'Y' columns filled with random integers within the specified range\n    df = pd.DataFrame({\n        'X': np.random.randint(0, RANGE, SIZE),\n        'Y': np.random.randint(0, RANGE, SIZE)\n    })\n\n    # Plot the points using a scatter plot\n    sns.scatterplot(x='X', y='Y', data=df)\n    plt.show()\n\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Constants defining the range of random integers and the size of the DataFrame\nRANGE = 100\nSIZE = 1000\n\ndef task_func():\n    # Generate a DataFrame with 'X' and 'Y' columns filled with random integers within the specified range\n    df = pd.DataFrame({\n        'X': np.random.randint(0, RANGE, SIZE),\n        'Y': np.random.randint(0, RANGE, SIZE)\n    })\n\n    # Plot the points using a scatter plot\n    sns.scatterplot(x='X', y='Y', data=df)\n    plt.show()\n\n    return df\n\n# Test the function\ndf = task_func()"}
{"task_id": "BigCodeBench/589", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.cluster import KMeans\nRANGE = 100\nSIZE = 1000\nCLUSTERS = 5\ndef task_func():\n    # Generate a set of 2D random points within a specified range and size\n    data = np.random.rand(SIZE, 2) * RANGE\n\n    # Apply KMeans clustering to these points\n    kmeans = KMeans(n_clusters=CLUSTERS, random_state=0).fit(data)\n\n    # Plot the results with cluster centroids\n    plt.scatter(data[:, 0], data[:, 1], c=kmeans.labels_)\n    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n    plt.show()\n\n    return data, kmeans", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\n# Constants for configuration\nRANGE = 100\nSIZE = 1000\nCLUSTERS = 5\n\ndef task_func():\n    # Generate a set of 2D random points within a specified range and size\n    data = np.random.rand(SIZE, 2) * RANGE\n\n    # Apply KMeans clustering to these points\n    kmeans = KMeans(n_clusters=CLUSTERS, random_state=0).fit(data)\n\n    # Plot the results with cluster centroids\n    plt.scatter(data[:, 0], data[:, 1], c=kmeans.labels_)\n    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n    plt.show()\n\n    return data, kmeans\n\n# Test the function\ndata, kmeans = task_func()"}
{"task_id": "BigCodeBench/590", "solution": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\ndef task_func(url):\n    if not url:\n        raise ValueError(\"URL is invalid or empty\")\n\n    try:\n        response = urllib.request.urlopen(url)\n    except urllib.error.URLError as e:\n        raise urllib.error.URLError(\"Network connectivity or server issue\") from e\n\n    html = response.read().decode('utf-8')\n    d = pq(html)\n\n    data = []\n    for tag in d('a'):\n        text = tag.text\n        href = tag.attrib['href']\n        data.append((text, href))\n\n    df = pd.DataFrame(data, columns=['text', 'href'])\n    df['fetch_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n    return df", "raw_solution": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\n\ndef task_func(url):\n    if not url:\n        raise ValueError(\"URL is invalid or empty\")\n\n    try:\n        response = urllib.request.urlopen(url)\n    except urllib.error.URLError as e:\n        raise urllib.error.URLError(\"Network connectivity or server issue\") from e\n\n    html = response.read().decode('utf-8')\n    d = pq(html)\n\n    data = []\n    for tag in d('a'):\n        text = tag.text\n        href = tag.attrib['href']\n        data.append((text, href))\n\n    df = pd.DataFrame(data, columns=['text', 'href'])\n    df['fetch_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n    return df"}
{"task_id": "BigCodeBench/591", "solution": "from datetime import datetime, timedelta\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as panda\nTEMP_CATEGORIES = ['Cold', 'Normal', 'Hot']\nFILE_PATH = 'custom_data.csv'\ndef task_func(hours, file_path=FILE_PATH):\n    data = {'Time': [], 'Temperature': [], 'Category': []}\n    for i in range(hours):\n        current_time = datetime.now() + timedelta(hours=i)\n        temperature = randint(0, 100)\n        category = TEMP_CATEGORIES[0] if temperature < 30 else TEMP_CATEGORIES[1] if temperature < 60 else TEMP_CATEGORIES[2]\n        data['Time'].append(current_time)\n        data['Temperature'].append(temperature)\n        data['Category'].append(category)\n\n    df = panda.DataFrame(data)\n    df.to_csv(file_path, index=False)\n\n    fig, ax = plt.subplots()\n    ax.plot(df['Time'], df['Temperature'], color='blue')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Temperature')\n    ax.set_title('Temperature over Time')\n\n    return file_path, ax", "raw_solution": "from datetime import datetime, timedelta\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as panda\n\nTEMP_CATEGORIES = ['Cold', 'Normal', 'Hot']\nFILE_PATH = 'custom_data.csv'\n\ndef task_func(hours, file_path=FILE_PATH):\n    data = {'Time': [], 'Temperature': [], 'Category': []}\n    for i in range(hours):\n        current_time = datetime.now() + timedelta(hours=i)\n        temperature = randint(0, 100)\n        category = TEMP_CATEGORIES[0] if temperature < 30 else TEMP_CATEGORIES[1] if temperature < 60 else TEMP_CATEGORIES[2]\n        data['Time'].append(current_time)\n        data['Temperature'].append(temperature)\n        data['Category'].append(category)\n\n    df = panda.DataFrame(data)\n    df.to_csv(file_path, index=False)\n\n    fig, ax = plt.subplots()\n    ax.plot(df['Time'], df['Temperature'], color='blue')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Temperature')\n    ax.set_title('Temperature over Time')\n\n    return file_path, ax\n\n# Test the function\nfile_path, ax = task_func(24)"}
{"task_id": "BigCodeBench/592", "solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    filename = os.path.join(output_dir, 'sensor_data.csv')\n\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Time', 'Temperature', 'Humidity', 'Pressure'])\n\n        start_time = datetime.now()\n        for _ in range(hours):\n            for _ in range(60):  # 60 minutes in an hour\n                time = (start_time + timedelta(minutes=1)).strftime('%Y-%m-%d %H:%M:%S')\n                data = [time] + [randint(0, 100) for _ in SENSORS]\n                writer.writerow(data)\n                start_time += timedelta(minutes=1)", "raw_solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\n\n# Constants\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    filename = os.path.join(output_dir, 'sensor_data.csv')\n\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Time', 'Temperature', 'Humidity', 'Pressure'])\n\n        start_time = datetime.now()\n        for _ in range(hours):\n            for _ in range(60):  # 60 minutes in an hour\n                time = (start_time + timedelta(minutes=1)).strftime('%Y-%m-%d %H:%M:%S')\n                data = [time] + [randint(0, 100) for _ in SENSORS]\n                writer.writerow(data)\n                start_time += timedelta(minutes=1)\n\n# Test the function\ntask_func(2)"}
{"task_id": "BigCodeBench/593", "solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Generate traffic data\n    traffic_data = []\n    current_time = datetime.now()\n    for i in range(hours):\n        traffic_counts = {vehicle_type: randint(0, 100) for vehicle_type in VEHICLE_TYPES}\n        traffic_data.append({'Time': current_time, **traffic_counts})\n        current_time += timedelta(hours=1)\n\n    # Save data to CSV file\n    csv_file_path = os.path.join(output_dir, 'traffic_data.csv')\n    with open(csv_file_path, 'w', newline='') as csvfile:\n        fieldnames = ['Time'] + VEHICLE_TYPES\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n        writer.writeheader()\n        for data in traffic_data:\n            writer.writerow(data)\n\n    # Load data from CSV file into pandas DataFrame\n    df = pd.read_csv(csv_file_path)\n    df['Time'] = pd.to_datetime(df['Time'])\n\n    # Plot data\n    plt.figure(figsize=(10, 6))\n    for vehicle_type in VEHICLE_TYPES:\n        plt.plot(df['Time'], df[vehicle_type], label=vehicle_type)\n    plt.xlabel('Time')\n    plt.ylabel('Vehicle Count')\n    plt.title('Traffic Data Over Time')\n    plt.legend()\n    plt.grid(True)\n\n    return csv_file_path, plt.gca()", "raw_solution": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Generate traffic data\n    traffic_data = []\n    current_time = datetime.now()\n    for i in range(hours):\n        traffic_counts = {vehicle_type: randint(0, 100) for vehicle_type in VEHICLE_TYPES}\n        traffic_data.append({'Time': current_time, **traffic_counts})\n        current_time += timedelta(hours=1)\n\n    # Save data to CSV file\n    csv_file_path = os.path.join(output_dir, 'traffic_data.csv')\n    with open(csv_file_path, 'w', newline='') as csvfile:\n        fieldnames = ['Time'] + VEHICLE_TYPES\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n        writer.writeheader()\n        for data in traffic_data:\n            writer.writerow(data)\n\n    # Load data from CSV file into pandas DataFrame\n    df = pd.read_csv(csv_file_path)\n    df['Time'] = pd.to_datetime(df['Time'])\n\n    # Plot data\n    plt.figure(figsize=(10, 6))\n    for vehicle_type in VEHICLE_TYPES:\n        plt.plot(df['Time'], df[vehicle_type], label=vehicle_type)\n    plt.xlabel('Time')\n    plt.ylabel('Vehicle Count')\n    plt.title('Traffic Data Over Time')\n    plt.legend()\n    plt.grid(True)\n\n    return csv_file_path, plt.gca()\n\n# Test the function\ncsv_file_path, ax = task_func(10)"}
{"task_id": "BigCodeBench/594", "solution": "import csv\nimport os\nimport shutil\nfrom datetime import datetime, timedelta\nfrom random import randint\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\nBACKUP_DIR = './backup'\ndef task_func(hours, output_dir=OUTPUT_DIR, backup_dir=BACKUP_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Create backup directory if it doesn't exist\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n\n    # Generate weather data\n    weather_data = []\n    start_time = datetime.now()\n    for i in range(hours):\n        time = (start_time + timedelta(hours=i)).strftime(\"%Y-%m-%d %H:%M:%S\")\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS)-1)]\n        weather_data.append([time, condition])\n\n    # Save weather data to CSV file\n    csv_file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(csv_file_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Time', 'Condition'])\n        writer.writerows(weather_data)\n\n    # Backup the CSV file to the backup directory\n    backup_file_path = os.path.join(backup_dir, 'weather_data.csv')\n    shutil.copyfile(csv_file_path, backup_file_path)\n\n    return csv_file_path", "raw_solution": "import csv\nimport os\nimport shutil\nfrom datetime import datetime, timedelta\nfrom random import randint\n\n# Constants\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\nBACKUP_DIR = './backup'\n\ndef task_func(hours, output_dir=OUTPUT_DIR, backup_dir=BACKUP_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Create backup directory if it doesn't exist\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n\n    # Generate weather data\n    weather_data = []\n    start_time = datetime.now()\n    for i in range(hours):\n        time = (start_time + timedelta(hours=i)).strftime(\"%Y-%m-%d %H:%M:%S\")\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS)-1)]\n        weather_data.append([time, condition])\n\n    # Save weather data to CSV file\n    csv_file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(csv_file_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Time', 'Condition'])\n        writer.writerows(weather_data)\n\n    # Backup the CSV file to the backup directory\n    backup_file_path = os.path.join(backup_dir, 'weather_data.csv')\n    shutil.copyfile(csv_file_path, backup_file_path)\n\n    return csv_file_path"}
{"task_id": "BigCodeBench/595", "solution": "import random\nimport bisect\nfrom array import array\ndef task_func(n=10, total=100):\n    while True:\n        # Generate 'n' random integers\n        numbers = [random.randint(1, total) for _ in range(n-1)]\n        # The remaining number is calculated to make the sum equal to 'total'\n        remaining = total - sum(numbers)\n        # If the remaining number is less than 0, we retry\n        if remaining < 0:\n            continue\n        # If the remaining number is greater than 0, we append it to the list\n        numbers.append(remaining)\n        # Sort the list\n        numbers.sort()\n        # Find the insertion position for the remaining number\n        pos = bisect.bisect(numbers, remaining)\n        return (numbers, pos)", "raw_solution": "import random\nimport bisect\nfrom array import array\n\ndef task_func(n=10, total=100):\n    while True:\n        # Generate 'n' random integers\n        numbers = [random.randint(1, total) for _ in range(n-1)]\n        # The remaining number is calculated to make the sum equal to 'total'\n        remaining = total - sum(numbers)\n        # If the remaining number is less than 0, we retry\n        if remaining < 0:\n            continue\n        # If the remaining number is greater than 0, we append it to the list\n        numbers.append(remaining)\n        # Sort the list\n        numbers.sort()\n        # Find the insertion position for the remaining number\n        pos = bisect.bisect(numbers, remaining)\n        return (numbers, pos)\n\n# Test the function"}
{"task_id": "BigCodeBench/596", "solution": "import time\nfrom datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\ndef task_func(duration):\n    start_time = time.time()\n    timestamps = []\n    values = []\n\n    while time.time() - start_time < duration:\n        now = datetime.now()\n        current_time = now.strftime(\"%H:%M:%S.%f\")\n        timestamps.append(current_time)\n        values.append(randint(1, 100))\n        time.sleep(0.1)  # sleep for 0.1 seconds to simulate real-time data generation\n\n    return (timestamps, values)", "raw_solution": "import time\nfrom datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\n\ndef task_func(duration):\n    start_time = time.time()\n    timestamps = []\n    values = []\n\n    while time.time() - start_time < duration:\n        now = datetime.now()\n        current_time = now.strftime(\"%H:%M:%S.%f\")\n        timestamps.append(current_time)\n        values.append(randint(1, 100))\n        time.sleep(0.1)  # sleep for 0.1 seconds to simulate real-time data generation\n\n    return (timestamps, values)\n\n# Test the function\ntimestamps, values = task_func(5)\n\n# Plot the data\nplt.plot(timestamps, values)\nplt.xlabel('Time')\nplt.ylabel('Value')\nplt.show()"}
{"task_id": "BigCodeBench/597", "solution": "import pandas as pd\nimport time\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\ndef task_func(data, letter):\n    if letter.lower() not in LETTERS:\n        raise ValueError(\"Letter must be a lowercase letter from the English alphabet.\")\n\n    df = pd.DataFrame(data)\n    filtered_df = df[df['Name'].str.lower().str.startswith(letter.lower())]\n\n    return filtered_df['Name']\ndata = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Helen', 'Igor', 'John']}", "raw_solution": "import pandas as pd\nimport time\n\n# Constants\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\n\ndef task_func(data, letter):\n    if letter.lower() not in LETTERS:\n        raise ValueError(\"Letter must be a lowercase letter from the English alphabet.\")\n\n    df = pd.DataFrame(data)\n    filtered_df = df[df['Name'].str.lower().str.startswith(letter.lower())]\n\n    return filtered_df['Name']\n\n# Test the function\ndata = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Helen', 'Igor', 'John']}"}
{"task_id": "BigCodeBench/598", "solution": "import pandas as pd\ndef task_func(df, letter):\n    # Filter rows where the 'Word' column starts with the specified letter\n    filtered_df = df[df['Word'].str.startswith(letter)]\n\n    # Calculate the length of the words in the filtered column\n    word_lengths = filtered_df['Word'].str.len()\n\n    # Return a dictionary of word lengths and their counts\n    return word_lengths.value_counts().to_dict()\ndata = {'Word': ['apple', 'banana', 'cherry', 'date', 'apple', 'banana', 'cherry', 'date', 'apple']}\ndf = pd.DataFrame(data)", "raw_solution": "import pandas as pd\n\ndef task_func(df, letter):\n    # Filter rows where the 'Word' column starts with the specified letter\n    filtered_df = df[df['Word'].str.startswith(letter)]\n\n    # Calculate the length of the words in the filtered column\n    word_lengths = filtered_df['Word'].str.len()\n\n    # Return a dictionary of word lengths and their counts\n    return word_lengths.value_counts().to_dict()\n\n# Test the function\ndata = {'Word': ['apple', 'banana', 'cherry', 'date', 'apple', 'banana', 'cherry', 'date', 'apple']}\ndf = pd.DataFrame(data)"}
{"task_id": "BigCodeBench/599", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, letter):\n    # Filter rows where 'Word' column values start with the specified letter\n    filtered_df = df[df['Word'].str.startswith(letter)]\n    \n    # Calculate the lengths of these words\n    filtered_df['Word_Length'] = filtered_df['Word'].str.len()\n    \n    # Plot a histogram of the word lengths\n    plt.hist(filtered_df['Word_Length'], bins='auto')\n    plt.title(f\"Histogram of word lengths for words starting with '{letter}'\")\n    plt.xlabel(\"Word Length\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\ndf = pd.DataFrame({'Word': ['apple', 'banana', 'cherry', 'date', 'grape', 'melon', 'peach', 'pear', 'plum', 'pineapple']})", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, letter):\n    # Filter rows where 'Word' column values start with the specified letter\n    filtered_df = df[df['Word'].str.startswith(letter)]\n    \n    # Calculate the lengths of these words\n    filtered_df['Word_Length'] = filtered_df['Word'].str.len()\n    \n    # Plot a histogram of the word lengths\n    plt.hist(filtered_df['Word_Length'], bins='auto')\n    plt.title(f\"Histogram of word lengths for words starting with '{letter}'\")\n    plt.xlabel(\"Word Length\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n\n# Test the function\ndf = pd.DataFrame({'Word': ['apple', 'banana', 'cherry', 'date', 'grape', 'melon', 'peach', 'pear', 'plum', 'pineapple']})\ntask_func(df, 'p')"}
{"task_id": "BigCodeBench/600", "solution": "import numpy as np\nimport pandas as pd\nfrom scipy import stats\ndef task_func(df, letter):\n    # Filter rows where 'Word' column values start with the specified letter\n    filtered_df = df[df['Word'].str.startswith(letter)]\n    \n    # Calculate the lengths of the words\n    filtered_df['Word_Length'] = filtered_df['Word'].str.len()\n    \n    # Calculate mean, median, and mode of the word lengths\n    mean_length = filtered_df['Word_Length'].mean()\n    median_length = filtered_df['Word_Length'].median()\n    mode_length = filtered_df['Word_Length'].mode()[0] if filtered_df['Word_Length'].mode().empty == False else None\n    \n    # Return the results in a dictionary\n    return {'Mean': mean_length, 'Median': median_length, 'Mode': mode_length}\ndf = pd.DataFrame({'Word': ['apple', 'banana', 'cherry', 'date', 'grape']})", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndef task_func(df, letter):\n    # Filter rows where 'Word' column values start with the specified letter\n    filtered_df = df[df['Word'].str.startswith(letter)]\n    \n    # Calculate the lengths of the words\n    filtered_df['Word_Length'] = filtered_df['Word'].str.len()\n    \n    # Calculate mean, median, and mode of the word lengths\n    mean_length = filtered_df['Word_Length'].mean()\n    median_length = filtered_df['Word_Length'].median()\n    mode_length = filtered_df['Word_Length'].mode()[0] if filtered_df['Word_Length'].mode().empty == False else None\n    \n    # Return the results in a dictionary\n    return {'Mean': mean_length, 'Median': median_length, 'Mode': mode_length}\n\n# Test the function\ndf = pd.DataFrame({'Word': ['apple', 'banana', 'cherry', 'date', 'grape']})"}
{"task_id": "BigCodeBench/601", "solution": "import seaborn as sns\nimport pandas as pd\ndef task_func(df, letter):\n    if 'Word' not in df.columns or df.empty:\n        return None\n\n    # Filter rows based on the starting letter\n    filtered_df = df[df['Word'].str.startswith(letter)]\n\n    # Calculate the lengths of the words\n    filtered_df['Word_Length'] = filtered_df['Word'].str.len()\n\n    # Plot the box plot\n    ax = sns.boxplot(x='Word_Length', data=filtered_df)\n\n    return ax", "raw_solution": "import seaborn as sns\nimport pandas as pd\n\ndef task_func(df, letter):\n    if 'Word' not in df.columns or df.empty:\n        return None\n\n    # Filter rows based on the starting letter\n    filtered_df = df[df['Word'].str.startswith(letter)]\n\n    # Calculate the lengths of the words\n    filtered_df['Word_Length'] = filtered_df['Word'].str.len()\n\n    # Plot the box plot\n    ax = sns.boxplot(x='Word_Length', data=filtered_df)\n\n    return ax"}
{"task_id": "BigCodeBench/602", "solution": "import numpy as np\nimport pandas as pd\nimport os\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\nOUTPUT_DIR = './output'\ndef task_func(file_path, output_dir=OUTPUT_DIR):\n    # Generate a 2D matrix with random lowercase letters\n    matrix = np.random.choice(LETTERS, size=(5,5))\n\n    # Convert the matrix to a DataFrame\n    df = pd.DataFrame(matrix)\n\n    # Write the DataFrame to a CSV file\n    df.to_csv(os.path.join(output_dir, file_path), index=False)", "raw_solution": "import numpy as np\nimport pandas as pd\nimport os\n\n# Constants\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\nOUTPUT_DIR = './output'\n\ndef task_func(file_path, output_dir=OUTPUT_DIR):\n    # Generate a 2D matrix with random lowercase letters\n    matrix = np.random.choice(LETTERS, size=(5,5))\n\n    # Convert the matrix to a DataFrame\n    df = pd.DataFrame(matrix)\n\n    # Write the DataFrame to a CSV file\n    df.to_csv(os.path.join(output_dir, file_path), index=False)\n\n# Test the function\ntask_func('test.csv')"}
{"task_id": "BigCodeBench/603", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(matrix1, matrix2):\n    # Connects two 2D numeric arrays along the second axis (columns)\n    result = np.concatenate((matrix1, matrix2), axis=1)\n    \n    # Converts the result into a Pandas DataFrame\n    df = pd.DataFrame(result)\n    \n    # Returns a string representation of the DataFrame without the index and header\n    return df.to_string(header=False, index=False)\nmatrix1 = np.array([[1, 2, 3], [4, 5, 6]])\nmatrix2 = np.array([[7, 8, 9], [10, 11, 12]])", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(matrix1, matrix2):\n    # Connects two 2D numeric arrays along the second axis (columns)\n    result = np.concatenate((matrix1, matrix2), axis=1)\n    \n    # Converts the result into a Pandas DataFrame\n    df = pd.DataFrame(result)\n    \n    # Returns a string representation of the DataFrame without the index and header\n    return df.to_string(header=False, index=False)\n\n# Testing the function\nmatrix1 = np.array([[1, 2, 3], [4, 5, 6]])\nmatrix2 = np.array([[7, 8, 9], [10, 11, 12]])\n"}
{"task_id": "BigCodeBench/604", "solution": "import subprocess\nimport logging\nimport os\ndef task_func(filepath):\n    try:\n        if not os.path.exists(filepath):\n            raise FileNotFoundError(f\"The file {filepath} does not exist.\")\n        \n        # Assuming g++ is the C++ compiler\n        # Adjust as needed for your specific environment\n        subprocess.run(['g++', filepath, '-o', 'output'], check=True, stderr=subprocess.PIPE)\n        \n        logging.info(f\"Successfully compiled the file {filepath}.\")\n        \n    except subprocess.CalledProcessError as e:\n        logging.error(f\"Compilation of the file {filepath} failed with error: {str(e)}\")\n        raise\n    except FileNotFoundError as e:\n        logging.error(str(e))\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {str(e)}\")\n        raise", "raw_solution": "import subprocess\nimport logging\nimport os\n\ndef task_func(filepath):\n    try:\n        if not os.path.exists(filepath):\n            raise FileNotFoundError(f\"The file {filepath} does not exist.\")\n        \n        # Assuming g++ is the C++ compiler\n        # Adjust as needed for your specific environment\n        subprocess.run(['g++', filepath, '-o', 'output'], check=True, stderr=subprocess.PIPE)\n        \n        logging.info(f\"Successfully compiled the file {filepath}.\")\n        \n    except subprocess.CalledProcessError as e:\n        logging.error(f\"Compilation of the file {filepath} failed with error: {str(e)}\")\n        raise\n    except FileNotFoundError as e:\n        logging.error(str(e))\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {str(e)}\")\n        raise"}
{"task_id": "BigCodeBench/605", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(matrix):\n    # Convert the matrix to a DataFrame\n    df = pd.DataFrame(matrix)\n\n    # Create a new figure and an axes\n    fig, ax = plt.subplots()\n\n    # Create the heatmap\n    heatmap = ax.pcolor(df, cmap='hot', edgecolors='k')\n\n    # Return the axes object\n    return ax\nmatrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(matrix):\n    # Convert the matrix to a DataFrame\n    df = pd.DataFrame(matrix)\n\n    # Create a new figure and an axes\n    fig, ax = plt.subplots()\n\n    # Create the heatmap\n    heatmap = ax.pcolor(df, cmap='hot', edgecolors='k')\n\n    # Return the axes object\n    return ax\n\n# Test the function\nmatrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nax = task_func(matrix)\nplt.show()"}
{"task_id": "BigCodeBench/606", "solution": "import pandas as pd\nfrom scipy import stats\ndef task_func(matrix):\n    df = pd.DataFrame(matrix)\n    df_norm = (df - df.mean()) / df.std()\n    return df_norm\nmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]", "raw_solution": "import pandas as pd\nfrom scipy import stats\n\ndef task_func(matrix):\n    df = pd.DataFrame(matrix)\n    df_norm = (df - df.mean()) / df.std()\n    return df_norm\n\n# Test the function\nmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]"}
{"task_id": "BigCodeBench/607", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import sample\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows based on column values\n    for col, val in tuples:\n        df = df[df[col] != val]\n\n    # Generate random scatter plots\n    axes = []\n    for _ in range(n_plots):\n        # Select random columns\n        cols = sample(COLUMNS, 2)\n        # Create scatter plot\n        ax = df.plot(kind='scatter', x=cols[0], y=cols[1], alpha=0.5)\n        axes.append(ax)\n\n    return df, axes", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import sample\n\n# Constants for column names to use in plots\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows based on column values\n    for col, val in tuples:\n        df = df[df[col] != val]\n\n    # Generate random scatter plots\n    axes = []\n    for _ in range(n_plots):\n        # Select random columns\n        cols = sample(COLUMNS, 2)\n        # Create scatter plot\n        ax = df.plot(kind='scatter', x=cols[0], y=cols[1], alpha=0.5)\n        axes.append(ax)\n\n    return df, axes"}
{"task_id": "BigCodeBench/608", "solution": "import seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import sample\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    for col, val in tuples:\n        if col in df.columns:\n            df = df[df[col] != val]\n\n    # Generate pairplots\n    pairplot_axes = []\n    for _ in range(n_plots):\n        pairplot = sns.pairplot(df, vars=sample(COLUMNS, 2))\n        pairplot_axes.append(pairplot)\n\n    return df, pairplot_axes\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500],\n    'D': [1000, 2000, 3000, 4000, 5000],\n    'E': [10000, 20000, 30000, 40000, 50000]\n})\ntuples = [('A', 1), ('B', 20)]\nn_plots = 2", "raw_solution": "import seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import sample\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    for col, val in tuples:\n        if col in df.columns:\n            df = df[df[col] != val]\n\n    # Generate pairplots\n    pairplot_axes = []\n    for _ in range(n_plots):\n        pairplot = sns.pairplot(df, vars=sample(COLUMNS, 2))\n        pairplot_axes.append(pairplot)\n\n    return df, pairplot_axes\n\n# Test the function\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500],\n    'D': [1000, 2000, 3000, 4000, 5000],\n    'E': [10000, 20000, 30000, 40000, 50000]\n})\n\ntuples = [('A', 1), ('B', 20)]\nn_plots = 2\n\ndf, pairplot_axes = task_func(df, tuples, n_plots)"}
{"task_id": "BigCodeBench/609", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations\nfrom random import sample", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations\nfrom random import sample\n\ndef task_func(df, tuples, n_plots):\n    # Remove rows from DataFrame based on a list of tuples\n    df = df.drop(df[list(zip(*tuples))].min(axis=1)[df[list(zip(*tuples))].min(axis=1) != ].index)\n\n    # Generate up to 'n_plots' scatter plots for random combinations of two columns from the remaining DataFrame\n    plot_list = []\n    for cols in sample(list(combinations(df.columns, 2)), min(n_plots, len(list(combinations(df.columns, 2))))):\n        plot = df.plot.scatter(x=cols[0], y=cols[1])\n        plot_list.append((cols, plot))\n\n    return df, plot_list"}
{"task_id": "BigCodeBench/610", "solution": "from random import sample\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows based on values of multiple columns\n    for tup in tuples:\n        df = df[~df[tup[0]].between(tup[1], tup[2])]\n\n    # Create n random joint plots of two columns against each other\n    joint_plots = []\n    if not df.empty:\n        for _ in range(n_plots):\n            cols = sample(COLUMNS, 2)\n            joint_grid = sns.jointplot(df[cols[0]], df[cols[1]])\n            joint_plots.append(joint_grid)\n\n    return df, joint_plots", "raw_solution": "from random import sample\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows based on values of multiple columns\n    for tup in tuples:\n        df = df[~df[tup[0]].between(tup[1], tup[2])]\n\n    # Create n random joint plots of two columns against each other\n    joint_plots = []\n    if not df.empty:\n        for _ in range(n_plots):\n            cols = sample(COLUMNS, 2)\n            joint_grid = sns.jointplot(df[cols[0]], df[cols[1]])\n            joint_plots.append(joint_grid)\n\n    return df, joint_plots"}
{"task_id": "BigCodeBench/611", "solution": "from random import sample\nimport matplotlib.pyplot as plt\nimport pandas as pd\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    for col, val in tuples:\n        df = df[df[col] != val]\n\n    # Create n random line plots of two columns against each other\n    plot_details = []\n    for _ in range(n_plots):\n        cols = sample(COLUMNS, 2)\n        plot_details.append(tuple(cols))\n        df.plot(x=cols[0], y=cols[1], kind='line')\n        plt.show()\n\n    return df, plot_details\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500],\n    'D': [1000, 2000, 3000, 4000, 5000],\n    'E': [10000, 20000, 30000, 40000, 50000]\n})\ntuples = [('A', 1), ('B', 20)]\nn_plots = 3", "raw_solution": "from random import sample\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    for col, val in tuples:\n        df = df[df[col] != val]\n\n    # Create n random line plots of two columns against each other\n    plot_details = []\n    for _ in range(n_plots):\n        cols = sample(COLUMNS, 2)\n        plot_details.append(tuple(cols))\n        df.plot(x=cols[0], y=cols[1], kind='line')\n        plt.show()\n\n    return df, plot_details\n\n# Test the function\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500],\n    'D': [1000, 2000, 3000, 4000, 5000],\n    'E': [10000, 20000, 30000, 40000, 50000]\n})\n\ntuples = [('A', 1), ('B', 20)]\nn_plots = 3\n\ndf, plot_details = task_func(df, tuples, n_plots)"}
{"task_id": "BigCodeBench/612", "solution": "from random import choice\nimport numpy as np\nimport pandas as pd\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTIES_COSTS = [100, 200, 300, 400, 500]\ndef task_func(goals, penalties, teams=TEAMS, penalties_costs=PENALTIES_COSTS):\n    # Create a DataFrame from the input data\n    df = pd.DataFrame({\n        'Team': teams,\n        'Goals': goals,\n        'Penalties': penalties\n    })\n\n    # Calculate 'Penalties Cost' and 'Performance Score'\n    df['Penalties Cost'] = df['Penalties'].apply(lambda x: choice(penalties_costs) * x)\n    df['Performance Score'] = df['Goals'] - df['Penalties']\n\n    # Ensure 'Performance Score' is non-negative\n    df['Performance Score'] = df['Performance Score'].apply(lambda x: x if x > 0 else 0)\n\n    return df\ngoals = [2, 3, 1, 4, 2]\npenalties = [1, 2, 1, 1, 3]", "raw_solution": "from random import choice\nimport numpy as np\nimport pandas as pd\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTIES_COSTS = [100, 200, 300, 400, 500]\n\ndef task_func(goals, penalties, teams=TEAMS, penalties_costs=PENALTIES_COSTS):\n    # Create a DataFrame from the input data\n    df = pd.DataFrame({\n        'Team': teams,\n        'Goals': goals,\n        'Penalties': penalties\n    })\n\n    # Calculate 'Penalties Cost' and 'Performance Score'\n    df['Penalties Cost'] = df['Penalties'].apply(lambda x: choice(penalties_costs) * x)\n    df['Performance Score'] = df['Goals'] - df['Penalties']\n\n    # Ensure 'Performance Score' is non-negative\n    df['Performance Score'] = df['Performance Score'].apply(lambda x: x if x > 0 else 0)\n\n    return df\n\n# Test the function\ngoals = [2, 3, 1, 4, 2]\npenalties = [1, 2, 1, 1, 3]"}
{"task_id": "BigCodeBench/613", "solution": "import pandas as pd\nfrom matplotlib import pyplot as plt\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nGOALS_RANGE = (-10, 10)\ndef task_func(goals, penalties):\n    # Check if the inputs are valid\n    assert len(goals) == len(penalties) == len(TEAMS), \"Inputs must be of the same length\"\n    assert all(g >= GOALS_RANGE[0] and g <= GOALS_RANGE[1] for g in goals), f\"Goals must be in the range {GOALS_RANGE}\"\n    assert all(p >= 0 for p in penalties), \"Penalties must be non-negative\"\n\n    # Calculate net scores\n    scores = [g - p for g, p in zip(goals, penalties)]\n\n    # Clip scores to stay within -10 to 10\n    scores = [max(min(s, 10), -10) for s in scores]\n\n    # Create a DataFrame\n    df = pd.DataFrame({'Team': TEAMS, 'Score': scores})\n\n    # Visualize results\n    df.plot(x='Team', y='Score', kind='bar', legend=False)\n    plt.xlabel('Team')\n    plt.ylabel('Score')\n    plt.title('Net Scores for Teams')\n    plt.show()\n\n    return df", "raw_solution": "import pandas as pd\nfrom matplotlib import pyplot as plt\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nGOALS_RANGE = (-10, 10)\n\ndef task_func(goals, penalties):\n    # Check if the inputs are valid\n    assert len(goals) == len(penalties) == len(TEAMS), \"Inputs must be of the same length\"\n    assert all(g >= GOALS_RANGE[0] and g <= GOALS_RANGE[1] for g in goals), f\"Goals must be in the range {GOALS_RANGE}\"\n    assert all(p >= 0 for p in penalties), \"Penalties must be non-negative\"\n\n    # Calculate net scores\n    scores = [g - p for g, p in zip(goals, penalties)]\n\n    # Clip scores to stay within -10 to 10\n    scores = [max(min(s, 10), -10) for s in scores]\n\n    # Create a DataFrame\n    df = pd.DataFrame({'Team': TEAMS, 'Score': scores})\n\n    # Visualize results\n    df.plot(x='Team', y='Score', kind='bar', legend=False)\n    plt.xlabel('Team')\n    plt.ylabel('Score')\n    plt.title('Net Scores for Teams')\n    plt.show()\n\n    return df"}
{"task_id": "BigCodeBench/614", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(goals, penalties):\n    # Create a DataFrame from the input data\n    df = pd.DataFrame({'Team': goals.keys(), 'Goals': goals.values(), 'Penalties': penalties.values()})\n\n    # Create a pairplot\n    pairplot = sns.pairplot(df, hue='Team')\n\n    return (df, pairplot)\ngoals = {'Team1': 5, 'Team2': 3, 'Team3': 7}\npenalties = {'Team1': 2, 'Team2': 3, 'Team3': 1}", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(goals, penalties):\n    # Create a DataFrame from the input data\n    df = pd.DataFrame({'Team': goals.keys(), 'Goals': goals.values(), 'Penalties': penalties.values()})\n\n    # Create a pairplot\n    pairplot = sns.pairplot(df, hue='Team')\n\n    return (df, pairplot)\n\n# Test the function\ngoals = {'Team1': 5, 'Team2': 3, 'Team3': 7}\npenalties = {'Team1': 2, 'Team2': 3, 'Team3': 1}\ndf, pairplot = task_func(goals, penalties)"}
{"task_id": "BigCodeBench/615", "solution": "from random import randint, seed\nimport pandas as pd\ndef task_func(teams, goals, penalties, penalty_cost, rng_seed=None):\n    # Seed the random number generator if a seed is provided\n    if rng_seed is not None:\n        seed(rng_seed)\n\n    # Initialize an empty list to store the match results\n    match_results = []\n\n    # For each team, generate a random number of goals and penalties, and calculate the fines\n    for team in teams:\n        team_goals = sum(randint(0, goals) for _ in range(1))\n        team_penalties = sum(randint(0, penalties) for _ in range(1))\n        team_fines = team_penalties * penalty_cost\n        match_results.append({'Team': team, 'Goals': team_goals, 'Penalties': team_penalties, 'Fines': team_fines})\n\n    # Convert the list of match results to a pandas DataFrame and return it\n    return pd.DataFrame(match_results)\nteams = ['Team A', 'Team B', 'Team C', 'Team D']\ngoals = 5\npenalties = 3\npenalty_cost = 50\nrng_seed = 123", "raw_solution": "from random import randint, seed\nimport pandas as pd\n\n# Method\ndef task_func(teams, goals, penalties, penalty_cost, rng_seed=None):\n    # Seed the random number generator if a seed is provided\n    if rng_seed is not None:\n        seed(rng_seed)\n\n    # Initialize an empty list to store the match results\n    match_results = []\n\n    # For each team, generate a random number of goals and penalties, and calculate the fines\n    for team in teams:\n        team_goals = sum(randint(0, goals) for _ in range(1))\n        team_penalties = sum(randint(0, penalties) for _ in range(1))\n        team_fines = team_penalties * penalty_cost\n        match_results.append({'Team': team, 'Goals': team_goals, 'Penalties': team_penalties, 'Fines': team_fines})\n\n    # Convert the list of match results to a pandas DataFrame and return it\n    return pd.DataFrame(match_results)\n\n# Test the function\nteams = ['Team A', 'Team B', 'Team C', 'Team D']\ngoals = 5\npenalties = 3\npenalty_cost = 50\nrng_seed = 123\n\ndf = task_func(teams, goals, penalties, penalty_cost, rng_seed)"}
{"task_id": "BigCodeBench/616", "solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties, teams=TEAMS, penalty_cost=PENALTY_COST, rng_seed=None):\n    # Set the random seed for reproducibility\n    if rng_seed is not None:\n        seed(rng_seed)\n\n    # Generate random goals and penalties for each team\n    data = {\n        'Team': teams,\n        'Goals': [randint(0, goals) for _ in teams],\n        'Penalty Cost': [randint(0, penalties) * penalty_cost for _ in teams]\n    }\n\n    # Create a DataFrame from the data\n    df = pd.DataFrame(data)\n\n    # Create a bar plot of the results\n    fig, ax = plt.subplots()\n    df.plot(x='Team', y=['Goals', 'Penalty Cost'], kind='bar', ax=ax)\n    ax.set_ylabel('Score')\n\n    return df, ax.figure", "raw_solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties, teams=TEAMS, penalty_cost=PENALTY_COST, rng_seed=None):\n    # Set the random seed for reproducibility\n    if rng_seed is not None:\n        seed(rng_seed)\n\n    # Generate random goals and penalties for each team\n    data = {\n        'Team': teams,\n        'Goals': [randint(0, goals) for _ in teams],\n        'Penalty Cost': [randint(0, penalties) * penalty_cost for _ in teams]\n    }\n\n    # Create a DataFrame from the data\n    df = pd.DataFrame(data)\n\n    # Create a bar plot of the results\n    fig, ax = plt.subplots()\n    df.plot(x='Team', y=['Goals', 'Penalty Cost'], kind='bar', ax=ax)\n    ax.set_ylabel('Score')\n\n    return df, ax.figure\n\n# Test the function\ndf, fig = task_func(10, 5)\nplt.show()"}
{"task_id": "BigCodeBench/617", "solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport re\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties, rng_seed=None, teams=TEAMS):\n    if rng_seed is not None:\n        seed(rng_seed)\n\n    # Generate random goals and penalties for each team\n    data = {'Team': teams,\n            'Goals': [randint(0, goals) for _ in teams],\n            'Penalties': [randint(0, penalties) for _ in teams]}\n\n    # Calculate penalty cost\n    data['Penalty Cost'] = data['Penalties'] * PENALTY_COST\n\n    # Create DataFrame\n    df = pd.DataFrame(data)\n\n    return df", "raw_solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport re\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties, rng_seed=None, teams=TEAMS):\n    if rng_seed is not None:\n        seed(rng_seed)\n\n    # Generate random goals and penalties for each team\n    data = {'Team': teams,\n            'Goals': [randint(0, goals) for _ in teams],\n            'Penalties': [randint(0, penalties) for _ in teams]}\n\n    # Calculate penalty cost\n    data['Penalty Cost'] = data['Penalties'] * PENALTY_COST\n\n    # Create DataFrame\n    df = pd.DataFrame(data)\n\n    return df\n\n# Test the function\ndf = task_func(10, 5)"}
{"task_id": "BigCodeBench/618", "solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties):\n    # Generate random goals and penalties\n    data = {'Team': [], 'Goals': [], 'Penalty Cost': []}\n    for i in range(len(TEAMS)):\n        data['Team'].append(TEAMS[i])\n        data['Goals'].append(randint(0, goals))\n        data['Penalty Cost'].append(randint(0, penalties) * PENALTY_COST)\n\n    # Create DataFrame\n    df = pd.DataFrame(data)\n\n    # Create plots\n    fig1, ax1 = plt.subplots()\n    sns.barplot(x='Team', y='Goals', data=df, ax=ax1)\n    ax1.set_title('Goals per Team')\n\n    fig2, ax2 = plt.subplots()\n    sns.barplot(x='Team', y='Penalty Cost', data=df, ax=ax2)\n    ax2.set_title('Penalty Costs per Team')\n\n    plt.tight_layout()\n\n    return df, [ax1, ax2]", "raw_solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties):\n    # Generate random goals and penalties\n    data = {'Team': [], 'Goals': [], 'Penalty Cost': []}\n    for i in range(len(TEAMS)):\n        data['Team'].append(TEAMS[i])\n        data['Goals'].append(randint(0, goals))\n        data['Penalty Cost'].append(randint(0, penalties) * PENALTY_COST)\n\n    # Create DataFrame\n    df = pd.DataFrame(data)\n\n    # Create plots\n    fig1, ax1 = plt.subplots()\n    sns.barplot(x='Team', y='Goals', data=df, ax=ax1)\n    ax1.set_title('Goals per Team')\n\n    fig2, ax2 = plt.subplots()\n    sns.barplot(x='Team', y='Penalty Cost', data=df, ax=ax2)\n    ax2.set_title('Penalty Costs per Team')\n\n    plt.tight_layout()\n\n    return df, [ax1, ax2]\n\n# Test the function\ndf, plots = task_func(10, 5)"}
{"task_id": "BigCodeBench/619", "solution": "from random import randint, seed\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties, rng_seed=None):\n    # Set the random seed for reproducibility\n    if rng_seed is not None:\n        seed(rng_seed)\n\n    # Generate data\n    data = []\n    for _ in range(goals):\n        team = TEAMS[randint(0, len(TEAMS)-1)]\n        goal = randint(0, 10)  # Assuming a team can score up to 10 goals\n        penalty = randint(0, PENALTY_COST)\n        data.append([team, goal, penalty])\n\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=['Team', 'Goals', 'Penalty Cost'])\n\n    # Train Linear Regression Model\n    X = df[['Goals']]\n    y = df['Penalty Cost']\n    model = LinearRegression().fit(X, y)\n\n    return df, model", "raw_solution": "from random import randint, seed\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties, rng_seed=None):\n    # Set the random seed for reproducibility\n    if rng_seed is not None:\n        seed(rng_seed)\n\n    # Generate data\n    data = []\n    for _ in range(goals):\n        team = TEAMS[randint(0, len(TEAMS)-1)]\n        goal = randint(0, 10)  # Assuming a team can score up to 10 goals\n        penalty = randint(0, PENALTY_COST)\n        data.append([team, goal, penalty])\n\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=['Team', 'Goals', 'Penalty Cost'])\n\n    # Train Linear Regression Model\n    X = df[['Goals']]\n    y = df['Penalty Cost']\n    model = LinearRegression().fit(X, y)\n\n    return df, model\n\n# Test the function\ndf, model = task_func(100, 100, rng_seed=42)"}
{"task_id": "BigCodeBench/620", "solution": "import numpy as np\nimport pandas as pd\nRANGE = (1, 100)\ndef task_func(L):\n    # Generate a DataFrame with random integers\n    df = pd.DataFrame(np.random.randint(RANGE[0], RANGE[1], size=(np.prod(L), len(L))))\n    # Set the column names\n    df.columns = [str(i) for i in L]\n    return df\nL = [[2, 3], [4, 5]]", "raw_solution": "import numpy as np\nimport pandas as pd\n\n# Constants\nRANGE = (1, 100)\n\ndef task_func(L):\n    # Generate a DataFrame with random integers\n    df = pd.DataFrame(np.random.randint(RANGE[0], RANGE[1], size=(np.prod(L), len(L))))\n    # Set the column names\n    df.columns = [str(i) for i in L]\n    return df\n\n# Test the function\nL = [[2, 3], [4, 5]]"}
{"task_id": "BigCodeBench/621", "solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n\n    # Convert the list to a numpy array\n    arr = np.array(flat_list).reshape(-1, 1)\n\n    # Standardize the values\n    scaler = StandardScaler()\n    standardized_values = scaler.fit_transform(arr)\n\n    # Plot the standardized values\n    plt.figure(figsize=(10, 6))\n    plt.plot(standardized_values)\n    plt.title('Standardized Values')\n    plt.xlabel('Index')\n    plt.ylabel('Standardized Value')\n\n    return plt.gca()", "raw_solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n\n    # Convert the list to a numpy array\n    arr = np.array(flat_list).reshape(-1, 1)\n\n    # Standardize the values\n    scaler = StandardScaler()\n    standardized_values = scaler.fit_transform(arr)\n\n    # Plot the standardized values\n    plt.figure(figsize=(10, 6))\n    plt.plot(standardized_values)\n    plt.title('Standardized Values')\n    plt.xlabel('Index')\n    plt.ylabel('Standardized Value')\n\n    return plt.gca()"}
{"task_id": "BigCodeBench/622", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import norm\nfrom itertools import chain\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n\n    # Convert the flattened list to a numpy array\n    data = np.array(flat_list)\n\n    # Fit a normal distribution to the data\n    mu, std = norm.fit(data)\n\n    # Create a range of values for the x-axis\n    xmin, xmax = min(data), max(data)\n    x = np.linspace(xmin, xmax, 100)\n\n    # Create a range of values for the y-axis\n    p = norm.pdf(x, mu, std)\n\n    # Create the histogram\n    plt.hist(data, bins=20, density=True, alpha=0.6, color='g', label='Histogram')\n\n    # Plot the normal distribution\n    plt.plot(x, p, 'k', linewidth=2, label='Normal distribution')\n\n    # Add legend\n    plt.legend()\n\n    # Return the axes object\n    return plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import norm\nfrom itertools import chain\n\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n\n    # Convert the flattened list to a numpy array\n    data = np.array(flat_list)\n\n    # Fit a normal distribution to the data\n    mu, std = norm.fit(data)\n\n    # Create a range of values for the x-axis\n    xmin, xmax = min(data), max(data)\n    x = np.linspace(xmin, xmax, 100)\n\n    # Create a range of values for the y-axis\n    p = norm.pdf(x, mu, std)\n\n    # Create the histogram\n    plt.hist(data, bins=20, density=True, alpha=0.6, color='g', label='Histogram')\n\n    # Plot the normal distribution\n    plt.plot(x, p, 'k', linewidth=2, label='Normal distribution')\n\n    # Add legend\n    plt.legend()\n\n    # Return the axes object\n    return plt.gca()"}
{"task_id": "BigCodeBench/623", "solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n    # Convert the list to numpy array\n    data = np.array(flat_list).reshape(-1,1)\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=3)\n    kmeans.fit(data)\n    # Get the cluster labels\n    labels = kmeans.predict(data)\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(data, data, c=labels, cmap='viridis')\n    return ax\nL = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]", "raw_solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n    # Convert the list to numpy array\n    data = np.array(flat_list).reshape(-1,1)\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=3)\n    kmeans.fit(data)\n    # Get the cluster labels\n    labels = kmeans.predict(data)\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(data, data, c=labels, cmap='viridis')\n    return ax\n\n# Test the function\nL = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nax = task_func(L)\nplt.show()"}
{"task_id": "BigCodeBench/624", "solution": "from sklearn.decomposition import PCA\nimport numpy as np\nimport matplotlib.pyplot as plt\nN_COMPONENTS = 2\ndef task_func(L):\n    # Convert list of lists to numpy array\n    arr = np.array(L)\n\n    # Apply PCA\n    pca = PCA(n_components=N_COMPONENTS)\n    pca_result = pca.fit_transform(arr)\n\n    # Create scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1])\n\n    return (pca_result, ax)\nL = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]", "raw_solution": "from sklearn.decomposition import PCA\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nN_COMPONENTS = 2\n\ndef task_func(L):\n    # Convert list of lists to numpy array\n    arr = np.array(L)\n\n    # Apply PCA\n    pca = PCA(n_components=N_COMPONENTS)\n    pca_result = pca.fit_transform(arr)\n\n    # Create scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1])\n\n    return (pca_result, ax)\n\n# Test the function\nL = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\npca_result, ax = task_func(L)"}
{"task_id": "BigCodeBench/625", "solution": "import math\nfrom random import randint\nimport pandas as pd\ndef task_func(cities_list):\n    population_list = [math.ceil(randint(1,100)*1000) for _ in range(len(cities_list))]\n    df = pd.DataFrame(list(zip(cities_list, population_list)), columns=['City', 'Population'])\n    return df", "raw_solution": "import math\nfrom random import randint\nimport pandas as pd\n\ndef task_func(cities_list):\n    population_list = [math.ceil(randint(1,100)*1000) for _ in range(len(cities_list))]\n    df = pd.DataFrame(list(zip(cities_list, population_list)), columns=['City', 'Population'])\n    return df\n\n# Test the function\ncities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']"}
{"task_id": "BigCodeBench/626", "solution": "from random import choice\nimport pytz\nfrom dateutil.parser import parse\nTIMEZONES = ['America/New_York', 'Europe/London', 'Asia/Shanghai', 'Asia/Tokyo', 'Australia/Sydney']\ndef task_func(date_str, from_tz):\n    # Parse the input datetime string to a datetime object\n    dt = parse(date_str)\n\n    # Set the timezone of the datetime object to the input timezone\n    dt = dt.replace(tzinfo=pytz.timezone(from_tz))\n\n    # Randomly choose a timezone from the list of timezones\n    to_tz = choice(TIMEZONES)\n\n    # Convert the datetime object to the randomly chosen timezone\n    dt = dt.astimezone(pytz.timezone(to_tz))\n\n    # Return the converted datetime string and the randomly chosen timezone\n    return dt.strftime('%Y-%m-%d %H:%M:%S %Z%z'), to_tz\ndate_str = '2022-01-01 12:00:00'\nfrom_tz = 'America/New_York'", "raw_solution": "from random import choice\nimport pytz\nfrom dateutil.parser import parse\n\n# Constants\nTIMEZONES = ['America/New_York', 'Europe/London', 'Asia/Shanghai', 'Asia/Tokyo', 'Australia/Sydney']\n\ndef task_func(date_str, from_tz):\n    # Parse the input datetime string to a datetime object\n    dt = parse(date_str)\n\n    # Set the timezone of the datetime object to the input timezone\n    dt = dt.replace(tzinfo=pytz.timezone(from_tz))\n\n    # Randomly choose a timezone from the list of timezones\n    to_tz = choice(TIMEZONES)\n\n    # Convert the datetime object to the randomly chosen timezone\n    dt = dt.astimezone(pytz.timezone(to_tz))\n\n    # Return the converted datetime string and the randomly chosen timezone\n    return dt.strftime('%Y-%m-%d %H:%M:%S %Z%z'), to_tz\n\n# Test the function\ndate_str = '2022-01-01 12:00:00'\nfrom_tz = 'America/New_York'"}
{"task_id": "BigCodeBench/627", "solution": "from random import randint\nfrom statistics import mean\nimport pandas as pd\ndef task_func(products_list):\n    data = []\n    for product in products_list:\n        sales = [randint(1, 100) for _ in range(12)]\n        avg_sales = mean(sales)\n        data.append([product] + sales + [avg_sales])\n\n    df = pd.DataFrame(data, columns=['Product', 'Month 1', 'Month 2', 'Month 3', 'Month 4', 'Month 5', 'Month 6', 'Month 7', 'Month 8', 'Month 9', 'Month 10', 'Month 11', 'Month 12', 'Average Sales'])\n    return df\nproducts = ['Product A', 'Product B', 'Product C']", "raw_solution": "from random import randint\nfrom statistics import mean\nimport pandas as pd\n\ndef task_func(products_list):\n    data = []\n    for product in products_list:\n        sales = [randint(1, 100) for _ in range(12)]\n        avg_sales = mean(sales)\n        data.append([product] + sales + [avg_sales])\n\n    df = pd.DataFrame(data, columns=['Product', 'Month 1', 'Month 2', 'Month 3', 'Month 4', 'Month 5', 'Month 6', 'Month 7', 'Month 8', 'Month 9', 'Month 10', 'Month 11', 'Month 12', 'Average Sales'])\n    return df\n\n# Test the function\nproducts = ['Product A', 'Product B', 'Product C']\ndf = task_func(products)"}
{"task_id": "BigCodeBench/628", "solution": "import math\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func():\n    # Generate random frequency, amplitude and phase shift\n    frequency = randint(1, 10)\n    amplitude = randint(1, 10)\n    phase_shift = randint(1, 10)\n\n    # Generate time points\n    t = np.arange(0.0, 1.0, 0.01)\n\n    # Generate sine wave\n    s = amplitude * np.sin(2 * np.pi * frequency * t + phase_shift)\n\n    # Create figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot sine wave\n    ax.plot(t, s)\n\n    # Set title and labels\n    ax.set(title='Random Sine Wave', xlabel='Time', ylabel='Amplitude')\n\n    # Show plot\n    plt.show()\n\n    return ax", "raw_solution": "import math\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func():\n    # Generate random frequency, amplitude and phase shift\n    frequency = randint(1, 10)\n    amplitude = randint(1, 10)\n    phase_shift = randint(1, 10)\n\n    # Generate time points\n    t = np.arange(0.0, 1.0, 0.01)\n\n    # Generate sine wave\n    s = amplitude * np.sin(2 * np.pi * frequency * t + phase_shift)\n\n    # Create figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot sine wave\n    ax.plot(t, s)\n\n    # Set title and labels\n    ax.set(title='Random Sine Wave', xlabel='Time', ylabel='Amplitude')\n\n    # Show plot\n    plt.show()\n\n    return ax"}
{"task_id": "BigCodeBench/629", "solution": "import os\nimport pandas as pd\nOUTPUT_DIR = './output'\ndef task_func(datasets, filename, output_dir=OUTPUT_DIR):\n    # Check if output directory exists, if not create it\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Construct the full path of the output file\n    filepath = os.path.join(output_dir, filename)\n\n    # Open the file in write mode\n    with open(filepath, 'w') as f:\n        # Iterate over each dataset\n        for i, df in enumerate(datasets):\n            # Write the DataFrame to the file\n            df.to_csv(f, index=False)\n\n            # If it's not the last DataFrame, write a line of hyphens\n            if i < len(datasets) - 1:\n                f.write('------\\n')\n\n    return None", "raw_solution": "import os\nimport pandas as pd\n\nOUTPUT_DIR = './output'\n\ndef task_func(datasets, filename, output_dir=OUTPUT_DIR):\n    # Check if output directory exists, if not create it\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Construct the full path of the output file\n    filepath = os.path.join(output_dir, filename)\n\n    # Open the file in write mode\n    with open(filepath, 'w') as f:\n        # Iterate over each dataset\n        for i, df in enumerate(datasets):\n            # Write the DataFrame to the file\n            df.to_csv(f, index=False)\n\n            # If it's not the last DataFrame, write a line of hyphens\n            if i < len(datasets) - 1:\n                f.write('------\\n')\n\n    return None"}
{"task_id": "BigCodeBench/630", "solution": "import pandas as pd\nimport os\nOUTPUT_DIR = './output'\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    # Check if output directory exists, if not create it\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Save DataFrame to JSON file\n    file_path = os.path.join(output_dir, filename)\n    df.to_json(file_path, orient='records')\n\n    return file_path\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})", "raw_solution": "import pandas as pd\nimport os\n\nOUTPUT_DIR = './output'\n\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    # Check if output directory exists, if not create it\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Save DataFrame to JSON file\n    file_path = os.path.join(output_dir, filename)\n    df.to_json(file_path, orient='records')\n\n    return file_path\n\n# Test the function\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})"}
{"task_id": "BigCodeBench/631", "solution": "import pandas as pd\nimport os\nOUTPUT_DIR = './output'\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    # Create the output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Save the DataFrame to a CSV file\n    df.to_csv(os.path.join(output_dir, filename), index=False)\n\n    # Return the absolute path of the saved CSV file\n    return os.path.abspath(os.path.join(output_dir, filename))\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})", "raw_solution": "import pandas as pd\nimport os\n\nOUTPUT_DIR = './output'\n\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    # Create the output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Save the DataFrame to a CSV file\n    df.to_csv(os.path.join(output_dir, filename), index=False)\n\n    # Return the absolute path of the saved CSV file\n    return os.path.abspath(os.path.join(output_dir, filename))\n\n# Test the function\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})"}
{"task_id": "BigCodeBench/632", "solution": "import pandas as pd\nimport json\nimport os\nOUTPUT_DIR = './output'\ndef task_func(df: pd.DataFrame, filename: str) -> str:\n    # Create output directory if it doesn't exist\n    if not os.path.exists(OUTPUT_DIR):\n        os.makedirs(OUTPUT_DIR)\n\n    # Convert DataFrame to JSON Lines\n    json_str = df.to_json(orient='records', lines=True)\n\n    # Save JSON Lines to file\n    file_path = os.path.join(OUTPUT_DIR, filename)\n    with open(file_path, 'w') as f:\n        f.write(json_str)\n\n    return file_path\ndf = pd.DataFrame({\n    'A': [1, 2, 3],\n    'B': ['a', 'b', 'c']\n})", "raw_solution": "import pandas as pd\nimport json\nimport os\n\nOUTPUT_DIR = './output'\n\ndef task_func(df: pd.DataFrame, filename: str) -> str:\n    # Create output directory if it doesn't exist\n    if not os.path.exists(OUTPUT_DIR):\n        os.makedirs(OUTPUT_DIR)\n\n    # Convert DataFrame to JSON Lines\n    json_str = df.to_json(orient='records', lines=True)\n\n    # Save JSON Lines to file\n    file_path = os.path.join(OUTPUT_DIR, filename)\n    with open(file_path, 'w') as f:\n        f.write(json_str)\n\n    return file_path\n\n# Test the function\ndf = pd.DataFrame({\n    'A': [1, 2, 3],\n    'B': ['a', 'b', 'c']\n})\n"}
{"task_id": "BigCodeBench/633", "solution": "import re\nfrom nltk.corpus import stopwords\nfrom nltk.probability import FreqDist\ndef task_func(text: str) -> dict:\n    # Define a set of common English stopwords\n    stop_words = set(stopwords.words('english'))\n\n    # Remove punctuation and convert text to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n\n    # Split the text into words\n    words = text.split()\n\n    # Remove stopwords and count the frequency of remaining words\n    filtered_words = [word for word in words if word not in stop_words]\n    freq_dist = FreqDist(filtered_words)\n\n    # Convert the frequency distribution to a dictionary and return\n    return dict(freq_dist)", "raw_solution": "import re\nfrom nltk.corpus import stopwords\nfrom nltk.probability import FreqDist\n\ndef task_func(text: str) -> dict:\n    # Define a set of common English stopwords\n    stop_words = set(stopwords.words('english'))\n\n    # Remove punctuation and convert text to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n\n    # Split the text into words\n    words = text.split()\n\n    # Remove stopwords and count the frequency of remaining words\n    filtered_words = [word for word in words if word not in stop_words]\n    freq_dist = FreqDist(filtered_words)\n\n    # Convert the frequency distribution to a dictionary and return\n    return dict(freq_dist)\n\n# Test the function"}
{"task_id": "BigCodeBench/634", "solution": "import itertools\nfrom typing import Any\nfrom scipy import stats\nimport numpy as np\ndef task_func(input_list: list, repetitions: int) -> Any:\n    # Flatten the list with multiple repetitions\n    flattened_list = list(itertools.chain.from_iterable(itertools.repeat(input_list, repetitions)))\n    \n    # Calculate the mode of the flattened list\n    mode_result = stats.mode(flattened_list)\n    \n    return mode_result", "raw_solution": "import itertools\nfrom typing import Any\nfrom scipy import stats\nimport numpy as np\n\ndef task_func(input_list: list, repetitions: int) -> Any:\n    # Flatten the list with multiple repetitions\n    flattened_list = list(itertools.chain.from_iterable(itertools.repeat(input_list, repetitions)))\n    \n    # Calculate the mode of the flattened list\n    mode_result = stats.mode(flattened_list)\n    \n    return mode_result\n\n# Test the function"}
{"task_id": "BigCodeBench/635", "solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\ndef task_func(text, n=2):\n    # Remove punctuation and convert to lower case\n    text = re.sub(r'[^\\w\\s]', ' ', text).lower()\n\n    # Remove duplicate consecutive words\n    text = re.sub(r'\\b(\\w+\\b\\s+\\b\\1\\b)+\\s+', '', text)\n\n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n\n    # Create a square co-occurrence matrix of words\n    vectorizer = CountVectorizer(ngram_range=(n, n), stop_words='english')\n    matrix = vectorizer.fit_transform([text])\n    matrix = matrix.toarray()\n\n    # Create a dataframe from the matrix\n    df = pd.DataFrame(matrix, columns=vectorizer.get_feature_names())\n\n    # Plot the co-occurrence matrix\n    fig, ax = plt.subplots(figsize=(10, 10))\n    ax.matshow(df, cmap='viridis')\n\n    # Add word labels to the plot\n    for i in range(df.shape[0]):\n        for j in range(df.shape[1]):\n            ax.text(j, i, df.iloc[i, j], ha='center', va='center', color='black')\n\n    return (df, ax)", "raw_solution": "# Importing the required libraries\nimport re\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\n\ndef task_func(text, n=2):\n    # Remove punctuation and convert to lower case\n    text = re.sub(r'[^\\w\\s]', ' ', text).lower()\n\n    # Remove duplicate consecutive words\n    text = re.sub(r'\\b(\\w+\\b\\s+\\b\\1\\b)+\\s+', '', text)\n\n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n\n    # Create a square co-occurrence matrix of words\n    vectorizer = CountVectorizer(ngram_range=(n, n), stop_words='english')\n    matrix = vectorizer.fit_transform([text])\n    matrix = matrix.toarray()\n\n    # Create a dataframe from the matrix\n    df = pd.DataFrame(matrix, columns=vectorizer.get_feature_names())\n\n    # Plot the co-occurrence matrix\n    fig, ax = plt.subplots(figsize=(10, 10))\n    ax.matshow(df, cmap='viridis')\n\n    # Add word labels to the plot\n    for i in range(df.shape[0]):\n        for j in range(df.shape[1]):\n            ax.text(j, i, df.iloc[i, j], ha='center', va='center', color='black')\n\n    return (df, ax)"}
{"task_id": "BigCodeBench/636", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(rows):\n    # Create a DataFrame with random integer values between 0 and 9\n    df = pd.DataFrame(np.random.randint(0,10,size=(rows, len(COLUMNS))), columns=COLUMNS)\n\n    # Count the non-zero values in each column\n    non_zero_counts = df.ne(0).sum()\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n\n    ax.set_title('Non-zero values in each column')\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Counts')\n\n    return (df, ax)", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(rows):\n    # Create a DataFrame with random integer values between 0 and 9\n    df = pd.DataFrame(np.random.randint(0,10,size=(rows, len(COLUMNS))), columns=COLUMNS)\n\n    # Count the non-zero values in each column\n    non_zero_counts = df.ne(0).sum()\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n\n    ax.set_title('Non-zero values in each column')\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Counts')\n\n    return (df, ax)\n\n# Test the function\ndf, ax = task_func(100)\nplt.show()"}
{"task_id": "BigCodeBench/637", "solution": "from random import sample\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\ndef task_func(num_students):\n    np.random.seed(0)\n    courses = ['Math', 'English', 'Science', 'History', 'Art']\n    grades = np.random.randint(50, 100, (num_students, len(courses)))\n    students = [f'Student_{i}' for i in range(1, num_students+1)]\n\n    df = pd.DataFrame(grades, index=students, columns=courses)\n\n    avg_grades = df.mean()\n    passing_grades = (df >= 60).sum()\n\n    df_output = pd.DataFrame({'Average Grade': avg_grades, 'Passing Grades': passing_grades})\n\n    fig, ax = plt.subplots()\n    df_output[['Average Grade', 'Passing Grades']].plot(kind='bar', ax=ax)\n    ax.set_title('Course-wise Average and Passing Grade Counts')\n    ax.set_ylabel('Counts')\n    ax.legend(loc='upper left')\n\n    return df_output, ax", "raw_solution": "from random import sample\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndef task_func(num_students):\n    np.random.seed(0)\n    courses = ['Math', 'English', 'Science', 'History', 'Art']\n    grades = np.random.randint(50, 100, (num_students, len(courses)))\n    students = [f'Student_{i}' for i in range(1, num_students+1)]\n\n    df = pd.DataFrame(grades, index=students, columns=courses)\n\n    avg_grades = df.mean()\n    passing_grades = (df >= 60).sum()\n\n    df_output = pd.DataFrame({'Average Grade': avg_grades, 'Passing Grades': passing_grades})\n\n    fig, ax = plt.subplots()\n    df_output[['Average Grade', 'Passing Grades']].plot(kind='bar', ax=ax)\n    ax.set_title('Course-wise Average and Passing Grade Counts')\n    ax.set_ylabel('Counts')\n    ax.legend(loc='upper left')\n\n    return df_output, ax\n\n# Test the function\ndf, ax = task_func(20)\nplt.show()"}
{"task_id": "BigCodeBench/638", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(num_teams=5, num_games=100):\n    teams = ['Team'+str(i) for i in range(1, num_teams+1)]\n    games = ['Game'+str(i) for i in range(1, num_games+1)]\n    scores = np.random.randint(0, 100, size=(num_teams, num_games))\n    df = pd.DataFrame(scores, index=teams, columns=games)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(num_teams=5, num_games=100):\n    teams = ['Team'+str(i) for i in range(1, num_teams+1)]\n    games = ['Game'+str(i) for i in range(1, num_games+1)]\n    scores = np.random.randint(0, 100, size=(num_teams, num_games))\n    df = pd.DataFrame(scores, index=teams, columns=games)\n    return df\n\n# Test the function\ndf = task_func(5, 100)"}
{"task_id": "BigCodeBench/639", "solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(num_samples=100, num_features=5):\n    # Generate a DataFrame with random values\n    np.random.seed(0)\n    df = pd.DataFrame(np.random.randn(num_samples, num_features), \n                      columns=[f'Feature_{i}' for i in range(1, num_features + 1)])\n    \n    # Calculate the correlation matrix\n    corr = df.corr()\n\n    # Visualize the correlation matrix using a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, fmt=\".2f\")\n    plt.title(\"Correlation Heatmap\")\n    plt.show()\n    \n    return df, corr", "raw_solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(num_samples=100, num_features=5):\n    # Generate a DataFrame with random values\n    np.random.seed(0)\n    df = pd.DataFrame(np.random.randn(num_samples, num_features), \n                      columns=[f'Feature_{i}' for i in range(1, num_features + 1)])\n    \n    # Calculate the correlation matrix\n    corr = df.corr()\n\n    # Visualize the correlation matrix using a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, fmt=\".2f\")\n    plt.title(\"Correlation Heatmap\")\n    plt.show()\n    \n    return df, corr\n\n# Test the function\ndf, corr = task_func(100, 5)"}
{"task_id": "BigCodeBench/640", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nPRODUCTS = ['Product' + str(i) for i in range(1, 6)]\nMONTHS = ['Month' + str(i) for i in range(1, 13)]\ndef task_func():\n    # Generate random sales figures\n    np.random.seed(0)\n    sales_data = np.random.randint(100, 500, size=(12, 5))\n\n    # Create DataFrame\n    df = pd.DataFrame(sales_data, columns=PRODUCTS, index=MONTHS)\n\n    # Plot total sales per product\n    df.sum().plot(kind='line', title='Total Sales per Product')\n    plt.ylabel('Sales')\n    plt.show()\n\n    # Plot heatmap\n    sns.heatmap(df, annot=True, fmt=\"d\", cmap='YlGnBu', cbar=True)\n    plt.title('Sales Heatmap')\n    plt.show()\n\n    return df", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nPRODUCTS = ['Product' + str(i) for i in range(1, 6)]\nMONTHS = ['Month' + str(i) for i in range(1, 13)]\n\ndef task_func():\n    # Generate random sales figures\n    np.random.seed(0)\n    sales_data = np.random.randint(100, 500, size=(12, 5))\n\n    # Create DataFrame\n    df = pd.DataFrame(sales_data, columns=PRODUCTS, index=MONTHS)\n\n    # Plot total sales per product\n    df.sum().plot(kind='line', title='Total Sales per Product')\n    plt.ylabel('Sales')\n    plt.show()\n\n    # Plot heatmap\n    sns.heatmap(df, annot=True, fmt=\"d\", cmap='YlGnBu', cbar=True)\n    plt.title('Sales Heatmap')\n    plt.show()\n\n    return df\n\n# Call the function\ndf = task_func()"}
{"task_id": "BigCodeBench/641", "solution": "import os\nimport re\nimport pandas as pd\ndef task_func(pattern: str, directory: str, output_csv: str) -> pd.DataFrame:\n    matched_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(pattern, file):\n                matched_files.append(os.path.join(root, file))\n\n    df = pd.DataFrame(matched_files, columns=['File Path'])\n    df.to_csv(output_csv, index=False)\n    return df", "raw_solution": "import os\nimport re\nimport pandas as pd\n\ndef task_func(pattern: str, directory: str, output_csv: str) -> pd.DataFrame:\n    matched_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(pattern, file):\n                matched_files.append(os.path.join(root, file))\n\n    df = pd.DataFrame(matched_files, columns=['File Path'])\n    df.to_csv(output_csv, index=False)\n    return df"}
{"task_id": "BigCodeBench/642", "solution": "import os\nimport re\nimport hashlib\ndef task_func(directory: str, pattern: str = r\"(?<!Distillr)\\\\AcroTray\\.exe\") -> dict:\n    # Initialize an empty dictionary to store file paths and their SHA256 hashes\n    file_hashes = {}\n\n    # Walk through the directory\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # Check if the file matches the regex pattern\n            if re.search(pattern, file):\n                # Compute the SHA256 hash of the file's content\n                with open(os.path.join(root, file), 'rb') as f:\n                    file_hash = hashlib.sha256(f.read()).hexdigest()\n                # Store the file path and its SHA256 hash in the dictionary\n                file_hashes[os.path.join(root, file)] = file_hash\n\n    return file_hashes", "raw_solution": "import os\nimport re\nimport hashlib\n\ndef task_func(directory: str, pattern: str = r\"(?<!Distillr)\\\\AcroTray\\.exe\") -> dict:\n    # Initialize an empty dictionary to store file paths and their SHA256 hashes\n    file_hashes = {}\n\n    # Walk through the directory\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # Check if the file matches the regex pattern\n            if re.search(pattern, file):\n                # Compute the SHA256 hash of the file's content\n                with open(os.path.join(root, file), 'rb') as f:\n                    file_hash = hashlib.sha256(f.read()).hexdigest()\n                # Store the file path and its SHA256 hash in the dictionary\n                file_hashes[os.path.join(root, file)] = file_hash\n\n    return file_hashes\n\n# Test the function"}
{"task_id": "BigCodeBench/643", "solution": "import re\nimport pandas as pd\nimport numpy as np\nDATA_PATTERN = r'>\\d+\\.\\d+<'\ndef task_func(dataframe, data_pattern=DATA_PATTERN):\n    # Apply function to each cell in the DataFrame\n    dataframe = dataframe.applymap(lambda x: extract_number(x, data_pattern))\n    return dataframe\ndef extract_number(cell, pattern):\n    # Search for pattern in cell\n    match = re.search(pattern, str(cell))\n    # If match found, return the matched number, else return NaN\n    return float(match.group(0)[1:-1]) if match else np.nan", "raw_solution": "import re\nimport pandas as pd\nimport numpy as np\n\n# Constants\nDATA_PATTERN = r'>\\d+\\.\\d+<'\n\ndef task_func(dataframe, data_pattern=DATA_PATTERN):\n    # Apply function to each cell in the DataFrame\n    dataframe = dataframe.applymap(lambda x: extract_number(x, data_pattern))\n    return dataframe\n\ndef extract_number(cell, pattern):\n    # Search for pattern in cell\n    match = re.search(pattern, str(cell))\n    # If match found, return the matched number, else return NaN\n    return float(match.group(0)[1:-1]) if match else np.nan\n\n# Test the function\ndf = pd.DataFrame({\n    'A': ['>1.23<', 'text', '>4.56<text', '789', '>0.99<123'],\n    'B': ['text>1.23<', '>2.34<text', '789', '>0.50<666', '>1.01<'],\n    'C': ['>0.01<', 'text', '>2.22<text', '>1.11<', '>0.00<100']\n})\n"}
{"task_id": "BigCodeBench/644", "solution": "import os\nimport hashlib\nimport base64\nfrom Crypto.Cipher import AES\nfrom Crypto import Random\ndef task_func(filename, data, password):\n    # Create directory if it does not exist\n    directory = os.path.dirname(filename)\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    # Encrypt the data\n    encrypted_data = encrypt(data, password)\n\n    # Write the encrypted data to the file\n    with open(filename, 'w') as file:\n        file.write(encrypted_data)\n\n    return encrypted_data\ndef encrypt(data, password):\n    # Generate a salt\n    salt = Random.new().read(AES.block_size)\n\n    # Use the password and salt to generate a key\n    key = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, 100000)\n\n    # Create a new AES cipher object with the key\n    cipher = AES.new(key, AES.MODE_CBC)\n\n    # Pad the data to make it a multiple of 16 bytes\n    padding_length = AES.block_size - len(data) % AES.block_size\n    data += bytes([padding_length]) * padding_length\n\n    # Encrypt the data\n    encrypted_data = base64.b64encode(cipher.encrypt(data)).decode('utf-8')\n\n    return encrypted_data\nfilename = 'encrypted.txt'\ndata = 'Hello, World!'\npassword = 'password'", "raw_solution": "import os\nimport hashlib\nimport base64\nfrom Crypto.Cipher import AES\nfrom Crypto import Random\n\ndef task_func(filename, data, password):\n    # Create directory if it does not exist\n    directory = os.path.dirname(filename)\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    # Encrypt the data\n    encrypted_data = encrypt(data, password)\n\n    # Write the encrypted data to the file\n    with open(filename, 'w') as file:\n        file.write(encrypted_data)\n\n    return encrypted_data\n\ndef encrypt(data, password):\n    # Generate a salt\n    salt = Random.new().read(AES.block_size)\n\n    # Use the password and salt to generate a key\n    key = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, 100000)\n\n    # Create a new AES cipher object with the key\n    cipher = AES.new(key, AES.MODE_CBC)\n\n    # Pad the data to make it a multiple of 16 bytes\n    padding_length = AES.block_size - len(data) % AES.block_size\n    data += bytes([padding_length]) * padding_length\n\n    # Encrypt the data\n    encrypted_data = base64.b64encode(cipher.encrypt(data)).decode('utf-8')\n\n    return encrypted_data\n\n# Test the function\nfilename = 'encrypted.txt'\ndata = 'Hello, World!'\npassword = 'password'"}
{"task_id": "BigCodeBench/645", "solution": "import os\nimport pandas as pd\ndef task_func(filename: str) -> pd.DataFrame:\n    if not os.path.isfile(filename):\n        raise FileNotFoundError(f\"The file {filename} does not exist.\")\n\n    df = pd.read_csv(filename)\n    os.remove(filename)\n\n    return df", "raw_solution": "import os\nimport pandas as pd\n\ndef task_func(filename: str) -> pd.DataFrame:\n    if not os.path.isfile(filename):\n        raise FileNotFoundError(f\"The file {filename} does not exist.\")\n\n    df = pd.read_csv(filename)\n    os.remove(filename)\n\n    return df"}
{"task_id": "BigCodeBench/646", "solution": "import os\nimport pandas as pd\nfrom dateutil.parser import parse\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom pandas.plotting import register_matplotlib_converters\nOUTPUT_DIR = './output'\ndef task_func(csv_path=os.path.join(OUTPUT_DIR, 'data.csv'), date_column='date'):\n    # Read CSV file\n    df = pd.read_csv(csv_path)\n\n    # Convert date strings to datetime objects\n    df[date_column] = df[date_column].apply(lambda x: parse(x))\n\n    # Extract year from datetime objects\n    df['year'] = df[date_column].dt.year\n\n    # Plot histogram\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.hist(df['year'], bins=20, color='skyblue', edgecolor='black')\n    ax.xaxis.set_major_locator(mdates.YearLocator())\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n    ax.set_xlabel('Year')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Year Distribution')\n\n    return ax", "raw_solution": "import os\nimport pandas as pd\nfrom dateutil.parser import parse\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\nOUTPUT_DIR = './output'\n\ndef task_func(csv_path=os.path.join(OUTPUT_DIR, 'data.csv'), date_column='date'):\n    # Read CSV file\n    df = pd.read_csv(csv_path)\n\n    # Convert date strings to datetime objects\n    df[date_column] = df[date_column].apply(lambda x: parse(x))\n\n    # Extract year from datetime objects\n    df['year'] = df[date_column].dt.year\n\n    # Plot histogram\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.hist(df['year'], bins=20, color='skyblue', edgecolor='black')\n    ax.xaxis.set_major_locator(mdates.YearLocator())\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n    ax.set_xlabel('Year')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Year Distribution')\n\n    return ax"}
{"task_id": "BigCodeBench/647", "solution": "from datetime import datetime\nimport pytz\nfrom dateutil.parser import parse\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the date string into a datetime object\n    dt = parse(date_str)\n\n    # Localize the datetime object to the from_tz timezone\n    dt = dt.replace(tzinfo=pytz.timezone(from_tz))\n\n    # Convert the datetime object to the to_tz timezone\n    dt = dt.astimezone(pytz.timezone(to_tz))\n\n    # Get the current time in the to_tz timezone\n    now = datetime.now(pytz.timezone(to_tz))\n\n    # Calculate the time difference in seconds\n    diff = (now - dt).total_seconds()\n\n    return int(diff)", "raw_solution": "from datetime import datetime\nimport pytz\nfrom dateutil.parser import parse\n\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the date string into a datetime object\n    dt = parse(date_str)\n\n    # Localize the datetime object to the from_tz timezone\n    dt = dt.replace(tzinfo=pytz.timezone(from_tz))\n\n    # Convert the datetime object to the to_tz timezone\n    dt = dt.astimezone(pytz.timezone(to_tz))\n\n    # Get the current time in the to_tz timezone\n    now = datetime.now(pytz.timezone(to_tz))\n\n    # Calculate the time difference in seconds\n    diff = (now - dt).total_seconds()\n\n    return int(diff)\n\n# Test the function"}
{"task_id": "BigCodeBench/648", "solution": "from dateutil.parser import parse\nfrom datetime import timedelta\ndef task_func(date_str):\n    # Parse the date string into a datetime object\n    date = parse(date_str)\n\n    # Calculate the number of days to add to get the next business day\n    days_to_add = 1\n    while True:\n        next_day = date + timedelta(days=days_to_add)\n        if next_day.weekday() < 5:  # 0-4 for Monday to Friday\n            break\n        days_to_add += 1\n\n    return next_day", "raw_solution": "from dateutil.parser import parse\nfrom datetime import timedelta\n\ndef task_func(date_str):\n    # Parse the date string into a datetime object\n    date = parse(date_str)\n\n    # Calculate the number of days to add to get the next business day\n    days_to_add = 1\n    while True:\n        next_day = date + timedelta(days=days_to_add)\n        if next_day.weekday() < 5:  # 0-4 for Monday to Friday\n            break\n        days_to_add += 1\n\n    return next_day\n\n# Test the function"}
{"task_id": "BigCodeBench/649", "solution": "import numpy as np\nimport pandas as pd\nfrom dateutil.parser import parse\ndef task_func(dates_str_list):\n    # Create a list to store the weekdays\n    weekdays = []\n\n    # Iterate over the list of date strings\n    for date_str in dates_str_list:\n        # Parse the date string and get the weekday\n        date = parse(date_str)\n        weekday = date.weekday()\n        # Append the weekday to the list\n        weekdays.append(weekday)\n\n    # Create a pandas Series from the list of weekdays\n    weekdays_series = pd.Series(weekdays)\n\n    # Calculate the distribution of the weekdays\n    distribution = weekdays_series.value_counts().sort_index()\n\n    # Map the index of the distribution to the names of the weekdays\n    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    distribution.index = days\n\n    return distribution\ndates_str_list = ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06', '2022-01-07']", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom dateutil.parser import parse\n\ndef task_func(dates_str_list):\n    # Create a list to store the weekdays\n    weekdays = []\n\n    # Iterate over the list of date strings\n    for date_str in dates_str_list:\n        # Parse the date string and get the weekday\n        date = parse(date_str)\n        weekday = date.weekday()\n        # Append the weekday to the list\n        weekdays.append(weekday)\n\n    # Create a pandas Series from the list of weekdays\n    weekdays_series = pd.Series(weekdays)\n\n    # Calculate the distribution of the weekdays\n    distribution = weekdays_series.value_counts().sort_index()\n\n    # Map the index of the distribution to the names of the weekdays\n    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    distribution.index = days\n\n    return distribution\n\n# Test the function\ndates_str_list = ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06', '2022-01-07']"}
{"task_id": "BigCodeBench/650", "solution": "from datetime import datetime\nimport pytz\nfrom dateutil.parser import parse\ndef task_func(date_str, tz_str):\n    # Parse the date string into a datetime object\n    dt = parse(date_str)\n\n    # Create a timezone object\n    tz = pytz.timezone(tz_str)\n\n    # Localize the datetime object to the specified timezone\n    dt = dt.replace(tzinfo=tz)\n\n    # Calculate the next New Year in the specified timezone\n    next_year = dt.year + 1\n    next_year_dt = datetime(next_year, 1, 1, 0, 0, 0, tzinfo=tz)\n\n    # Calculate the time difference between the current time and the next New Year\n    diff = next_year_dt - dt\n\n    # Return the time difference in seconds\n    return diff.total_seconds()", "raw_solution": "from datetime import datetime\nimport pytz\nfrom dateutil.parser import parse\n\ndef task_func(date_str, tz_str):\n    # Parse the date string into a datetime object\n    dt = parse(date_str)\n\n    # Create a timezone object\n    tz = pytz.timezone(tz_str)\n\n    # Localize the datetime object to the specified timezone\n    dt = dt.replace(tzinfo=tz)\n\n    # Calculate the next New Year in the specified timezone\n    next_year = dt.year + 1\n    next_year_dt = datetime(next_year, 1, 1, 0, 0, 0, tzinfo=tz)\n\n    # Calculate the time difference between the current time and the next New Year\n    diff = next_year_dt - dt\n\n    # Return the time difference in seconds\n    return diff.total_seconds()\n\n# Test the function"}
{"task_id": "BigCodeBench/651", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, target_value):\n    # Convert the input dictionary of lists to a DataFrame\n    df = pd.DataFrame(df)\n\n    # Search in the DataFrame for rows with cells equal to the provided target_value\n    target_rows = df[df == target_value]\n\n    # If the DataFrame is not empty, count the number of such rows per column\n    if not target_rows.empty:\n        counts = target_rows.count()\n\n        # Plot the count of such rows per column\n        counts.plot(kind='bar')\n        plt.ylabel('Count')\n        plt.title('Count of Rows with Target Value per Column')\n        ax = plt.gca()\n    else:\n        counts = None\n        ax = None\n\n    return counts, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_value):\n    # Convert the input dictionary of lists to a DataFrame\n    df = pd.DataFrame(df)\n\n    # Search in the DataFrame for rows with cells equal to the provided target_value\n    target_rows = df[df == target_value]\n\n    # If the DataFrame is not empty, count the number of such rows per column\n    if not target_rows.empty:\n        counts = target_rows.count()\n\n        # Plot the count of such rows per column\n        counts.plot(kind='bar')\n        plt.ylabel('Count')\n        plt.title('Count of Rows with Target Value per Column')\n        ax = plt.gca()\n    else:\n        counts = None\n        ax = None\n\n    return counts, ax"}
{"task_id": "BigCodeBench/652", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\nTARGET_VALUE = '332'\nARRAY = np.array([['0', '1', '2'], ['a', 'bb', 'ccc'], ['332', '33', '2'], ['33', '22', '332']])\ndef task_func(target_value=TARGET_VALUE, array=ARRAY):\n    # Find the row indices where the first cell matches target_value\n    indices = np.where(array[:,0] == target_value)[0]\n\n    # If no target value found, return 'N/A' for all stats\n    if len(indices) == 0:\n        return 'N/A', 'N/A', 'N/A', 'N/A'\n\n    # Perform statistical analysis on the indices\n    mean = np.mean(indices)\n    variance = np.var(indices)\n    skewness = stats.skew(indices)\n    kurtosis = stats.kurtosis(indices)\n\n    # Plot the distribution of the indices\n    plt.hist(indices, bins='auto', alpha=0.75)\n    plt.title('Distribution of Indices')\n    plt.xlabel('Index')\n    plt.ylabel('Frequency')\n    plt.show()\n\n    return mean, variance, skewness, kurtosis", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\n\n# Constants\nTARGET_VALUE = '332'\nARRAY = np.array([['0', '1', '2'], ['a', 'bb', 'ccc'], ['332', '33', '2'], ['33', '22', '332']])\n\ndef task_func(target_value=TARGET_VALUE, array=ARRAY):\n    # Find the row indices where the first cell matches target_value\n    indices = np.where(array[:,0] == target_value)[0]\n\n    # If no target value found, return 'N/A' for all stats\n    if len(indices) == 0:\n        return 'N/A', 'N/A', 'N/A', 'N/A'\n\n    # Perform statistical analysis on the indices\n    mean = np.mean(indices)\n    variance = np.var(indices)\n    skewness = stats.skew(indices)\n    kurtosis = stats.kurtosis(indices)\n\n    # Plot the distribution of the indices\n    plt.hist(indices, bins='auto', alpha=0.75)\n    plt.title('Distribution of Indices')\n    plt.xlabel('Index')\n    plt.ylabel('Frequency')\n    plt.show()\n\n    return mean, variance, skewness, kurtosis\n\n# Test the function"}
{"task_id": "BigCodeBench/653", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\ndef task_func(dataframe, target_value='332'):\n    # Create a Boolean DataFrame indicating the presence of the target value\n    target_df = dataframe == target_value\n\n    # Create a heatmap using seaborn\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(data=target_df, cmap='Blues', cbar=False)\n    plt.title(f'Heatmap of occurrences of \"{target_value}\"')\n\n    # Return the DataFrame and the Axes object of the heatmap\n    return target_df, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\ndef task_func(dataframe, target_value='332'):\n    # Create a Boolean DataFrame indicating the presence of the target value\n    target_df = dataframe == target_value\n\n    # Create a heatmap using seaborn\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(data=target_df, cmap='Blues', cbar=False)\n    plt.title(f'Heatmap of occurrences of \"{target_value}\"')\n\n    # Return the DataFrame and the Axes object of the heatmap\n    return target_df, plt.gca()\n\n# Test the function\ndf = pd.DataFrame(np.random.randint(0, 100, size=(10, 10)), columns=list('ABCDEFGHIJ'))\ntarget_df, ax = task_func(df, '332')\n\n# Print the DataFrame and show the heatmap"}
{"task_id": "BigCodeBench/654", "solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\ndef task_func(array, target_value):\n    # Define the exponential decay function\n    def func(x, a, b, c):\n        return a * np.exp(-b * x) + c\n\n    # Find the indices where the first column matches the target value\n    indices = np.where(array[:, 0] == target_value)\n\n    # Extract the corresponding y values\n    y = array[indices, 1]\n\n    # Perform the curve fitting\n    popt, _ = optimize.curve_fit(func, indices, y)\n\n    # Create a new figure\n    fig, ax = plt.subplots()\n\n    # Plot the original data\n    ax.scatter(indices, y, color='red', label='Data')\n\n    # Plot the fitted function\n    ax.plot(indices, func(indices, *popt), color='blue', label='Fit')\n\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    plt.show()\n\n    return popt, ax\narray = np.array([[1, 2], [2, 3], [3, 4], [1, 5], [2, 6], [3, 7]])", "raw_solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\n\ndef task_func(array, target_value):\n    # Define the exponential decay function\n    def func(x, a, b, c):\n        return a * np.exp(-b * x) + c\n\n    # Find the indices where the first column matches the target value\n    indices = np.where(array[:, 0] == target_value)\n\n    # Extract the corresponding y values\n    y = array[indices, 1]\n\n    # Perform the curve fitting\n    popt, _ = optimize.curve_fit(func, indices, y)\n\n    # Create a new figure\n    fig, ax = plt.subplots()\n\n    # Plot the original data\n    ax.scatter(indices, y, color='red', label='Data')\n\n    # Plot the fitted function\n    ax.plot(indices, func(indices, *popt), color='blue', label='Fit')\n\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    plt.show()\n\n    return popt, ax\n\n# Test the function\narray = np.array([[1, 2], [2, 3], [3, 4], [1, 5], [2, 6], [3, 7]])\npopt, ax = task_func(array, 1)"}
{"task_id": "BigCodeBench/655", "solution": "import re\nimport nltk\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef preprocess_text(text):\n    # Remove non-alphanumeric characters\n    text = ALPHANUMERIC.sub(' ', text)\n    # Convert to lowercase\n    text = text.lower()\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n    return text\ndef task_func(texts, num_topics):\n    # Preprocess texts\n    texts = [preprocess_text(text) for text in texts]\n    # Vectorize texts\n    vectorizer = TfidfVectorizer(stop_words='english')\n    tfidf_matrix = vectorizer.fit_transform(texts)\n    # Apply NMF\n    nmf = NMF(n_components=num_topics, random_state=42)\n    nmf.fit(tfidf_matrix)\n    # Extract topics\n    feature_names = vectorizer.get_feature_names_out()\n    topics = []\n    for topic_idx, topic in enumerate(nmf.components_):\n        top_features_ind = topic.argsort()[:-num_topics - 1:-1]\n        top_features = [feature_names[i] for i in top_features_ind]\n        topics.append(top_features)\n    return topics", "raw_solution": "import re\nimport nltk\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# Ensure nltk's stopwords are downloaded\nnltk.download('stopwords')\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\n\ndef preprocess_text(text):\n    # Remove non-alphanumeric characters\n    text = ALPHANUMERIC.sub(' ', text)\n    # Convert to lowercase\n    text = text.lower()\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n    return text\n\ndef task_func(texts, num_topics):\n    # Preprocess texts\n    texts = [preprocess_text(text) for text in texts]\n    # Vectorize texts\n    vectorizer = TfidfVectorizer(stop_words='english')\n    tfidf_matrix = vectorizer.fit_transform(texts)\n    # Apply NMF\n    nmf = NMF(n_components=num_topics, random_state=42)\n    nmf.fit(tfidf_matrix)\n    # Extract topics\n    feature_names = vectorizer.get_feature_names_out()\n    topics = []\n    for topic_idx, topic in enumerate(nmf.components_):\n        top_features_ind = topic.argsort()[:-num_topics - 1:-1]\n        top_features = [feature_names[i] for i in top_features_ind]\n        topics.append(top_features)\n    return topics"}
{"task_id": "BigCodeBench/656", "solution": "import re\nimport string\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nALPHANUMERIC = re.compile('[\\W_]+')\nPUNCTUATIONS = string.punctuation\ndef task_func(text: str, sia: SentimentIntensityAnalyzer) -> dict:\n    # Clean the text\n    text = re.sub(ALPHANUMERIC, ' ', text.lower())\n    text = re.sub(r'\\s+', ' ', text)\n    text = ''.join([char for char in text if char not in PUNCTUATIONS])\n\n    # Analyze the sentiment\n    sentiment = sia.polarity_scores(text)\n\n    return sentiment\nsia = SentimentIntensityAnalyzer()\ntext = \"I love programming! It's so fun and challenging.\"", "raw_solution": "import re\nimport string\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nnltk.download('vader_lexicon')\n\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\nPUNCTUATIONS = string.punctuation\n\ndef task_func(text: str, sia: SentimentIntensityAnalyzer) -> dict:\n    # Clean the text\n    text = re.sub(ALPHANUMERIC, ' ', text.lower())\n    text = re.sub(r'\\s+', ' ', text)\n    text = ''.join([char for char in text if char not in PUNCTUATIONS])\n\n    # Analyze the sentiment\n    sentiment = sia.polarity_scores(text)\n\n    return sentiment\n\n# Test the function\nsia = SentimentIntensityAnalyzer()\ntext = \"I love programming! It's so fun and challenging.\""}
{"task_id": "BigCodeBench/657", "solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom gensim.models import Word2Vec\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n    # If no stopwords provided, use nltk's english stopwords\n    if stopwords is None:\n        stopwords = set(nltk.corpus.stopwords.words('english'))\n\n    # Clean texts\n    cleaned_texts = []\n    for text in texts:\n        # Remove non-alphanumeric characters except space\n        text = ALPHANUMERIC.sub(' ', text)\n        # Lowercase\n        text = text.lower()\n        # Split into words\n        words = text.split()\n        # Remove stopwords\n        words = [word for word in words if word not in stopwords]\n        cleaned_texts.append(words)\n\n    # Train Word2Vec model\n    model = Word2Vec(cleaned_texts, min_count=1)\n\n    return model", "raw_solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom gensim.models import Word2Vec\n\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\n\ndef task_func(texts, stopwords=None):\n    # If no stopwords provided, use nltk's english stopwords\n    if stopwords is None:\n        stopwords = set(nltk.corpus.stopwords.words('english'))\n\n    # Clean texts\n    cleaned_texts = []\n    for text in texts:\n        # Remove non-alphanumeric characters except space\n        text = ALPHANUMERIC.sub(' ', text)\n        # Lowercase\n        text = text.lower()\n        # Split into words\n        words = text.split()\n        # Remove stopwords\n        words = [word for word in words if word not in stopwords]\n        cleaned_texts.append(words)\n\n    # Train Word2Vec model\n    model = Word2Vec(cleaned_texts, min_count=1)\n\n    return model"}
{"task_id": "BigCodeBench/658", "solution": "import re\nimport nltk\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(texts):\n    # Preprocessing: remove non-alphanumeric characters, convert to lowercase, and remove stop words\n    preprocessed_texts = [ALPHANUMERIC.sub(' ', text.lower()) for text in texts]\n    preprocessed_texts = [' '.join([word for word in text.split() if word not in STOPWORDS]) for text in preprocessed_texts]\n\n    # Create a document-term matrix (DTM)\n    vectorizer = CountVectorizer()\n    dtm = vectorizer.fit_transform(preprocessed_texts)\n\n    # Convert the DTM to a DataFrame\n    dtm_df = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n\n    return dtm_df\ntexts = ['This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?']", "raw_solution": "import re\nimport nltk\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Make sure to download NLTK stopwords\nnltk.download('stopwords')\n\n# Define a regex pattern for matching all non-alphanumeric characters\nALPHANUMERIC = re.compile('[\\W_]+')\n\n# Load NLTK's list of English stop words\nSTOPWORDS = nltk.corpus.stopwords.words('english')\n\ndef task_func(texts):\n    # Preprocessing: remove non-alphanumeric characters, convert to lowercase, and remove stop words\n    preprocessed_texts = [ALPHANUMERIC.sub(' ', text.lower()) for text in texts]\n    preprocessed_texts = [' '.join([word for word in text.split() if word not in STOPWORDS]) for text in preprocessed_texts]\n\n    # Create a document-term matrix (DTM)\n    vectorizer = CountVectorizer()\n    dtm = vectorizer.fit_transform(preprocessed_texts)\n\n    # Convert the DTM to a DataFrame\n    dtm_df = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n\n    return dtm_df\n\n# Test the function\ntexts = ['This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?']"}
{"task_id": "BigCodeBench/659", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\ndef task_func(x, y, labels):\n    # Create a new figure\n    fig, ax = plt.subplots(figsize=(10, 7))\n\n    # Check if the lengths of x, y and labels are equal\n    if len(x) != len(y) or len(x) != len(labels):\n        raise ValueError(\"x, y and labels should have the same length\")\n\n    # Plot the normal distributions\n    for i in range(len(x)):\n        mu, sigma = x[i], y[i]\n        x_axis = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n        ax.plot(x_axis, stats.norm.pdf(x_axis, mu, sigma), label=labels[i])\n\n    # Set labels and title\n    ax.set_xlabel('x')\n    ax.set_ylabel('Probability Density')\n    ax.set_title('Normal Distribution')\n    ax.legend()\n\n    return fig", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\n\ndef task_func(x, y, labels):\n    # Create a new figure\n    fig, ax = plt.subplots(figsize=(10, 7))\n\n    # Check if the lengths of x, y and labels are equal\n    if len(x) != len(y) or len(x) != len(labels):\n        raise ValueError(\"x, y and labels should have the same length\")\n\n    # Plot the normal distributions\n    for i in range(len(x)):\n        mu, sigma = x[i], y[i]\n        x_axis = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n        ax.plot(x_axis, stats.norm.pdf(x_axis, mu, sigma), label=labels[i])\n\n    # Set labels and title\n    ax.set_xlabel('x')\n    ax.set_ylabel('Probability Density')\n    ax.set_title('Normal Distribution')\n    ax.legend()\n\n    return fig"}
{"task_id": "BigCodeBench/660", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(x, y, labels):\n    # Initialize StandardScaler\n    scaler = StandardScaler()\n\n    # Scale x and y arrays independently\n    x_scaled = scaler.fit_transform(x)\n    y_scaled = scaler.fit_transform(y)\n\n    # Create a new figure\n    fig = plt.figure()\n\n    # Plot the scaled x and y arrays with corresponding labels\n    plt.plot(x_scaled, label=labels[0])\n    plt.plot(y_scaled, label=labels[1])\n\n    # Add legend to the plot\n    plt.legend()\n\n    return fig", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(x, y, labels):\n    # Initialize StandardScaler\n    scaler = StandardScaler()\n\n    # Scale x and y arrays independently\n    x_scaled = scaler.fit_transform(x)\n    y_scaled = scaler.fit_transform(y)\n\n    # Create a new figure\n    fig = plt.figure()\n\n    # Plot the scaled x and y arrays with corresponding labels\n    plt.plot(x_scaled, label=labels[0])\n    plt.plot(y_scaled, label=labels[1])\n\n    # Add legend to the plot\n    plt.legend()\n\n    return fig"}
{"task_id": "BigCodeBench/661", "solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nLABELS = ['H\\u2082O', 'O\\u2082', 'CO\\u2082', 'N\\u2082', 'Ar']\ndef task_func(x, y, labels):\n    # Create a DataFrame from the input data\n    df = pd.DataFrame({'x': x, 'y': y}, columns=['x', 'y'])\n\n    # Create a heatmap using seaborn\n    ax = sns.heatmap(df, annot=True, fmt=\"d\", cmap='viridis', xticklabels=labels, yticklabels=labels)\n\n    return ax, df\nx = [1, 2, 3, 4, 5]\ny = [1, 2, 3, 4, 5]\nlabels = LABELS", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nLABELS = ['H\\u2082O', 'O\\u2082', 'CO\\u2082', 'N\\u2082', 'Ar']\n\ndef task_func(x, y, labels):\n    # Create a DataFrame from the input data\n    df = pd.DataFrame({'x': x, 'y': y}, columns=['x', 'y'])\n\n    # Create a heatmap using seaborn\n    ax = sns.heatmap(df, annot=True, fmt=\"d\", cmap='viridis', xticklabels=labels, yticklabels=labels)\n\n    return ax, df\n\n# Test the function\nx = [1, 2, 3, 4, 5]\ny = [1, 2, 3, 4, 5]\nlabels = LABELS\nax, df = task_func(x, y, labels)\n\nplt.show()"}
{"task_id": "BigCodeBench/662", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(x, y, labels):\n    # Combine x, y and labels into a single array\n    data = np.column_stack((x, y, labels))\n\n    # Perform PCA\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(data)\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1], c=labels)\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    ax.set_title('PCA on x and y')\n\n    return fig", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(x, y, labels):\n    # Combine x, y and labels into a single array\n    data = np.column_stack((x, y, labels))\n\n    # Perform PCA\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(data)\n\n    # Create a scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1], c=labels)\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    ax.set_title('PCA on x and y')\n\n    return fig"}
{"task_id": "BigCodeBench/663", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\ndef exp_func(x, a, b, c):\n    return a * np.exp(-b * x) + c\ndef task_func(x, y, labels):\n    # Create a new figure\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n\n    # Plot the original data points\n    for i in range(len(x)):\n        ax.scatter(x[i], y[i], label=labels[i])\n\n    # Fit an exponential curve to each set of data points\n    for i in range(len(x)):\n        popt, _ = curve_fit(exp_func, x[i], y[i])\n        ax.plot(x[i], exp_func(x[i], *popt), label='Fit '+labels[i])\n\n    ax.legend()\n    plt.show()\n\n    return fig\nx = [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]]\ny = [[2.5, 2.2, 1.8, 1.5, 1.2, 1], [10, 20, 30, 20, 10, 0]]\nlabels = ['Set 1', 'Set 2']", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n\ndef exp_func(x, a, b, c):\n    return a * np.exp(-b * x) + c\n\ndef task_func(x, y, labels):\n    # Create a new figure\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n\n    # Plot the original data points\n    for i in range(len(x)):\n        ax.scatter(x[i], y[i], label=labels[i])\n\n    # Fit an exponential curve to each set of data points\n    for i in range(len(x)):\n        popt, _ = curve_fit(exp_func, x[i], y[i])\n        ax.plot(x[i], exp_func(x[i], *popt), label='Fit '+labels[i])\n\n    ax.legend()\n    plt.show()\n\n    return fig\n\n# Test the function\nx = [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]]\ny = [[2.5, 2.2, 1.8, 1.5, 1.2, 1], [10, 20, 30, 20, 10, 0]]\nlabels = ['Set 1', 'Set 2']\nfig = task_func(x, y, labels)"}
{"task_id": "BigCodeBench/664", "solution": "import statistics\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(sales_data):\n    # Extract product names and sales data\n    product_names = list(sales_data.keys())\n    sales_values = list(sales_data.values())\n\n    # Create a figure and an axis\n    fig, ax = plt.subplots()\n\n    # Calculate mean and standard deviation for each product\n    means = [np.mean(sales) for sales in sales_values]\n    std_devs = [np.std(sales) for sales in sales_values]\n\n    # Plot sales data\n    for i in range(len(product_names)):\n        ax.plot('Month', sales_values[i], data=pd.DataFrame(sales_values[i], columns=['Sales'], index=pd.Series(range(1,13), name='Month')), label=product_names[i])\n\n    # Add shading for standard deviation\n    for i in range(len(product_names)):\n        ax.fill_between('Month', np.array(means[i]-std_devs[i]), np.array(means[i]+std_devs[i]), alpha=0.2, label='_nolegend_')\n\n    # Set labels and title\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Sales')\n    ax.set_title('Sales Trends for Five Products')\n    ax.legend(loc='upper left')\n\n    # Return the axes object\n    return ax", "raw_solution": "import statistics\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(sales_data):\n    # Extract product names and sales data\n    product_names = list(sales_data.keys())\n    sales_values = list(sales_data.values())\n\n    # Create a figure and an axis\n    fig, ax = plt.subplots()\n\n    # Calculate mean and standard deviation for each product\n    means = [np.mean(sales) for sales in sales_values]\n    std_devs = [np.std(sales) for sales in sales_values]\n\n    # Plot sales data\n    for i in range(len(product_names)):\n        ax.plot('Month', sales_values[i], data=pd.DataFrame(sales_values[i], columns=['Sales'], index=pd.Series(range(1,13), name='Month')), label=product_names[i])\n\n    # Add shading for standard deviation\n    for i in range(len(product_names)):\n        ax.fill_between('Month', np.array(means[i]-std_devs[i]), np.array(means[i]+std_devs[i]), alpha=0.2, label='_nolegend_')\n\n    # Set labels and title\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Sales')\n    ax.set_title('Sales Trends for Five Products')\n    ax.legend(loc='upper left')\n\n    # Return the axes object\n    return ax"}
{"task_id": "BigCodeBench/665", "solution": "import shutil\nimport os\nimport fnmatch\nimport itertools\ndef task_func(src_dir, dst_dir):\n    # Define the patterns to match\n    patterns = ['*.txt', '*.docx']\n\n    # Iterate over each pattern\n    for pattern in patterns:\n        # Get a list of all files in the source directory that match the pattern\n        for file_name in fnmatch.filter(os.listdir(src_dir), pattern):\n            # Construct the full path to the file\n            src_file = os.path.join(src_dir, file_name)\n            # Copy the file to the destination directory\n            shutil.copy2(src_file, dst_dir)\n\n    # Return the destination directory\n    return dst_dir", "raw_solution": "import shutil\nimport os\nimport fnmatch\nimport itertools\n\ndef task_func(src_dir, dst_dir):\n    # Define the patterns to match\n    patterns = ['*.txt', '*.docx']\n\n    # Iterate over each pattern\n    for pattern in patterns:\n        # Get a list of all files in the source directory that match the pattern\n        for file_name in fnmatch.filter(os.listdir(src_dir), pattern):\n            # Construct the full path to the file\n            src_file = os.path.join(src_dir, file_name)\n            # Copy the file to the destination directory\n            shutil.copy2(src_file, dst_dir)\n\n    # Return the destination directory\n    return dst_dir"}
{"task_id": "BigCodeBench/666", "solution": "from itertools import combinations\nimport math\ndef task_func(seq, letter_weight_dict):\n    max_weight = 0\n    max_subseq = ''\n    for i in range(len(seq), 0, -1):\n        for subset in combinations(seq, i):\n            subset_weight = sum(letter_weight_dict[letter] for letter in subset)\n            if subset_weight > max_weight:\n                max_weight = subset_weight\n                max_subseq = ''.join(subset)\n    return max_subseq\nletter_weight_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5}\nseq = 'abcde'", "raw_solution": "from itertools import combinations\nimport math\n\ndef task_func(seq, letter_weight_dict):\n    max_weight = 0\n    max_subseq = ''\n    for i in range(len(seq), 0, -1):\n        for subset in combinations(seq, i):\n            subset_weight = sum(letter_weight_dict[letter] for letter in subset)\n            if subset_weight > max_weight:\n                max_weight = subset_weight\n                max_subseq = ''.join(subset)\n    return max_subseq\n\n# Test the function\nletter_weight_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5}\nseq = 'abcde'"}
{"task_id": "BigCodeBench/667", "solution": "import heapq\nimport collections\ndef task_func(x, n):\n    # Count the frequency of each letter in the dictionary\n    counter = collections.Counter(x)\n    # Use a heap to get the n most common letters\n    most_common = heapq.nlargest(n, counter.items(), key=lambda x: x[1])\n    # Return the letters as a list\n    return [letter for letter, freq in most_common]", "raw_solution": "import heapq\nimport collections\n\ndef task_func(x, n):\n    # Count the frequency of each letter in the dictionary\n    counter = collections.Counter(x)\n    # Use a heap to get the n most common letters\n    most_common = heapq.nlargest(n, counter.items(), key=lambda x: x[1])\n    # Return the letters as a list\n    return [letter for letter, freq in most_common]\n\n# Test the function\ndictionary = {'a': 5, 'b': 3, 'c': 2, 'd': 4, 'e': 1}"}
{"task_id": "BigCodeBench/668", "solution": "import itertools\nimport math\ndef task_func(x):\n    # Sort the dictionary by values\n    x = dict(sorted(x.items(), key=lambda item: item[1]))\n\n    # Initialize minimum length to infinity and subsequence to empty list\n    min_length = math.inf\n    min_subsequence = []\n\n    # Iterate over all possible subsequences of the dictionary\n    for L in range(0, len(x)+1):\n        for subset in itertools.combinations(x, L):\n            # Calculate the total length of the current subsequence\n            total_length = sum(x[key] for key in subset)\n            # If the total length is less than the current minimum, update the minimum and subsequence\n            if total_length < min_length:\n                min_length = total_length\n                min_subsequence = list(subset)\n\n    # Return the subsequence with the minimum total length\n    return min_subsequence\nx = {'a': 3, 'b': 2, 'c': 1, 'd': 4, 'e': 5}", "raw_solution": "import itertools\nimport math\n\ndef task_func(x):\n    # Sort the dictionary by values\n    x = dict(sorted(x.items(), key=lambda item: item[1]))\n\n    # Initialize minimum length to infinity and subsequence to empty list\n    min_length = math.inf\n    min_subsequence = []\n\n    # Iterate over all possible subsequences of the dictionary\n    for L in range(0, len(x)+1):\n        for subset in itertools.combinations(x, L):\n            # Calculate the total length of the current subsequence\n            total_length = sum(x[key] for key in subset)\n            # If the total length is less than the current minimum, update the minimum and subsequence\n            if total_length < min_length:\n                min_length = total_length\n                min_subsequence = list(subset)\n\n    # Return the subsequence with the minimum total length\n    return min_subsequence\n\n# Test the function\nx = {'a': 3, 'b': 2, 'c': 1, 'd': 4, 'e': 5}"}
{"task_id": "BigCodeBench/669", "solution": "import itertools\nimport math\ndef task_func(x):\n    max_cos_sum = -2\n    max_keys = ()\n    for keys in itertools.combinations(x.keys(), 2):\n        cos_sum = math.cos(x[keys[0]]) + math.cos(x[keys[1]])\n        if cos_sum > max_cos_sum:\n            max_cos_sum = cos_sum\n            max_keys = keys\n    return max_cos_sum, max_keys\nx = {1: 0.5, 2: 1.5, 3: 2.5, 4: 0.7}", "raw_solution": "import itertools\nimport math\n\ndef task_func(x):\n    max_cos_sum = -2\n    max_keys = ()\n    for keys in itertools.combinations(x.keys(), 2):\n        cos_sum = math.cos(x[keys[0]]) + math.cos(x[keys[1]])\n        if cos_sum > max_cos_sum:\n            max_cos_sum = cos_sum\n            max_keys = keys\n    return max_cos_sum, max_keys\n\n# Test the function\nx = {1: 0.5, 2: 1.5, 3: 2.5, 4: 0.7}"}
{"task_id": "BigCodeBench/670", "solution": "from itertools import combinations\ndef task_func(x, w):\n    max_weight = 0\n    max_substr = ''\n    for i in range(len(x), 0, -1):\n        for c in combinations(x, i):\n            c_str = ''.join(c)\n            weight = sum(w.get(char, 0) for char in c_str)\n            if weight > max_weight:\n                max_weight = weight\n                max_substr = c_str\n    return max_substr\nw = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\nx = 'abcd'", "raw_solution": "from itertools import combinations\n\ndef task_func(x, w):\n    max_weight = 0\n    max_substr = ''\n    for i in range(len(x), 0, -1):\n        for c in combinations(x, i):\n            c_str = ''.join(c)\n            weight = sum(w.get(char, 0) for char in c_str)\n            if weight > max_weight:\n                max_weight = weight\n                max_substr = c_str\n    return max_substr\n\n# Test the function\nw = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\nx = 'abcd'"}
{"task_id": "BigCodeBench/671", "solution": "import os\nimport random\nimport json\ndef task_func(directory, n):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    for i in range(n):\n        file_name = os.path.join(directory, f'file_{i}.json')\n        with open(file_name, 'w') as file:\n            data = {'number': random.randint(1, 100)}\n            json.dump(data, file)\n\n    return directory", "raw_solution": "import os\nimport random\nimport json\n\ndef task_func(directory, n):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    for i in range(n):\n        file_name = os.path.join(directory, f'file_{i}.json')\n        with open(file_name, 'w') as file:\n            data = {'number': random.randint(1, 100)}\n            json.dump(data, file)\n\n    return directory"}
{"task_id": "BigCodeBench/672", "solution": "import csv\nimport sys\ndef task_func(filename):\n    try:\n        with open(filename, 'r') as file:\n            lines = file.readlines()\n\n        with open(filename, 'w') as file:\n            for line in reversed(lines):\n                file.write(line)\n\n        with open(filename, 'r+') as file:\n            file.seek(0)\n\n    except FileNotFoundError:\n        print(f\"File {filename} not found.\")\n        sys.exit(1)\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        sys.exit(1)\n\n    print(f\"File {filename} processed successfully.\")", "raw_solution": "import csv\nimport sys\n\ndef task_func(filename):\n    try:\n        with open(filename, 'r') as file:\n            lines = file.readlines()\n\n        with open(filename, 'w') as file:\n            for line in reversed(lines):\n                file.write(line)\n\n        with open(filename, 'r+') as file:\n            file.seek(0)\n\n    except FileNotFoundError:\n        print(f\"File {filename} not found.\")\n        sys.exit(1)\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        sys.exit(1)\n\n    print(f\"File {filename} processed successfully.\")\n\n# Test the function\ntask_func('test.csv')"}
{"task_id": "BigCodeBench/673", "solution": "import os\nimport random\ndef task_func(directory, n_files):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    for i in range(n_files):\n        filename = os.path.join(directory, f'file_{i+1}.txt')\n        with open(filename, 'w') as f:\n            f.write(str(random.randint(0, 9)))\n        f.seek(0)\n\n    return n_files", "raw_solution": "import os\nimport random\n\ndef task_func(directory, n_files):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    for i in range(n_files):\n        filename = os.path.join(directory, f'file_{i+1}.txt')\n        with open(filename, 'w') as f:\n            f.write(str(random.randint(0, 9)))\n        f.seek(0)\n\n    return n_files\n\n# Test the function\nn_files = task_func('test_directory', 5)"}
{"task_id": "BigCodeBench/674", "solution": "import pandas as pd\nimport os\ndef task_func(filename):\n    if os.path.exists(filename):\n        # Read the CSV file\n        df = pd.read_csv(filename)\n\n        # Reverse the order of the lines\n        df = df.iloc[::-1]\n\n        # Write the inverted lines back into the file\n        df.to_csv(filename, index=False)\n\n        # Move the cursor back to the beginning of the file\n        with open(filename, 'r+') as f:\n            f.seek(0)\n    else:\n        print(f\"File {filename} does not exist.\")", "raw_solution": "import pandas as pd\nimport os\n\ndef task_func(filename):\n    if os.path.exists(filename):\n        # Read the CSV file\n        df = pd.read_csv(filename)\n\n        # Reverse the order of the lines\n        df = df.iloc[::-1]\n\n        # Write the inverted lines back into the file\n        df.to_csv(filename, index=False)\n\n        # Move the cursor back to the beginning of the file\n        with open(filename, 'r+') as f:\n            f.seek(0)\n    else:\n        print(f\"File {filename} does not exist.\")\n\n# Test the function\ntask_func('test.csv')"}
{"task_id": "BigCodeBench/675", "solution": "import os\nimport random\nimport string\ndef task_func(directory, n_files):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    for i in range(n_files):\n        filename = os.path.join(directory, f'file_{i}.txt')\n        with open(filename, 'w') as f:\n            random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n            f.write(random_string)\n\n    return directory", "raw_solution": "import os\nimport random\nimport string\n\ndef task_func(directory, n_files):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    for i in range(n_files):\n        filename = os.path.join(directory, f'file_{i}.txt')\n        with open(filename, 'w') as f:\n            random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n            f.write(random_string)\n\n    return directory\n\n# Test the function"}
{"task_id": "BigCodeBench/676", "solution": "import pandas as pd\nimport random\ndef task_func(df):\n    # Add a 'winner' column to the DataFrame\n    df['winner'] = df.apply(lambda row: random.choice([row['team1'], row['team2']]) if row['score1'] == row['score2'] else (row['team1'] if row['score1'] > row['score2'] else row['team2']), axis=1)\n    return df\ndf = pd.DataFrame({\n    'team1': ['TeamA', 'TeamB', 'TeamC', 'TeamD'],\n    'score1': [5, 7, 7, 3],\n    'team2': ['TeamB', 'TeamC', 'TeamD', 'TeamA'],\n    'score2': [2, 2, 8, 1]\n})", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(df):\n    # Add a 'winner' column to the DataFrame\n    df['winner'] = df.apply(lambda row: random.choice([row['team1'], row['team2']]) if row['score1'] == row['score2'] else (row['team1'] if row['score1'] > row['score2'] else row['team2']), axis=1)\n    return df\n\n# Test the function\ndf = pd.DataFrame({\n    'team1': ['TeamA', 'TeamB', 'TeamC', 'TeamD'],\n    'score1': [5, 7, 7, 3],\n    'team2': ['TeamB', 'TeamC', 'TeamD', 'TeamA'],\n    'score2': [2, 2, 8, 1]\n})\n"}
{"task_id": "BigCodeBench/677", "solution": "import numpy as np\nimport pandas as pd\nfrom scipy.stats import linregress\ndef task_func(df):\n    # Check if the DataFrame has at least two columns\n    if len(df.columns) < 2:\n        raise ValueError(\"The DataFrame should have at least two columns.\")\n\n    # Get the names of the first two columns\n    x_col, y_col = df.columns[0], df.columns[1]\n\n    # Perform a linear regression\n    slope, intercept, r_value, p_value, std_err = linregress(df[x_col], df[y_col])\n\n    # Add a 'predicted' column to the DataFrame\n    df['predicted'] = intercept + slope * df[x_col]\n\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom scipy.stats import linregress\n\ndef task_func(df):\n    # Check if the DataFrame has at least two columns\n    if len(df.columns) < 2:\n        raise ValueError(\"The DataFrame should have at least two columns.\")\n\n    # Get the names of the first two columns\n    x_col, y_col = df.columns[0], df.columns[1]\n\n    # Perform a linear regression\n    slope, intercept, r_value, p_value, std_err = linregress(df[x_col], df[y_col])\n\n    # Add a 'predicted' column to the DataFrame\n    df['predicted'] = intercept + slope * df[x_col]\n\n    return df"}
{"task_id": "BigCodeBench/678", "solution": "import pandas as pd\nimport json\nimport os\nimport shutil\ndef task_func(path):\n    # Check if the path exists, if not create it\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n    # Check if the processed directory exists, if not create it\n    processed_dir = os.path.join(path, 'processed')\n    if not os.path.exists(processed_dir):\n        os.makedirs(processed_dir)\n\n    # Get a list of all json files in the directory\n    json_files = [f for f in os.listdir(path) if f.endswith('.json')]\n\n    # Sort the files alphabetically\n    json_files.sort()\n\n    # Initialize an empty DataFrame\n    df = pd.DataFrame()\n\n    # Loop over all json files\n    for file in json_files:\n        # Read the json file into a DataFrame\n        temp_df = pd.read_json(os.path.join(path, file), orient='records')\n\n        # Add a 'Source' column with the filename\n        temp_df['Source'] = file\n\n        # Append the DataFrame to the main DataFrame\n        df = df.append(temp_df, ignore_index=True)\n\n        # Move the processed file to the processed directory\n        shutil.move(os.path.join(path, file), os.path.join(processed_dir, file))\n\n    return df", "raw_solution": "import pandas as pd\nimport json\nimport os\nimport shutil\n\ndef task_func(path):\n    # Check if the path exists, if not create it\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n    # Check if the processed directory exists, if not create it\n    processed_dir = os.path.join(path, 'processed')\n    if not os.path.exists(processed_dir):\n        os.makedirs(processed_dir)\n\n    # Get a list of all json files in the directory\n    json_files = [f for f in os.listdir(path) if f.endswith('.json')]\n\n    # Sort the files alphabetically\n    json_files.sort()\n\n    # Initialize an empty DataFrame\n    df = pd.DataFrame()\n\n    # Loop over all json files\n    for file in json_files:\n        # Read the json file into a DataFrame\n        temp_df = pd.read_json(os.path.join(path, file), orient='records')\n\n        # Add a 'Source' column with the filename\n        temp_df['Source'] = file\n\n        # Append the DataFrame to the main DataFrame\n        df = df.append(temp_df, ignore_index=True)\n\n        # Move the processed file to the processed directory\n        shutil.move(os.path.join(path, file), os.path.join(processed_dir, file))\n\n    return df"}
{"task_id": "BigCodeBench/679", "solution": "import pandas as pd\nfrom collections import Counter\nfrom itertools import combinations\ndef task_func(df):\n    # Add a 'combination' column to the DataFrame\n    df['combination'] = df.apply(lambda row: tuple(sorted(combinations(row.dropna().values, 2))), axis=1)\n\n    # Flatten the list of combinations and count the frequency\n    all_combinations = [item for sublist in df['combination'].tolist() for item in sublist]\n    frequency_dict = dict(Counter(all_combinations))\n\n    return frequency_dict", "raw_solution": "import pandas as pd\nfrom collections import Counter\nfrom itertools import combinations\n\ndef task_func(df):\n    # Add a 'combination' column to the DataFrame\n    df['combination'] = df.apply(lambda row: tuple(sorted(combinations(row.dropna().values, 2))), axis=1)\n\n    # Flatten the list of combinations and count the frequency\n    all_combinations = [item for sublist in df['combination'].tolist() for item in sublist]\n    frequency_dict = dict(Counter(all_combinations))\n\n    return frequency_dict"}
{"task_id": "BigCodeBench/680", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, features):\n    # Initialize a StandardScaler\n    scaler = StandardScaler()\n\n    # Fit and transform the features\n    df[features] = scaler.fit_transform(df[features])\n\n    return df\ndf = pd.DataFrame({\n    'feature1': [1, 2, 3, 4, 5],\n    'feature2': [10, 20, 30, 40, 50],\n    'feature3': [100, 200, 300, 400, 500]\n})", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, features):\n    # Initialize a StandardScaler\n    scaler = StandardScaler()\n\n    # Fit and transform the features\n    df[features] = scaler.fit_transform(df[features])\n\n    return df\n\n# Test the function\n# Create a sample DataFrame\ndf = pd.DataFrame({\n    'feature1': [1, 2, 3, 4, 5],\n    'feature2': [10, 20, 30, 40, 50],\n    'feature3': [100, 200, 300, 400, 500]\n})\n\n# Standardize the features\ndf = task_func(df, ['feature1', 'feature2', 'feature3'])\n\n# Print the standardized DataFrame"}
{"task_id": "BigCodeBench/681", "solution": "import pandas as pd\nimport json\ndef task_func(file_path, key):\n    # Load JSON file into a DataFrame\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    df = pd.DataFrame(data)\n\n    # Remove specific key from each object\n    df = df.drop(key, axis=1, errors='ignore')\n\n    # Write the processed DataFrame back into a JSON file\n    df.to_json(file_path, orient='records', indent=4)\n\n    return df", "raw_solution": "import pandas as pd\nimport json\n\ndef task_func(file_path, key):\n    # Load JSON file into a DataFrame\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    df = pd.DataFrame(data)\n\n    # Remove specific key from each object\n    df = df.drop(key, axis=1, errors='ignore')\n\n    # Write the processed DataFrame back into a JSON file\n    df.to_json(file_path, orient='records', indent=4)\n\n    return df"}
{"task_id": "BigCodeBench/682", "solution": "from collections import Counter\nimport math\ndef task_func(nested_dict):\n    # Flatten the dictionary and remove \"ele\" key\n    flat_dict = {k: v for k, v in nested_dict.items() if k != \"ele\"}\n\n    # Aggregate the values of the same keys\n    aggregated_dict = dict(Counter(flat_dict))\n\n    # Take the sine of each value\n    result_dict = {k: math.sin(v) for k, v in aggregated_dict.items()}\n\n    return result_dict\nnested_dict = {\"ele\": 1, \"one\": 2, \"two\": 2, \"three\": 3, \"ele\": 1}", "raw_solution": "from collections import Counter\nimport math\n\ndef task_func(nested_dict):\n    # Flatten the dictionary and remove \"ele\" key\n    flat_dict = {k: v for k, v in nested_dict.items() if k != \"ele\"}\n\n    # Aggregate the values of the same keys\n    aggregated_dict = dict(Counter(flat_dict))\n\n    # Take the sine of each value\n    result_dict = {k: math.sin(v) for k, v in aggregated_dict.items()}\n\n    return result_dict\n\n# Test the function\nnested_dict = {\"ele\": 1, \"one\": 2, \"two\": 2, \"three\": 3, \"ele\": 1}"}
{"task_id": "BigCodeBench/683", "solution": "import math\nimport yaml\ndef task_func(yaml_path, key):\n    with open(yaml_path, 'r') as file:\n        data = yaml.safe_load(file)\n\n    if key in data:\n        data[key] = math.cos(data[key])\n    else:\n        raise KeyError(f\"The key '{key}' does not exist in the YAML file.\")\n\n    with open(yaml_path, 'w') as file:\n        yaml.safe_dump(data, file)\n\n    return data", "raw_solution": "import math\nimport yaml\n\ndef task_func(yaml_path, key):\n    with open(yaml_path, 'r') as file:\n        data = yaml.safe_load(file)\n\n    if key in data:\n        data[key] = math.cos(data[key])\n    else:\n        raise KeyError(f\"The key '{key}' does not exist in the YAML file.\")\n\n    with open(yaml_path, 'w') as file:\n        yaml.safe_dump(data, file)\n\n    return data"}
{"task_id": "BigCodeBench/684", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(df, col):\n    if col in df.columns:\n        df = df.drop(columns=col)\n    df['IsEvenIndex'] = df.index % 2 == 0\n    return df\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500]\n})", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(df, col):\n    if col in df.columns:\n        df = df.drop(columns=col)\n    df['IsEvenIndex'] = df.index % 2 == 0\n    return df\n\n# Test the function\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500]\n})\n\ndf = task_func(df, 'B')"}
{"task_id": "BigCodeBench/685", "solution": "from collections import Counter\nfrom itertools import chain\ndef task_func(list_of_lists):\n    # Merge all sublists into one using chain function\n    merged_list = list(chain(*list_of_lists))\n    \n    # Count the elements using Counter\n    count_dict = Counter(merged_list)\n    \n    return count_dict, len(merged_list)\nlist_of_lists = [[1, 2, 3], ['a', 'b', 'c'], [1, 'a', 'b']]", "raw_solution": "from collections import Counter\nfrom itertools import chain\n\ndef task_func(list_of_lists):\n    # Merge all sublists into one using chain function\n    merged_list = list(chain(*list_of_lists))\n    \n    # Count the elements using Counter\n    count_dict = Counter(merged_list)\n    \n    return count_dict, len(merged_list)\n\n# Test the function\nlist_of_lists = [[1, 2, 3], ['a', 'b', 'c'], [1, 'a', 'b']]\ncount_dict, count = task_func(list_of_lists)"}
{"task_id": "BigCodeBench/686", "solution": "import numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\ndef task_func(list_of_lists):\n    # Merge the lists\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    \n    # Convert the merged list to numpy array\n    merged_array = np.array(merged_list).reshape(-1, 1)\n    \n    # Initialize OneHotEncoder\n    enc = OneHotEncoder(sparse=False)\n    \n    # Fit and transform the data\n    one_hot = enc.fit_transform(merged_array)\n    \n    return one_hot\nlist_of_lists = [[1, 2, 3], ['a', 'b', 'c'], ['red', 'blue', 'green']]", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\n\ndef task_func(list_of_lists):\n    # Merge the lists\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    \n    # Convert the merged list to numpy array\n    merged_array = np.array(merged_list).reshape(-1, 1)\n    \n    # Initialize OneHotEncoder\n    enc = OneHotEncoder(sparse=False)\n    \n    # Fit and transform the data\n    one_hot = enc.fit_transform(merged_array)\n    \n    return one_hot\n\n# Test the function\nlist_of_lists = [[1, 2, 3], ['a', 'b', 'c'], ['red', 'blue', 'green']]"}
{"task_id": "BigCodeBench/687", "solution": "import numpy as np\nfrom scipy.stats import mode\ndef task_func(list_of_lists):\n    # Merge the lists\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    \n    # Convert the merged list to numpy array\n    merged_array = np.array(merged_list)\n    \n    # Find the mode\n    mode_value = mode(merged_array)[0][0]\n    mode_count = mode(merged_array)[0][1]\n    \n    # Return the mode and count as a tuple and the mode value and count as separate variables\n    return (mode_value, mode_count), mode_value, mode_count\nlist_of_lists = [[1, 2, 2, 3], [2, 2, 4], [3, 4, 4, 4, 5, 5, 5]]", "raw_solution": "import numpy as np\nfrom scipy.stats import mode\n\ndef task_func(list_of_lists):\n    # Merge the lists\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    \n    # Convert the merged list to numpy array\n    merged_array = np.array(merged_list)\n    \n    # Find the mode\n    mode_value = mode(merged_array)[0][0]\n    mode_count = mode(merged_array)[0][1]\n    \n    # Return the mode and count as a tuple and the mode value and count as separate variables\n    return (mode_value, mode_count), mode_value, mode_count\n\n# Test the function\nlist_of_lists = [[1, 2, 2, 3], [2, 2, 4], [3, 4, 4, 4, 5, 5, 5]]"}
{"task_id": "BigCodeBench/688", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    scaler = StandardScaler()\n    df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df_standardized\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500]\n})", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    scaler = StandardScaler()\n    df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df_standardized\n\n# Test the function\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500]\n})\n"}
{"task_id": "BigCodeBench/689", "solution": "import numpy as np\nimport pandas as pd\nfrom scipy import stats\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input should be a pandas DataFrame\")\n\n    p_values = {}\n\n    for col in df.columns:\n        if pd.api.types.is_numeric_dtype(df[col]):\n            _, p_value = stats.shapiro(df[col].dropna())\n            p_values[col] = p_value\n        else:\n            print(f\"Column {col} is not numeric. Skipping...\")\n\n    return p_values", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input should be a pandas DataFrame\")\n\n    p_values = {}\n\n    for col in df.columns:\n        if pd.api.types.is_numeric_dtype(df[col]):\n            _, p_value = stats.shapiro(df[col].dropna())\n            p_values[col] = p_value\n        else:\n            print(f\"Column {col} is not numeric. Skipping...\")\n\n    return p_values"}
{"task_id": "BigCodeBench/690", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\nROWS = 100\nCOLUMNS = ['X', 'Y']\ndef task_func(df):\n    # Create a linear regression model\n    model = LinearRegression()\n\n    # Fit the model to the data\n    model.fit(df[['X']], df['Y'])\n\n    return model\ndf = pd.DataFrame(np.random.rand(ROWS, len(COLUMNS)), columns=COLUMNS)", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\nROWS = 100\nCOLUMNS = ['X', 'Y']\n\ndef task_func(df):\n    # Create a linear regression model\n    model = LinearRegression()\n\n    # Fit the model to the data\n    model.fit(df[['X']], df['Y'])\n\n    return model\n\n# Create a DataFrame with random numeric values\nnp.random.seed(0)\ndf = pd.DataFrame(np.random.rand(ROWS, len(COLUMNS)), columns=COLUMNS)\n\n# Call the function with the DataFrame\nmodel = task_func(df)\n\n# Print the coefficients of the fitted model"}
{"task_id": "BigCodeBench/691", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\ndef task_func(df):\n    # Standardize the data\n    scaler = StandardScaler()\n    df_std = scaler.fit_transform(df)\n\n    # Initialize KMeans\n    kmeans = KMeans(n_clusters=3)\n\n    # Fit and predict\n    labels = kmeans.fit_predict(df_std)\n\n    return labels", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\ndef task_func(df):\n    # Standardize the data\n    scaler = StandardScaler()\n    df_std = scaler.fit_transform(df)\n\n    # Initialize KMeans\n    kmeans = KMeans(n_clusters=3)\n\n    # Fit and predict\n    labels = kmeans.fit_predict(df_std)\n\n    return labels"}
{"task_id": "BigCodeBench/692", "solution": "import math\nimport pandas as pd\ndef task_func(tuples_list):\n    df = pd.DataFrame(tuples_list, columns=['A', 'B', 'C'])\n    df = df.applymap(math.sin)\n    return df\ntuples_list = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]", "raw_solution": "import math\nimport pandas as pd\n\ndef task_func(tuples_list):\n    df = pd.DataFrame(tuples_list, columns=['A', 'B', 'C'])\n    df = df.applymap(math.sin)\n    return df\n\n# Test the function\ntuples_list = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]\ndf = task_func(tuples_list)"}
{"task_id": "BigCodeBench/693", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(tuples_list, columns):\n    # Convert the list of tuples into a DataFrame\n    df = pd.DataFrame(tuples_list, columns=columns)\n\n    # Initialize a StandardScaler\n    scaler = StandardScaler()\n\n    # Fit and transform the DataFrame\n    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=columns)\n\n    return df_scaled\ntuples_list = [(1, 2), (3, 4), (5, 6)]\ncolumns = ['column1', 'column2']", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(tuples_list, columns):\n    # Convert the list of tuples into a DataFrame\n    df = pd.DataFrame(tuples_list, columns=columns)\n\n    # Initialize a StandardScaler\n    scaler = StandardScaler()\n\n    # Fit and transform the DataFrame\n    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=columns)\n\n    return df_scaled\n\n# Test the function\ntuples_list = [(1, 2), (3, 4), (5, 6)]\ncolumns = ['column1', 'column2']"}
{"task_id": "BigCodeBench/694", "solution": "import itertools\nimport random\ndef task_func(t, n):\n    # Generate all combinations from a tuple with length n\n    combinations = list(itertools.product(t, repeat=n))\n\n    # Return a random combination of length n\n    return random.choice(combinations)\nt = ('a', 'b', 'c')\nn = 2", "raw_solution": "import itertools\nimport random\n\ndef task_func(t, n):\n    # Generate all combinations from a tuple with length n\n    combinations = list(itertools.product(t, repeat=n))\n\n    # Return a random combination of length n\n    return random.choice(combinations)\n\n# Test the function\nt = ('a', 'b', 'c')\nn = 2"}
{"task_id": "BigCodeBench/695", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\ndef task_func(tuples_list, n_components):\n    # Convert the list of tuples to numpy array\n    data = np.array(tuples_list)\n\n    # Initialize PCA with n_components\n    pca = PCA(n_components=n_components)\n\n    # Fit and transform the data\n    transformed_data = pca.fit_transform(data)\n\n    return transformed_data\ntuples_list = [(1, 2), (3, 4), (5, 6)]\nn_components = 2", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\n\ndef task_func(tuples_list, n_components):\n    # Convert the list of tuples to numpy array\n    data = np.array(tuples_list)\n\n    # Initialize PCA with n_components\n    pca = PCA(n_components=n_components)\n\n    # Fit and transform the data\n    transformed_data = pca.fit_transform(data)\n\n    return transformed_data\n\n# Test the function\ntuples_list = [(1, 2), (3, 4), (5, 6)]\nn_components = 2"}
{"task_id": "BigCodeBench/696", "solution": "import numpy as np\nimport math\nimport random\nfrom random import uniform\ndef task_func(radius, num_points):\n    points_in_circle = []\n    for _ in range(num_points):\n        r = radius * math.sqrt(random.uniform(0, 1))\n        theta = random.uniform(0, 2*math.pi)\n        x = r * math.cos(theta)\n        y = r * math.sin(theta)\n        points_in_circle.append((x, y))\n    return points_in_circle\nradius = 5\nnum_points = 10", "raw_solution": "import numpy as np\nimport math\nimport random\nfrom random import uniform\n\ndef task_func(radius, num_points):\n    points_in_circle = []\n    for _ in range(num_points):\n        r = radius * math.sqrt(random.uniform(0, 1))\n        theta = random.uniform(0, 2*math.pi)\n        x = r * math.cos(theta)\n        y = r * math.sin(theta)\n        points_in_circle.append((x, y))\n    return points_in_circle\n\n# Test the function\nradius = 5\nnum_points = 10"}
{"task_id": "BigCodeBench/697", "solution": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    # Extract the feature and target columns\n    X = df[['feature']]\n    y = df['value']\n\n    # Initialize the linear regression model\n    model = LinearRegression()\n\n    # Fit the model\n    model.fit(X, y)\n\n    # Get the coefficients and intercept\n    coef = model.coef_[0]\n    intercept = model.intercept_\n\n    # Return the coefficients and intercept in a dictionary\n    result = {'coefficient': coef, 'intercept': intercept}\n    return result", "raw_solution": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    # Extract the feature and target columns\n    X = df[['feature']]\n    y = df['value']\n\n    # Initialize the linear regression model\n    model = LinearRegression()\n\n    # Fit the model\n    model.fit(X, y)\n\n    # Get the coefficients and intercept\n    coef = model.coef_[0]\n    intercept = model.intercept_\n\n    # Return the coefficients and intercept in a dictionary\n    result = {'coefficient': coef, 'intercept': intercept}\n    return result"}
{"task_id": "BigCodeBench/698", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\ndef task_func(df):\n    # Separate the \"target\" column from the rest of the DataFrame\n    X = df.drop('target', axis=1)\n    y = df['target']\n\n    # Split the DataFrame into a training set and a test set\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n    return (X_train, X_test, y_train, y_test)", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(df):\n    # Separate the \"target\" column from the rest of the DataFrame\n    X = df.drop('target', axis=1)\n    y = df['target']\n\n    # Split the DataFrame into a training set and a test set\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n    return (X_train, X_test, y_train, y_test)"}
{"task_id": "BigCodeBench/699", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport numpy as np\ndef task_func(x_list, y_list, n_clusters=2, random_state=0):\n    # Create a DataFrame\n    data = pd.DataFrame({\n        'x': x_list,\n        'y': y_list\n    })\n\n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(data)\n\n    # Return labels and centroids\n    return kmeans.labels_, kmeans.cluster_centers_\nx_list = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ny_list = np.array([1, 2, 1, 2, 1, 2, 1, 2, 1, 2])", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport numpy as np\n\ndef task_func(x_list, y_list, n_clusters=2, random_state=0):\n    # Create a DataFrame\n    data = pd.DataFrame({\n        'x': x_list,\n        'y': y_list\n    })\n\n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(data)\n\n    # Return labels and centroids\n    return kmeans.labels_, kmeans.cluster_centers_\n\n# Test the function\nx_list = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ny_list = np.array([1, 2, 1, 2, 1, 2, 1, 2, 1, 2])\nlabels, centroids = task_func(x_list, y_list, n_clusters=2, random_state=0)"}
{"task_id": "BigCodeBench/700", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(data, cols):\n    # Convert the data to a DataFrame\n    df = pd.DataFrame(data, columns=cols)\n\n    # Calculate the correlation matrix\n    correlation_matrix = df.corr()\n\n    return correlation_matrix\ndata = {'A': [1, 2, 3, 4, 5],\n        'B': [10, 20, 30, 40, 50],\n        'C': [100, 200, 300, 400, 500]}\ncols = ['A', 'B', 'C']", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(data, cols):\n    # Convert the data to a DataFrame\n    df = pd.DataFrame(data, columns=cols)\n\n    # Calculate the correlation matrix\n    correlation_matrix = df.corr()\n\n    return correlation_matrix\n\n# Test the function\ndata = {'A': [1, 2, 3, 4, 5],\n        'B': [10, 20, 30, 40, 50],\n        'C': [100, 200, 300, 400, 500]}\ncols = ['A', 'B', 'C']\n"}
{"task_id": "BigCodeBench/701", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\ndef task_func(df, target):\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[target]), df[target], test_size=0.2, random_state=42)\n\n    # Create a linear regression model\n    model = LinearRegression()\n\n    # Fit the model to the training data\n    model.fit(X_train, y_train)\n\n    # Make predictions on the testing set\n    predictions = model.predict(X_test)\n\n    # Calculate the R-squared score of the model\n    score = model.score(X_test, y_test)\n\n    return score\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500],\n    'target': [1000, 2000, 3000, 4000, 5000]\n})", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(df, target):\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[target]), df[target], test_size=0.2, random_state=42)\n\n    # Create a linear regression model\n    model = LinearRegression()\n\n    # Fit the model to the training data\n    model.fit(X_train, y_train)\n\n    # Make predictions on the testing set\n    predictions = model.predict(X_test)\n\n    # Calculate the R-squared score of the model\n    score = model.score(X_test, y_test)\n\n    return score\n\n# Test the function\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [10, 20, 30, 40, 50],\n    'C': [100, 200, 300, 400, 500],\n    'target': [1000, 2000, 3000, 4000, 5000]\n})\n"}
{"task_id": "BigCodeBench/702", "solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\ndef task_func(df):\n    # Initialize PCA\n    pca = PCA(n_components=2)\n\n    # Fit and transform the data\n    df_pca = pca.fit_transform(df)\n\n    # Create a DataFrame from the transformed data\n    df_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n\n    return df_pca", "raw_solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\n\ndef task_func(df):\n    # Initialize PCA\n    pca = PCA(n_components=2)\n\n    # Fit and transform the data\n    df_pca = pca.fit_transform(df)\n\n    # Create a DataFrame from the transformed data\n    df_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n\n    return df_pca"}
{"task_id": "BigCodeBench/703", "solution": "import pandas as pd\nfrom sklearn.cluster import DBSCAN\ndef task_func(data, cols):\n    # Convert data to DataFrame\n    df = pd.DataFrame(data, columns=cols)\n\n    # Initialize DBSCAN\n    clustering = DBSCAN(eps=3, min_samples=2).fit(df)\n\n    # Add cluster labels\n    df['Cluster'] = clustering.labels_\n\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import DBSCAN\n\ndef task_func(data, cols):\n    # Convert data to DataFrame\n    df = pd.DataFrame(data, columns=cols)\n\n    # Initialize DBSCAN\n    clustering = DBSCAN(eps=3, min_samples=2).fit(df)\n\n    # Add cluster labels\n    df['Cluster'] = clustering.labels_\n\n    return df"}
{"task_id": "BigCodeBench/704", "solution": "import pandas as pd\nfrom itertools import combinations\nMIN_PERCENTAGE = 0.75\ndef task_func(data, cols, percentage):\n    # Filter columns\n    data = data[cols]\n\n    # Calculate correlation matrix\n    corr_matrix = data.corr().abs()\n\n    # Initialize list to store combinations\n    corr_combinations = []\n\n    # Iterate over all combinations of columns\n    for comb in combinations(corr_matrix.columns, 2):\n        # If correlation is greater than the threshold\n        if corr_matrix.loc[comb[0], comb[1]] > percentage:\n            # Add combination to list\n            corr_combinations.append(comb)\n\n    return corr_combinations\ndata = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [1, 2, 3, 4, 5],\n    'C': [1, 2, 3, 4, 5],\n    'D': [1, 2, 3, 4, 5],\n    'E': [1, 2, 3, 4, 5]\n})\ncols = ['A', 'B', 'C', 'D', 'E']\npercentage = MIN_PERCENTAGE", "raw_solution": "import pandas as pd\nfrom itertools import combinations\n\n# Constants\nMIN_PERCENTAGE = 0.75\n\ndef task_func(data, cols, percentage):\n    # Filter columns\n    data = data[cols]\n\n    # Calculate correlation matrix\n    corr_matrix = data.corr().abs()\n\n    # Initialize list to store combinations\n    corr_combinations = []\n\n    # Iterate over all combinations of columns\n    for comb in combinations(corr_matrix.columns, 2):\n        # If correlation is greater than the threshold\n        if corr_matrix.loc[comb[0], comb[1]] > percentage:\n            # Add combination to list\n            corr_combinations.append(comb)\n\n    return corr_combinations\n\n# Test the function\ndata = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [1, 2, 3, 4, 5],\n    'C': [1, 2, 3, 4, 5],\n    'D': [1, 2, 3, 4, 5],\n    'E': [1, 2, 3, 4, 5]\n})\n\ncols = ['A', 'B', 'C', 'D', 'E']\npercentage = MIN_PERCENTAGE\n"}
{"task_id": "BigCodeBench/705", "solution": "import numpy as np\nfrom scipy import stats\ndef task_func(df, column, alpha):\n    \"\"\"\n    This function tests the normality of a particular numeric column from a DataFrame using the Shapiro-Wilk test.\n\n    Parameters:\n    df (pandas.DataFrame): The DataFrame to be tested.\n    column (str): The name of the column to be tested.\n    alpha (float): The significance level for the Shapiro-Wilk test.\n\n    Returns:\n    bool: True if the column passes the normality test, False otherwise.\n    \"\"\"\n    # Extract the column data\n    data = df[column]\n\n    # Perform the Shapiro-Wilk test\n    stat, p = stats.shapiro(data)\n\n    # Return True if the p-value is greater than the alpha level, False otherwise\n    return p > alpha", "raw_solution": "import numpy as np\nfrom scipy import stats\n\ndef task_func(df, column, alpha):\n    \"\"\"\n    This function tests the normality of a particular numeric column from a DataFrame using the Shapiro-Wilk test.\n\n    Parameters:\n    df (pandas.DataFrame): The DataFrame to be tested.\n    column (str): The name of the column to be tested.\n    alpha (float): The significance level for the Shapiro-Wilk test.\n\n    Returns:\n    bool: True if the column passes the normality test, False otherwise.\n    \"\"\"\n    # Extract the column data\n    data = df[column]\n\n    # Perform the Shapiro-Wilk test\n    stat, p = stats.shapiro(data)\n\n    # Return True if the p-value is greater than the alpha level, False otherwise\n    return p > alpha"}
{"task_id": "BigCodeBench/706", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\ndef task_func(data, columns, target_column):\n    # Split the data into features and target\n    X = data[columns]\n    y = data[target_column]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Initialize the logistic regression model\n    model = LogisticRegression()\n\n    # Fit the model to the training data\n    model.fit(X_train, y_train)\n\n    # Make predictions on the testing data\n    y_pred = model.predict(X_test)\n\n    # Calculate the accuracy of the model\n    accuracy = accuracy_score(y_test, y_pred)\n\n    return accuracy", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\ndef task_func(data, columns, target_column):\n    # Split the data into features and target\n    X = data[columns]\n    y = data[target_column]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Initialize the logistic regression model\n    model = LogisticRegression()\n\n    # Fit the model to the training data\n    model.fit(X_train, y_train)\n\n    # Make predictions on the testing data\n    y_pred = model.predict(X_test)\n\n    # Calculate the accuracy of the model\n    accuracy = accuracy_score(y_test, y_pred)\n\n    return accuracy"}
{"task_id": "BigCodeBench/707", "solution": "import json\nimport numpy as np\nimport pandas as pd\ndef task_func(df):\n    df['IntCol'] = np.log10(df['IntCol'])\n    df['IntCol'] = df['IntCol'].apply(lambda x: int(x) if np.isfinite(x) else np.nan)\n    df.to_json('IntCol.json')\n    return df", "raw_solution": "import json\nimport numpy as np\nimport pandas as pd\n\ndef task_func(df):\n    df['IntCol'] = np.log10(df['IntCol'])\n    df['IntCol'] = df['IntCol'].apply(lambda x: int(x) if np.isfinite(x) else np.nan)\n    df.to_json('IntCol.json')\n    return df"}
{"task_id": "BigCodeBench/708", "solution": "import json\nimport csv\nimport os\nimport base64\ndef task_func(raw_string, filename, output_dir):\n    # Decode the base64 string\n    decoded_string = base64.b64decode(raw_string).decode('utf-8')\n\n    # Convert the decoded string to a JSON object\n    json_obj = json.loads(decoded_string)\n\n    # Create the output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Create the file path\n    file_path = os.path.join(output_dir, filename)\n\n    # Write the JSON object to a CSV file\n    with open(file_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        for key in json_obj:\n            writer.writerow([key, json_obj[key]])\n\n    return file_path", "raw_solution": "import json\nimport csv\nimport os\nimport base64\n\ndef task_func(raw_string, filename, output_dir):\n    # Decode the base64 string\n    decoded_string = base64.b64decode(raw_string).decode('utf-8')\n\n    # Convert the decoded string to a JSON object\n    json_obj = json.loads(decoded_string)\n\n    # Create the output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Create the file path\n    file_path = os.path.join(output_dir, filename)\n\n    # Write the JSON object to a CSV file\n    with open(file_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        for key in json_obj:\n            writer.writerow([key, json_obj[key]])\n\n    return file_path"}
{"task_id": "BigCodeBench/709", "solution": "import base64\nimport re\nfrom html import unescape\nimport textwrap\ndef task_func(raw_string, line_length):\n    # Decode base64\n    decoded_string = base64.b64decode(raw_string).decode()\n\n    # Decouple HTML entities\n    decoupled_string = unescape(decoded_string)\n\n    # Replace multiple spaces with a single space\n    single_space_string = re.sub(' +', ' ', decoupled_string)\n\n    # Strip leading and subsequent spaces\n    stripped_string = single_space_string.strip()\n\n    # Wrap text to a certain line length\n    wrapped_text = textwrap.fill(stripped_string, line_length)\n\n    return wrapped_text\nraw_string = 'WW91ciBlbmNvZGVkIG1lc3NhZ2U='", "raw_solution": "import base64\nimport re\nfrom html import unescape\nimport textwrap\n\ndef task_func(raw_string, line_length):\n    # Decode base64\n    decoded_string = base64.b64decode(raw_string).decode()\n\n    # Decouple HTML entities\n    decoupled_string = unescape(decoded_string)\n\n    # Replace multiple spaces with a single space\n    single_space_string = re.sub(' +', ' ', decoupled_string)\n\n    # Strip leading and subsequent spaces\n    stripped_string = single_space_string.strip()\n\n    # Wrap text to a certain line length\n    wrapped_text = textwrap.fill(stripped_string, line_length)\n\n    return wrapped_text\n\n# Test the function\nraw_string = 'WW91ciBlbmNvZGVkIG1lc3NhZ2U='  # base64 encoded string for 'This is a test'"}
{"task_id": "BigCodeBench/710", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data_path):\n    # Load the dataset\n    df = pd.read_csv(data_path)\n\n    # Initialize a scaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the data\n    df[df.columns] = scaler.fit_transform(df[df.columns])\n\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data_path):\n    # Load the dataset\n    df = pd.read_csv(data_path)\n\n    # Initialize a scaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the data\n    df[df.columns] = scaler.fit_transform(df[df.columns])\n\n    return df"}
{"task_id": "BigCodeBench/711", "solution": "import json\nimport csv\nimport os\ndef task_func(json_file, csv_file):\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n\n    with open(csv_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(data[0].keys())\n        for row in data:\n            writer.writerow(row.values())\n\n    return csv_file", "raw_solution": "import json\nimport csv\nimport os\n\ndef task_func(json_file, csv_file):\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n\n    with open(csv_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(data[0].keys())\n        for row in data:\n            writer.writerow(row.values())\n\n    return csv_file"}
{"task_id": "BigCodeBench/712", "solution": "import os\nimport shutil\nimport glob\ndef task_func(source_dir, dest_dir, extension):\n    # Check if source directory exists\n    if not os.path.isdir(source_dir):\n        return \"Source directory does not exist.\"\n\n    # Check if destination directory exists, if not create it\n    if not os.path.isdir(dest_dir):\n        os.makedirs(dest_dir)\n\n    # Get a list of all files with the specified extension in the source directory\n    files = glob.glob(os.path.join(source_dir, f'*.{extension}'))\n\n    # Move each file to the destination directory\n    for file in files:\n        shutil.move(file, dest_dir)\n\n    # Return the count of files moved\n    return len(files)\nsource_dir = \"/path/to/source/directory\"\ndest_dir = \"/path/to/destination/directory\"\nextension = \"txt\"", "raw_solution": "import os\nimport shutil\nimport glob\n\ndef task_func(source_dir, dest_dir, extension):\n    # Check if source directory exists\n    if not os.path.isdir(source_dir):\n        return \"Source directory does not exist.\"\n\n    # Check if destination directory exists, if not create it\n    if not os.path.isdir(dest_dir):\n        os.makedirs(dest_dir)\n\n    # Get a list of all files with the specified extension in the source directory\n    files = glob.glob(os.path.join(source_dir, f'*.{extension}'))\n\n    # Move each file to the destination directory\n    for file in files:\n        shutil.move(file, dest_dir)\n\n    # Return the count of files moved\n    return len(files)\n\n# Test the function\nsource_dir = \"/path/to/source/directory\"\ndest_dir = \"/path/to/destination/directory\"\nextension = \"txt\""}
{"task_id": "BigCodeBench/713", "solution": "import os\nimport re\ndef task_func(log_file_path: str, keywords: list):\n    if not os.path.exists(log_file_path):\n        return \"Log file does not exist.\"\n\n    formatted_lines = []\n\n    with open(log_file_path, 'r') as log_file:\n        for line in log_file:\n            for keyword in keywords:\n                if keyword in line:\n                    timestamp_match = re.search(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', line)\n                    if timestamp_match:\n                        timestamp = timestamp_match.group()\n                        formatted_line = f\"{keyword:<20}{timestamp:<20}{line.strip()}\"\n                        formatted_lines.append(formatted_line)\n                    else:\n                        formatted_line = f\"{keyword:<20}{'No timestamp found':<20}{line.strip()}\"\n                        formatted_lines.append(formatted_line)\n                    break\n\n    return formatted_lines", "raw_solution": "import os\nimport re\n\ndef task_func(log_file_path: str, keywords: list):\n    if not os.path.exists(log_file_path):\n        return \"Log file does not exist.\"\n\n    formatted_lines = []\n\n    with open(log_file_path, 'r') as log_file:\n        for line in log_file:\n            for keyword in keywords:\n                if keyword in line:\n                    timestamp_match = re.search(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', line)\n                    if timestamp_match:\n                        timestamp = timestamp_match.group()\n                        formatted_line = f\"{keyword:<20}{timestamp:<20}{line.strip()}\"\n                        formatted_lines.append(formatted_line)\n                    else:\n                        formatted_line = f\"{keyword:<20}{'No timestamp found':<20}{line.strip()}\"\n                        formatted_lines.append(formatted_line)\n                    break\n\n    return formatted_lines"}
{"task_id": "BigCodeBench/714", "solution": "import sys\nfrom pathlib import Path\nimport os\nPATH_TO_APPEND = '/path/to/whatever'\ndef task_func(path_to_append=PATH_TO_APPEND):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Create a directory if it does not exist\n    Path(path_to_append).mkdir(parents=True, exist_ok=True)\n\n    return path_to_append", "raw_solution": "import sys\nfrom pathlib import Path\nimport os\n\n# Constants\nPATH_TO_APPEND = '/path/to/whatever'\n\ndef task_func(path_to_append=PATH_TO_APPEND):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Create a directory if it does not exist\n    Path(path_to_append).mkdir(parents=True, exist_ok=True)\n\n    return path_to_append\n\n# Test the function"}
{"task_id": "BigCodeBench/715", "solution": "import sys\nimport subprocess\nimport platform\nPYTHON_VERSION = '3.8'\nPATH_TO_APPEND = '/path/to/whatever'\ndef task_func(python_version=PYTHON_VERSION, path_to_append=PATH_TO_APPEND):\n    # Check if the Python version is already the one we want\n    if platform.python_version().split('.')[0]+'.'+platform.python_version().split('.')[1] != python_version:\n        # If not, switch to the desired Python version\n        subprocess.run(['pyenv', 'global', python_version])\n    # Add the path to sys.path\n    sys.path.append(path_to_append)\n    # Return the Python version\n    return platform.python_version()", "raw_solution": "import sys\nimport subprocess\nimport platform\n\n# Constants\nPYTHON_VERSION = '3.8'\nPATH_TO_APPEND = '/path/to/whatever'\n\ndef task_func(python_version=PYTHON_VERSION, path_to_append=PATH_TO_APPEND):\n    # Check if the Python version is already the one we want\n    if platform.python_version().split('.')[0]+'.'+platform.python_version().split('.')[1] != python_version:\n        # If not, switch to the desired Python version\n        subprocess.run(['pyenv', 'global', python_version])\n    # Add the path to sys.path\n    sys.path.append(path_to_append)\n    # Return the Python version\n    return platform.python_version()\n\n# Test the function"}
{"task_id": "BigCodeBench/716", "solution": "import sys\nimport json\nfrom datetime import datetime\nPATH_TO_APPEND = '/path/to/whatever'\nJSON_FILE = '/path/to/json_file.json'\ndef task_func(path_to_append=PATH_TO_APPEND, json_file=JSON_FILE):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Load the JSON file\n    with open(json_file, 'r') as file:\n        json_data = json.load(file)\n\n    # Update the 'last_updated' key with the current date and time\n    json_data['last_updated'] = str(datetime.now())\n\n    # Write the updated JSON data back to the file\n    with open(json_file, 'w') as file:\n        json.dump(json_data, file)\n\n    return json_data", "raw_solution": "import sys\nimport json\nfrom datetime import datetime\n\n# Constants\nPATH_TO_APPEND = '/path/to/whatever'\nJSON_FILE = '/path/to/json_file.json'\n\ndef task_func(path_to_append=PATH_TO_APPEND, json_file=JSON_FILE):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Load the JSON file\n    with open(json_file, 'r') as file:\n        json_data = json.load(file)\n\n    # Update the 'last_updated' key with the current date and time\n    json_data['last_updated'] = str(datetime.now())\n\n    # Write the updated JSON data back to the file\n    with open(json_file, 'w') as file:\n        json.dump(json_data, file)\n\n    return json_data"}
{"task_id": "BigCodeBench/717", "solution": "import sys\nfrom configparser import ConfigParser\nimport os\nPATH_TO_APPEND = '/path/to/whatever'\nCONFIG_FILE = '/path/to/config.ini'\ndef task_func(path_to_append=PATH_TO_APPEND, config_file=CONFIG_FILE):\n    # Add the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Check if the file exists\n    if not os.path.isfile(config_file):\n        raise FileNotFoundError(f\"The file {config_file} does not exist.\")\n\n    # Initialize ConfigParser\n    config = ConfigParser()\n\n    # Read the configuration file\n    config.read(config_file)\n\n    # Update the configuration file with the new path\n    config.set('DEFAULT', 'path', path_to_append)\n\n    # Write the changes to the configuration file\n    with open(config_file, 'w') as file:\n        config.write(file)\n\n    return config, config_file", "raw_solution": "import sys\nfrom configparser import ConfigParser\nimport os\n\n# Constants\nPATH_TO_APPEND = '/path/to/whatever'\nCONFIG_FILE = '/path/to/config.ini'\n\ndef task_func(path_to_append=PATH_TO_APPEND, config_file=CONFIG_FILE):\n    # Add the path to sys.path\n    sys.path.append(path_to_append)\n\n    # Check if the file exists\n    if not os.path.isfile(config_file):\n        raise FileNotFoundError(f\"The file {config_file} does not exist.\")\n\n    # Initialize ConfigParser\n    config = ConfigParser()\n\n    # Read the configuration file\n    config.read(config_file)\n\n    # Update the configuration file with the new path\n    config.set('DEFAULT', 'path', path_to_append)\n\n    # Write the changes to the configuration file\n    with open(config_file, 'w') as file:\n        config.write(file)\n\n    return config, config_file\n\n# Test the function\nconfig, config_file = task_func()"}
{"task_id": "BigCodeBench/718", "solution": "import re\nimport numpy as np\nfrom scipy.stats import ttest_rel\ndef task_func(text1, text2):\n    # Split the texts into words\n    words1 = re.findall(r'\\b\\w+\\b', text1)\n    words2 = re.findall(r'\\b\\w+\\b', text2)\n\n    # Check if the lengths of the words lists are equal\n    if len(words1) != len(words2):\n        # If not, return NaN for both t_statistic and p_value\n        return np.nan, np.nan\n\n    # Convert the word lists to numpy arrays\n    words1 = np.array(words1)\n    words2 = np.array(words2)\n\n    # Perform the paired t-test\n    t_statistic, p_value = ttest_rel(words1, words2)\n\n    # Return the t_statistic and p_value\n    return t_statistic, p_value", "raw_solution": "import re\nimport numpy as np\nfrom scipy.stats import ttest_rel\n\ndef task_func(text1, text2):\n    # Split the texts into words\n    words1 = re.findall(r'\\b\\w+\\b', text1)\n    words2 = re.findall(r'\\b\\w+\\b', text2)\n\n    # Check if the lengths of the words lists are equal\n    if len(words1) != len(words2):\n        # If not, return NaN for both t_statistic and p_value\n        return np.nan, np.nan\n\n    # Convert the word lists to numpy arrays\n    words1 = np.array(words1)\n    words2 = np.array(words2)\n\n    # Perform the paired t-test\n    t_statistic, p_value = ttest_rel(words1, words2)\n\n    # Return the t_statistic and p_value\n    return t_statistic, p_value"}
{"task_id": "BigCodeBench/719", "solution": "import re\nimport os\nimport glob\ndef task_func(directory, word):\n    count = 0\n    for filename in glob.glob(os.path.join(directory, '*')):\n        if os.path.isfile(filename):\n            with open(filename, 'r') as f:\n                if re.search(word, f.read()):\n                    count += 1\n    return count", "raw_solution": "import re\nimport os\nimport glob\n\ndef task_func(directory, word):\n    count = 0\n    for filename in glob.glob(os.path.join(directory, '*')):\n        if os.path.isfile(filename):\n            with open(filename, 'r') as f:\n                if re.search(word, f.read()):\n                    count += 1\n    return count\n\n# Test the function"}
{"task_id": "BigCodeBench/720", "solution": "import os\nimport csv\nimport random\nfrom datetime import datetime\ndef task_func():\n    # Define the path to the CSV file\n    file_path = \"task_func_data/Output.txt\"\n\n    # Create the CSV file if it doesn't exist\n    if not os.path.exists(\"task_func_data\"):\n        os.makedirs(\"task_func_data\")\n\n    # Generate random temperature and humidity data\n    temperature = random.uniform(0, 100)\n    humidity = random.uniform(0, 100)\n\n    # Write the data to the CSV file\n    with open(file_path, 'a', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([datetime.now(), temperature, humidity])\n\n    # Return the path to the CSV file\n    print(f\"CSV file path: {file_path}\")\n\n    # Delete the CSV file\n    os.remove(file_path)\n\n    return file_path", "raw_solution": "import os\nimport csv\nimport random\nfrom datetime import datetime\n\ndef task_func():\n    # Define the path to the CSV file\n    file_path = \"task_func_data/Output.txt\"\n\n    # Create the CSV file if it doesn't exist\n    if not os.path.exists(\"task_func_data\"):\n        os.makedirs(\"task_func_data\")\n\n    # Generate random temperature and humidity data\n    temperature = random.uniform(0, 100)\n    humidity = random.uniform(0, 100)\n\n    # Write the data to the CSV file\n    with open(file_path, 'a', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([datetime.now(), temperature, humidity])\n\n    # Return the path to the CSV file\n    print(f\"CSV file path: {file_path}\")\n\n    # Delete the CSV file\n    os.remove(file_path)\n\n    return file_path\n\n# Test the function\nfile_path = task_func()"}
{"task_id": "BigCodeBench/721", "solution": "import os\nimport csv\nfrom collections import Counter\ndef task_func(file_path):\n    if not os.path.exists(file_path):\n        return None\n\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        words = [word for row in reader for word in row]\n\n    if not words:\n        return None\n\n    word_counts = Counter(words)\n    most_common_word = word_counts.most_common(1)\n\n    return most_common_word[0] if most_common_word else None", "raw_solution": "import os\nimport csv\nfrom collections import Counter\n\ndef task_func(file_path):\n    if not os.path.exists(file_path):\n        return None\n\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        words = [word for row in reader for word in row]\n\n    if not words:\n        return None\n\n    word_counts = Counter(words)\n    most_common_word = word_counts.most_common(1)\n\n    return most_common_word[0] if most_common_word else None"}
{"task_id": "BigCodeBench/722", "solution": "import urllib.request\nimport os\nimport re\nTARGET_FILE = 'downloaded_file.txt'\nSEARCH_PATTERN = r'\\bERROR\\b'\ndef task_func(url):\n    # Download the file\n    urllib.request.urlretrieve(url, TARGET_FILE)\n\n    # Check if the file exists\n    if not os.path.exists(TARGET_FILE):\n        return \"File not found\"\n\n    # Open the file and read its content\n    with open(TARGET_FILE, 'r') as file:\n        content = file.read()\n\n    # Use regex to find all occurrences of 'ERROR'\n    occurrences = len(re.findall(SEARCH_PATTERN, content, re.IGNORECASE))\n\n    # Remove the downloaded file\n    os.remove(TARGET_FILE)\n\n    return occurrences\nurl = \"https://raw.githubusercontent.com/dolph/dictionary/master/words\"", "raw_solution": "import urllib.request\nimport os\nimport re\n\n# Constants\nTARGET_FILE = 'downloaded_file.txt'\nSEARCH_PATTERN = r'\\bERROR\\b'\n\ndef task_func(url):\n    # Download the file\n    urllib.request.urlretrieve(url, TARGET_FILE)\n\n    # Check if the file exists\n    if not os.path.exists(TARGET_FILE):\n        return \"File not found\"\n\n    # Open the file and read its content\n    with open(TARGET_FILE, 'r') as file:\n        content = file.read()\n\n    # Use regex to find all occurrences of 'ERROR'\n    occurrences = len(re.findall(SEARCH_PATTERN, content, re.IGNORECASE))\n\n    # Remove the downloaded file\n    os.remove(TARGET_FILE)\n\n    return occurrences\n\n# Test the function\nurl = \"https://raw.githubusercontent.com/dolph/dictionary/master/words\""}
{"task_id": "BigCodeBench/723", "solution": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n    # Open the URL\n    response = urllib.request.urlopen(url)\n    # Parse the HTML and save to BeautifulSoup object\n    soup = BeautifulSoup(response, 'html.parser')\n\n    # Find all table rows\n    rows = soup.find_all('tr')\n\n    # Open the CSV file for writing\n    with open(CSV_FILE_PATH, 'w', newline='') as file:\n        writer = csv.writer(file)\n\n        # Write each row to the CSV file\n        for row in rows:\n            row_data = [td.get_text(strip=True) for td in row.find_all('td')]\n            writer.writerow(row_data)\n\n    return CSV_FILE_PATH", "raw_solution": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\n\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\n\ndef task_func(url):\n    # Open the URL\n    response = urllib.request.urlopen(url)\n    # Parse the HTML and save to BeautifulSoup object\n    soup = BeautifulSoup(response, 'html.parser')\n\n    # Find all table rows\n    rows = soup.find_all('tr')\n\n    # Open the CSV file for writing\n    with open(CSV_FILE_PATH, 'w', newline='') as file:\n        writer = csv.writer(file)\n\n        # Write each row to the CSV file\n        for row in rows:\n            row_data = [td.get_text(strip=True) for td in row.find_all('td')]\n            writer.writerow(row_data)\n\n    return CSV_FILE_PATH"}
{"task_id": "BigCodeBench/724", "solution": "import os\nimport json\ndef task_func(config_path: str) -> dict:\n    if not os.path.isfile(config_path):\n        raise FileNotFoundError(\"The provided configuration file does not exist.\")\n    with open(config_path, 'r') as config_file:\n        config = json.load(config_file)\n    return config", "raw_solution": "import os\nimport json\n\ndef task_func(config_path: str) -> dict:\n    if not os.path.isfile(config_path):\n        raise FileNotFoundError(\"The provided configuration file does not exist.\")\n    with open(config_path, 'r') as config_file:\n        config = json.load(config_file)\n    return config"}
{"task_id": "BigCodeBench/725", "solution": "import codecs\nimport os\nimport glob\nDIRECTORY_PATH = './files/'\ndef task_func(directory=DIRECTORY_PATH, from_encoding='cp1251', to_encoding='utf8'):\n    # Get all text files in the directory\n    for file in glob.glob(os.path.join(directory, '*.txt')):\n        # Open the file in the original encoding\n        with codecs.open(file, 'r', encoding=from_encoding) as f:\n            content = f.read()\n        # Write the content back to the file in the new encoding\n        with codecs.open(file, 'w', encoding=to_encoding) as f:\n            f.write(content)", "raw_solution": "import codecs\nimport os\nimport glob\n\n# Constants\nDIRECTORY_PATH = './files/'\n\ndef task_func(directory=DIRECTORY_PATH, from_encoding='cp1251', to_encoding='utf8'):\n    # Get all text files in the directory\n    for file in glob.glob(os.path.join(directory, '*.txt')):\n        # Open the file in the original encoding\n        with codecs.open(file, 'r', encoding=from_encoding) as f:\n            content = f.read()\n        # Write the content back to the file in the new encoding\n        with codecs.open(file, 'w', encoding=to_encoding) as f:\n            f.write(content)\n\n# Test the function\ntask_func()"}
{"task_id": "BigCodeBench/726", "solution": "import re\nimport random\nfrom nltk.corpus import words\nfrom random import sample\nimport nltk\ndef task_func(s, n):\n    # Convert the string to lowercase\n    s = s.lower()\n    # Use a regular expression to find all words in the string\n    words = re.findall(r'\\b\\w+\\b', s)\n    # Find the distinct words in the list\n    distinct_words = set(words)\n    # If there are fewer than n different words, return all distinct ones\n    if len(distinct_words) < n:\n        return list(distinct_words)\n    # Otherwise, return a random sample of n different words\n    else:\n        return random.sample(distinct_words, n)", "raw_solution": "import re\nimport random\nfrom nltk.corpus import words\nfrom random import sample\n# Ensure the words corpus is downloaded\nimport nltk\nnltk.download('words')\n# Constants\nSAMPLE_ENGLISH_WORDS = set(words.words())  # Correct initialization\n\ndef task_func(s, n):\n    # Convert the string to lowercase\n    s = s.lower()\n    # Use a regular expression to find all words in the string\n    words = re.findall(r'\\b\\w+\\b', s)\n    # Find the distinct words in the list\n    distinct_words = set(words)\n    # If there are fewer than n different words, return all distinct ones\n    if len(distinct_words) < n:\n        return list(distinct_words)\n    # Otherwise, return a random sample of n different words\n    else:\n        return random.sample(distinct_words, n)\n\n# Test the function"}
{"task_id": "BigCodeBench/727", "solution": "import re\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np\nSENTENCES = ['This is a sentence', 'Another sentence here', 'More sentences']\ndef task_func(s: str) -> np.ndarray:\n    # Remove punctuation\n    s = re.sub(r'[^\\w\\s]', '', s)\n\n    # Initialize CountVectorizer\n    vectorizer = CountVectorizer()\n\n    # Fit and transform the sentences\n    vectorizer.fit_transform(SENTENCES)\n\n    # Transform the input string\n    vec = vectorizer.transform([s])\n\n    # Return the vectorized string as a numpy array\n    return vec.toarray()", "raw_solution": "import re\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np\n\n# Constants\nSENTENCES = ['This is a sentence', 'Another sentence here', 'More sentences']\n\ndef task_func(s: str) -> np.ndarray:\n    # Remove punctuation\n    s = re.sub(r'[^\\w\\s]', '', s)\n\n    # Initialize CountVectorizer\n    vectorizer = CountVectorizer()\n\n    # Fit and transform the sentences\n    vectorizer.fit_transform(SENTENCES)\n\n    # Transform the input string\n    vec = vectorizer.transform([s])\n\n    # Return the vectorized string as a numpy array\n    return vec.toarray()\n\n# Test the function"}
{"task_id": "BigCodeBench/728", "solution": "import csv\nimport io\ndef task_func(filename='sample.csv', from_encoding='cp1251', to_encoding='utf8', delimiter=','):\n    with open(filename, 'r', encoding=from_encoding) as f:\n        reader = csv.reader(f, delimiter=delimiter)\n        headers = next(reader)\n        data = [dict(zip(headers, row)) for row in reader]\n\n    output = io.StringIO()\n    writer = csv.writer(output, delimiter=delimiter)\n    writer.writerow(headers)\n    for row in data:\n        writer.writerow(list(row.values()))\n\n    converted_data = output.getvalue().encode(to_encoding).decode(to_encoding)\n    output.close()\n\n    return (data, converted_data)", "raw_solution": "import csv\nimport io\n\ndef task_func(filename='sample.csv', from_encoding='cp1251', to_encoding='utf8', delimiter=','):\n    with open(filename, 'r', encoding=from_encoding) as f:\n        reader = csv.reader(f, delimiter=delimiter)\n        headers = next(reader)\n        data = [dict(zip(headers, row)) for row in reader]\n\n    output = io.StringIO()\n    writer = csv.writer(output, delimiter=delimiter)\n    writer.writerow(headers)\n    for row in data:\n        writer.writerow(list(row.values()))\n\n    converted_data = output.getvalue().encode(to_encoding).decode(to_encoding)\n    output.close()\n\n    return (data, converted_data)"}
{"task_id": "BigCodeBench/729", "solution": "import pickle\nimport os\nimport random\nimport string\ndef task_func(strings, filename=None):\n    if filename is None:\n        filename = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10)) + '.pkl'\n\n    with open(filename, 'wb') as f:\n        pickle.dump(strings, f)\n\n    with open(filename, 'rb') as f:\n        loaded_strings = pickle.load(f)\n\n    os.remove(filename)\n\n    return loaded_strings\nstrings = [\"\".join(random.choices(string.ascii_lowercase, k=5)) for _ in range(5)]", "raw_solution": "import pickle\nimport os\nimport random\nimport string\n\ndef task_func(strings, filename=None):\n    if filename is None:\n        filename = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10)) + '.pkl'\n\n    with open(filename, 'wb') as f:\n        pickle.dump(strings, f)\n\n    with open(filename, 'rb') as f:\n        loaded_strings = pickle.load(f)\n\n    os.remove(filename)\n\n    return loaded_strings\n\n# Test the function\nstrings = [\"\".join(random.choices(string.ascii_lowercase, k=5)) for _ in range(5)]\nloaded_strings = task_func(strings)"}
{"task_id": "BigCodeBench/730", "solution": "import pickle\nimport os\nfrom datetime import datetime\nFILE_NAME = 'save.pkl'\ndef task_func(dt):\n    # Save the datetime object to a pickle file\n    with open(FILE_NAME, 'wb') as f:\n        pickle.dump(dt, f)\n\n    # Load the datetime object from the pickle file\n    with open(FILE_NAME, 'rb') as f:\n        loaded_dt = pickle.load(f)\n\n    # Remove the pickle file\n    os.remove(FILE_NAME)\n\n    return loaded_dt\ndt = datetime.now()", "raw_solution": "import pickle\nimport os\nfrom datetime import datetime\n\n# Constants\nFILE_NAME = 'save.pkl'\n\ndef task_func(dt):\n    # Save the datetime object to a pickle file\n    with open(FILE_NAME, 'wb') as f:\n        pickle.dump(dt, f)\n\n    # Load the datetime object from the pickle file\n    with open(FILE_NAME, 'rb') as f:\n        loaded_dt = pickle.load(f)\n\n    # Remove the pickle file\n    os.remove(FILE_NAME)\n\n    return loaded_dt\n\n# Test the function\ndt = datetime.now()\nloaded_dt = task_func(dt)\n\n# Validate that the loaded datetime object is the same as the original one\nassert loaded_dt == dt, \"Loaded datetime object is not the same as the original one\""}
{"task_id": "BigCodeBench/731", "solution": "import pickle\nimport os\nfrom sklearn.datasets import make_classification\nFILE_NAME = 'save.pkl'\ndef task_func(data, target):\n    # Save data and target to pickle file\n    with open(FILE_NAME, 'wb') as f:\n        pickle.dump((data, target), f)\n\n    # Load data and target from pickle file\n    with open(FILE_NAME, 'rb') as f:\n        loaded_data, loaded_target = pickle.load(f)\n\n    # Remove the pickle file\n    os.remove(FILE_NAME)\n\n    # Return loaded data and target\n    return (loaded_data, loaded_target)", "raw_solution": "import pickle\nimport os\nfrom sklearn.datasets import make_classification\n\n# Constants\nFILE_NAME = 'save.pkl'\nDATA, TARGET = make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=10, n_classes=2, random_state=1)\n\ndef task_func(data, target):\n    # Save data and target to pickle file\n    with open(FILE_NAME, 'wb') as f:\n        pickle.dump((data, target), f)\n\n    # Load data and target from pickle file\n    with open(FILE_NAME, 'rb') as f:\n        loaded_data, loaded_target = pickle.load(f)\n\n    # Remove the pickle file\n    os.remove(FILE_NAME)\n\n    # Return loaded data and target\n    return (loaded_data, loaded_target)\n\n# Test the function\ndata, target = task_func(DATA, TARGET)"}
{"task_id": "BigCodeBench/732", "solution": "import re\nimport string\nfrom nltk.stem import PorterStemmer\nfrom collections import Counter\nSTEMMER = PorterStemmer()\ndef task_func(content):\n    # Remove punctuation\n    content = re.sub('[^A-Za-z0-9\\s]+', '', content)\n    # Split the content into words\n    words = content.split()\n    # Stem every word except the last one\n    stems = [STEMMER.stem(word) if i != len(words) - 1 else word for i, word in enumerate(words)]\n    # Count the frequency of each stem\n    freq_dict = dict(Counter(stems))\n    return freq_dict\ncontent = \"This is a test sentence. It is used to test the function.\"", "raw_solution": "import re\nimport string\nfrom nltk.stem import PorterStemmer\nfrom collections import Counter\nSTEMMER = PorterStemmer()\n\ndef task_func(content):\n    # Remove punctuation\n    content = re.sub('[^A-Za-z0-9\\s]+', '', content)\n    # Split the content into words\n    words = content.split()\n    # Stem every word except the last one\n    stems = [STEMMER.stem(word) if i != len(words) - 1 else word for i, word in enumerate(words)]\n    # Count the frequency of each stem\n    freq_dict = dict(Counter(stems))\n    return freq_dict\n\n# Test the function\ncontent = \"This is a test sentence. It is used to test the function.\""}
{"task_id": "BigCodeBench/733", "solution": "import re\nimport string\nstop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n              \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \n              \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \n              \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \n              \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \n              \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \n              \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \n              \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \n              \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \n              \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \n              \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \n              \"should\", \"now\"]\ndef task_func(content):\n    # Remove punctuation from the content\n    content = re.sub(r'[^\\w\\s]', '', content)\n    \n    # Split the content into words\n    words = content.split()\n    \n    # Count the non-stop words\n    count = sum(1 for word in words if word.lower() not in stop_words)\n    \n    return count", "raw_solution": "import re\nimport string\n\n# Define a list of stop words\nstop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n              \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \n              \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \n              \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \n              \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \n              \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \n              \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \n              \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \n              \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \n              \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \n              \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \n              \"should\", \"now\"]\n\ndef task_func(content):\n    # Remove punctuation from the content\n    content = re.sub(r'[^\\w\\s]', '', content)\n    \n    # Split the content into words\n    words = content.split()\n    \n    # Count the non-stop words\n    count = sum(1 for word in words if word.lower() not in stop_words)\n    \n    return count\n\n# Test the function"}
{"task_id": "BigCodeBench/734", "solution": "import nltk\nfrom collections import Counter\ndef task_func(content):\n    # Tokenize the sentence\n    tokens = nltk.word_tokenize(content)\n    # Tag the POS\n    tags = nltk.pos_tag(tokens)\n    # Count the POS tags\n    pos_counts = Counter(tag for word, tag in tags)\n    # Remove the last word from the count\n    pos_counts.pop(tags[-1][1], None)\n    return pos_counts", "raw_solution": "import nltk\n# Download necessary NLTK data (if not already present)\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nfrom collections import Counter\n\ndef task_func(content):\n    # Tokenize the sentence\n    tokens = nltk.word_tokenize(content)\n    # Tag the POS\n    tags = nltk.pos_tag(tokens)\n    # Count the POS tags\n    pos_counts = Counter(tag for word, tag in tags)\n    # Remove the last word from the count\n    pos_counts.pop(tags[-1][1], None)\n    return pos_counts\n\n# Test the function"}
{"task_id": "BigCodeBench/735", "solution": "import numpy as np\nfrom itertools import chain\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = list(chain(*L))\n    \n    # Calculate mean\n    mean = np.mean(flat_list)\n    \n    # Calculate variance\n    variance = np.var(flat_list)\n    \n    # Return as dictionary\n    return {'mean': mean, 'variance': variance}\nL = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]", "raw_solution": "import numpy as np\nfrom itertools import chain\n\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = list(chain(*L))\n    \n    # Calculate mean\n    mean = np.mean(flat_list)\n    \n    # Calculate variance\n    variance = np.var(flat_list)\n    \n    # Return as dictionary\n    return {'mean': mean, 'variance': variance}\n\n# Test the function\nL = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]"}
{"task_id": "BigCodeBench/736", "solution": "import numpy as np\nfrom scipy import stats\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    # Calculate the mode\n    mode = stats.mode(flat_list)\n    return mode.mode[0]\nL = [[1, 2, 2, 3], [3, 4, 5, 5], [5, 6, 7, 7, 8]]", "raw_solution": "import numpy as np\nfrom scipy import stats\n\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    # Calculate the mode\n    mode = stats.mode(flat_list)\n    return mode.mode[0]\n\n# Test the function\nL = [[1, 2, 2, 3], [3, 4, 5, 5], [5, 6, 7, 7, 8]]"}
{"task_id": "BigCodeBench/737", "solution": "import numpy as np\nimport math\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    \n    # Calculate the median\n    median = np.median(flat_list)\n    \n    return float(median)\nL = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]", "raw_solution": "import numpy as np\nimport math\n\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    \n    # Calculate the median\n    median = np.median(flat_list)\n    \n    return float(median)\n\n# Test the function\nL = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]"}
{"task_id": "BigCodeBench/738", "solution": "import numpy as np\nfrom scipy.stats import iqr\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    # Calculate the interquartile range\n    iqr_value = iqr(flat_list)\n    return iqr_value\nL = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]", "raw_solution": "import numpy as np\nfrom scipy.stats import iqr\n\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    # Calculate the interquartile range\n    iqr_value = iqr(flat_list)\n    return iqr_value\n\n# Test the function\nL = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]"}
{"task_id": "BigCodeBench/739", "solution": "import struct\nimport random\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_key=None):\n    if hex_key is None:\n        hex_key = random.choice(KEYS)\n    float_val = struct.unpack('f', bytes.fromhex(hex_key))[0]\n    rounded_float = round(float_val, 2)\n    return rounded_float", "raw_solution": "import struct\nimport random\n\n# Constants\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\n\ndef task_func(hex_key=None):\n    if hex_key is None:\n        hex_key = random.choice(KEYS)\n    float_val = struct.unpack('f', bytes.fromhex(hex_key))[0]\n    rounded_float = round(float_val, 2)\n    return rounded_float\n\n# Test the function\nfor _ in range(5):\n    print(task_func())"}
{"task_id": "BigCodeBench/740", "solution": "from collections import Counter\nimport heapq\nimport random\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\ndef task_func(my_dict):\n    # Generate a dictionary with random integers for each letter\n    if not my_dict:\n        my_dict = {letter: random.randint(1, 100) for letter in LETTERS}\n\n    # Count the frequency of each letter\n    counter = Counter(my_dict)\n\n    # Find the 3 most common letters\n    most_common_letters = heapq.nlargest(3, counter.items(), key=lambda x: x[1])\n    most_common_letters = [letter for letter, count in most_common_letters]\n\n    return most_common_letters", "raw_solution": "from collections import Counter\nimport heapq\nimport random\n\n# Constants\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\n\ndef task_func(my_dict):\n    # Generate a dictionary with random integers for each letter\n    if not my_dict:\n        my_dict = {letter: random.randint(1, 100) for letter in LETTERS}\n\n    # Count the frequency of each letter\n    counter = Counter(my_dict)\n\n    # Find the 3 most common letters\n    most_common_letters = heapq.nlargest(3, counter.items(), key=lambda x: x[1])\n    most_common_letters = [letter for letter, count in most_common_letters]\n\n    return most_common_letters\n\n# Test the function"}
{"task_id": "BigCodeBench/741", "solution": "from itertools import groupby\nfrom operator import itemgetter\nKEY_FUNC = itemgetter(0)\ndef task_func(my_dict):\n    # Sort the dictionary by key\n    sorted_dict = dict(sorted(my_dict.items(), key=KEY_FUNC))\n\n    # Group the dictionary entries by the first character of the key\n    grouped_dict = {key: list(group) for key, group in groupby(sorted_dict.items(), KEY_FUNC)}\n\n    # Add the values for each group\n    aggregated_dict = {key: sum(int(item[1]) for item in group) for key, group in grouped_dict.items()}\n\n    return aggregated_dict\nmy_dict = {'apple': 10, 'banana': 20, 'cherry': 15, 'date': 5, 'elderberry': 30}", "raw_solution": "from itertools import groupby\nfrom operator import itemgetter\n\n# Constants\nKEY_FUNC = itemgetter(0)\n\ndef task_func(my_dict):\n    # Sort the dictionary by key\n    sorted_dict = dict(sorted(my_dict.items(), key=KEY_FUNC))\n\n    # Group the dictionary entries by the first character of the key\n    grouped_dict = {key: list(group) for key, group in groupby(sorted_dict.items(), KEY_FUNC)}\n\n    # Add the values for each group\n    aggregated_dict = {key: sum(int(item[1]) for item in group) for key, group in grouped_dict.items()}\n\n    return aggregated_dict\n\n# Test the function\nmy_dict = {'apple': 10, 'banana': 20, 'cherry': 15, 'date': 5, 'elderberry': 30}"}
{"task_id": "BigCodeBench/742", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(list_of_pairs):\n    if not list_of_pairs:\n        raise Exception(\"Input array is empty\")\n\n    for pair in list_of_pairs:\n        if not isinstance(pair, tuple) or not len(pair) == 2:\n            raise ValueError(\"Values are not numeric\")\n        if not isinstance(pair[0], (int, float)) or not isinstance(pair[1], (int, float)):\n            raise ValueError(\"Values are not numeric\")\n\n    data = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    scaler = MinMaxScaler()\n    data['Value'] = scaler.fit_transform(data[['Value']])\n\n    return data", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(list_of_pairs):\n    if not list_of_pairs:\n        raise Exception(\"Input array is empty\")\n\n    for pair in list_of_pairs:\n        if not isinstance(pair, tuple) or not len(pair) == 2:\n            raise ValueError(\"Values are not numeric\")\n        if not isinstance(pair[0], (int, float)) or not isinstance(pair[1], (int, float)):\n            raise ValueError(\"Values are not numeric\")\n\n    data = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    scaler = MinMaxScaler()\n    data['Value'] = scaler.fit_transform(data[['Value']])\n\n    return data"}
{"task_id": "BigCodeBench/743", "solution": "import json\nimport os\nPREFIXES = [\"is_\", \"has_\", \"can_\", \"should_\"]\ndef task_func(directory):\n    # Initialize a dictionary to store the counts\n    stats = {prefix: 0 for prefix in PREFIXES}\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the file and load the JSON data\n            with open(os.path.join(directory, filename), 'r') as file:\n                data = json.load(file)\n\n            # Recursively search for keys starting with the prefixes\n            for prefix in PREFIXES:\n                stats[prefix] += sum(key.startswith(prefix) for key in data.keys())\n\n    return stats", "raw_solution": "import json\nimport os\n\n# Constants\nPREFIXES = [\"is_\", \"has_\", \"can_\", \"should_\"]\n\ndef task_func(directory):\n    # Initialize a dictionary to store the counts\n    stats = {prefix: 0 for prefix in PREFIXES}\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the file and load the JSON data\n            with open(os.path.join(directory, filename), 'r') as file:\n                data = json.load(file)\n\n            # Recursively search for keys starting with the prefixes\n            for prefix in PREFIXES:\n                stats[prefix] += sum(key.startswith(prefix) for key in data.keys())\n\n    return stats\n\n# Test the function"}
{"task_id": "BigCodeBench/744", "solution": "import nltk\nfrom string import punctuation\nimport pandas as pd\ndef task_func(text):\n    if not isinstance(text, str):\n        raise ValueError(\"Input should be a string\")\n\n    # Remove punctuation from text\n    text = ''.join(ch for ch in text if ch not in punctuation)\n\n    # Split text into words\n    words = nltk.word_tokenize(text)\n\n    # Filter words that start with '$'\n    dollar_words = [word for word in words if word.startswith('$')]\n\n    # Count occurrences of each word\n    freq_dist = nltk.FreqDist(dollar_words)\n\n    # Create a pandas DataFrame\n    df = pd.DataFrame(list(freq_dist.items()), columns=[\"Word\", \"Frequency\"])\n\n    return df\ntext = \"$hello this is a $test $test $test\"", "raw_solution": "import nltk\nfrom string import punctuation\nimport pandas as pd\ndef task_func(text):\n    if not isinstance(text, str):\n        raise ValueError(\"Input should be a string\")\n\n    # Remove punctuation from text\n    text = ''.join(ch for ch in text if ch not in punctuation)\n\n    # Split text into words\n    words = nltk.word_tokenize(text)\n\n    # Filter words that start with '$'\n    dollar_words = [word for word in words if word.startswith('$')]\n\n    # Count occurrences of each word\n    freq_dist = nltk.FreqDist(dollar_words)\n\n    # Create a pandas DataFrame\n    df = pd.DataFrame(list(freq_dist.items()), columns=[\"Word\", \"Frequency\"])\n\n    return df\n\ntext = \"$hello this is a $test $test $test\""}
{"task_id": "BigCodeBench/745", "solution": "import subprocess\nimport random\nimport os\nSCRIPTS = ['script1.sh', 'script2.sh', 'script3.sh']\nSCRIPTS_DIR = '/path/to/scripts'\ndef task_func():\n    # Select a random script\n    script = random.choice(SCRIPTS)\n    script_path = os.path.join(SCRIPTS_DIR, script)\n\n    # Run the script\n    subprocess.run(['bash', script_path])\n\n    return script_path", "raw_solution": "import subprocess\nimport random\nimport os\n\n# Constants\nSCRIPTS = ['script1.sh', 'script2.sh', 'script3.sh']\nSCRIPTS_DIR = '/path/to/scripts'  # replace with your scripts directory\n\ndef task_func():\n    # Select a random script\n    script = random.choice(SCRIPTS)\n    script_path = os.path.join(SCRIPTS_DIR, script)\n\n    # Run the script\n    subprocess.run(['bash', script_path])\n\n    return script_path\n\n# Test the function"}
{"task_id": "BigCodeBench/746", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, target_column, target_values=None):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"df should be a pandas DataFrame\")\n    # Check if target_column is a string\n    if not isinstance(target_column, str):\n        raise ValueError(\"target_column should be a string\")\n    # Check if target_values is an array-like object\n    if target_values is not None and not isinstance(target_values, (list, tuple, np.ndarray)):\n        raise ValueError(\"target_values should be an array-like object\")\n\n    # Replace all elements in DataFrame columns that are not present in the target_values array with zeros\n    if target_values is not None:\n        for col in df.columns:\n            df[col] = df[col].apply(lambda x: x if x in target_values else 0)\n\n    # Perform a linear regression using the target column\n    model = LinearRegression()\n    model.fit(df.drop(columns=[target_column]), df[target_column])\n\n    return model\nrng = np.random.default_rng(seed=0)\ndf = pd.DataFrame(rng.integers(0, 100, size=(1000, 5)), columns=['A', 'B', 'C', 'D', 'predict'])", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, target_column, target_values=None):\n    # Check if df is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"df should be a pandas DataFrame\")\n    # Check if target_column is a string\n    if not isinstance(target_column, str):\n        raise ValueError(\"target_column should be a string\")\n    # Check if target_values is an array-like object\n    if target_values is not None and not isinstance(target_values, (list, tuple, np.ndarray)):\n        raise ValueError(\"target_values should be an array-like object\")\n\n    # Replace all elements in DataFrame columns that are not present in the target_values array with zeros\n    if target_values is not None:\n        for col in df.columns:\n            df[col] = df[col].apply(lambda x: x if x in target_values else 0)\n\n    # Perform a linear regression using the target column\n    model = LinearRegression()\n    model.fit(df.drop(columns=[target_column]), df[target_column])\n\n    return model\n\n# Test the function\nrng = np.random.default_rng(seed=0)\ndf = pd.DataFrame(rng.integers(0, 100, size=(1000, 5)), columns=['A', 'B', 'C', 'D', 'predict'])\nmodel = task_func(df, 'predict')"}
{"task_id": "BigCodeBench/747", "solution": "import re\nimport math\ndef task_func(s):\n    # Find all numbers in the string\n    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|[-+]?\\d+\", s)\n    \n    # Initialize count and sum\n    count = len(numbers)\n    sqrt_sum = 0\n    \n    # Calculate sum of square roots\n    for num in numbers:\n        sqrt_sum += math.sqrt(float(num))\n    \n    return count, sqrt_sum\ns = \"1, 2.0, 3, -4.5, 5\"", "raw_solution": "import re\nimport math\n\ndef task_func(s):\n    # Find all numbers in the string\n    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|[-+]?\\d+\", s)\n    \n    # Initialize count and sum\n    count = len(numbers)\n    sqrt_sum = 0\n    \n    # Calculate sum of square roots\n    for num in numbers:\n        sqrt_sum += math.sqrt(float(num))\n    \n    return count, sqrt_sum\n\n# Test the function\ns = \"1, 2.0, 3, -4.5, 5\"\ncount, sqrt_sum = task_func(s)"}
{"task_id": "BigCodeBench/748", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, age, weight):\n    # Check if the DataFrame contains the required columns\n    if 'Age' not in df.columns or 'Weight' not in df.columns:\n        raise KeyError(\"The input DataFrame does not contain the required columns 'Age' and 'Weight'\")\n\n    # Filter the DataFrame based on the age and weight criteria\n    filtered_df = df[(df['Age'] < age) & (df['Weight'] > weight)]\n\n    # If the filtered DataFrame is not empty, standardize the numerical values\n    if not filtered_df.empty:\n        scaler = StandardScaler()\n        filtered_df[filtered_df.columns] = scaler.fit_transform(filtered_df[filtered_df.columns])\n\n    return filtered_df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, age, weight):\n    # Check if the DataFrame contains the required columns\n    if 'Age' not in df.columns or 'Weight' not in df.columns:\n        raise KeyError(\"The input DataFrame does not contain the required columns 'Age' and 'Weight'\")\n\n    # Filter the DataFrame based on the age and weight criteria\n    filtered_df = df[(df['Age'] < age) & (df['Weight'] > weight)]\n\n    # If the filtered DataFrame is not empty, standardize the numerical values\n    if not filtered_df.empty:\n        scaler = StandardScaler()\n        filtered_df[filtered_df.columns] = scaler.fit_transform(filtered_df[filtered_df.columns])\n\n    return filtered_df\n\n# Test the function\ndata = pd.DataFrame({\n    \"Age\": [32, 51, 11, 5, 88, 434],\n    \"Weight\": [62, 76, 72, 859, 69, 102],\n    \"shoe_size\": [12, 6, 7, 8, 9, 6]\n})"}
{"task_id": "BigCodeBench/749", "solution": "from sklearn.preprocessing import MinMaxScaler\nimport numpy as np\ndef task_func(myList):\n    # Convert list to numpy array\n    np_array = np.array(myList).reshape(-1, 1)\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the data\n    normalized_data = scaler.fit_transform(np_array)\n\n    # Return as numpy array\n    return np.array(normalized_data).reshape(-1)", "raw_solution": "from sklearn.preprocessing import MinMaxScaler\nimport numpy as np\n\ndef task_func(myList):\n    # Convert list to numpy array\n    np_array = np.array(myList).reshape(-1, 1)\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the data\n    normalized_data = scaler.fit_transform(np_array)\n\n    # Return as numpy array\n    return np.array(normalized_data).reshape(-1)\n\n# Test the function"}
{"task_id": "BigCodeBench/750", "solution": "import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\ndef task_func(df: pd.DataFrame, height: int, weight: int, columns: list) -> sm.regression.linear_model.RegressionResultsWrapper:\n    if df.empty or df.shape[0] == 0:\n        return None\n    else:\n        subset_df = df.loc[(df[columns[1]] > height) & (df[columns[2]] < weight)]\n        if subset_df.empty or subset_df.shape[0] == 0:\n            return None\n        else:\n            X = sm.add_constant(subset_df[columns[0]])\n            y = subset_df[columns[1]]\n            model = sm.OLS(y, X)\n            results = model.fit()\n            return results\ndf = pd.DataFrame(np.random.randint(10,98,size=(100, 3)), columns=['Age', 'Height', 'Weight'])", "raw_solution": "import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\ndef task_func(df: pd.DataFrame, height: int, weight: int, columns: list) -> sm.regression.linear_model.RegressionResultsWrapper:\n    if df.empty or df.shape[0] == 0:\n        return None\n    else:\n        subset_df = df.loc[(df[columns[1]] > height) & (df[columns[2]] < weight)]\n        if subset_df.empty or subset_df.shape[0] == 0:\n            return None\n        else:\n            X = sm.add_constant(subset_df[columns[0]])\n            y = subset_df[columns[1]]\n            model = sm.OLS(y, X)\n            results = model.fit()\n            return results\n\n# Testing the function\ndf = pd.DataFrame(np.random.randint(10,98,size=(100, 3)), columns=['Age', 'Height', 'Weight'])\nmodel = task_func(df, 45, 72, columns=['Age', 'Height', 'Weight'])"}
{"task_id": "BigCodeBench/751", "solution": "import random\nfrom collections import Counter\ndef task_func(values, weights, n_samples):\n    random.seed(0)  # for reproducibility\n    samples = random.choices(values, weights, k=n_samples)\n    histogram = dict(Counter(samples))\n    return histogram\nvalues = [1, 2, 3, 4, 5]\nweights = [0.1, 0.2, 0.3, 0.2, 0.2]\nn_samples = 1000", "raw_solution": "import random\nfrom collections import Counter\n\ndef task_func(values, weights, n_samples):\n    random.seed(0)  # for reproducibility\n    samples = random.choices(values, weights, k=n_samples)\n    histogram = dict(Counter(samples))\n    return histogram\n\n# Test the function\nvalues = [1, 2, 3, 4, 5]\nweights = [0.1, 0.2, 0.3, 0.2, 0.2]\nn_samples = 1000\n\nhistogram = task_func(values, weights, n_samples)"}
{"task_id": "BigCodeBench/752", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data is not a DataFrame.\")\n    if data.empty:\n        raise ValueError(\"Data is empty.\")\n    if target_column not in data.columns:\n        raise ValueError(f\"{target_column} is not a column of data.\")\n    if not np.issubdtype(data.dtypes.object, np.number).all():\n        raise ValueError(\"Data contains values that are not numeric.\")\n    if not isinstance(random_state, int):\n        raise ValueError(\"Random state is not an integer.\")\n    if not 0 <= test_size <= 1:\n        raise ValueError(\"Test size is not between 0 and 1.\")\n\n    X = data.drop([target_column], axis=1)\n    y = data[target_column]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    return model.score(X_test, y_test)", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data is not a DataFrame.\")\n    if data.empty:\n        raise ValueError(\"Data is empty.\")\n    if target_column not in data.columns:\n        raise ValueError(f\"{target_column} is not a column of data.\")\n    if not np.issubdtype(data.dtypes.object, np.number).all():\n        raise ValueError(\"Data contains values that are not numeric.\")\n    if not isinstance(random_state, int):\n        raise ValueError(\"Random state is not an integer.\")\n    if not 0 <= test_size <= 1:\n        raise ValueError(\"Test size is not between 0 and 1.\")\n\n    X = data.drop([target_column], axis=1)\n    y = data[target_column]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    return model.score(X_test, y_test)"}
{"task_id": "BigCodeBench/753", "solution": "import math\nimport random\nimport statistics\nRADIUS = 5\ndef task_func(n):\n    # Generate n random points within a circle of radius RADIUS\n    points = [(random.uniform(-RADIUS, RADIUS), random.uniform(-RADIUS, RADIUS)) for _ in range(n)]\n    \n    # Calculate the distance of each point from the center (0,0)\n    distances = [math.sqrt(x**2 + y**2) for x, y in points]\n    \n    # Return the average distance\n    return statistics.mean(distances)", "raw_solution": "import math\nimport random\nimport statistics\n\n# Constants\nRADIUS = 5\n\ndef task_func(n):\n    # Generate n random points within a circle of radius RADIUS\n    points = [(random.uniform(-RADIUS, RADIUS), random.uniform(-RADIUS, RADIUS)) for _ in range(n)]\n    \n    # Calculate the distance of each point from the center (0,0)\n    distances = [math.sqrt(x**2 + y**2) for x, y in points]\n    \n    # Return the average distance\n    return statistics.mean(distances)\n\n# Test the function"}
{"task_id": "BigCodeBench/754", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(result):\n    # Check if result is a pandas DataFrame\n    if not isinstance(result, pd.DataFrame):\n        raise TypeError(\"Input should be a pandas DataFrame\")\n\n    # Check if 'from_user' column exists in the DataFrame\n    if 'from_user' not in result.columns:\n        raise ValueError(\"'from_user' column not found in the DataFrame\")\n\n    # Check if 'from_user' column contains only numeric values\n    if not pd.api.types.is_numeric_dtype(result['from_user']):\n        raise ValueError(\"'from_user' values should be numeric\")\n\n    # Calculate statistics\n    current_time = datetime.now().strftime(DATE_FORMAT)\n    stats_summary = pd.Series(dtype=np.float64)\n    if result['from_user'].count() > 0:\n        stats_summary['mean'] = np.mean(result['from_user'])\n        stats_summary['median'] = np.median(result['from_user'])\n        stats_summary['min'] = np.min(result['from_user'])\n        stats_summary['max'] = np.max(result['from_user'])\n        stats_summary['std'] = np.std(result['from_user'])\n    else:\n        stats_summary['mean'] = np.nan\n        stats_summary['median'] = np.nan\n        stats_summary['min'] = np.nan\n        stats_summary['max'] = np.nan\n        stats_summary['std'] = np.nan\n\n    stats_summary['current_time'] = current_time\n\n    return stats_summary", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\n# Constants\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(result):\n    # Check if result is a pandas DataFrame\n    if not isinstance(result, pd.DataFrame):\n        raise TypeError(\"Input should be a pandas DataFrame\")\n\n    # Check if 'from_user' column exists in the DataFrame\n    if 'from_user' not in result.columns:\n        raise ValueError(\"'from_user' column not found in the DataFrame\")\n\n    # Check if 'from_user' column contains only numeric values\n    if not pd.api.types.is_numeric_dtype(result['from_user']):\n        raise ValueError(\"'from_user' values should be numeric\")\n\n    # Calculate statistics\n    current_time = datetime.now().strftime(DATE_FORMAT)\n    stats_summary = pd.Series(dtype=np.float64)\n    if result['from_user'].count() > 0:\n        stats_summary['mean'] = np.mean(result['from_user'])\n        stats_summary['median'] = np.median(result['from_user'])\n        stats_summary['min'] = np.min(result['from_user'])\n        stats_summary['max'] = np.max(result['from_user'])\n        stats_summary['std'] = np.std(result['from_user'])\n    else:\n        stats_summary['mean'] = np.nan\n        stats_summary['median'] = np.nan\n        stats_summary['min'] = np.nan\n        stats_summary['max'] = np.nan\n        stats_summary['std'] = np.nan\n\n    stats_summary['current_time'] = current_time\n\n    return stats_summary"}
{"task_id": "BigCodeBench/755", "solution": "import os\nimport glob\ndef task_func(directory_path):\n    # Get all file names in the directory\n    filenames = glob.glob(os.path.join(directory_path, '*'))\n\n    new_filenames = []\n    for filename in filenames:\n        # Split the filename by periods\n        parts = filename.split('.')\n        # Reverse the order of the parts\n        parts.reverse()\n        # Join the parts back together with periods\n        new_filename = '.'.join(parts)\n        # Append the new filename to the list\n        new_filenames.append(new_filename)\n\n    return new_filenames", "raw_solution": "import os\nimport glob\n\ndef task_func(directory_path):\n    # Get all file names in the directory\n    filenames = glob.glob(os.path.join(directory_path, '*'))\n\n    new_filenames = []\n    for filename in filenames:\n        # Split the filename by periods\n        parts = filename.split('.')\n        # Reverse the order of the parts\n        parts.reverse()\n        # Join the parts back together with periods\n        new_filename = '.'.join(parts)\n        # Append the new filename to the list\n        new_filenames.append(new_filename)\n\n    return new_filenames"}
{"task_id": "BigCodeBench/756", "solution": "import shutil\nfrom pathlib import Path\nfrom typing import List\ndef task_func(source_dir: str, target_dir: str, extensions: List[str]) -> int:\n    source_dir_path = Path(source_dir)\n    target_dir_path = Path(target_dir)\n\n    if not source_dir_path.exists():\n        raise ValueError(f\"Source directory {source_dir} does not exist.\")\n    if not target_dir_path.exists():\n        raise ValueError(f\"Target directory {target_dir} does not exist.\")\n\n    moved_files_count = 0\n    for ext in extensions:\n        for file in source_dir_path.glob(f'**/*.{ext}'):\n            shutil.move(str(file), target_dir_path)\n            moved_files_count += 1\n\n    return moved_files_count", "raw_solution": "import shutil\nfrom pathlib import Path\nfrom typing import List\n\ndef task_func(source_dir: str, target_dir: str, extensions: List[str]) -> int:\n    source_dir_path = Path(source_dir)\n    target_dir_path = Path(target_dir)\n\n    if not source_dir_path.exists():\n        raise ValueError(f\"Source directory {source_dir} does not exist.\")\n    if not target_dir_path.exists():\n        raise ValueError(f\"Target directory {target_dir} does not exist.\")\n\n    moved_files_count = 0\n    for ext in extensions:\n        for file in source_dir_path.glob(f'**/*.{ext}'):\n            shutil.move(str(file), target_dir_path)\n            moved_files_count += 1\n\n    return moved_files_count"}
{"task_id": "BigCodeBench/757", "solution": "import numpy as np\ndef task_func(arr):\n    # Check if the input is a numpy array\n    if not isinstance(arr, np.ndarray):\n        raise TypeError(\"Input should be a numpy array\")\n\n    # Convert the numpy array to a list\n    arr_list = arr.tolist()\n\n    # Reverse the order of words in each string\n    for i in range(len(arr_list)):\n        arr_list[i] = \" \".join(arr_list[i].split()[::-1])\n\n    # Convert the list back to a numpy array\n    arr = np.array(arr_list)\n\n    return arr", "raw_solution": "import numpy as np\n\ndef task_func(arr):\n    # Check if the input is a numpy array\n    if not isinstance(arr, np.ndarray):\n        raise TypeError(\"Input should be a numpy array\")\n\n    # Convert the numpy array to a list\n    arr_list = arr.tolist()\n\n    # Reverse the order of words in each string\n    for i in range(len(arr_list)):\n        arr_list[i] = \" \".join(arr_list[i].split()[::-1])\n\n    # Convert the list back to a numpy array\n    arr = np.array(arr_list)\n\n    return arr"}
{"task_id": "BigCodeBench/758", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(num_samples, countries=['Russia', 'China', 'USA', 'India', 'Brazil'], \n           ages=np.arange(18, 60), genders=['Male', 'Female'], rng_seed=None):\n    if not isinstance(num_samples, int):\n        raise ValueError(\"num_samples should be an integer\")\n\n    rng = np.random.default_rng(rng_seed)\n\n    country = rng.choice(countries, num_samples)\n    age = rng.choice(ages, num_samples)\n\n    le = LabelEncoder()\n    gender = le.fit_transform(rng.choice(genders, num_samples))\n\n    data = {'Country': country, 'Age': age, 'Gender': gender}\n    df = pd.DataFrame(data)\n\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(num_samples, countries=['Russia', 'China', 'USA', 'India', 'Brazil'], \n           ages=np.arange(18, 60), genders=['Male', 'Female'], rng_seed=None):\n    if not isinstance(num_samples, int):\n        raise ValueError(\"num_samples should be an integer\")\n\n    rng = np.random.default_rng(rng_seed)\n\n    country = rng.choice(countries, num_samples)\n    age = rng.choice(ages, num_samples)\n\n    le = LabelEncoder()\n    gender = le.fit_transform(rng.choice(genders, num_samples))\n\n    data = {'Country': country, 'Age': age, 'Gender': gender}\n    df = pd.DataFrame(data)\n\n    return df\n\n# Testing the function\ndemographics = task_func(5, countries=['Austria', 'Germany'], rng_seed=3)"}
{"task_id": "BigCodeBench/759", "solution": "import os\nimport shutil\nimport fnmatch\ndef task_func(source_directory, destination_directory, file_pattern):\n    # Check if source directory exists\n    if not os.path.isdir(source_directory):\n        return \"Source directory does not exist.\"\n\n    # Check if destination directory exists, if not create it\n    if not os.path.isdir(destination_directory):\n        os.makedirs(destination_directory)\n\n    # Get a list of all files in the source directory\n    files = os.listdir(source_directory)\n\n    # Filter the list of files to only include those that match the file pattern\n    matching_files = fnmatch.filter(files, file_pattern)\n\n    # Move each matching file from the source directory to the destination directory\n    moved_files = []\n    for file in matching_files:\n        shutil.move(os.path.join(source_directory, file), destination_directory)\n        moved_files.append(file)\n\n    return moved_files\nsource_directory = \"/path/to/source\"\ndestination_directory = \"/path/to/destination\"\nfile_pattern = \"*.txt\"", "raw_solution": "import os\nimport shutil\nimport fnmatch\n\ndef task_func(source_directory, destination_directory, file_pattern):\n    # Check if source directory exists\n    if not os.path.isdir(source_directory):\n        return \"Source directory does not exist.\"\n\n    # Check if destination directory exists, if not create it\n    if not os.path.isdir(destination_directory):\n        os.makedirs(destination_directory)\n\n    # Get a list of all files in the source directory\n    files = os.listdir(source_directory)\n\n    # Filter the list of files to only include those that match the file pattern\n    matching_files = fnmatch.filter(files, file_pattern)\n\n    # Move each matching file from the source directory to the destination directory\n    moved_files = []\n    for file in matching_files:\n        shutil.move(os.path.join(source_directory, file), destination_directory)\n        moved_files.append(file)\n\n    return moved_files\n\n# Test the function\nsource_directory = \"/path/to/source\"\ndestination_directory = \"/path/to/destination\"\nfile_pattern = \"*.txt\""}
{"task_id": "BigCodeBench/760", "solution": "import pandas as pd\nimport numpy as np\nimport random\nimport datetime\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n\n    random.seed(rng_seed)\n    np.random.seed(rng_seed)\n\n    # Generate random data\n    ids = list(range(1, 101))\n    names = latin_names + other_names\n    random.shuffle(names)\n    dobs = [datetime.datetime(random.randint(start_year, end_year), random.randint(1, 12), random.randint(1, 28)) for _ in range(100)]\n    emails = [f\"{name.lower()}{dob.strftime('%Y')}@{email_domain}\" for name, dob in zip(names, dobs)]\n\n    # Create DataFrame\n    df = pd.DataFrame(list(zip(ids, names, dobs, emails)), \n                      columns =['ID', 'Name', 'Date of Birth', 'Email'])\n\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport random\nimport datetime\n\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n\n    random.seed(rng_seed)\n    np.random.seed(rng_seed)\n\n    # Generate random data\n    ids = list(range(1, 101))\n    names = latin_names + other_names\n    random.shuffle(names)\n    dobs = [datetime.datetime(random.randint(start_year, end_year), random.randint(1, 12), random.randint(1, 28)) for _ in range(100)]\n    emails = [f\"{name.lower()}{dob.strftime('%Y')}@{email_domain}\" for name, dob in zip(names, dobs)]\n\n    # Create DataFrame\n    df = pd.DataFrame(list(zip(ids, names, dobs, emails)), \n                      columns =['ID', 'Name', 'Date of Birth', 'Email'])\n\n    return df\n\n# Test the function\ndf = task_func(start_year=1980, end_year=2000, email_domain='test.at', rng_seed=3)"}
{"task_id": "BigCodeBench/761", "solution": "import json\nimport re\nfrom collections import Counter\nREPLACE_NONE = \"None\"\nEMAIL_REGEX = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\ndef task_func(json_str):\n    # Load JSON\n    data = json.loads(json_str)\n\n    # Remove None values\n    data = {k: v for k, v in data.items() if v is not None}\n\n    # Replace email addresses with placeholder\n    data = {k: re.sub(EMAIL_REGEX, REPLACE_NONE, str(v)) for k, v in data.items()}\n\n    # Count the frequency of each unique value\n    value_counts = Counter(data.values())\n\n    return {\n        \"data\": data,\n        \"value_counts\": value_counts\n    }\njson_str = json.dumps({\"name\": \"John\", \"email\": \"john@example.com\", \"age\": 30, \"city\": \"New York\", \"country\": None, \"email2\": \"john2@example.com\"})", "raw_solution": "import json\nimport re\nfrom collections import Counter\n\n# Constants\nREPLACE_NONE = \"None\"\nEMAIL_REGEX = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n\ndef task_func(json_str):\n    # Load JSON\n    data = json.loads(json_str)\n\n    # Remove None values\n    data = {k: v for k, v in data.items() if v is not None}\n\n    # Replace email addresses with placeholder\n    data = {k: re.sub(EMAIL_REGEX, REPLACE_NONE, str(v)) for k, v in data.items()}\n\n    # Count the frequency of each unique value\n    value_counts = Counter(data.values())\n\n    return {\n        \"data\": data,\n        \"value_counts\": value_counts\n    }\n\n# Test\njson_str = json.dumps({\"name\": \"John\", \"email\": \"john@example.com\", \"age\": 30, \"city\": \"New York\", \"country\": None, \"email2\": \"john2@example.com\"})\nresult = task_func(json_str)"}
{"task_id": "BigCodeBench/762", "solution": "import os\nimport zipfile\nimport codecs\ndef task_func(directory_name=\"latin_files\",\n              content='Sopet\u00f3n',\n              file_names=['file1.txt', 'file2.txt', 'file3.txt'],\n              encoding=\"latin-1\"):\n\n    # Create directory\n    if not os.path.exists(directory_name):\n        os.makedirs(directory_name)\n\n    # Create .txt files\n    for file_name in file_names:\n        with open(os.path.join(directory_name, file_name), 'w', encoding=encoding) as f:\n            f.write(content)\n\n    # Zip the directory\n    zipped_file = directory_name + '.zip'\n    with zipfile.ZipFile(zipped_file, 'w') as zipf:\n        for file_name in file_names:\n            zipf.write(os.path.join(directory_name, file_name), arcname=file_name)\n\n    return zipped_file", "raw_solution": "import os\nimport zipfile\nimport codecs\n\ndef task_func(directory_name=\"latin_files\",\n              content='Sopet\u00f3n',\n              file_names=['file1.txt', 'file2.txt', 'file3.txt'],\n              encoding=\"latin-1\"):\n\n    # Create directory\n    if not os.path.exists(directory_name):\n        os.makedirs(directory_name)\n\n    # Create .txt files\n    for file_name in file_names:\n        with open(os.path.join(directory_name, file_name), 'w', encoding=encoding) as f:\n            f.write(content)\n\n    # Zip the directory\n    zipped_file = directory_name + '.zip'\n    with zipfile.ZipFile(zipped_file, 'w') as zipf:\n        for file_name in file_names:\n            zipf.write(os.path.join(directory_name, file_name), arcname=file_name)\n\n    return zipped_file\n\n# Test the function\nzipped_file = task_func(directory_name=\"directorio\", content='hi', file_names=[\"custom1.txt\", \"custom2.txt\"], encoding='utf-8')"}
{"task_id": "BigCodeBench/763", "solution": "import numpy as np\nfrom collections import defaultdict\nimport json\nimport csv\nFIELDNAMES = ['field', 'mean', 'median']\ndef task_func(input_file, output_file):\n    # Read JSON file\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    # Initialize defaultdict to store mean and median\n    mean_median_dict = defaultdict(lambda: {'mean': None, 'median': None})\n\n    # Calculate mean and median for each key\n    for key in data[0].keys():\n        values = [d[key] for d in data if isinstance(d.get(key), (int, float))]\n        mean_median_dict[key]['mean'] = np.mean(values)\n        mean_median_dict[key]['median'] = np.median(values)\n\n    # Write results to CSV file\n    with open(output_file, 'w', newline='') as f:\n        writer = csv.DictWriter(f, fieldnames=FIELDNAMES)\n        writer.writeheader()\n        for field, stats in mean_median_dict.items():\n            writer.writerow({'field': field, 'mean': stats['mean'], 'median': stats['median']})\n\n    return mean_median_dict", "raw_solution": "import numpy as np\nfrom collections import defaultdict\nimport json\nimport csv\n\n# Constants\nFIELDNAMES = ['field', 'mean', 'median']\n\ndef task_func(input_file, output_file):\n    # Read JSON file\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    # Initialize defaultdict to store mean and median\n    mean_median_dict = defaultdict(lambda: {'mean': None, 'median': None})\n\n    # Calculate mean and median for each key\n    for key in data[0].keys():\n        values = [d[key] for d in data if isinstance(d.get(key), (int, float))]\n        mean_median_dict[key]['mean'] = np.mean(values)\n        mean_median_dict[key]['median'] = np.median(values)\n\n    # Write results to CSV file\n    with open(output_file, 'w', newline='') as f:\n        writer = csv.DictWriter(f, fieldnames=FIELDNAMES)\n        writer.writeheader()\n        for field, stats in mean_median_dict.items():\n            writer.writerow({'field': field, 'mean': stats['mean'], 'median': stats['median']})\n\n    return mean_median_dict"}
{"task_id": "BigCodeBench/764", "solution": "", "raw_solution": ""}
{"task_id": "BigCodeBench/765", "solution": "import os\nfrom pathlib import Path\nimport shutil\ndef task_func(file_dict, target_dir=\"non_none_files\"):\n    copied_files = []\n\n    # Create target directory if it doesn't exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # Iterate over the dictionary\n    for file_name, file_path in file_dict.items():\n        # Check if file exists\n        if os.path.isfile(file_path):\n            # Check if file is not empty\n            if os.path.getsize(file_path) > 0:\n                # Copy file to target directory\n                shutil.copy2(file_path, target_dir)\n                # Append full file path to list\n                copied_files.append(os.path.join(target_dir, file_name))\n\n    return copied_files", "raw_solution": "import os\nfrom pathlib import Path\nimport shutil\n\ndef task_func(file_dict, target_dir=\"non_none_files\"):\n    copied_files = []\n\n    # Create target directory if it doesn't exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # Iterate over the dictionary\n    for file_name, file_path in file_dict.items():\n        # Check if file exists\n        if os.path.isfile(file_path):\n            # Check if file is not empty\n            if os.path.getsize(file_path) > 0:\n                # Copy file to target directory\n                shutil.copy2(file_path, target_dir)\n                # Append full file path to list\n                copied_files.append(os.path.join(target_dir, file_name))\n\n    return copied_files"}
{"task_id": "BigCodeBench/766", "solution": "import re\nimport collections\ndef task_func(string, patterns=['nnn', 'aaa', 'sss', 'ddd', 'fff']):\n    # Check if string is of type str\n    if not isinstance(string, str):\n        raise TypeError(\"String should be of type str\")\n\n    # Check if patterns is a list of str\n    if not all(isinstance(i, str) for i in patterns):\n        raise TypeError(\"Patterns should be a list of str\")\n\n    # Initialize a dictionary to store the counts\n    count_dict = collections.defaultdict(int)\n\n    # For each pattern, count its occurrences in the string\n    for pattern in patterns:\n        count_dict[pattern] = len(re.findall(pattern, string))\n\n    return count_dict", "raw_solution": "import re\nimport collections\n\ndef task_func(string, patterns=['nnn', 'aaa', 'sss', 'ddd', 'fff']):\n    # Check if string is of type str\n    if not isinstance(string, str):\n        raise TypeError(\"String should be of type str\")\n\n    # Check if patterns is a list of str\n    if not all(isinstance(i, str) for i in patterns):\n        raise TypeError(\"Patterns should be a list of str\")\n\n    # Initialize a dictionary to store the counts\n    count_dict = collections.defaultdict(int)\n\n    # For each pattern, count its occurrences in the string\n    for pattern in patterns:\n        count_dict[pattern] = len(re.findall(pattern, string))\n\n    return count_dict\n\n# Test the function"}
{"task_id": "BigCodeBench/767", "solution": "from collections import Counter\nimport random\nimport string\nLETTERS = string.ascii_letters\ndef task_func(list_of_lists):\n    # Replace each sublist with a random letter\n    replaced_list = [random.choice(LETTERS) for _ in list_of_lists]\n    \n    # Count the occurrences of each letter in the list\n    count_dict = dict(Counter(replaced_list))\n    \n    return count_dict\nlist_of_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]", "raw_solution": "from collections import Counter\nimport random\nimport string\n\n# Constants\nLETTERS = string.ascii_letters\n\ndef task_func(list_of_lists):\n    # Replace each sublist with a random letter\n    replaced_list = [random.choice(LETTERS) for _ in list_of_lists]\n    \n    # Count the occurrences of each letter in the list\n    count_dict = dict(Counter(replaced_list))\n    \n    return count_dict\n\n# Test the function\nlist_of_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]"}
{"task_id": "BigCodeBench/768", "solution": "import re\nimport os\nimport glob\ndef task_func(dir_path):\n    if not os.path.isdir(dir_path):\n        raise ValueError(\"Directory does not exist.\")\n\n    file_dict = {}\n    for filename in glob.iglob(dir_path + '/**/*.txt', recursive=True):\n        with open(filename, 'r') as file:\n            count = len(re.findall(r'\\berror\\b', file.read().lower()))\n            file_dict[os.path.relpath(filename, dir_path)] = count\n\n    return file_dict", "raw_solution": "import re\nimport os\nimport glob\n\ndef task_func(dir_path):\n    if not os.path.isdir(dir_path):\n        raise ValueError(\"Directory does not exist.\")\n\n    file_dict = {}\n    for filename in glob.iglob(dir_path + '/**/*.txt', recursive=True):\n        with open(filename, 'r') as file:\n            count = len(re.findall(r'\\berror\\b', file.read().lower()))\n            file_dict[os.path.relpath(filename, dir_path)] = count\n\n    return file_dict"}
{"task_id": "BigCodeBench/769", "solution": "from collections import Counter\nimport itertools\nimport operator\ndef task_func(list_of_menuitems):\n    # Flatten the list\n    flat_list = list(itertools.chain.from_iterable(list_of_menuitems))\n    # Count the frequency of each item\n    counter = Counter(flat_list)\n    # Get the most common item\n    most_common_item = max(counter.items(), key=operator.itemgetter(1))[0]\n    return most_common_item", "raw_solution": "from collections import Counter\nimport itertools\nimport operator\n\ndef task_func(list_of_menuitems):\n    # Flatten the list\n    flat_list = list(itertools.chain.from_iterable(list_of_menuitems))\n    # Count the frequency of each item\n    counter = Counter(flat_list)\n    # Get the most common item\n    most_common_item = max(counter.items(), key=operator.itemgetter(1))[0]\n    return most_common_item\n\n# Test the function\nmenu_items = [['Pasta', 'Pizza', 'Pasta'], ['Soup', 'Soup', 'Pizza'], ['Pasta', 'Pizza', 'Salad']]"}
{"task_id": "BigCodeBench/770", "solution": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\ndef task_func(num_samples=500, noise_strength=1, random_seed=None, test_size=0.2):\n    if num_samples < 2:\n        raise ValueError(\"Number of samples should be greater than 1\")\n    if test_size < 0 or test_size > 1:\n        raise ValueError(\"Test size should be between 0 and 1\")\n    if random_seed is not None:\n        np.random.seed(random_seed)\n\n    X = np.random.rand(num_samples, 1)\n    y = 3 * X + np.random.randn(num_samples, 1) * noise_strength\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    score = model.score(X_test, y_test)\n\n    return score, model", "raw_solution": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(num_samples=500, noise_strength=1, random_seed=None, test_size=0.2):\n    if num_samples < 2:\n        raise ValueError(\"Number of samples should be greater than 1\")\n    if test_size < 0 or test_size > 1:\n        raise ValueError(\"Test size should be between 0 and 1\")\n    if random_seed is not None:\n        np.random.seed(random_seed)\n\n    X = np.random.rand(num_samples, 1)\n    y = 3 * X + np.random.randn(num_samples, 1) * noise_strength\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    score = model.score(X_test, y_test)\n\n    return score, model"}
{"task_id": "BigCodeBench/771", "solution": "import re\nimport os\nfrom pathlib import Path\nimport csv\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n    # Initialize an empty list to store new file names\n    new_files = []\n\n    # Get a list of all CSV files in the directory\n    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n\n    # Iterate over each CSV file\n    for csv_file in csv_files:\n        # Match the file name with the pattern\n        match = re.match(pattern, csv_file)\n\n        # If a match is found\n        if match:\n            # Get the base name of the file\n            base_name = match.group(1)\n\n            # Create a new file name by appending a unique number to the base name\n            new_file_name = f\"{base_name}-{len(new_files)+1}.csv\"\n\n            # Add the new file name to the list\n            new_files.append(new_file_name)\n\n            # Open the original CSV file and the new CSV file\n            with open(os.path.join(directory, csv_file), 'r') as original_file, open(os.path.join(directory, new_file_name), 'w', newline='') as new_file:\n                # Copy the content of the original CSV file to the new CSV file\n                csv.writer(new_file).writerows(csv.reader(original_file))\n\n    # Return the list of new file names\n    return new_files", "raw_solution": "import re\nimport os\nfrom pathlib import Path\nimport csv\n\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n    # Initialize an empty list to store new file names\n    new_files = []\n\n    # Get a list of all CSV files in the directory\n    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n\n    # Iterate over each CSV file\n    for csv_file in csv_files:\n        # Match the file name with the pattern\n        match = re.match(pattern, csv_file)\n\n        # If a match is found\n        if match:\n            # Get the base name of the file\n            base_name = match.group(1)\n\n            # Create a new file name by appending a unique number to the base name\n            new_file_name = f\"{base_name}-{len(new_files)+1}.csv\"\n\n            # Add the new file name to the list\n            new_files.append(new_file_name)\n\n            # Open the original CSV file and the new CSV file\n            with open(os.path.join(directory, csv_file), 'r') as original_file, open(os.path.join(directory, new_file_name), 'w', newline='') as new_file:\n                # Copy the content of the original CSV file to the new CSV file\n                csv.writer(new_file).writerows(csv.reader(original_file))\n\n    # Return the list of new file names\n    return new_files"}
{"task_id": "BigCodeBench/772", "solution": "import numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\ndef task_func(num_samples=1000, k=5, d=2, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    # Generate a dataset consisting of random numbers sampled from a gaussian normal distribution\n    original_data = np.random.normal(size=num_samples)\n    # Apply a linear transformation to the dataset\n    transformed_data = k * original_data + d\n    # Standardize the dataset with the StandardScaler of sklearn\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(transformed_data.reshape(-1, 1))\n    # Calculate the average square error between the original dataset and the standardized dataset\n    mse = mean_squared_error(original_data, standardized_data)\n    return mse", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\n\ndef task_func(num_samples=1000, k=5, d=2, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    # Generate a dataset consisting of random numbers sampled from a gaussian normal distribution\n    original_data = np.random.normal(size=num_samples)\n    # Apply a linear transformation to the dataset\n    transformed_data = k * original_data + d\n    # Standardize the dataset with the StandardScaler of sklearn\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(transformed_data.reshape(-1, 1))\n    # Calculate the average square error between the original dataset and the standardized dataset\n    mse = mean_squared_error(original_data, standardized_data)\n    return mse\n\n# Test the function\nmse = task_func()"}
{"task_id": "BigCodeBench/773", "solution": "import os\nimport re\nimport shutil\nSOURCE_DIR = '/source/dir'\nTARGET_DIR = '/target/dir'\nFILE_PATTERN = re.compile(r'^(.*?)-\\d+\\.json$')\ndef task_func():\n    for filename in os.listdir(SOURCE_DIR):\n        match = FILE_PATTERN.match(filename)\n        if match:\n            prefix = match.group(1)\n            new_filename = f\"{prefix}.json\"\n            shutil.move(os.path.join(SOURCE_DIR, filename), os.path.join(TARGET_DIR, new_filename))\n    return None", "raw_solution": "import os\nimport re\nimport shutil\n\n# Constants\nSOURCE_DIR = '/source/dir'\nTARGET_DIR = '/target/dir'\nFILE_PATTERN = re.compile(r'^(.*?)-\\d+\\.json$')\n\ndef task_func():\n    for filename in os.listdir(SOURCE_DIR):\n        match = FILE_PATTERN.match(filename)\n        if match:\n            prefix = match.group(1)\n            new_filename = f\"{prefix}.json\"\n            shutil.move(os.path.join(SOURCE_DIR, filename), os.path.join(TARGET_DIR, new_filename))\n    return None\n\n# Test the function\ntask_func()"}
{"task_id": "BigCodeBench/774", "solution": "import numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\ndef task_func(num_samples=100, n_estimators=100, random_seed=None, cv=5):\n    if num_samples / cv < 2:\n        raise ValueError(\"num_samples / cv should be greater than 2\")\n\n    np.random.seed(random_seed)\n    X = np.random.standard_normal(size=(num_samples, 5))\n    epsilon = np.random.standard_normal(size=num_samples)\n    y = X.sum(axis=1) + epsilon\n\n    model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_seed)\n    scores = cross_val_score(model, X, y, cv=cv)\n\n    return scores.mean(), model.fit(X, y)", "raw_solution": "import numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef task_func(num_samples=100, n_estimators=100, random_seed=None, cv=5):\n    if num_samples / cv < 2:\n        raise ValueError(\"num_samples / cv should be greater than 2\")\n\n    np.random.seed(random_seed)\n    X = np.random.standard_normal(size=(num_samples, 5))\n    epsilon = np.random.standard_normal(size=num_samples)\n    y = X.sum(axis=1) + epsilon\n\n    model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_seed)\n    scores = cross_val_score(model, X, y, cv=cv)\n\n    return scores.mean(), model.fit(X, y)\n\nresults = task_func(random_seed=1)"}
{"task_id": "BigCodeBench/775", "solution": "from string import ascii_lowercase\nimport re\nfrom collections import Counter\nLETTERS_PATTERN = re.compile(r'^(.*?)-[a-z]$')\nLETTERS = ascii_lowercase\ndef task_func(string):\n    match = LETTERS_PATTERN.match(string)\n    if match:\n        prefix = match.group(1)\n        letters = [c for c in prefix if c in LETTERS]\n        return dict(Counter(letters))\n    else:\n        return {}", "raw_solution": "from string import ascii_lowercase\nimport re\nfrom collections import Counter\n\n# Constants\nLETTERS_PATTERN = re.compile(r'^(.*?)-[a-z]$')\nLETTERS = ascii_lowercase\n\ndef task_func(string):\n    match = LETTERS_PATTERN.match(string)\n    if match:\n        prefix = match.group(1)\n        letters = [c for c in prefix if c in LETTERS]\n        return dict(Counter(letters))\n    else:\n        return {}\n\n# Test cases"}
{"task_id": "BigCodeBench/776", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(file_path, output_path=None, sort_key='title', linear_regression=False, x_column=None, y_column=None):\n    try:\n        # Read CSV file\n        df = pd.read_csv(file_path)\n    except Exception as e:\n        raise Exception(f\"Error in reading the file: {e}\")\n\n    # Sort data by sort_key\n    try:\n        df = df.sort_values(by=sort_key)\n    except Exception as e:\n        raise Exception(f\"Error in sorting the data: {e}\")\n\n    if output_path is not None:\n        # Write sorted data to another CSV file\n        try:\n            df.to_csv(output_path, index=False)\n        except Exception as e:\n            raise Exception(f\"Error in writing to the file: {e}\")\n        return output_path\n\n    if linear_regression:\n        # Check if specified columns for linear regression exist in the dataframe\n        if x_column is None or y_column is None or x_column not in df.columns or y_column not in df.columns:\n            raise ValueError(\"Specified columns for linear regression do not exist in the dataframe\")\n\n        # Fit a linear regression model\n        lm = LinearRegression()\n        X = df[[x_column]]\n        y = df[y_column]\n        try:\n            lm.fit(X, y)\n        except Exception as e:\n            raise Exception(f\"Error in fitting the model: {e}\")\n        return lm\n\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(file_path, output_path=None, sort_key='title', linear_regression=False, x_column=None, y_column=None):\n    try:\n        # Read CSV file\n        df = pd.read_csv(file_path)\n    except Exception as e:\n        raise Exception(f\"Error in reading the file: {e}\")\n\n    # Sort data by sort_key\n    try:\n        df = df.sort_values(by=sort_key)\n    except Exception as e:\n        raise Exception(f\"Error in sorting the data: {e}\")\n\n    if output_path is not None:\n        # Write sorted data to another CSV file\n        try:\n            df.to_csv(output_path, index=False)\n        except Exception as e:\n            raise Exception(f\"Error in writing to the file: {e}\")\n        return output_path\n\n    if linear_regression:\n        # Check if specified columns for linear regression exist in the dataframe\n        if x_column is None or y_column is None or x_column not in df.columns or y_column not in df.columns:\n            raise ValueError(\"Specified columns for linear regression do not exist in the dataframe\")\n\n        # Fit a linear regression model\n        lm = LinearRegression()\n        X = df[[x_column]]\n        y = df[y_column]\n        try:\n            lm.fit(X, y)\n        except Exception as e:\n            raise Exception(f\"Error in fitting the model: {e}\")\n        return lm\n\n    return df"}
{"task_id": "BigCodeBench/777", "solution": "import re\nimport os\nimport zipfile\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    extracted_dirs = []\n    for filename in os.listdir(directory):\n        match = re.match(pattern, filename)\n        if match:\n            prefix = match.group(1)\n            if not os.path.exists(os.path.join(directory, prefix)):\n                os.mkdir(os.path.join(directory, prefix))\n            with zipfile.ZipFile(os.path.join(directory, filename), 'r') as zip_ref:\n                zip_ref.extractall(os.path.join(directory, prefix))\n            extracted_dirs.append(prefix)\n            os.remove(os.path.join(directory, filename))\n    return extracted_dirs", "raw_solution": "import re\nimport os\nimport zipfile\n\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    extracted_dirs = []\n    for filename in os.listdir(directory):\n        match = re.match(pattern, filename)\n        if match:\n            prefix = match.group(1)\n            if not os.path.exists(os.path.join(directory, prefix)):\n                os.mkdir(os.path.join(directory, prefix))\n            with zipfile.ZipFile(os.path.join(directory, filename), 'r') as zip_ref:\n                zip_ref.extractall(os.path.join(directory, prefix))\n            extracted_dirs.append(prefix)\n            os.remove(os.path.join(directory, filename))\n    return extracted_dirs"}
{"task_id": "BigCodeBench/778", "solution": "from collections import defaultdict\nfrom operator import itemgetter\ndef task_func(news_articles):\n    # Check if all dictionaries have the required keys\n    for article in news_articles:\n        if not all(key in article for key in ('title', 'title_url', 'id', 'category')):\n            raise ValueError(\"All dictionaries must have keys: 'title', 'title_url', 'id', and 'category'\")\n\n    # Sort articles by category and title\n    sorted_articles = sorted(news_articles, key=itemgetter('category', 'title'))\n\n    # Group articles by category\n    grouped_articles = defaultdict(list)\n    for category, articles in groupby(sorted_articles, key=itemgetter('category')):\n        grouped_articles[category] = list(articles)\n\n    return grouped_articles\narticles = [\n    {'title': 'Der Standard', 'title_url': 'standard', 'id': 2, 'category': 'climate'},\n    {'title': 'tecky', 'title_url': 'tecky', 'id': 4, 'category': 'climate'},\n    {'title': 'earth magazine', 'title_url': 'earth', 'id': 4, 'category': 'environment'}\n]", "raw_solution": "from collections import defaultdict\nfrom operator import itemgetter\n\ndef task_func(news_articles):\n    # Check if all dictionaries have the required keys\n    for article in news_articles:\n        if not all(key in article for key in ('title', 'title_url', 'id', 'category')):\n            raise ValueError(\"All dictionaries must have keys: 'title', 'title_url', 'id', and 'category'\")\n\n    # Sort articles by category and title\n    sorted_articles = sorted(news_articles, key=itemgetter('category', 'title'))\n\n    # Group articles by category\n    grouped_articles = defaultdict(list)\n    for category, articles in groupby(sorted_articles, key=itemgetter('category')):\n        grouped_articles[category] = list(articles)\n\n    return grouped_articles\n\n# Test the function\narticles = [\n    {'title': 'Der Standard', 'title_url': 'standard', 'id': 2, 'category': 'climate'},\n    {'title': 'tecky', 'title_url': 'tecky', 'id': 4, 'category': 'climate'},\n    {'title': 'earth magazine', 'title_url': 'earth', 'id': 4, 'category': 'environment'}\n]\n\nsorted_articles = task_func(articles)"}
{"task_id": "BigCodeBench/779", "solution": "import os\nimport shutil\nimport time\nimport tempfile\nBACKUP_DIR = '/tmp/backup'\ndef get_unique_backup_dir():\n    return tempfile.mkdtemp(prefix='backup_', dir=BACKUP_DIR)\ndef task_func(directory):\n    if not os.path.isdir(directory):\n        return (None, ['Directory does not exist.'])\n\n    backup_dir = get_unique_backup_dir()\n    backup_path = os.path.join(backup_dir, os.path.basename(directory))\n\n    try:\n        # Create backup\n        shutil.copytree(directory, backup_path)\n    except Exception as e:\n        return (None, [f'Error creating backup: {str(e)}'])\n\n    try:\n        # Clean directory\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            try:\n                if os.path.isfile(file_path) or os.path.islink(file_path):\n                    os.unlink(file_path)\n                elif os.path.isdir(file_path):\n                    shutil.rmtree(file_path)\n            except Exception as e:\n                return (backup_dir, [f'Error cleaning directory: {str(e)}'])\n    except Exception as e:\n        return (backup_dir, [f'Error cleaning directory: {str(e)}'])\n\n    return (backup_dir, [])", "raw_solution": "import os\nimport shutil\nimport time\nimport tempfile\n\n# Constants\nBACKUP_DIR = '/tmp/backup'\n\ndef get_unique_backup_dir():\n    return tempfile.mkdtemp(prefix='backup_', dir=BACKUP_DIR)\n\ndef task_func(directory):\n    if not os.path.isdir(directory):\n        return (None, ['Directory does not exist.'])\n\n    backup_dir = get_unique_backup_dir()\n    backup_path = os.path.join(backup_dir, os.path.basename(directory))\n\n    try:\n        # Create backup\n        shutil.copytree(directory, backup_path)\n    except Exception as e:\n        return (None, [f'Error creating backup: {str(e)}'])\n\n    try:\n        # Clean directory\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            try:\n                if os.path.isfile(file_path) or os.path.islink(file_path):\n                    os.unlink(file_path)\n                elif os.path.isdir(file_path):\n                    shutil.rmtree(file_path)\n            except Exception as e:\n                return (backup_dir, [f'Error cleaning directory: {str(e)}'])\n    except Exception as e:\n        return (backup_dir, [f'Error cleaning directory: {str(e)}'])\n\n    return (backup_dir, [])\n\n# Test the function\ndir_to_backup = '/tmp/test_dir'\nbackup_dir, errors = task_func(dir_to_backup)\nif backup_dir:\n    print(f'Backup created at: {backup_dir}')\nelse:\n    print('Errors encountered:')\n    for error in errors:\n        print(f' - {error}')"}
{"task_id": "BigCodeBench/780", "solution": "import pandas as pd\nimport pytz\ndef task_func(articles, timezone):\n    # Check if articles is a list of dictionaries\n    if not isinstance(articles, list) or not all(isinstance(article, dict) for article in articles):\n        raise TypeError(\"articles should be a list of dictionaries\")\n\n    # Check if articles is not empty\n    if not articles:\n        raise ValueError(\"articles should not be an empty list\")\n\n    # Check if all dictionaries have 'published_time' and 'category' keys\n    for article in articles:\n        if not all(key in article for key in ('published_time', 'category')):\n            raise ValueError(\"all dictionaries should have 'published_time' and 'category' keys\")\n\n    # Convert 'published_time' to specified timezone and extract hour\n    for article in articles:\n        published_time = pytz.utc.localize(article['published_time']).astimezone(pytz.timezone(timezone))\n        article['published_hour'] = published_time.hour\n\n    # Convert list of dictionaries to pandas DataFrame\n    df = pd.DataFrame(articles)\n\n    # Group by 'category' and calculate count, mean, min, max of 'published_hour'\n    result = df.groupby('category').agg({'published_hour': ['count', 'mean', 'min', 'max']})\n\n    return result", "raw_solution": "import pandas as pd\nimport pytz\n\ndef task_func(articles, timezone):\n    # Check if articles is a list of dictionaries\n    if not isinstance(articles, list) or not all(isinstance(article, dict) for article in articles):\n        raise TypeError(\"articles should be a list of dictionaries\")\n\n    # Check if articles is not empty\n    if not articles:\n        raise ValueError(\"articles should not be an empty list\")\n\n    # Check if all dictionaries have 'published_time' and 'category' keys\n    for article in articles:\n        if not all(key in article for key in ('published_time', 'category')):\n            raise ValueError(\"all dictionaries should have 'published_time' and 'category' keys\")\n\n    # Convert 'published_time' to specified timezone and extract hour\n    for article in articles:\n        published_time = pytz.utc.localize(article['published_time']).astimezone(pytz.timezone(timezone))\n        article['published_hour'] = published_time.hour\n\n    # Convert list of dictionaries to pandas DataFrame\n    df = pd.DataFrame(articles)\n\n    # Group by 'category' and calculate count, mean, min, max of 'published_hour'\n    result = df.groupby('category').agg({'published_hour': ['count', 'mean', 'min', 'max']})\n\n    return result"}
{"task_id": "BigCodeBench/781", "solution": "import os\nfrom datetime import datetime\ndef task_func(filepath: str) -> dict:\n    if os.path.isfile(filepath):\n        file_info = os.stat(filepath)\n        file_size = file_info.st_size\n        last_modified_time = datetime.fromtimestamp(file_info.st_mtime).strftime('%Y-%m-%d %H:%M:%S')\n        return {'size': file_size, 'last_modified': last_modified_time}\n    else:\n        return \"The provided path is not a file\"", "raw_solution": "import os\nfrom datetime import datetime\n\ndef task_func(filepath: str) -> dict:\n    if os.path.isfile(filepath):\n        file_info = os.stat(filepath)\n        file_size = file_info.st_size\n        last_modified_time = datetime.fromtimestamp(file_info.st_mtime).strftime('%Y-%m-%d %H:%M:%S')\n        return {'size': file_size, 'last_modified': last_modified_time}\n    else:\n        return \"The provided path is not a file\"\n\n# Test the function"}
{"task_id": "BigCodeBench/782", "solution": "import random\nimport pandas as pd\nimport numpy as np\ndef task_func(n,\n              domain=\"samplewebsite.com\",\n              categories=['Sports', 'Technology', 'Health', 'Science', 'Business'],\n              random_seed=None):\n    \n    if random_seed is not None:\n        random.seed(random_seed)\n\n    data = []\n    for i in range(n):\n        title = f\"Article {i}\"\n        title_url = f\"{domain}/{title}\"\n        id = i\n        category = random.choice(categories)\n        views = np.random.poisson(1000)\n        data.append([title, title_url, id, category, views])\n\n    df = pd.DataFrame(data, columns=['title', 'title_url', 'id', 'category', 'views'])\n    return df", "raw_solution": "import random\nimport pandas as pd\nimport numpy as np\n\ndef task_func(n,\n              domain=\"samplewebsite.com\",\n              categories=['Sports', 'Technology', 'Health', 'Science', 'Business'],\n              random_seed=None):\n    \n    if random_seed is not None:\n        random.seed(random_seed)\n\n    data = []\n    for i in range(n):\n        title = f\"Article {i}\"\n        title_url = f\"{domain}/{title}\"\n        id = i\n        category = random.choice(categories)\n        views = np.random.poisson(1000)\n        data.append([title, title_url, id, category, views])\n\n    df = pd.DataFrame(data, columns=['title', 'title_url', 'id', 'category', 'views'])\n    return df\n\ndf = task_func(3, categories=['A', 'B'], domain='test.de', random_seed=12)"}
{"task_id": "BigCodeBench/783", "solution": "import os\nimport shutil\ndef task_func(src_dir, dest_dir, extension):\n    if not os.path.exists(src_dir) or not os.path.exists(dest_dir):\n        return \"Source or Destination directory does not exist.\"\n\n    if not os.path.isdir(src_dir) or not os.path.isdir(dest_dir):\n        return \"Either Source or Destination is not a directory.\"\n\n    files_moved = 0\n    for file_name in os.listdir(src_dir):\n        if file_name.endswith(extension):\n            shutil.move(os.path.join(src_dir, file_name), dest_dir)\n            files_moved += 1\n\n    return files_moved\nsrc_dir = \"/path/to/source/directory\"\ndest_dir = \"/path/to/destination/directory\"\nextension = \".txt\"", "raw_solution": "import os\nimport shutil\n\ndef task_func(src_dir, dest_dir, extension):\n    if not os.path.exists(src_dir) or not os.path.exists(dest_dir):\n        return \"Source or Destination directory does not exist.\"\n\n    if not os.path.isdir(src_dir) or not os.path.isdir(dest_dir):\n        return \"Either Source or Destination is not a directory.\"\n\n    files_moved = 0\n    for file_name in os.listdir(src_dir):\n        if file_name.endswith(extension):\n            shutil.move(os.path.join(src_dir, file_name), dest_dir)\n            files_moved += 1\n\n    return files_moved\n\n# Test the function\nsrc_dir = \"/path/to/source/directory\"\ndest_dir = \"/path/to/destination/directory\"\nextension = \".txt\""}
{"task_id": "BigCodeBench/784", "solution": "import pandas as pd\nimport random\nimport csv\ndef task_func(n, \n           categories=['Sports', 'Technology', 'Business', 'Politics', 'Entertainment'],\n           news_sites=['New York Times', 'USA Today', 'Apple News', 'CNN', 'BBC'],\n           likert_scale=['Strongly Disagree', 'Disagree', 'Neither Agree nor Disagree', 'Agree', 'Strongly Agree'],\n           file_path='news_survey_data.csv',\n           random_seed=None):\n    \n    if random_seed is not None:\n        random.seed(random_seed)\n\n    data = []\n    for _ in range(n):\n        site = random.choice(news_sites)\n        category = random.choice(categories)\n        response = random.choice(likert_scale)\n        value = likert_scale.index(response) + 1\n        data.append([site, category, response, value])\n\n    df = pd.DataFrame(data, columns=['Site', 'Category', 'Response', 'Value'])\n\n    df.to_csv(file_path, index=False)\n\n    df = pd.read_csv(file_path)\n\n    return df", "raw_solution": "import pandas as pd\nimport random\nimport csv\n\ndef task_func(n, \n           categories=['Sports', 'Technology', 'Business', 'Politics', 'Entertainment'],\n           news_sites=['New York Times', 'USA Today', 'Apple News', 'CNN', 'BBC'],\n           likert_scale=['Strongly Disagree', 'Disagree', 'Neither Agree nor Disagree', 'Agree', 'Strongly Agree'],\n           file_path='news_survey_data.csv',\n           random_seed=None):\n    \n    if random_seed is not None:\n        random.seed(random_seed)\n\n    data = []\n    for _ in range(n):\n        site = random.choice(news_sites)\n        category = random.choice(categories)\n        response = random.choice(likert_scale)\n        value = likert_scale.index(response) + 1\n        data.append([site, category, response, value])\n\n    df = pd.DataFrame(data, columns=['Site', 'Category', 'Response', 'Value'])\n\n    df.to_csv(file_path, index=False)\n\n    df = pd.read_csv(file_path)\n\n    return df\n\ndf = task_func(8, ['test', 'fun'], likert_scale=['true', 'false'], news_sites=['cat', 'dog'], random_seed=12)"}
{"task_id": "BigCodeBench/785", "solution": "import subprocess\nimport os\nimport glob\nimport shutil\nARCHIVE_DIR = '/tmp/archive'\ndef task_func(pattern):\n    # Create archive directory if it doesn't exist\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n\n    # Find files that match the pattern\n    files = glob.glob(pattern)\n\n    # Archive and delete each file\n    for file in files:\n        # Get the base name of the file\n        base_name = os.path.basename(file)\n\n        # Create the archive file path\n        archive_file = os.path.join(ARCHIVE_DIR, base_name)\n\n        # Archive the file\n        shutil.move(file, archive_file)\n\n    # Return the archive file path\n    return archive_file", "raw_solution": "import subprocess\nimport os\nimport glob\nimport shutil\n\n# Constants\nARCHIVE_DIR = '/tmp/archive'\n\ndef task_func(pattern):\n    # Create archive directory if it doesn't exist\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n\n    # Find files that match the pattern\n    files = glob.glob(pattern)\n\n    # Archive and delete each file\n    for file in files:\n        # Get the base name of the file\n        base_name = os.path.basename(file)\n\n        # Create the archive file path\n        archive_file = os.path.join(ARCHIVE_DIR, base_name)\n\n        # Archive the file\n        shutil.move(file, archive_file)\n\n    # Return the archive file path\n    return archive_file\n\n# Test the function"}
{"task_id": "BigCodeBench/786", "solution": "import pandas as pd\nimport random\ndef task_func(\n    n, \n    countries=['USA', 'UK', 'China', 'India', 'Germany'], \n    products=['Product A', 'Product B', 'Product C', 'Product D', 'Product E'], \n    output_path=None,\n    random_seed=None):\n\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    data = {\n        'Country': [random.choice(countries) for _ in range(n)],\n        'Product': [random.choice(products) for _ in range(n)],\n        'Sales': [random.randint(1, 100) for _ in range(n)]\n    }\n\n    df = pd.DataFrame(data)\n\n    if output_path is not None:\n        df.to_csv(output_path, index=False)\n\n    return df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(\n    n, \n    countries=['USA', 'UK', 'China', 'India', 'Germany'], \n    products=['Product A', 'Product B', 'Product C', 'Product D', 'Product E'], \n    output_path=None,\n    random_seed=None):\n\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    data = {\n        'Country': [random.choice(countries) for _ in range(n)],\n        'Product': [random.choice(products) for _ in range(n)],\n        'Sales': [random.randint(1, 100) for _ in range(n)]\n    }\n\n    df = pd.DataFrame(data)\n\n    if output_path is not None:\n        df.to_csv(output_path, index=False)\n\n    return df"}
{"task_id": "BigCodeBench/787", "solution": "import numpy as np\nfrom itertools import combinations\ndef task_func(array1, array2):\n    if len(array1) != len(array2):\n        raise ValueError(\"Input arrays must have the same length\")\n    if len(array1) == 0:\n        return 0\n    points = [(x, y) for x in array1 for y in array2]\n    distances = [np.linalg.norm(np.array(p1)-np.array(p2)) for p1, p2 in combinations(points, 2)]\n    return max(distances)", "raw_solution": "import numpy as np\nfrom itertools import combinations\n\ndef task_func(array1, array2):\n    if len(array1) != len(array2):\n        raise ValueError(\"Input arrays must have the same length\")\n    if len(array1) == 0:\n        return 0\n    points = [(x, y) for x in array1 for y in array2]\n    distances = [np.linalg.norm(np.array(p1)-np.array(p2)) for p1, p2 in combinations(points, 2)]\n    return max(distances)"}
{"task_id": "BigCodeBench/788", "solution": "import pandas as pd\nimport heapq\nfrom scipy import stats\ndef task_func(df, col1, col2, N=10):\n    # Check if columns are in the DataFrame\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"One or both of the specified columns are not in the DataFrame.\")\n    \n    # Check if N is greater than 1\n    if N <= 1:\n        raise ValueError(\"N should be greater than 1.\")\n    \n    # Calculate absolute differences\n    df['diff'] = df[col1].sub(df[col2]).abs()\n    \n    # Get N largest differences\n    largest_diffs = heapq.nlargest(N, df['diff'])\n    \n    # Perform t-test\n    t_stat, p_val = stats.ttest_1samp(largest_diffs, 0)\n    \n    # Return p-value\n    return p_val\ndf = pd.DataFrame({\n    'col1': [1, 3, 4, 70],\n    'col2': [2, 3, 5, 1]\n})", "raw_solution": "import pandas as pd\nimport heapq\nfrom scipy import stats\n\ndef task_func(df, col1, col2, N=10):\n    # Check if columns are in the DataFrame\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"One or both of the specified columns are not in the DataFrame.\")\n    \n    # Check if N is greater than 1\n    if N <= 1:\n        raise ValueError(\"N should be greater than 1.\")\n    \n    # Calculate absolute differences\n    df['diff'] = df[col1].sub(df[col2]).abs()\n    \n    # Get N largest differences\n    largest_diffs = heapq.nlargest(N, df['diff'])\n    \n    # Perform t-test\n    t_stat, p_val = stats.ttest_1samp(largest_diffs, 0)\n    \n    # Return p-value\n    return p_val\n\n# Test the function\ndf = pd.DataFrame({\n    'col1': [1, 3, 4, 70],\n    'col2': [2, 3, 5, 1]\n})\n\ntry:\n    p_value = task_func(df, 'col1', 'col2', N=2)\n    print(p_value)\nexcept ValueError as e:\n    print(e)"}
{"task_id": "BigCodeBench/789", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nARRAY_LENGTH = 10\ndef task_func():\n    # Generate a random array\n    array = np.random.rand(ARRAY_LENGTH)\n\n    # Reshape array to 2D array for MinMaxScaler\n    array = array.reshape(-1, 1)\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the array\n    scaled_array = scaler.fit_transform(array)\n\n    # Flatten the array back to 1D\n    scaled_array = scaled_array.flatten()\n\n    return scaled_array", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Constants\nARRAY_LENGTH = 10\n\ndef task_func():\n    # Generate a random array\n    array = np.random.rand(ARRAY_LENGTH)\n\n    # Reshape array to 2D array for MinMaxScaler\n    array = array.reshape(-1, 1)\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the array\n    scaled_array = scaler.fit_transform(array)\n\n    # Flatten the array back to 1D\n    scaled_array = scaled_array.flatten()\n\n    return scaled_array\n\n# Test the function"}
{"task_id": "BigCodeBench/790", "solution": "import pandas as pd\nimport heapq\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, col1, col2, N=10):\n    # Check if columns are in the DataFrame\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"One or both of the specified columns are not in the DataFrame.\")\n\n    # Standardize the columns\n    scaler = StandardScaler()\n    df[[col1, col2]] = scaler.fit_transform(df[[col1, col2]])\n\n    # Calculate the differences between the standardized columns\n    df['diff'] = abs(df[col1] - df[col2])\n\n    # Return the indices of the N largest differences\n    return [i for i in heapq.nlargest(N, range(len(df)), df['diff'].__getitem__)]\ndf = pd.DataFrame({\n    'a': [1, 2, 3, 4],\n    'b': [1, 2, 3, 5]\n})", "raw_solution": "import pandas as pd\nimport heapq\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, col1, col2, N=10):\n    # Check if columns are in the DataFrame\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"One or both of the specified columns are not in the DataFrame.\")\n\n    # Standardize the columns\n    scaler = StandardScaler()\n    df[[col1, col2]] = scaler.fit_transform(df[[col1, col2]])\n\n    # Calculate the differences between the standardized columns\n    df['diff'] = abs(df[col1] - df[col2])\n\n    # Return the indices of the N largest differences\n    return [i for i in heapq.nlargest(N, range(len(df)), df['diff'].__getitem__)]\n\n# Test the function\ndf = pd.DataFrame({\n    'a': [1, 2, 3, 4],\n    'b': [1, 2, 3, 5]\n})\n\nindices = task_func(df, 'a', 'b')"}
{"task_id": "BigCodeBench/791", "solution": "from collections import Counter\nimport random\nfrom itertools import cycle\nELEMENTS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\ndef task_func(l):\n    # Shuffle the list\n    random.shuffle(l)\n\n    # Create a cycled iterator from the list\n    cycled_l = cycle(l)\n\n    # Create a list with the first 30 elements from the cycled iterator\n    first_30_elements = [next(cycled_l) for _ in range(30)]\n\n    # Move the first 3 elements to the end of the list\n    first_30_elements = first_30_elements[3:] + first_30_elements[:3]\n\n    # Create a counter from the list\n    counter = Counter(first_30_elements)\n\n    return counter\nl = [random.choice(ELEMENTS) for _ in range(100)]", "raw_solution": "from collections import Counter\nimport random\nfrom itertools import cycle\n\n# Constants\nELEMENTS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n\ndef task_func(l):\n    # Shuffle the list\n    random.shuffle(l)\n\n    # Create a cycled iterator from the list\n    cycled_l = cycle(l)\n\n    # Create a list with the first 30 elements from the cycled iterator\n    first_30_elements = [next(cycled_l) for _ in range(30)]\n\n    # Move the first 3 elements to the end of the list\n    first_30_elements = first_30_elements[3:] + first_30_elements[:3]\n\n    # Create a counter from the list\n    counter = Counter(first_30_elements)\n\n    return counter\n\n# Test the function\nl = [random.choice(ELEMENTS) for _ in range(100)]"}
{"task_id": "BigCodeBench/792", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, feature, target, n=10):\n    if feature not in df.columns or target not in df.columns:\n        raise ValueError(\"Specified columns are not in the provided DataFrame.\")\n    \n    X = df[[feature]]\n    y = df[target]\n\n    model = LinearRegression()\n    model.fit(X, y)\n\n    residuals = np.abs(y - model.predict(X))\n    indices = np.argsort(residuals)[-n:]\n\n    return indices.tolist(), model\ndf = pd.DataFrame({\n    'a': [1, 2, 3, 4, 5],\n    'b': [1, 2, 3, 4, 5]\n})", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, feature, target, n=10):\n    if feature not in df.columns or target not in df.columns:\n        raise ValueError(\"Specified columns are not in the provided DataFrame.\")\n    \n    X = df[[feature]]\n    y = df[target]\n\n    model = LinearRegression()\n    model.fit(X, y)\n\n    residuals = np.abs(y - model.predict(X))\n    indices = np.argsort(residuals)[-n:]\n\n    return indices.tolist(), model\n\n# Test the function\ndf = pd.DataFrame({\n    'a': [1, 2, 3, 4, 5],\n    'b': [1, 2, 3, 4, 5]\n})\n\nindices, model = task_func(df, 'a', 'b', n=3)"}
{"task_id": "BigCodeBench/793", "solution": "import numpy as np\nimport random\nELEMENTS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\ndef task_func(l=None):\n    if l is None:\n        l = ELEMENTS\n    # Convert list to numpy array\n    arr = np.array(l)\n    # Move first 3 elements to the end\n    arr = np.roll(arr, -3)\n    return arr", "raw_solution": "import numpy as np\nimport random\n\n# Constants\nELEMENTS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n\ndef task_func(l=None):\n    if l is None:\n        l = ELEMENTS\n    # Convert list to numpy array\n    arr = np.array(l)\n    # Move first 3 elements to the end\n    arr = np.roll(arr, -3)\n    return arr\n\n# Test the function"}
{"task_id": "BigCodeBench/794", "solution": "import string\nimport random\ndef task_func(length, random_seed=None):\n    BRACKETS = \"(){}[]\"\n    ALL_CHARS = string.ascii_lowercase + BRACKETS\n\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    return ''.join(random.choice(ALL_CHARS) for _ in range(length))", "raw_solution": "import string\nimport random\n\ndef task_func(length, random_seed=None):\n    BRACKETS = \"(){}[]\"\n    ALL_CHARS = string.ascii_lowercase + BRACKETS\n\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    return ''.join(random.choice(ALL_CHARS) for _ in range(length))\n\n# Test the function\nstring = task_func(34, random_seed=42)"}
{"task_id": "BigCodeBench/795", "solution": "from collections import deque\nimport math\ndef task_func(l):\n    dq = deque(l)\n    dq.rotate(3)\n    sum_of_elements = sum(i for i in dq if isinstance(i, (int, float)))\n    if sum_of_elements:\n        print(f\"The square root of the sum of numeric elements: {math.sqrt(sum_of_elements)}\")\n    return dq", "raw_solution": "from collections import deque\nimport math\n\ndef task_func(l):\n    dq = deque(l)\n    dq.rotate(3)\n    sum_of_elements = sum(i for i in dq if isinstance(i, (int, float)))\n    if sum_of_elements:\n        print(f\"The square root of the sum of numeric elements: {math.sqrt(sum_of_elements)}\")\n    return dq\n\n# Test the function"}
{"task_id": "BigCodeBench/796", "solution": "import os\nimport re\nBRACKET_PATTERN = '[(){}\\[\\]]'\ndef task_func(directory):\n    files_with_brackets = []\n    for filename in os.listdir(directory):\n        if re.search(BRACKET_PATTERN, filename):\n            files_with_brackets.append(os.path.join(directory, filename))\n    return files_with_brackets", "raw_solution": "import os\nimport re\n\nBRACKET_PATTERN = '[(){}\\[\\]]'\n\ndef task_func(directory):\n    files_with_brackets = []\n    for filename in os.listdir(directory):\n        if re.search(BRACKET_PATTERN, filename):\n            files_with_brackets.append(os.path.join(directory, filename))\n    return files_with_brackets\n\n# Test the function"}
{"task_id": "BigCodeBench/797", "solution": "import re\nimport pandas as pd\ndef task_func(df: pd.DataFrame) -> int:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"Input should be a pandas DataFrame\")\n\n    pattern = r'[(){}\\[\\]]'\n    brackets_count = 0\n\n    for col in df.columns:\n        for row in df[col]:\n            brackets_count += len(re.findall(pattern, str(row)))\n\n    return brackets_count\ndf = pd.DataFrame({'Test': ['(a)', 'b', '[[[[))c']})", "raw_solution": "import re\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> int:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"Input should be a pandas DataFrame\")\n\n    pattern = r'[(){}\\[\\]]'\n    brackets_count = 0\n\n    for col in df.columns:\n        for row in df[col]:\n            brackets_count += len(re.findall(pattern, str(row)))\n\n    return brackets_count\n\n# Testing the function\ndf = pd.DataFrame({'Test': ['(a)', 'b', '[[[[))c']})"}
{"task_id": "BigCodeBench/798", "solution": "import os\nimport shutil\nBACKUP_DIR = '/tmp/backup'\ndef task_func(directory):\n    backup_path = os.path.join(BACKUP_DIR, os.path.basename(directory))\n\n    # Check if backup directory exists\n    if not os.path.exists(BACKUP_DIR):\n        return f\"Backup directory {BACKUP_DIR} does not exist. Cannot rollback update.\"\n\n    # Check if backup for the directory exists\n    if not os.path.exists(backup_path):\n        return f\"Backup for directory {directory} does not exist. Cannot rollback update.\"\n\n    # Remove the directory if it exists\n    if os.path.exists(directory):\n        shutil.rmtree(directory)\n\n    # Restore the directory from backup\n    shutil.copytree(backup_path, directory)\n\n    return directory", "raw_solution": "import os\nimport shutil\n\n# Constants\nBACKUP_DIR = '/tmp/backup'\n\ndef task_func(directory):\n    backup_path = os.path.join(BACKUP_DIR, os.path.basename(directory))\n\n    # Check if backup directory exists\n    if not os.path.exists(BACKUP_DIR):\n        return f\"Backup directory {BACKUP_DIR} does not exist. Cannot rollback update.\"\n\n    # Check if backup for the directory exists\n    if not os.path.exists(backup_path):\n        return f\"Backup for directory {directory} does not exist. Cannot rollback update.\"\n\n    # Remove the directory if it exists\n    if os.path.exists(directory):\n        shutil.rmtree(directory)\n\n    # Restore the directory from backup\n    shutil.copytree(backup_path, directory)\n\n    return directory\n\n# Test the function"}
{"task_id": "BigCodeBench/799", "solution": "import pandas as pd\nfrom random import seed, choices\ndef task_func(L, num_dataframes=5, random_seed=None):\n    if random_seed is not None:\n        seed(random_seed)\n\n    if not L:\n        return pd.DataFrame(), []\n\n    column_names = [''.join(choices(list('abcdefghijklmnopqrstuvwxyz'), k=3)) for _ in range(3)]\n    df_list = []\n    for _ in range(num_dataframes):\n        df = pd.DataFrame(columns=column_names)\n        for _ in range(3):\n            df = df.append(pd.Series(choices(L, k=3), index=column_names), ignore_index=True)\n        df_list.append(df)\n\n    common_rows = df_list[0]\n    for df in df_list[1:]:\n        common_rows = pd.merge(common_rows, df, how='inner')\n\n    return common_rows, df_list\nL = [[1, '65', 76], [2, '5', 6]]", "raw_solution": "import pandas as pd\nfrom random import seed, choices\n\ndef task_func(L, num_dataframes=5, random_seed=None):\n    if random_seed is not None:\n        seed(random_seed)\n\n    if not L:\n        return pd.DataFrame(), []\n\n    column_names = [''.join(choices(list('abcdefghijklmnopqrstuvwxyz'), k=3)) for _ in range(3)]\n    df_list = []\n    for _ in range(num_dataframes):\n        df = pd.DataFrame(columns=column_names)\n        for _ in range(3):\n            df = df.append(pd.Series(choices(L, k=3), index=column_names), ignore_index=True)\n        df_list.append(df)\n\n    common_rows = df_list[0]\n    for df in df_list[1:]:\n        common_rows = pd.merge(common_rows, df, how='inner')\n\n    return common_rows, df_list\n\nL = [[1, '65', 76], [2, '5', 6]]\ncommon_rows, df_list = task_func(L, num_dataframes=1, random_seed=1)"}
{"task_id": "BigCodeBench/800", "solution": "import csv\nimport os\nfrom collections import Counter\nCSV_FILE_PATH = 'match_data.csv'\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    # Initialize counters\n    total_goals = 0\n    total_penalties = 0\n\n    # Open the CSV file\n    with open(csv_file_path, 'r') as csv_file:\n        reader = csv.reader(csv_file)\n        next(reader)  # Skip the header\n\n        # Iterate over the rows\n        for row in reader:\n            # Add the goals and penalties to the total\n            total_goals += int(row[1])\n            total_penalties += int(row[2])\n\n    # Add the given goals and penalties to the total\n    total_goals += goals\n    total_penalties += penalties\n\n    # Return a Counter object with the total counts\n    return Counter({'goals': total_goals, 'penalties': total_penalties})", "raw_solution": "import csv\nimport os\nfrom collections import Counter\n\n# Constants\nCSV_FILE_PATH = 'match_data.csv'\n\ndef create_test_csv(filename, content):\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerows(content)\n\n# Example usage in a test setup:\ndef setup_csv():\n    content = [\n        ['team', 'goals', 'penalties'],\n        ['Team A', '2', '1'],\n        ['Team B', '1', '2'],\n        ['Team C', '3', '0']\n    ]\n    create_test_csv('test_data/test_case_2.csv', content)\n\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    # Initialize counters\n    total_goals = 0\n    total_penalties = 0\n\n    # Open the CSV file\n    with open(csv_file_path, 'r') as csv_file:\n        reader = csv.reader(csv_file)\n        next(reader)  # Skip the header\n\n        # Iterate over the rows\n        for row in reader:\n            # Add the goals and penalties to the total\n            total_goals += int(row[1])\n            total_penalties += int(row[2])\n\n    # Add the given goals and penalties to the total\n    total_goals += goals\n    total_penalties += penalties\n\n    # Return a Counter object with the total counts\n    return Counter({'goals': total_goals, 'penalties': total_penalties})\n\n# Test the function\nsetup_csv()"}
{"task_id": "BigCodeBench/801", "solution": "import collections\nimport csv\nimport numpy as np\ndef task_func(file_name):\n    try:\n        with open(file_name, 'r') as file:\n            reader = csv.reader(file)\n            data = list(reader)\n\n        if not data:\n            return {}\n\n        data = np.array(data)\n        col_names = data[0]\n        data = data[1:]\n\n        result = {}\n        for i, col_name in enumerate(col_names):\n            col_data = data[:, i]\n            counter = collections.Counter(col_data)\n            most_common = counter.most_common(1)\n            result[col_name] = most_common[0][0] if most_common else None\n\n        return result\n    except FileNotFoundError:\n        print(f\"File {file_name} not found.\")\n        return {}", "raw_solution": "import collections\nimport csv\nimport numpy as np\n\ndef task_func(file_name):\n    try:\n        with open(file_name, 'r') as file:\n            reader = csv.reader(file)\n            data = list(reader)\n\n        if not data:\n            return {}\n\n        data = np.array(data)\n        col_names = data[0]\n        data = data[1:]\n\n        result = {}\n        for i, col_name in enumerate(col_names):\n            col_data = data[:, i]\n            counter = collections.Counter(col_data)\n            most_common = counter.most_common(1)\n            result[col_name] = most_common[0][0] if most_common else None\n\n        return result\n    except FileNotFoundError:\n        print(f\"File {file_name} not found.\")\n        return {}\n\n# Test the function"}
{"task_id": "BigCodeBench/802", "solution": "import numpy as np\ndef task_func(dimension, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.randint(1, 101, dimension)\n    flat_list = list(itertools.chain.from_iterable(matrix.tolist()))\n    return matrix, flat_list\ndimension = (5, 5)", "raw_solution": "import numpy as np\n\ndef task_func(dimension, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.randint(1, 101, dimension)\n    flat_list = list(itertools.chain.from_iterable(matrix.tolist()))\n    return matrix, flat_list\n\n# Test the function\ndimension = (5, 5)\nmatrix, flat_list = task_func(dimension)"}
{"task_id": "BigCodeBench/803", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(file_name: str) -> pd.DataFrame:\n    try:\n        # Load the data\n        df = pd.read_csv(file_name)\n\n        # Identify numeric columns\n        num_cols = df.select_dtypes(include=[pd.np.number]).columns\n\n        if len(num_cols) == 0:\n            raise ValueError(\"Input does not have numeric columns\")\n\n        # Initialize MinMaxScaler\n        scaler = MinMaxScaler()\n\n        # Fit and transform the data\n        df[num_cols] = scaler.fit_transform(df[num_cols])\n\n        return df\n\n    except FileNotFoundError:\n        print(f\"File {file_name} not found.\")\n    except ValueError as e:\n        print(e)", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(file_name: str) -> pd.DataFrame:\n    try:\n        # Load the data\n        df = pd.read_csv(file_name)\n\n        # Identify numeric columns\n        num_cols = df.select_dtypes(include=[pd.np.number]).columns\n\n        if len(num_cols) == 0:\n            raise ValueError(\"Input does not have numeric columns\")\n\n        # Initialize MinMaxScaler\n        scaler = MinMaxScaler()\n\n        # Fit and transform the data\n        df[num_cols] = scaler.fit_transform(df[num_cols])\n\n        return df\n\n    except FileNotFoundError:\n        print(f\"File {file_name} not found.\")\n    except ValueError as e:\n        print(e)\n\n# Test the function\ndf = task_func(\"test.csv\")\nif df is not None:\n    print(df.head())"}
{"task_id": "BigCodeBench/804", "solution": "import os\nfrom datetime import datetime\nLOG_DIR = './logs'\ndef task_func(metrics, filename, log_dir=LOG_DIR):\n    # Create the logs directory if it doesn't exist\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n\n    # Construct the full path to the log file\n    filepath = os.path.join(log_dir, filename)\n\n    try:\n        # Open the log file in append mode\n        with open(filepath, 'a') as log_file:\n            # Write the metrics to the log file with a timestamp\n            log_file.write(f\"{datetime.now()} - {str(metrics)}\\n\")\n    except IOError:\n        # If an IOError occurs, return False\n        return False\n\n    # If no exception was raised, return True\n    return True\nmetrics = {'precision': 0.75, 'recall': 0.80}", "raw_solution": "import os\nfrom datetime import datetime\n\n# Constants\nLOG_DIR = './logs'\n\ndef task_func(metrics, filename, log_dir=LOG_DIR):\n    # Create the logs directory if it doesn't exist\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n\n    # Construct the full path to the log file\n    filepath = os.path.join(log_dir, filename)\n\n    try:\n        # Open the log file in append mode\n        with open(filepath, 'a') as log_file:\n            # Write the metrics to the log file with a timestamp\n            log_file.write(f\"{datetime.now()} - {str(metrics)}\\n\")\n    except IOError:\n        # If an IOError occurs, return False\n        return False\n\n    # If no exception was raised, return True\n    return True\n\n# Test the function\nmetrics = {'precision': 0.75, 'recall': 0.80}"}
{"task_id": "BigCodeBench/805", "solution": "import pandas as pd\nimport random\ndef task_func(dictionary, item, seed):\n    # Set the seed for the random number generator\n    random.seed(seed)\n\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame(dictionary)\n\n    # Initialize an empty list to store the locations of the item\n    locations = []\n\n    # Iterate over the DataFrame\n    for i, row in df.iterrows():\n        for col in df.columns:\n            # If the item is found in the cell\n            if row[col] == item:\n                # Add the row index and column name to the list\n                locations.append((i, col))\n\n    # Count the number of occurrences of the item\n    count = len(locations)\n\n    # Add a random integer to each location\n    for i in range(count):\n        locations[i] = (*locations[i], random.randint(0, 9))\n\n    # Return the list of locations, count, and DataFrame\n    return locations, count, df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(dictionary, item, seed):\n    # Set the seed for the random number generator\n    random.seed(seed)\n\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame(dictionary)\n\n    # Initialize an empty list to store the locations of the item\n    locations = []\n\n    # Iterate over the DataFrame\n    for i, row in df.iterrows():\n        for col in df.columns:\n            # If the item is found in the cell\n            if row[col] == item:\n                # Add the row index and column name to the list\n                locations.append((i, col))\n\n    # Count the number of occurrences of the item\n    count = len(locations)\n\n    # Add a random integer to each location\n    for i in range(count):\n        locations[i] = (*locations[i], random.randint(0, 9))\n\n    # Return the list of locations, count, and DataFrame\n    return locations, count, df\n\n# Test the function\ndict = {'A': ['a', 'b', 'e'], 'B': ['c', 'd', 'd'], '2': ['asdf', 'ddd', 'aaaa'], '12': ['e', 'e', 'd']}"}
{"task_id": "BigCodeBench/806", "solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom collections import Counter\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(text, n=2):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n\n    # Tokenize the text\n    tokens = nltk.word_tokenize(text)\n\n    # Remove stopwords\n    tokens = [token for token in tokens if token not in STOPWORDS]\n\n    # Generate n-grams\n    n_grams = list(ngrams(tokens, n))\n\n    # Count the n-grams\n    n_gram_counts = Counter(n_grams)\n\n    return n_gram_counts\ntext = \"This is a sample text. It contains several sentences and words.\"", "raw_solution": "import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom collections import Counter\n\n# Constants\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(text, n=2):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n\n    # Tokenize the text\n    tokens = nltk.word_tokenize(text)\n\n    # Remove stopwords\n    tokens = [token for token in tokens if token not in STOPWORDS]\n\n    # Generate n-grams\n    n_grams = list(ngrams(tokens, n))\n\n    # Count the n-grams\n    n_gram_counts = Counter(n_grams)\n\n    return n_gram_counts\n\n# Test the function\ntext = \"This is a sample text. It contains several sentences and words.\""}
{"task_id": "BigCodeBench/807", "solution": "import numpy as np\nfrom scipy.stats import norm\ndef task_func(data: np.ndarray, threshold: float = 2.0) -> list:\n    # Calculate mean and standard deviation\n    mean = np.mean(data)\n    std_dev = np.std(data)\n    \n    # If standard deviation is 0, return empty list and mean and variance\n    if std_dev == 0:\n        return [], mean, 0\n    \n    # Calculate Z scores\n    z_scores = [(x - mean) / std_dev for x in data]\n    \n    # Find outliers\n    outliers = [i for i, z_score in enumerate(z_scores) if abs(z_score) > threshold]\n    \n    # Calculate variance\n    variance = std_dev ** 2\n    \n    return outliers, mean, variance\ndata = np.array([-10, 3, 5, 5, 5, 5, 5, 7, 20])", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\n\ndef task_func(data: np.ndarray, threshold: float = 2.0) -> list:\n    # Calculate mean and standard deviation\n    mean = np.mean(data)\n    std_dev = np.std(data)\n    \n    # If standard deviation is 0, return empty list and mean and variance\n    if std_dev == 0:\n        return [], mean, 0\n    \n    # Calculate Z scores\n    z_scores = [(x - mean) / std_dev for x in data]\n    \n    # Find outliers\n    outliers = [i for i, z_score in enumerate(z_scores) if abs(z_score) > threshold]\n    \n    # Calculate variance\n    variance = std_dev ** 2\n    \n    return outliers, mean, variance\n\n# Test the function\ndata = np.array([-10, 3, 5, 5, 5, 5, 5, 7, 20])\noutliers, mean, var = task_func(data, threshold=4)"}
{"task_id": "BigCodeBench/808", "solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(text):\n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    # Tokenize the text\n    words = nltk.word_tokenize(text)\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n    # Join the words back into a string\n    text = ' '.join(words)\n    # Analyze the sentiment\n    sentiment = TextBlob(text).sentiment.polarity\n    return sentiment", "raw_solution": "import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\n# Constants\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(text):\n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    # Tokenize the text\n    words = nltk.word_tokenize(text)\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n    # Join the words back into a string\n    text = ' '.join(words)\n    # Analyze the sentiment\n    sentiment = TextBlob(text).sentiment.polarity\n    return sentiment\n\n# Test the function\ntext = \"This is a sample text. It contains several words that are repeated and stopwords like 'is', 'a', 'it', 'the', 'and', 'that', 'not', 'or', 'in', 'to', 'be', 'are', 'you', 'your', 'it', 'this', 'an', 'the', 'and', 'is', 'to', 'of', 'at', 'by', 'for', 'with', 'on', 'do', 'dont', 'should', 'can', 'we', 'youre', 'arent', 'was', 'am', 'ive', 'ive', 'dont', 'this', 'that', 'those', 'am', 'isnt', 'arent', 'has', 'had', 'have', 'hasnt', 'hadnt', 'haven', 'haven', 'hasn', 'hasnt', 'hadn', 'hadnt', 'will', 'wont', 'shall', 'shant', 'shouldve', 'shouldnt', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aint', 'ain', 'gonna', 'gotta', 'lemme', 'wanna', 'wan', 'im', 'im', 'ill', 'ive', 'id', 'wtf', 'rt', 'thats', 'thatll', 'thatll', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those', 'those"}
{"task_id": "BigCodeBench/809", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\ndef task_func(data, n_clusters):\n    kmeans = KMeans(n_clusters=n_clusters).fit(data)\n    labels = kmeans.labels_\n    result = {}\n    for i, label in enumerate(labels):\n        if label not in result:\n            result[label] = []\n        result[label].append(i)\n    return result\ndata = np.array([[1, 1], [2, 2]])", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\n\ndef task_func(data, n_clusters):\n    kmeans = KMeans(n_clusters=n_clusters).fit(data)\n    labels = kmeans.labels_\n    result = {}\n    for i, label in enumerate(labels):\n        if label not in result:\n            result[label] = []\n        result[label].append(i)\n    return result\n\n# Test the function\ndata = np.array([[1, 1], [2, 2]])\ncluster = task_func(data, 2)\ncluster_list = list(cluster.values())\ncluster_list.sort(key=lambda x: x[0])"}
{"task_id": "BigCodeBench/810", "solution": "import re\nimport os\nimport subprocess\ndef task_func(dir_path, exe_pattern, execute_files=True):\n    results = []\n    for root, dirs, files in os.walk(dir_path):\n        for file in files:\n            if re.search(exe_pattern, file):\n                file_path = os.path.join(root, file)\n                if execute_files:\n                    try:\n                        output = subprocess.check_output(file_path, stderr=subprocess.STDOUT, shell=True)\n                        results.append(output.decode('utf-8'))\n                    except subprocess.CalledProcessError as e:\n                        print(f\"Error executing {file_path}: {str(e)}\")\n                else:\n                    results.append(file_path)\n    return results", "raw_solution": "import re\nimport os\nimport subprocess\n\ndef task_func(dir_path, exe_pattern, execute_files=True):\n    results = []\n    for root, dirs, files in os.walk(dir_path):\n        for file in files:\n            if re.search(exe_pattern, file):\n                file_path = os.path.join(root, file)\n                if execute_files:\n                    try:\n                        output = subprocess.check_output(file_path, stderr=subprocess.STDOUT, shell=True)\n                        results.append(output.decode('utf-8'))\n                    except subprocess.CalledProcessError as e:\n                        print(f\"Error executing {file_path}: {str(e)}\")\n                else:\n                    results.append(file_path)\n    return results"}
{"task_id": "BigCodeBench/811", "solution": "import pandas as pd\nfrom random import randint, seed\ndef task_func(dictionary, item, sample_size=None, random_seed=None):\n    # Convert dictionary to DataFrame\n    df = pd.DataFrame(dictionary)\n    \n    # Find positions of the item\n    positions = [(i, col) for i, row in enumerate(df.values) for col in row.index[row == item]]\n    \n    # If sample_size is provided, return a random sample of these positions\n    if sample_size is not None:\n        if random_seed is not None:\n            seed(random_seed)\n        positions = [positions[randint(0, len(positions)-1)] for _ in range(sample_size)]\n    \n    return positions, df\ndictionary = {\n    1: ['road', 'car', 'traffic'],\n    2: ['car', 'light', 'candle']\n}", "raw_solution": "import pandas as pd\nfrom random import randint, seed\n\ndef task_func(dictionary, item, sample_size=None, random_seed=None):\n    # Convert dictionary to DataFrame\n    df = pd.DataFrame(dictionary)\n    \n    # Find positions of the item\n    positions = [(i, col) for i, row in enumerate(df.values) for col in row.index[row == item]]\n    \n    # If sample_size is provided, return a random sample of these positions\n    if sample_size is not None:\n        if random_seed is not None:\n            seed(random_seed)\n        positions = [positions[randint(0, len(positions)-1)] for _ in range(sample_size)]\n    \n    return positions, df\n\n# Test the function\ndictionary = {\n    1: ['road', 'car', 'traffic'],\n    2: ['car', 'light', 'candle']\n}\n\npositions, df = task_func(dictionary, 'car', sample_size=2, random_seed=42)"}
{"task_id": "BigCodeBench/812", "solution": "import re\nfrom pathlib import Path\nimport tarfile\nimport os\nPATTERN = r\"(?<!Distillr)\\\\\\\\AcroTray\\.exe\"\nDIRECTORY = r\"C:\\\\SomeDir\\\\\"\ndef task_func(directory=DIRECTORY, file_pattern=PATTERN):\n    # Create a list to store the matched files\n    matched_files = []\n\n    # Iterate over all files in the directory\n    for file in Path(directory).rglob('*'):\n        # Check if the file name matches the pattern\n        if re.search(file_pattern, file.name):\n            matched_files.append(file)\n\n    # If there are matched files\n    if matched_files:\n        # Create a tar file\n        tar_name = 'archive.tar'\n        with tarfile.open(tar_name, 'w') as tar:\n            for file in matched_files:\n                tar.add(file, arcname=os.path.basename(file))\n\n        return tar_name\n\n    else:\n        return \"No files found\"", "raw_solution": "import re\nfrom pathlib import Path\nimport tarfile\nimport os\n\n# Constants\nPATTERN = r\"(?<!Distillr)\\\\\\\\AcroTray\\.exe\"\nDIRECTORY = r\"C:\\\\SomeDir\\\\\"\n\ndef task_func(directory=DIRECTORY, file_pattern=PATTERN):\n    # Create a list to store the matched files\n    matched_files = []\n\n    # Iterate over all files in the directory\n    for file in Path(directory).rglob('*'):\n        # Check if the file name matches the pattern\n        if re.search(file_pattern, file.name):\n            matched_files.append(file)\n\n    # If there are matched files\n    if matched_files:\n        # Create a tar file\n        tar_name = 'archive.tar'\n        with tarfile.open(tar_name, 'w') as tar:\n            for file in matched_files:\n                tar.add(file, arcname=os.path.basename(file))\n\n        return tar_name\n\n    else:\n        return \"No files found\"\n\n# Test the function"}
{"task_id": "BigCodeBench/813", "solution": "from itertools import combinations\nimport pandas as pd\ndef task_func(number_list, element):\n    if not number_list:\n        return pd.DataFrame(columns=['Combinations'])\n    \n    result = [combo for combo in combinations(number_list, 3) if sum(combo) == element]\n    \n    if not result:\n        return pd.DataFrame(columns=['Combinations'])\n    \n    df = pd.DataFrame(result, columns=['Combinations'])\n    df.index += 1\n    \n    return df", "raw_solution": "from itertools import combinations\nimport pandas as pd\n\ndef task_func(number_list, element):\n    if not number_list:\n        return pd.DataFrame(columns=['Combinations'])\n    \n    result = [combo for combo in combinations(number_list, 3) if sum(combo) == element]\n    \n    if not result:\n        return pd.DataFrame(columns=['Combinations'])\n    \n    df = pd.DataFrame(result, columns=['Combinations'])\n    df.index += 1\n    \n    return df\n\n# Test the function\nresult = task_func([-1, 1, 0, -2, 2, 3], 0)"}
{"task_id": "BigCodeBench/814", "solution": "import re\nimport os\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    # Create target directory if it doesn't exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # Create a configuration file path\n    config_file_path = os.path.join(target_dir, 'config.txt')\n\n    # Open the configuration file in write mode\n    with open(config_file_path, 'w') as config_file:\n        # Walk through the source directory\n        for root, dirs, files in os.walk(source_dir):\n            for file in files:\n                # Check if the file matches the pattern\n                if re.search(file_pattern, file):\n                    # Get the file path\n                    file_path = os.path.join(root, file)\n                    # Write the file path to the configuration file\n                    config_file.write(file_path + '\\n')\n\n    return config_file_path", "raw_solution": "import re\nimport os\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    # Create target directory if it doesn't exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # Create a configuration file path\n    config_file_path = os.path.join(target_dir, 'config.txt')\n\n    # Open the configuration file in write mode\n    with open(config_file_path, 'w') as config_file:\n        # Walk through the source directory\n        for root, dirs, files in os.walk(source_dir):\n            for file in files:\n                # Check if the file matches the pattern\n                if re.search(file_pattern, file):\n                    # Get the file path\n                    file_path = os.path.join(root, file)\n                    # Write the file path to the configuration file\n                    config_file.write(file_path + '\\n')\n\n    return config_file_path"}
{"task_id": "BigCodeBench/815", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(test_scores, student):\n    df = pd.DataFrame(test_scores)\n    if student not in df['Student'].values:\n        raise ValueError('student is not present in the test_scores dataframe')\n    else:\n        student_scores = df.loc[df['Student'] == student, 'Score']\n        return np.array([np.mean(student_scores), np.std(student_scores)]), df", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(test_scores, student):\n    df = pd.DataFrame(test_scores)\n    if student not in df['Student'].values:\n        raise ValueError('student is not present in the test_scores dataframe')\n    else:\n        student_scores = df.loc[df['Student'] == student, 'Score']\n        return np.array([np.mean(student_scores), np.std(student_scores)]), df\n\n# Test the function\nscores = {'Student': [1, 2, 1, 1], 'Score': [10, 1, 1, 1]}"}
{"task_id": "BigCodeBench/816", "solution": "from collections import Counter\nimport random", "raw_solution": "from collections import Counter\nimport random\n\n# Constants\nHAND_RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\nSUITS = ['H', 'D', 'C', 'S']\n\ndef generate_poker_hand():\n    hand = [random.choice(HAND_RANKS) + random.choice(SUITS) for _ in range(5)]\n    rank_count = Counter(card[0] for card in hand)\n    return (tuple(hand), rank_count)\n\ndef test_generate_poker_hand():\n    hand, rank_count = generate_poker_hand()\n    assert len(hand) == 5\n    assert all(card[0] in HAND_RANKS for card in hand)\n    assert all(card[1] in SUITS for card in hand)\n    assert len(rank_count) == 5  # Ensure all ranks are present\n    assert all(count >= 1 and count <= 4 for count in rank_count.values())  # Ensure no rank is repeated more than 4 times\n\ntest_generate_poker_hand()"}
{"task_id": "BigCodeBench/817", "solution": "from collections import Counter\nimport logging\ndef task_func(letter_list, element, log_path='./'):\n    # Set up logging\n    logging.basicConfig(filename=f'{log_path}task_func.log', filemode='w', format='%(levelname)s:%(message)s', level=logging.DEBUG, encoding='utf-8')\n\n    # Log function call\n    logging.info(f\"Function called with list: {letter_list} and element: {element}\")\n\n    # Check if element is in letter_list\n    if element not in letter_list:\n        logging.error(f\"The element '{element}' is not in the letter list.\")\n        raise ValueError(\"The element is not in the letter list.\")\n\n    # Count frequency of element\n    frequency = Counter(letter_list)[element]\n\n    # Log frequency\n    logging.info(f\"Frequency of '{element}' is {frequency}\")\n\n    # Shutdown logging\n    logging.shutdown()\n\n    return frequency", "raw_solution": "from collections import Counter\nimport logging\n\ndef task_func(letter_list, element, log_path='./'):\n    # Set up logging\n    logging.basicConfig(filename=f'{log_path}task_func.log', filemode='w', format='%(levelname)s:%(message)s', level=logging.DEBUG, encoding='utf-8')\n\n    # Log function call\n    logging.info(f\"Function called with list: {letter_list} and element: {element}\")\n\n    # Check if element is in letter_list\n    if element not in letter_list:\n        logging.error(f\"The element '{element}' is not in the letter list.\")\n        raise ValueError(\"The element is not in the letter list.\")\n\n    # Count frequency of element\n    frequency = Counter(letter_list)[element]\n\n    # Log frequency\n    logging.info(f\"Frequency of '{element}' is {frequency}\")\n\n    # Shutdown logging\n    logging.shutdown()\n\n    return frequency"}
{"task_id": "BigCodeBench/818", "solution": "import re\nimport string\nPUNCTUATION = string.punctuation\ndef task_func(text):\n    # Remove punctuation\n    text_no_punct = \"\".join('' if char in PUNCTUATION else char for char in text)\n    # Split into words and convert to lowercase\n    cleaned_words = re.split('\\W+', text_no_punct.lower())\n    return cleaned_words\ntext = \"Hello, world! This is a test.\"", "raw_solution": "import re\nimport string\n\n# Constants\nPUNCTUATION = string.punctuation\n\ndef task_func(text):\n    # Remove punctuation\n    text_no_punct = \"\".join('' if char in PUNCTUATION else char for char in text)\n    # Split into words and convert to lowercase\n    cleaned_words = re.split('\\W+', text_no_punct.lower())\n    return cleaned_words\n\n# Test the function\ntext = \"Hello, world! This is a test.\""}
{"task_id": "BigCodeBench/819", "solution": "import time\nimport random\ndef task_func(iterations=5, min_delay=1.0, max_delay=2.0, seed=None):\n    # Check if inputs are valid\n    if not isinstance(iterations, int) or iterations <= 0:\n        raise ValueError(\"Iterations must be a positive integer.\")\n    if not isinstance(min_delay, (int, float)) or min_delay <= 0:\n        raise ValueError(\"Min_delay must be a positive number.\")\n    if not isinstance(max_delay, (int, float)) or max_delay <= 0:\n        raise ValueError(\"Max_delay must be a positive number.\")\n    if seed is not None and not isinstance(seed, int):\n        raise ValueError(\"Seed must be an integer or None.\")\n\n    # Set the seed for the random number generator\n    if seed is not None:\n        random.seed(seed)\n\n    # Initialize variables\n    messages = []\n    total_delay = 0\n\n    # Perform the task\n    for i in range(iterations):\n        delay = random.uniform(min_delay, max_delay)\n        time.sleep(delay)\n        messages.append(f\"{delay:.2f} seconds have passed\")\n        total_delay += delay\n\n    return messages, total_delay", "raw_solution": "import time\nimport random\n\ndef task_func(iterations=5, min_delay=1.0, max_delay=2.0, seed=None):\n    # Check if inputs are valid\n    if not isinstance(iterations, int) or iterations <= 0:\n        raise ValueError(\"Iterations must be a positive integer.\")\n    if not isinstance(min_delay, (int, float)) or min_delay <= 0:\n        raise ValueError(\"Min_delay must be a positive number.\")\n    if not isinstance(max_delay, (int, float)) or max_delay <= 0:\n        raise ValueError(\"Max_delay must be a positive number.\")\n    if seed is not None and not isinstance(seed, int):\n        raise ValueError(\"Seed must be an integer or None.\")\n\n    # Set the seed for the random number generator\n    if seed is not None:\n        random.seed(seed)\n\n    # Initialize variables\n    messages = []\n    total_delay = 0\n\n    # Perform the task\n    for i in range(iterations):\n        delay = random.uniform(min_delay, max_delay)\n        time.sleep(delay)\n        messages.append(f\"{delay:.2f} seconds have passed\")\n        total_delay += delay\n\n    return messages, total_delay\n\n# Test the function\nmessages, delay = task_func(2, 2.0, 4.2, seed=12)"}
{"task_id": "BigCodeBench/820", "solution": "import random\nimport string\nLETTERS = string.ascii_letters\ndef task_func(num_words, word_length):\n    if num_words < 0 or word_length < 0:\n        raise ValueError(\"num_words and word_length should be non-negative\")\n\n    words = []\n    for _ in range(num_words):\n        word = ''.join(random.choice(LETTERS) for _ in range(word_length))\n        words.append(word)\n\n    return words", "raw_solution": "import random\nimport string\n\n# Constants\nLETTERS = string.ascii_letters\n\ndef task_func(num_words, word_length):\n    if num_words < 0 or word_length < 0:\n        raise ValueError(\"num_words and word_length should be non-negative\")\n\n    words = []\n    for _ in range(num_words):\n        word = ''.join(random.choice(LETTERS) for _ in range(word_length))\n        words.append(word)\n\n    return words\n\n# Test the function"}
{"task_id": "BigCodeBench/821", "solution": "import time\nimport threading\ndef task_func(delay_time: float = 1.0, num_threads: int = 5):\n    def thread_func(i):\n        time.sleep(delay_time)\n        print(f'Delay in thread {i} completed')\n\n    threads = []\n    for i in range(num_threads):\n        thread = threading.Thread(target=thread_func, args=(i,))\n        threads.append(thread)\n        thread.start()\n\n    for thread in threads:\n        thread.join()", "raw_solution": "import time\nimport threading\n\ndef task_func(delay_time: float = 1.0, num_threads: int = 5):\n    def thread_func(i):\n        time.sleep(delay_time)\n        print(f'Delay in thread {i} completed')\n\n    threads = []\n    for i in range(num_threads):\n        thread = threading.Thread(target=thread_func, args=(i,))\n        threads.append(thread)\n        thread.start()\n\n    for thread in threads:\n        thread.join()\n\ntask_func(1, 10)"}
{"task_id": "BigCodeBench/822", "solution": "import random\nimport string\nLETTERS = string.ascii_letters\nDIGITS = string.digits\ndef task_func(length, num_digits):\n    if num_digits > length:\n        raise ValueError(\"Number of digits cannot be greater than the length of the password\")\n\n    # Generate a list of random letters and digits\n    password_list = [random.choice(LETTERS) for _ in range(length - num_digits)] + \\\n                    [random.choice(DIGITS) for _ in range(num_digits)]\n\n    # Shuffle the list to ensure randomness\n    random.shuffle(password_list)\n\n    # Join the list into a string and return\n    return ''.join(password_list)", "raw_solution": "import random\nimport string\n\n# Constants\nLETTERS = string.ascii_letters\nDIGITS = string.digits\n\ndef task_func(length, num_digits):\n    if num_digits > length:\n        raise ValueError(\"Number of digits cannot be greater than the length of the password\")\n\n    # Generate a list of random letters and digits\n    password_list = [random.choice(LETTERS) for _ in range(length - num_digits)] + \\\n                    [random.choice(DIGITS) for _ in range(num_digits)]\n\n    # Shuffle the list to ensure randomness\n    random.shuffle(password_list)\n\n    # Join the list into a string and return\n    return ''.join(password_list)\n\n# Test the function"}
{"task_id": "BigCodeBench/823", "solution": "import time\nimport numpy as np\ndef task_func(samples=10, delay=0.1):\n    delay_times = []\n    for i in range(samples):\n        start_time = time.time()\n        time.sleep(delay)\n        end_time = time.time()\n        delay_times.append(end_time - start_time)\n\n    mean_delay = np.mean(delay_times)\n    std_dev_delay = np.std(delay_times)\n\n    return (mean_delay, std_dev_delay)", "raw_solution": "import time\nimport numpy as np\n\ndef task_func(samples=10, delay=0.1):\n    delay_times = []\n    for i in range(samples):\n        start_time = time.time()\n        time.sleep(delay)\n        end_time = time.time()\n        delay_times.append(end_time - start_time)\n\n    mean_delay = np.mean(delay_times)\n    std_dev_delay = np.std(delay_times)\n\n    return (mean_delay, std_dev_delay)\n\n# Test the function\nmean, std_dev = task_func(samples=5, delay=0.2)"}
{"task_id": "BigCodeBench/824", "solution": "import re\nimport string\nPUNCTUATION = string.punctuation\ndef task_func(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    punctuation_marks = sum(1 for char in text if char in PUNCTUATION)\n    return (len(words), punctuation_marks)\ntext = \"Hello, world! How's it going? Good, I hope.\"", "raw_solution": "import re\nimport string\n\n# Constants\nPUNCTUATION = string.punctuation\n\ndef task_func(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    punctuation_marks = sum(1 for char in text if char in PUNCTUATION)\n    return (len(words), punctuation_marks)\n\n# Test the function\ntext = \"Hello, world! How's it going? Good, I hope.\""}
{"task_id": "BigCodeBench/825", "solution": "import numpy as np\nfrom itertools import product\nimport string\ndef task_func(length, seed=None, alphabets=list(string.ascii_lowercase)):\n    np.random.seed(seed)\n    random_strings = []\n    for _ in range(10):\n        random_strings.append(''.join(np.random.choice(alphabets, size=length)))\n    return random_strings", "raw_solution": "import numpy as np\nfrom itertools import product\nimport string\n\ndef task_func(length, seed=None, alphabets=list(string.ascii_lowercase)):\n    np.random.seed(seed)\n    random_strings = []\n    for _ in range(10):\n        random_strings.append(''.join(np.random.choice(alphabets, size=length)))\n    return random_strings\n"}
{"task_id": "BigCodeBench/826", "solution": "import re\nimport os\nimport shutil\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    if not os.path.exists(source_dir) or not os.path.exists(target_dir):\n        raise ValueError(\"Source or target directory does not exist.\")\n\n    moved_files_count = 0\n    for filename in os.listdir(source_dir):\n        if re.match(file_pattern, filename):\n            shutil.move(os.path.join(source_dir, filename), target_dir)\n            moved_files_count += 1\n\n    return moved_files_count\nsource_dir = \"/path/to/source\"\ntarget_dir = \"/path/to/target\"", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    if not os.path.exists(source_dir) or not os.path.exists(target_dir):\n        raise ValueError(\"Source or target directory does not exist.\")\n\n    moved_files_count = 0\n    for filename in os.listdir(source_dir):\n        if re.match(file_pattern, filename):\n            shutil.move(os.path.join(source_dir, filename), target_dir)\n            moved_files_count += 1\n\n    return moved_files_count\n\n# Test the function\nsource_dir = \"/path/to/source\"\ntarget_dir = \"/path/to/target\""}
{"task_id": "BigCodeBench/827", "solution": "import math\nfrom sympy import isprime\ndef task_func(input_list):\n    prime_list = [i for i in input_list if isprime(i)]\n    prime_list.sort(key=lambda x: math.degrees(math.atan(x)))\n    return prime_list", "raw_solution": "import math\nfrom sympy import isprime\n\ndef task_func(input_list):\n    prime_list = [i for i in input_list if isprime(i)]\n    prime_list.sort(key=lambda x: math.degrees(math.atan(x)))\n    return prime_list\n"}
{"task_id": "BigCodeBench/828", "solution": "import os\nimport shutil\ndef task_func(filename, dest_dir):\n    try:\n        if not os.path.exists(filename):\n            raise FileNotFoundError(f\"The file {filename} does not exist.\")\n        \n        if not os.path.exists(dest_dir):\n            os.makedirs(dest_dir)\n        \n        shutil.copy(filename, dest_dir)\n        \n        with open(os.path.join(dest_dir, filename), 'w') as f:\n            pass\n        \n        return os.path.abspath(os.path.join(dest_dir, filename))\n    \n    except OSError as e:\n        print(f\"Error: {str(e)}\")\n        raise\n    except FileNotFoundError as e:\n        print(f\"Error: {str(e)}\")\n        raise", "raw_solution": "import os\nimport shutil\n\ndef task_func(filename, dest_dir):\n    try:\n        if not os.path.exists(filename):\n            raise FileNotFoundError(f\"The file {filename} does not exist.\")\n        \n        if not os.path.exists(dest_dir):\n            os.makedirs(dest_dir)\n        \n        shutil.copy(filename, dest_dir)\n        \n        with open(os.path.join(dest_dir, filename), 'w') as f:\n            pass\n        \n        return os.path.abspath(os.path.join(dest_dir, filename))\n    \n    except OSError as e:\n        print(f\"Error: {str(e)}\")\n        raise\n    except FileNotFoundError as e:\n        print(f\"Error: {str(e)}\")\n        raise"}
{"task_id": "BigCodeBench/829", "solution": "import pandas as pd\nfrom statistics import mean\ndef task_func(df: pd.DataFrame) -> dict:\n    if 'Name' not in df.columns or 'Score' not in df.columns:\n        raise ValueError(\"The DataFrame does not have the 'Name' and 'Score' columns.\")\n    \n    df_grouped = df.groupby('Name')['Score'].apply(list).reset_index()\n    gen_dict = df_grouped.set_index('Name').T.to_dict('records')\n\n    for key, value in gen_dict.items():\n        value['Score'] = mean(value['Score'])\n        gen_dict[key] = ((key, value['Score']))\n\n    return gen_dict\ndf_sample = pd.DataFrame({\n    'Name': ['Micky', 'Donald', 'Girl'],\n    'Score': [25.2, 9, -1]\n})", "raw_solution": "import pandas as pd\nfrom statistics import mean\n\ndef task_func(df: pd.DataFrame) -> dict:\n    if 'Name' not in df.columns or 'Score' not in df.columns:\n        raise ValueError(\"The DataFrame does not have the 'Name' and 'Score' columns.\")\n    \n    df_grouped = df.groupby('Name')['Score'].apply(list).reset_index()\n    gen_dict = df_grouped.set_index('Name').T.to_dict('records')\n\n    for key, value in gen_dict.items():\n        value['Score'] = mean(value['Score'])\n        gen_dict[key] = ((key, value['Score']))\n\n    return gen_dict\n\ndf_sample = pd.DataFrame({\n    'Name': ['Micky', 'Donald', 'Girl'],\n    'Score': [25.2, 9, -1]\n})\n\ngen_dict = task_func(df_sample)"}
{"task_id": "BigCodeBench/830", "solution": "import json\nimport os\ndef task_func(filename, data):\n    # Check if file exists\n    file_exists = os.path.isfile(filename)\n\n    # Write dictionary to file\n    with open(filename, 'w') as f:\n        json.dump(data, f)\n\n    # Read back the written data\n    with open(filename, 'r') as f:\n        written_data = json.load(f)\n\n    # Verify the written data\n    verification_success = written_data == data\n\n    # Return the result as a tuple\n    return (verification_success, written_data)\nfilename = 'test.json'\ndata = {'name': 'John', 'age': 30, 'city': 'New York'}", "raw_solution": "import json\nimport os\n\ndef task_func(filename, data):\n    # Check if file exists\n    file_exists = os.path.isfile(filename)\n\n    # Write dictionary to file\n    with open(filename, 'w') as f:\n        json.dump(data, f)\n\n    # Read back the written data\n    with open(filename, 'r') as f:\n        written_data = json.load(f)\n\n    # Verify the written data\n    verification_success = written_data == data\n\n    # Return the result as a tuple\n    return (verification_success, written_data)\n\n# Test the function\nfilename = 'test.json'\ndata = {'name': 'John', 'age': 30, 'city': 'New York'}"}
{"task_id": "BigCodeBench/831", "solution": "import random\nimport math\ndef task_func(range_start=1, range_end=100, pairs_count=10, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    for _ in range(pairs_count):\n        num1 = random.randint(range_start, range_end)\n        num2 = random.randint(range_start, range_end)\n        yield (num1, num2, math.sqrt(abs(num1 - num2)))", "raw_solution": "import random\nimport math\n\ndef task_func(range_start=1, range_end=100, pairs_count=10, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    for _ in range(pairs_count):\n        num1 = random.randint(range_start, range_end)\n        num2 = random.randint(range_start, range_end)\n        yield (num1, num2, math.sqrt(abs(num1 - num2)))\n\n# Test the function\npairs = task_func(1, 3, pairs_count=25, random_seed=14)\nfor _ in range(25):\n    print(next(pairs))"}
{"task_id": "BigCodeBench/832", "solution": "import pickle\nimport os\ndef task_func(filename, data):\n    try:\n        # Check if the directory exists, create it if necessary\n        directory = os.path.dirname(filename)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n\n        # Serialize the object using pickle\n        serialized_data = pickle.dumps(data)\n\n        # Write the serialized data to the file\n        with open(filename, 'wb') as file:\n            file.write(serialized_data)\n\n        return True\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return False", "raw_solution": "import pickle\nimport os\n\ndef task_func(filename, data):\n    try:\n        # Check if the directory exists, create it if necessary\n        directory = os.path.dirname(filename)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n\n        # Serialize the object using pickle\n        serialized_data = pickle.dumps(data)\n\n        # Write the serialized data to the file\n        with open(filename, 'wb') as file:\n            file.write(serialized_data)\n\n        return True\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return False\n\n# Test the function"}
{"task_id": "BigCodeBench/833", "solution": "import random\nfrom collections import Counter\nfrom statistics import mode\ndef task_func(list_length=1000, range_start=1, range_end=10, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    random_list = [random.randint(range_start, range_end) for _ in range(list_length)]\n    counter = Counter(random_list)\n    gen = ((num, freq) for num, freq in counter.items())\n    return mode(random_list), gen", "raw_solution": "import random\nfrom collections import Counter\nfrom statistics import mode\n\ndef task_func(list_length=1000, range_start=1, range_end=10, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    random_list = [random.randint(range_start, range_end) for _ in range(list_length)]\n    counter = Counter(random_list)\n    gen = ((num, freq) for num, freq in counter.items())\n    return mode(random_list), gen\n\nmode, numbers = task_func(20, -12, 334, random_seed=23)"}
{"task_id": "BigCodeBench/834", "solution": "import binascii\nimport io\nimport gzip\ndef task_func(compressed_hex, key):\n    try:\n        # Convert hexadecimal to bytes\n        compressed_bytes = binascii.unhexlify(compressed_hex)\n\n        # Decrypt the bytes\n        decrypted_bytes = bytes([b ^ key for b in compressed_bytes])\n\n        # Decompress the bytes\n        decompressed_bytes = gzip.decompress(decrypted_bytes)\n\n        # Convert bytes to string\n        decoded_string = decompressed_bytes.decode('utf-8')\n\n        return decoded_string\n\n    except Exception as e:\n        return f\"An error occurred: {str(e)}\"", "raw_solution": "import binascii\nimport io\nimport gzip\n\ndef task_func(compressed_hex, key):\n    try:\n        # Convert hexadecimal to bytes\n        compressed_bytes = binascii.unhexlify(compressed_hex)\n\n        # Decrypt the bytes\n        decrypted_bytes = bytes([b ^ key for b in compressed_bytes])\n\n        # Decompress the bytes\n        decompressed_bytes = gzip.decompress(decrypted_bytes)\n\n        # Convert bytes to string\n        decoded_string = decompressed_bytes.decode('utf-8')\n\n        return decoded_string\n\n    except Exception as e:\n        return f\"An error occurred: {str(e)}\"\n\n# Test the function\ncompressed_hex = '1f8b0800000000000003edd75b66233110c7f5f91343487d9f9b989999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999"}
{"task_id": "BigCodeBench/835", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(n_rows, remove_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.randint(0,101,size=(n_rows, len(columns))), columns=columns)\n    df = df.drop(df.columns[remove_cols], axis=1)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(n_rows, remove_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.randint(0,101,size=(n_rows, len(columns))), columns=columns)\n    df = df.drop(df.columns[remove_cols], axis=1)\n    return df\n\n# Test the function\ndf = task_func(3, [1, 3], columns=['test', 'rem1', 'apple', 'remove'], random_seed=12)"}
{"task_id": "BigCodeBench/836", "solution": "import os\nimport shutil\nimport csv\ndef task_func(target_value='332', csv_dir='./csv_files/', processed_dir='./processed_files/', simulate=False):\n    result = {}\n    for filename in os.listdir(csv_dir):\n        if filename.endswith('.csv'):\n            with open(os.path.join(csv_dir, filename), 'r') as file:\n                reader = csv.reader(file)\n                for i, row in enumerate(reader):\n                    if row and row[0] == target_value:\n                        result[filename] = i\n                        if not simulate:\n                            shutil.move(os.path.join(csv_dir, filename), os.path.join(processed_dir, filename))\n                        break\n    return result", "raw_solution": "import os\nimport shutil\nimport csv\n\ndef task_func(target_value='332', csv_dir='./csv_files/', processed_dir='./processed_files/', simulate=False):\n    result = {}\n    for filename in os.listdir(csv_dir):\n        if filename.endswith('.csv'):\n            with open(os.path.join(csv_dir, filename), 'r') as file:\n                reader = csv.reader(file)\n                for i, row in enumerate(reader):\n                    if row and row[0] == target_value:\n                        result[filename] = i\n                        if not simulate:\n                            shutil.move(os.path.join(csv_dir, filename), os.path.join(processed_dir, filename))\n                        break\n    return result"}
{"task_id": "BigCodeBench/837", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(n_rows, scale_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.randint(1,100,size=(n_rows, len(columns))), columns=columns)\n    scaler = StandardScaler()\n    df.iloc[:, scale_cols] = scaler.fit_transform(df.iloc[:, scale_cols])\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(n_rows, scale_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.randint(1,100,size=(n_rows, len(columns))), columns=columns)\n    scaler = StandardScaler()\n    df.iloc[:, scale_cols] = scaler.fit_transform(df.iloc[:, scale_cols])\n    return df\n\ndf = task_func(5, [1, 2, 3], random_seed=12)"}
{"task_id": "BigCodeBench/838", "solution": "import re\nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nimport pandas as pd\ndef task_func(text_series):\n    # Initialize PorterStemmer\n    ps = PorterStemmer()\n\n    # Define a function to process a single string\n    def process_string(s):\n        # Lowercase all letters\n        s = s.lower()\n        # Remove non-alphanumeric characters (except spaces)\n        s = re.sub(r'[^a-z0-9 ]', '', s)\n        # Tokenize the string into words\n        words = word_tokenize(s)\n        # Stem each word\n        stemmed_words = [ps.stem(word) for word in words]\n        # Join the stemmed words back into a string\n        s = ' '.join(stemmed_words)\n        return s\n\n    # Apply the function to each string in the Series\n    processed_series = text_series.apply(process_string)\n\n    return processed_series\ntext_series = pd.Series(['Hello, world!', 'This is a test.', 'Stemming is fun.'])", "raw_solution": "import re\nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nimport pandas as pd\n\n# Ensure NLTK data is downloaded\nnltk.download('punkt')\n\ndef task_func(text_series):\n    # Initialize PorterStemmer\n    ps = PorterStemmer()\n\n    # Define a function to process a single string\n    def process_string(s):\n        # Lowercase all letters\n        s = s.lower()\n        # Remove non-alphanumeric characters (except spaces)\n        s = re.sub(r'[^a-z0-9 ]', '', s)\n        # Tokenize the string into words\n        words = word_tokenize(s)\n        # Stem each word\n        stemmed_words = [ps.stem(word) for word in words]\n        # Join the stemmed words back into a string\n        s = ' '.join(stemmed_words)\n        return s\n\n    # Apply the function to each string in the Series\n    processed_series = text_series.apply(process_string)\n\n    return processed_series\n\n# Test the function\ntext_series = pd.Series(['Hello, world!', 'This is a test.', 'Stemming is fun.'])"}
{"task_id": "BigCodeBench/839", "solution": "import csv\nimport random\nimport string\ndef task_func(file_path,\n          num_rows,\n          gender=['Male', 'Female', 'Non-Binary'],\n          countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n          seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        if num_rows > 0:\n            writer.writerow(['Name', 'Age', 'Gender', 'Country'])\n            for _ in range(num_rows):\n                name = ''.join(random.choice(string.ascii_uppercase) for _ in range(5))\n                age = random.randint(20, 60)\n                gend = random.choice(gender)\n                countr = random.choice(countries)\n                writer.writerow([name, age, gend, countr])\n        else:\n            writer.writerow(['Name', 'Age', 'Gender', 'Country'])\n    return file_path", "raw_solution": "import csv\nimport random\nimport string\n\ndef task_func(file_path,\n          num_rows,\n          gender=['Male', 'Female', 'Non-Binary'],\n          countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n          seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        if num_rows > 0:\n            writer.writerow(['Name', 'Age', 'Gender', 'Country'])\n            for _ in range(num_rows):\n                name = ''.join(random.choice(string.ascii_uppercase) for _ in range(5))\n                age = random.randint(20, 60)\n                gend = random.choice(gender)\n                countr = random.choice(countries)\n                writer.writerow([name, age, gend, countr])\n        else:\n            writer.writerow(['Name', 'Age', 'Gender', 'Country'])\n    return file_path"}
{"task_id": "BigCodeBench/840", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(file_path, num_rows, data_dimensions=5, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n\n    data = np.random.rand(num_rows, data_dimensions)\n\n    df = pd.DataFrame(data)\n\n    df.columns = ['Feature_{}'.format(i+1) for i in range(data_dimensions)]\n\n    df.to_csv(file_path, index=False)\n\n    return file_path\nfile_path = 'test.csv'\nnum_rows = 10\ndata_dimensions = 4\nrandom_seed = 42", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(file_path, num_rows, data_dimensions=5, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n\n    data = np.random.rand(num_rows, data_dimensions)\n\n    df = pd.DataFrame(data)\n\n    df.columns = ['Feature_{}'.format(i+1) for i in range(data_dimensions)]\n\n    df.to_csv(file_path, index=False)\n\n    return file_path\n\n# Test the function\nfile_path = 'test.csv'\nnum_rows = 10\ndata_dimensions = 4\nrandom_seed = 42"}
{"task_id": "BigCodeBench/841", "solution": "import re\nimport json\nfrom collections import defaultdict\nimport string\ndef task_func(json_string):\n    try:\n        data = json.loads(json_string)\n        if \"text\" in data:\n            text = data[\"text\"]\n            text = text.lower()\n            text = re.sub(r'[^\\w\\s]', '', text)\n            words = text.split()\n            word_count = defaultdict(int)\n            for word in words:\n                word_count[word] += 1\n            return word_count\n        else:\n            return {}\n    except (json.JSONDecodeError, TypeError):\n        return {}\njson_string = '{\"text\": \"Hello, world! world.\"}'", "raw_solution": "import re\nimport json\nfrom collections import defaultdict\nimport string\n\ndef task_func(json_string):\n    try:\n        data = json.loads(json_string)\n        if \"text\" in data:\n            text = data[\"text\"]\n            text = text.lower()\n            text = re.sub(r'[^\\w\\s]', '', text)\n            words = text.split()\n            word_count = defaultdict(int)\n            for word in words:\n                word_count[word] += 1\n            return word_count\n        else:\n            return {}\n    except (json.JSONDecodeError, TypeError):\n        return {}\n\n# Testing\njson_string = '{\"text\": \"Hello, world! world.\"}'"}
{"task_id": "BigCodeBench/842", "solution": "import sqlite3\nimport random\ndef task_func(db_path,\n              num_entries,\n              users=['Alice', 'Bob', 'Charlie', 'Dave', 'Eve'],\n              countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n              random_seed=None):\n    \n    # Set the random seed\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_path)\n    c = conn.cursor()\n\n    # Create the 'users' table\n    c.execute('''\n        CREATE TABLE users\n        (id INTEGER PRIMARY KEY, name TEXT, age INTEGER, country TEXT)\n    ''')\n\n    # Insert data into the 'users' table\n    for i in range(num_entries):\n        name = random.choice(users)\n        age = random.randint(20, 60)\n        country = random.choice(countries)\n        c.execute(\"INSERT INTO users VALUES (?, ?, ?, ?)\", (i+1, name, age, country))\n\n    # Save (commit) the changes\n    conn.commit()\n\n    return db_path", "raw_solution": "import sqlite3\nimport random\n\ndef task_func(db_path,\n              num_entries,\n              users=['Alice', 'Bob', 'Charlie', 'Dave', 'Eve'],\n              countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n              random_seed=None):\n    \n    # Set the random seed\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_path)\n    c = conn.cursor()\n\n    # Create the 'users' table\n    c.execute('''\n        CREATE TABLE users\n        (id INTEGER PRIMARY KEY, name TEXT, age INTEGER, country TEXT)\n    ''')\n\n    # Insert data into the 'users' table\n    for i in range(num_entries):\n        name = random.choice(users)\n        age = random.randint(20, 60)\n        country = random.choice(countries)\n        c.execute(\"INSERT INTO users VALUES (?, ?, ?, ?)\", (i+1, name, age, country))\n\n    # Save (commit) the changes\n    conn.commit()\n\n    return db_path"}
{"task_id": "BigCodeBench/843", "solution": "import random\nimport re\nWORD_LIST = [\"sample\", \"text\", \"contains\", \"several\", \"words\", \"including\"]\ndef task_func(n_sentences):\n    # Generate sentences\n    sentences = []\n    for _ in range(n_sentences):\n        sentence = \" \".join(random.choice(WORD_LIST) for _ in range(random.randint(5, 15))) + \".\"\n        sentences.append(sentence)\n    \n    # Concatenate sentences into a single string\n    text = \" \".join(sentences)\n    \n    # Convert to lowercase and remove non-alphanumeric characters\n    text = text.lower()\n    text = re.sub(r'[^a-z\\s]', '', text)\n    \n    return text", "raw_solution": "import random\nimport re\n\n# Constants\nWORD_LIST = [\"sample\", \"text\", \"contains\", \"several\", \"words\", \"including\"]\n\ndef task_func(n_sentences):\n    # Generate sentences\n    sentences = []\n    for _ in range(n_sentences):\n        sentence = \" \".join(random.choice(WORD_LIST) for _ in range(random.randint(5, 15))) + \".\"\n        sentences.append(sentence)\n    \n    # Concatenate sentences into a single string\n    text = \" \".join(sentences)\n    \n    # Convert to lowercase and remove non-alphanumeric characters\n    text = text.lower()\n    text = re.sub(r'[^a-z\\s]', '', text)\n    \n    return text\n\n# Test the function"}
{"task_id": "BigCodeBench/844", "solution": "import csv\nimport random\nfrom faker import Faker\ndef task_func(file_path, num_rows, random_seed=None):\n    if not isinstance(num_rows, int) or num_rows < 0:\n        raise ValueError(\"num_rows should be an integer >= 0\")\n\n    fake = Faker()\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Name', 'Age', 'Address', 'Email'])\n        for _ in range(num_rows):\n            name = fake.name()\n            age = random.randint(20, 60)\n            address = fake.address().replace('\\n', ', ')\n            email = fake.email()\n            writer.writerow([name, age, address, email])\n\n    return file_path", "raw_solution": "import csv\nimport random\nfrom faker import Faker\n\ndef task_func(file_path, num_rows, random_seed=None):\n    if not isinstance(num_rows, int) or num_rows < 0:\n        raise ValueError(\"num_rows should be an integer >= 0\")\n\n    fake = Faker()\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Name', 'Age', 'Address', 'Email'])\n        for _ in range(num_rows):\n            name = fake.name()\n            age = random.randint(20, 60)\n            address = fake.address().replace('\\n', ', ')\n            email = fake.email()\n            writer.writerow([name, age, address, email])\n\n    return file_path\n\n# Test the function\npath = task_func('test.csv', 5, random_seed=12)\nwith open(path, 'r') as file:\n    reader = csv.reader(file)\n    rows = list(reader)"}
{"task_id": "BigCodeBench/845", "solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom Levenshtein import ratio\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(text1, text2):\n    # Clean the texts\n    text1 = ALPHANUMERIC.sub(' ', text1).lower()\n    text2 = ALPHANUMERIC.sub(' ', text2).lower()\n\n    # Compute term frequency\n    counter1 = Counter(text1.split())\n    counter2 = Counter(text2.split())\n\n    # Compute cosine similarity\n    cosine_similarity = sum(counter1.get(k, 0) * counter2.get(k, 0) for k in set(counter1.keys()).union(counter2.keys())) / (np.sqrt(sum(counter1[k]**2 for k in counter1.keys()) * sum(counter2[k]**2 for k in counter2.keys())) + 1e-10)\n\n    # Compute Levenshtein ratio\n    levenshtein_ratio = ratio(text1, text2)\n\n    return (cosine_similarity, levenshtein_ratio)\ntext1 = \"Hello, world!\"\ntext2 = \"hello, world!\"", "raw_solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom Levenshtein import ratio\n\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\n\ndef task_func(text1, text2):\n    # Clean the texts\n    text1 = ALPHANUMERIC.sub(' ', text1).lower()\n    text2 = ALPHANUMERIC.sub(' ', text2).lower()\n\n    # Compute term frequency\n    counter1 = Counter(text1.split())\n    counter2 = Counter(text2.split())\n\n    # Compute cosine similarity\n    cosine_similarity = sum(counter1.get(k, 0) * counter2.get(k, 0) for k in set(counter1.keys()).union(counter2.keys())) / (np.sqrt(sum(counter1[k]**2 for k in counter1.keys()) * sum(counter2[k]**2 for k in counter2.keys())) + 1e-10)\n\n    # Compute Levenshtein ratio\n    levenshtein_ratio = ratio(text1, text2)\n\n    return (cosine_similarity, levenshtein_ratio)\n\n# Test the function\ntext1 = \"Hello, world!\"\ntext2 = \"hello, world!\""}
{"task_id": "BigCodeBench/846", "solution": "import collections\nimport pandas as pd\nclass ExampleObject:\n    def __init__(self, animal, shape):\n        self.animal = animal\n        self.shape = shape\ndef task_func(obj_list, attr):\n    # Get the attribute values from the objects\n    attr_values = [getattr(obj, attr) for obj in obj_list]\n    \n    # Count the frequency of each value\n    counter = collections.Counter(attr_values)\n    \n    # Create a DataFrame from the counter\n    df = pd.DataFrame(list(counter.items()), columns=[attr, 'count'])\n    \n    return df\nobj_list = [ExampleObject('tiger', 'Square'), ExampleObject('leopard', 'Circle'), ExampleObject('cat', 'Rectangle'), ExampleObject('elephant', 'Rectangle')]", "raw_solution": "import collections\nimport pandas as pd\n\nclass ExampleObject:\n    def __init__(self, animal, shape):\n        self.animal = animal\n        self.shape = shape\n\ndef task_func(obj_list, attr):\n    # Get the attribute values from the objects\n    attr_values = [getattr(obj, attr) for obj in obj_list]\n    \n    # Count the frequency of each value\n    counter = collections.Counter(attr_values)\n    \n    # Create a DataFrame from the counter\n    df = pd.DataFrame(list(counter.items()), columns=[attr, 'count'])\n    \n    return df\n\n# Test the function\nobj_list = [ExampleObject('tiger', 'Square'), ExampleObject('leopard', 'Circle'), ExampleObject('cat', 'Rectangle'), ExampleObject('elephant', 'Rectangle')]\ncount = task_func(obj_list, 'shape')"}
{"task_id": "BigCodeBench/847", "solution": "import re\nimport os\nimport string\nimport random\ndef task_func(input_string, directory='./text_files'):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    file_paths = []\n    lines = input_string.split('\\n')\n    for i, line in enumerate(lines):\n        # Remove special characters\n        line = re.sub('['+string.punctuation+']', '', line)\n        # Save each string as a separate text file\n        file_path = os.path.join(directory, f'text_{i}.txt')\n        with open(file_path, 'w') as f:\n            f.write(line)\n        file_paths.append(file_path)\n\n    return file_paths\ninput_string = \"\"\"\nHello, world!\nThis is a test.\nWhat's up?\n\"\"\"", "raw_solution": "import re\nimport os\nimport string\nimport random\n\ndef task_func(input_string, directory='./text_files'):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    file_paths = []\n    lines = input_string.split('\\n')\n    for i, line in enumerate(lines):\n        # Remove special characters\n        line = re.sub('['+string.punctuation+']', '', line)\n        # Save each string as a separate text file\n        file_path = os.path.join(directory, f'text_{i}.txt')\n        with open(file_path, 'w') as f:\n            f.write(line)\n        file_paths.append(file_path)\n\n    return file_paths\n\n# Test the function\ninput_string = \"\"\"\nHello, world!\nThis is a test.\nWhat's up?\n\"\"\"\nfile_paths = task_func(input_string)\nfor file_path in file_paths:\n    with open(file_path, 'r') as f:\n        print(f.read())"}
{"task_id": "BigCodeBench/848", "solution": "import heapq\nimport random\nclass Object:\n    def __init__(self, value):\n        self.test = value\ndef task_func(obj_list, attr, top_n=5, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    values = [getattr(obj, attr, None) for obj in obj_list if hasattr(obj, attr)]\n    if not values:\n        return [], None\n\n    top_values = heapq.nlargest(top_n, values)\n    random_value = random.choice(values)\n\n    return top_values, random_value\nobj_list = [Object(random.randint(1, 12)) for _ in range(13)]", "raw_solution": "import heapq\nimport random\n\nclass Object:\n    def __init__(self, value):\n        self.test = value\n\ndef task_func(obj_list, attr, top_n=5, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    values = [getattr(obj, attr, None) for obj in obj_list if hasattr(obj, attr)]\n    if not values:\n        return [], None\n\n    top_values = heapq.nlargest(top_n, values)\n    random_value = random.choice(values)\n\n    return top_values, random_value\n\nrandom.seed(2)\nobj_list = [Object(random.randint(1, 12)) for _ in range(13)]\ntop_values, random_value = task_func(obj_list, 'test', 2, 12)"}
{"task_id": "BigCodeBench/849", "solution": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(input_string):\n    # Split the input string into individual lines\n    lines = input_string.split('\\n')\n\n    # Initialize an empty list to store words\n    words = []\n\n    # Iterate over each line\n    for line in lines:\n        # Remove punctuation and convert the line to lowercase\n        line = re.sub(r'[^\\w\\s]', '', line).lower()\n\n        # Split the line into words\n        line_words = line.split()\n\n        # Add the words to the list, excluding stopwords\n        words.extend([word for word in line_words if word not in STOPWORDS])\n\n    # Count the frequency of each word\n    word_freq = dict(Counter(words))\n\n    return word_freq\ninput_string = \"\"\"\nThis is a sample sentence. It contains several words, some of which are stopwords.\nThe function should remove these words and count the frequency of the remaining ones.\n\"\"\"", "raw_solution": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    # Split the input string into individual lines\n    lines = input_string.split('\\n')\n\n    # Initialize an empty list to store words\n    words = []\n\n    # Iterate over each line\n    for line in lines:\n        # Remove punctuation and convert the line to lowercase\n        line = re.sub(r'[^\\w\\s]', '', line).lower()\n\n        # Split the line into words\n        line_words = line.split()\n\n        # Add the words to the list, excluding stopwords\n        words.extend([word for word in line_words if word not in STOPWORDS])\n\n    # Count the frequency of each word\n    word_freq = dict(Counter(words))\n\n    return word_freq\n\n# Test the function\ninput_string = \"\"\"\nThis is a sample sentence. It contains several words, some of which are stopwords.\nThe function should remove these words and count the frequency of the remaining ones.\n\"\"\"\n"}
{"task_id": "BigCodeBench/850", "solution": "import pandas as pd\nimport random\ndef task_func(students, subjects, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    data = {'Student': []}\n    for subject in subjects:\n        data[subject] = []\n\n    for student in range(1, students + 1):\n        data['Student'].append('Student ' + str(student))\n        for subject in subjects:\n            data[subject].append(random.randint(0, 100))\n\n    df = pd.DataFrame(data)\n    df['Average Grade'] = df.mean(axis=1)\n\n    return df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(students, subjects, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    data = {'Student': []}\n    for subject in subjects:\n        data[subject] = []\n\n    for student in range(1, students + 1):\n        data['Student'].append('Student ' + str(student))\n        for subject in subjects:\n            data[subject].append(random.randint(0, 100))\n\n    df = pd.DataFrame(data)\n    df['Average Grade'] = df.mean(axis=1)\n\n    return df"}
{"task_id": "BigCodeBench/851", "solution": "import textwrap\nimport re\ndef task_func(input_string, width):\n    # Split the input string into separate lines\n    lines = input_string.split('\\n')\n    \n    # Wrap each line to the specified width\n    wrapped_lines = [textwrap.fill(line, width) for line in lines]\n    \n    # Join the wrapped lines back into a single string\n    output_string = '\\n'.join(wrapped_lines)\n    \n    return output_string\ninput_string = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam euismod, nisi eu consectetur interdum, nisi nisi consectetur neque, eu consectetur neque nisi eu nisi. Nullam euismod, nisi eu consectetur interdum, nisi nisi consectetur neque, eu consectetur neque nisi eu nisi.\"\nwidth = 20", "raw_solution": "import textwrap\nimport re\n\ndef task_func(input_string, width):\n    # Split the input string into separate lines\n    lines = input_string.split('\\n')\n    \n    # Wrap each line to the specified width\n    wrapped_lines = [textwrap.fill(line, width) for line in lines]\n    \n    # Join the wrapped lines back into a single string\n    output_string = '\\n'.join(wrapped_lines)\n    \n    return output_string\n\n# Test the function\ninput_string = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam euismod, nisi eu consectetur interdum, nisi nisi consectetur neque, eu consectetur neque nisi eu nisi. Nullam euismod, nisi eu consectetur interdum, nisi nisi consectetur neque, eu consectetur neque nisi eu nisi.\"\nwidth = 20"}
{"task_id": "BigCodeBench/852", "solution": "import random\nimport string\ndef task_func(max_length, n_samples, seed=None):\n    if max_length < 1:\n        raise ValueError(\"max_length must be greater than 0\")\n    if seed is not None:\n        random.seed(seed)\n    return [''.join(random.choices(string.ascii_lowercase, k=random.randint(1, max_length))) for _ in range(n_samples)]", "raw_solution": "import random\nimport string\n\ndef task_func(max_length, n_samples, seed=None):\n    if max_length < 1:\n        raise ValueError(\"max_length must be greater than 0\")\n    if seed is not None:\n        random.seed(seed)\n    return [''.join(random.choices(string.ascii_lowercase, k=random.randint(1, max_length))) for _ in range(n_samples)]\n\n# Test the function"}
{"task_id": "BigCodeBench/853", "solution": "import os\nimport shutil\nimport string\nINVALID_CHARACTERS = string.punctuation + string.whitespace\ndef task_func(directory_path):\n    # Initialize summary dictionary\n    summary = {\"total\": 0, \"moved\": 0}\n\n    # Check if directory exists\n    if not os.path.isdir(directory_path):\n        return \"Invalid directory path\"\n\n    # Create \"Invalid\" directory if it doesn't exist\n    invalid_dir = os.path.join(directory_path, \"Invalid\")\n    if not os.path.isdir(invalid_dir):\n        os.mkdir(invalid_dir)\n\n    # Scan directory\n    for filename in os.listdir(directory_path):\n        # Ignore \"Invalid\" directory\n        if filename == \"Invalid\":\n            continue\n\n        # Increment total count\n        summary[\"total\"] += 1\n\n        # Check if filename contains invalid characters\n        if any(char in filename for char in INVALID_CHARACTERS):\n            # Move file to \"Invalid\" directory\n            shutil.move(os.path.join(directory_path, filename), invalid_dir)\n            # Increment moved count\n            summary[\"moved\"] += 1\n\n    return summary", "raw_solution": "import os\nimport shutil\nimport string\n\n# Constants\nINVALID_CHARACTERS = string.punctuation + string.whitespace\n\ndef task_func(directory_path):\n    # Initialize summary dictionary\n    summary = {\"total\": 0, \"moved\": 0}\n\n    # Check if directory exists\n    if not os.path.isdir(directory_path):\n        return \"Invalid directory path\"\n\n    # Create \"Invalid\" directory if it doesn't exist\n    invalid_dir = os.path.join(directory_path, \"Invalid\")\n    if not os.path.isdir(invalid_dir):\n        os.mkdir(invalid_dir)\n\n    # Scan directory\n    for filename in os.listdir(directory_path):\n        # Ignore \"Invalid\" directory\n        if filename == \"Invalid\":\n            continue\n\n        # Increment total count\n        summary[\"total\"] += 1\n\n        # Check if filename contains invalid characters\n        if any(char in filename for char in INVALID_CHARACTERS):\n            # Move file to \"Invalid\" directory\n            shutil.move(os.path.join(directory_path, filename), invalid_dir)\n            # Increment moved count\n            summary[\"moved\"] += 1\n\n    return summary"}
{"task_id": "BigCodeBench/854", "solution": "from functools import reduce\nfrom itertools import permutations\nimport math\ndef task_func(numbers):\n    if not isinstance(numbers, list):\n        raise TypeError(\"Input should be a list of integers.\")\n    if not all(isinstance(i, int) for i in numbers):\n        raise TypeError(\"Input should be a list of integers.\")\n    if any(i < 0 for i in numbers):\n        raise ValueError(\"Input should not contain negative numbers.\")\n    \n    fac = []\n    perm = []\n    \n    if numbers:\n        perm = [i for i in permutations(numbers, len(numbers))]\n        fac = [sum(math.factorial(n) for n in p) for p in perm]\n    \n    return fac, perm", "raw_solution": "from functools import reduce\nfrom itertools import permutations\nimport math\n\ndef task_func(numbers):\n    if not isinstance(numbers, list):\n        raise TypeError(\"Input should be a list of integers.\")\n    if not all(isinstance(i, int) for i in numbers):\n        raise TypeError(\"Input should be a list of integers.\")\n    if any(i < 0 for i in numbers):\n        raise ValueError(\"Input should not contain negative numbers.\")\n    \n    fac = []\n    perm = []\n    \n    if numbers:\n        perm = [i for i in permutations(numbers, len(numbers))]\n        fac = [sum(math.factorial(n) for n in p) for p in perm]\n    \n    return fac, perm"}
{"task_id": "BigCodeBench/855", "solution": "import random\nimport string\nimport collections\nVALID_CHARACTERS = string.ascii_letters + string.digits\ndef task_func(n_strings, string_length):\n    # Generate n random strings of a specified length\n    random_strings = [''.join(random.choices(VALID_CHARACTERS, k=string_length)) for _ in range(n_strings)]\n\n    # Flatten the list of strings and count the frequency of each character\n    flattened_string = ''.join(random_strings)\n    char_counts = collections.Counter(flattened_string)\n\n    return dict(char_counts)\nn_strings = 100\nstring_length = 100", "raw_solution": "import random\nimport string\nimport collections\n\n# Constants\nVALID_CHARACTERS = string.ascii_letters + string.digits\n\ndef task_func(n_strings, string_length):\n    # Generate n random strings of a specified length\n    random_strings = [''.join(random.choices(VALID_CHARACTERS, k=string_length)) for _ in range(n_strings)]\n\n    # Flatten the list of strings and count the frequency of each character\n    flattened_string = ''.join(random_strings)\n    char_counts = collections.Counter(flattened_string)\n\n    return dict(char_counts)\n\n# Test the function\nn_strings = 100\nstring_length = 100"}
{"task_id": "BigCodeBench/856", "solution": "from functools import reduce\nfrom itertools import combinations\nimport numpy as np\ndef task_func(shape=(3, 3), low=1, high=10, seed=None):\n    if high <= low:\n        raise ValueError(\"high should be greater than low\")\n    if seed is not None:\n        np.random.seed(seed)\n    matrix = np.random.randint(low, high, shape)\n    pairs = list(combinations(matrix.flatten(), 2))\n    sum_of_products = sum(map(lambda x: x[0]*x[1], pairs))\n    return sum_of_products, matrix", "raw_solution": "from functools import reduce\nfrom itertools import combinations\nimport numpy as np\n\ndef task_func(shape=(3, 3), low=1, high=10, seed=None):\n    if high <= low:\n        raise ValueError(\"high should be greater than low\")\n    if seed is not None:\n        np.random.seed(seed)\n    matrix = np.random.randint(low, high, shape)\n    pairs = list(combinations(matrix.flatten(), 2))\n    sum_of_products = sum(map(lambda x: x[0]*x[1], pairs))\n    return sum_of_products, matrix\n\n# Testing the function"}
{"task_id": "BigCodeBench/857", "solution": "import warnings\nimport os\nimport glob\nimport shutil\nimport time\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    if not os.path.exists(SOURCE_DIR):\n        warnings.warn(f\"Source directory {SOURCE_DIR} does not exist.\")\n        return []\n\n    if not os.path.exists(DEST_DIR):\n        warnings.warn(f\"Destination directory {DEST_DIR} does not exist.\")\n        return []\n\n    transferred_files = []\n\n    for extension in EXTENSIONS:\n        files = glob.glob(os.path.join(SOURCE_DIR, f'*.{extension}'))\n\n        for file in files:\n            try:\n                shutil.move(file, DEST_DIR)\n                transferred_files.append(os.path.basename(file))\n            except Exception as e:\n                warnings.warn(f\"Could not transfer file {file} due to {str(e)}.\")\n\n    return transferred_files", "raw_solution": "import warnings\nimport os\nimport glob\nimport shutil\nimport time\n\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    if not os.path.exists(SOURCE_DIR):\n        warnings.warn(f\"Source directory {SOURCE_DIR} does not exist.\")\n        return []\n\n    if not os.path.exists(DEST_DIR):\n        warnings.warn(f\"Destination directory {DEST_DIR} does not exist.\")\n        return []\n\n    transferred_files = []\n\n    for extension in EXTENSIONS:\n        files = glob.glob(os.path.join(SOURCE_DIR, f'*.{extension}'))\n\n        for file in files:\n            try:\n                shutil.move(file, DEST_DIR)\n                transferred_files.append(os.path.basename(file))\n            except Exception as e:\n                warnings.warn(f\"Could not transfer file {file} due to {str(e)}.\")\n\n    return transferred_files"}
{"task_id": "BigCodeBench/858", "solution": "import string\nimport random\nfrom collections import Counter\ndef task_func(n, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    letters = [random.choice(string.ascii_lowercase) for _ in range(n)]\n    return Counter(letters)", "raw_solution": "import string\nimport random\nfrom collections import Counter\n\ndef task_func(n, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    letters = [random.choice(string.ascii_lowercase) for _ in range(n)]\n    return Counter(letters)\n\n# Test the function"}
{"task_id": "BigCodeBench/859", "solution": "import warnings\nimport sklearn.model_selection as model_selection\nimport sklearn.svm as svm\nimport sklearn.datasets as datasets\nimport sklearn.metrics as metrics\ndef task_func():\n    # Load iris dataset\n    iris = datasets.load_iris()\n    X = iris.data\n    y = iris.target\n\n    # Split the data into a training set and a test set\n    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n\n    # Create a SVM classifier\n    clf = svm.SVC(gamma='scale')\n\n    # Train the model using the training sets\n    clf.fit(X_train, y_train)\n\n    # Predict the response for test dataset\n    y_pred = clf.predict(X_test)\n\n    # Calculate accuracy\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n\n    # Set warning\n    warnings.filterwarnings(\"always\")\n    if accuracy < 0.9:\n        warning_msg = f\"Accuracy is less than 0.9: {accuracy}\"\n    else:\n        warning_msg = None\n\n    return accuracy, warning_msg", "raw_solution": "import warnings\nimport sklearn.model_selection as model_selection\nimport sklearn.svm as svm\nimport sklearn.datasets as datasets\nimport sklearn.metrics as metrics\n\ndef task_func():\n    # Load iris dataset\n    iris = datasets.load_iris()\n    X = iris.data\n    y = iris.target\n\n    # Split the data into a training set and a test set\n    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n\n    # Create a SVM classifier\n    clf = svm.SVC(gamma='scale')\n\n    # Train the model using the training sets\n    clf.fit(X_train, y_train)\n\n    # Predict the response for test dataset\n    y_pred = clf.predict(X_test)\n\n    # Calculate accuracy\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n\n    # Set warning\n    warnings.filterwarnings(\"always\")\n    if accuracy < 0.9:\n        warning_msg = f\"Accuracy is less than 0.9: {accuracy}\"\n    else:\n        warning_msg = None\n\n    return accuracy, warning_msg"}
{"task_id": "BigCodeBench/860", "solution": "import re\nimport random\nimport string\ndef task_func(n, pattern, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=n))\n    matches = re.findall(pattern, random_string)\n    return matches", "raw_solution": "import re\nimport random\nimport string\n\ndef task_func(n, pattern, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=n))\n    matches = re.findall(pattern, random_string)\n    return matches\n\n# Test the function"}
{"task_id": "BigCodeBench/861", "solution": "from collections import Counter\nfrom random import choice, seed\nPOSSIBLE_ITEMS = ['apple', 'banana', 'cherry', 'date', 'elderberry']\ndef task_func(list_of_lists):\n    baskets = []\n    for sublist in list_of_lists:\n        basket = Counter()\n        for _ in range(len(sublist)):\n            basket[choice(POSSIBLE_ITEMS)] += 1\n        baskets.append(basket)\n    return baskets\nlist_of_lists = [[], ['apple'], ['apple', 'banana'], ['apple', 'banana', 'cherry', 'date']]", "raw_solution": "from collections import Counter\nfrom random import choice, seed\n\n# Constants\nPOSSIBLE_ITEMS = ['apple', 'banana', 'cherry', 'date', 'elderberry']\n\ndef task_func(list_of_lists):\n    baskets = []\n    for sublist in list_of_lists:\n        basket = Counter()\n        for _ in range(len(sublist)):\n            basket[choice(POSSIBLE_ITEMS)] += 1\n        baskets.append(basket)\n    return baskets\n\n# Test the function\nlist_of_lists = [[], ['apple'], ['apple', 'banana'], ['apple', 'banana', 'cherry', 'date']]"}
{"task_id": "BigCodeBench/862", "solution": "import random\nimport string\nfrom collections import defaultdict\ndef task_func(n, seed=None):\n    random.seed(seed)\n    letters = list(string.ascii_lowercase)\n    random.shuffle(letters)\n    result = defaultdict(list)\n    for i in range(n):\n        letter = letters[i % 26]\n        result[letter].append(letter)\n    return result", "raw_solution": "import random\nimport string\nfrom collections import defaultdict\n\ndef task_func(n, seed=None):\n    random.seed(seed)\n    letters = list(string.ascii_lowercase)\n    random.shuffle(letters)\n    result = defaultdict(list)\n    for i in range(n):\n        letter = letters[i % 26]\n        result[letter].append(letter)\n    return result\n\n# Test the function"}
{"task_id": "BigCodeBench/863", "solution": "import numpy as np\nimport math\nPOSSIBLE_NUMBERS = np.arange(1, 11)\ndef task_func(list_of_lists):\n    sums = []\n    for lst in list_of_lists:\n        if len(lst) <= len(POSSIBLE_NUMBERS):\n            selected_numbers = POSSIBLE_NUMBERS[:len(lst)]\n            sum_of_squares = sum(num**2 for num in selected_numbers)\n            sums.append(sum_of_squares)\n        else:\n            print(\"Warning: Not enough numbers in POSSIBLE_NUMBERS for list\")\n    return sums\nlist_of_lists = [[1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]", "raw_solution": "import numpy as np\nimport math\n\n# Constants\nPOSSIBLE_NUMBERS = np.arange(1, 11)\n\ndef task_func(list_of_lists):\n    sums = []\n    for lst in list_of_lists:\n        if len(lst) <= len(POSSIBLE_NUMBERS):\n            selected_numbers = POSSIBLE_NUMBERS[:len(lst)]\n            sum_of_squares = sum(num**2 for num in selected_numbers)\n            sums.append(sum_of_squares)\n        else:\n            print(\"Warning: Not enough numbers in POSSIBLE_NUMBERS for list\")\n    return sums\n\n# Test the function\nlist_of_lists = [[1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]"}
{"task_id": "BigCodeBench/864", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(fruit_data):\n    if not fruit_data:\n        return pd.DataFrame()\n    df = pd.DataFrame(fruit_data, columns=['Fruit', 'Count'])\n    df = df.groupby('Fruit').agg({'Count': ['sum', 'mean']})\n    df.columns = ['Total Count', 'Average Count']\n    df.reset_index(inplace=True)\n    return df\nfruit = [('apple', 1), ('orange', 25), ('apple', 111)]", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(fruit_data):\n    if not fruit_data:\n        return pd.DataFrame()\n    df = pd.DataFrame(fruit_data, columns=['Fruit', 'Count'])\n    df = df.groupby('Fruit').agg({'Count': ['sum', 'mean']})\n    df.columns = ['Total Count', 'Average Count']\n    df.reset_index(inplace=True)\n    return df\n\nfruit = [('apple', 1), ('orange', 25), ('apple', 111)]\ndf = task_func(fruit)\ndf.sort_index(inplace=True)"}
{"task_id": "BigCodeBench/865", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data):\n    # Convert the input data to a pandas DataFrame\n    df = pd.DataFrame(data, columns=['Item', 'Count', 'Weight'])\n\n    # Normalize the counts using z-score normalization\n    df['Normalized Count'] = zscore(df['Count'])\n\n    # Normalize the weights using min-max scaling\n    scaler = MinMaxScaler()\n    df['Normalized Weight'] = scaler.fit_transform(df[['Weight']])\n\n    # Return the DataFrame with the normalized counts and weights\n    return df[['Item', 'Normalized Count', 'Normalized Weight']]\ndata = [('Item1', 10, 20), ('Item2', 20, 30), ('Item3', 30, 40)]", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data):\n    # Convert the input data to a pandas DataFrame\n    df = pd.DataFrame(data, columns=['Item', 'Count', 'Weight'])\n\n    # Normalize the counts using z-score normalization\n    df['Normalized Count'] = zscore(df['Count'])\n\n    # Normalize the weights using min-max scaling\n    scaler = MinMaxScaler()\n    df['Normalized Weight'] = scaler.fit_transform(df[['Weight']])\n\n    # Return the DataFrame with the normalized counts and weights\n    return df[['Item', 'Normalized Count', 'Normalized Weight']]\n\n# Test the function\ndata = [('Item1', 10, 20), ('Item2', 20, 30), ('Item3', 30, 40)]"}
{"task_id": "BigCodeBench/866", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\ndef task_func(data, n_clusters=2, random_state=0):\n    # Extract the 2D coordinates from the data\n    coordinates = [point[1:] for point in data]\n    \n    # Convert the coordinates to numpy array\n    coordinates = np.array(coordinates)\n    \n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(coordinates)\n    \n    # Return the cluster labels\n    return kmeans.labels_\ndata = [('T1', 1, 1), ('T2', 1, 1.1), ('T2', 1.1, 1), ('C1', 400, 400), ('C2', 401, 401), ('B1', 35, 35)]", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\n\ndef task_func(data, n_clusters=2, random_state=0):\n    # Extract the 2D coordinates from the data\n    coordinates = [point[1:] for point in data]\n    \n    # Convert the coordinates to numpy array\n    coordinates = np.array(coordinates)\n    \n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(coordinates)\n    \n    # Return the cluster labels\n    return kmeans.labels_\n\n# Test the function\ndata = [('T1', 1, 1), ('T2', 1, 1.1), ('T2', 1.1, 1), ('C1', 400, 400), ('C2', 401, 401), ('B1', 35, 35)]\nlabels = task_func(data, n_clusters=3, random_state=42)"}
{"task_id": "BigCodeBench/867", "solution": "import re\nimport string\ndef task_func(text1, text2):\n    # Define the punctuation to be removed\n    punctuation = string.punctuation\n\n    # Remove punctuation from the texts\n    cleaned_text1 = re.sub('[%s]' % re.escape(punctuation), '', text1)\n    cleaned_text2 = re.sub('[%s]' % re.escape(punctuation), '', text2)\n\n    # Return the cleaned texts as a tuple\n    return (cleaned_text1, cleaned_text2)", "raw_solution": "import re\nimport string\n\ndef task_func(text1, text2):\n    # Define the punctuation to be removed\n    punctuation = string.punctuation\n\n    # Remove punctuation from the texts\n    cleaned_text1 = re.sub('[%s]' % re.escape(punctuation), '', text1)\n    cleaned_text2 = re.sub('[%s]' % re.escape(punctuation), '', text2)\n\n    # Return the cleaned texts as a tuple\n    return (cleaned_text1, cleaned_text2)\n\n# Test the function\ncleaned_text1, cleaned_text2 = task_func(\"test (with parenthesis []!!)\", \"And, other; stuff ^_`\")\n\n# Print the cleaned texts"}
{"task_id": "BigCodeBench/868", "solution": "from itertools import cycle\nfrom random import choice, seed\ndef task_func(n_colors, colors=['Red', 'Green', 'Blue', 'Yellow', 'Purple'], rng_seed=None):\n    if n_colors <= 0:\n        return []\n\n    if rng_seed is not None:\n        seed(rng_seed)\n\n    color_pattern = []\n    color_cycle = cycle(colors)\n\n    for i in range(n_colors):\n        if i % 2 == 0:\n            color_pattern.append(next(color_cycle))\n        else:\n            color_pattern.append(choice(colors))\n\n    return color_pattern\ncolors = ['Brown', 'Green', 'Black']", "raw_solution": "from itertools import cycle\nfrom random import choice, seed\n\ndef task_func(n_colors, colors=['Red', 'Green', 'Blue', 'Yellow', 'Purple'], rng_seed=None):\n    if n_colors <= 0:\n        return []\n\n    if rng_seed is not None:\n        seed(rng_seed)\n\n    color_pattern = []\n    color_cycle = cycle(colors)\n\n    for i in range(n_colors):\n        if i % 2 == 0:\n            color_pattern.append(next(color_cycle))\n        else:\n            color_pattern.append(choice(colors))\n\n    return color_pattern\n\n# Test the function\ncolors = ['Brown', 'Green', 'Black']\ncolor_pattern = task_func(12, colors=colors, rng_seed=42)"}
{"task_id": "BigCodeBench/869", "solution": "import pandas as pd\nfrom itertools import cycle\nfrom random import randint, seed\ndef task_func(\n    n_grades,\n    students=['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    grade_range=range(1, 11),\n    rng_seed=None\n):\n    if not students:\n        raise ValueError(\"List of students is empty\")\n    if rng_seed is not None:\n        seed(rng_seed)\n    student_cycle = cycle(students)\n    grade_report = []\n    for _ in range(n_grades):\n        student = next(student_cycle)\n        grade = randint(min(grade_range), max(grade_range))\n        grade_report.append({'Student': student, 'Grade': grade})\n    return pd.DataFrame(grade_report)", "raw_solution": "import pandas as pd\nfrom itertools import cycle\nfrom random import randint, seed\n\ndef task_func(\n    n_grades,\n    students=['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    grade_range=range(1, 11),\n    rng_seed=None\n):\n    if not students:\n        raise ValueError(\"List of students is empty\")\n    if rng_seed is not None:\n        seed(rng_seed)\n    student_cycle = cycle(students)\n    grade_report = []\n    for _ in range(n_grades):\n        student = next(student_cycle)\n        grade = randint(min(grade_range), max(grade_range))\n        grade_report.append({'Student': student, 'Grade': grade})\n    return pd.DataFrame(grade_report)\n\n# Test the function\ngrade_report = task_func(5, rng_seed=12)"}
{"task_id": "BigCodeBench/870", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    # Initialize an empty list to store the mean values\n    mean_values = []\n    \n    # Iterate over the tuples in the list\n    for i in range(len(data_list[0])):\n        # Initialize a list to store the numerical values at the current position\n        num_values = []\n        \n        # Iterate over the tuples in the list\n        for j in range(len(data_list)):\n            # Check if the current position in the tuple is a number\n            if isinstance(data_list[j][i], (int, float)):\n                # If it is, add it to the list of numerical values\n                num_values.append(data_list[j][i])\n        \n        # Calculate the mean of the numerical values at the current position\n        mean = np.mean(num_values) if num_values else np.nan\n        \n        # Add the mean to the list of mean values\n        mean_values.append(mean)\n    \n    # Create a pandas DataFrame with the mean values\n    df = pd.DataFrame(mean_values, columns=['Mean Value'], index=['Position ' + str(i) for i in range(len(mean_values))])\n    \n    return df\ndata = [('a', '1', 2.1), ('b', 21, 'c'), (12, 3, 4.3), (['d'], 4, 5.4), ('e', 5, 6.5)]", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    # Initialize an empty list to store the mean values\n    mean_values = []\n    \n    # Iterate over the tuples in the list\n    for i in range(len(data_list[0])):\n        # Initialize a list to store the numerical values at the current position\n        num_values = []\n        \n        # Iterate over the tuples in the list\n        for j in range(len(data_list)):\n            # Check if the current position in the tuple is a number\n            if isinstance(data_list[j][i], (int, float)):\n                # If it is, add it to the list of numerical values\n                num_values.append(data_list[j][i])\n        \n        # Calculate the mean of the numerical values at the current position\n        mean = np.mean(num_values) if num_values else np.nan\n        \n        # Add the mean to the list of mean values\n        mean_values.append(mean)\n    \n    # Create a pandas DataFrame with the mean values\n    df = pd.DataFrame(mean_values, columns=['Mean Value'], index=['Position ' + str(i) for i in range(len(mean_values))])\n    \n    return df\n\ndata = [('a', '1', 2.1), ('b', 21, 'c'), (12, 3, 4.3), (['d'], 4, 5.4), ('e', 5, 6.5)]\ndf = task_func(data)"}
{"task_id": "BigCodeBench/871", "solution": "import numpy as np\nimport itertools\ndef task_func(data_list, file_name):\n    means = []\n    with open(file_name, 'w') as f:\n        if data_list:\n            for i, data in enumerate(data_list, start=1):\n                numeric_data = [x for x in data[1:] if isinstance(x, (int, float))]\n                if numeric_data:\n                    mean = np.mean(numeric_data)\n                    means.append(mean)\n                    f.write(f\"Position {i}: {mean}\\n\")\n                else:\n                    means.append(np.nan)\n                    f.write(f\"Position {i}: NaN\\n\")\n        else:\n            return []\n    return means", "raw_solution": "import numpy as np\nimport itertools\n\ndef task_func(data_list, file_name):\n    means = []\n    with open(file_name, 'w') as f:\n        if data_list:\n            for i, data in enumerate(data_list, start=1):\n                numeric_data = [x for x in data[1:] if isinstance(x, (int, float))]\n                if numeric_data:\n                    mean = np.mean(numeric_data)\n                    means.append(mean)\n                    f.write(f\"Position {i}: {mean}\\n\")\n                else:\n                    means.append(np.nan)\n                    f.write(f\"Position {i}: NaN\\n\")\n        else:\n            return []\n    return means"}
{"task_id": "BigCodeBench/872", "solution": "import numpy as np\nimport itertools\ndef task_func(data_list):\n    if not data_list:\n        return []\n\n    # Unzip the list of tuples\n    unzipped = list(itertools.zip_longest(*data_list, fillvalue=0))\n\n    # Convert all elements to float, if possible, else keep as is\n    unzipped = [[float(j) if j.replace('.','',1).isdigit() or j.isdigit() else j for j in i] for i in unzipped]\n\n    # Calculate mean for each position\n    means = [np.nan if all(isinstance(p, str) for p in pos) else np.mean(v for v in pos if isinstance(v, (int, float))) for pos in unzipped]\n\n    return means", "raw_solution": "import numpy as np\nimport itertools\n\ndef task_func(data_list):\n    if not data_list:\n        return []\n\n    # Unzip the list of tuples\n    unzipped = list(itertools.zip_longest(*data_list, fillvalue=0))\n\n    # Convert all elements to float, if possible, else keep as is\n    unzipped = [[float(j) if j.replace('.','',1).isdigit() or j.isdigit() else j for j in i] for i in unzipped]\n\n    # Calculate mean for each position\n    means = [np.nan if all(isinstance(p, str) for p in pos) else np.mean(v for v in pos if isinstance(v, (int, float))) for pos in unzipped]\n\n    return means"}
{"task_id": "BigCodeBench/873", "solution": "import csv\nimport os\ndef task_func(data, file_path, headers):\n    if file_path is None:\n        raise ValueError(\"file_path cannot be None\")\n\n    with open(file_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(headers)\n        for row in data:\n            while len(row) < len(headers):\n                row += (None,)\n            writer.writerow(row)\n\n    return os.path.abspath(file_path)", "raw_solution": "import csv\nimport os\n\ndef task_func(data, file_path, headers):\n    if file_path is None:\n        raise ValueError(\"file_path cannot be None\")\n\n    with open(file_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(headers)\n        for row in data:\n            while len(row) < len(headers):\n                row += (None,)\n            writer.writerow(row)\n\n    return os.path.abspath(file_path)\n\n# Test the function"}
{"task_id": "BigCodeBench/874", "solution": "from itertools import tee, islice\nfrom math import sqrt\ndef pairwise(iterable):\n    a, b = tee(iterable, 2)\n    return zip(a, islice(b, 1, None))\ndef task_func(points):\n    if len(points) < 2:\n        return []\n    distances = []\n    for point1, point2 in pairwise(points):\n        x1, y1 = point1 if len(point1) == 2 else (point1[0], point1[0])\n        x2, y2 = point2 if len(point2) == 2 else (point2[0], point2[0])\n        distance = sqrt((x2 - x1)**2 + (y2 - y1)**2)\n        distances.append(distance)\n    return distances", "raw_solution": "from itertools import tee, islice\nfrom math import sqrt\n\ndef pairwise(iterable):\n    a, b = tee(iterable, 2)\n    return zip(a, islice(b, 1, None))\n\ndef task_func(points):\n    if len(points) < 2:\n        return []\n    distances = []\n    for point1, point2 in pairwise(points):\n        x1, y1 = point1 if len(point1) == 2 else (point1[0], point1[0])\n        x2, y2 = point2 if len(point2) == 2 else (point2[0], point2[0])\n        distance = sqrt((x2 - x1)**2 + (y2 - y1)**2)\n        distances.append(distance)\n    return distances\n\n# Test the function"}
{"task_id": "BigCodeBench/875", "solution": "import pandas as pd\nimport random\ndef task_func(data, columns=['Name', 'Age', 'Occupation'], fill_missing=False, num_range=(0, 100), seed=None):\n    if seed is not None:\n        random.seed(seed)\n    data_filled = []\n    max_len = max(len(row) for row in data)\n    for row in data:\n        row_filled = list(row)\n        while len(row_filled) < max_len:\n            row_filled.append(None)\n        data_filled.append(tuple(row_filled))\n    if fill_missing:\n        data_filled = [tuple(row[:len(columns)]) + tuple(random.randint(num_range[0], num_range[1]) for _ in range(len(row) - len(columns))) for row in data_filled]\n    df = pd.DataFrame(data_filled, columns=columns)\n    return df\ndata = [('Mango', 20), ('Apple', ), ('Banana', )]", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(data, columns=['Name', 'Age', 'Occupation'], fill_missing=False, num_range=(0, 100), seed=None):\n    if seed is not None:\n        random.seed(seed)\n    data_filled = []\n    max_len = max(len(row) for row in data)\n    for row in data:\n        row_filled = list(row)\n        while len(row_filled) < max_len:\n            row_filled.append(None)\n        data_filled.append(tuple(row_filled))\n    if fill_missing:\n        data_filled = [tuple(row[:len(columns)]) + tuple(random.randint(num_range[0], num_range[1]) for _ in range(len(row) - len(columns))) for row in data_filled]\n    df = pd.DataFrame(data_filled, columns=columns)\n    return df\n\ndata = [('Mango', 20), ('Apple', ), ('Banana', )]\ndf = task_func(data, columns=['Fruit', 'Quantity'], fill_missing=False, seed=42)"}
{"task_id": "BigCodeBench/876", "solution": "import collections\nimport operator\nimport os\nimport shutil\ndef task_func(data_dict, source_directory, backup_directory):\n    # Task 1: Update the dictionary\n    data_dict['a'] = 1\n\n    # Task 2: Sort the dictionary by frequency of values\n    value_frequencies = collections.Counter(data_dict.values()).most_common()\n    value_frequencies = [(k, v) for k, v in value_frequencies]\n\n    # Task 3: Backup files from source directory to backup directory\n    backup_status = False\n    if os.path.exists(source_directory) and not os.path.exists(backup_directory):\n        try:\n            shutil.copytree(source_directory, backup_directory)\n            backup_status = True\n        except Exception as e:\n            print(f\"Backup failed: {str(e)}\")\n\n    return data_dict, value_frequencies, backup_status\ndata_dict = {'avc': '1', 'hello': 'world', 'test': 'world', 'cat': 'meow'}", "raw_solution": "import collections\nimport operator\nimport os\nimport shutil\n\ndef task_func(data_dict, source_directory, backup_directory):\n    # Task 1: Update the dictionary\n    data_dict['a'] = 1\n\n    # Task 2: Sort the dictionary by frequency of values\n    value_frequencies = collections.Counter(data_dict.values()).most_common()\n    value_frequencies = [(k, v) for k, v in value_frequencies]\n\n    # Task 3: Backup files from source directory to backup directory\n    backup_status = False\n    if os.path.exists(source_directory) and not os.path.exists(backup_directory):\n        try:\n            shutil.copytree(source_directory, backup_directory)\n            backup_status = True\n        except Exception as e:\n            print(f\"Backup failed: {str(e)}\")\n\n    return data_dict, value_frequencies, backup_status\n\n# Test the function\ndata_dict = {'avc': '1', 'hello': 'world', 'test': 'world', 'cat': 'meow'}\nupdated_dict, value_frequencies, backup_status = task_func(data_dict, 'to_backup', 'backup')\n"}
{"task_id": "BigCodeBench/877", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\ndef task_func(data, n_components=2):\n    # Check if data is a DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data is not a DataFrame.\")\n    \n    # Check if data is empty\n    if data.empty:\n        raise ValueError(\"Input data is empty.\")\n    \n    # Check if data contains non-numeric data\n    if not all(data.dtypes != object):\n        raise ValueError(\"Input data contains non-numeric data.\")\n    \n    # Check if n_components is greater than the number of columns in the data\n    if n_components > data.shape[1]:\n        raise ValueError(\"n_components is greater than the number of columns in the data.\")\n    \n    # Scale the data\n    scaler = StandardScaler()\n    data_scaled = scaler.fit_transform(data)\n    \n    # Apply PCA\n    pca = PCA(n_components=n_components)\n    pca_data = pca.fit_transform(data_scaled)\n    \n    # Return the transformed data as a DataFrame\n    return pd.DataFrame(pca_data)", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    # Check if data is a DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data is not a DataFrame.\")\n    \n    # Check if data is empty\n    if data.empty:\n        raise ValueError(\"Input data is empty.\")\n    \n    # Check if data contains non-numeric data\n    if not all(data.dtypes != object):\n        raise ValueError(\"Input data contains non-numeric data.\")\n    \n    # Check if n_components is greater than the number of columns in the data\n    if n_components > data.shape[1]:\n        raise ValueError(\"n_components is greater than the number of columns in the data.\")\n    \n    # Scale the data\n    scaler = StandardScaler()\n    data_scaled = scaler.fit_transform(data)\n    \n    # Apply PCA\n    pca = PCA(n_components=n_components)\n    pca_data = pca.fit_transform(data_scaled)\n    \n    # Return the transformed data as a DataFrame\n    return pd.DataFrame(pca_data)"}
{"task_id": "BigCodeBench/878", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\ndef task_func(data, target, test_size=0.2, random_state=None):\n    # Convert the input data into a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Check if the DataFrame is empty or if the target column is not in the DataFrame\n    if df.empty or target not in df.columns:\n        raise ValueError(\"The input DataFrame is empty or the target column name is not in the DataFrame.\")\n\n    # Split the DataFrame into a train and test set\n    X = df.drop(target, axis=1)\n    y = df[target]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    # Train a RandomForestRegressor on the train set\n    model = RandomForestRegressor(random_state=random_state)\n    model.fit(X_train, y_train)\n\n    # Make predictions on the test set\n    y_pred = model.predict(X_test)\n\n    # Calculate the mean squared error of the predictions\n    mse = mean_squared_error(y_test, y_pred)\n\n    return mse, model, df", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\ndef task_func(data, target, test_size=0.2, random_state=None):\n    # Convert the input data into a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Check if the DataFrame is empty or if the target column is not in the DataFrame\n    if df.empty or target not in df.columns:\n        raise ValueError(\"The input DataFrame is empty or the target column name is not in the DataFrame.\")\n\n    # Split the DataFrame into a train and test set\n    X = df.drop(target, axis=1)\n    y = df[target]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    # Train a RandomForestRegressor on the train set\n    model = RandomForestRegressor(random_state=random_state)\n    model.fit(X_train, y_train)\n\n    # Make predictions on the test set\n    y_pred = model.predict(X_test)\n\n    # Calculate the mean squared error of the predictions\n    mse = mean_squared_error(y_test, y_pred)\n\n    return mse, model, df"}
{"task_id": "BigCodeBench/879", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\ndef task_func(data, col1, col2):\n    # Check if data is empty\n    if data.empty:\n        raise ValueError(\"'data' is empty\")\n\n    # Check if col1 and col2 are in data\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError(\"One or both of the columns are not in 'data'\")\n\n    # Check if both columns have multiple categories\n    if data[col1].nunique() == 1 or data[col2].nunique() == 1:\n        raise ValueError(\"One or both of the columns do not have multiple categories\")\n\n    # Check if all categories have at least 5 observations\n    if data[col1].value_counts().min() < 5 or data[col2].value_counts().min() < 5:\n        raise ValueError(\"Some categories have less than 5 observations\")\n\n    # Check if both columns are categorical\n    if not pd.api.types.is_categorical_dtype(data[col1]) or not pd.api.types.is_categorical_dtype(data[col2]):\n        raise TypeError(\"One or both of the columns contain non-categorical data\")\n\n    # Construct contingency table\n    contingency_table = pd.crosstab(data[col1], data[col2])\n\n    # Perform chi-square test of independence\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n\n    return p", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\n\ndef task_func(data, col1, col2):\n    # Check if data is empty\n    if data.empty:\n        raise ValueError(\"'data' is empty\")\n\n    # Check if col1 and col2 are in data\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError(\"One or both of the columns are not in 'data'\")\n\n    # Check if both columns have multiple categories\n    if data[col1].nunique() == 1 or data[col2].nunique() == 1:\n        raise ValueError(\"One or both of the columns do not have multiple categories\")\n\n    # Check if all categories have at least 5 observations\n    if data[col1].value_counts().min() < 5 or data[col2].value_counts().min() < 5:\n        raise ValueError(\"Some categories have less than 5 observations\")\n\n    # Check if both columns are categorical\n    if not pd.api.types.is_categorical_dtype(data[col1]) or not pd.api.types.is_categorical_dtype(data[col2]):\n        raise TypeError(\"One or both of the columns contain non-categorical data\")\n\n    # Construct contingency table\n    contingency_table = pd.crosstab(data[col1], data[col2])\n\n    # Perform chi-square test of independence\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n\n    return p"}
{"task_id": "BigCodeBench/880", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport numpy as np\ndef task_func(data, n_clusters=3, seed=None):\n    if not all(data.dtypes[data.dtypes!='object'].values):\n        raise ValueError(\"DataFrame contains non numeric entries.\")\n\n    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=seed)\n    labels = kmeans.fit_predict(data)\n\n    return labels, kmeans\ndata = pd.DataFrame({\n    'a': [1, 20, 2, 22, 100],\n    'b': [1, 20, 2, 22, 100]\n})", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport numpy as np\n\ndef task_func(data, n_clusters=3, seed=None):\n    if not all(data.dtypes[data.dtypes!='object'].values):\n        raise ValueError(\"DataFrame contains non numeric entries.\")\n\n    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=seed)\n    labels = kmeans.fit_predict(data)\n\n    return labels, kmeans\n\n# Test the function\ndata = pd.DataFrame({\n    'a': [1, 20, 2, 22, 100],\n    'b': [1, 20, 2, 22, 100]\n})\n\nlabels, model = task_func(data, seed=213)"}
{"task_id": "BigCodeBench/881", "solution": "import pandas as pd\nimport re\nimport random\ndef task_func(csv_file, column_name='data', pattern='\\d+[xX]', sample_size=None, seed=42):\n    # Read the CSV file\n    df = pd.read_csv(csv_file)\n\n    # Check if the column exists\n    if column_name not in df.columns:\n        raise ValueError(f\"Column {column_name} not found in the CSV file.\")\n\n    # Apply the regex pattern to the column\n    df['match'] = df[column_name].apply(lambda x: bool(re.search(pattern, str(x))))\n\n    # If sample_size is not None, generate a random sample\n    if sample_size is not None:\n        # Set the seed for reproducibility\n        random.seed(seed)\n\n        # Get the indices of the rows where the pattern is found\n        indices = df[df['match'] == True].index.tolist()\n\n        # If there are not enough matches, raise an error\n        if len(indices) < sample_size:\n            raise ValueError(f\"Not enough matches found. Only {len(indices)} matches found.\")\n\n        # Generate a random sample of indices\n        sample_indices = random.sample(indices, sample_size)\n\n        # Return the rows with the sampled indices\n        return df.loc[sample_indices]\n\n    # If sample_size is None, return all rows where the pattern is found\n    else:\n        return df[df['match'] == True]", "raw_solution": "import pandas as pd\nimport re\nimport random\n\ndef task_func(csv_file, column_name='data', pattern='\\d+[xX]', sample_size=None, seed=42):\n    # Read the CSV file\n    df = pd.read_csv(csv_file)\n\n    # Check if the column exists\n    if column_name not in df.columns:\n        raise ValueError(f\"Column {column_name} not found in the CSV file.\")\n\n    # Apply the regex pattern to the column\n    df['match'] = df[column_name].apply(lambda x: bool(re.search(pattern, str(x))))\n\n    # If sample_size is not None, generate a random sample\n    if sample_size is not None:\n        # Set the seed for reproducibility\n        random.seed(seed)\n\n        # Get the indices of the rows where the pattern is found\n        indices = df[df['match'] == True].index.tolist()\n\n        # If there are not enough matches, raise an error\n        if len(indices) < sample_size:\n            raise ValueError(f\"Not enough matches found. Only {len(indices)} matches found.\")\n\n        # Generate a random sample of indices\n        sample_indices = random.sample(indices, sample_size)\n\n        # Return the rows with the sampled indices\n        return df.loc[sample_indices]\n\n    # If sample_size is None, return all rows where the pattern is found\n    else:\n        return df[df['match'] == True]"}
{"task_id": "BigCodeBench/882", "solution": "import sqlite3\nimport pandas as pd\nimport os\nimport re\ndef task_func(db_file, table_name, column_name, pattern='\\d+[xX]'):\n    # Check if the database file exists\n    if not os.path.isfile(db_file):\n        raise ValueError(\"The specified database file does not exist.\")\n\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_file)\n\n    # Query the database for all entries from the specified table\n    query = f\"SELECT * FROM {table_name}\"\n    df = pd.read_sql_query(query, conn)\n\n    # Find all matches with the regex pattern in the specified column\n    df_matches = df[df[column_name].str.contains(pattern, regex=True)]\n\n    # Close the database connection\n    conn.close()\n\n    return df_matches", "raw_solution": "import sqlite3\nimport pandas as pd\nimport os\nimport re\n\ndef task_func(db_file, table_name, column_name, pattern='\\d+[xX]'):\n    # Check if the database file exists\n    if not os.path.isfile(db_file):\n        raise ValueError(\"The specified database file does not exist.\")\n\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_file)\n\n    # Query the database for all entries from the specified table\n    query = f\"SELECT * FROM {table_name}\"\n    df = pd.read_sql_query(query, conn)\n\n    # Find all matches with the regex pattern in the specified column\n    df_matches = df[df[column_name].str.contains(pattern, regex=True)]\n\n    # Close the database connection\n    conn.close()\n\n    return df_matches"}
{"task_id": "BigCodeBench/883", "solution": "import pandas as pd\nfrom statsmodels.tsa.stattools import adfuller\ndef task_func(df: pd.DataFrame, column_a: str, column_b: str, column_c: str) -> bool:\n    # Filter rows where column_b > 50 and column_c == 900\n    filtered_df = df[(df[column_b] > 50) & (df[column_c] == 900)]\n\n    # Check if column_a is empty or its values are constant\n    if filtered_df[column_a].empty or (filtered_df[column_a].nunique() == 1):\n        return True\n\n    # Perform Augmented Dickey-Fuller test\n    result = adfuller(filtered_df[column_a])\n\n    # Check if p-value is less than 0.05\n    if result[1] < 0.05:\n        return True\n\n    return False", "raw_solution": "import pandas as pd\nfrom statsmodels.tsa.stattools import adfuller\n\ndef task_func(df: pd.DataFrame, column_a: str, column_b: str, column_c: str) -> bool:\n    # Filter rows where column_b > 50 and column_c == 900\n    filtered_df = df[(df[column_b] > 50) & (df[column_c] == 900)]\n\n    # Check if column_a is empty or its values are constant\n    if filtered_df[column_a].empty or (filtered_df[column_a].nunique() == 1):\n        return True\n\n    # Perform Augmented Dickey-Fuller test\n    result = adfuller(filtered_df[column_a])\n\n    # Check if p-value is less than 0.05\n    if result[1] < 0.05:\n        return True\n\n    return False"}
{"task_id": "BigCodeBench/884", "solution": "import pandas as pd\nfrom scipy.stats import chi2_contingency\ndef task_func(df, columns=['A', 'B', 'C'], larger=50, equal=900):\n    # Check if the number of specified columns is 3\n    if len(columns) != 3:\n        raise ValueError(\"The number of specified columns must be 3.\")\n    \n    # Check if the specified columns are contained in df\n    for col in columns:\n        if col not in df.columns:\n            raise ValueError(f\"The column {col} is not contained in df.\")\n    \n    # Filter rows based on the criteria\n    filtered_df = df[(df[columns[1]] > larger) & (df[columns[2]] == equal)]\n    \n    # Check if there's insufficient data for the test\n    if len(filtered_df) < 30:\n        raise ValueError(\"Insufficient data for the test. At least 30 rows should meet the criteria.\")\n    \n    # Compute a contingency table\n    contingency_table = pd.crosstab(filtered_df[columns[0]], filtered_df[columns[1]])\n    \n    # Perform a chi-square independence test\n    _, p_value, _, _ = chi2_contingency(contingency_table)\n    \n    return p_value", "raw_solution": "import pandas as pd\nfrom scipy.stats import chi2_contingency\n\ndef task_func(df, columns=['A', 'B', 'C'], larger=50, equal=900):\n    # Check if the number of specified columns is 3\n    if len(columns) != 3:\n        raise ValueError(\"The number of specified columns must be 3.\")\n    \n    # Check if the specified columns are contained in df\n    for col in columns:\n        if col not in df.columns:\n            raise ValueError(f\"The column {col} is not contained in df.\")\n    \n    # Filter rows based on the criteria\n    filtered_df = df[(df[columns[1]] > larger) & (df[columns[2]] == equal)]\n    \n    # Check if there's insufficient data for the test\n    if len(filtered_df) < 30:\n        raise ValueError(\"Insufficient data for the test. At least 30 rows should meet the criteria.\")\n    \n    # Compute a contingency table\n    contingency_table = pd.crosstab(filtered_df[columns[0]], filtered_df[columns[1]])\n    \n    # Perform a chi-square independence test\n    _, p_value, _, _ = chi2_contingency(contingency_table)\n    \n    return p_value"}
{"task_id": "BigCodeBench/885", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, col_a='A', col_b='B', col_c='C', seed=None):\n    # Check if df is empty\n    if df.empty:\n        return None, None\n\n    # Check if columns exist in df\n    if col_a not in df.columns or col_b not in df.columns or col_c not in df.columns:\n        return None, None\n\n    # Check if df contains non-numeric data\n    if pd.api.types.is_numeric_dtype(df[col_a]) == False or pd.api.types.is_numeric_dtype(df[col_b]) == False or pd.api.types.is_numeric_dtype(df[col_c]) == False:\n        return None, None\n\n    # Filter rows based on conditions in columns B and C\n    df = df[df[col_b] > 50]\n    df = df[df[col_c] == 900]\n\n    # Check if filtered df is empty\n    if df.empty:\n        return None, None\n\n    # Reshape X and Y data\n    X = df[col_a].values.reshape(-1, 1)\n    Y = df[col_b].values.reshape(-1, 1)\n\n    # Split data into train and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n\n    # Train a Linear Regression model\n    model = LinearRegression()\n    model.fit(X_train, Y_train)\n\n    # Generate predictions\n    predictions = model.predict(X_test)\n\n    return predictions, model", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, col_a='A', col_b='B', col_c='C', seed=None):\n    # Check if df is empty\n    if df.empty:\n        return None, None\n\n    # Check if columns exist in df\n    if col_a not in df.columns or col_b not in df.columns or col_c not in df.columns:\n        return None, None\n\n    # Check if df contains non-numeric data\n    if pd.api.types.is_numeric_dtype(df[col_a]) == False or pd.api.types.is_numeric_dtype(df[col_b]) == False or pd.api.types.is_numeric_dtype(df[col_c]) == False:\n        return None, None\n\n    # Filter rows based on conditions in columns B and C\n    df = df[df[col_b] > 50]\n    df = df[df[col_c] == 900]\n\n    # Check if filtered df is empty\n    if df.empty:\n        return None, None\n\n    # Reshape X and Y data\n    X = df[col_a].values.reshape(-1, 1)\n    Y = df[col_b].values.reshape(-1, 1)\n\n    # Split data into train and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n\n    # Train a Linear Regression model\n    model = LinearRegression()\n    model.fit(X_train, Y_train)\n\n    # Generate predictions\n    predictions = model.predict(X_test)\n\n    return predictions, model"}
{"task_id": "BigCodeBench/886", "solution": "import pandas as pd\nfrom collections import Counter\ndef task_func(data):\n    # Check if the dictionary has the required keys\n    required_keys = ['Name', 'Age', 'Score']\n    for student in data:\n        if not all(key in student for key in required_keys):\n            raise ValueError(\"The dictionary does not have the required keys.\")\n\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame(data)\n\n    # Sort the DataFrame by 'Name' and 'Age' in ascending order\n    df = df.sort_values(by=['Name', 'Age'])\n\n    # Calculate the average score per student as a Series\n    avg_scores = df.groupby('Name')['Score'].mean()\n\n    # Calculate the most common age\n    counter = Counter(df['Age'])\n    most_common_age = counter.most_common(1)\n    most_common_age = most_common_age[0][0] if most_common_age else None\n\n    return df, avg_scores, most_common_age", "raw_solution": "import pandas as pd\nfrom collections import Counter\n\ndef task_func(data):\n    # Check if the dictionary has the required keys\n    required_keys = ['Name', 'Age', 'Score']\n    for student in data:\n        if not all(key in student for key in required_keys):\n            raise ValueError(\"The dictionary does not have the required keys.\")\n\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame(data)\n\n    # Sort the DataFrame by 'Name' and 'Age' in ascending order\n    df = df.sort_values(by=['Name', 'Age'])\n\n    # Calculate the average score per student as a Series\n    avg_scores = df.groupby('Name')['Score'].mean()\n\n    # Calculate the most common age\n    counter = Counter(df['Age'])\n    most_common_age = counter.most_common(1)\n    most_common_age = most_common_age[0][0] if most_common_age else None\n\n    return df, avg_scores, most_common_age"}
{"task_id": "BigCodeBench/887", "solution": "import pandas as pd\nimport numpy as np\nimport itertools\ndef task_func(T1, row_num=50, seed=None):\n    # Convert elements in T1 to integers\n    T1 = [(int(i), int(j)) for i, j in T1]\n\n    # Calculate the sum of the integers in T1\n    col_num = sum(sum(pair) for pair in T1)\n\n    # Set the seed for the random number generator\n    if seed is not None:\n        np.random.seed(seed)\n\n    # Generate a DataFrame with random numbers\n    df = pd.DataFrame(np.random.randint(0, 100, size=(row_num, col_num)), columns=pd.RangeIndex(start=1, stop=col_num+1))\n\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport itertools\n\ndef task_func(T1, row_num=50, seed=None):\n    # Convert elements in T1 to integers\n    T1 = [(int(i), int(j)) for i, j in T1]\n\n    # Calculate the sum of the integers in T1\n    col_num = sum(sum(pair) for pair in T1)\n\n    # Set the seed for the random number generator\n    if seed is not None:\n        np.random.seed(seed)\n\n    # Generate a DataFrame with random numbers\n    df = pd.DataFrame(np.random.randint(0, 100, size=(row_num, col_num)), columns=pd.RangeIndex(start=1, stop=col_num+1))\n\n    return df\n\n# Test the function\ndf = task_func(('1', ('1', '3')), row_num=2, seed=32)"}
{"task_id": "BigCodeBench/888", "solution": "import pandas as pd\nimport os\ndef task_func(data_dir: str, csv_files: list) -> pd.DataFrame:\n    if not csv_files:\n        return pd.DataFrame()\n\n    full_paths = [os.path.join(data_dir, file) for file in csv_files if file.endswith('.csv')]\n    dfs = [pd.read_csv(file) for file in full_paths]\n    merged_df = pd.concat(dfs, ignore_index=True)\n\n    return merged_df", "raw_solution": "import pandas as pd\nimport os\n\ndef task_func(data_dir: str, csv_files: list) -> pd.DataFrame:\n    if not csv_files:\n        return pd.DataFrame()\n\n    full_paths = [os.path.join(data_dir, file) for file in csv_files if file.endswith('.csv')]\n    dfs = [pd.read_csv(file) for file in full_paths]\n    merged_df = pd.concat(dfs, ignore_index=True)\n\n    return merged_df"}
{"task_id": "BigCodeBench/889", "solution": "import os\nimport pandas as pd\nimport numpy as np\ndef task_func(data_dir: str, csv_file: str) -> pd.DataFrame:\n    # Check if the file exists\n    if not os.path.isfile(os.path.join(data_dir, csv_file)):\n        raise FileNotFoundError(f\"The file {csv_file} does not exist in the directory {data_dir}\")\n\n    # Load the CSV file into a pandas DataFrame\n    df = pd.read_csv(os.path.join(data_dir, csv_file))\n\n    # Replace NaN values in numeric columns with the mean of the corresponding column\n    for col in df.select_dtypes(include=[np.number]):\n        df[col].fillna(df[col].mean(), inplace=True)\n\n    return df", "raw_solution": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(data_dir: str, csv_file: str) -> pd.DataFrame:\n    # Check if the file exists\n    if not os.path.isfile(os.path.join(data_dir, csv_file)):\n        raise FileNotFoundError(f\"The file {csv_file} does not exist in the directory {data_dir}\")\n\n    # Load the CSV file into a pandas DataFrame\n    df = pd.read_csv(os.path.join(data_dir, csv_file))\n\n    # Replace NaN values in numeric columns with the mean of the corresponding column\n    for col in df.select_dtypes(include=[np.number]):\n        df[col].fillna(df[col].mean(), inplace=True)\n\n    return df"}
{"task_id": "BigCodeBench/890", "solution": "import os\nimport random\nimport pandas as pd\ndef task_func(data_dir,\n              csv_files=['file1.csv', 'file2.csv', 'file3.csv'],\n              seed=None,\n              num_records=10):\n    if seed is not None:\n        random.seed(seed)\n\n    # Randomly select a csv_file\n    csv_file = random.choice(csv_files)\n    csv_file_path = os.path.join(data_dir, csv_file)\n\n    # Check if the csv_file exists and is not empty\n    if os.path.isfile(csv_file_path) and os.path.getsize(csv_file_path) > 0:\n        # Read the csv_file\n        df = pd.read_csv(csv_file_path)\n\n        # Select num_records from the DataFrame at random\n        df = df.sample(n=num_records)\n    else:\n        # If the csv_file is empty, return an empty DataFrame\n        df = pd.DataFrame()\n\n    return csv_file, df", "raw_solution": "import os\nimport random\nimport pandas as pd\n\ndef task_func(data_dir,\n              csv_files=['file1.csv', 'file2.csv', 'file3.csv'],\n              seed=None,\n              num_records=10):\n    if seed is not None:\n        random.seed(seed)\n\n    # Randomly select a csv_file\n    csv_file = random.choice(csv_files)\n    csv_file_path = os.path.join(data_dir, csv_file)\n\n    # Check if the csv_file exists and is not empty\n    if os.path.isfile(csv_file_path) and os.path.getsize(csv_file_path) > 0:\n        # Read the csv_file\n        df = pd.read_csv(csv_file_path)\n\n        # Select num_records from the DataFrame at random\n        df = df.sample(n=num_records)\n    else:\n        # If the csv_file is empty, return an empty DataFrame\n        df = pd.DataFrame()\n\n    return csv_file, df"}
{"task_id": "BigCodeBench/891", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\ndef task_func(csv_file_path, attribute, test_size=0.2, random_state=42):\n    # Load the data\n    df = pd.read_csv(csv_file_path)\n\n    # Separate the data into features and target\n    X = df.drop(attribute, axis=1)\n    y = df[attribute]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    # Train the model\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    # Make predictions\n    predictions = model.predict(X_test)\n\n    return model, predictions", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(csv_file_path, attribute, test_size=0.2, random_state=42):\n    # Load the data\n    df = pd.read_csv(csv_file_path)\n\n    # Separate the data into features and target\n    X = df.drop(attribute, axis=1)\n    y = df[attribute]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    # Train the model\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    # Make predictions\n    predictions = model.predict(X_test)\n\n    return model, predictions"}
{"task_id": "BigCodeBench/892", "solution": "import re\nfrom collections import Counter\ndef task_func(strings: list) -> dict:\n    pattern = 'pattern'  # replace 'pattern' with your specific pattern\n    pattern_counts = Counter()\n\n    for string in strings:\n        matches = re.findall(pattern, string)\n        pattern_counts.update(matches)\n\n    return pattern_counts\nstrings = ['This is a pattern', 'This pattern is unique', 'Pattern pattern pattern']", "raw_solution": "import re\nfrom collections import Counter\n\ndef task_func(strings: list) -> dict:\n    pattern = 'pattern'  # replace 'pattern' with your specific pattern\n    pattern_counts = Counter()\n\n    for string in strings:\n        matches = re.findall(pattern, string)\n        pattern_counts.update(matches)\n\n    return pattern_counts\n\n# Test the function\nstrings = ['This is a pattern', 'This pattern is unique', 'Pattern pattern pattern']"}
{"task_id": "BigCodeBench/893", "solution": "import re\nfrom datetime import datetime, timedelta\ndef task_func(logs: list):\n    error_times = []\n    for log in logs:\n        if 'error' in log.lower():\n            match = re.search(r'\\d{2}:\\d{2}:\\d{2}', log)\n            if match:\n                error_time = datetime.strptime(match.group(), '%H:%M:%S')\n                error_times.append(error_time)\n\n    if not error_times:\n        return {'list': [], 'time': 'No errors occurred'}\n\n    avg_time = sum(error_times[i+1] - error_times[i] for i in range(len(error_times)-1)) / (len(error_times)-1)\n    avg_time = str(timedelta(seconds=avg_time.total_seconds()))\n\n    return {'list': [str(time) for time in error_times], 'time': avg_time}\nlogs = [\n    '2022-01-01 12:00:00 INFO This is a normal log.',\n    '2022-01-01 12:00:30 ERROR An error occurred.',\n    '2022-01-01 12:01:00 ERROR Another error occurred.',\n    '2022-01-01 12:01:30 INFO Another normal log.',\n    '2022-01-01 12:02:00 ERROR One more error.',\n]", "raw_solution": "import re\nfrom datetime import datetime, timedelta\n\ndef task_func(logs: list):\n    error_times = []\n    for log in logs:\n        if 'error' in log.lower():\n            match = re.search(r'\\d{2}:\\d{2}:\\d{2}', log)\n            if match:\n                error_time = datetime.strptime(match.group(), '%H:%M:%S')\n                error_times.append(error_time)\n\n    if not error_times:\n        return {'list': [], 'time': 'No errors occurred'}\n\n    avg_time = sum(error_times[i+1] - error_times[i] for i in range(len(error_times)-1)) / (len(error_times)-1)\n    avg_time = str(timedelta(seconds=avg_time.total_seconds()))\n\n    return {'list': [str(time) for time in error_times], 'time': avg_time}\n\n# Test the function\nlogs = [\n    '2022-01-01 12:00:00 INFO This is a normal log.',\n    '2022-01-01 12:00:30 ERROR An error occurred.',\n    '2022-01-01 12:01:00 ERROR Another error occurred.',\n    '2022-01-01 12:01:30 INFO Another normal log.',\n    '2022-01-01 12:02:00 ERROR One more error.',\n]"}
{"task_id": "BigCodeBench/894", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nARRAY_SIZE = 10000\ndef task_func():\n    # Create a numeric array of random integers\n    array = np.random.randint(1, 101, ARRAY_SIZE)\n    \n    # Calculate the mean and standard deviation\n    mean = np.mean(array)\n    std_dev = np.std(array)\n    \n    # Draw a histogram of the distribution\n    fig, ax = plt.subplots()\n    ax.hist(array, bins=100, color='blue', edgecolor='black')\n    ax.set_title('Histogram of Random Integers')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    \n    # Plot the mean as a red dashed line\n    ax.axvline(mean, color='red', linestyle='dashed', linewidth=1, label='Mean')\n    \n    # Plot the standard deviation as purple dashed lines\n    ax.axvline(mean - std_dev, color='purple', linestyle='dashed', linewidth=1, label='Standard Deviation')\n    ax.axvline(mean + std_dev, color='purple', linestyle='dashed', linewidth=1)\n    \n    ax.legend()\n    \n    return (array, mean, std_dev, ax)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nARRAY_SIZE = 10000\n\ndef task_func():\n    # Create a numeric array of random integers\n    array = np.random.randint(1, 101, ARRAY_SIZE)\n    \n    # Calculate the mean and standard deviation\n    mean = np.mean(array)\n    std_dev = np.std(array)\n    \n    # Draw a histogram of the distribution\n    fig, ax = plt.subplots()\n    ax.hist(array, bins=100, color='blue', edgecolor='black')\n    ax.set_title('Histogram of Random Integers')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    \n    # Plot the mean as a red dashed line\n    ax.axvline(mean, color='red', linestyle='dashed', linewidth=1, label='Mean')\n    \n    # Plot the standard deviation as purple dashed lines\n    ax.axvline(mean - std_dev, color='purple', linestyle='dashed', linewidth=1, label='Standard Deviation')\n    ax.axvline(mean + std_dev, color='purple', linestyle='dashed', linewidth=1)\n    \n    ax.legend()\n    \n    return (array, mean, std_dev, ax)\n\n# Test the function\narray, mean, std_dev, ax = task_func()\nplt.show()"}
{"task_id": "BigCodeBench/895", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nARRAY_SIZE = 10000\ndef task_func():\n    # Create a numeric array of random integers\n    arr = np.random.randint(1, 101, ARRAY_SIZE)\n    \n    # Calculate the mean and standard deviation\n    mean = np.mean(arr)\n    std_dev = np.std(arr)\n    \n    # Draw a histogram of the distribution\n    fig, ax = plt.subplots()\n    ax.hist(arr, bins=100, color='blue', edgecolor='black')\n    ax.set_title('Histogram of Random Values')\n    ax.set_xlabel('Val')\n    ax.set_ylabel('Freq')\n    \n    # Plot the mean as a red dashed line\n    ax.axvline(mean, color='red', linestyle='dashed', linewidth=1, label='Mean')\n    \n    # Plot the standard deviation as purple dashed lines\n    ax.axvline(mean - std_dev, color='purple', linestyle='dashed', linewidth=1, label='1 std dev')\n    ax.axvline(mean + std_dev, color='purple', linestyle='dashed', linewidth=1, label='1 std dev')\n    \n    ax.legend()\n    \n    return (arr, mean, std_dev, ax)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nARRAY_SIZE = 10000\n\ndef task_func():\n    # Create a numeric array of random integers\n    arr = np.random.randint(1, 101, ARRAY_SIZE)\n    \n    # Calculate the mean and standard deviation\n    mean = np.mean(arr)\n    std_dev = np.std(arr)\n    \n    # Draw a histogram of the distribution\n    fig, ax = plt.subplots()\n    ax.hist(arr, bins=100, color='blue', edgecolor='black')\n    ax.set_title('Histogram of Random Values')\n    ax.set_xlabel('Val')\n    ax.set_ylabel('Freq')\n    \n    # Plot the mean as a red dashed line\n    ax.axvline(mean, color='red', linestyle='dashed', linewidth=1, label='Mean')\n    \n    # Plot the standard deviation as purple dashed lines\n    ax.axvline(mean - std_dev, color='purple', linestyle='dashed', linewidth=1, label='1 std dev')\n    ax.axvline(mean + std_dev, color='purple', linestyle='dashed', linewidth=1, label='1 std dev')\n    \n    ax.legend()\n    \n    return (arr, mean, std_dev, ax)\n\n# Test the function\narr, mean, std_dev, ax = task_func()\nplt.show()"}
{"task_id": "BigCodeBench/896", "solution": "from collections import Counter\nimport random\nimport itertools\ndef task_func(length, count, seed=0):\n    random.seed(seed)\n    letters = ['a', 'b', 'c', 'd', 'e']\n    strings = [''.join(random.choices(letters, k=length)) for _ in range(count)]\n    flattened_string = ''.join(strings)\n    counter = Counter(flattened_string)\n    return counter", "raw_solution": "from collections import Counter\nimport random\nimport itertools\n\ndef task_func(length, count, seed=0):\n    random.seed(seed)\n    letters = ['a', 'b', 'c', 'd', 'e']\n    strings = [''.join(random.choices(letters, k=length)) for _ in range(count)]\n    flattened_string = ''.join(strings)\n    counter = Counter(flattened_string)\n    return counter\n\n# Test the function\ncounter = task_func(5, 1000, seed=0)"}
{"task_id": "BigCodeBench/897", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nNUMBERS = list(range(1, 7))\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    results = [random.choice(NUMBERS) for _ in range(rolls)]\n    frequencies = np.bincount(results)\n    fig, ax = plt.subplots()\n    ax.bar(NUMBERS, frequencies)\n    ax.set_title(\"Histogram of Dice Rolls\")\n    ax.set_xlabel(\"Dice Value\")\n    ax.set_ylabel(\"Frequency\")\n    return (frequencies, ax.figure)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\n\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    results = [random.choice(NUMBERS) for _ in range(rolls)]\n    frequencies = np.bincount(results)\n    fig, ax = plt.subplots()\n    ax.bar(NUMBERS, frequencies)\n    ax.set_title(\"Histogram of Dice Rolls\")\n    ax.set_xlabel(\"Dice Value\")\n    ax.set_ylabel(\"Frequency\")\n    return (frequencies, ax.figure)\n\n# Test the function\nfrequencies, figure = task_func(1000, seed=42)"}
{"task_id": "BigCodeBench/898", "solution": "from collections import Counter\nimport random\nLETTERS = ['a', 'b', 'c', 'd', 'e']\ndef task_func(count, seed=0):\n    random.seed(seed)\n    pairs = [random.choices(LETTERS, k=2) for _ in range(count)]\n    flat_pairs = [''.join(pair) for pair in pairs]\n    counter = Counter(flat_pairs)\n    return counter", "raw_solution": "from collections import Counter\nimport random\n\nLETTERS = ['a', 'b', 'c', 'd', 'e']\n\ndef task_func(count, seed=0):\n    random.seed(seed)\n    pairs = [random.choices(LETTERS, k=2) for _ in range(count)]\n    flat_pairs = [''.join(pair) for pair in pairs]\n    counter = Counter(flat_pairs)\n    return counter\n\n# Test the function"}
{"task_id": "BigCodeBench/899", "solution": "import numpy as np\nimport random\ndef task_func(length=10000, seed=0):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    random.seed(seed)\n    steps = [random.choice([-1, 1]) for _ in range(length)]\n    walk = np.cumsum(steps)\n    return walk", "raw_solution": "import numpy as np\nimport random\n\ndef task_func(length=10000, seed=0):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    random.seed(seed)\n    steps = [random.choice([-1, 1]) for _ in range(length)]\n    walk = np.cumsum(steps)\n    return walk"}
{"task_id": "BigCodeBench/900", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(d):\n    if not isinstance(d, list):\n        raise ValueError(\"Input should be a list of dictionaries\")\n    if not all(isinstance(i, dict) for i in d):\n        raise ValueError(\"Input should be a list of dictionaries\")\n    if not all('x' in i and 'y' in i and 'z' in i for i in d):\n        raise ValueError(\"Each dictionary should have keys 'x', 'y', and 'z'\")\n\n    df = pd.DataFrame(d)\n    stats_dict = {\n        'x': {\n            'mean': df['x'].mean(),\n            'sum': df['x'].sum(),\n            'max': df['x'].max(),\n            'min': df['x'].min(),\n            'std': df['x'].std()\n        },\n        'y': {\n            'mean': df['y'].mean(),\n            'sum': df['y'].sum(),\n            'max': df['y'].max(),\n            'min': df['y'].min(),\n            'std': df['y'].std()\n        },\n        'z': {\n            'mean': df['z'].mean(),\n            'sum': df['z'].sum(),\n            'max': df['z'].max(),\n            'min': df['z'].min(),\n            'std': df['z'].std()\n        }\n    }\n    return stats_dict", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(d):\n    if not isinstance(d, list):\n        raise ValueError(\"Input should be a list of dictionaries\")\n    if not all(isinstance(i, dict) for i in d):\n        raise ValueError(\"Input should be a list of dictionaries\")\n    if not all('x' in i and 'y' in i and 'z' in i for i in d):\n        raise ValueError(\"Each dictionary should have keys 'x', 'y', and 'z'\")\n\n    df = pd.DataFrame(d)\n    stats_dict = {\n        'x': {\n            'mean': df['x'].mean(),\n            'sum': df['x'].sum(),\n            'max': df['x'].max(),\n            'min': df['x'].min(),\n            'std': df['x'].std()\n        },\n        'y': {\n            'mean': df['y'].mean(),\n            'sum': df['y'].sum(),\n            'max': df['y'].max(),\n            'min': df['y'].min(),\n            'std': df['y'].std()\n        },\n        'z': {\n            'mean': df['z'].mean(),\n            'sum': df['z'].sum(),\n            'max': df['z'].max(),\n            'min': df['z'].min(),\n            'std': df['z'].std()\n        }\n    }\n    return stats_dict"}
{"task_id": "BigCodeBench/901", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(d):\n    if not d:\n        return pd.DataFrame()\n\n    df = pd.DataFrame(d)\n    scaler = MinMaxScaler()\n    df[['x', 'y', 'z']] = scaler.fit_transform(df[['x', 'y', 'z']])\n\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Updated function to handle empty input list\ndef task_func(d):\n    if not d:\n        return pd.DataFrame()\n\n    df = pd.DataFrame(d)\n    scaler = MinMaxScaler()\n    df[['x', 'y', 'z']] = scaler.fit_transform(df[['x', 'y', 'z']])\n\n    return df\n\ndata = [{'x': -1, 'y': 0, 'z': 5}, {'x': 3, 'y': -15, 'z': 0}, {'x': 0, 'y': 1, 'z': -7}]"}
{"task_id": "BigCodeBench/902", "solution": "import pandas as pd\nfrom collections import Counter\ndef task_func(d):\n    # Initialize counters for 'x', 'y', and 'z'\n    x_counter = Counter()\n    y_counter = Counter()\n    z_counter = Counter()\n\n    # Iterate over each dictionary in the list\n    for dic in d:\n        # If the key 'x' exists, update the counter\n        if 'x' in dic:\n            x_counter.update(dic['x'])\n        # If the key 'y' exists, update the counter\n        if 'y' in dic:\n            y_counter.update(dic['y'])\n        # If the key 'z' exists, update the counter\n        if 'z' in dic:\n            z_counter.update(dic['z'])\n\n    # Return a dictionary with the counters\n    return {'x': x_counter, 'y': y_counter, 'z': z_counter}\nd = [{'x': [1, 2, 2, 3], 'y': [1, 1, 2, 2, 2], 'z': [1, 1, 1, 1]}, \n     {'x': [1, 1, 2, 2], 'y': [1, 1, 2, 2, 2], 'z': [1, 1, 1, 1]}, \n     {'x': [1, 1, 1, 1], 'y': [1, 1, 1, 1, 1], 'z': [1, 1, 1, 1]}]", "raw_solution": "import pandas as pd\nfrom collections import Counter\n\ndef task_func(d):\n    # Initialize counters for 'x', 'y', and 'z'\n    x_counter = Counter()\n    y_counter = Counter()\n    z_counter = Counter()\n\n    # Iterate over each dictionary in the list\n    for dic in d:\n        # If the key 'x' exists, update the counter\n        if 'x' in dic:\n            x_counter.update(dic['x'])\n        # If the key 'y' exists, update the counter\n        if 'y' in dic:\n            y_counter.update(dic['y'])\n        # If the key 'z' exists, update the counter\n        if 'z' in dic:\n            z_counter.update(dic['z'])\n\n    # Return a dictionary with the counters\n    return {'x': x_counter, 'y': y_counter, 'z': z_counter}\n\n# Test the function\nd = [{'x': [1, 2, 2, 3], 'y': [1, 1, 2, 2, 2], 'z': [1, 1, 1, 1]}, \n     {'x': [1, 1, 2, 2], 'y': [1, 1, 2, 2, 2], 'z': [1, 1, 1, 1]}, \n     {'x': [1, 1, 1, 1], 'y': [1, 1, 1, 1, 1], 'z': [1, 1, 1, 1]}]\n"}
{"task_id": "BigCodeBench/903", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(d, target='z'):\n    # Convert the list of dictionaries to a pandas DataFrame\n    df = pd.DataFrame(d)\n\n    # Define the features and target\n    X = df[['x', 'z']]\n    y = df[target]\n\n    # Create a Linear Regression model\n    model = LinearRegression()\n\n    # Fit the model\n    model.fit(X, y)\n\n    return model\ndata = [{'x': 4, 'y': 20, 'z': 10}, {'x': 5, 'y': 25, 'z': 15}, {'x': 6, 'y': 5, 'z': 20}]", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(d, target='z'):\n    # Convert the list of dictionaries to a pandas DataFrame\n    df = pd.DataFrame(d)\n\n    # Define the features and target\n    X = df[['x', 'z']]\n    y = df[target]\n\n    # Create a Linear Regression model\n    model = LinearRegression()\n\n    # Fit the model\n    model.fit(X, y)\n\n    return model\n\n# Test the function\ndata = [{'x': 4, 'y': 20, 'z': 10}, {'x': 5, 'y': 25, 'z': 15}, {'x': 6, 'y': 5, 'z': 20}]\nmodel = task_func(data, target='y')\n\n# Check if the model is a LinearRegression instance"}
{"task_id": "BigCodeBench/904", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(d, keys=['x', 'y', 'z']):\n    # Convert the list of dictionaries to a pandas DataFrame\n    df = pd.DataFrame(d)\n    \n    # Check if the keys exist in the DataFrame\n    for key in keys:\n        if key not in df.columns:\n            print(f\"Key '{key}' not found in the data.\")\n            return None\n    \n    # Create a new figure and get the Axes object\n    fig, ax = plt.subplots()\n    \n    # Plot the data\n    for key in keys:\n        ax.plot(df[key])\n    \n    return ax\ndata = [{'x': 1, 'y': 2, 'z': 3}, {'x': 2, 'y': 3, 'z': 4}, {'x': 3, 'y': 4, 'z': 5}]", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(d, keys=['x', 'y', 'z']):\n    # Convert the list of dictionaries to a pandas DataFrame\n    df = pd.DataFrame(d)\n    \n    # Check if the keys exist in the DataFrame\n    for key in keys:\n        if key not in df.columns:\n            print(f\"Key '{key}' not found in the data.\")\n            return None\n    \n    # Create a new figure and get the Axes object\n    fig, ax = plt.subplots()\n    \n    # Plot the data\n    for key in keys:\n        ax.plot(df[key])\n    \n    return ax\n\n# Test the function\ndata = [{'x': 1, 'y': 2, 'z': 3}, {'x': 2, 'y': 3, 'z': 4}, {'x': 3, 'y': 4, 'z': 5}]\nax = task_func(data, keys=['x', 'y'])\n\n# Check the type of the returned object"}
{"task_id": "BigCodeBench/905", "solution": "import os\nimport glob\nimport csv\ndef task_func(directory_path, file_extension='.csv'):\n    data = {}\n    for file in glob.glob(os.path.join(directory_path, f'*{file_extension}')):\n        with open(file, 'r') as f:\n            reader = csv.reader(f)\n            data[os.path.splitext(os.path.basename(file))[0]] = list(reader)\n    return data", "raw_solution": "import os\nimport glob\nimport csv\n\ndef task_func(directory_path, file_extension='.csv'):\n    data = {}\n    for file in glob.glob(os.path.join(directory_path, f'*{file_extension}')):\n        with open(file, 'r') as f:\n            reader = csv.reader(f)\n            data[os.path.splitext(os.path.basename(file))[0]] = list(reader)\n    return data\n\n# Test the function\ndata = task_func('/home/user/data', '.txt')"}
{"task_id": "BigCodeBench/906", "solution": "import zipfile\nimport os\nimport re\nimport shutil\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    # Check if source directory exists\n    if not os.path.isdir(source_dir):\n        raise ValueError(f\"Source directory {source_dir} does not exist.\")\n\n    # Check if target directory exists\n    if not os.path.isdir(target_dir):\n        raise ValueError(f\"Target directory {target_dir} does not exist.\")\n\n    # Create a list of all files in the source directory with '_processed' in their names\n    processed_files = [f for f in os.listdir(source_dir) if '_processed' in f]\n\n    # Move the processed files to the target directory\n    for file in processed_files:\n        shutil.move(os.path.join(source_dir, file), os.path.join(target_dir, file))\n\n    # Create a zip archive of the processed files in the target directory\n    with zipfile.ZipFile(os.path.join(target_dir, archive_name), 'w') as zipf:\n        for file in processed_files:\n            zipf.write(os.path.join(target_dir, file), arcname=file)\n\n    # Return the path to the created archive\n    return os.path.join(target_dir, archive_name)", "raw_solution": "import zipfile\nimport os\nimport re\nimport shutil\n\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    # Check if source directory exists\n    if not os.path.isdir(source_dir):\n        raise ValueError(f\"Source directory {source_dir} does not exist.\")\n\n    # Check if target directory exists\n    if not os.path.isdir(target_dir):\n        raise ValueError(f\"Target directory {target_dir} does not exist.\")\n\n    # Create a list of all files in the source directory with '_processed' in their names\n    processed_files = [f for f in os.listdir(source_dir) if '_processed' in f]\n\n    # Move the processed files to the target directory\n    for file in processed_files:\n        shutil.move(os.path.join(source_dir, file), os.path.join(target_dir, file))\n\n    # Create a zip archive of the processed files in the target directory\n    with zipfile.ZipFile(os.path.join(target_dir, archive_name), 'w') as zipf:\n        for file in processed_files:\n            zipf.write(os.path.join(target_dir, file), arcname=file)\n\n    # Return the path to the created archive\n    return os.path.join(target_dir, archive_name)"}
{"task_id": "BigCodeBench/907", "solution": "import os\nimport re\ndef task_func(pattern: str, replacement: str, directory: str) -> bool:\n    try:\n        for filename in os.listdir(directory):\n            if re.search(pattern, filename):\n                os.rename(os.path.join(directory, filename), os.path.join(directory, re.sub(pattern, replacement, filename)))\n        return True\n    except Exception:\n        return False", "raw_solution": "import os\nimport re\n\ndef task_func(pattern: str, replacement: str, directory: str) -> bool:\n    try:\n        for filename in os.listdir(directory):\n            if re.search(pattern, filename):\n                os.rename(os.path.join(directory, filename), os.path.join(directory, re.sub(pattern, replacement, filename)))\n        return True\n    except Exception:\n        return False\n\n# Test the function"}
{"task_id": "BigCodeBench/908", "solution": "import os\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\ndef task_func(directory: str, pattern: str) -> list:\n    # Initialize an empty list to store the axes objects\n    axes_list = []\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the file matches the regular expression pattern\n        if re.match(pattern, filename):\n            # If the file is a CSV file\n            if filename.endswith('.csv'):\n                # Read the CSV file into a pandas DataFrame\n                df = pd.read_csv(os.path.join(directory, filename))\n\n                # Check if the DataFrame has the correct columns\n                if 'Month' in df.columns and 'Sales' in df.columns:\n                    # Create a new figure and axis\n                    fig, ax = plt.subplots()\n\n                    # Plot the sales data\n                    ax.plot(df['Month'], df['Sales'])\n\n                    # Add the axes object to the list\n                    axes_list.append(ax)\n\n    # Return the list of axes objects\n    return axes_list", "raw_solution": "import os\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\n\ndef task_func(directory: str, pattern: str) -> list:\n    # Initialize an empty list to store the axes objects\n    axes_list = []\n\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the file matches the regular expression pattern\n        if re.match(pattern, filename):\n            # If the file is a CSV file\n            if filename.endswith('.csv'):\n                # Read the CSV file into a pandas DataFrame\n                df = pd.read_csv(os.path.join(directory, filename))\n\n                # Check if the DataFrame has the correct columns\n                if 'Month' in df.columns and 'Sales' in df.columns:\n                    # Create a new figure and axis\n                    fig, ax = plt.subplots()\n\n                    # Plot the sales data\n                    ax.plot(df['Month'], df['Sales'])\n\n                    # Add the axes object to the list\n                    axes_list.append(ax)\n\n    # Return the list of axes objects\n    return axes_list"}
{"task_id": "BigCodeBench/909", "solution": "import pandas as pd\nimport random\ndef task_func(letters=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'], categories=['Category 1', 'Category 2', 'Category 3']):\n    random.shuffle(categories)\n    data = {'Letter': letters, 'Category': categories}\n    df = pd.DataFrame(data)\n    return df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(letters=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'], categories=['Category 1', 'Category 2', 'Category 3']):\n    random.shuffle(categories)\n    data = {'Letter': letters, 'Category': categories}\n    df = pd.DataFrame(data)\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/910", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(letters, repetitions, colors):\n    # Check if the inputs are empty\n    if not letters or not repetitions or not colors:\n        raise ValueError(\"Input lists cannot be empty\")\n\n    # Check if the lengths of the inputs match\n    if len(letters) != len(repetitions) or len(letters) != len(colors):\n        raise ValueError(\"Lengths of input lists do not match\")\n\n    # Flatten the list of letters\n    flat_letters = [letter for letter, rep in zip(letters, repetitions) for _ in range(rep)]\n\n    # Get the frequency of each letter\n    unique_letters, freq = np.unique(flat_letters, return_counts=True)\n\n    # Create the bar chart\n    fig, ax = plt.subplots()\n    ax.bar(unique_letters, freq, color=colors)\n\n    # Set labels and title\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of Letters')\n\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(letters, repetitions, colors):\n    # Check if the inputs are empty\n    if not letters or not repetitions or not colors:\n        raise ValueError(\"Input lists cannot be empty\")\n\n    # Check if the lengths of the inputs match\n    if len(letters) != len(repetitions) or len(letters) != len(colors):\n        raise ValueError(\"Lengths of input lists do not match\")\n\n    # Flatten the list of letters\n    flat_letters = [letter for letter, rep in zip(letters, repetitions) for _ in range(rep)]\n\n    # Get the frequency of each letter\n    unique_letters, freq = np.unique(flat_letters, return_counts=True)\n\n    # Create the bar chart\n    fig, ax = plt.subplots()\n    ax.bar(unique_letters, freq, color=colors)\n\n    # Set labels and title\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Frequency of Letters')\n\n    return ax"}
{"task_id": "BigCodeBench/911", "solution": "from functools import reduce\nimport operator\nimport string\ndef task_func(letters):\n    # Create a dictionary to map each uppercase letter to its corresponding number\n    letter_to_num = {letter: num for num, letter in enumerate(string.ascii_uppercase, start=1)}\n\n    # Convert the letters to their corresponding numbers and calculate the product\n    nums = [letter_to_num[letter] for letter in letters]\n    product = reduce(operator.mul, nums)\n\n    return product", "raw_solution": "from functools import reduce\nimport operator\nimport string\n\ndef task_func(letters):\n    # Create a dictionary to map each uppercase letter to its corresponding number\n    letter_to_num = {letter: num for num, letter in enumerate(string.ascii_uppercase, start=1)}\n\n    # Convert the letters to their corresponding numbers and calculate the product\n    nums = [letter_to_num[letter] for letter in letters]\n    product = reduce(operator.mul, nums)\n\n    return product\n\n# Test the function"}
{"task_id": "BigCodeBench/912", "solution": "from collections import Counter\nimport itertools\ndef task_func(letters: list, repetitions: int) -> dict:\n    # Repeat the list of letters for the given number of times\n    repeated_letters = list(itertools.islice(itertools.cycle(letters), repetitions))\n    \n    # Count the frequency of each letter using Counter\n    freq_dict = dict(Counter(repeated_letters))\n    \n    return freq_dict\nletters = ['a', 'b', 'c']\nrepetitions = 10", "raw_solution": "from collections import Counter\nimport itertools\n\ndef task_func(letters: list, repetitions: int) -> dict:\n    # Repeat the list of letters for the given number of times\n    repeated_letters = list(itertools.islice(itertools.cycle(letters), repetitions))\n    \n    # Count the frequency of each letter using Counter\n    freq_dict = dict(Counter(repeated_letters))\n    \n    return freq_dict\n\n# Test the function\nletters = ['a', 'b', 'c']\nrepetitions = 10"}
{"task_id": "BigCodeBench/913", "solution": "from typing import List, Union\nimport numpy as np\nfrom scipy import stats\nimport scipy.fft\ndef task_func(data: List[Union[int, str]], repetitions: int = 1):\n    if not data or repetitions <= 0:\n        return {'mode': np.array([]), 'count': np.array([])}\n\n    # Repeat the data\n    repeated_data = data * repetitions\n\n    # Calculate the mode(s)\n    mode_data = stats.mode(repeated_data)\n    mode = mode_data.mode[0]\n    count = mode_data.count[0]\n\n    # Calculate the FFT\n    fft_data = scipy.fft.fft(repeated_data)\n\n    return {'mode': np.array([mode]), 'count': np.array([count]), 'fft': fft_data}\ndata = [1, 2, 2, 3, 3, 3]\nrepetitions = 3", "raw_solution": "from typing import List, Union\nimport numpy as np\nfrom scipy import stats\nimport scipy.fft\n\ndef task_func(data: List[Union[int, str]], repetitions: int = 1):\n    if not data or repetitions <= 0:\n        return {'mode': np.array([]), 'count': np.array([])}\n\n    # Repeat the data\n    repeated_data = data * repetitions\n\n    # Calculate the mode(s)\n    mode_data = stats.mode(repeated_data)\n    mode = mode_data.mode[0]\n    count = mode_data.count[0]\n\n    # Calculate the FFT\n    fft_data = scipy.fft.fft(repeated_data)\n\n    return {'mode': np.array([mode]), 'count': np.array([count]), 'fft': fft_data}\n\n# Test the function\ndata = [1, 2, 2, 3, 3, 3]\nrepetitions = 3"}
{"task_id": "BigCodeBench/914", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    # Convert the 'Date' column to datetime\n    df['Date'] = pd.to_datetime(df['Date'])\n\n    # Set the 'Date' column as the index\n    df.set_index('Date', inplace=True)\n\n    # Resample the data to daily frequency and fill missing values\n    df = df.resample('D').mean().fillna(method='ffill')\n\n    # Create a new column 'Time' which represents the time in seconds since the start of the data\n    df['Time'] = (df.index - df.index[0]).total_seconds()\n\n    # Reshape the data for the linear regression model\n    X = df['Time'].values.reshape(-1, 1)\n    y = df['Close'].values.reshape(-1, 1)\n\n    # Create and fit the linear regression model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Generate future timestamps\n    future_timestamps = pd.date_range(start=df.index[-1], periods=7, freq='D')\n    future_timestamps = (future_timestamps - df.index[0]).total_seconds()\n\n    # Predict the closing prices for the next 7 days\n    future_X = future_timestamps.reshape(-1, 1)\n    future_y = model.predict(future_X)\n\n    # Plot the data\n    plt.figure(figsize=(10, 6))\n    plt.plot(df.index, df['Close'], label='Actual')\n    plt.plot(future_timestamps, future_y, label='Predicted')\n    plt.xlabel('Date')\n    plt.ylabel('Closing Price')\n    plt.title('Stock Closing Prices Prediction')\n    plt.legend()\n    plt.grid(True)\n\n    return (future_y.flatten().tolist(), plt.gca())", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    # Convert the 'Date' column to datetime\n    df['Date'] = pd.to_datetime(df['Date'])\n\n    # Set the 'Date' column as the index\n    df.set_index('Date', inplace=True)\n\n    # Resample the data to daily frequency and fill missing values\n    df = df.resample('D').mean().fillna(method='ffill')\n\n    # Create a new column 'Time' which represents the time in seconds since the start of the data\n    df['Time'] = (df.index - df.index[0]).total_seconds()\n\n    # Reshape the data for the linear regression model\n    X = df['Time'].values.reshape(-1, 1)\n    y = df['Close'].values.reshape(-1, 1)\n\n    # Create and fit the linear regression model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Generate future timestamps\n    future_timestamps = pd.date_range(start=df.index[-1], periods=7, freq='D')\n    future_timestamps = (future_timestamps - df.index[0]).total_seconds()\n\n    # Predict the closing prices for the next 7 days\n    future_X = future_timestamps.reshape(-1, 1)\n    future_y = model.predict(future_X)\n\n    # Plot the data\n    plt.figure(figsize=(10, 6))\n    plt.plot(df.index, df['Close'], label='Actual')\n    plt.plot(future_timestamps, future_y, label='Predicted')\n    plt.xlabel('Date')\n    plt.ylabel('Closing Price')\n    plt.title('Stock Closing Prices Prediction')\n    plt.legend()\n    plt.grid(True)\n\n    return (future_y.flatten().tolist(), plt.gca())"}
{"task_id": "BigCodeBench/915", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\ndef task_func(df, z_threshold=2):\n    df['z_score'] = zscore(df['closing_price'])\n    outliers = df[np.abs(df['z_score']) > z_threshold]\n    plot = df['closing_price'].plot(kind='line', title='Outliers in Closing Prices')\n    plot.set_xlabel('Index')\n    plot.set_ylabel('Closing Price')\n    plt.scatter(outliers.index, outliers['closing_price'], color='red')\n    return outliers, plot", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\n\ndef task_func(df, z_threshold=2):\n    df['z_score'] = zscore(df['closing_price'])\n    outliers = df[np.abs(df['z_score']) > z_threshold]\n    plot = df['closing_price'].plot(kind='line', title='Outliers in Closing Prices')\n    plot.set_xlabel('Index')\n    plot.set_ylabel('Closing Price')\n    plt.scatter(outliers.index, outliers['closing_price'], color='red')\n    return outliers, plot\n\n# Test the function\ndf2 = pd.DataFrame({\n    'closing_price': [10, 20, 30, 40, 50, 100]\n})\noutliers2, plot2 = task_func(df2, z_threshold=1.5)\nplt.show()"}
{"task_id": "BigCodeBench/916", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df: pd.DataFrame) -> tuple:\n    # Ensure the DataFrame has a 'Close' column\n    assert 'Close' in df.columns, \"DataFrame must have a 'Close' column\"\n\n    # Create a new figure\n    fig, axes = plt.subplots(2, figsize=(10,10))\n\n    # Create a boxplot\n    sns.boxplot(df['Close'], ax=axes[0])\n    axes[0].set_title('Box Plot of Closing Prices')\n\n    # Create a histogram\n    sns.histplot(df['Close'], ax=axes[1], kde=True)\n    axes[1].set_title('Histogram of Closing Prices')\n\n    # Return the axes\n    return (axes[0], axes[1])", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df: pd.DataFrame) -> tuple:\n    # Ensure the DataFrame has a 'Close' column\n    assert 'Close' in df.columns, \"DataFrame must have a 'Close' column\"\n\n    # Create a new figure\n    fig, axes = plt.subplots(2, figsize=(10,10))\n\n    # Create a boxplot\n    sns.boxplot(df['Close'], ax=axes[0])\n    axes[0].set_title('Box Plot of Closing Prices')\n\n    # Create a histogram\n    sns.histplot(df['Close'], ax=axes[1], kde=True)\n    axes[1].set_title('Histogram of Closing Prices')\n\n    # Return the axes\n    return (axes[0], axes[1])"}
{"task_id": "BigCodeBench/917", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    # Fit the model\n    model = ARIMA(df['Close'], order=(5,1,0))\n    model_fit = model.fit(disp=0)\n\n    # Forecast\n    forecast = model_fit.forecast(steps=7)\n\n    # Plot\n    fig, ax = plt.subplots(1, 1)\n    ax.plot(df['Close'])\n    ax.plot(pd.date_range(start=df.index[-1], periods=8)[1:], forecast)\n\n    return forecast.tolist(), ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\n\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    # Fit the model\n    model = ARIMA(df['Close'], order=(5,1,0))\n    model_fit = model.fit(disp=0)\n\n    # Forecast\n    forecast = model_fit.forecast(steps=7)\n\n    # Plot\n    fig, ax = plt.subplots(1, 1)\n    ax.plot(df['Close'])\n    ax.plot(pd.date_range(start=df.index[-1], periods=8)[1:], forecast)\n\n    return forecast.tolist(), ax"}
{"task_id": "BigCodeBench/918", "solution": "import pandas as pd\nimport re\ndef task_func(data, mapping):\n    # Create a regular expression pattern from the acronyms in the mapping\n    pattern = re.compile(\"|\".join(map(re.escape, mapping.keys())), re.IGNORECASE)\n\n    # Replace the acronyms in the DataFrame with their full words\n    data = data.applymap(lambda x: pattern.sub(lambda m: mapping[m.string[m.start():m.end()]], str(x)))\n\n    return data\nmapping = {'NASA': 'National Aeronautics and Space Administration', \n           'SpaceX': 'Space Exploration Technologies Corporation', \n           'ISS': 'International Space Station', \n           'USA': 'United States of America', \n           'Space Station': 'International Space Station', \n           'Earth': 'Earth'}", "raw_solution": "import pandas as pd\nimport re\n\n# Function to replace acronyms in DataFrame\ndef task_func(data, mapping):\n    # Create a regular expression pattern from the acronyms in the mapping\n    pattern = re.compile(\"|\".join(map(re.escape, mapping.keys())), re.IGNORECASE)\n\n    # Replace the acronyms in the DataFrame with their full words\n    data = data.applymap(lambda x: pattern.sub(lambda m: mapping[m.string[m.start():m.end()]], str(x)))\n\n    return data\n\n# Test the function\n# Create a DataFrame\ndf = pd.DataFrame({'A': ['NASA', 'SpaceX', 'ISS'], 'B': ['USA', 'Space Station', 'Earth']})\n\n# Define the mapping\nmapping = {'NASA': 'National Aeronautics and Space Administration', \n           'SpaceX': 'Space Exploration Technologies Corporation', \n           'ISS': 'International Space Station', \n           'USA': 'United States of America', \n           'Space Station': 'International Space Station', \n           'Earth': 'Earth'}\n\n# Replace the acronyms in the DataFrame\ndf = task_func(df, mapping)\n\n# Print the DataFrame"}
{"task_id": "BigCodeBench/919", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nCATEGORIES = ['A', 'B', 'C', 'D', 'E']\ndef task_func(data, column):\n    # Ensure the data is a pandas DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data must be a pandas DataFrame\")\n\n    # Ensure the column exists in the DataFrame\n    if column not in data.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame\")\n\n    # Count the occurrences of each category in the column\n    counts = data[column].value_counts()\n\n    # Fill in any missing categories with a count of zero\n    counts = counts.reindex(CATEGORIES, fill_value=0)\n\n    # Create a bar chart\n    ax = counts.plot(kind='bar', figsize=(10, 6))\n\n    # Set labels and title\n    ax.set_xlabel('Category')\n    ax.set_ylabel('Count')\n    ax.set_title(f'Distribution of {column}')\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\nCATEGORIES = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(data, column):\n    # Ensure the data is a pandas DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data must be a pandas DataFrame\")\n\n    # Ensure the column exists in the DataFrame\n    if column not in data.columns:\n        raise ValueError(f\"Column '{column}' does not exist in the DataFrame\")\n\n    # Count the occurrences of each category in the column\n    counts = data[column].value_counts()\n\n    # Fill in any missing categories with a count of zero\n    counts = counts.reindex(CATEGORIES, fill_value=0)\n\n    # Create a bar chart\n    ax = counts.plot(kind='bar', figsize=(10, 6))\n\n    # Set labels and title\n    ax.set_xlabel('Category')\n    ax.set_ylabel('Count')\n    ax.set_title(f'Distribution of {column}')\n\n    return ax"}
{"task_id": "BigCodeBench/920", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Check if the input is a DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input should be a pandas DataFrame\")\n\n    # Check if the DataFrame contains only numerical columns\n    if not all(data.dtypes[col] in ['int64', 'float64'] for col in data.columns):\n        raise ValueError(\"DataFrame should only contain numerical columns\")\n\n    # Calculate the correlation matrix\n    corr = data.corr()\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, square=True,\n                xticklabels=corr.columns.values,\n                yticklabels=corr.columns.values,\n                title='Correlation Matrix')\n\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Check if the input is a DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input should be a pandas DataFrame\")\n\n    # Check if the DataFrame contains only numerical columns\n    if not all(data.dtypes[col] in ['int64', 'float64'] for col in data.columns):\n        raise ValueError(\"DataFrame should only contain numerical columns\")\n\n    # Calculate the correlation matrix\n    corr = data.corr()\n\n    # Create a heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, square=True,\n                xticklabels=corr.columns.values,\n                yticklabels=corr.columns.values,\n                title='Correlation Matrix')\n\n    return plt.gca()"}
{"task_id": "BigCodeBench/921", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data, columns):\n    # Check if data is a pandas DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data should be a pandas DataFrame\")\n\n    # Check if columns is a list\n    if not isinstance(columns, list):\n        raise ValueError(\"Columns should be a list\")\n\n    # Check if all elements in columns are strings\n    if not all(isinstance(col, str) for col in columns):\n        raise ValueError(\"All elements in columns should be strings\")\n\n    # Check if all columns in data are in columns\n    if not all(col in data.columns for col in columns):\n        raise ValueError(\"All columns in columns should be in data\")\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the specified columns\n    data[columns] = scaler.fit_transform(data[columns])\n\n    return data", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data, columns):\n    # Check if data is a pandas DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Data should be a pandas DataFrame\")\n\n    # Check if columns is a list\n    if not isinstance(columns, list):\n        raise ValueError(\"Columns should be a list\")\n\n    # Check if all elements in columns are strings\n    if not all(isinstance(col, str) for col in columns):\n        raise ValueError(\"All elements in columns should be strings\")\n\n    # Check if all columns in data are in columns\n    if not all(col in data.columns for col in columns):\n        raise ValueError(\"All columns in columns should be in data\")\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the specified columns\n    data[columns] = scaler.fit_transform(data[columns])\n\n    return data"}
{"task_id": "BigCodeBench/922", "solution": "import pandas as pd\nfrom nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(data, column):\n    # Check if the column exists in the DataFrame\n    if column not in data.columns:\n        raise ValueError(f\"Column {column} not found in DataFrame\")\n    \n    # Remove stopwords\n    data[column] = data[column].apply(lambda x: ' '.join([word for word in x.split() if word not in STOPWORDS]))\n    \n    return data", "raw_solution": "import pandas as pd\nfrom nltk.corpus import stopwords\n\n# Constants\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(data, column):\n    # Check if the column exists in the DataFrame\n    if column not in data.columns:\n        raise ValueError(f\"Column {column} not found in DataFrame\")\n    \n    # Remove stopwords\n    data[column] = data[column].apply(lambda x: ' '.join([word for word in x.split() if word not in STOPWORDS]))\n    \n    return data\n\n# Test the function\ndf = pd.DataFrame({\n    'text': ['This is a sample text with stopwords like is, at, and, or, but, can']\n})\n"}
{"task_id": "BigCodeBench/923", "solution": "import pandas as pd\nimport random\nimport re\ndef task_func(person_names, email_domains, num_records=5):\n    if not person_names or not email_domains:\n        raise ValueError(\"No names or email domains provided\")\n    if len(person_names) < num_records:\n        raise ValueError(\"Number of names provided is less than the number of records requested\")\n\n    names_list = random.choices(person_names, k=num_records)\n    emails_list = [re.sub(r'@', '[at]', name + '@' + random.choice(email_domains)) for name in names_list]\n\n    df = pd.DataFrame(list(zip(names_list, emails_list)), columns =['Name', 'Email'])\n    return df", "raw_solution": "import pandas as pd\nimport random\nimport re\n\ndef task_func(person_names, email_domains, num_records=5):\n    if not person_names or not email_domains:\n        raise ValueError(\"No names or email domains provided\")\n    if len(person_names) < num_records:\n        raise ValueError(\"Number of names provided is less than the number of records requested\")\n\n    names_list = random.choices(person_names, k=num_records)\n    emails_list = [re.sub(r'@', '[at]', name + '@' + random.choice(email_domains)) for name in names_list]\n\n    df = pd.DataFrame(list(zip(names_list, emails_list)), columns =['Name', 'Email'])\n    return df"}
{"task_id": "BigCodeBench/924", "solution": "import pandas as pd\nimport os\nimport sys\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    if not os.path.exists(file_path):\n        print(f\"File {file_path} does not exist.\")\n        sys.exit(1)\n\n    try:\n        df = pd.read_csv(file_path)\n    except Exception as e:\n        print(f\"Error reading file {file_path}: {str(e)}\")\n        sys.exit(1)\n\n    if column_name not in df.columns:\n        print(f\"Column {column_name} does not exist in the DataFrame.\")\n        sys.exit(1)\n\n    df[column_name] = df[column_name].apply(lambda x: str(x).replace('\\n', '<br>'))\n\n    return df", "raw_solution": "import pandas as pd\nimport os\nimport sys\n\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    if not os.path.exists(file_path):\n        print(f\"File {file_path} does not exist.\")\n        sys.exit(1)\n\n    try:\n        df = pd.read_csv(file_path)\n    except Exception as e:\n        print(f\"Error reading file {file_path}: {str(e)}\")\n        sys.exit(1)\n\n    if column_name not in df.columns:\n        print(f\"Column {column_name} does not exist in the DataFrame.\")\n        sys.exit(1)\n\n    df[column_name] = df[column_name].apply(lambda x: str(x).replace('\\n', '<br>'))\n\n    return df"}
{"task_id": "BigCodeBench/925", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(data_size=1000, column_names=['A', 'B', 'C', 'D', 'E'], seed=0):\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.randint(1, 101, size=(data_size, len(column_names))), columns=column_names)\n    df[df < 10] = -1\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(data_size=1000, column_names=['A', 'B', 'C', 'D', 'E'], seed=0):\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.randint(1, 101, size=(data_size, len(column_names))), columns=column_names)\n    df[df < 10] = -1\n    return df\n\n# Test the function\ndf = task_func()"}
{"task_id": "BigCodeBench/926", "solution": "import pandas as pd\nimport sqlite3\ndef task_func(db_path: str, table_name: str, column_name: str) -> pd.DataFrame:\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_path)\n\n    # Load data from the specified table into a DataFrame\n    df = pd.read_sql_query(f\"SELECT * from {table_name}\", conn)\n\n    # Replace all occurrences of '\\n' with '<br>' in the specified column\n    df[column_name] = df[column_name].apply(lambda x: str(x).replace('\\n', '<br>'))\n\n    # Close the database connection\n    conn.close()\n\n    # Return the modified DataFrame\n    return df", "raw_solution": "import pandas as pd\nimport sqlite3\n\ndef task_func(db_path: str, table_name: str, column_name: str) -> pd.DataFrame:\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_path)\n\n    # Load data from the specified table into a DataFrame\n    df = pd.read_sql_query(f\"SELECT * from {table_name}\", conn)\n\n    # Replace all occurrences of '\\n' with '<br>' in the specified column\n    df[column_name] = df[column_name].apply(lambda x: str(x).replace('\\n', '<br>'))\n\n    # Close the database connection\n    conn.close()\n\n    # Return the modified DataFrame\n    return df"}
{"task_id": "BigCodeBench/927", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    # Load CSV file into a DataFrame\n    df = pd.read_csv(file_path)\n\n    # Replace '\\n' with '<br>' in the specified column\n    df[column_name] = df[column_name].apply(lambda x: str(x).replace('\\n', '<br>'))\n\n    # Initialize LabelEncoder\n    le = LabelEncoder()\n\n    # Encode the specified column as a categorical variable\n    df[column_name] = le.fit_transform(df[column_name])\n\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    # Load CSV file into a DataFrame\n    df = pd.read_csv(file_path)\n\n    # Replace '\\n' with '<br>' in the specified column\n    df[column_name] = df[column_name].apply(lambda x: str(x).replace('\\n', '<br>'))\n\n    # Initialize LabelEncoder\n    le = LabelEncoder()\n\n    # Encode the specified column as a categorical variable\n    df[column_name] = le.fit_transform(df[column_name])\n\n    return df"}
{"task_id": "BigCodeBench/928", "solution": "from collections import Counter\nimport itertools\nimport string\ndef task_func(word: str) -> dict:\n    # Generate all possible two-letter combinations\n    combinations = [''.join(x) for x in itertools.product(string.ascii_lowercase, repeat=2)]\n\n    # Create a dictionary with all combinations and their counts\n    word_counter = Counter(word[i:i+2] for i in range(len(word)-1))\n    result = {key: word_counter[key] for key in combinations}\n\n    return result", "raw_solution": "from collections import Counter\nimport itertools\nimport string\n\ndef task_func(word: str) -> dict:\n    # Generate all possible two-letter combinations\n    combinations = [''.join(x) for x in itertools.product(string.ascii_lowercase, repeat=2)]\n\n    # Create a dictionary with all combinations and their counts\n    word_counter = Counter(word[i:i+2] for i in range(len(word)-1))\n    result = {key: word_counter[key] for key in combinations}\n\n    return result\n\n# Test the function"}
{"task_id": "BigCodeBench/929", "solution": "import numpy as np\nfrom scipy import stats\nimport math\ndef task_func(word: str) -> (np.ndarray, float):\n    # Calculate the difference between the ASCII values of each pair of adjacent letters\n    diffs = np.array([ord(word[i]) - ord(word[i-1]) for i in range(1, len(word))])\n    \n    # Calculate the entropy of the differences\n    # We use stats.entropy function from scipy to calculate entropy\n    # We need to provide probabilities, so we normalize the counts by the total number of differences\n    # We add a small constant to avoid taking logarithm of zero\n    probs = np.bincount(diffs) / len(diffs) + 1e-10\n    entropy = stats.entropy(probs)\n    \n    return diffs, entropy\nword = \"hello\"", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport math\n\ndef task_func(word: str) -> (np.ndarray, float):\n    # Calculate the difference between the ASCII values of each pair of adjacent letters\n    diffs = np.array([ord(word[i]) - ord(word[i-1]) for i in range(1, len(word))])\n    \n    # Calculate the entropy of the differences\n    # We use stats.entropy function from scipy to calculate entropy\n    # We need to provide probabilities, so we normalize the counts by the total number of differences\n    # We add a small constant to avoid taking logarithm of zero\n    probs = np.bincount(diffs) / len(diffs) + 1e-10\n    entropy = stats.entropy(probs)\n    \n    return diffs, entropy\n\n# Test the function\nword = \"hello\"\ndiffs, entropy = task_func(word)"}
{"task_id": "BigCodeBench/930", "solution": "import random\nimport string\nPOSSIBLE_LETTERS = ['a', 'b', 'c']\ndef task_func(word):\n    # Check if the input contains non-letter characters\n    if not all(char.isalpha() for char in word):\n        raise ValueError(\"Input contains non-letter characters\")\n\n    # If the word has fewer than 2 letters, return a list of empty strings\n    if len(word) < 2:\n        return [\"\"] * len(POSSIBLE_LETTERS)\n\n    # Generate a list of random pairs of adjacent letters from the word\n    pairs = [word[i:i+2] for i in range(len(word) - 1)]\n\n    # If the number of pairs is less than the length of POSSIBLE_LETTERS,\n    # return a list of empty strings\n    if len(pairs) < len(POSSIBLE_LETTERS):\n        return [\"\"] * len(POSSIBLE_LETTERS)\n\n    # Randomly select pairs from the list of pairs\n    random_pairs = random.sample(pairs, len(POSSIBLE_LETTERS))\n\n    return random_pairs", "raw_solution": "import random\nimport string\n\nPOSSIBLE_LETTERS = ['a', 'b', 'c']\n\ndef task_func(word):\n    # Check if the input contains non-letter characters\n    if not all(char.isalpha() for char in word):\n        raise ValueError(\"Input contains non-letter characters\")\n\n    # If the word has fewer than 2 letters, return a list of empty strings\n    if len(word) < 2:\n        return [\"\"] * len(POSSIBLE_LETTERS)\n\n    # Generate a list of random pairs of adjacent letters from the word\n    pairs = [word[i:i+2] for i in range(len(word) - 1)]\n\n    # If the number of pairs is less than the length of POSSIBLE_LETTERS,\n    # return a list of empty strings\n    if len(pairs) < len(POSSIBLE_LETTERS):\n        return [\"\"] * len(POSSIBLE_LETTERS)\n\n    # Randomly select pairs from the list of pairs\n    random_pairs = random.sample(pairs, len(POSSIBLE_LETTERS))\n\n    return random_pairs\n\n# Test the function"}
{"task_id": "BigCodeBench/931", "solution": "from collections import defaultdict\nimport re\ndef task_func(word: str) -> dict:\n    # sanitize the word by removing non-alphabetic characters\n    sanitized_word = re.sub(r'[^a-zA-Z]', '', word)\n\n    # create a defaultdict to store the two-letter combinations and their counts\n    two_letter_combinations = defaultdict(int)\n\n    # iterate over the sanitized word and find two-letter combinations\n    for i in range(len(sanitized_word) - 1):\n        two_letter_combination = sanitized_word[i:i+2]\n        two_letter_combinations[two_letter_combination] += 1\n\n    return two_letter_combinations\nword = \"Hello, World! This is a test.\"", "raw_solution": "from collections import defaultdict\nimport re\n\ndef task_func(word: str) -> dict:\n    # sanitize the word by removing non-alphabetic characters\n    sanitized_word = re.sub(r'[^a-zA-Z]', '', word)\n\n    # create a defaultdict to store the two-letter combinations and their counts\n    two_letter_combinations = defaultdict(int)\n\n    # iterate over the sanitized word and find two-letter combinations\n    for i in range(len(sanitized_word) - 1):\n        two_letter_combination = sanitized_word[i:i+2]\n        two_letter_combinations[two_letter_combination] += 1\n\n    return two_letter_combinations\n\n# test the function\nword = \"Hello, World! This is a test.\""}
{"task_id": "BigCodeBench/932", "solution": "from collections import Counter\nimport re\ndef task_func(word: str) -> list:\n    # Clean the word by removing non-alphabetic characters and lowercasing it\n    cleaned_word = re.sub(r'[^a-z]', '', word.lower())\n\n    # If the cleaned word has fewer than 2 letters, return an empty list\n    if len(cleaned_word) < 2:\n        return []\n\n    # Find all two-letter combinations in the cleaned word\n    two_letter_combinations = [cleaned_word[i:i+2] for i in range(len(cleaned_word)-1)]\n\n    # Count the frequency of each two-letter combination\n    counter = Counter(two_letter_combinations)\n\n    # Find the most common two-letter combination and its frequency\n    most_common = counter.most_common(1)\n\n    return most_common", "raw_solution": "from collections import Counter\nimport re\n\ndef task_func(word: str) -> list:\n    # Clean the word by removing non-alphabetic characters and lowercasing it\n    cleaned_word = re.sub(r'[^a-z]', '', word.lower())\n\n    # If the cleaned word has fewer than 2 letters, return an empty list\n    if len(cleaned_word) < 2:\n        return []\n\n    # Find all two-letter combinations in the cleaned word\n    two_letter_combinations = [cleaned_word[i:i+2] for i in range(len(cleaned_word)-1)]\n\n    # Count the frequency of each two-letter combination\n    counter = Counter(two_letter_combinations)\n\n    # Find the most common two-letter combination and its frequency\n    most_common = counter.most_common(1)\n\n    return most_common\n\n# Test the function"}
{"task_id": "BigCodeBench/933", "solution": "import string\nimport wordninja\ndef task_func(word):\n    alphabet = string.ascii_lowercase\n    alphabet_dict = {letter: index+1 for index, letter in enumerate(alphabet)}\n    word_list = wordninja.split(word)\n    result = []\n    for w in word_list:\n        temp = []\n        for letter in w:\n            if letter.isalpha():\n                temp.append((letter, alphabet_dict[letter.lower()]))\n            else:\n                temp.append((letter, None))\n        result.append(temp)\n    return result", "raw_solution": "import string\nimport wordninja\n\ndef task_func(word):\n    alphabet = string.ascii_lowercase\n    alphabet_dict = {letter: index+1 for index, letter in enumerate(alphabet)}\n    word_list = wordninja.split(word)\n    result = []\n    for w in word_list:\n        temp = []\n        for letter in w:\n            if letter.isalpha():\n                temp.append((letter, alphabet_dict[letter.lower()]))\n            else:\n                temp.append((letter, None))\n        result.append(temp)\n    return result\n\n# Test the function"}
{"task_id": "BigCodeBench/934", "solution": "from collections import Counter\nimport hashlib\ndef task_func(word: str) -> dict:\n    pairs = [word[i:i+2] for i in range(len(word)-1)]\n    count = Counter(pairs)\n    return count", "raw_solution": "from collections import Counter\nimport hashlib\n\ndef task_func(word: str) -> dict:\n    pairs = [word[i:i+2] for i in range(len(word)-1)]\n    count = Counter(pairs)\n    return count\n\ndef test_task_func():\n    word = \"mississippi\"\n    result = task_func(word)\n    assert result == {'mi': 1, 'ss': 2, 'is': 2, 'si': 2, 'ip': 1}, f\"Expected output: {{'mi': 1, 'ss': 2, 'is': 2, 'si': 2, 'ip': 1}}, but got {result}\"\n    print(\"All tests passed.\")\n\ntest_task_func()"}
{"task_id": "BigCodeBench/935", "solution": "import pandas as pd\nimport string\ndef task_func(word):\n    if not word.islower():\n        raise ValueError(\"Input word should be in lowercase.\")\n    if not word.isalpha():\n        raise ValueError(\"Input word should not contain non-alphabetic characters.\")\n    \n    alphabet = string.ascii_lowercase\n    position = {letter: index+1 for index, letter in enumerate(alphabet)}\n    data = [(letter, position[letter]) for letter in word]\n    df = pd.DataFrame(data, columns=['Letter', 'Position'])\n    return df", "raw_solution": "import pandas as pd\nimport string\n\ndef task_func(word):\n    if not word.islower():\n        raise ValueError(\"Input word should be in lowercase.\")\n    if not word.isalpha():\n        raise ValueError(\"Input word should not contain non-alphabetic characters.\")\n    \n    alphabet = string.ascii_lowercase\n    position = {letter: index+1 for index, letter in enumerate(alphabet)}\n    data = [(letter, position[letter]) for letter in word]\n    df = pd.DataFrame(data, columns=['Letter', 'Position'])\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/936", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport string\nALPHABET = list(string.ascii_lowercase)\ndef task_func(word):\n    # Convert the word to lowercase\n    word = word.lower()\n\n    # Create a list to store the positions of each letter in the word\n    positions = []\n\n    # Iterate over each letter in the word\n    for letter in word:\n        # If the letter is in the alphabet, get its position and add it to the list\n        if letter in ALPHABET:\n            positions.append(ALPHABET.index(letter) + 1)\n\n    # Create a numpy array from the list of positions\n    positions = np.array(positions)\n\n    # Create a histogram of the positions\n    counts, bins = np.histogram(positions, bins=range(1,27))\n\n    # Create a bar chart of the histogram\n    fig, ax = plt.subplots()\n    ax.bar(bins[:-1], counts, align='center')\n\n    # Set the x-axis label to 'Position'\n    ax.set_xlabel('Position')\n\n    # Set the y-axis label to 'Frequency'\n    ax.set_ylabel('Frequency')\n\n    # Set the title of the plot\n    ax.set_title('Positions of each letter in the word')\n\n    # Return the axes of the plot\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport string\n\n# Constants\nALPHABET = list(string.ascii_lowercase)\n\ndef task_func(word):\n    # Convert the word to lowercase\n    word = word.lower()\n\n    # Create a list to store the positions of each letter in the word\n    positions = []\n\n    # Iterate over each letter in the word\n    for letter in word:\n        # If the letter is in the alphabet, get its position and add it to the list\n        if letter in ALPHABET:\n            positions.append(ALPHABET.index(letter) + 1)\n\n    # Create a numpy array from the list of positions\n    positions = np.array(positions)\n\n    # Create a histogram of the positions\n    counts, bins = np.histogram(positions, bins=range(1,27))\n\n    # Create a bar chart of the histogram\n    fig, ax = plt.subplots()\n    ax.bar(bins[:-1], counts, align='center')\n\n    # Set the x-axis label to 'Position'\n    ax.set_xlabel('Position')\n\n    # Set the y-axis label to 'Frequency'\n    ax.set_ylabel('Frequency')\n\n    # Set the title of the plot\n    ax.set_title('Positions of each letter in the word')\n\n    # Return the axes of the plot\n    return ax"}
{"task_id": "BigCodeBench/937", "solution": "import re\nfrom collections import Counter\ndef task_func(input_str):\n    # Remove all non-alphanumeric characters and convert to lowercase\n    cleaned_str = re.sub(r'\\W+', '', input_str).lower()\n\n    # Count the frequency of each character\n    freq_dict = Counter(cleaned_str)\n\n    return dict(freq_dict)", "raw_solution": "import re\nfrom collections import Counter\n\ndef task_func(input_str):\n    # Remove all non-alphanumeric characters and convert to lowercase\n    cleaned_str = re.sub(r'\\W+', '', input_str).lower()\n\n    # Count the frequency of each character\n    freq_dict = Counter(cleaned_str)\n\n    return dict(freq_dict)\n\n# Test the function"}
{"task_id": "BigCodeBench/938", "solution": "import re\nimport pandas as pd\ndef task_func(input_df):\n    if 'text' not in input_df.columns:\n        raise ValueError(\"The DataFrame does not contain a column named 'text'\")\n\n    # Remove all special characters, punctuation marks, and spaces\n    input_df['clean_text'] = input_df['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n    input_df['clean_text'] = input_df['clean_text'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n\n    # Calculate the length of the cleaned text\n    input_df['text_length'] = input_df['clean_text'].apply(lambda x: len(x))\n\n    return input_df", "raw_solution": "import re\nimport pandas as pd\n\ndef task_func(input_df):\n    if 'text' not in input_df.columns:\n        raise ValueError(\"The DataFrame does not contain a column named 'text'\")\n\n    # Remove all special characters, punctuation marks, and spaces\n    input_df['clean_text'] = input_df['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n    input_df['clean_text'] = input_df['clean_text'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n\n    # Calculate the length of the cleaned text\n    input_df['text_length'] = input_df['clean_text'].apply(lambda x: len(x))\n\n    return input_df\n\n# Test the function\ndf = pd.DataFrame({'text': ['Hello, world!', 'This is a test.', 'What about you?']})"}
{"task_id": "BigCodeBench/939", "solution": "import re\nimport os\nimport glob\ndef task_func(dir_path: str) -> list:\n    # Get all files in the directory\n    files = glob.glob(dir_path + '/*')\n\n    new_names = []\n\n    for file in files:\n        # Get the base name of the file\n        base_name = os.path.basename(file)\n\n        # Remove special characters, punctuation marks, and spaces\n        new_name = re.sub(r'[^A-Za-z0-9]+', '', base_name)\n\n        # Append the new name to the list\n        new_names.append(new_name)\n\n    return new_names", "raw_solution": "import re\nimport os\nimport glob\n\ndef task_func(dir_path: str) -> list:\n    # Get all files in the directory\n    files = glob.glob(dir_path + '/*')\n\n    new_names = []\n\n    for file in files:\n        # Get the base name of the file\n        base_name = os.path.basename(file)\n\n        # Remove special characters, punctuation marks, and spaces\n        new_name = re.sub(r'[^A-Za-z0-9]+', '', base_name)\n\n        # Append the new name to the list\n        new_names.append(new_name)\n\n    return new_names"}
{"task_id": "BigCodeBench/940", "solution": "import re\nfrom nltk import word_tokenize\nfrom collections import Counter\ndef task_func(input_str):\n    # Remove all special characters, punctuation marks and spaces from the string\n    cleaned_str = re.sub(r'[^\\w\\s]', '', input_str)\n    cleaned_str = re.sub(r'\\_', '', cleaned_str)\n    cleaned_str = re.sub(r'\\s+', ' ', cleaned_str)\n\n    # Tokenize the string into words\n    words = word_tokenize(cleaned_str)\n\n    # Count the frequency of each word\n    word_freq = Counter(words)\n\n    return dict(word_freq)\ninput_str = \"Hello, world! This is a test. Test, test, test.\"", "raw_solution": "import re\nfrom nltk import word_tokenize\nfrom collections import Counter\n\ndef task_func(input_str):\n    # Remove all special characters, punctuation marks and spaces from the string\n    cleaned_str = re.sub(r'[^\\w\\s]', '', input_str)\n    cleaned_str = re.sub(r'\\_', '', cleaned_str)\n    cleaned_str = re.sub(r'\\s+', ' ', cleaned_str)\n\n    # Tokenize the string into words\n    words = word_tokenize(cleaned_str)\n\n    # Count the frequency of each word\n    word_freq = Counter(words)\n\n    return dict(word_freq)\n\n# Test the function\ninput_str = \"Hello, world! This is a test. Test, test, test.\""}
{"task_id": "BigCodeBench/941", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_date: str, periods: int, freq: str, random_seed: int = 0) -> (pd.DataFrame, plt.Axes):\n    np.random.seed(random_seed)\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    sales = np.random.randint(100, 500, size=periods)\n    df = pd.DataFrame({'Date': dates, 'Sales': sales})\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.plot(df['Date'], df['Sales'], marker='o')\n    ax.set_title('Sales Forecast')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    return df, ax.figure", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date: str, periods: int, freq: str, random_seed: int = 0) -> (pd.DataFrame, plt.Axes):\n    np.random.seed(random_seed)\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    sales = np.random.randint(100, 500, size=periods)\n    df = pd.DataFrame({'Date': dates, 'Sales': sales})\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.plot(df['Date'], df['Sales'], marker='o')\n    ax.set_title('Sales Forecast')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    return df, ax.figure\n\n# Test the function\ndf, fig = task_func('2022-01-01', 12, 'M')"}
{"task_id": "BigCodeBench/942", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Create a date range\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n\n    # Create a DataFrame\n    df = pd.DataFrame(dates, columns=['Date'])\n    df['Category'] = np.random.choice(categories, size=periods)\n    df['Sales'] = np.random.randint(100, 1000, size=periods)\n\n    # Plot the data\n    ax = df.groupby('Category')['Sales'].sum().plot(kind='bar', figsize=(10, 6))\n    ax.set_xlabel('Category')\n    ax.set_ylabel('Sales')\n    ax.set_title('Sales Report for Different Categories over a Period of Time')\n\n    return df, ax.figure", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Create a date range\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n\n    # Create a DataFrame\n    df = pd.DataFrame(dates, columns=['Date'])\n    df['Category'] = np.random.choice(categories, size=periods)\n    df['Sales'] = np.random.randint(100, 1000, size=periods)\n\n    # Plot the data\n    ax = df.groupby('Category')['Sales'].sum().plot(kind='bar', figsize=(10, 6))\n    ax.set_xlabel('Category')\n    ax.set_ylabel('Sales')\n    ax.set_title('Sales Report for Different Categories over a Period of Time')\n\n    return df, ax.figure\n\n# Test the function\ndf, fig = task_func()\nplt.show()"}
{"task_id": "BigCodeBench/943", "solution": "import pandas as pd\nimport numpy as np\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(start_date='2016-01-01', periods=24, freq='M', model='additive'):\n    # Generate a sales time-series\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    sales = np.random.randint(100, 500, size=periods)\n    time_series = pd.Series(sales, index=dates)\n\n    # Decompose the time-series\n    decomposition = seasonal_decompose(time_series, model=model)\n\n    # Return the trend, seasonal, and residual components\n    return {'trend': decomposition.trend, 'seasonal': decomposition.seasonal, 'residual': decomposition.resid}", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndef task_func(start_date='2016-01-01', periods=24, freq='M', model='additive'):\n    # Generate a sales time-series\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    sales = np.random.randint(100, 500, size=periods)\n    time_series = pd.Series(sales, index=dates)\n\n    # Decompose the time-series\n    decomposition = seasonal_decompose(time_series, model=model)\n\n    # Return the trend, seasonal, and residual components\n    return {'trend': decomposition.trend, 'seasonal': decomposition.seasonal, 'residual': decomposition.resid}\n\n# Test the function\nresult = task_func('2020-01-01', 24, 'M', 'multiplicative')"}
{"task_id": "BigCodeBench/944", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=0):\n    np.random.seed(seed)\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    prices = np.random.uniform(100, 500, size=periods)\n    df = pd.DataFrame({'Date': dates, 'Price': prices})\n    fig, ax = plt.subplots()\n    df.plot(x='Date', y='Price', ax=ax)\n    ax.set_title('Share Prices Over Time')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price')\n    return (df, ax.figure)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=0):\n    np.random.seed(seed)\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    prices = np.random.uniform(100, 500, size=periods)\n    df = pd.DataFrame({'Date': dates, 'Price': prices})\n    fig, ax = plt.subplots()\n    df.plot(x='Date', y='Price', ax=ax)\n    ax.set_title('Share Prices Over Time')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price')\n    return (df, ax.figure)\n\n# Test the function\ndf, fig = task_func()\nplt.show()"}
{"task_id": "BigCodeBench/945", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    if sales_data is None:\n        sales_data = pd.DataFrame(np.random.randint(1, 100, size=(periods, 1)), columns=['Sales'], \n                                 index=pd.date_range(start=start_date, periods=periods, freq=freq))\n    else:\n        sales_data = pd.DataFrame(sales_data, columns=['Sales'], \n                                 index=pd.date_range(start=start_date, periods=periods, freq=freq))\n\n    # Create a new column 'Time' to represent time step\n    sales_data['Time'] = range(1, len(sales_data) + 1)\n    sales_data = sales_data[['Time', 'Sales']]\n\n    # Fit a linear regression model\n    model = LinearRegression()\n    model.fit(sales_data[['Time']], sales_data['Sales'])\n\n    # Generate future time steps\n    future_time = pd.DataFrame(range(len(sales_data) + 1, len(sales_data) + len(sales_data)), columns=['Time'])\n\n    # Predict future sales\n    future_sales = model.predict(future_time)\n\n    return future_sales", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    if sales_data is None:\n        sales_data = pd.DataFrame(np.random.randint(1, 100, size=(periods, 1)), columns=['Sales'], \n                                 index=pd.date_range(start=start_date, periods=periods, freq=freq))\n    else:\n        sales_data = pd.DataFrame(sales_data, columns=['Sales'], \n                                 index=pd.date_range(start=start_date, periods=periods, freq=freq))\n\n    # Create a new column 'Time' to represent time step\n    sales_data['Time'] = range(1, len(sales_data) + 1)\n    sales_data = sales_data[['Time', 'Sales']]\n\n    # Fit a linear regression model\n    model = LinearRegression()\n    model.fit(sales_data[['Time']], sales_data['Sales'])\n\n    # Generate future time steps\n    future_time = pd.DataFrame(range(len(sales_data) + 1, len(sales_data) + len(sales_data)), columns=['Time'])\n\n    # Predict future sales\n    future_sales = model.predict(future_time)\n\n    return future_sales\n\n# Test the function"}
{"task_id": "BigCodeBench/946", "solution": "import numpy as np\nimport pandas as pd\nimport random\ndef task_func(rows=3, cols=2, min_val=0, max_val=100, seed=0):\n    np.random.seed(seed)\n    matrix = np.random.randint(min_val, max_val, size=(rows, cols))\n    df = pd.DataFrame(matrix)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nimport random\n\ndef task_func(rows=3, cols=2, min_val=0, max_val=100, seed=0):\n    np.random.seed(seed)\n    matrix = np.random.randint(min_val, max_val, size=(rows, cols))\n    df = pd.DataFrame(matrix)\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/947", "solution": "import numpy as np\nimport random\nfrom datetime import datetime, timedelta\ndef daterange(start_date, end_date):\n    for n in range(int ((end_date - start_date).days)):\n        yield start_date + timedelta(n)\ndef task_func(rows=3, columns=2, start_date=datetime(2021, 1, 1), end_date=datetime(2021, 12, 31), seed=0):\n    random.seed(seed)\n    date_list = list(daterange(start_date, end_date))\n    random.shuffle(date_list)\n    matrix = np.array(date_list).reshape(rows, columns)\n    return matrix", "raw_solution": "import numpy as np\nimport random\nfrom datetime import datetime, timedelta\n\ndef daterange(start_date, end_date):\n    for n in range(int ((end_date - start_date).days)):\n        yield start_date + timedelta(n)\n\ndef task_func(rows=3, columns=2, start_date=datetime(2021, 1, 1), end_date=datetime(2021, 12, 31), seed=0):\n    random.seed(seed)\n    date_list = list(daterange(start_date, end_date))\n    random.shuffle(date_list)\n    matrix = np.array(date_list).reshape(rows, columns)\n    return matrix\n\n# Test the function"}
{"task_id": "BigCodeBench/948", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(rows=3, columns=2, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    scaler = MinMaxScaler()\n    scaled_matrix = scaler.fit_transform(matrix)\n    return scaled_matrix", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(rows=3, columns=2, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    scaler = MinMaxScaler()\n    scaled_matrix = scaler.fit_transform(matrix)\n    return scaled_matrix\n\n# Test the function"}
{"task_id": "BigCodeBench/949", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(rows, columns, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    df = pd.DataFrame(np.random.rand(rows, columns))\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(rows, columns, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    df = pd.DataFrame(np.random.rand(rows, columns))\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/950", "solution": "import numpy as np\nfrom scipy.linalg import svd\ndef task_func(rows=3, columns=2, seed=0):\n    np.random.seed(seed)\n    A = np.random.rand(rows, columns)\n    U, s, Vh = svd(A)\n    return U, np.sort(s)[::-1], Vh", "raw_solution": "import numpy as np\nfrom scipy.linalg import svd\n\ndef task_func(rows=3, columns=2, seed=0):\n    np.random.seed(seed)\n    A = np.random.rand(rows, columns)\n    U, s, Vh = svd(A)\n    return U, np.sort(s)[::-1], Vh\n\n# Test the function\nU, s, Vh = task_func(5, 4, 0)"}
{"task_id": "BigCodeBench/951", "solution": "import pandas as pd\nimport numpy as np\nimport random\nfrom random import randint, seed\nCATEGORIES = ['Electronics', 'Clothing', 'Home & Kitchen', 'Books', 'Toys & Games']\ndef task_func(mystrings, n_products, seed=0):\n    random.seed(seed)\n    product_names = [name.replace(' ', '_') for name in mystrings]\n    categories = [random.choice(CATEGORIES) for _ in range(n_products)]\n    prices = np.random.normal(50, 10, n_products).round(2)\n\n    df = pd.DataFrame({\n        'Product_Name': product_names,\n        'Category': categories,\n        'Price': prices\n    })\n\n    return df\nmystrings = ['Laptop', 'T-Shirt', 'Fridge', 'Book', 'Lego Set']\nn_products = 5", "raw_solution": "import pandas as pd\nimport numpy as np\nimport random\nfrom random import randint, seed\n\n# Constants\nCATEGORIES = ['Electronics', 'Clothing', 'Home & Kitchen', 'Books', 'Toys & Games']\n\ndef task_func(mystrings, n_products, seed=0):\n    random.seed(seed)\n    product_names = [name.replace(' ', '_') for name in mystrings]\n    categories = [random.choice(CATEGORIES) for _ in range(n_products)]\n    prices = np.random.normal(50, 10, n_products).round(2)\n\n    df = pd.DataFrame({\n        'Product_Name': product_names,\n        'Category': categories,\n        'Price': prices\n    })\n\n    return df\n\n# Test the function\nmystrings = ['Laptop', 'T-Shirt', 'Fridge', 'Book', 'Lego Set']\nn_products = 5\ndf = task_func(mystrings, n_products)"}
{"task_id": "BigCodeBench/952", "solution": "import pandas as pd\nimport random\nfrom datetime import datetime\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks cannot be negative\")\n    if seed is not None:\n        random.seed(seed)\n    today = datetime.now().date()\n    data = []\n    for task in task_list:\n        task_name = task.replace(\" \", \"_\")\n        assigned_to = random.choice(employees)\n        data.append([task_name, assigned_to, today])\n    df = pd.DataFrame(data, columns=[\"Task Name\", \"Assigned To\", \"Due Date\"])\n    return df.head(n_tasks)\ntask_list = [\"Task 1\", \"Task 2\", \"Task 3\", \"Task 4\", \"Task 5\"]", "raw_solution": "import pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks cannot be negative\")\n    if seed is not None:\n        random.seed(seed)\n    today = datetime.now().date()\n    data = []\n    for task in task_list:\n        task_name = task.replace(\" \", \"_\")\n        assigned_to = random.choice(employees)\n        data.append([task_name, assigned_to, today])\n    df = pd.DataFrame(data, columns=[\"Task Name\", \"Assigned To\", \"Due Date\"])\n    return df.head(n_tasks)\n\n# Test the function\ntask_list = [\"Task 1\", \"Task 2\", \"Task 3\", \"Task 4\", \"Task 5\"]"}
{"task_id": "BigCodeBench/953", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(mystrings, folder_path, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n\n    if not os.path.exists(folder_path):\n        try:\n            os.makedirs(folder_path)\n        except FileNotFoundError:\n            raise FileNotFoundError(\"The provided directory path does not exist and cannot be created.\")\n\n    file_names = []\n    for mystring in mystrings:\n        data = np.random.rand(10)\n        plt.bar(range(1, 11), data)\n        plt.title(mystring)\n        plt.xlabel('Index')\n        plt.ylabel('Value')\n        file_name = mystring.replace(' ', '_') + '.png'\n        file_path = os.path.join(folder_path, file_name)\n        plt.savefig(file_path)\n        file_names.append(file_name)\n        plt.clf()\n\n    return file_names", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(mystrings, folder_path, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n\n    if not os.path.exists(folder_path):\n        try:\n            os.makedirs(folder_path)\n        except FileNotFoundError:\n            raise FileNotFoundError(\"The provided directory path does not exist and cannot be created.\")\n\n    file_names = []\n    for mystring in mystrings:\n        data = np.random.rand(10)\n        plt.bar(range(1, 11), data)\n        plt.title(mystring)\n        plt.xlabel('Index')\n        plt.ylabel('Value')\n        file_name = mystring.replace(' ', '_') + '.png'\n        file_path = os.path.join(folder_path, file_name)\n        plt.savefig(file_path)\n        file_names.append(file_name)\n        plt.clf()\n\n    return file_names"}
{"task_id": "BigCodeBench/954", "solution": "import random\nimport re\ndef task_func(target_words, n_sentences, vocabulary):\n    if n_sentences < 0:\n        raise ValueError(\"n_sentences cannot be negative\")\n    if not vocabulary:\n        raise ValueError(\"Vocabulary cannot be empty\")\n\n    result = []\n    for _ in range(n_sentences):\n        sentence = ' '.join(random.choices(vocabulary, k=10))\n        for word in target_words:\n            sentence = re.sub(r'\\b' + word + r'\\b', word.replace(' ', '_'), sentence, flags=re.IGNORECASE)\n        result.append(sentence.lower())\n    return result", "raw_solution": "import random\nimport re\n\ndef task_func(target_words, n_sentences, vocabulary):\n    if n_sentences < 0:\n        raise ValueError(\"n_sentences cannot be negative\")\n    if not vocabulary:\n        raise ValueError(\"Vocabulary cannot be empty\")\n\n    result = []\n    for _ in range(n_sentences):\n        sentence = ' '.join(random.choices(vocabulary, k=10))\n        for word in target_words:\n            sentence = re.sub(r'\\b' + word + r'\\b', word.replace(' ', '_'), sentence, flags=re.IGNORECASE)\n        result.append(sentence.lower())\n    return result"}
{"task_id": "BigCodeBench/955", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter\ndef task_func(mystrings, text):\n    if not text:\n        raise ValueError(\"Input text is empty\")\n\n    # Replace spaces with underscores\n    text = text.lower()\n    text = re.sub(r'\\s', '_', text)\n\n    # Split the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Count the frequency of each unique word\n    word_counts = Counter(words)\n\n    # Create a list of words and their corresponding counts\n    words = list(word_counts.keys())\n    counts = list(word_counts.values())\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    ax.bar(words, counts)\n\n    # Set the x-axis label and y-axis label\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n\n    # Rotate the x-axis labels for better readability\n    plt.xticks(rotation=90)\n\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter\n\ndef task_func(mystrings, text):\n    if not text:\n        raise ValueError(\"Input text is empty\")\n\n    # Replace spaces with underscores\n    text = text.lower()\n    text = re.sub(r'\\s', '_', text)\n\n    # Split the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Count the frequency of each unique word\n    word_counts = Counter(words)\n\n    # Create a list of words and their corresponding counts\n    words = list(word_counts.keys())\n    counts = list(word_counts.values())\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    ax.bar(words, counts)\n\n    # Set the x-axis label and y-axis label\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n\n    # Rotate the x-axis labels for better readability\n    plt.xticks(rotation=90)\n\n    return ax"}
{"task_id": "BigCodeBench/956", "solution": "import re\nimport string\nimport random\ndef task_func(text: str, seed=None) -> str:\n    if seed is not None:\n        random.seed(seed)\n\n    # Remove special characters\n    text = re.sub(r'[^\\w\\s]', '', text)\n\n    # Normalize whitespace\n    text = re.sub(r'\\s+', '_', text)\n    text = re.sub(r'_+', '__', text)\n    text = re.sub(r'__+', '___', text)\n\n    # Randomize casing\n    text = ''.join([char.upper() if random.random() < 0.5 else char.lower() for char in text])\n\n    return text", "raw_solution": "import re\nimport string\nimport random\n\ndef task_func(text: str, seed=None) -> str:\n    if seed is not None:\n        random.seed(seed)\n\n    # Remove special characters\n    text = re.sub(r'[^\\w\\s]', '', text)\n\n    # Normalize whitespace\n    text = re.sub(r'\\s+', '_', text)\n    text = re.sub(r'_+', '__', text)\n    text = re.sub(r'__+', '___', text)\n\n    # Randomize casing\n    text = ''.join([char.upper() if random.random() < 0.5 else char.lower() for char in text])\n\n    return text\n\n# Test the function"}
{"task_id": "BigCodeBench/957", "solution": "import string\nimport re\ndef task_func(text: str) -> tuple:\n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    \n    # Split the text into words\n    words = text.split()\n    \n    # Count the number of words, characters and unique characters\n    num_words = len(words)\n    num_chars = len(text.replace(\" \", \"\"))\n    num_unique_chars = len(set(text))\n    \n    return (num_words, num_chars, num_unique_chars)\ntext = \"Hello, world! This is a test.\"", "raw_solution": "import string\nimport re\n\ndef task_func(text: str) -> tuple:\n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    \n    # Split the text into words\n    words = text.split()\n    \n    # Count the number of words, characters and unique characters\n    num_words = len(words)\n    num_chars = len(text.replace(\" \", \"\"))\n    num_unique_chars = len(set(text))\n    \n    return (num_words, num_chars, num_unique_chars)\n\n# Test the function\ntext = \"Hello, world! This is a test.\""}
{"task_id": "BigCodeBench/958", "solution": "import random\nimport re\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    words = re.findall(r'\\b\\w+\\b', text)\n    for i in range(len(words)):\n        if len(words[i]) > 2:\n            middle = list(words[i][1:-1])\n            random.shuffle(middle)\n            words[i] = words[i][0] + ''.join(middle) + words[i][-1]\n    return ' '.join(words)", "raw_solution": "import random\nimport re\n\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    words = re.findall(r'\\b\\w+\\b', text)\n    for i in range(len(words)):\n        if len(words[i]) > 2:\n            middle = list(words[i][1:-1])\n            random.shuffle(middle)\n            words[i] = words[i][0] + ''.join(middle) + words[i][-1]\n    return ' '.join(words)\n\n# Test the function"}
{"task_id": "BigCodeBench/959", "solution": "import string\nimport random\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    def replacement_char(c):\n        if c.isalpha():\n            return random.choice(string.ascii_uppercase if c.isupper() else string.ascii_lowercase)\n        else:\n            return c\n\n    return ''.join(map(replacement_char, text))", "raw_solution": "import string\nimport random\n\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n\n    def replacement_char(c):\n        if c.isalpha():\n            return random.choice(string.ascii_uppercase if c.isupper() else string.ascii_lowercase)\n        else:\n            return c\n\n    return ''.join(map(replacement_char, text))\n\n# Testing the function"}
{"task_id": "BigCodeBench/960", "solution": "import string\nimport random\ndef task_func(text, seed=None):\n    if not text:\n        raise ValueError(\"Input text cannot be empty\")\n\n    random.seed(seed)\n\n    password = []\n    for char in text:\n        if char.isalpha():\n            password.append(chr(random.randint(97, 122)))\n        elif char.isdigit():\n            password.append(str(random.randint(0, 9)))\n        elif char.isspace():\n            password.append(str(random.choice([random.randint(0, 9), chr(random.randint(97, 122))])))\n        else:\n            password.append(char)\n\n    return ''.join(password)", "raw_solution": "import string\nimport random\n\ndef task_func(text, seed=None):\n    if not text:\n        raise ValueError(\"Input text cannot be empty\")\n\n    random.seed(seed)\n\n    password = []\n    for char in text:\n        if char.isalpha():\n            password.append(chr(random.randint(97, 122)))\n        elif char.isdigit():\n            password.append(str(random.randint(0, 9)))\n        elif char.isspace():\n            password.append(str(random.choice([random.randint(0, 9), chr(random.randint(97, 122))])))\n        else:\n            password.append(char)\n\n    return ''.join(password)\n\n# Testing the function"}
{"task_id": "BigCodeBench/961", "solution": "import os\nimport glob\nfrom collections import Counter\ndef task_func(directory, extensions=[\".txt\", \".docx\", \".xlsx\", \".csv\"], keep_zero=True):\n    if not os.path.exists(directory):\n        raise OSError(\"The specified directory does not exist.\")\n\n    counter = Counter()\n    for extension in extensions:\n        files = glob.glob(directory + '/**/*' + extension, recursive=True)\n        counter.update(files)\n\n    if not keep_zero:\n        counter = Counter({k: v for k, v in counter.items() if v > 0})\n\n    return counter", "raw_solution": "import os\nimport glob\nfrom collections import Counter\n\ndef task_func(directory, extensions=[\".txt\", \".docx\", \".xlsx\", \".csv\"], keep_zero=True):\n    if not os.path.exists(directory):\n        raise OSError(\"The specified directory does not exist.\")\n\n    counter = Counter()\n    for extension in extensions:\n        files = glob.glob(directory + '/**/*' + extension, recursive=True)\n        counter.update(files)\n\n    if not keep_zero:\n        counter = Counter({k: v for k, v in counter.items() if v > 0})\n\n    return counter"}
{"task_id": "BigCodeBench/962", "solution": "import os\nfrom pathlib import Path\nimport glob\nimport shutil\ndef task_func(source_directory: str, target_directory: str) -> int:\n    # Check if source directory exists\n    if not os.path.isdir(source_directory):\n        raise FileNotFoundError(f\"Source directory {source_directory} does not exist.\")\n\n    # Define the file extensions to be moved\n    extensions = [\".txt\", \".docx\", \".xlsx\", \".csv\"]\n\n    # Initialize counter for successfully moved files\n    moved_files_count = 0\n\n    # Iterate over all files in source directory and its subdirectories\n    for file_path in Path(source_directory).rglob('*'):\n        # Check if file has one of the specified extensions\n        if file_path.suffix in extensions:\n            # Define target file path\n            target_file_path = os.path.join(target_directory, file_path.name)\n            # Check if target file path already exists\n            if os.path.isfile(target_file_path):\n                # If target file path already exists, generate a new name for the file\n                base_name, extension = os.path.splitext(file_path.name)\n                i = 1\n                while os.path.isfile(target_file_path):\n                    target_file_path = os.path.join(target_directory, f\"{base_name}-{i}{extension}\")\n                    i += 1\n            # Move file to target directory\n            shutil.move(file_path, target_file_path)\n            moved_files_count += 1\n\n    return moved_files_count", "raw_solution": "import os\nfrom pathlib import Path\nimport glob\nimport shutil\n\ndef task_func(source_directory: str, target_directory: str) -> int:\n    # Check if source directory exists\n    if not os.path.isdir(source_directory):\n        raise FileNotFoundError(f\"Source directory {source_directory} does not exist.\")\n\n    # Define the file extensions to be moved\n    extensions = [\".txt\", \".docx\", \".xlsx\", \".csv\"]\n\n    # Initialize counter for successfully moved files\n    moved_files_count = 0\n\n    # Iterate over all files in source directory and its subdirectories\n    for file_path in Path(source_directory).rglob('*'):\n        # Check if file has one of the specified extensions\n        if file_path.suffix in extensions:\n            # Define target file path\n            target_file_path = os.path.join(target_directory, file_path.name)\n            # Check if target file path already exists\n            if os.path.isfile(target_file_path):\n                # If target file path already exists, generate a new name for the file\n                base_name, extension = os.path.splitext(file_path.name)\n                i = 1\n                while os.path.isfile(target_file_path):\n                    target_file_path = os.path.join(target_directory, f\"{base_name}-{i}{extension}\")\n                    i += 1\n            # Move file to target directory\n            shutil.move(file_path, target_file_path)\n            moved_files_count += 1\n\n    return moved_files_count"}
{"task_id": "BigCodeBench/963", "solution": "import os\nimport glob\nfrom pathlib import Path\nimport zipfile\ndef task_func(source_directory, target_directory, zip_name):\n    valid_extensions = ['.txt', '.docx', '.xlsx', '.csv']\n\n    # Check if source directory exists\n    if not os.path.isdir(source_directory):\n        raise OSError(f\"Source directory {source_directory} does not exist.\")\n\n    # Create target directory if it does not exist\n    if not os.path.isdir(target_directory):\n        os.makedirs(target_directory)\n\n    # Get all files with valid extensions from source directory\n    files_to_zip = []\n    for extension in valid_extensions:\n        files_to_zip.extend(glob.glob(f\"{source_directory}/*{extension}\"))\n\n    # Create zip file\n    zip_path = os.path.join(target_directory, f\"{zip_name}.zip\")\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file in files_to_zip:\n            zipf.write(file, arcname=Path(file).name)\n\n    return zip_path", "raw_solution": "import os\nimport glob\nfrom pathlib import Path\nimport zipfile\n\ndef task_func(source_directory, target_directory, zip_name):\n    valid_extensions = ['.txt', '.docx', '.xlsx', '.csv']\n\n    # Check if source directory exists\n    if not os.path.isdir(source_directory):\n        raise OSError(f\"Source directory {source_directory} does not exist.\")\n\n    # Create target directory if it does not exist\n    if not os.path.isdir(target_directory):\n        os.makedirs(target_directory)\n\n    # Get all files with valid extensions from source directory\n    files_to_zip = []\n    for extension in valid_extensions:\n        files_to_zip.extend(glob.glob(f\"{source_directory}/*{extension}\"))\n\n    # Create zip file\n    zip_path = os.path.join(target_directory, f\"{zip_name}.zip\")\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file in files_to_zip:\n            zipf.write(file, arcname=Path(file).name)\n\n    return zip_path"}
{"task_id": "BigCodeBench/964", "solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nimport docx\nimport csv\nimport zipfile\ndef task_func(source_directory: str, target_directory: str) -> int:\n    # Check if source directory exists\n    if not os.path.isdir(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n\n    # Get a list of files in the source directory\n    files = os.listdir(source_directory)\n\n    # Filter files by their extensions\n    txt_files = [f for f in files if f.endswith('.txt')]\n    docx_files = [f for f in files if f.endswith('.docx')]\n    xlsx_files = [f for f in files if f.endswith('.xlsx')]\n    csv_files = [f for f in files if f.endswith('.csv')]\n\n    # Initialize counter\n    count = 0\n\n    # Convert .txt files\n    for txt_file in txt_files:\n        # Read the text file\n        with open(os.path.join(source_directory, txt_file), 'r') as file:\n            data = file.read()\n\n        # Create a DataFrame\n        df = pd.DataFrame({'Text': [data]})\n\n        # Save the DataFrame as a CSV file\n        df.to_csv(os.path.join(target_directory, txt_file.replace('.txt', '.csv')), index=False)\n\n        # Increment the counter\n        count += 1\n\n    # Convert .docx files\n    for docx_file in docx_files:\n        # Load the Word document\n        doc = docx.Document(os.path.join(source_directory, docx_file))\n\n        # Extract the text\n        data = ' '.join([p.text for p in doc.paragraphs])\n\n        # Create a DataFrame\n        df = pd.DataFrame({'Text': [data]})\n\n        # Save the DataFrame as a CSV file\n        df.to_csv(os.path.join(target_directory, docx_file.replace('.docx', '.csv')), index=False)\n\n        # Increment the counter\n        count += 1\n\n    # Convert .xlsx files\n    for xlsx_file in xlsx_files:\n        # Load the Excel file\n        xls = pd.ExcelFile(os.path.join(source_directory, xlsx_file))\n\n        # Extract the text from each sheet\n        data = []\n        for sheet in xls.sheet_names:\n            df = xls.parse(sheet)\n            data.append(df.to_csv(index=False))\n\n        # Create a DataFrame\n        df = pd.DataFrame({'Text': data})\n\n        # Save the DataFrame as a CSV file\n        df.to_csv(os.path.join(target_directory, xlsx_file.replace('.xlsx', '.csv')), index=False)\n\n        # Increment the counter\n        count += 1\n\n    # Return the number of files successfully converted\n    return count", "raw_solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nimport docx\nimport csv\nimport zipfile\n\ndef task_func(source_directory: str, target_directory: str) -> int:\n    # Check if source directory exists\n    if not os.path.isdir(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n\n    # Get a list of files in the source directory\n    files = os.listdir(source_directory)\n\n    # Filter files by their extensions\n    txt_files = [f for f in files if f.endswith('.txt')]\n    docx_files = [f for f in files if f.endswith('.docx')]\n    xlsx_files = [f for f in files if f.endswith('.xlsx')]\n    csv_files = [f for f in files if f.endswith('.csv')]\n\n    # Initialize counter\n    count = 0\n\n    # Convert .txt files\n    for txt_file in txt_files:\n        # Read the text file\n        with open(os.path.join(source_directory, txt_file), 'r') as file:\n            data = file.read()\n\n        # Create a DataFrame\n        df = pd.DataFrame({'Text': [data]})\n\n        # Save the DataFrame as a CSV file\n        df.to_csv(os.path.join(target_directory, txt_file.replace('.txt', '.csv')), index=False)\n\n        # Increment the counter\n        count += 1\n\n    # Convert .docx files\n    for docx_file in docx_files:\n        # Load the Word document\n        doc = docx.Document(os.path.join(source_directory, docx_file))\n\n        # Extract the text\n        data = ' '.join([p.text for p in doc.paragraphs])\n\n        # Create a DataFrame\n        df = pd.DataFrame({'Text': [data]})\n\n        # Save the DataFrame as a CSV file\n        df.to_csv(os.path.join(target_directory, docx_file.replace('.docx', '.csv')), index=False)\n\n        # Increment the counter\n        count += 1\n\n    # Convert .xlsx files\n    for xlsx_file in xlsx_files:\n        # Load the Excel file\n        xls = pd.ExcelFile(os.path.join(source_directory, xlsx_file))\n\n        # Extract the text from each sheet\n        data = []\n        for sheet in xls.sheet_names:\n            df = xls.parse(sheet)\n            data.append(df.to_csv(index=False))\n\n        # Create a DataFrame\n        df = pd.DataFrame({'Text': data})\n\n        # Save the DataFrame as a CSV file\n        df.to_csv(os.path.join(target_directory, xlsx_file.replace('.xlsx', '.csv')), index=False)\n\n        # Increment the counter\n        count += 1\n\n    # Return the number of files successfully converted\n    return count"}
{"task_id": "BigCodeBench/965", "solution": "import os\nimport re\nimport shutil\ndef task_func(source_directory: str, target_directory: str, pattern: str = r\"\\d{4}\") -> int:\n    if not os.path.isdir(source_directory):\n        return 0\n\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n\n    files_moved = 0\n    for file_name in os.listdir(source_directory):\n        if re.search(pattern, file_name):\n            shutil.move(os.path.join(source_directory, file_name), target_directory)\n            files_moved += 1\n\n    return files_moved", "raw_solution": "import os\nimport re\nimport shutil\n\ndef task_func(source_directory: str, target_directory: str, pattern: str = r\"\\d{4}\") -> int:\n    if not os.path.isdir(source_directory):\n        return 0\n\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n\n    files_moved = 0\n    for file_name in os.listdir(source_directory):\n        if re.search(pattern, file_name):\n            shutil.move(os.path.join(source_directory, file_name), target_directory)\n            files_moved += 1\n\n    return files_moved"}
{"task_id": "BigCodeBench/966", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not df.select_dtypes(include=[pd.np.number]).empty:\n        raise ValueError(\"DataFrame contains non-numeric data\")\n\n    cumulative_sum_df = df.cumsum(axis=0)\n\n    fig, ax = plt.subplots()\n    cumulative_sum_df.plot(kind='bar', ax=ax)\n    ax.set_title('Cumulative Sum per Column')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Cumulative Sum')\n    plt.legend(loc='upper left')\n\n    return cumulative_sum_df, fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not df.select_dtypes(include=[pd.np.number]).empty:\n        raise ValueError(\"DataFrame contains non-numeric data\")\n\n    cumulative_sum_df = df.cumsum(axis=0)\n\n    fig, ax = plt.subplots()\n    cumulative_sum_df.plot(kind='bar', ax=ax)\n    ax.set_title('Cumulative Sum per Column')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Cumulative Sum')\n    plt.legend(loc='upper left')\n\n    return cumulative_sum_df, fig"}
{"task_id": "BigCodeBench/967", "solution": "import numpy as np\nfrom scipy import integrate\nimport matplotlib.pyplot as plt\ndef task_func(func, x_range=(-2, 2), num_points=1000):\n    x = np.linspace(*x_range, num_points)\n    y = [func(i) for i in x]\n    integral, error = integrate.cumtrapz(y, x, initial=0)\n\n    fig, ax1 = plt.subplots()\n\n    color = 'tab:red'\n    ax1.set_xlabel('x')\n    ax1.set_ylabel('f(x)', color=color)\n    ax1.plot(x, y, color=color, label=f'f(x) = {func.__name__}')\n    ax1.tick_params(axis='y', labelcolor=color)\n\n    ax2 = ax1.twinx()\n    color = 'tab:blue'\n    ax2.set_ylabel('Integral(f(x))', color=color)\n    ax2.plot(x, integral, color=color, label=f'Integral(f(x))')\n    ax2.tick_params(axis='y', labelcolor=color)\n\n    fig.tight_layout()\n    plt.legend()\n    plt.show()\n\n    return ax1, ax2", "raw_solution": "import numpy as np\nfrom scipy import integrate\nimport matplotlib.pyplot as plt\n\ndef task_func(func, x_range=(-2, 2), num_points=1000):\n    x = np.linspace(*x_range, num_points)\n    y = [func(i) for i in x]\n    integral, error = integrate.cumtrapz(y, x, initial=0)\n\n    fig, ax1 = plt.subplots()\n\n    color = 'tab:red'\n    ax1.set_xlabel('x')\n    ax1.set_ylabel('f(x)', color=color)\n    ax1.plot(x, y, color=color, label=f'f(x) = {func.__name__}')\n    ax1.tick_params(axis='y', labelcolor=color)\n\n    ax2 = ax1.twinx()\n    color = 'tab:blue'\n    ax2.set_ylabel('Integral(f(x))', color=color)\n    ax2.plot(x, integral, color=color, label=f'Integral(f(x))')\n    ax2.tick_params(axis='y', labelcolor=color)\n\n    fig.tight_layout()\n    plt.legend()\n    plt.show()\n\n    return ax1, ax2"}
{"task_id": "BigCodeBench/968", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame):\n        raise TypeError(\"Input data should be a pandas DataFrame\")\n    if data.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not any(data.dtypes == 'float64') and not any(data.dtypes == 'int64'):\n        raise ValueError(\"No numeric columns are present in the DataFrame\")\n\n    numeric_data = data.select_dtypes(include=[np.number])\n    cumulative_sum_data = numeric_data.cumsum(axis=0)\n\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cumulative_sum_data, cmap=\"YlGnBu\", annot=True, fmt=\".0f\")\n    plt.title(\"Heatmap of Cumulative Sum of Each Column\")\n    plt.show()\n\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame):\n        raise TypeError(\"Input data should be a pandas DataFrame\")\n    if data.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if not any(data.dtypes == 'float64') and not any(data.dtypes == 'int64'):\n        raise ValueError(\"No numeric columns are present in the DataFrame\")\n\n    numeric_data = data.select_dtypes(include=[np.number])\n    cumulative_sum_data = numeric_data.cumsum(axis=0)\n\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cumulative_sum_data, cmap=\"YlGnBu\", annot=True, fmt=\".0f\")\n    plt.title(\"Heatmap of Cumulative Sum of Each Column\")\n    plt.show()\n\n    return plt.gca()"}
{"task_id": "BigCodeBench/969", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"Input should be a pandas DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if df.isnull().values.any():\n        raise ValueError(\"DataFrame contains NaN values\")\n    if not df.select_dtypes(include=[np.number]).empty:\n        raise TypeError(\"DataFrame contains non-numeric data types\")\n\n    scaler = MinMaxScaler()\n    df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    return df_normalized.cumsum()", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"Input should be a pandas DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if df.isnull().values.any():\n        raise ValueError(\"DataFrame contains NaN values\")\n    if not df.select_dtypes(include=[np.number]).empty:\n        raise TypeError(\"DataFrame contains non-numeric data types\")\n\n    scaler = MinMaxScaler()\n    df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n    return df_normalized.cumsum()"}
{"task_id": "BigCodeBench/970", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data: np.ndarray) -> plt.Axes:\n    if not isinstance(data, np.ndarray):\n        raise TypeError(\"Input data should be a NumPy array.\")\n    if np.issubdtype(data.dtype, np.number):\n        raise ValueError(\"Input data should not contain negative numbers or NaNs.\")\n    if np.isnan(data).any():\n        raise ValueError(\"Input data should not contain negative numbers or NaNs.\")\n    if (data < 0).any():\n        raise ValueError(\"Input data should not contain negative numbers or NaNs.\")\n\n    sorted_indices = np.argsort(data)\n    yvals = np.arange(len(data)) / float(len(data) - 1)\n\n    plt.figure()\n    ax = plt.gca()\n    ax.plot(sorted_indices, yvals, marker='o', linestyle='-')\n    plt.title(\"Cumulative Probability Plot\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Cumulative Probability\")\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data: np.ndarray) -> plt.Axes:\n    if not isinstance(data, np.ndarray):\n        raise TypeError(\"Input data should be a NumPy array.\")\n    if np.issubdtype(data.dtype, np.number):\n        raise ValueError(\"Input data should not contain negative numbers or NaNs.\")\n    if np.isnan(data).any():\n        raise ValueError(\"Input data should not contain negative numbers or NaNs.\")\n    if (data < 0).any():\n        raise ValueError(\"Input data should not contain negative numbers or NaNs.\")\n\n    sorted_indices = np.argsort(data)\n    yvals = np.arange(len(data)) / float(len(data) - 1)\n\n    plt.figure()\n    ax = plt.gca()\n    ax.plot(sorted_indices, yvals, marker='o', linestyle='-')\n    plt.title(\"Cumulative Probability Plot\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Cumulative Probability\")\n    return ax"}
{"task_id": "BigCodeBench/971", "solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\ndef task_func(directory_path: str):\n    if not os.path.exists(directory_path):\n        raise ValueError(\"The provided directory does not exist.\")\n\n    result = []\n    for file_name in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, file_name)\n        if os.path.isfile(file_path):\n            file_size = os.path.getsize(file_path)\n            creation_time = os.path.getctime(file_path)\n            modification_time = os.path.getmtime(file_path)\n            creation_time = datetime.fromtimestamp(creation_time, tz=timezone.utc).isoformat()\n            modification_time = datetime.fromtimestamp(modification_time, tz=timezone.utc).isoformat()\n            result.append((file_name, file_size, creation_time, modification_time))\n    return result", "raw_solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\n\ndef task_func(directory_path: str):\n    if not os.path.exists(directory_path):\n        raise ValueError(\"The provided directory does not exist.\")\n\n    result = []\n    for file_name in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, file_name)\n        if os.path.isfile(file_path):\n            file_size = os.path.getsize(file_path)\n            creation_time = os.path.getctime(file_path)\n            modification_time = os.path.getmtime(file_path)\n            creation_time = datetime.fromtimestamp(creation_time, tz=timezone.utc).isoformat()\n            modification_time = datetime.fromtimestamp(modification_time, tz=timezone.utc).isoformat()\n            result.append((file_name, file_size, creation_time, modification_time))\n    return result"}
{"task_id": "BigCodeBench/972", "solution": "import pathlib\nimport os\ndef task_func(path: str, delimiter: str = os.path.sep) -> list:\n    invalid_chars = ['<', '>', ':', '\"', '|', '?', '*']\n    for char in invalid_chars:\n        if char in path:\n            raise ValueError(\"Invalid character in path\")\n    path = path.replace('\\\\', '/')\n    return path.split(delimiter)", "raw_solution": "import pathlib\nimport os\n\ndef task_func(path: str, delimiter: str = os.path.sep) -> list:\n    invalid_chars = ['<', '>', ':', '\"', '|', '?', '*']\n    for char in invalid_chars:\n        if char in path:\n            raise ValueError(\"Invalid character in path\")\n    path = path.replace('\\\\', '/')\n    return path.split(delimiter)\n\n# Test cases"}
{"task_id": "BigCodeBench/973", "solution": "import os\nimport shutil\ndef task_func(path, delimiter=\"/\"):\n    if not isinstance(path, str):\n        raise ValueError(\"Path must be a string\")\n    if not path:\n        raise ValueError(\"Path cannot be empty\")\n    if delimiter not in path:\n        raise ValueError(\"Invalid path\")\n    if not os.path.exists(path):\n        raise FileNotFoundError(\"Path does not exist\")\n\n    components = path.split(delimiter)\n    result = []\n\n    for component in components:\n        if not component:\n            continue\n        usage = shutil.disk_usage(component)\n        result.append((component, {'total': usage.total, 'used': usage.used, 'free': usage.free}))\n\n    return result", "raw_solution": "import os\nimport shutil\n\ndef task_func(path, delimiter=\"/\"):\n    if not isinstance(path, str):\n        raise ValueError(\"Path must be a string\")\n    if not path:\n        raise ValueError(\"Path cannot be empty\")\n    if delimiter not in path:\n        raise ValueError(\"Invalid path\")\n    if not os.path.exists(path):\n        raise FileNotFoundError(\"Path does not exist\")\n\n    components = path.split(delimiter)\n    result = []\n\n    for component in components:\n        if not component:\n            continue\n        usage = shutil.disk_usage(component)\n        result.append((component, {'total': usage.total, 'used': usage.used, 'free': usage.free}))\n\n    return result"}
{"task_id": "BigCodeBench/974", "solution": "import shutil\nimport pathlib\nimport os\ndef task_func(source_path, destination_path):\n    source_path = pathlib.Path(source_path)\n    destination_path = pathlib.Path(destination_path)\n\n    if not source_path.exists():\n        raise ValueError(\"Source path does not exist\")\n    if not source_path.is_dir():\n        raise ValueError(\"Source path is not a directory\")\n\n    copied_files = []\n    for file in source_path.iterdir():\n        if file.is_file():\n            shutil.copy2(file, destination_path)\n            copied_files.append(file.name)\n\n    return (source_path.name, copied_files)", "raw_solution": "import shutil\nimport pathlib\nimport os\n\ndef task_func(source_path, destination_path):\n    source_path = pathlib.Path(source_path)\n    destination_path = pathlib.Path(destination_path)\n\n    if not source_path.exists():\n        raise ValueError(\"Source path does not exist\")\n    if not source_path.is_dir():\n        raise ValueError(\"Source path is not a directory\")\n\n    copied_files = []\n    for file in source_path.iterdir():\n        if file.is_file():\n            shutil.copy2(file, destination_path)\n            copied_files.append(file.name)\n\n    return (source_path.name, copied_files)"}
{"task_id": "BigCodeBench/975", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(rows, columns=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=0) -> pd.DataFrame:\n    np.random.seed(seed)\n    data = np.random.rand(rows, len(columns))\n    df = pd.DataFrame(data, columns=columns)\n    df = df.reindex(np.random.permutation(df.columns))\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(rows, columns=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=0) -> pd.DataFrame:\n    np.random.seed(seed)\n    data = np.random.rand(rows, len(columns))\n    df = pd.DataFrame(data, columns=columns)\n    df = df.reindex(np.random.permutation(df.columns))\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/976", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(records: np.ndarray, random_seed: int = 0) -> pd.DataFrame:\n    if len(records.shape) != 2:\n        raise ValueError(\"records must be a 2D array\")\n\n    np.random.seed(random_seed)\n    np.random.shuffle(records)\n\n    scaler = StandardScaler()\n    records = scaler.fit_transform(records)\n\n    feature_names = [f'f{i+1}' for i in range(records.shape[1])]\n    np.random.shuffle(feature_names)\n\n    df = pd.DataFrame(records, columns=feature_names)\n\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(records: np.ndarray, random_seed: int = 0) -> pd.DataFrame:\n    if len(records.shape) != 2:\n        raise ValueError(\"records must be a 2D array\")\n\n    np.random.seed(random_seed)\n    np.random.shuffle(records)\n\n    scaler = StandardScaler()\n    records = scaler.fit_transform(records)\n\n    feature_names = [f'f{i+1}' for i in range(records.shape[1])]\n    np.random.shuffle(feature_names)\n\n    df = pd.DataFrame(records, columns=feature_names)\n\n    return df"}
{"task_id": "BigCodeBench/977", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(array, features=None, seed=None):\n    if len(array.shape) != 2:\n        raise ValueError(\"Array must be 2-dimensional\")\n    if array.size == 0:\n        raise ValueError(\"Array must not be empty\")\n    if features is not None and len(features) != array.shape[1]:\n        raise ValueError(\"Features must match the number of columns in the array\")\n\n    if seed is not None:\n        np.random.seed(seed)\n    array_shuffled = np.random.permutation(array.T).T\n\n    fig, ax = plt.subplots()\n    if features is None:\n        features = list(range(1, array.shape[1]+1))\n    sns.heatmap(array_shuffled, annot=True, fmt=\".2f\", cmap='viridis', xticklabels=features, yticklabels=list(range(1, array.shape[0]+1)), ax=ax)\n    plt.xlabel('Columns')\n    plt.ylabel('Rows')\n    plt.title('Shuffled 2D Array Heatmap')\n    plt.show()\n\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(array, features=None, seed=None):\n    if len(array.shape) != 2:\n        raise ValueError(\"Array must be 2-dimensional\")\n    if array.size == 0:\n        raise ValueError(\"Array must not be empty\")\n    if features is not None and len(features) != array.shape[1]:\n        raise ValueError(\"Features must match the number of columns in the array\")\n\n    if seed is not None:\n        np.random.seed(seed)\n    array_shuffled = np.random.permutation(array.T).T\n\n    fig, ax = plt.subplots()\n    if features is None:\n        features = list(range(1, array.shape[1]+1))\n    sns.heatmap(array_shuffled, annot=True, fmt=\".2f\", cmap='viridis', xticklabels=features, yticklabels=list(range(1, array.shape[0]+1)), ax=ax)\n    plt.xlabel('Columns')\n    plt.ylabel('Rows')\n    plt.title('Shuffled 2D Array Heatmap')\n    plt.show()\n\n    return ax"}
{"task_id": "BigCodeBench/978", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\ndef task_func(array, seed=None):\n    if len(array.shape) != 2:\n        raise ValueError(\"Input array must be 2D\")\n    if array.size == 0:\n        return pd.DataFrame()\n\n    np.random.seed(seed)\n    np.random.shuffle(array.T)\n\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(array)\n\n    df = pd.DataFrame(data=principalComponents, columns=['PC1', 'PC2'])\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\ndef task_func(array, seed=None):\n    if len(array.shape) != 2:\n        raise ValueError(\"Input array must be 2D\")\n    if array.size == 0:\n        return pd.DataFrame()\n\n    np.random.seed(seed)\n    np.random.shuffle(array.T)\n\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(array)\n\n    df = pd.DataFrame(data=principalComponents, columns=['PC1', 'PC2'])\n    return df"}
{"task_id": "BigCodeBench/979", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils import shuffle\ndef task_func(\n    feature_array,\n    target_array,\n    feature_names=[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\"],\n    target_name=\"target\",\n    seed=None,\n):\n    # Shuffle the data\n    feature_array, target_array = shuffle(feature_array, target_array, random_state=seed)\n\n    # Create a DataFrame\n    df = pd.DataFrame(data=np.column_stack((feature_array, target_array)), \n                      columns=feature_names + [target_name])\n\n    # Split the data into features and target\n    X = df[feature_names]\n    y = df[target_name]\n\n    # Train a Random Forest Classifier\n    clf = RandomForestClassifier(random_state=seed)\n    clf.fit(X, y)\n\n    return clf", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils import shuffle\n\ndef task_func(\n    feature_array,\n    target_array,\n    feature_names=[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\"],\n    target_name=\"target\",\n    seed=None,\n):\n    # Shuffle the data\n    feature_array, target_array = shuffle(feature_array, target_array, random_state=seed)\n\n    # Create a DataFrame\n    df = pd.DataFrame(data=np.column_stack((feature_array, target_array)), \n                      columns=feature_names + [target_name])\n\n    # Split the data into features and target\n    X = df[feature_names]\n    y = df[target_name]\n\n    # Train a Random Forest Classifier\n    clf = RandomForestClassifier(random_state=seed)\n    clf.fit(X, y)\n\n    return clf"}
{"task_id": "BigCodeBench/980", "solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\ndef task_func(df):\n    # Check if DataFrame is empty\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n\n    # Check if there are any numeric columns\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if not numeric_cols.any():\n        raise ValueError(\"No numeric columns are present\")\n\n    # Compute correlation matrix\n    corr = df[numeric_cols].corr()\n\n    # Plot heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, fmt=\".2f\")\n    plt.show()\n\n    # Standardize numeric columns\n    scaler = StandardScaler()\n    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n\n    return df", "raw_solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\ndef task_func(df):\n    # Check if DataFrame is empty\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n\n    # Check if there are any numeric columns\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if not numeric_cols.any():\n        raise ValueError(\"No numeric columns are present\")\n\n    # Compute correlation matrix\n    corr = df[numeric_cols].corr()\n\n    # Plot heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, fmt=\".2f\")\n    plt.show()\n\n    # Standardize numeric columns\n    scaler = StandardScaler()\n    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n\n    return df"}
{"task_id": "BigCodeBench/981", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nimport random\ndef task_func(start_date, end_date, num_series, seed=None):\n    # Check if start_date is later than end_date\n    if start_date > end_date:\n        raise ValueError(\"start_date cannot be later than end_date\")\n\n    # Check if num_series is less than 1\n    if num_series < 1:\n        raise ValueError(\"num_series must be greater than 0\")\n\n    # Set the random seed if provided\n    if seed is not None:\n        random.seed(seed)\n\n    # Generate dates\n    dates = pd.date_range(start=start_date, end=end_date)\n\n    # Generate random integer time series\n    data = {f'series_{i+1}': [random.randint(0, 100) for _ in range(len(dates))] for i in range(num_series)}\n\n    # Create DataFrame\n    df = pd.DataFrame(data, index=dates)\n\n    # Plot the time series\n    fig, ax = plt.subplots()\n    ax.plot(df)\n    ax.set_title(\"Random Time Series\")\n    ax.set_xlabel(\"Date\")\n    ax.set_ylabel(\"Value\")\n    ax.legend(df.columns, title=\"Series\")\n\n    return df, ax.figure\nstart_date = datetime.now()\nend_date = datetime.now() + timedelta(days=10)", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nimport random\n\ndef task_func(start_date, end_date, num_series, seed=None):\n    # Check if start_date is later than end_date\n    if start_date > end_date:\n        raise ValueError(\"start_date cannot be later than end_date\")\n\n    # Check if num_series is less than 1\n    if num_series < 1:\n        raise ValueError(\"num_series must be greater than 0\")\n\n    # Set the random seed if provided\n    if seed is not None:\n        random.seed(seed)\n\n    # Generate dates\n    dates = pd.date_range(start=start_date, end=end_date)\n\n    # Generate random integer time series\n    data = {f'series_{i+1}': [random.randint(0, 100) for _ in range(len(dates))] for i in range(num_series)}\n\n    # Create DataFrame\n    df = pd.DataFrame(data, index=dates)\n\n    # Plot the time series\n    fig, ax = plt.subplots()\n    ax.plot(df)\n    ax.set_title(\"Random Time Series\")\n    ax.set_xlabel(\"Date\")\n    ax.set_ylabel(\"Value\")\n    ax.legend(df.columns, title=\"Series\")\n\n    return df, ax.figure\n\n# Test the function\nstart_date = datetime.now()\nend_date = datetime.now() + timedelta(days=10)\ndf, fig = task_func(start_date, end_date, 5)\nplt.show()"}
{"task_id": "BigCodeBench/982", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nimport pandas as pd\ndef task_func(df, column, bins=30, density=True, alpha=0.6, color=\"g\", seed=None):\n    # Check if the column exists in the dataframe\n    if column not in df.columns:\n        raise ValueError(f\"Column {column} not found in the dataframe\")\n\n    # Set the seed for reproducibility\n    if seed is not None:\n        np.random.seed(seed)\n\n    # Get the data from the specified column\n    data = df[column].dropna()\n\n    # Create the histogram\n    plt.figure(figsize=(10, 6))\n    plt.hist(data, bins=bins, density=density, alpha=alpha, color=color, label='Histogram')\n\n    # Fit a normal distribution to the data\n    mu, sigma = norm.fit(data)\n\n    # Prepare the range for the normal distribution\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n\n    # Create the normal distribution\n    p = norm.pdf(x, mu, sigma)\n\n    # Overlay the normal distribution on the histogram\n    plt.plot(x, p, 'k', linewidth=2, label='Normal distribution')\n\n    # Add legend\n    plt.legend()\n\n    # Return the axes object\n    return plt.gca()\ndf = pd.DataFrame({'A': np.random.normal(0, 1, 1000)})", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nimport pandas as pd\n\ndef task_func(df, column, bins=30, density=True, alpha=0.6, color=\"g\", seed=None):\n    # Check if the column exists in the dataframe\n    if column not in df.columns:\n        raise ValueError(f\"Column {column} not found in the dataframe\")\n\n    # Set the seed for reproducibility\n    if seed is not None:\n        np.random.seed(seed)\n\n    # Get the data from the specified column\n    data = df[column].dropna()\n\n    # Create the histogram\n    plt.figure(figsize=(10, 6))\n    plt.hist(data, bins=bins, density=density, alpha=alpha, color=color, label='Histogram')\n\n    # Fit a normal distribution to the data\n    mu, sigma = norm.fit(data)\n\n    # Prepare the range for the normal distribution\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n\n    # Create the normal distribution\n    p = norm.pdf(x, mu, sigma)\n\n    # Overlay the normal distribution on the histogram\n    plt.plot(x, p, 'k', linewidth=2, label='Normal distribution')\n\n    # Add legend\n    plt.legend()\n\n    # Return the axes object\n    return plt.gca()\n\n# Test the function\ndf = pd.DataFrame({'A': np.random.normal(0, 1, 1000)})\nax = task_func(df, 'A', seed=0)\nplt.show()"}
{"task_id": "BigCodeBench/983", "solution": "import seaborn as sns\nimport pandas as pd\nimport numpy as np\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"The DataFrame is empty.\")\n    if not np.issubdtype(df.dtypes, np.number).all():\n        raise TypeError(\"The DataFrame contains non-numeric data types.\")\n\n    covariance_df = df.cov()\n    pair_plot = sns.pairplot(df)\n\n    return covariance_df, pair_plot", "raw_solution": "import seaborn as sns\nimport pandas as pd\nimport numpy as np\n\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"The DataFrame is empty.\")\n    if not np.issubdtype(df.dtypes, np.number).all():\n        raise TypeError(\"The DataFrame contains non-numeric data types.\")\n\n    covariance_df = df.cov()\n    pair_plot = sns.pairplot(df)\n\n    return covariance_df, pair_plot"}
{"task_id": "BigCodeBench/984", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, x_column, y_column):\n    # Check if the columns exist in the dataframe\n    if x_column not in df.columns or y_column not in df.columns:\n        raise ValueError(\"One or both of the columns do not exist in the dataframe\")\n\n    # Create a scatter plot\n    plt.scatter(df[x_column], df[y_column])\n\n    # Fit a linear regression model\n    model = LinearRegression()\n    model.fit(df[[x_column]], df[y_column])\n\n    # Create a line for the regression line\n    x_range = np.linspace(df[x_column].min(), df[x_column].max(), 100)\n    y_range = model.predict(x_range.reshape(-1, 1))\n\n    # Plot the regression line\n    plt.plot(x_range, y_range, color='red')\n\n    return plt.gca()\ndf = pd.DataFrame({\n    'x': np.random.rand(100),\n    'y': np.random.rand(100)\n})", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, x_column, y_column):\n    # Check if the columns exist in the dataframe\n    if x_column not in df.columns or y_column not in df.columns:\n        raise ValueError(\"One or both of the columns do not exist in the dataframe\")\n\n    # Create a scatter plot\n    plt.scatter(df[x_column], df[y_column])\n\n    # Fit a linear regression model\n    model = LinearRegression()\n    model.fit(df[[x_column]], df[y_column])\n\n    # Create a line for the regression line\n    x_range = np.linspace(df[x_column].min(), df[x_column].max(), 100)\n    y_range = model.predict(x_range.reshape(-1, 1))\n\n    # Plot the regression line\n    plt.plot(x_range, y_range, color='red')\n\n    return plt.gca()\n\n# Test the function\ndf = pd.DataFrame({\n    'x': np.random.rand(100),\n    'y': np.random.rand(100)\n})\n\ntask_func(df, 'x', 'y')"}
{"task_id": "BigCodeBench/985", "solution": "import pandas as pd\nimport json\nimport os\nimport math\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    try:\n        # Check if JSON data is malformed\n        json_data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"The JSON data is malformed.\")\n\n    # Check if JSON data is empty\n    if not json_data:\n        raise ValueError(\"The JSON data is empty.\")\n\n    # Create a DataFrame from the JSON data\n    df = pd.DataFrame(json_data)\n\n    # Check if country names are non-string\n    if not all(df['Country'].apply(lambda x: isinstance(x, str))):\n        raise ValueError(\"Non-string country names are not allowed.\")\n\n    # Check if populations are non-numeric or negative\n    if not all(df['Population'].apply(lambda x: isinstance(x, (int, float)) and x >= 0)):\n        raise ValueError(\"Non-numeric or negative populations are not allowed.\")\n\n    # Round down the population to the nearest integer\n    df['Population'] = df['Population'].apply(lambda x: math.floor(x))\n\n    # Create the output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Save the DataFrame to a CSV file\n    file_path = os.path.join(output_dir, file_name)\n    try:\n        df.to_csv(file_path, index=False)\n    except IOError:\n        raise IOError(\"The file cannot be written to the specified directory.\")\n\n    return file_path, df", "raw_solution": "import pandas as pd\nimport json\nimport os\nimport math\n\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    try:\n        # Check if JSON data is malformed\n        json_data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"The JSON data is malformed.\")\n\n    # Check if JSON data is empty\n    if not json_data:\n        raise ValueError(\"The JSON data is empty.\")\n\n    # Create a DataFrame from the JSON data\n    df = pd.DataFrame(json_data)\n\n    # Check if country names are non-string\n    if not all(df['Country'].apply(lambda x: isinstance(x, str))):\n        raise ValueError(\"Non-string country names are not allowed.\")\n\n    # Check if populations are non-numeric or negative\n    if not all(df['Population'].apply(lambda x: isinstance(x, (int, float)) and x >= 0)):\n        raise ValueError(\"Non-numeric or negative populations are not allowed.\")\n\n    # Round down the population to the nearest integer\n    df['Population'] = df['Population'].apply(lambda x: math.floor(x))\n\n    # Create the output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Save the DataFrame to a CSV file\n    file_path = os.path.join(output_dir, file_name)\n    try:\n        df.to_csv(file_path, index=False)\n    except IOError:\n        raise IOError(\"The file cannot be written to the specified directory.\")\n\n    return file_path, df"}
{"task_id": "BigCodeBench/986", "solution": "import json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\ndef task_func(json_data: str, key_path: list):\n    data = json.loads(json_data)\n    for key in key_path:\n        try:\n            data = data[key]\n        except KeyError:\n            raise KeyError(f\"Key '{key}' not found in JSON data.\")\n\n    if not isinstance(data, (list, np.ndarray, pd.Series)):\n        raise ValueError(\"Data is not a list, numpy array, or pandas Series.\")\n\n    data = pd.Series(data)\n\n    if data.empty:\n        raise ValueError(\"Data is empty.\")\n\n    if not pd.to_numeric(data, errors='coerce').isnull().all():\n        raise ValueError(\"Data contains non-numeric values.\")\n\n    fig, ax = plt.subplots(figsize=(10, 6))\n    sns.boxplot(data, ax=ax)\n    ax.set_title('Boxplot of Numerical Data')\n    return fig", "raw_solution": "import json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\ndef task_func(json_data: str, key_path: list):\n    data = json.loads(json_data)\n    for key in key_path:\n        try:\n            data = data[key]\n        except KeyError:\n            raise KeyError(f\"Key '{key}' not found in JSON data.\")\n\n    if not isinstance(data, (list, np.ndarray, pd.Series)):\n        raise ValueError(\"Data is not a list, numpy array, or pandas Series.\")\n\n    data = pd.Series(data)\n\n    if data.empty:\n        raise ValueError(\"Data is empty.\")\n\n    if not pd.to_numeric(data, errors='coerce').isnull().all():\n        raise ValueError(\"Data contains non-numeric values.\")\n\n    fig, ax = plt.subplots(figsize=(10, 6))\n    sns.boxplot(data, ax=ax)\n    ax.set_title('Boxplot of Numerical Data')\n    return fig"}
{"task_id": "BigCodeBench/987", "solution": "import json\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(json_data: str, data_key: str):\n    try:\n        data = pd.read_json(json_data, typ='series')[data_key]\n    except KeyError:\n        raise KeyError(f\"Key path {data_key} not found in the given data.\")\n\n    if data.empty:\n        return data, None, None\n\n    original_data = data.astype(float)\n    scaler = MinMaxScaler()\n    normalized_data = pd.Series(scaler.fit_transform(original_data.values.reshape(-1, 1)).reshape(-1), index=original_data.index)\n\n    fig, ax = plt.subplots()\n    ax.plot(original_data, label='Original Data')\n    ax.plot(normalized_data, label='Normalized Data')\n    ax.set_title('Comparison of Original and Normalized Data')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    return original_data, normalized_data, ax.figure", "raw_solution": "import json\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(json_data: str, data_key: str):\n    try:\n        data = pd.read_json(json_data, typ='series')[data_key]\n    except KeyError:\n        raise KeyError(f\"Key path {data_key} not found in the given data.\")\n\n    if data.empty:\n        return data, None, None\n\n    original_data = data.astype(float)\n    scaler = MinMaxScaler()\n    normalized_data = pd.Series(scaler.fit_transform(original_data.values.reshape(-1, 1)).reshape(-1), index=original_data.index)\n\n    fig, ax = plt.subplots()\n    ax.plot(original_data, label='Original Data')\n    ax.plot(normalized_data, label='Normalized Data')\n    ax.set_title('Comparison of Original and Normalized Data')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.legend()\n\n    return original_data, normalized_data, ax.figure"}
{"task_id": "BigCodeBench/988", "solution": "import os\nimport re\nfrom pathlib import Path\ndef task_func(dir_path: str, predicates: list) -> dict:\n    if not predicates:\n        raise ValueError(\"No valid predicates provided.\")\n    if not os.path.isdir(dir_path):\n        raise FileNotFoundError(\"Specified directory does not exist or is not a directory.\")\n    \n    result = {}\n    for item in os.listdir(dir_path):\n        item_path = os.path.join(dir_path, item)\n        for predicate in predicates:\n            if re.search(predicate, item):\n                result[item] = True\n                break\n        else:\n            result[item] = False\n    return result", "raw_solution": "import os\nimport re\nfrom pathlib import Path\n\ndef task_func(dir_path: str, predicates: list) -> dict:\n    if not predicates:\n        raise ValueError(\"No valid predicates provided.\")\n    if not os.path.isdir(dir_path):\n        raise FileNotFoundError(\"Specified directory does not exist or is not a directory.\")\n    \n    result = {}\n    for item in os.listdir(dir_path):\n        item_path = os.path.join(dir_path, item)\n        for predicate in predicates:\n            if re.search(predicate, item):\n                result[item] = True\n                break\n        else:\n            result[item] = False\n    return result"}
{"task_id": "BigCodeBench/989", "solution": "import random\nimport string\ndef task_func(length: int, predicates: list, seed: int = None):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    if seed is not None:\n        random.seed(seed)\n    charset = string.ascii_letters + string.digits + string.punctuation\n    text = ''.join(random.choices(charset, k=length))\n    characteristics = {}\n    if not predicates:\n        return (text, characteristics)\n    for predicate in predicates:\n        if predicate not in ['digits', 'letters', 'punctuation']:\n            raise KeyError(f\"Unrecognized predicate: {predicate}\")\n        if predicate == 'digits':\n            characteristics[predicate] = sum(c.isdigit() for c in text)\n        elif predicate == 'letters':\n            characteristics[predicate] = sum(c.isalpha() for c in text)\n        elif predicate == 'punctuation':\n            characteristics[predicate] = sum(c in string.punctuation for c in text)\n    return (text, characteristics)", "raw_solution": "import random\nimport string\n\ndef task_func(length: int, predicates: list, seed: int = None):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    if seed is not None:\n        random.seed(seed)\n    charset = string.ascii_letters + string.digits + string.punctuation\n    text = ''.join(random.choices(charset, k=length))\n    characteristics = {}\n    if not predicates:\n        return (text, characteristics)\n    for predicate in predicates:\n        if predicate not in ['digits', 'letters', 'punctuation']:\n            raise KeyError(f\"Unrecognized predicate: {predicate}\")\n        if predicate == 'digits':\n            characteristics[predicate] = sum(c.isdigit() for c in text)\n        elif predicate == 'letters':\n            characteristics[predicate] = sum(c.isalpha() for c in text)\n        elif predicate == 'punctuation':\n            characteristics[predicate] = sum(c in string.punctuation for c in text)\n    return (text, characteristics)\n\n# Testing\ntext, characteristics = task_func(10, ['digits', 'letters', 'punctuation'])"}
{"task_id": "BigCodeBench/990", "solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\ndef task_func(hex_string):\n    # Convert hex to bytes\n    bytes_obj = binascii.unhexlify(hex_string)\n\n    # Convert bytes to UTF-8 string\n    utf8_str = bytes_obj.decode('utf-8')\n\n    # Initialize dictionary\n    encodings = {\n        'hex': hex_string,\n        'base64': base64.b64encode(bytes_obj).decode('utf-8'),\n        'utf-8': utf8_str,\n        'utf-16': utf8_str,\n        'utf-32': utf8_str,\n        'ASCII': 'Not representable in ASCII',\n        'URL': urllib.parse.quote(utf8_str),\n        'ROT13': codecs.encode(utf8_str, 'rot_13')\n    }\n\n    # Check if string can be represented in ASCII\n    for char in utf8_str:\n        if ord(char) > 127:\n            encodings['ASCII'] = 'Not representable in ASCII'\n            break\n        else:\n            encodings['ASCII'] = utf8_str\n\n    return encodings", "raw_solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\n\ndef task_func(hex_string):\n    # Convert hex to bytes\n    bytes_obj = binascii.unhexlify(hex_string)\n\n    # Convert bytes to UTF-8 string\n    utf8_str = bytes_obj.decode('utf-8')\n\n    # Initialize dictionary\n    encodings = {\n        'hex': hex_string,\n        'base64': base64.b64encode(bytes_obj).decode('utf-8'),\n        'utf-8': utf8_str,\n        'utf-16': utf8_str,\n        'utf-32': utf8_str,\n        'ASCII': 'Not representable in ASCII',\n        'URL': urllib.parse.quote(utf8_str),\n        'ROT13': codecs.encode(utf8_str, 'rot_13')\n    }\n\n    # Check if string can be represented in ASCII\n    for char in utf8_str:\n        if ord(char) > 127:\n            encodings['ASCII'] = 'Not representable in ASCII'\n            break\n        else:\n            encodings['ASCII'] = utf8_str\n\n    return encodings\n\n# Test the function"}
{"task_id": "BigCodeBench/991", "solution": "import binascii\nimport string\nimport random\ndef task_func(length):\n    # Generate a random hexadecimal string of a given length\n    hex_string = ''.join(random.choices(string.hexdigits, k=length))\n\n    # Attempt to decode the hexadecimal string in ASCII\n    try:\n        ascii_string = binascii.unhexlify(hex_string).decode('ascii')\n    except binascii.Error:\n        ascii_string = \"Decoding failed. The resulting ASCII string may contain non-printable characters or be shorter than the input length.\"\n\n    return ascii_string", "raw_solution": "import binascii\nimport string\nimport random\n\ndef task_func(length):\n    # Generate a random hexadecimal string of a given length\n    hex_string = ''.join(random.choices(string.hexdigits, k=length))\n\n    # Attempt to decode the hexadecimal string in ASCII\n    try:\n        ascii_string = binascii.unhexlify(hex_string).decode('ascii')\n    except binascii.Error:\n        ascii_string = \"Decoding failed. The resulting ASCII string may contain non-printable characters or be shorter than the input length.\"\n\n    return ascii_string\n\n# Test the function"}
{"task_id": "BigCodeBench/992", "solution": "import sys\nimport sqlite3\nPATH_TO_APPEND = \"path/to/whatever\"\nDATABASE = \"path/to/database.db\"\ndef task_func(path_to_append=PATH_TO_APPEND, database=DATABASE):\n    # Append path to sys.path\n    sys.path.append(path_to_append)\n\n    # Connect to SQLite database\n    conn = sqlite3.connect(database)\n    c = conn.cursor()\n\n    # Create table if it doesn't exist\n    c.execute('''\n        CREATE TABLE IF NOT EXISTS paths\n        (path TEXT PRIMARY KEY)\n    ''')\n\n    # Insert path into database if it doesn't exist\n    c.execute('''\n        INSERT OR IGNORE INTO paths (path) VALUES (?)\n    ''', (path_to_append,))\n\n    # Commit changes and close connection\n    conn.commit()\n    conn.close()\n\n    # Return the path that was appended to sys.path and inserted into the database\n    return path_to_append", "raw_solution": "import sys\nimport sqlite3\n\n# Constants\nPATH_TO_APPEND = \"path/to/whatever\"\nDATABASE = \"path/to/database.db\"\n\ndef task_func(path_to_append=PATH_TO_APPEND, database=DATABASE):\n    # Append path to sys.path\n    sys.path.append(path_to_append)\n\n    # Connect to SQLite database\n    conn = sqlite3.connect(database)\n    c = conn.cursor()\n\n    # Create table if it doesn't exist\n    c.execute('''\n        CREATE TABLE IF NOT EXISTS paths\n        (path TEXT PRIMARY KEY)\n    ''')\n\n    # Insert path into database if it doesn't exist\n    c.execute('''\n        INSERT OR IGNORE INTO paths (path) VALUES (?)\n    ''', (path_to_append,))\n\n    # Commit changes and close connection\n    conn.commit()\n    conn.close()\n\n    # Return the path that was appended to sys.path and inserted into the database\n    return path_to_append\n\n# Test the function"}
{"task_id": "BigCodeBench/993", "solution": "import re\nfrom scipy.stats import gaussian_kde\nfrom scipy import linalg\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(text):\n    # Split the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Calculate the lengths of the words\n    lengths = [len(word) for word in words]\n\n    # Create a histogram and KDE plot\n    fig, ax = plt.subplots()\n    ax.hist(lengths, bins=20, density=True, alpha=0.6, color='g', label='Histogram')\n\n    # Calculate the kernel density estimate\n    kde = gaussian_kde(lengths)\n    x = np.linspace(min(lengths), max(lengths), 100)\n    ax.plot(x, kde(x), color='r', label='KDE')\n\n    ax.set_xlabel('Word Length')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution of Word Lengths')\n    ax.legend()\n\n    return ax\ntext = \"This is a sample text. It contains several words of different lengths.\"", "raw_solution": "import re\nfrom scipy.stats import gaussian_kde\nfrom scipy import linalg\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(text):\n    # Split the text into words\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # Calculate the lengths of the words\n    lengths = [len(word) for word in words]\n\n    # Create a histogram and KDE plot\n    fig, ax = plt.subplots()\n    ax.hist(lengths, bins=20, density=True, alpha=0.6, color='g', label='Histogram')\n\n    # Calculate the kernel density estimate\n    kde = gaussian_kde(lengths)\n    x = np.linspace(min(lengths), max(lengths), 100)\n    ax.plot(x, kde(x), color='r', label='KDE')\n\n    ax.set_xlabel('Word Length')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution of Word Lengths')\n    ax.legend()\n\n    return ax\n\n# Test the function\ntext = \"This is a sample text. It contains several words of different lengths.\"\nax = task_func(text)\nplt.show()"}
{"task_id": "BigCodeBench/994", "solution": "import requests\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nfrom requests.exceptions import RequestException\ndef task_func(url: str, csv_file_path: str) -> list:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        raise SystemExit(f\"Error fetching URL: {e}\")\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    data = []\n    for container in soup.find_all('div', {'class': 'container'}):\n        title = container.find('h1').text if container.find('h1') else 'No Title'\n        date = container.find('span', {'class': 'date'}).text if container.find('span', {'class': 'date'}) else 'No Date'\n        author = container.find('span', {'class': 'author'}).text if container.find('span', {'class': 'author'}) else 'No Author'\n        data.append((title, date, author))\n\n    df = pd.DataFrame(data, columns=['Title', 'Date', 'Author'])\n    df.to_csv(csv_file_path, index=False)\n\n    return data", "raw_solution": "import requests\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nfrom requests.exceptions import RequestException\n\ndef task_func(url: str, csv_file_path: str) -> list:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        raise SystemExit(f\"Error fetching URL: {e}\")\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    data = []\n    for container in soup.find_all('div', {'class': 'container'}):\n        title = container.find('h1').text if container.find('h1') else 'No Title'\n        date = container.find('span', {'class': 'date'}).text if container.find('span', {'class': 'date'}) else 'No Date'\n        author = container.find('span', {'class': 'author'}).text if container.find('span', {'class': 'author'}) else 'No Author'\n        data.append((title, date, author))\n\n    df = pd.DataFrame(data, columns=['Title', 'Date', 'Author'])\n    df.to_csv(csv_file_path, index=False)\n\n    return data"}
{"task_id": "BigCodeBench/995", "solution": "import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(file_path: str, plot_path: str) -> (float, float, str):\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(\"The file does not exist.\")\n\n    df = pd.read_csv(file_path)\n    data = df.values.flatten()\n    data = data[~np.isnan(data)]\n\n    if len(data) == 0:\n        return (np.nan, np.nan, plot_path)\n\n    mean_val = np.mean(data)\n    median_val = np.median(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(range(len(data)), data)\n    plt.title(\"Data Visualization\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Value\")\n    plt.savefig(plot_path)\n\n    return (mean_val, median_val, plot_path)", "raw_solution": "import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(file_path: str, plot_path: str) -> (float, float, str):\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(\"The file does not exist.\")\n\n    df = pd.read_csv(file_path)\n    data = df.values.flatten()\n    data = data[~np.isnan(data)]\n\n    if len(data) == 0:\n        return (np.nan, np.nan, plot_path)\n\n    mean_val = np.mean(data)\n    median_val = np.median(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(range(len(data)), data)\n    plt.title(\"Data Visualization\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Value\")\n    plt.savefig(plot_path)\n\n    return (mean_val, median_val, plot_path)"}
{"task_id": "BigCodeBench/996", "solution": "import requests\nimport json\nfrom bs4 import BeautifulSoup\ndef task_func(url: str, file_name: str = \"Output.txt\") -> str:\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        title = soup.title.string if soup.title else None\n    except:\n        title = None\n\n    data = {'url': url, 'title': title}\n\n    with open(file_name, 'a') as file:\n        file.write(json.dumps(data) + '\\n')\n\n    return file_name", "raw_solution": "import requests\nimport json\nfrom bs4 import BeautifulSoup\n\ndef task_func(url: str, file_name: str = \"Output.txt\") -> str:\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        title = soup.title.string if soup.title else None\n    except:\n        title = None\n\n    data = {'url': url, 'title': title}\n\n    with open(file_name, 'a') as file:\n        file.write(json.dumps(data) + '\\n')\n\n    return file_name"}
{"task_id": "BigCodeBench/997", "solution": "import urllib.request\nimport os\nimport zipfile\nTARGET_DIR = \"downloaded_files\"\nTARGET_ZIP_FILE = \"downloaded_files.zip\"\ndef task_func(url):\n    # Create target directory if it doesn't exist\n    if not os.path.exists(TARGET_DIR):\n        os.makedirs(TARGET_DIR)\n\n    # Download the zip file\n    urllib.request.urlretrieve(url, TARGET_ZIP_FILE)\n\n    # Extract the zip file\n    with zipfile.ZipFile(TARGET_ZIP_FILE, 'r') as zip_ref:\n        zip_ref.extractall(TARGET_DIR)\n\n    # Delete the zip file\n    os.remove(TARGET_ZIP_FILE)\n\n    return TARGET_DIR", "raw_solution": "import urllib.request\nimport os\nimport zipfile\n\n# Constants\nTARGET_DIR = \"downloaded_files\"\nTARGET_ZIP_FILE = \"downloaded_files.zip\"\n\ndef task_func(url):\n    # Create target directory if it doesn't exist\n    if not os.path.exists(TARGET_DIR):\n        os.makedirs(TARGET_DIR)\n\n    # Download the zip file\n    urllib.request.urlretrieve(url, TARGET_ZIP_FILE)\n\n    # Extract the zip file\n    with zipfile.ZipFile(TARGET_ZIP_FILE, 'r') as zip_ref:\n        zip_ref.extractall(TARGET_DIR)\n\n    # Delete the zip file\n    os.remove(TARGET_ZIP_FILE)\n\n    return TARGET_DIR"}
{"task_id": "BigCodeBench/998", "solution": "import urllib.request\nimport os\nimport hashlib\nimport tarfile\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5_CHECKSUM = \"d41d8cd98f00b204e9800998ecf8427e\"\ndef task_func(url):\n    try:\n        # Download the file\n        urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n    except Exception as e:\n        print(f\"Download failed: {e}\")\n        return False\n\n    # Calculate the MD5 checksum of the downloaded file\n    with open(TARGET_TAR_FILE, 'rb') as f:\n        md5_returned = hashlib.md5(f.read()).hexdigest()\n\n    # Check if the MD5 checksum matches the expected value\n    if md5_returned != EXPECTED_MD5_CHECKSUM:\n        print(\"MD5 checksum does not match. Deleting the file.\")\n        os.remove(TARGET_TAR_FILE)\n        return False\n\n    # If the MD5 checksum matches, extract the contents of the tar.gz file\n    try:\n        with tarfile.open(TARGET_TAR_FILE, 'r:gz') as tar:\n            tar.extractall()\n    except Exception as e:\n        print(f\"Extraction failed: {e}\")\n        return False\n\n    # Remove the downloaded file\n    os.remove(TARGET_TAR_FILE)\n\n    return True", "raw_solution": "import urllib.request\nimport os\nimport hashlib\nimport tarfile\n\n# Constants\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5_CHECKSUM = \"d41d8cd98f00b204e9800998ecf8427e\"\n\ndef task_func(url):\n    try:\n        # Download the file\n        urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n    except Exception as e:\n        print(f\"Download failed: {e}\")\n        return False\n\n    # Calculate the MD5 checksum of the downloaded file\n    with open(TARGET_TAR_FILE, 'rb') as f:\n        md5_returned = hashlib.md5(f.read()).hexdigest()\n\n    # Check if the MD5 checksum matches the expected value\n    if md5_returned != EXPECTED_MD5_CHECKSUM:\n        print(\"MD5 checksum does not match. Deleting the file.\")\n        os.remove(TARGET_TAR_FILE)\n        return False\n\n    # If the MD5 checksum matches, extract the contents of the tar.gz file\n    try:\n        with tarfile.open(TARGET_TAR_FILE, 'r:gz') as tar:\n            tar.extractall()\n    except Exception as e:\n        print(f\"Extraction failed: {e}\")\n        return False\n\n    # Remove the downloaded file\n    os.remove(TARGET_TAR_FILE)\n\n    return True"}
{"task_id": "BigCodeBench/999", "solution": "import urllib.request\nimport os\nimport csv\nimport collections\ndef task_func(url, column_name, csv_file_path):\n    try:\n        urllib.request.urlretrieve(url, csv_file_path)\n    except urllib.error.URLError:\n        print(\"Failed to download the file from the provided URL.\")\n        return\n\n    if not os.path.isfile(csv_file_path):\n        print(\"Failed to download the file from the provided URL.\")\n        return\n\n    try:\n        with open(csv_file_path, 'r') as csv_file:\n            csv_reader = csv.DictReader(csv_file)\n            column_values = [row[column_name] for row in csv_reader if column_name in row]\n\n            if not column_values:\n                raise ValueError(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n\n            count_dict = dict(collections.Counter(column_values))\n\n            os.remove(csv_file_path)\n\n            return count_dict\n    except csv.Error:\n        print(\"Failed to read the CSV file.\")\n        os.remove(csv_file_path)\n        return", "raw_solution": "import urllib.request\nimport os\nimport csv\nimport collections\n\ndef task_func(url, column_name, csv_file_path):\n    try:\n        urllib.request.urlretrieve(url, csv_file_path)\n    except urllib.error.URLError:\n        print(\"Failed to download the file from the provided URL.\")\n        return\n\n    if not os.path.isfile(csv_file_path):\n        print(\"Failed to download the file from the provided URL.\")\n        return\n\n    try:\n        with open(csv_file_path, 'r') as csv_file:\n            csv_reader = csv.DictReader(csv_file)\n            column_values = [row[column_name] for row in csv_reader if column_name in row]\n\n            if not column_values:\n                raise ValueError(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n\n            count_dict = dict(collections.Counter(column_values))\n\n            os.remove(csv_file_path)\n\n            return count_dict\n    except csv.Error:\n        print(\"Failed to read the CSV file.\")\n        os.remove(csv_file_path)\n        return"}
{"task_id": "BigCodeBench/1000", "solution": "import urllib.request\nimport os\nimport json\nimport pandas as pd\nTARGET_JSON_FILE = \"downloaded_file.json\"\ndef task_func(url):\n    # Retrieve JSON file from URL\n    urllib.request.urlretrieve(url, TARGET_JSON_FILE)\n\n    # Read JSON file\n    with open(TARGET_JSON_FILE, 'r') as f:\n        data = json.load(f)\n\n    # Convert JSON data to pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Delete temporary JSON file\n    os.remove(TARGET_JSON_FILE)\n\n    return df", "raw_solution": "import urllib.request\nimport os\nimport json\nimport pandas as pd\n\n# Constants\nTARGET_JSON_FILE = \"downloaded_file.json\"\n\ndef task_func(url):\n    # Retrieve JSON file from URL\n    urllib.request.urlretrieve(url, TARGET_JSON_FILE)\n\n    # Read JSON file\n    with open(TARGET_JSON_FILE, 'r') as f:\n        data = json.load(f)\n\n    # Convert JSON data to pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Delete temporary JSON file\n    os.remove(TARGET_JSON_FILE)\n\n    return df"}
{"task_id": "BigCodeBench/1001", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(csv_file_path: str) -> 'matplotlib.axes.Axes':\n    # Read data from CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Normalize 'column1'\n    df['column1'] = (df['column1'] - df['column1'].min()) / (df['column1'].max() - df['column1'].min())\n\n    # Create plot\n    fig, ax = plt.subplots()\n\n    # Plot normalized data\n    ax.hist(df['column1'], bins=30)\n\n    # Set title\n    ax.set_title('{0:^20}: {1:^20}'.format('Plot Title', 'Normalized Column 1'))\n\n    # Set x-label\n    ax.set_xlabel('{0:^20}: {1:^20}'.format('Index', 'Normalized Value'))\n\n    # Set y-label\n    ax.set_ylabel('{0:^20}: {1:^20}'.format('Frequency', 'Normalized Value'))\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file_path: str) -> 'matplotlib.axes.Axes':\n    # Read data from CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Normalize 'column1'\n    df['column1'] = (df['column1'] - df['column1'].min()) / (df['column1'].max() - df['column1'].min())\n\n    # Create plot\n    fig, ax = plt.subplots()\n\n    # Plot normalized data\n    ax.hist(df['column1'], bins=30)\n\n    # Set title\n    ax.set_title('{0:^20}: {1:^20}'.format('Plot Title', 'Normalized Column 1'))\n\n    # Set x-label\n    ax.set_xlabel('{0:^20}: {1:^20}'.format('Index', 'Normalized Value'))\n\n    # Set y-label\n    ax.set_ylabel('{0:^20}: {1:^20}'.format('Frequency', 'Normalized Value'))\n\n    return ax"}
{"task_id": "BigCodeBench/1002", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data, column_name=\"target_column\"):\n    # Convert JSON data to DataFrame\n    df = pd.read_json(data, orient='records')\n\n    # Check if the specified column exists in the DataFrame\n    if column_name not in df.columns:\n        raise ValueError(f\"The specified column '{column_name}' does not exist in the DataFrame.\")\n\n    # Convert non-numeric columns to categorical type and then to numeric codes\n    df[column_name] = pd.Categorical(df[column_name]).codes\n\n    # Plot histogram\n    plt.figure(figsize=(10, 6))\n    plt.hist(df[column_name], bins='auto', color='#007BFF', ec='black')\n    plt.title(f'Histogram of {column_name}')\n    plt.xlabel(column_name)\n    plt.ylabel('Frequency')\n    plt.grid(True)\n\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data, column_name=\"target_column\"):\n    # Convert JSON data to DataFrame\n    df = pd.read_json(data, orient='records')\n\n    # Check if the specified column exists in the DataFrame\n    if column_name not in df.columns:\n        raise ValueError(f\"The specified column '{column_name}' does not exist in the DataFrame.\")\n\n    # Convert non-numeric columns to categorical type and then to numeric codes\n    df[column_name] = pd.Categorical(df[column_name]).codes\n\n    # Plot histogram\n    plt.figure(figsize=(10, 6))\n    plt.hist(df[column_name], bins='auto', color='#007BFF', ec='black')\n    plt.title(f'Histogram of {column_name}')\n    plt.xlabel(column_name)\n    plt.ylabel('Frequency')\n    plt.grid(True)\n\n    return df, plt.gca()"}
{"task_id": "BigCodeBench/1003", "solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\ndef task_func(url):\n    try:\n        # Fetch the XML file from the URL\n        response = urllib.request.urlopen(url)\n        xml_content = response.read()\n\n        # Parse the XML content\n        root = etree.fromstring(xml_content)\n\n        # Find all 'item' elements\n        items = root.findall('.//item')\n\n        # Create a DataFrame from the 'item' elements\n        data = []\n        for item in items:\n            item_data = {}\n            for child in item:\n                item_data[child.tag] = child.text\n            data.append(item_data)\n\n        df = pd.DataFrame(data)\n\n        return df\n\n    except etree.XMLSyntaxError:\n        raise ValueError(\"The XML file has invalid syntax.\")\n    except urllib.error.URLError:\n        raise ValueError(\"The URL is invalid or the XML file cannot be fetched from the URL.\")\n    except Exception as e:\n        raise ValueError(\"XML structure does not match expected format.\") from e", "raw_solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\n\ndef task_func(url):\n    try:\n        # Fetch the XML file from the URL\n        response = urllib.request.urlopen(url)\n        xml_content = response.read()\n\n        # Parse the XML content\n        root = etree.fromstring(xml_content)\n\n        # Find all 'item' elements\n        items = root.findall('.//item')\n\n        # Create a DataFrame from the 'item' elements\n        data = []\n        for item in items:\n            item_data = {}\n            for child in item:\n                item_data[child.tag] = child.text\n            data.append(item_data)\n\n        df = pd.DataFrame(data)\n\n        return df\n\n    except etree.XMLSyntaxError:\n        raise ValueError(\"The XML file has invalid syntax.\")\n    except urllib.error.URLError:\n        raise ValueError(\"The URL is invalid or the XML file cannot be fetched from the URL.\")\n    except Exception as e:\n        raise ValueError(\"XML structure does not match expected format.\") from e\n\n# Test the function\ntry:\n    df = task_func('http://example.com/invalid_structure.xml')\n    print(df)\nexcept ValueError as e:\n    print(e)"}
{"task_id": "BigCodeBench/1004", "solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(url):\n    # Download the text file\n    response = urllib.request.urlopen(url)\n    data = response.read()\n    text = data.decode('utf-8')\n\n    # Process the text to count the frequency of each word\n    words = re.findall(r'\\b\\w+\\b', text)\n    counter = Counter(words)\n\n    # Plot a bar chart showing the ten most frequently occurring words\n    most_common_words = counter.most_common(10)\n    words, frequencies = zip(*most_common_words)\n    ax = plt.bar(words, frequencies)\n\n    return (counter, ax)", "raw_solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(url):\n    # Download the text file\n    response = urllib.request.urlopen(url)\n    data = response.read()\n    text = data.decode('utf-8')\n\n    # Process the text to count the frequency of each word\n    words = re.findall(r'\\b\\w+\\b', text)\n    counter = Counter(words)\n\n    # Plot a bar chart showing the ten most frequently occurring words\n    most_common_words = counter.most_common(10)\n    words, frequencies = zip(*most_common_words)\n    ax = plt.bar(words, frequencies)\n\n    return (counter, ax)"}
{"task_id": "BigCodeBench/1005", "solution": "import urllib.request\nimport zipfile\nimport os\nimport urllib.error\ndef task_func(\n    url: str,\n    save_path: str = \"downloaded_file.zip\",\n    extract_path: str = \"extracted_files\",\n) -> str:\n    try:\n        urllib.request.urlretrieve(url, save_path)\n    except urllib.error.URLError as e:\n        return f\"URL Error: {str(e.reason)}\"\n    except Exception as e:\n        return f\"Unexpected Error: {str(e)}\"\n\n    try:\n        with zipfile.ZipFile(save_path, 'r') as zip_ref:\n            zip_ref.extractall(extract_path)\n    except zipfile.BadZipFile as e:\n        os.remove(save_path)\n        return f\"BadZipFile Error: {str(e)}\"\n    except Exception as e:\n        os.remove(save_path)\n        return f\"Unexpected Error: {str(e)}\"\n\n    try:\n        os.remove(save_path)\n    except Exception as e:\n        return f\"File I/O Error: {str(e)}\"\n\n    return extract_path", "raw_solution": "import urllib.request\nimport zipfile\nimport os\nimport urllib.error\n\ndef task_func(\n    url: str,\n    save_path: str = \"downloaded_file.zip\",\n    extract_path: str = \"extracted_files\",\n) -> str:\n    try:\n        urllib.request.urlretrieve(url, save_path)\n    except urllib.error.URLError as e:\n        return f\"URL Error: {str(e.reason)}\"\n    except Exception as e:\n        return f\"Unexpected Error: {str(e)}\"\n\n    try:\n        with zipfile.ZipFile(save_path, 'r') as zip_ref:\n            zip_ref.extractall(extract_path)\n    except zipfile.BadZipFile as e:\n        os.remove(save_path)\n        return f\"BadZipFile Error: {str(e)}\"\n    except Exception as e:\n        os.remove(save_path)\n        return f\"Unexpected Error: {str(e)}\"\n\n    try:\n        os.remove(save_path)\n    except Exception as e:\n        return f\"File I/O Error: {str(e)}\"\n\n    return extract_path"}
{"task_id": "BigCodeBench/1006", "solution": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    try:\n        response = requests.get(url, stream=True)\n        if response.status_code != 200:\n            return \"Error: Unable to download the file from the provided URL.\"\n        content_type = response.headers.get('content-type')\n        if 'application/zip' not in content_type:\n            return \"Error: The URL does not point to a ZIP file.\"\n        zip_file_path = os.path.join(download_path, 'downloaded.zip')\n        with open(zip_file_path, 'wb') as f:\n            f.write(response.content)\n        try:\n            with ZipFile(zip_file_path, 'r') as zip_ref:\n                zip_ref.extractall(download_path)\n        except BadZipFile:\n            return \"Error: The downloaded file is not a valid ZIP file.\"\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n        return download_path\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {str(e)}\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"", "raw_solution": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\n\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    try:\n        response = requests.get(url, stream=True)\n        if response.status_code != 200:\n            return \"Error: Unable to download the file from the provided URL.\"\n        content_type = response.headers.get('content-type')\n        if 'application/zip' not in content_type:\n            return \"Error: The URL does not point to a ZIP file.\"\n        zip_file_path = os.path.join(download_path, 'downloaded.zip')\n        with open(zip_file_path, 'wb') as f:\n            f.write(response.content)\n        try:\n            with ZipFile(zip_file_path, 'r') as zip_ref:\n                zip_ref.extractall(download_path)\n        except BadZipFile:\n            return \"Error: The downloaded file is not a valid ZIP file.\"\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n        return download_path\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {str(e)}\"\n    except Exception as e:\n        return f\"Error: {str(e)}\""}
{"task_id": "BigCodeBench/1007", "solution": "import requests\nimport pandas as pd\nfrom requests.exceptions import RequestException, HTTPError\ndef task_func(url: str) -> pd.DataFrame:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()  # Raise an HTTPError if the status is 4xx, 5xx\n        data = response.json()\n        if not isinstance(data, list):\n            raise ValueError(\"The fetched data is not in a valid JSON format that can be converted into a DataFrame.\")\n        for item in data:\n            if not isinstance(item, dict):\n                raise ValueError(\"The fetched data is not in a valid JSON format that can be converted into a DataFrame.\")\n        return pd.DataFrame(data)\n    except HTTPError as http_err:\n        raise HTTPError(f'HTTP error occurred: {http_err}') from http_err\n    except ValueError as val_err:\n        raise ValueError(f'Value error occurred: {val_err}') from val_err\n    except RequestException as req_err:\n        raise RequestException(f'Network error occurred: {req_err}') from req_err", "raw_solution": "import requests\nimport pandas as pd\nfrom requests.exceptions import RequestException, HTTPError\n\ndef task_func(url: str) -> pd.DataFrame:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()  # Raise an HTTPError if the status is 4xx, 5xx\n        data = response.json()\n        if not isinstance(data, list):\n            raise ValueError(\"The fetched data is not in a valid JSON format that can be converted into a DataFrame.\")\n        for item in data:\n            if not isinstance(item, dict):\n                raise ValueError(\"The fetched data is not in a valid JSON format that can be converted into a DataFrame.\")\n        return pd.DataFrame(data)\n    except HTTPError as http_err:\n        raise HTTPError(f'HTTP error occurred: {http_err}') from http_err\n    except ValueError as val_err:\n        raise ValueError(f'Value error occurred: {val_err}') from val_err\n    except RequestException as req_err:\n        raise RequestException(f'Network error occurred: {req_err}') from req_err"}
{"task_id": "BigCodeBench/1008", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        print (\"HTTP Error:\",errh)\n        return\n    except requests.exceptions.ConnectionError as errc:\n        print (\"Error Connecting:\",errc)\n        return\n    except requests.exceptions.Timeout as errt:\n        print (\"Timeout Error:\",errt)\n        return\n    except requests.exceptions.RequestException as err:\n        print (\"Something went wrong\",err)\n        return\n\n    soup = BeautifulSoup(response.content, 'html.parser')\n    table = soup.find('table', {'id': table_id})\n\n    if table is None:\n        raise ValueError('Table with the specified ID not found.')\n\n    csv = pd.read_html(str(table))[0].to_csv(index=False)\n    df = pd.read_csv(StringIO(csv))\n\n    return df", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\n\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as errh:\n        print (\"HTTP Error:\",errh)\n        return\n    except requests.exceptions.ConnectionError as errc:\n        print (\"Error Connecting:\",errc)\n        return\n    except requests.exceptions.Timeout as errt:\n        print (\"Timeout Error:\",errt)\n        return\n    except requests.exceptions.RequestException as err:\n        print (\"Something went wrong\",err)\n        return\n\n    soup = BeautifulSoup(response.content, 'html.parser')\n    table = soup.find('table', {'id': table_id})\n\n    if table is None:\n        raise ValueError('Table with the specified ID not found.')\n\n    csv = pd.read_html(str(table))[0].to_csv(index=False)\n    df = pd.read_csv(StringIO(csv))\n\n    return df"}
{"task_id": "BigCodeBench/1009", "solution": "import xml.etree.ElementTree as ET\nimport csv\ndef task_func(xml_content, output_csv_path):\n    try:\n        tree = ET.ElementTree(ET.fromstring(xml_content))\n    except ET.ParseError as e:\n        raise ET.ParseError(f\"XML parsing error: {str(e)}\")\n    except Exception as e:\n        raise IOError(f\"IO error: {str(e)}\")\n\n    root = tree.getroot()\n\n    data = []\n    for i, child in enumerate(root):\n        data.append({})\n        for subchild in child:\n            data[i][subchild.tag] = subchild.text\n\n    try:\n        with open(output_csv_path, 'w', newline='') as csvfile:\n            fieldnames = data[0].keys()\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n            writer.writeheader()\n            for row in data:\n                writer.writerow(row)\n    except IOError as e:\n        raise IOError(f\"IO error: {str(e)}\")", "raw_solution": "import xml.etree.ElementTree as ET\nimport csv\n\ndef task_func(xml_content, output_csv_path):\n    try:\n        tree = ET.ElementTree(ET.fromstring(xml_content))\n    except ET.ParseError as e:\n        raise ET.ParseError(f\"XML parsing error: {str(e)}\")\n    except Exception as e:\n        raise IOError(f\"IO error: {str(e)}\")\n\n    root = tree.getroot()\n\n    data = []\n    for i, child in enumerate(root):\n        data.append({})\n        for subchild in child:\n            data[i][subchild.tag] = subchild.text\n\n    try:\n        with open(output_csv_path, 'w', newline='') as csvfile:\n            fieldnames = data[0].keys()\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n            writer.writeheader()\n            for row in data:\n                writer.writerow(row)\n    except IOError as e:\n        raise IOError(f\"IO error: {str(e)}\")"}
{"task_id": "BigCodeBench/1010", "solution": "import requests\nfrom PIL import Image\nimport io\ndef task_func(url):\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise ValueError(\"URL is invalid or cannot be reached within the timeout period\") from e\n\n    if not 200 <= response.status_code <= 299:\n        raise ValueError(\"Response from the server is not a successful HTTP status code\")\n\n    try:\n        image = Image.open(io.BytesIO(response.content))\n        return image\n    except IOError as e:\n        raise ValueError(\"Content fetched from the URL is not a valid image format that can be handled by PIL\") from e", "raw_solution": "import requests\nfrom PIL import Image\nimport io\n\ndef task_func(url):\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise ValueError(\"URL is invalid or cannot be reached within the timeout period\") from e\n\n    if not 200 <= response.status_code <= 299:\n        raise ValueError(\"Response from the server is not a successful HTTP status code\")\n\n    try:\n        image = Image.open(io.BytesIO(response.content))\n        return image\n    except IOError as e:\n        raise ValueError(\"Content fetched from the URL is not a valid image format that can be handled by PIL\") from e"}
{"task_id": "BigCodeBench/1011", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(csv_file_path, col1_name=\"column1\", col2_name=\"column2\"):\n    # Read data from CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Check if columns exist in the DataFrame\n    if col1_name not in df.columns or col2_name not in df.columns:\n        raise ValueError(f\"Either {col1_name} or {col2_name} does not exist in the CSV file.\")\n\n    # Group by col1_name and calculate mean of col2_name\n    grouped_df = df.groupby(col1_name)[col2_name].mean().reset_index()\n\n    # Create bar plot\n    ax = grouped_df.plot(kind='bar', x=col1_name, y=col2_name, legend=False)\n\n    # Configure plot\n    ax.set_title(f\"Mean of {col2_name} Grouped by {col1_name}\")\n    ax.set_xlabel(col1_name)\n    ax.set_ylabel(f\"Mean of {col2_name}\")\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file_path, col1_name=\"column1\", col2_name=\"column2\"):\n    # Read data from CSV file\n    df = pd.read_csv(csv_file_path)\n\n    # Check if columns exist in the DataFrame\n    if col1_name not in df.columns or col2_name not in df.columns:\n        raise ValueError(f\"Either {col1_name} or {col2_name} does not exist in the CSV file.\")\n\n    # Group by col1_name and calculate mean of col2_name\n    grouped_df = df.groupby(col1_name)[col2_name].mean().reset_index()\n\n    # Create bar plot\n    ax = grouped_df.plot(kind='bar', x=col1_name, y=col2_name, legend=False)\n\n    # Configure plot\n    ax.set_title(f\"Mean of {col2_name} Grouped by {col1_name}\")\n    ax.set_xlabel(col1_name)\n    ax.set_ylabel(f\"Mean of {col2_name}\")\n\n    return ax"}
{"task_id": "BigCodeBench/1012", "solution": "import requests\nfrom pathlib import Path\nimport zipfile\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\ndef task_func(url, filename):\n    try:\n        # Create download directory if it doesn't exist\n        DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n\n        # Download the file\n        response = requests.get(url)\n        response.raise_for_status()\n\n        # Save the file\n        download_path = DOWNLOAD_DIR / filename\n        download_path.write_bytes(response.content)\n\n        # Create unzip directory if it doesn't exist\n        ZIP_DIR.mkdir(parents=True, exist_ok=True)\n\n        # Extract the zip file\n        with zipfile.ZipFile(download_path, 'r') as zip_ref:\n            zip_ref.extractall(ZIP_DIR)\n\n        # Get the list of filenames in the unzipped directory\n        unzipped_files = [file.name for file in ZIP_DIR.iterdir() if file.is_file()]\n\n        return \"Success\", unzipped_files\n\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {str(e)}\", []\n\n    except Exception as e:\n        return f\"Error: {str(e)}\", []\nurl = \"https://github.com/twbs/bootstrap/releases/download/v4.1.1/bootstrap-4.1.1-dist.zip\"\nfilename = \"bootstrap.zip\"", "raw_solution": "import requests\nfrom pathlib import Path\nimport zipfile\n\n# Constants\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\n\ndef task_func(url, filename):\n    try:\n        # Create download directory if it doesn't exist\n        DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n\n        # Download the file\n        response = requests.get(url)\n        response.raise_for_status()\n\n        # Save the file\n        download_path = DOWNLOAD_DIR / filename\n        download_path.write_bytes(response.content)\n\n        # Create unzip directory if it doesn't exist\n        ZIP_DIR.mkdir(parents=True, exist_ok=True)\n\n        # Extract the zip file\n        with zipfile.ZipFile(download_path, 'r') as zip_ref:\n            zip_ref.extractall(ZIP_DIR)\n\n        # Get the list of filenames in the unzipped directory\n        unzipped_files = [file.name for file in ZIP_DIR.iterdir() if file.is_file()]\n\n        return \"Success\", unzipped_files\n\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {str(e)}\", []\n\n    except Exception as e:\n        return f\"Error: {str(e)}\", []\n\n# Test the function\nurl = \"https://github.com/twbs/bootstrap/releases/download/v4.1.1/bootstrap-4.1.1-dist.zip\"\nfilename = \"bootstrap.zip\""}
{"task_id": "BigCodeBench/1013", "solution": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    # Send a GET request\n    response = requests.get(url)\n\n    # Parse the content of the request with BeautifulSoup\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    # Find all the links\n    links = soup.find_all('a')\n\n    # Set to store unique absolute links\n    unique_links = set()\n\n    # Open the CSV file\n    with open(csv_file, 'w', newline='') as file:\n        writer = csv.writer(file)\n        # Iterate over the links\n        for link in links:\n            # Get the href attribute\n            href = link.get('href')\n            # If the href attribute exists and is not None\n            if href:\n                # Join the base URL and the href to get the absolute URL\n                absolute_url = urljoin(base_url, href)\n                # Add the absolute URL to the set\n                unique_links.add(absolute_url)\n                # Write the absolute URL to the CSV file\n                writer.writerow([absolute_url])\n\n    # Return the number of unique absolute links\n    return len(unique_links)", "raw_solution": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\n\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    # Send a GET request\n    response = requests.get(url)\n\n    # Parse the content of the request with BeautifulSoup\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    # Find all the links\n    links = soup.find_all('a')\n\n    # Set to store unique absolute links\n    unique_links = set()\n\n    # Open the CSV file\n    with open(csv_file, 'w', newline='') as file:\n        writer = csv.writer(file)\n        # Iterate over the links\n        for link in links:\n            # Get the href attribute\n            href = link.get('href')\n            # If the href attribute exists and is not None\n            if href:\n                # Join the base URL and the href to get the absolute URL\n                absolute_url = urljoin(base_url, href)\n                # Add the absolute URL to the set\n                unique_links.add(absolute_url)\n                # Write the absolute URL to the CSV file\n                writer.writerow([absolute_url])\n\n    # Return the number of unique absolute links\n    return len(unique_links)\n\n# Test the function"}
{"task_id": "BigCodeBench/1014", "solution": "import requests\nimport pandas as pd\nfrom requests.exceptions import HTTPError\nimport matplotlib.pyplot as plt\ndef task_func(api_url):\n    if not isinstance(api_url, str):\n        raise TypeError(\"api_url should be a string\")\n\n    try:\n        response = requests.get(api_url)\n        # If the response was successful, no Exception will be raised\n        response.raise_for_status()\n    except HTTPError as http_err:\n        print(f'HTTP error occurred: {http_err}')\n        raise HTTPError from http_err\n    except Exception as err:\n        print(f'Other error occurred: {err}')\n        raise err\n    else:\n        print('Success!')\n\n    data = response.json()\n    df = pd.DataFrame(data)\n\n    if df.empty:\n        print(\"Data is empty, no plot will be generated.\")\n        return df, None\n    else:\n        print(\"Data is not empty, plot will be generated.\")\n        fig, ax = plt.subplots()\n        ax.plot(df)\n        return df, ax", "raw_solution": "import requests\nimport pandas as pd\nfrom requests.exceptions import HTTPError\nimport matplotlib.pyplot as plt\n\ndef task_func(api_url):\n    if not isinstance(api_url, str):\n        raise TypeError(\"api_url should be a string\")\n\n    try:\n        response = requests.get(api_url)\n        # If the response was successful, no Exception will be raised\n        response.raise_for_status()\n    except HTTPError as http_err:\n        print(f'HTTP error occurred: {http_err}')\n        raise HTTPError from http_err\n    except Exception as err:\n        print(f'Other error occurred: {err}')\n        raise err\n    else:\n        print('Success!')\n\n    data = response.json()\n    df = pd.DataFrame(data)\n\n    if df.empty:\n        print(\"Data is empty, no plot will be generated.\")\n        return df, None\n    else:\n        print(\"Data is not empty, plot will be generated.\")\n        fig, ax = plt.subplots()\n        ax.plot(df)\n        return df, ax"}
{"task_id": "BigCodeBench/1015", "solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        # Fetch the HTML content\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    # Parse the HTML content\n    try:\n        parsed_html = html.fromstring(response.content)\n        table_html = parsed_html.get_element_by_id('my_table')\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    # Convert the HTML table to a pandas DataFrame\n    try:\n        df = pd.read_html(html.tostring(table_html))[0]\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    # Connect to the SQLite database\n    try:\n        conn = sqlite3.connect(database_name)\n    except sqlite3.DatabaseError as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    # Replace the table with new data\n    try:\n        df.to_sql('my_table', conn, if_exists='replace', index=False)\n    except sqlite3.DatabaseError as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    # Close the connection\n    conn.close()\n\n    # Return the number of rows in the parsed HTML table\n    return len(df.index)", "raw_solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\n\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        # Fetch the HTML content\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    # Parse the HTML content\n    try:\n        parsed_html = html.fromstring(response.content)\n        table_html = parsed_html.get_element_by_id('my_table')\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    # Convert the HTML table to a pandas DataFrame\n    try:\n        df = pd.read_html(html.tostring(table_html))[0]\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    # Connect to the SQLite database\n    try:\n        conn = sqlite3.connect(database_name)\n    except sqlite3.DatabaseError as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    # Replace the table with new data\n    try:\n        df.to_sql('my_table', conn, if_exists='replace', index=False)\n    except sqlite3.DatabaseError as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    # Close the connection\n    conn.close()\n\n    # Return the number of rows in the parsed HTML table\n    return len(df.index)"}
{"task_id": "BigCodeBench/1016", "solution": "import requests\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(url: str) -> \"matplotlib.axes._axes.Axes\":\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as err:\n        raise ValueError(f\"Error downloading image: {err}\")\n\n    try:\n        img = Image.open(BytesIO(response.content))\n    except IOError as e:\n        raise IOError(f\"Error processing image: {e}\")\n\n    img_gray = img.convert('L')\n    img_array = np.array(img_gray)\n\n    histogram = plt.hist(img_array.ravel(), bins=256, range=(0,256))\n    plt.title(\"Grayscale Histogram\")\n    plt.xlabel(\"Grayscale Values\")\n    plt.ylabel(\"Frequency\")\n\n    return histogram", "raw_solution": "import requests\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(url: str) -> \"matplotlib.axes._axes.Axes\":\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as err:\n        raise ValueError(f\"Error downloading image: {err}\")\n\n    try:\n        img = Image.open(BytesIO(response.content))\n    except IOError as e:\n        raise IOError(f\"Error processing image: {e}\")\n\n    img_gray = img.convert('L')\n    img_array = np.array(img_gray)\n\n    histogram = plt.hist(img_array.ravel(), bins=256, range=(0,256))\n    plt.title(\"Grayscale Histogram\")\n    plt.xlabel(\"Grayscale Values\")\n    plt.ylabel(\"Frequency\")\n\n    return histogram"}
{"task_id": "BigCodeBench/1017", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\ndef task_func(csv_file_path, target_column=\"target\", test_size=0.2, n_estimators=100):\n    # Load the CSV file\n    try:\n        df = pd.read_csv(csv_file_path)\n    except FileNotFoundError:\n        return \"File not found. Please check the file path.\"\n\n    # Check if the target column exists\n    if target_column not in df.columns:\n        raise ValueError(f\"The specified target_column: {target_column} is not found in the CSV file.\")\n\n    # Split the data into features and target\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n\n    # Train the Random Forest classifier\n    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n    clf.fit(X_train, y_train)\n\n    # Make predictions\n    y_pred = clf.predict(X_test)\n\n    # Generate and return the classification report\n    report = classification_report(y_test, y_pred)\n    return report", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\ndef task_func(csv_file_path, target_column=\"target\", test_size=0.2, n_estimators=100):\n    # Load the CSV file\n    try:\n        df = pd.read_csv(csv_file_path)\n    except FileNotFoundError:\n        return \"File not found. Please check the file path.\"\n\n    # Check if the target column exists\n    if target_column not in df.columns:\n        raise ValueError(f\"The specified target_column: {target_column} is not found in the CSV file.\")\n\n    # Split the data into features and target\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n\n    # Train the Random Forest classifier\n    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n    clf.fit(X_train, y_train)\n\n    # Make predictions\n    y_pred = clf.predict(X_test)\n\n    # Generate and return the classification report\n    report = classification_report(y_test, y_pred)\n    return report"}
{"task_id": "BigCodeBench/1018", "solution": "from bs4 import BeautifulSoup\nimport requests\nURL = \"http://example.com\"\ndef task_func(url=URL, from_encoding=\"cp1251\", use_lxml=False):\n    # Return None if URL is empty or None\n    if not url:\n        return None\n\n    try:\n        # Fetch the web page\n        response = requests.get(url)\n\n        # Check for HTTP errors\n        response.raise_for_status()\n\n        # Check if the request was successful\n        if response.status_code == 200:\n            # Decode the content\n            content = response.content.decode(from_encoding)\n\n            # Parse the HTML using BeautifulSoup\n            parser = 'lxml' if use_lxml else 'html.parser'\n            soup = BeautifulSoup(content, parser)\n\n            return soup\n        else:\n            return None\n\n    except (requests.exceptions.RequestException, UnicodeDecodeError):\n        return None", "raw_solution": "from bs4 import BeautifulSoup\nimport requests\n\n# Constants\nURL = \"http://example.com\"\n\ndef task_func(url=URL, from_encoding=\"cp1251\", use_lxml=False):\n    # Return None if URL is empty or None\n    if not url:\n        return None\n\n    try:\n        # Fetch the web page\n        response = requests.get(url)\n\n        # Check for HTTP errors\n        response.raise_for_status()\n\n        # Check if the request was successful\n        if response.status_code == 200:\n            # Decode the content\n            content = response.content.decode(from_encoding)\n\n            # Parse the HTML using BeautifulSoup\n            parser = 'lxml' if use_lxml else 'html.parser'\n            soup = BeautifulSoup(content, parser)\n\n            return soup\n        else:\n            return None\n\n    except (requests.exceptions.RequestException, UnicodeDecodeError):\n        return None\n\n# Test the function\nsoup = task_func(URL, \"cp1251\", True)\nif soup:\n    print(\"Fetch and parse successful.\")\nelse:\n    print(\"Failed to fetch or parse the webpage.\")"}
{"task_id": "BigCodeBench/1019", "solution": "from PIL import Image\nimport codecs\nimport pytesseract\nIMAGE_PATH = \"image.png\"\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        # Open the image file\n        image = Image.open(filename)\n\n        # Extract text from the image using OCR\n        ocr_text = pytesseract.image_to_string(image, lang='eng')\n\n        # Convert the OCR text encoding\n        ocr_text = ocr_text.encode(from_encoding).decode(to_encoding)\n\n        return ocr_text\n\n    except (ValueError, UnicodeDecodeError, LookupError) as e:\n        try:\n            # If OCR extraction fails, try to extract text from the image comment\n            exif_data = image._getexif()\n            if exif_data is not None:\n                comment_text = exif_data.get(0x013B)\n                if comment_text is not None:\n                    comment_text = comment_text.encode(from_encoding).decode(to_encoding)\n                    return comment_text\n\n        except (ValueError, UnicodeDecodeError, LookupError) as e:\n            # If both OCR extraction and comment processing fail, return an empty string\n            return \"\"", "raw_solution": "from PIL import Image\nimport codecs\nimport pytesseract\n\nIMAGE_PATH = \"image.png\"\n\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        # Open the image file\n        image = Image.open(filename)\n\n        # Extract text from the image using OCR\n        ocr_text = pytesseract.image_to_string(image, lang='eng')\n\n        # Convert the OCR text encoding\n        ocr_text = ocr_text.encode(from_encoding).decode(to_encoding)\n\n        return ocr_text\n\n    except (ValueError, UnicodeDecodeError, LookupError) as e:\n        try:\n            # If OCR extraction fails, try to extract text from the image comment\n            exif_data = image._getexif()\n            if exif_data is not None:\n                comment_text = exif_data.get(0x013B)\n                if comment_text is not None:\n                    comment_text = comment_text.encode(from_encoding).decode(to_encoding)\n                    return comment_text\n\n        except (ValueError, UnicodeDecodeError, LookupError) as e:\n            # If both OCR extraction and comment processing fail, return an empty string\n            return \"\"\n\n# Test the function"}
{"task_id": "BigCodeBench/1020", "solution": "import json\nimport requests\nimport chardet\nAPI_URL = \"http://api.example.com/data\"\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    try:\n        response = requests.get(url, timeout=5)\n        content = response.content\n\n        if not content:\n            return {}\n\n        if not from_encoding:\n            from_encoding = chardet.detect(content)['encoding']\n            if not from_encoding:\n                raise ValueError(\"Unable to detect encoding for non-empty content\")\n\n        decoded_content = content.decode(from_encoding)\n        encoded_content = decoded_content.encode(to_encoding)\n\n        return json.loads(encoded_content)\n\n    except Exception as e:\n        raise e", "raw_solution": "import json\nimport requests\nimport chardet\n\n# Constants\nAPI_URL = \"http://api.example.com/data\"\n\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    try:\n        response = requests.get(url, timeout=5)\n        content = response.content\n\n        if not content:\n            return {}\n\n        if not from_encoding:\n            from_encoding = chardet.detect(content)['encoding']\n            if not from_encoding:\n                raise ValueError(\"Unable to detect encoding for non-empty content\")\n\n        decoded_content = content.decode(from_encoding)\n        encoded_content = decoded_content.encode(to_encoding)\n\n        return json.loads(encoded_content)\n\n    except Exception as e:\n        raise e\n\n# Test the function"}
{"task_id": "BigCodeBench/1021", "solution": "import hashlib\ndef task_func(input_string, verify_hash=None):\n    if not isinstance(input_string, str):\n        raise TypeError(\"input_string must be a string\")\n    if verify_hash is not None and not isinstance(verify_hash, str):\n        raise TypeError(\"verify_hash must be a string or None\")\n\n    hash_object = hashlib.sha256(input_string.encode())\n    hex_dig = hash_object.hexdigest()\n\n    if verify_hash is not None:\n        return hex_dig, hex_dig == verify_hash\n    else:\n        return hex_dig, None", "raw_solution": "import hashlib\n\ndef task_func(input_string, verify_hash=None):\n    if not isinstance(input_string, str):\n        raise TypeError(\"input_string must be a string\")\n    if verify_hash is not None and not isinstance(verify_hash, str):\n        raise TypeError(\"verify_hash must be a string or None\")\n\n    hash_object = hashlib.sha256(input_string.encode())\n    hex_dig = hash_object.hexdigest()\n\n    if verify_hash is not None:\n        return hex_dig, hex_dig == verify_hash\n    else:\n        return hex_dig, None\n\n# Test the function\nhash, match = task_func(\"Hello, World!\", \"7f83b1657ff1fc53b92dc18148a1d65dfca320781447e260260093cb1a51480c\")"}
{"task_id": "BigCodeBench/1022", "solution": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    # Check if file exists\n    if not os.path.isfile(csv_file_path):\n        raise FileNotFoundError(f\"The file {csv_file_path} does not exist.\")\n\n    # Read CSV file\n    try:\n        df = pd.read_csv(csv_file_path)\n    except EmptyDataError:\n        return pd.DataFrame()\n\n    # Check if column exists\n    if column_name not in df.columns:\n        raise ValueError(f\"The column {column_name} does not exist in the CSV file.\")\n\n    # Convert date values to datetime objects\n    df[column_name] = pd.to_datetime(df[column_name], format=date_format, errors='coerce')\n\n    # Filter rows based on the current date\n    df = df[df[column_name] <= datetime.now()]\n\n    # Sort the resulting data\n    df = df.sort_values(by=column_name)\n\n    return df", "raw_solution": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\n\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    # Check if file exists\n    if not os.path.isfile(csv_file_path):\n        raise FileNotFoundError(f\"The file {csv_file_path} does not exist.\")\n\n    # Read CSV file\n    try:\n        df = pd.read_csv(csv_file_path)\n    except EmptyDataError:\n        return pd.DataFrame()\n\n    # Check if column exists\n    if column_name not in df.columns:\n        raise ValueError(f\"The column {column_name} does not exist in the CSV file.\")\n\n    # Convert date values to datetime objects\n    df[column_name] = pd.to_datetime(df[column_name], format=date_format, errors='coerce')\n\n    # Filter rows based on the current date\n    df = df[df[column_name] <= datetime.now()]\n\n    # Sort the resulting data\n    df = df.sort_values(by=column_name)\n\n    return df"}
{"task_id": "BigCodeBench/1023", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(dataframe):\n    # Check if DataFrame is empty\n    if dataframe.empty:\n        raise ValueError(\"Input DataFrame is empty\")\n\n    # Check if DataFrame has at least two columns\n    if dataframe.shape[1] < 2:\n        raise ValueError(\"DataFrame has fewer than two columns\")\n\n    # Check if all columns are numeric\n    for col in dataframe.columns:\n        if not np.issubdtype(dataframe[col].dtype, np.number):\n            raise TypeError(\"All columns in the DataFrame should be numeric\")\n\n    # Calculate correlation matrix\n    corr_matrix = dataframe.corr().abs()\n\n    # Find the pair of columns with the highest absolute correlation\n    unstacked_corr_matrix = corr_matrix.unstack()\n    sorted_pairs = unstacked_corr_matrix.sort_values(ascending=False, kind=\"quicksort\")\n    highest_corr_pair = sorted_pairs.index[1]\n\n    # Plot scatter plot\n    plt.figure(figsize=(10, 8))\n    plt.scatter(dataframe[highest_corr_pair[0]], dataframe[highest_corr_pair[1]])\n    plt.xlabel(highest_corr_pair[0])\n    plt.ylabel(highest_corr_pair[1])\n    plt.title(f\"Scatter plot of {highest_corr_pair[0]} and {highest_corr_pair[1]}\")\n    plt.show()", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(dataframe):\n    # Check if DataFrame is empty\n    if dataframe.empty:\n        raise ValueError(\"Input DataFrame is empty\")\n\n    # Check if DataFrame has at least two columns\n    if dataframe.shape[1] < 2:\n        raise ValueError(\"DataFrame has fewer than two columns\")\n\n    # Check if all columns are numeric\n    for col in dataframe.columns:\n        if not np.issubdtype(dataframe[col].dtype, np.number):\n            raise TypeError(\"All columns in the DataFrame should be numeric\")\n\n    # Calculate correlation matrix\n    corr_matrix = dataframe.corr().abs()\n\n    # Find the pair of columns with the highest absolute correlation\n    unstacked_corr_matrix = corr_matrix.unstack()\n    sorted_pairs = unstacked_corr_matrix.sort_values(ascending=False, kind=\"quicksort\")\n    highest_corr_pair = sorted_pairs.index[1]\n\n    # Plot scatter plot\n    plt.figure(figsize=(10, 8))\n    plt.scatter(dataframe[highest_corr_pair[0]], dataframe[highest_corr_pair[1]])\n    plt.xlabel(highest_corr_pair[0])\n    plt.ylabel(highest_corr_pair[1])\n    plt.title(f\"Scatter plot of {highest_corr_pair[0]} and {highest_corr_pair[1]}\")\n    plt.show()"}
{"task_id": "BigCodeBench/1024", "solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nPLOT_TITLE = \"Value Distribution\"\ndef task_func(data_dict):\n    # Create a DataFrame from the dictionary\n    df = pd.DataFrame(list(data_dict.items()), columns=['Key', 'Value'])\n    \n    # Remove None values\n    df = df[df['Value'].notna()]\n    \n    # If the DataFrame is empty or all values are the same, return None\n    if df.empty or df['Value'].nunique() == 1:\n        return df, None\n    \n    # Calculate the number of bins dynamically\n    num_bins = max(2, min(11, int(df.shape[0]*0.5)))\n    \n    # Generate a histogram using seaborn\n    plot = sns.histplot(df['Value'], bins=num_bins, kde=False)\n    plot.set_title(PLOT_TITLE)\n    \n    return df, plot.get_figure()\ndata_dict = {'a': 1, 'b': 2, 'c': 2, 'd': 3, 'e': 4, 'f': 4, 'g': 5, 'h': None, 'i': 6, 'j': 7, 'k': 8, 'l': 8, 'm': 9, 'n': 10}", "raw_solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Constants\nPLOT_TITLE = \"Value Distribution\"\n\ndef task_func(data_dict):\n    # Create a DataFrame from the dictionary\n    df = pd.DataFrame(list(data_dict.items()), columns=['Key', 'Value'])\n    \n    # Remove None values\n    df = df[df['Value'].notna()]\n    \n    # If the DataFrame is empty or all values are the same, return None\n    if df.empty or df['Value'].nunique() == 1:\n        return df, None\n    \n    # Calculate the number of bins dynamically\n    num_bins = max(2, min(11, int(df.shape[0]*0.5)))\n    \n    # Generate a histogram using seaborn\n    plot = sns.histplot(df['Value'], bins=num_bins, kde=False)\n    plot.set_title(PLOT_TITLE)\n    \n    return df, plot.get_figure()\n\n# Test the function\ndata_dict = {'a': 1, 'b': 2, 'c': 2, 'd': 3, 'e': 4, 'f': 4, 'g': 5, 'h': None, 'i': 6, 'j': 7, 'k': 8, 'l': 8, 'm': 9, 'n': 10}\ndf, plot = task_func(data_dict)\nif plot is not None:\n    plt.show()"}
{"task_id": "BigCodeBench/1025", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nPLOT_TITLE = \"Scaled Values\"\ndef task_func(data_dict):\n    # Convert dictionary to DataFrame\n    df = pd.DataFrame(list(data_dict.items()), columns=['Key', 'Value'])\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the data\n    df[['Value']] = scaler.fit_transform(df[['Value']])\n\n    # Create a plot\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', x='Key', y='Value', ax=ax, legend=False)\n    ax.set_title(PLOT_TITLE)\n\n    return df, ax.figure", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Constants\nPLOT_TITLE = \"Scaled Values\"\n\ndef task_func(data_dict):\n    # Convert dictionary to DataFrame\n    df = pd.DataFrame(list(data_dict.items()), columns=['Key', 'Value'])\n\n    # Initialize MinMaxScaler\n    scaler = MinMaxScaler()\n\n    # Fit and transform the data\n    df[['Value']] = scaler.fit_transform(df[['Value']])\n\n    # Create a plot\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', x='Key', y='Value', ax=ax, legend=False)\n    ax.set_title(PLOT_TITLE)\n\n    return df, ax.figure"}
{"task_id": "BigCodeBench/1026", "solution": "import numpy as np\nfrom scipy.stats import ttest_ind\nimport matplotlib.pyplot as plt\ndef task_func(group1, group2, alpha=0.05, var_threshold=1e-8):\n    # Remove NaN values\n    group1 = group1[~np.isnan(group1)]\n    group2 = group2[~np.isnan(group2)]\n\n    # Check for sufficient data points and variance\n    if len(group1) < 2 or len(group2) < 2:\n        raise ValueError(\"Both groups should have at least two non-NaN values.\")\n    if np.var(group1) < var_threshold or np.var(group2) < var_threshold:\n        raise ValueError(\"Both groups should have a variance greater than the threshold.\")\n\n    # Perform t-test\n    t_stat, p_val = ttest_ind(group1, group2, nan_policy='omit')\n\n    # Compute descriptive statistics\n    group1_stats = {'mean': np.mean(group1), 'std': np.std(group1)}\n    group2_stats = {'mean': np.mean(group2), 'std': np.std(group2)}\n\n    # Create figure for boxplot and histogram\n    fig, (ax_boxplot, ax_histogram) = plt.subplots(2, sharex=True)\n\n    # Boxplot\n    ax_boxplot.boxplot([group1, group2], labels=['Group 1', 'Group 2'])\n    ax_boxplot.set_title('Boxplot of Group 1 and Group 2')\n\n    # Histogram\n    ax_histogram.hist(group1, alpha=0.5, label='Group 1')\n    ax_histogram.hist(group2, alpha=0.5, label='Group 2')\n    ax_histogram.set_title('Histogram of Group 1 and Group 2')\n    ax_histogram.legend(loc='upper right')\n\n    # Output\n    output = {\n        'significant': p_val < alpha,\n        'group1_stats': group1_stats,\n        'group2_stats': group2_stats,\n        'ax_boxplot': ax_boxplot,\n        'ax_histogram': ax_histogram\n    }\n\n    return output", "raw_solution": "import numpy as np\nfrom scipy.stats import ttest_ind\nimport matplotlib.pyplot as plt\n\ndef task_func(group1, group2, alpha=0.05, var_threshold=1e-8):\n    # Remove NaN values\n    group1 = group1[~np.isnan(group1)]\n    group2 = group2[~np.isnan(group2)]\n\n    # Check for sufficient data points and variance\n    if len(group1) < 2 or len(group2) < 2:\n        raise ValueError(\"Both groups should have at least two non-NaN values.\")\n    if np.var(group1) < var_threshold or np.var(group2) < var_threshold:\n        raise ValueError(\"Both groups should have a variance greater than the threshold.\")\n\n    # Perform t-test\n    t_stat, p_val = ttest_ind(group1, group2, nan_policy='omit')\n\n    # Compute descriptive statistics\n    group1_stats = {'mean': np.mean(group1), 'std': np.std(group1)}\n    group2_stats = {'mean': np.mean(group2), 'std': np.std(group2)}\n\n    # Create figure for boxplot and histogram\n    fig, (ax_boxplot, ax_histogram) = plt.subplots(2, sharex=True)\n\n    # Boxplot\n    ax_boxplot.boxplot([group1, group2], labels=['Group 1', 'Group 2'])\n    ax_boxplot.set_title('Boxplot of Group 1 and Group 2')\n\n    # Histogram\n    ax_histogram.hist(group1, alpha=0.5, label='Group 1')\n    ax_histogram.hist(group2, alpha=0.5, label='Group 2')\n    ax_histogram.set_title('Histogram of Group 1 and Group 2')\n    ax_histogram.legend(loc='upper right')\n\n    # Output\n    output = {\n        'significant': p_val < alpha,\n        'group1_stats': group1_stats,\n        'group2_stats': group2_stats,\n        'ax_boxplot': ax_boxplot,\n        'ax_histogram': ax_histogram\n    }\n\n    return output"}
{"task_id": "BigCodeBench/1027", "solution": "import binascii\nimport urllib.parse\ndef task_func(url):\n    try:\n        query_params = urllib.parse.urlparse(url).query\n        q_param_value = urllib.parse.parse_qs(query_params).get('q', [None])[0]\n        if q_param_value is not None:\n            decoded_str = binascii.unhexlify(q_param_value).decode('utf-8')\n            return decoded_str\n        else:\n            return None\n    except (binascii.Error, UnicodeDecodeError):\n        return None", "raw_solution": "import binascii\nimport urllib.parse\n\ndef task_func(url):\n    try:\n        query_params = urllib.parse.urlparse(url).query\n        q_param_value = urllib.parse.parse_qs(query_params).get('q', [None])[0]\n        if q_param_value is not None:\n            decoded_str = binascii.unhexlify(q_param_value).decode('utf-8')\n            return decoded_str\n        else:\n            return None\n    except (binascii.Error, UnicodeDecodeError):\n        return None\n\n# Testing\nurl1 = \"http://example.com/?q=48656c6c6f20576f726c64\"  # \"Hello World\" in hex\nurl2 = \"http://example.com/?q=7468697320697320612074657374\"  # \"this is a test\" in hex\nurl3 = \"http://example.com/?q=invalidhexstring\"  # Invalid hexadecimal string\n"}
{"task_id": "BigCodeBench/1028", "solution": "import subprocess\nimport time\nimport json\nimport platform\nimport psutil\nLOGFILE_PATH = \"logfile.log\"\ndef task_func(interval, duration):\n    if interval <= 0 or duration <= 0:\n        raise ValueError(\"Interval and duration must be greater than 0\")\n\n    start_time = time.time()\n    cpu_data = []\n\n    while time.time() - start_time <= duration:\n        cpu_percent = psutil.cpu_percent(interval=interval)\n        current_time = time.time()\n        cpu_data.append({\"timestamp\": current_time, \"cpu_usage\": cpu_percent})\n\n    try:\n        with open(LOGFILE_PATH, 'w') as logfile:\n            json.dump(cpu_data, logfile)\n    except IOError:\n        return None\n\n    return LOGFILE_PATH", "raw_solution": "import subprocess\nimport time\nimport json\nimport platform\nimport psutil\n\nLOGFILE_PATH = \"logfile.log\"\n\ndef task_func(interval, duration):\n    if interval <= 0 or duration <= 0:\n        raise ValueError(\"Interval and duration must be greater than 0\")\n\n    start_time = time.time()\n    cpu_data = []\n\n    while time.time() - start_time <= duration:\n        cpu_percent = psutil.cpu_percent(interval=interval)\n        current_time = time.time()\n        cpu_data.append({\"timestamp\": current_time, \"cpu_usage\": cpu_percent})\n\n    try:\n        with open(LOGFILE_PATH, 'w') as logfile:\n            json.dump(cpu_data, logfile)\n    except IOError:\n        return None\n\n    return LOGFILE_PATH"}
{"task_id": "BigCodeBench/1029", "solution": "import pandas as pd\nimport numpy as np\nimport string\ndef task_func(rows=100, columns=3):\n    # Generate column names\n    column_names = [string.ascii_lowercase[i] for i in range(columns)]\n    \n    # Generate random alphabets\n    data = np.random.choice(list(string.ascii_lowercase), size=(rows, columns))\n    \n    # Create DataFrame\n    df = pd.DataFrame(data, columns=column_names)\n    \n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport string\n\ndef task_func(rows=100, columns=3):\n    # Generate column names\n    column_names = [string.ascii_lowercase[i] for i in range(columns)]\n    \n    # Generate random alphabets\n    data = np.random.choice(list(string.ascii_lowercase), size=(rows, columns))\n    \n    # Create DataFrame\n    df = pd.DataFrame(data, columns=column_names)\n    \n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/1030", "solution": "import itertools\nimport string\nimport pandas as pd\ndef task_func():\n    # Generate all possible combinations (with replacement) of three letters from the alphabet\n    combinations = list(itertools.product(string.ascii_uppercase, repeat=3))\n\n    # Convert the list of tuples to a list of strings\n    combinations = [''.join(comb) for comb in combinations]\n\n    # Create a pandas DataFrame from the list of combinations\n    df = pd.DataFrame(combinations, columns=['Combinations'])\n\n    return df", "raw_solution": "import itertools\nimport string\nimport pandas as pd\n\ndef task_func():\n    # Generate all possible combinations (with replacement) of three letters from the alphabet\n    combinations = list(itertools.product(string.ascii_uppercase, repeat=3))\n\n    # Convert the list of tuples to a list of strings\n    combinations = [''.join(comb) for comb in combinations]\n\n    # Create a pandas DataFrame from the list of combinations\n    df = pd.DataFrame(combinations, columns=['Combinations'])\n\n    return df\n\n# Test the function\ndf = task_func()"}
{"task_id": "BigCodeBench/1031", "solution": "import random\nimport string\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(n_rows=1000):\n    if n_rows <= 0:\n        raise ValueError(\"n_rows should be greater than 0\")\n\n    # Generate random 3-letter strings\n    strings = [''.join(random.choices(string.ascii_lowercase, k=3)) for _ in range(n_rows)]\n\n    # Count the frequency of each string\n    counts = pd.Series(strings).value_counts()\n\n    # Get the top 30 unique strings\n    top_30_strings = counts.head(30)\n\n    # Plot the histogram\n    fig, ax = plt.subplots()\n    top_30_strings.plot(kind='bar', ax=ax)\n    ax.set_title('Frequency of the top 30 unique random 3-letter strings')\n    ax.set_xlabel('String')\n    ax.set_ylabel('Frequency')\n\n    return ax", "raw_solution": "import random\nimport string\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(n_rows=1000):\n    if n_rows <= 0:\n        raise ValueError(\"n_rows should be greater than 0\")\n\n    # Generate random 3-letter strings\n    strings = [''.join(random.choices(string.ascii_lowercase, k=3)) for _ in range(n_rows)]\n\n    # Count the frequency of each string\n    counts = pd.Series(strings).value_counts()\n\n    # Get the top 30 unique strings\n    top_30_strings = counts.head(30)\n\n    # Plot the histogram\n    fig, ax = plt.subplots()\n    top_30_strings.plot(kind='bar', ax=ax)\n    ax.set_title('Frequency of the top 30 unique random 3-letter strings')\n    ax.set_xlabel('String')\n    ax.set_ylabel('Frequency')\n\n    return ax"}
{"task_id": "BigCodeBench/1032", "solution": "import matplotlib.pyplot as plt\nimport random\nimport string\nimport pandas as pd\nimport seaborn as sns\nLETTERS = list(string.ascii_lowercase)\ndef task_func(rows=1000, string_length=3):\n    if rows == 0:\n        print(\"No data to generate heatmap.\")\n        return None\n\n    # Generate random strings\n    random_strings = [''.join(random.choices(LETTERS, k=string_length)) for _ in range(rows)]\n\n    # Create DataFrame\n    df = pd.DataFrame(random_strings, columns=['String'])\n\n    # One-hot encode the strings\n    df = pd.get_dummies(df['String'])\n\n    # Calculate the frequency of each letter\n    letter_frequencies = df.sum().sort_values(ascending=False)\n\n    # Create a correlation matrix\n    correlation_matrix = df.corr()\n\n    # Plot the heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n    plt.title('Heatmap of Correlation Matrix')\n    plt.show()\n\n    return letter_frequencies", "raw_solution": "import matplotlib.pyplot as plt\nimport random\nimport string\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nLETTERS = list(string.ascii_lowercase)\n\ndef task_func(rows=1000, string_length=3):\n    if rows == 0:\n        print(\"No data to generate heatmap.\")\n        return None\n\n    # Generate random strings\n    random_strings = [''.join(random.choices(LETTERS, k=string_length)) for _ in range(rows)]\n\n    # Create DataFrame\n    df = pd.DataFrame(random_strings, columns=['String'])\n\n    # One-hot encode the strings\n    df = pd.get_dummies(df['String'])\n\n    # Calculate the frequency of each letter\n    letter_frequencies = df.sum().sort_values(ascending=False)\n\n    # Create a correlation matrix\n    correlation_matrix = df.corr()\n\n    # Plot the heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n    plt.title('Heatmap of Correlation Matrix')\n    plt.show()\n\n    return letter_frequencies"}
{"task_id": "BigCodeBench/1033", "solution": "import itertools\nimport string\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func():\n    # Generate all possible 3-letter combinations\n    combinations = [''.join(i) for i in itertools.product(string.ascii_lowercase, repeat=3)]\n    \n    # Create a DataFrame from these combinations\n    df = pd.DataFrame(combinations, columns=['Combinations'])\n    \n    # Count the frequency of the first letters in these combinations\n    counts = df['Combinations'].str[0].value_counts()\n    \n    # Plot a histogram of the frequency\n    fig, ax = plt.subplots()\n    counts.plot(kind='bar', ax=ax)\n    ax.set_title('Frequency of the first letters in 3-letter combinations')\n    ax.set_xlabel('Letter')\n    ax.set_ylabel('Frequency')\n    \n    return (combinations, df, ax.figure)", "raw_solution": "import itertools\nimport string\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    # Generate all possible 3-letter combinations\n    combinations = [''.join(i) for i in itertools.product(string.ascii_lowercase, repeat=3)]\n    \n    # Create a DataFrame from these combinations\n    df = pd.DataFrame(combinations, columns=['Combinations'])\n    \n    # Count the frequency of the first letters in these combinations\n    counts = df['Combinations'].str[0].value_counts()\n    \n    # Plot a histogram of the frequency\n    fig, ax = plt.subplots()\n    counts.plot(kind='bar', ax=ax)\n    ax.set_title('Frequency of the first letters in 3-letter combinations')\n    ax.set_xlabel('Letter')\n    ax.set_ylabel('Frequency')\n    \n    return (combinations, df, ax.figure)\n\ncombinations, df, fig = task_func()\nplt.show()"}
{"task_id": "BigCodeBench/1034", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import distance\nCATEGORIES = [\"Electronics\", \"Clothing\", \"Home Decor\", \"Automotive\", \"Books\"]\ndef task_func(s1, s2):\n    # Ensure the inputs are pandas Series\n    if not isinstance(s1, pd.Series) or not isinstance(s2, pd.Series):\n        raise ValueError(\"Both inputs must be pandas Series\")\n\n    # Ensure the series have the same index\n    if not s1.index.equals(s2.index):\n        raise ValueError(\"Both series must have the same index\")\n\n    # Ensure the series have the same categories\n    if not set(s1.index).issubset(CATEGORIES) or not set(s2.index).issubset(CATEGORIES):\n        raise ValueError(\"Both series must have the same categories\")\n\n    # Filter the categories where both stores have sales exceeding the threshold\n    filtered_categories = s1[s1 > 200] & s2[s2 > 200]\n\n    # If no such categories exist, return None for the plot and 0.0 for the Euclidean distance\n    if filtered_categories.empty:\n        return None, 0.0\n\n    # Compute the Euclidean distance\n    euclidean_distance = distance.euclidean(s1[filtered_categories], s2[filtered_categories])\n\n    # Plot the series\n    fig, ax = plt.subplots()\n    ax.bar(filtered_categories.index, s1[filtered_categories], label='Store 1')\n    ax.bar(filtered_categories.index, s2[filtered_categories], label='Store 2')\n    ax.set_xlabel('Category')\n    ax.set_ylabel('Sales')\n    ax.legend()\n    plt.show()\n\n    return ax, euclidean_distance", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import distance\n\nCATEGORIES = [\"Electronics\", \"Clothing\", \"Home Decor\", \"Automotive\", \"Books\"]\n\ndef task_func(s1, s2):\n    # Ensure the inputs are pandas Series\n    if not isinstance(s1, pd.Series) or not isinstance(s2, pd.Series):\n        raise ValueError(\"Both inputs must be pandas Series\")\n\n    # Ensure the series have the same index\n    if not s1.index.equals(s2.index):\n        raise ValueError(\"Both series must have the same index\")\n\n    # Ensure the series have the same categories\n    if not set(s1.index).issubset(CATEGORIES) or not set(s2.index).issubset(CATEGORIES):\n        raise ValueError(\"Both series must have the same categories\")\n\n    # Filter the categories where both stores have sales exceeding the threshold\n    filtered_categories = s1[s1 > 200] & s2[s2 > 200]\n\n    # If no such categories exist, return None for the plot and 0.0 for the Euclidean distance\n    if filtered_categories.empty:\n        return None, 0.0\n\n    # Compute the Euclidean distance\n    euclidean_distance = distance.euclidean(s1[filtered_categories], s2[filtered_categories])\n\n    # Plot the series\n    fig, ax = plt.subplots()\n    ax.bar(filtered_categories.index, s1[filtered_categories], label='Store 1')\n    ax.bar(filtered_categories.index, s2[filtered_categories], label='Store 2')\n    ax.set_xlabel('Category')\n    ax.set_ylabel('Sales')\n    ax.legend()\n    plt.show()\n\n    return ax, euclidean_distance"}
{"task_id": "BigCodeBench/1035", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(feature: pd.Series, target: pd.Series) -> (np.ndarray, plt.Axes):\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(feature.values.reshape(-1,1), target.values, test_size=0.2, random_state=42)\n\n    # Standardize the features\n    sc = StandardScaler()\n    X_train = sc.fit_transform(X_train)\n    X_test = sc.transform(X_test)\n\n    # Train the logistic regression model\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n\n    # Predict the target for the test set\n    y_pred = model.predict(X_test)\n\n    # Create the confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n\n    # Plot the confusion matrix\n    fig, ax = plt.subplots(figsize=(6, 6))\n    sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r', ax=ax)\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n    plt.title('Confusion matrix')\n\n    return cm, ax", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(feature: pd.Series, target: pd.Series) -> (np.ndarray, plt.Axes):\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(feature.values.reshape(-1,1), target.values, test_size=0.2, random_state=42)\n\n    # Standardize the features\n    sc = StandardScaler()\n    X_train = sc.fit_transform(X_train)\n    X_test = sc.transform(X_test)\n\n    # Train the logistic regression model\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n\n    # Predict the target for the test set\n    y_pred = model.predict(X_test)\n\n    # Create the confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n\n    # Plot the confusion matrix\n    fig, ax = plt.subplots(figsize=(6, 6))\n    sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r', ax=ax)\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n    plt.title('Confusion matrix')\n\n    return cm, ax"}
{"task_id": "BigCodeBench/1036", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(s1, s2):\n    # Check if both inputs are pandas Series\n    if not isinstance(s1, pd.Series) or not isinstance(s2, pd.Series):\n        raise ValueError(\"Both inputs must be pandas Series\")\n\n    # Create a DataFrame from the two Series\n    df = pd.DataFrame({'s1': s1, 's2': s2})\n\n    # Create a swarm plot\n    ax = sns.swarmplot(x='s1', y='s2', data=df)\n\n    # Highlight the intersecting data points\n    intersecting_data = df[df['s1'].isin(df['s2'])]\n    for i, row in intersecting_data.iterrows():\n        ax.plot(row['s1'], row['s2'], 'ro')\n\n    # Count the number of unique intersecting data points\n    intersection_count = intersecting_data['s1'].nunique()\n\n    return ax, intersection_count\ns1 = pd.Series([1, 2, 3, 4, 5])\ns2 = pd.Series([4, 5, 6, 7, 8])", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(s1, s2):\n    # Check if both inputs are pandas Series\n    if not isinstance(s1, pd.Series) or not isinstance(s2, pd.Series):\n        raise ValueError(\"Both inputs must be pandas Series\")\n\n    # Create a DataFrame from the two Series\n    df = pd.DataFrame({'s1': s1, 's2': s2})\n\n    # Create a swarm plot\n    ax = sns.swarmplot(x='s1', y='s2', data=df)\n\n    # Highlight the intersecting data points\n    intersecting_data = df[df['s1'].isin(df['s2'])]\n    for i, row in intersecting_data.iterrows():\n        ax.plot(row['s1'], row['s2'], 'ro')\n\n    # Count the number of unique intersecting data points\n    intersection_count = intersecting_data['s1'].nunique()\n\n    return ax, intersection_count\n\n# Test the function\ns1 = pd.Series([1, 2, 3, 4, 5])\ns2 = pd.Series([4, 5, 6, 7, 8])\nax, intersection_count = task_func(s1, s2)"}
{"task_id": "BigCodeBench/1037", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(s1, s2, n_clusters=3):\n    # Check if s1 and s2 are pandas Series\n    if not isinstance(s1, pd.Series) or not isinstance(s2, pd.Series):\n        raise ValueError(\"s1 and s2 must be pandas Series\")\n\n    # Check if s1 and s2 have the same length\n    if len(s1) != len(s2):\n        raise ValueError(\"s1 and s2 must have the same length\")\n\n    # Combine s1 and s2 into a DataFrame\n    df = pd.DataFrame({'s1': s1, 's2': s2})\n\n    # Perform K-Means clustering\n    kmeans = KMeans(n_clusters=n_clusters)\n    labels = kmeans.fit_predict(df)\n\n    # Create a scatter plot\n    plt.scatter(df['s1'], df['s2'], c=labels)\n    plt.title(\"K-Means Clustering\")\n    plt.legend([\"Cluster 1\", \"Cluster 2\", \"Cluster 3\"])\n\n    return labels, plt.gca()", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(s1, s2, n_clusters=3):\n    # Check if s1 and s2 are pandas Series\n    if not isinstance(s1, pd.Series) or not isinstance(s2, pd.Series):\n        raise ValueError(\"s1 and s2 must be pandas Series\")\n\n    # Check if s1 and s2 have the same length\n    if len(s1) != len(s2):\n        raise ValueError(\"s1 and s2 must have the same length\")\n\n    # Combine s1 and s2 into a DataFrame\n    df = pd.DataFrame({'s1': s1, 's2': s2})\n\n    # Perform K-Means clustering\n    kmeans = KMeans(n_clusters=n_clusters)\n    labels = kmeans.fit_predict(df)\n\n    # Create a scatter plot\n    plt.scatter(df['s1'], df['s2'], c=labels)\n    plt.title(\"K-Means Clustering\")\n    plt.legend([\"Cluster 1\", \"Cluster 2\", \"Cluster 3\"])\n\n    return labels, plt.gca()"}
{"task_id": "BigCodeBench/1038", "solution": "from datetime import datetime\nimport json\ndef task_func(client_socket):\n    current_time = datetime.now().strftime(\"%H:%M:%S\")\n    message = {\"time\": current_time, \"greeting\": \"Hello, client!\"}\n    client_socket.send(json.dumps(message).encode())\n    client_socket.close()\n    return None", "raw_solution": "from datetime import datetime\nimport json\n\nSERVER_ADDRESS = \"localhost\"\nBUFFER_SIZE = 1024\n\ndef task_func(client_socket):\n    current_time = datetime.now().strftime(\"%H:%M:%S\")\n    message = {\"time\": current_time, \"greeting\": \"Hello, client!\"}\n    client_socket.send(json.dumps(message).encode())\n    client_socket.close()\n    return None"}
{"task_id": "BigCodeBench/1039", "solution": "import ssl\nimport os\nimport hashlib\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    try:\n        # Secure the client socket using SSL/TLS\n        context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n        context.load_cert_chain(cert_file, key_file)\n        secure_sock = context.wrap_socket(client_socket, server_side=True)\n\n        # Receive the file path from the client\n        file_path = secure_sock.recv(buffer_size).decode()\n\n        # Check if the file exists\n        if not os.path.isfile(file_path):\n            return 'File not found'\n\n        # Calculate the SHA256 hash of the file\n        sha256_hash = hashlib.sha256()\n        with open(file_path, \"rb\") as f:\n            for byte_block in iter(lambda: f.read(4096), b\"\"):\n                sha256_hash.update(byte_block)\n            return sha256_hash.hexdigest()\n\n    except Exception as e:\n        return str(e)", "raw_solution": "import ssl\nimport os\nimport hashlib\n\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    try:\n        # Secure the client socket using SSL/TLS\n        context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n        context.load_cert_chain(cert_file, key_file)\n        secure_sock = context.wrap_socket(client_socket, server_side=True)\n\n        # Receive the file path from the client\n        file_path = secure_sock.recv(buffer_size).decode()\n\n        # Check if the file exists\n        if not os.path.isfile(file_path):\n            return 'File not found'\n\n        # Calculate the SHA256 hash of the file\n        sha256_hash = hashlib.sha256()\n        with open(file_path, \"rb\") as f:\n            for byte_block in iter(lambda: f.read(4096), b\"\"):\n                sha256_hash.update(byte_block)\n            return sha256_hash.hexdigest()\n\n    except Exception as e:\n        return str(e)"}
{"task_id": "BigCodeBench/1040", "solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    # Create a TCP/IP socket\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_socket.bind((server_address, server_port))\n    server_socket.listen(5)\n\n    # List for socket descriptors\n    sockets_list = [server_socket]\n\n    # List for connected clients - socket as a key, user header and name as data\n    clients = {}\n\n    start_time = datetime.now()\n\n    print(f\"Server started at {start_time}\")\n\n    while (datetime.now() - start_time).seconds < run_duration:\n        read_sockets, _, exception_sockets = select.select(sockets_list, [], sockets_list)\n\n        # Handling received messages\n        for notified_socket in read_sockets:\n            if notified_socket == server_socket:\n                client_socket, client_address = server_socket.accept()\n                user = {\"header\": b\"\", \"data\": b\"\"}\n                sockets_list.append(client_socket)\n                clients[client_socket] = user\n            else:\n                data = notified_socket.recv(buffer_size)\n                if data:\n                    user = clients[notified_socket]\n                    user[\"data\"] += data\n                    if user[\"header\"] == b\"\":\n                        user[\"header\"] = data.split(b\"$\")[0]\n                        user[\"data\"] = data.split(b\"$\")[1]\n                    while True:\n                        if b\"$\" in user[\"data\"]:\n                            msg = user[\"data\"].split(b\"$\")[0]\n                            user[\"data\"] = user[\"data\"].split(b\"$\")[1]\n                            message = f\"{msg} at {datetime.now()}\".encode()\n                            notified_socket.send(user[\"header\"] + b\"$\" + message)\n                        else:\n                            break\n                else:\n                    # Remove the socket from our list\n                    sockets_list.remove(notified_socket)\n                    # Remove the socket from our dictionary\n                    del clients[notified_socket]\n                    continue\n\n        # Handling exceptions\n        for notified_socket in exception_sockets:\n            sockets_list.remove(notified_socket)\n            del clients[notified_socket]\n\n    end_time = datetime.now()\n    print(f\"Server stopped at {end_time}\")\n    print(f\"Server operation duration: {end_time - start_time}\")\n\n    # Close all sockets\n    for client_socket in clients:\n        client_socket.close()\n    server_socket.close()\n\n    return f\"Server started at {start_time} and stopped at {end_time}, operation duration: {end_time - start_time}\"", "raw_solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    # Create a TCP/IP socket\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_socket.bind((server_address, server_port))\n    server_socket.listen(5)\n\n    # List for socket descriptors\n    sockets_list = [server_socket]\n\n    # List for connected clients - socket as a key, user header and name as data\n    clients = {}\n\n    start_time = datetime.now()\n\n    print(f\"Server started at {start_time}\")\n\n    while (datetime.now() - start_time).seconds < run_duration:\n        read_sockets, _, exception_sockets = select.select(sockets_list, [], sockets_list)\n\n        # Handling received messages\n        for notified_socket in read_sockets:\n            if notified_socket == server_socket:\n                client_socket, client_address = server_socket.accept()\n                user = {\"header\": b\"\", \"data\": b\"\"}\n                sockets_list.append(client_socket)\n                clients[client_socket] = user\n            else:\n                data = notified_socket.recv(buffer_size)\n                if data:\n                    user = clients[notified_socket]\n                    user[\"data\"] += data\n                    if user[\"header\"] == b\"\":\n                        user[\"header\"] = data.split(b\"$\")[0]\n                        user[\"data\"] = data.split(b\"$\")[1]\n                    while True:\n                        if b\"$\" in user[\"data\"]:\n                            msg = user[\"data\"].split(b\"$\")[0]\n                            user[\"data\"] = user[\"data\"].split(b\"$\")[1]\n                            message = f\"{msg} at {datetime.now()}\".encode()\n                            notified_socket.send(user[\"header\"] + b\"$\" + message)\n                        else:\n                            break\n                else:\n                    # Remove the socket from our list\n                    sockets_list.remove(notified_socket)\n                    # Remove the socket from our dictionary\n                    del clients[notified_socket]\n                    continue\n\n        # Handling exceptions\n        for notified_socket in exception_sockets:\n            sockets_list.remove(notified_socket)\n            del clients[notified_socket]\n\n    end_time = datetime.now()\n    print(f\"Server stopped at {end_time}\")\n    print(f\"Server operation duration: {end_time - start_time}\")\n\n    # Close all sockets\n    for client_socket in clients:\n        client_socket.close()\n    server_socket.close()\n\n    return f\"Server started at {start_time} and stopped at {end_time}, operation duration: {end_time - start_time}\"\n"}
{"task_id": "BigCodeBench/1041", "solution": "import re\nimport os\ndef task_func(request):\n    # Check if the request is a GET request\n    if request.startswith('GET'):\n        # Extract the filename from the request\n        filename = re.search(r'GET /(.*) HTTP', request).group(1)\n        # Check if the file exists\n        if os.path.isfile(filename):\n            # Read the file content\n            with open(filename, 'r') as file:\n                file_content = file.read()\n            # Create the HTTP response\n            response = 'HTTP/1.1 200 OK\\nContent-Length: {}\\n\\n{}'.format(len(file_content), file_content)\n        else:\n            # File not found\n            response = 'HTTP/1.1 404 Not Found\\nContent-Length: 0\\n\\n'\n    else:\n        # Invalid request\n        response = 'HTTP/1.1 400 Bad Request\\nContent-Length: 0\\n\\n'\n    return response", "raw_solution": "import re\nimport os\n\ndef task_func(request):\n    # Check if the request is a GET request\n    if request.startswith('GET'):\n        # Extract the filename from the request\n        filename = re.search(r'GET /(.*) HTTP', request).group(1)\n        # Check if the file exists\n        if os.path.isfile(filename):\n            # Read the file content\n            with open(filename, 'r') as file:\n                file_content = file.read()\n            # Create the HTTP response\n            response = 'HTTP/1.1 200 OK\\nContent-Length: {}\\n\\n{}'.format(len(file_content), file_content)\n        else:\n            # File not found\n            response = 'HTTP/1.1 404 Not Found\\nContent-Length: 0\\n\\n'\n    else:\n        # Invalid request\n        response = 'HTTP/1.1 400 Bad Request\\nContent-Length: 0\\n\\n'\n    return response\n\n# Test the function"}
{"task_id": "BigCodeBench/1042", "solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\ndef task_func(client_socket):\n    # Receive message from client socket\n    data = client_socket.recv(1024).decode()\n\n    # Prompt for sender's email, recipient's email, and password\n    sender_email = input(\"Enter your email: \")\n    recipient_email = input(\"Enter recipient's email: \")\n    password = getpass.getpass(\"Enter your password: \")\n\n    # Create an email message\n    msg = EmailMessage()\n    msg.set_content(data)\n    msg['Subject'] = 'Message from client'\n    msg['From'] = sender_email\n    msg['To'] = recipient_email\n\n    # Send the email\n    server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n    server.starttls()\n    server.login(sender_email, password)\n    server.send_message(msg)\n    server.quit()\n\n    return None", "raw_solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\n\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\n\ndef task_func(client_socket):\n    # Receive message from client socket\n    data = client_socket.recv(1024).decode()\n\n    # Prompt for sender's email, recipient's email, and password\n    sender_email = input(\"Enter your email: \")\n    recipient_email = input(\"Enter recipient's email: \")\n    password = getpass.getpass(\"Enter your password: \")\n\n    # Create an email message\n    msg = EmailMessage()\n    msg.set_content(data)\n    msg['Subject'] = 'Message from client'\n    msg['From'] = sender_email\n    msg['To'] = recipient_email\n\n    # Send the email\n    server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n    server.starttls()\n    server.login(sender_email, password)\n    server.send_message(msg)\n    server.quit()\n\n    return None"}
{"task_id": "BigCodeBench/1043", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nCATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\"]\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"The data list is empty.\")\n\n    # Create a pandas Series from the data_list\n    data_series = pd.Series(data_list)\n\n    # Count the occurrences of each category\n    category_counts = data_series.value_counts()\n\n    # Get all categories (predefined and extra)\n    all_categories = CATEGORIES + category_counts.index.tolist()\n\n    # Reindex the category_counts to include all categories\n    category_counts = category_counts.reindex(all_categories, fill_value=0)\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    ax.bar(all_categories, category_counts, width=0.8, align=\"center\")\n\n    # Check if the distribution is uniform\n    if not category_counts.equals(category_counts.iloc[0]):\n        print(\"The distribution of predefined categories is not uniform.\")\n\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"The data list is empty.\")\n\n    # Create a pandas Series from the data_list\n    data_series = pd.Series(data_list)\n\n    # Count the occurrences of each category\n    category_counts = data_series.value_counts()\n\n    # Get all categories (predefined and extra)\n    all_categories = CATEGORIES + category_counts.index.tolist()\n\n    # Reindex the category_counts to include all categories\n    category_counts = category_counts.reindex(all_categories, fill_value=0)\n\n    # Create a bar plot\n    fig, ax = plt.subplots()\n    ax.bar(all_categories, category_counts, width=0.8, align=\"center\")\n\n    # Check if the distribution is uniform\n    if not category_counts.equals(category_counts.iloc[0]):\n        print(\"The distribution of predefined categories is not uniform.\")\n\n    return ax"}
{"task_id": "BigCodeBench/1044", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nROOMS = [\"Room1\", \"Room2\", \"Room3\", \"Room4\", \"Room5\"]\ndef task_func(date_str, booking_data):\n    # Validate date_str\n    try:\n        date = datetime.strptime(date_str, \"%Y-%m-%d\")\n    except ValueError:\n        raise ValueError(\"date_str does not follow the 'yyyy-mm-dd' format or is not a valid date.\")\n\n    # Validate date_str is not a past date\n    if date < datetime.now():\n        raise ValueError(\"date_str refers to a past date.\")\n\n    # Generate status report\n    status_report = pd.DataFrame(columns=[\"Room\", \"Status\"])\n    for room in ROOMS:\n        status = \"Booked\" if room in booking_data.keys() and booking_data[room] == date else \"Available\"\n        status_report = status_report.append({\"Room\": room, \"Status\": status}, ignore_index=True)\n\n    # Plot booking status\n    fig, ax = plt.subplots()\n    status_report.groupby(\"Status\").count().plot(kind=\"bar\", y=\"Room\", ax=ax)\n    ax.set_title(f\"Booking Status on {date_str}\")\n    ax.set_xlabel(\"Status\")\n    ax.set_ylabel(\"Number of Rooms\")\n\n    return status_report, ax.figure", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n# Constants\nROOMS = [\"Room1\", \"Room2\", \"Room3\", \"Room4\", \"Room5\"]\n\ndef task_func(date_str, booking_data):\n    # Validate date_str\n    try:\n        date = datetime.strptime(date_str, \"%Y-%m-%d\")\n    except ValueError:\n        raise ValueError(\"date_str does not follow the 'yyyy-mm-dd' format or is not a valid date.\")\n\n    # Validate date_str is not a past date\n    if date < datetime.now():\n        raise ValueError(\"date_str refers to a past date.\")\n\n    # Generate status report\n    status_report = pd.DataFrame(columns=[\"Room\", \"Status\"])\n    for room in ROOMS:\n        status = \"Booked\" if room in booking_data.keys() and booking_data[room] == date else \"Available\"\n        status_report = status_report.append({\"Room\": room, \"Status\": status}, ignore_index=True)\n\n    # Plot booking status\n    fig, ax = plt.subplots()\n    status_report.groupby(\"Status\").count().plot(kind=\"bar\", y=\"Room\", ax=ax)\n    ax.set_title(f\"Booking Status on {date_str}\")\n    ax.set_xlabel(\"Status\")\n    ax.set_ylabel(\"Number of Rooms\")\n\n    return status_report, ax.figure"}
{"task_id": "BigCodeBench/1045", "solution": "from datetime import datetime\nimport numpy as np\nfrom dateutil.parser import parse\nLEAP_SECONDS = np.array(\n    [\n        1972,\n        1973,\n        1974,\n        1975,\n        1976,\n        1977,\n        1978,\n        1979,\n        1980,\n        1981,\n        1982,\n        1983,\n        1985,\n        1988,\n        1990,\n        1993,\n        1994,\n        1997,\n        1999,\n        2006,\n        2009,\n        2012,\n        2015,\n        2016,\n        2020,\n    ]\n)\ndef task_func(date_str):\n    given_date = parse(date_str)\n    current_date = datetime.now()\n    elapsed_time = current_date - given_date\n    total_seconds = int(elapsed_time.total_seconds())\n    leap_seconds_added = len(LEAP_SECONDS[(LEAP_SECONDS >= given_date.year) & (LEAP_SECONDS <= current_date.year)])\n    total_seconds += leap_seconds_added\n    return total_seconds", "raw_solution": "from datetime import datetime\nimport numpy as np\nfrom dateutil.parser import parse\n\nLEAP_SECONDS = np.array(\n    [\n        1972,\n        1973,\n        1974,\n        1975,\n        1976,\n        1977,\n        1978,\n        1979,\n        1980,\n        1981,\n        1982,\n        1983,\n        1985,\n        1988,\n        1990,\n        1993,\n        1994,\n        1997,\n        1999,\n        2006,\n        2009,\n        2012,\n        2015,\n        2016,\n        2020,\n    ]\n)\n\ndef task_func(date_str):\n    given_date = parse(date_str)\n    current_date = datetime.now()\n    elapsed_time = current_date - given_date\n    total_seconds = int(elapsed_time.total_seconds())\n    leap_seconds_added = len(LEAP_SECONDS[(LEAP_SECONDS >= given_date.year) & (LEAP_SECONDS <= current_date.year)])\n    total_seconds += leap_seconds_added\n    return total_seconds\n\n# Testing the function"}
{"task_id": "BigCodeBench/1046", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nEMPLOYEES = [\"John\", \"Alice\", \"Bob\", \"Charlie\", \"Dave\"]\ndef task_func(date_str):\n    # Convert string to datetime object\n    date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n\n    # Generate a list of dates for the next 10 days\n    dates = [(date_obj + timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range(10)]\n\n    # Create a DataFrame\n    df = pd.DataFrame(list(product(EMPLOYEES, dates)), columns=[\"Employee\", \"Date\"])\n\n    return df", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\n\n# Constants\nEMPLOYEES = [\"John\", \"Alice\", \"Bob\", \"Charlie\", \"Dave\"]\n\ndef task_func(date_str):\n    # Convert string to datetime object\n    date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n\n    # Generate a list of dates for the next 10 days\n    dates = [(date_obj + timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range(10)]\n\n    # Create a DataFrame\n    df = pd.DataFrame(list(product(EMPLOYEES, dates)), columns=[\"Employee\", \"Date\"])\n\n    return df\n\n# Test the function"}
{"task_id": "BigCodeBench/1047", "solution": "from datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\ndef task_func(date_str):\n    # Parse the date\n    date = datetime.strptime(date_str, '%Y-%m-%d')\n\n    # Generate a list of random integers\n    random_numbers = [random.randint(0, 100) for _ in range(date.day)]\n\n    # Generate a line plot of these integers\n    ax = plt.plot(random_numbers)\n\n    return ax", "raw_solution": "from datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\n\ndef task_func(date_str):\n    # Parse the date\n    date = datetime.strptime(date_str, '%Y-%m-%d')\n\n    # Generate a list of random integers\n    random_numbers = [random.randint(0, 100) for _ in range(date.day)]\n\n    # Generate a line plot of these integers\n    ax = plt.plot(random_numbers)\n\n    return ax\n\n# Test the function\nax = task_func('2022-03-31')\nplt.show()"}
{"task_id": "BigCodeBench/1048", "solution": "from datetime import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(date_str):\n    date = datetime.strptime(date_str, '%Y-%m-%d')\n    day_of_month = date.day\n    frequency = day_of_month / 30  # Assuming 30 days in a month\n    x = np.linspace(0, 2 * np.pi, 100)\n    y = np.sin(frequency * x)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    ax.set_title('Sine wave with frequency determined by day of the month')\n    ax.set_xlabel('x')\n    ax.set_ylabel('sin(x)')\n\n    return ax", "raw_solution": "from datetime import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(date_str):\n    date = datetime.strptime(date_str, '%Y-%m-%d')\n    day_of_month = date.day\n    frequency = day_of_month / 30  # Assuming 30 days in a month\n    x = np.linspace(0, 2 * np.pi, 100)\n    y = np.sin(frequency * x)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    ax.set_title('Sine wave with frequency determined by day of the month')\n    ax.set_xlabel('x')\n    ax.set_ylabel('sin(x)')\n\n    return ax\n\n# Test the function\nax = task_func('2022-05-15')\nplt.show()"}
{"task_id": "BigCodeBench/1049", "solution": "import re\nimport pandas as pd\ndef task_func(input_string: str) -> pd.DataFrame:\n    lines = input_string.split('\\n')\n    lines = [re.sub('\\t', ' ', line) for line in lines]\n    lines = [line for line in lines if line.strip() != '']\n    return pd.DataFrame(lines, columns=['Text'])\ninput_string = \"\"\"\nThis is a test.\n    This is another test.\n\nAnd this is a third test.\n\"\"\"", "raw_solution": "import re\nimport pandas as pd\n\ndef task_func(input_string: str) -> pd.DataFrame:\n    lines = input_string.split('\\n')\n    lines = [re.sub('\\t', ' ', line) for line in lines]\n    lines = [line for line in lines if line.strip() != '']\n    return pd.DataFrame(lines, columns=['Text'])\n\n# Test the function\ninput_string = \"\"\"\nThis is a test.\n    This is another test.\n\nAnd this is a third test.\n\"\"\"\n"}
{"task_id": "BigCodeBench/1050", "solution": "import os\nimport hashlib\nDIRECTORY = \"./hashed_files\"\ndef task_func(input_string):\n    # Create directory if it doesn't exist\n    if not os.path.exists(DIRECTORY):\n        os.makedirs(DIRECTORY)\n\n    # Split input string into lines\n    lines = input_string.split('\\n')\n\n    # List to store file paths\n    file_paths = []\n\n    # Hash and save each non-empty line\n    for line in lines:\n        if line.strip():\n            # Hash the line\n            hashed_line = hashlib.sha256(line.encode()).hexdigest()\n\n            # Create file path\n            file_path = os.path.join(DIRECTORY, hashed_line[:10] + '.txt')\n\n            # Save the hash to the file\n            with open(file_path, 'w') as file:\n                file.write(hashed_line)\n\n            # Add file path to the list\n            file_paths.append(file_path)\n\n    # Return the list of file paths\n    return file_paths", "raw_solution": "import os\nimport hashlib\n\n# Constants\nDIRECTORY = \"./hashed_files\"\n\ndef task_func(input_string):\n    # Create directory if it doesn't exist\n    if not os.path.exists(DIRECTORY):\n        os.makedirs(DIRECTORY)\n\n    # Split input string into lines\n    lines = input_string.split('\\n')\n\n    # List to store file paths\n    file_paths = []\n\n    # Hash and save each non-empty line\n    for line in lines:\n        if line.strip():\n            # Hash the line\n            hashed_line = hashlib.sha256(line.encode()).hexdigest()\n\n            # Create file path\n            file_path = os.path.join(DIRECTORY, hashed_line[:10] + '.txt')\n\n            # Save the hash to the file\n            with open(file_path, 'w') as file:\n                file.write(hashed_line)\n\n            # Add file path to the list\n            file_paths.append(file_path)\n\n    # Return the list of file paths\n    return file_paths"}
{"task_id": "BigCodeBench/1051", "solution": "import collections\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data_dict):\n    if not data_dict:\n        return None, \"The distribution is uniform.\"\n\n    counts = list(data_dict.values())\n    avg_count = np.mean(counts)\n\n    is_uniform = all(abs(count - avg_count) <= 1e-5 for count in counts)\n\n    if is_uniform:\n        message = \"The distribution is uniform.\"\n    else:\n        message = \"The distribution is not uniform.\"\n\n    fig, ax = plt.subplots()\n    ax.hist(list(data_dict.keys()), bins=min(10, len(set(counts))), weights=counts)\n    ax.set_xticks(list(data_dict.keys()))\n    ax.set_xticklabels(list(data_dict.keys()))\n\n    return ax, message", "raw_solution": "import collections\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict):\n    if not data_dict:\n        return None, \"The distribution is uniform.\"\n\n    counts = list(data_dict.values())\n    avg_count = np.mean(counts)\n\n    is_uniform = all(abs(count - avg_count) <= 1e-5 for count in counts)\n\n    if is_uniform:\n        message = \"The distribution is uniform.\"\n    else:\n        message = \"The distribution is not uniform.\"\n\n    fig, ax = plt.subplots()\n    ax.hist(list(data_dict.keys()), bins=min(10, len(set(counts))), weights=counts)\n    ax.set_xticks(list(data_dict.keys()))\n    ax.set_xticklabels(list(data_dict.keys()))\n\n    return ax, message"}
{"task_id": "BigCodeBench/1052", "solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\ndef task_func(file_path, save_path=None):\n    # Load the CSV file\n    try:\n        df = pd.read_csv(file_path)\n    except Exception as e:\n        print(f\"Error loading file: {e}\")\n        return None\n\n    # Check if the dataframe is empty\n    if df.empty:\n        print(\"The input file is empty or contains only stop words.\")\n        return None\n\n    # Initialize CountVectorizer\n    vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n\n    # Fit and transform the data\n    X = vectorizer.fit_transform(df['text'])\n\n    # Get the word counts\n    word_counts = X.toarray().sum(axis=0)\n\n    # Get the top 10 words\n    top_10_words = vectorizer.get_feature_names_out()[word_counts.argsort()[-10:][::-1]]\n\n    # Create a histogram\n    fig, ax = plt.subplots()\n    ax.barh(top_10_words, word_counts[word_counts.argsort()[-10:][::-1]])\n    ax.set_xlabel('Frequency')\n    ax.set_ylabel('Words')\n    ax.set_title('Top 10 most common words')\n\n    # Save or display the plot\n    if save_path:\n        try:\n            plt.savefig(save_path)\n        except Exception as e:\n            print(f\"Error saving plot: {e}\")\n            return None\n    else:\n        plt.show()\n        return ax", "raw_solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n\n# Constants\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\n\ndef task_func(file_path, save_path=None):\n    # Load the CSV file\n    try:\n        df = pd.read_csv(file_path)\n    except Exception as e:\n        print(f\"Error loading file: {e}\")\n        return None\n\n    # Check if the dataframe is empty\n    if df.empty:\n        print(\"The input file is empty or contains only stop words.\")\n        return None\n\n    # Initialize CountVectorizer\n    vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n\n    # Fit and transform the data\n    X = vectorizer.fit_transform(df['text'])\n\n    # Get the word counts\n    word_counts = X.toarray().sum(axis=0)\n\n    # Get the top 10 words\n    top_10_words = vectorizer.get_feature_names_out()[word_counts.argsort()[-10:][::-1]]\n\n    # Create a histogram\n    fig, ax = plt.subplots()\n    ax.barh(top_10_words, word_counts[word_counts.argsort()[-10:][::-1]])\n    ax.set_xlabel('Frequency')\n    ax.set_ylabel('Words')\n    ax.set_title('Top 10 most common words')\n\n    # Save or display the plot\n    if save_path:\n        try:\n            plt.savefig(save_path)\n        except Exception as e:\n            print(f\"Error saving plot: {e}\")\n            return None\n    else:\n        plt.show()\n        return ax"}
{"task_id": "BigCodeBench/1053", "solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\ndef task_func(file_path, save_path=None):\n    try:\n        # Read CSV file\n        df = pd.read_csv(file_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None\n\n    # If the CSV file does not have a header, use the first column as the text data\n    if 'Text' not in df.columns:\n        df.columns = ['Text']\n\n    # Split the text into words\n    vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n    X = vectorizer.fit_transform(df['Text'])\n    word_counts = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n    word_counts = word_counts.sum().sort_values(ascending=False)\n\n    # Generate a histogram of the frequency of the top ten most common words\n    top_10_words = word_counts[:10]\n    ax = top_10_words.plot(kind='bar')\n\n    # Save the plot to a file if a save_path is provided\n    if save_path is not None:\n        plt.savefig(save_path)\n        return None\n\n    return ax", "raw_solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n\n# Constants\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\n\ndef task_func(file_path, save_path=None):\n    try:\n        # Read CSV file\n        df = pd.read_csv(file_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None\n\n    # If the CSV file does not have a header, use the first column as the text data\n    if 'Text' not in df.columns:\n        df.columns = ['Text']\n\n    # Split the text into words\n    vectorizer = CountVectorizer(stop_words=STOP_WORDS)\n    X = vectorizer.fit_transform(df['Text'])\n    word_counts = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n    word_counts = word_counts.sum().sort_values(ascending=False)\n\n    # Generate a histogram of the frequency of the top ten most common words\n    top_10_words = word_counts[:10]\n    ax = top_10_words.plot(kind='bar')\n\n    # Save the plot to a file if a save_path is provided\n    if save_path is not None:\n        plt.savefig(save_path)\n        return None\n\n    return ax"}
{"task_id": "BigCodeBench/1054", "solution": "import csv\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\ndef task_func(file_path):\n    try:\n        with open(file_path, 'r') as file:\n            reader = csv.reader(file)\n            population = [float(row[0]) for row in reader if row]\n    except (FileNotFoundError, IOError):\n        print(f\"Error: File {file_path} not found.\")\n        return\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return\n\n    sample = np.random.choice(population, size=30, replace=False)\n    sample_mean = np.mean(sample)\n    sample_stddev = np.std(sample, ddof=1)\n\n    fig, ax = plt.subplots()\n    ax.hist(sample, bins='auto', alpha=0.7, rwidth=0.85, color='#003f5c', density=True)\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = stats.norm.pdf(x, sample_mean, sample_stddev)\n    ax.plot(x, p, 'k', linewidth=2)\n    title = f\"Histogram and Normal Distribution Curve: Mean={sample_mean:.2f}, Stddev={sample_stddev:.2f}\"\n    plt.title(title)\n\n    return sample_mean, sample_stddev, ax", "raw_solution": "import csv\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path):\n    try:\n        with open(file_path, 'r') as file:\n            reader = csv.reader(file)\n            population = [float(row[0]) for row in reader if row]\n    except (FileNotFoundError, IOError):\n        print(f\"Error: File {file_path} not found.\")\n        return\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return\n\n    sample = np.random.choice(population, size=30, replace=False)\n    sample_mean = np.mean(sample)\n    sample_stddev = np.std(sample, ddof=1)\n\n    fig, ax = plt.subplots()\n    ax.hist(sample, bins='auto', alpha=0.7, rwidth=0.85, color='#003f5c', density=True)\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = stats.norm.pdf(x, sample_mean, sample_stddev)\n    ax.plot(x, p, 'k', linewidth=2)\n    title = f\"Histogram and Normal Distribution Curve: Mean={sample_mean:.2f}, Stddev={sample_stddev:.2f}\"\n    plt.title(title)\n\n    return sample_mean, sample_stddev, ax"}
{"task_id": "BigCodeBench/1055", "solution": "import pandas as pd\nimport itertools\nimport random\ndef task_func(colors, states):\n    # Generate all possible combinations of colors and states\n    combinations = list(itertools.product(colors, states))\n    \n    # Shuffle the combinations\n    random.shuffle(combinations)\n    \n    # Determine the number of columns\n    num_cols = min(len(colors), len(states))\n    \n    # Split the combinations into num_cols chunks\n    chunks = [combinations[i::num_cols] for i in range(num_cols)]\n    \n    # Create a DataFrame from the chunks\n    df = pd.DataFrame(chunks).T\n    \n    # Format the DataFrame\n    df.columns = [f\"Column {i+1}\" for i in range(num_cols)]\n    df = df.applymap(\":\".join, axis=1)\n    \n    return df", "raw_solution": "import pandas as pd\nimport itertools\nimport random\n\ndef task_func(colors, states):\n    # Generate all possible combinations of colors and states\n    combinations = list(itertools.product(colors, states))\n    \n    # Shuffle the combinations\n    random.shuffle(combinations)\n    \n    # Determine the number of columns\n    num_cols = min(len(colors), len(states))\n    \n    # Split the combinations into num_cols chunks\n    chunks = [combinations[i::num_cols] for i in range(num_cols)]\n    \n    # Create a DataFrame from the chunks\n    df = pd.DataFrame(chunks).T\n    \n    # Format the DataFrame\n    df.columns = [f\"Column {i+1}\" for i in range(num_cols)]\n    df = df.applymap(\":\".join, axis=1)\n    \n    return df"}
{"task_id": "BigCodeBench/1056", "solution": "import numpy as np\nimport random\nimport matplotlib.pyplot as plt\nLETTERS = list(\"abcdefghijklmnopqrstuvwxyz\")\nNUMBERS = list(range(1, 27))\ndef task_func(n_pairs=26):\n    if n_pairs < 1 or n_pairs > 26:\n        raise ValueError(\"'n_pairs' must be in the range of 1 to 26, inclusive.\")\n\n    # Generate letter-number pairs\n    pairs = [f\"{LETTERS[i]}:{NUMBERS[i]}\" for i in np.random.choice(range(26), size=n_pairs, replace=False)]\n    counts = [random.randint(1, 9) for _ in range(n_pairs)]\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    bars = ax.bar(pairs, counts)\n\n    # Label each bar with its corresponding pair\n    ax.bar_label(bars, labels=pairs)\n\n    # Set chart title and labels\n    ax.set_title(\"Random Letter:Number Pairs Chart\")\n    ax.set_xlabel(\"Letter:Number Pairs\")\n    ax.set_ylabel(\"Counts\")\n\n    plt.show()\n\n    return bars", "raw_solution": "import numpy as np\nimport random\nimport matplotlib.pyplot as plt\n\n# Constants\nLETTERS = list(\"abcdefghijklmnopqrstuvwxyz\")\nNUMBERS = list(range(1, 27))\n\ndef task_func(n_pairs=26):\n    if n_pairs < 1 or n_pairs > 26:\n        raise ValueError(\"'n_pairs' must be in the range of 1 to 26, inclusive.\")\n\n    # Generate letter-number pairs\n    pairs = [f\"{LETTERS[i]}:{NUMBERS[i]}\" for i in np.random.choice(range(26), size=n_pairs, replace=False)]\n    counts = [random.randint(1, 9) for _ in range(n_pairs)]\n\n    # Create bar chart\n    fig, ax = plt.subplots()\n    bars = ax.bar(pairs, counts)\n\n    # Label each bar with its corresponding pair\n    ax.bar_label(bars, labels=pairs)\n\n    # Set chart title and labels\n    ax.set_title(\"Random Letter:Number Pairs Chart\")\n    ax.set_xlabel(\"Letter:Number Pairs\")\n    ax.set_ylabel(\"Counts\")\n\n    plt.show()\n\n    return bars"}
{"task_id": "BigCodeBench/1057", "solution": "import pandas as pd\nimport itertools\nimport numpy as np\ndef task_func(animals=None, foods=None):\n    if animals is None:\n        animals = ['Dog', 'Cat', 'Bird']\n    if foods is None:\n        foods = ['Bone', 'Fish', 'Seed']\n    if not animals and not foods:\n        return pd.DataFrame()\n\n    combinations = list(itertools.product(animals, foods))\n    np.random.shuffle(combinations)\n    df = pd.DataFrame(combinations, columns=foods)\n    df.index = animals\n    df = df.astype(str) + ':' + df\n    return df", "raw_solution": "import pandas as pd\nimport itertools\nimport numpy as np\n\ndef task_func(animals=None, foods=None):\n    if animals is None:\n        animals = ['Dog', 'Cat', 'Bird']\n    if foods is None:\n        foods = ['Bone', 'Fish', 'Seed']\n    if not animals and not foods:\n        return pd.DataFrame()\n\n    combinations = list(itertools.product(animals, foods))\n    np.random.shuffle(combinations)\n    df = pd.DataFrame(combinations, columns=foods)\n    df.index = animals\n    df = df.astype(str) + ':' + df\n    return df\n\n# Testing the function"}
{"task_id": "BigCodeBench/1058", "solution": "import itertools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nSHAPES = [\n    \"Circle\",\n    \"Square\",\n    \"Triangle\",\n    \"Rectangle\",\n    \"Pentagon\",\n    \"Hexagon\",\n    \"Heptagon\",\n    \"Octagon\",\n    \"Nonagon\",\n    \"Decagon\",\n]\nCOLORS = [\n    \"Red\",\n    \"Blue\",\n    \"Green\",\n    \"Yellow\",\n    \"Black\",\n    \"White\",\n    \"Purple\",\n    \"Orange\",\n    \"Pink\",\n    \"Brown\",\n]\ndef task_func(num_pairs=10):\n    # Generate all possible shape-color pairs\n    pairs = list(itertools.product(SHAPES, COLORS))\n\n    # Select the first 'num_pairs' pairs\n    selected_pairs = pairs[:num_pairs]\n\n    # Create a DataFrame from the selected pairs\n    df = pd.DataFrame(selected_pairs, columns=[\"Shape\", \"Color\"])\n\n    # Generate the countplot\n    ax = sns.countplot(x=\"Shape\", hue=\"Color\", data=df)\n\n    return ax", "raw_solution": "import itertools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nSHAPES = [\n    \"Circle\",\n    \"Square\",\n    \"Triangle\",\n    \"Rectangle\",\n    \"Pentagon\",\n    \"Hexagon\",\n    \"Heptagon\",\n    \"Octagon\",\n    \"Nonagon\",\n    \"Decagon\",\n]\nCOLORS = [\n    \"Red\",\n    \"Blue\",\n    \"Green\",\n    \"Yellow\",\n    \"Black\",\n    \"White\",\n    \"Purple\",\n    \"Orange\",\n    \"Pink\",\n    \"Brown\",\n]\n\ndef task_func(num_pairs=10):\n    # Generate all possible shape-color pairs\n    pairs = list(itertools.product(SHAPES, COLORS))\n\n    # Select the first 'num_pairs' pairs\n    selected_pairs = pairs[:num_pairs]\n\n    # Create a DataFrame from the selected pairs\n    df = pd.DataFrame(selected_pairs, columns=[\"Shape\", \"Color\"])\n\n    # Generate the countplot\n    ax = sns.countplot(x=\"Shape\", hue=\"Color\", data=df)\n\n    return ax\n\n# Test the function\nax = task_func(10)\nplt.show()"}
{"task_id": "BigCodeBench/1059", "solution": "import numpy as np\nimport random\nimport itertools\nimport pandas as pd\nPLANETS = [\n    \"Mercury\",\n    \"Venus\",\n    \"Earth\",\n    \"Mars\",\n    \"Jupiter\",\n    \"Saturn\",\n    \"Uranus\",\n    \"Neptune\",\n]\nELEMENTS = [\n    \"Hydrogen\",\n    \"Helium\",\n    \"Oxygen\",\n    \"Carbon\",\n    \"Nitrogen\",\n    \"Magnesium\",\n    \"Silicon\",\n    \"Iron\",\n    \"Nickel\",\n]\ndef task_func():\n    # Generate all possible planet-element pairs\n    pairs = list(itertools.product(PLANETS, ELEMENTS))\n\n    # Shuffle the pairs\n    random.shuffle(pairs)\n\n    # Create a DataFrame from the pairs\n    df = pd.DataFrame(pairs, columns=[f'Column{i+1}' for i in range(len(ELEMENTS))])\n\n    return df", "raw_solution": "import numpy as np\nimport random\nimport itertools\nimport pandas as pd\n\n# Constants\nPLANETS = [\n    \"Mercury\",\n    \"Venus\",\n    \"Earth\",\n    \"Mars\",\n    \"Jupiter\",\n    \"Saturn\",\n    \"Uranus\",\n    \"Neptune\",\n]\nELEMENTS = [\n    \"Hydrogen\",\n    \"Helium\",\n    \"Oxygen\",\n    \"Carbon\",\n    \"Nitrogen\",\n    \"Magnesium\",\n    \"Silicon\",\n    \"Iron\",\n    \"Nickel\",\n]\n\ndef task_func():\n    # Generate all possible planet-element pairs\n    pairs = list(itertools.product(PLANETS, ELEMENTS))\n\n    # Shuffle the pairs\n    random.shuffle(pairs)\n\n    # Create a DataFrame from the pairs\n    df = pd.DataFrame(pairs, columns=[f'Column{i+1}' for i in range(len(ELEMENTS))])\n\n    return df\n\n# Test the function\ndf = task_func()"}
{"task_id": "BigCodeBench/1060", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame, column_name: str) -> (str, plt.Axes):\n    if df.empty or column_name not in df.columns or df[column_name].isnull().all():\n        plt.figure()\n        plt.title(\"Distribution of values in \" + column_name + \" (No Data)\")\n        plt.show()\n        return \"The DataFrame is empty or the specified column has no data.\", plt.gca()\n\n    unique_values = df[column_name].nunique()\n    is_uniform = df[column_name].nunique() == len(df)\n\n    plt.figure()\n    plt.hist(df[column_name], bins=unique_values, edgecolor='black', alpha=0.7)\n    plt.xlabel(\"Values\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Distribution of values in \" + column_name)\n    plt.show()\n\n    return (\"The distribution of values is uniform.\", plt.gca()) if is_uniform else (\"The distribution of values is not uniform.\", plt.gca())", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame, column_name: str) -> (str, plt.Axes):\n    if df.empty or column_name not in df.columns or df[column_name].isnull().all():\n        plt.figure()\n        plt.title(\"Distribution of values in \" + column_name + \" (No Data)\")\n        plt.show()\n        return \"The DataFrame is empty or the specified column has no data.\", plt.gca()\n\n    unique_values = df[column_name].nunique()\n    is_uniform = df[column_name].nunique() == len(df)\n\n    plt.figure()\n    plt.hist(df[column_name], bins=unique_values, edgecolor='black', alpha=0.7)\n    plt.xlabel(\"Values\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Distribution of values in \" + column_name)\n    plt.show()\n\n    return (\"The distribution of values is uniform.\", plt.gca()) if is_uniform else (\"The distribution of values is not uniform.\", plt.gca())"}
{"task_id": "BigCodeBench/1061", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(arr: np.ndarray) -> (plt.Axes, np.ndarray):\n    # Calculate the sum of elements in each row of the array\n    row_sums = np.sum(arr, axis=1)\n\n    # Calculate the mean and standard deviation of the row sums\n    mean = np.mean(row_sums)\n    std_dev = np.std(row_sums)\n\n    # Normalize the row sums\n    normalized_data = (row_sums - mean) / std_dev if std_dev != 0 else np.zeros_like(row_sums)\n\n    # Create a histogram of the normalized data\n    fig, ax = plt.subplots()\n    ax.hist(normalized_data, bins=30, color='g', alpha=0.6, density=True)\n\n    # Overlay the PDF of a standard normal distribution on the histogram\n    x = np.linspace(-4, 4, 1000)\n    ax.plot(x, norm.pdf(x), color='r', linewidth=2)\n\n    # Set the title of the plot\n    ax.set_title(\"Histogram of Normalized Data with Standard Normal PDF\")\n\n    return ax, normalized_data", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(arr: np.ndarray) -> (plt.Axes, np.ndarray):\n    # Calculate the sum of elements in each row of the array\n    row_sums = np.sum(arr, axis=1)\n\n    # Calculate the mean and standard deviation of the row sums\n    mean = np.mean(row_sums)\n    std_dev = np.std(row_sums)\n\n    # Normalize the row sums\n    normalized_data = (row_sums - mean) / std_dev if std_dev != 0 else np.zeros_like(row_sums)\n\n    # Create a histogram of the normalized data\n    fig, ax = plt.subplots()\n    ax.hist(normalized_data, bins=30, color='g', alpha=0.6, density=True)\n\n    # Overlay the PDF of a standard normal distribution on the histogram\n    x = np.linspace(-4, 4, 1000)\n    ax.plot(x, norm.pdf(x), color='r', linewidth=2)\n\n    # Set the title of the plot\n    ax.set_title(\"Histogram of Normalized Data with Standard Normal PDF\")\n\n    return ax, normalized_data"}
{"task_id": "BigCodeBench/1062", "solution": "import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\ndef task_func(arr):\n    if arr.size == 0:\n        fig, ax = plt.subplots()\n        ax.set_title('Time Series of Row Sums')\n        return ax\n    else:\n        sums = np.sum(arr, axis=1)\n        dates = pd.date_range(start='01-01-2020', periods=len(sums))\n        df = pd.DataFrame({'Date': dates, 'Sum': sums})\n        df.set_index('Date', inplace=True)\n        ax = df['Sum'].plot(kind='line', title='Time Series of Row Sums')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Sum')\n        return ax\narr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\ndef task_func(arr):\n    if arr.size == 0:\n        fig, ax = plt.subplots()\n        ax.set_title('Time Series of Row Sums')\n        return ax\n    else:\n        sums = np.sum(arr, axis=1)\n        dates = pd.date_range(start='01-01-2020', periods=len(sums))\n        df = pd.DataFrame({'Date': dates, 'Sum': sums})\n        df.set_index('Date', inplace=True)\n        ax = df['Sum'].plot(kind='line', title='Time Series of Row Sums')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Sum')\n        return ax\n\n# Testing the function\narr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nax = task_func(arr)\nplt.show()\n\n# Testing the function with an empty array\narr = np.array([])\nax = task_func(arr)\nplt.show()"}
{"task_id": "BigCodeBench/1063", "solution": "from matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\nimport numpy as np\ndef task_func(arr):\n    # Perform PCA\n    pca = PCA(n_components=1)\n    pca.fit(arr)\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot explained variance ratio\n    ax.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n\n    # Set title and labels\n    ax.set_title('Explained Variance Ratio of Principal Components')\n    ax.set_xlabel('Principal Component')\n    ax.set_ylabel('Explained Variance Ratio')\n\n    # Return the axis\n    return ax\narr = np.array([[1, 2], [3, 4], [5, 6]])", "raw_solution": "from matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\nimport numpy as np\n\ndef task_func(arr):\n    # Perform PCA\n    pca = PCA(n_components=1)\n    pca.fit(arr)\n\n    # Create a figure and axis\n    fig, ax = plt.subplots()\n\n    # Plot explained variance ratio\n    ax.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n\n    # Set title and labels\n    ax.set_title('Explained Variance Ratio of Principal Components')\n    ax.set_xlabel('Principal Component')\n    ax.set_ylabel('Explained Variance Ratio')\n\n    # Return the axis\n    return ax\n\n# Test the function\narr = np.array([[1, 2], [3, 4], [5, 6]])\nax = task_func(arr)\nplt.show()"}
{"task_id": "BigCodeBench/1064", "solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(arr):\n    # Calculate the sum of each row\n    row_sums = np.sum(arr, axis=1)\n    print(\"Sum of each row: \", row_sums)\n\n    # Create a heatmap\n    min_val = np.min(arr)\n    max_val = np.max(arr)\n    ax = sns.heatmap(arr, vmin=min_val, vmax=max_val, cmap='viridis')\n\n    return ax\narr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])", "raw_solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(arr):\n    # Calculate the sum of each row\n    row_sums = np.sum(arr, axis=1)\n    print(\"Sum of each row: \", row_sums)\n\n    # Create a heatmap\n    min_val = np.min(arr)\n    max_val = np.max(arr)\n    ax = sns.heatmap(arr, vmin=min_val, vmax=max_val, cmap='viridis')\n\n    return ax\n\n# Test the function\narr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nax = task_func(arr)\nplt.show()"}
{"task_id": "BigCodeBench/1065", "solution": "from scipy import fftpack\nimport numpy as np\nfrom matplotlib import pyplot as plt\ndef task_func(arr):\n    # Perform FFT on each row and sum them up\n    sum_rows = np.sum(arr, axis=1)\n    fft_coeff = np.abs(fftpack.fft(sum_rows))\n\n    # Plot the absolute values of the FFT coefficients\n    plt.plot(fft_coeff)\n    plt.title('FFT Coefficients of Sum of Rows')\n    plt.xlabel('Frequency')\n    plt.ylabel('Magnitude')\n    return plt.gca()\narr = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])", "raw_solution": "from scipy import fftpack\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\ndef task_func(arr):\n    # Perform FFT on each row and sum them up\n    sum_rows = np.sum(arr, axis=1)\n    fft_coeff = np.abs(fftpack.fft(sum_rows))\n\n    # Plot the absolute values of the FFT coefficients\n    plt.plot(fft_coeff)\n    plt.title('FFT Coefficients of Sum of Rows')\n    plt.xlabel('Frequency')\n    plt.ylabel('Magnitude')\n    return plt.gca()\n\n# Test the function\narr = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nax = task_func(arr)\nplt.show()"}
{"task_id": "BigCodeBench/1066", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nNUM_SAMPLES = 100\nNUM_OUTLIERS = 5\ndef task_func(num_samples=NUM_SAMPLES, num_outliers=NUM_OUTLIERS):\n    # Generate normally distributed data\n    data = np.random.normal(0, 1, num_samples)\n\n    # Generate artificially introduced outliers\n    outliers = np.random.uniform(-3, 3, num_outliers)\n    data = np.append(data, outliers)\n\n    # Detect outliers using IQR method\n    Q1 = np.percentile(data[:num_samples], 25)\n    Q3 = np.percentile(data[:num_samples], 75)\n    IQR = Q3 - Q1\n    outliers_detected = data[(data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))]\n\n    # Plot histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=20, color='blue', alpha=0.5)\n    ax.axvline(x=Q1 - 1.5 * IQR, color='r', linestyle='--')\n    ax.axvline(x=Q3 + 1.5 * IQR, color='r', linestyle='--')\n    ax.set_title('Histogram of Data with Outliers')\n\n    return data, outliers_detected, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nNUM_SAMPLES = 100\nNUM_OUTLIERS = 5\n\ndef task_func(num_samples=NUM_SAMPLES, num_outliers=NUM_OUTLIERS):\n    # Generate normally distributed data\n    data = np.random.normal(0, 1, num_samples)\n\n    # Generate artificially introduced outliers\n    outliers = np.random.uniform(-3, 3, num_outliers)\n    data = np.append(data, outliers)\n\n    # Detect outliers using IQR method\n    Q1 = np.percentile(data[:num_samples], 25)\n    Q3 = np.percentile(data[:num_samples], 75)\n    IQR = Q3 - Q1\n    outliers_detected = data[(data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))]\n\n    # Plot histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=20, color='blue', alpha=0.5)\n    ax.axvline(x=Q1 - 1.5 * IQR, color='r', linestyle='--')\n    ax.axvline(x=Q3 + 1.5 * IQR, color='r', linestyle='--')\n    ax.set_title('Histogram of Data with Outliers')\n\n    return data, outliers_detected, ax\n\n# Test the function\ndata, outliers_detected, ax = task_func()"}
{"task_id": "BigCodeBench/1067", "solution": "import requests\nimport logging\ndef task_func(repo_url: str) -> dict:\n    try:\n        response = requests.get(repo_url)\n        # If the response was successful, no Exception will be raised\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as http_err:\n        logging.error('HTTP error occurred: {}'.format(http_err))\n        raise\n    except requests.exceptions.RequestException as err:\n        logging.error('Request exception occurred: {}'.format(err))\n        raise\n\n    repo_info = response.json()\n\n    # Check for a large number of open issues\n    if 'open_issues' in repo_info and repo_info['open_issues'] > 100:\n        logging.warning('The repository has a large number of open issues: {}'.format(repo_info['open_issues']))\n\n    return repo_info", "raw_solution": "import requests\nimport logging\n\ndef task_func(repo_url: str) -> dict:\n    try:\n        response = requests.get(repo_url)\n        # If the response was successful, no Exception will be raised\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as http_err:\n        logging.error('HTTP error occurred: {}'.format(http_err))\n        raise\n    except requests.exceptions.RequestException as err:\n        logging.error('Request exception occurred: {}'.format(err))\n        raise\n\n    repo_info = response.json()\n\n    # Check for a large number of open issues\n    if 'open_issues' in repo_info and repo_info['open_issues'] > 100:\n        logging.warning('The repository has a large number of open issues: {}'.format(repo_info['open_issues']))\n\n    return repo_info"}
{"task_id": "BigCodeBench/1068", "solution": "import warnings\nimport sqlite3\nimport pandas as pd\ndef task_func(db_path, query, warn_large_dataset=True):\n    try:\n        # Connect to the SQLite database\n        conn = sqlite3.connect(db_path)\n\n        # Execute the SQL query\n        cursor = conn.execute(query)\n\n        # Fetch the data\n        data = cursor.fetchall()\n\n        # Check if the data contains more than 10000 rows\n        if warn_large_dataset and len(data) > 10000:\n            warnings.warn(\"The data contains more than 10000 rows.\")\n\n        # Convert the data to a pandas DataFrame\n        df = pd.DataFrame(data)\n\n        # Close the connection\n        conn.close()\n\n        return df\n\n    except Exception as e:\n        # Raise an exception if any error occurs during database connection, SQL query execution, or data fetching\n        raise Exception(f\"Error fetching data from the database: {str(e)}\")", "raw_solution": "import warnings\nimport sqlite3\nimport pandas as pd\n\ndef task_func(db_path, query, warn_large_dataset=True):\n    try:\n        # Connect to the SQLite database\n        conn = sqlite3.connect(db_path)\n\n        # Execute the SQL query\n        cursor = conn.execute(query)\n\n        # Fetch the data\n        data = cursor.fetchall()\n\n        # Check if the data contains more than 10000 rows\n        if warn_large_dataset and len(data) > 10000:\n            warnings.warn(\"The data contains more than 10000 rows.\")\n\n        # Convert the data to a pandas DataFrame\n        df = pd.DataFrame(data)\n\n        # Close the connection\n        conn.close()\n\n        return df\n\n    except Exception as e:\n        # Raise an exception if any error occurs during database connection, SQL query execution, or data fetching\n        raise Exception(f\"Error fetching data from the database: {str(e)}\")"}
{"task_id": "BigCodeBench/1069", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data_dict):\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame(data_dict)\n\n    # Initialize an empty list to store the Axes objects\n    axes_list = []\n\n    # Iterate over each column in the DataFrame\n    for col in df.columns:\n        # Generate a histogram for the column\n        ax = df[col].plot(kind='hist', rwidth=0.8)\n\n        # Add the Axes object to the list\n        axes_list.append(ax)\n\n        # Check if the distribution is uniform\n        if not df[col].is_monotonic_increasing and not df[col].is_monotonic_decreasing:\n            print(f\"The distribution of the column '{col}' is not uniform.\")\n\n    # Return the list of Axes objects\n    return axes_list", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict):\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame(data_dict)\n\n    # Initialize an empty list to store the Axes objects\n    axes_list = []\n\n    # Iterate over each column in the DataFrame\n    for col in df.columns:\n        # Generate a histogram for the column\n        ax = df[col].plot(kind='hist', rwidth=0.8)\n\n        # Add the Axes object to the list\n        axes_list.append(ax)\n\n        # Check if the distribution is uniform\n        if not df[col].is_monotonic_increasing and not df[col].is_monotonic_decreasing:\n            print(f\"The distribution of the column '{col}' is not uniform.\")\n\n    # Return the list of Axes objects\n    return axes_list"}
{"task_id": "BigCodeBench/1070", "solution": "import pandas as pd\nfrom random import shuffle\nPOSSIBLE_VALUES = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"]\ndef task_func(list_of_lists):\n    # Shuffle the possible values\n    shuffle(POSSIBLE_VALUES)\n\n    # Create a list to store the DataFrames\n    df_list = []\n\n    # Iterate over the sublists\n    for sublist in list_of_lists:\n        # Create a DataFrame from the sublist\n        df = pd.DataFrame(sublist)\n\n        # Shuffle the possible values\n        shuffle(POSSIBLE_VALUES)\n\n        # Add the shuffled values to the DataFrame\n        for i in range(len(sublist)):\n            df[i] = POSSIBLE_VALUES\n\n        # Append the DataFrame to the list\n        df_list.append(df)\n\n    return df_list\nlist_of_lists = [[\"a\", \"b\", \"c\"], [\"d\", \"e\", \"f\"], [\"g\", \"h\", \"i\"]]", "raw_solution": "import pandas as pd\nfrom random import shuffle\n\n# Constants\nPOSSIBLE_VALUES = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"]\n\ndef task_func(list_of_lists):\n    # Shuffle the possible values\n    shuffle(POSSIBLE_VALUES)\n\n    # Create a list to store the DataFrames\n    df_list = []\n\n    # Iterate over the sublists\n    for sublist in list_of_lists:\n        # Create a DataFrame from the sublist\n        df = pd.DataFrame(sublist)\n\n        # Shuffle the possible values\n        shuffle(POSSIBLE_VALUES)\n\n        # Add the shuffled values to the DataFrame\n        for i in range(len(sublist)):\n            df[i] = POSSIBLE_VALUES\n\n        # Append the DataFrame to the list\n        df_list.append(df)\n\n    return df_list\n\n# Test the function\nlist_of_lists = [[\"a\", \"b\", \"c\"], [\"d\", \"e\", \"f\"], [\"g\", \"h\", \"i\"]]\ndfs = task_func(list_of_lists)\nfor df in dfs:\n    print(df)\n    print()"}
{"task_id": "BigCodeBench/1071", "solution": "import matplotlib.pyplot as plt\nfrom itertools import cycle\nimport numpy as np\nfrom random import shuffle\nCOLORS = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\ndef task_func(list_of_lists):\n    fig, ax = plt.subplots()\n    color_cycle = cycle(COLORS)\n    for lst in list_of_lists:\n        if lst:\n            y = lst[:]\n            shuffle(y)\n            x = np.arange(1, len(lst) + 1)\n            ax.plot(x, y, color=next(color_cycle))\n    return fig, ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom itertools import cycle\nimport numpy as np\nfrom random import shuffle\n\nCOLORS = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\n\ndef task_func(list_of_lists):\n    fig, ax = plt.subplots()\n    color_cycle = cycle(COLORS)\n    for lst in list_of_lists:\n        if lst:\n            y = lst[:]\n            shuffle(y)\n            x = np.arange(1, len(lst) + 1)\n            ax.plot(x, y, color=next(color_cycle))\n    return fig, ax"}
{"task_id": "BigCodeBench/1072", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(list_of_lists):\n    np.random.seed(0)  # for reproducibility\n    series_list = []\n    for sublist in list_of_lists:\n        n = len(sublist)\n        values = np.arange(1, n+1)  # generate unique integers\n        np.random.shuffle(values)  # shuffle them\n        series = pd.Series(values, index=sublist)\n        series_list.append(series)\n    return series_list\nlist_of_lists = [['a', 'b', 'c'], ['x', 'y', 'z', 'w'], ['p', 'q']]", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(list_of_lists):\n    np.random.seed(0)  # for reproducibility\n    series_list = []\n    for sublist in list_of_lists:\n        n = len(sublist)\n        values = np.arange(1, n+1)  # generate unique integers\n        np.random.shuffle(values)  # shuffle them\n        series = pd.Series(values, index=sublist)\n        series_list.append(series)\n    return series_list\n\n# Test the function\nlist_of_lists = [['a', 'b', 'c'], ['x', 'y', 'z', 'w'], ['p', 'q']]\nseries_list = task_func(list_of_lists)\nfor series in series_list:\n    print(series)"}
{"task_id": "BigCodeBench/1073", "solution": "import time\nimport matplotlib.pyplot as plt\ndef task_func(time_strings, time_format=\"%d/%m/%Y %H:%M:%S.%f\"):\n    try:\n        # Convert all time strings to seconds\n        time_seconds = [time.mktime(time.strptime(t, time_format)) for t in time_strings]\n\n        # Plot histogram\n        fig, ax = plt.subplots()\n        ax.hist(time_seconds, bins='auto', color='#1f77b4')\n        ax.set_xlabel('Time (seconds)')\n        ax.set_ylabel('Frequency')\n        ax.set_title('Histogram of Time Strings')\n        plt.show()\n\n        return ax\n    except ValueError:\n        print(\"ValueError: One or more time strings could not be parsed according to the provided format.\")\n        return None\ntime_strings = [\"12/12/2020 12:12:12.123\", \"13/12/2020 13:13:13.132\", \"14/12/2020 14:14:14.141\"]", "raw_solution": "import time\nimport matplotlib.pyplot as plt\n\ndef task_func(time_strings, time_format=\"%d/%m/%Y %H:%M:%S.%f\"):\n    try:\n        # Convert all time strings to seconds\n        time_seconds = [time.mktime(time.strptime(t, time_format)) for t in time_strings]\n\n        # Plot histogram\n        fig, ax = plt.subplots()\n        ax.hist(time_seconds, bins='auto', color='#1f77b4')\n        ax.set_xlabel('Time (seconds)')\n        ax.set_ylabel('Frequency')\n        ax.set_title('Histogram of Time Strings')\n        plt.show()\n\n        return ax\n    except ValueError:\n        print(\"ValueError: One or more time strings could not be parsed according to the provided format.\")\n        return None\n\n# Test the function\ntime_strings = [\"12/12/2020 12:12:12.123\", \"13/12/2020 13:13:13.132\", \"14/12/2020 14:14:14.141\"]\ntask_func(time_strings)"}
{"task_id": "BigCodeBench/1074", "solution": "import pytz\nfrom dateutil.parser import parse\nfrom datetime import datetime\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_string, from_tz, to_tz):\n    # Parse the time string into a datetime object\n    dt = parse(time_string)\n\n    # Localize the datetime object to the source timezone\n    dt = dt.replace(tzinfo=pytz.timezone(from_tz))\n\n    # Convert the datetime object to the target timezone\n    dt = dt.astimezone(pytz.timezone(to_tz))\n\n    # Format the datetime object into a string\n    result = dt.strftime(TIME_FORMAT)\n\n    return result", "raw_solution": "import pytz\nfrom dateutil.parser import parse\nfrom datetime import datetime\n\n# Constants\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\n\ndef task_func(time_string, from_tz, to_tz):\n    # Parse the time string into a datetime object\n    dt = parse(time_string)\n\n    # Localize the datetime object to the source timezone\n    dt = dt.replace(tzinfo=pytz.timezone(from_tz))\n\n    # Convert the datetime object to the target timezone\n    dt = dt.astimezone(pytz.timezone(to_tz))\n\n    # Format the datetime object into a string\n    result = dt.strftime(TIME_FORMAT)\n\n    return result\n\n# Test the function"}
{"task_id": "BigCodeBench/1075", "solution": "import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_strings):\n    # Convert the time strings to datetime objects\n    time_objs = [datetime.datetime.strptime(time, TIME_FORMAT) for time in time_strings]\n\n    # Calculate the differences in seconds\n    diffs = [(time_objs[i] - time_objs[i-1]).total_seconds() for i in range(1, len(time_objs))]\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(range(len(diffs)), diffs)\n\n    return ax\ntime_strings = [\"30/12/20 12:00:00.000\", \"30/12/20 12:00:01.001\", \"30/12/20 12:00:02.002\"]", "raw_solution": "import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\n\ndef task_func(time_strings):\n    # Convert the time strings to datetime objects\n    time_objs = [datetime.datetime.strptime(time, TIME_FORMAT) for time in time_strings]\n\n    # Calculate the differences in seconds\n    diffs = [(time_objs[i] - time_objs[i-1]).total_seconds() for i in range(1, len(time_objs))]\n\n    # Create a bar chart\n    fig, ax = plt.subplots()\n    ax.bar(range(len(diffs)), diffs)\n\n    return ax\n\n# Test the function\ntime_strings = [\"30/12/20 12:00:00.000\", \"30/12/20 12:00:01.001\", \"30/12/20 12:00:02.002\"]\nax = task_func(time_strings)\nax.set_xlabel('Index')\nax.set_ylabel('Time Difference (s)')\nplt.show()"}
{"task_id": "BigCodeBench/1076", "solution": "from datetime import datetime\nimport pandas as pd\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_strings, target_tz):\n    # Initialize empty lists to store original and converted times\n    original_times = []\n    converted_times = []\n\n    # Iterate over each time string in the input list\n    for time_string in time_strings:\n        # Parse the time string into a datetime object\n        original_time = datetime.strptime(time_string, TIME_FORMAT)\n\n        # Convert the datetime object to the target timezone\n        converted_time = original_time.astimezone(ZoneInfo(target_tz))\n\n        # Append the original and converted times to their respective lists\n        original_times.append(original_time)\n        converted_times.append(converted_time)\n\n    # Create a DataFrame from the original and converted times\n    df = pd.DataFrame({\n        'Original Time': original_times,\n        'Converted Time': converted_times\n    })\n\n    return df\ntime_strings = ['31/12/21 23:59:59.999', '01/01/22 00:00:00.000']\ntarget_tz = 'Asia/Tokyo'", "raw_solution": "from datetime import datetime\nimport pandas as pd\n# For Python versions lower than 3.9, use 'pytz' instead of 'zoneinfo'\ntry:\n    from zoneinfo import ZoneInfo\nexcept ImportError:\n    from pytz import timezone as ZoneInfo\n\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\n\ndef task_func(time_strings, target_tz):\n    # Initialize empty lists to store original and converted times\n    original_times = []\n    converted_times = []\n\n    # Iterate over each time string in the input list\n    for time_string in time_strings:\n        # Parse the time string into a datetime object\n        original_time = datetime.strptime(time_string, TIME_FORMAT)\n\n        # Convert the datetime object to the target timezone\n        converted_time = original_time.astimezone(ZoneInfo(target_tz))\n\n        # Append the original and converted times to their respective lists\n        original_times.append(original_time)\n        converted_times.append(converted_time)\n\n    # Create a DataFrame from the original and converted times\n    df = pd.DataFrame({\n        'Original Time': original_times,\n        'Converted Time': converted_times\n    })\n\n    return df\n\n# Test the function\ntime_strings = ['31/12/21 23:59:59.999', '01/01/22 00:00:00.000']\ntarget_tz = 'Asia/Tokyo'\ndf = task_func(time_strings, target_tz)"}
{"task_id": "BigCodeBench/1077", "solution": "from datetime import datetime\nimport pytz\nimport numpy as np\ndef task_func(time_strings, timezone):\n    if len(time_strings) < 2:\n        return 0.0\n\n    # Convert timezone\n    converted_times = [pytz.timezone(timezone).localize(datetime.strptime(time, \"%Y-%m-%d %H:%M:%S\")) for time in time_strings]\n\n    # Calculate time difference in seconds\n    time_diffs = [(converted_times[i+1] - converted_times[i]).total_seconds() for i in range(len(converted_times)-1)]\n\n    # Return average time difference\n    return float(np.mean(time_diffs))", "raw_solution": "from datetime import datetime\nimport pytz\nimport numpy as np\n\ndef task_func(time_strings, timezone):\n    if len(time_strings) < 2:\n        return 0.0\n\n    # Convert timezone\n    converted_times = [pytz.timezone(timezone).localize(datetime.strptime(time, \"%Y-%m-%d %H:%M:%S\")) for time in time_strings]\n\n    # Calculate time difference in seconds\n    time_diffs = [(converted_times[i+1] - converted_times[i]).total_seconds() for i in range(len(converted_times)-1)]\n\n    # Return average time difference\n    return float(np.mean(time_diffs))\n\n# Test the function"}
{"task_id": "BigCodeBench/1078", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(arr):\n    unique, counts = np.unique(arr, return_counts=True)\n    bin_edges = np.arange(len(unique) + 1) - 0.5\n    hist, bins = np.histogram(arr, bins=bin_edges)\n\n    uniform_distribution = np.all(counts == counts[0])\n\n    fig, ax = plt.subplots()\n    ax.bar(bins[:-1], hist, align='edge', width=1)\n    ax.set_xlabel('Values')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Array Values')\n\n    return (uniform_distribution, ax)\narr = np.array([1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4])", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(arr):\n    unique, counts = np.unique(arr, return_counts=True)\n    bin_edges = np.arange(len(unique) + 1) - 0.5\n    hist, bins = np.histogram(arr, bins=bin_edges)\n\n    uniform_distribution = np.all(counts == counts[0])\n\n    fig, ax = plt.subplots()\n    ax.bar(bins[:-1], hist, align='edge', width=1)\n    ax.set_xlabel('Values')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Array Values')\n\n    return (uniform_distribution, ax)\n\n# Test the function\narr = np.array([1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4])\nuniform, ax = task_func(arr)"}
{"task_id": "BigCodeBench/1079", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Convert string prices to float\n    data['Price'] = data['Price_String'].apply(lambda x: float(x.replace(',', '')))\n\n    # Calculate statistics\n    stats = {\n        'mean': data['Price'].mean(),\n        'median': data['Price'].median(),\n        'std_dev': data['Price'].std()\n    }\n\n    # Generate histogram\n    fig, ax = plt.subplots()\n    ax.hist(data['Price'], bins='auto', color='blue', alpha=0.7, rwidth=0.85)\n    ax.set_title('Histogram of Product Prices')\n    ax.set_xlabel('Price')\n    ax.set_ylabel('Frequency')\n\n    return stats, ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Convert string prices to float\n    data['Price'] = data['Price_String'].apply(lambda x: float(x.replace(',', '')))\n\n    # Calculate statistics\n    stats = {\n        'mean': data['Price'].mean(),\n        'median': data['Price'].median(),\n        'std_dev': data['Price'].std()\n    }\n\n    # Generate histogram\n    fig, ax = plt.subplots()\n    ax.hist(data['Price'], bins='auto', color='blue', alpha=0.7, rwidth=0.85)\n    ax.set_title('Histogram of Product Prices')\n    ax.set_xlabel('Price')\n    ax.set_ylabel('Frequency')\n\n    return stats, ax"}
{"task_id": "BigCodeBench/1080", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nDATA = {\n    \"Area_String\": [\"1,000\", \"2,000\", \"3,000\", \"4,000\", \"5,000\"],\n    \"Price\": [100, 200, 300, 400, 500],\n}\ndef task_func(area_string, data=DATA):\n    # Convert the area_string to integer\n    area_value = int(area_string.replace(',', ''))\n\n    # Load the data into a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Convert the Area_String column to integer\n    df['Area_String'] = df['Area_String'].apply(lambda x: int(x.replace(',', '')))\n\n    # Reshape the data to fit the model\n    X = df['Area_String'].values.reshape(-1, 1)\n    y = df['Price'].values.reshape(-1, 1)\n\n    # Create a linear regression model\n    model = LinearRegression()\n\n    # Train the model\n    model.fit(X, y)\n\n    # Predict the price for the given area\n    prediction = model.predict([[area_value]])\n\n    # Return the prediction\n    return float(prediction[0])", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\nDATA = {\n    \"Area_String\": [\"1,000\", \"2,000\", \"3,000\", \"4,000\", \"5,000\"],\n    \"Price\": [100, 200, 300, 400, 500],\n}\n\ndef task_func(area_string, data=DATA):\n    # Convert the area_string to integer\n    area_value = int(area_string.replace(',', ''))\n\n    # Load the data into a pandas DataFrame\n    df = pd.DataFrame(data)\n\n    # Convert the Area_String column to integer\n    df['Area_String'] = df['Area_String'].apply(lambda x: int(x.replace(',', '')))\n\n    # Reshape the data to fit the model\n    X = df['Area_String'].values.reshape(-1, 1)\n    y = df['Price'].values.reshape(-1, 1)\n\n    # Create a linear regression model\n    model = LinearRegression()\n\n    # Train the model\n    model.fit(X, y)\n\n    # Predict the price for the given area\n    prediction = model.predict([[area_value]])\n\n    # Return the prediction\n    return float(prediction[0])\n\n# Test the function"}
{"task_id": "BigCodeBench/1081", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(data=None):\n    if data is None:\n        data = {'Weight_String': ['70', '75', '80', '85', '90'],\n                'Height': [170, 175, 180, 185, 190]}\n    else:\n        if not isinstance(data, dict):\n            raise TypeError(\"Input data should be a dictionary.\")\n        if 'Weight_String' not in data or 'Height' not in data:\n            raise KeyError(\"Both 'Weight_String' and 'Height' keys are required.\")\n        if not all(isinstance(i, str) for i in data['Weight_String']):\n            raise ValueError(\"All weight values should be strings.\")\n\n    df = pd.DataFrame(data)\n    df['Weight'] = df['Weight_String'].apply(float)\n    df = df.drop(columns=['Weight_String'])\n\n    ax = sns.scatterplot(x='Weight', y='Height', data=df)\n    ax.set_title(\"Weight vs Height\")\n    plt.show()\n\n    return ax", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data=None):\n    if data is None:\n        data = {'Weight_String': ['70', '75', '80', '85', '90'],\n                'Height': [170, 175, 180, 185, 190]}\n    else:\n        if not isinstance(data, dict):\n            raise TypeError(\"Input data should be a dictionary.\")\n        if 'Weight_String' not in data or 'Height' not in data:\n            raise KeyError(\"Both 'Weight_String' and 'Height' keys are required.\")\n        if not all(isinstance(i, str) for i in data['Weight_String']):\n            raise ValueError(\"All weight values should be strings.\")\n\n    df = pd.DataFrame(data)\n    df['Weight'] = df['Weight_String'].apply(float)\n    df = df.drop(columns=['Weight_String'])\n\n    ax = sns.scatterplot(x='Weight', y='Height', data=df)\n    ax.set_title(\"Weight vs Height\")\n    plt.show()\n\n    return ax"}
{"task_id": "BigCodeBench/1082", "solution": "import pandas as pd\nfrom scipy.stats import pearsonr\nimport numpy as np\ndef task_func(data):\n    # Check if dataframe has at least 2 rows\n    if len(data) < 2:\n        return np.nan\n\n    # Convert scores from string format to floats\n    data['scores'] = pd.to_numeric(data['scores'], errors='coerce')\n\n    # Encode categorical grades into numerical values based on their rank order\n    grade_ranks = data['grades'].rank(method='min')\n    data['grades'] = grade_ranks\n\n    # Compute the Pearson correlation coefficient between the numerical scores and the encoded grades\n    correlation, _ = pearsonr(data['scores'], data['grades'])\n\n    return correlation", "raw_solution": "import pandas as pd\nfrom scipy.stats import pearsonr\nimport numpy as np\n\ndef task_func(data):\n    # Check if dataframe has at least 2 rows\n    if len(data) < 2:\n        return np.nan\n\n    # Convert scores from string format to floats\n    data['scores'] = pd.to_numeric(data['scores'], errors='coerce')\n\n    # Encode categorical grades into numerical values based on their rank order\n    grade_ranks = data['grades'].rank(method='min')\n    data['grades'] = grade_ranks\n\n    # Compute the Pearson correlation coefficient between the numerical scores and the encoded grades\n    correlation, _ = pearsonr(data['scores'], data['grades'])\n\n    return correlation"}
{"task_id": "BigCodeBench/1083", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # 1. Input Validation\n    if not all(key in data for key in ('Salary_String', 'Experience')):\n        raise ValueError(\"Input data dictionary must contain 'Salary_String' and 'Experience' keys\")\n\n    # 2. DataFrame Conversion\n    df = pd.DataFrame(data)\n\n    # 3. Empty Data Handling\n    if df.empty:\n        return plt.gca()\n\n    # 4. Salary Conversion\n    try:\n        df['Salary'] = df['Salary_String'].apply(lambda x: float(x.replace(',', '')))\n    except ValueError as e:\n        raise ValueError(\"Failed to convert Salary_String to float: {}\".format(e))\n\n    # 5. Salary Normalization\n    scaler = MinMaxScaler()\n    df[['Salary']] = scaler.fit_transform(df[['Salary']])\n\n    # 6. Data Plotting\n    ax = df.plot(kind='scatter', x='Experience', y='Salary', figsize=(10, 6), title='Normalized Salary vs Experience')\n    ax.set_xlabel('Experience')\n    ax.set_ylabel('Normalized Salary')\n\n    return ax", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # 1. Input Validation\n    if not all(key in data for key in ('Salary_String', 'Experience')):\n        raise ValueError(\"Input data dictionary must contain 'Salary_String' and 'Experience' keys\")\n\n    # 2. DataFrame Conversion\n    df = pd.DataFrame(data)\n\n    # 3. Empty Data Handling\n    if df.empty:\n        return plt.gca()\n\n    # 4. Salary Conversion\n    try:\n        df['Salary'] = df['Salary_String'].apply(lambda x: float(x.replace(',', '')))\n    except ValueError as e:\n        raise ValueError(\"Failed to convert Salary_String to float: {}\".format(e))\n\n    # 5. Salary Normalization\n    scaler = MinMaxScaler()\n    df[['Salary']] = scaler.fit_transform(df[['Salary']])\n\n    # 6. Data Plotting\n    ax = df.plot(kind='scatter', x='Experience', y='Salary', figsize=(10, 6), title='Normalized Salary vs Experience')\n    ax.set_xlabel('Experience')\n    ax.set_ylabel('Normalized Salary')\n\n    return ax"}
{"task_id": "BigCodeBench/1084", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.feature_selection import f_oneway\ndef task_func(data_file_path: str):\n    # Read CSV file\n    df = pd.read_csv(data_file_path)\n\n    # Convert string representations of numbers with commas into floating point numbers\n    df = df.apply(pd.to_numeric, errors='ignore')\n\n    # Calculate the mean and standard deviation for each numerical column\n    means = df.mean()\n    std_devs = df.std()\n\n    # Generate a histogram plot for each numerical column\n    axes = []\n    for col in df.select_dtypes(include=[pd.np.number]):\n        ax = df[col].hist(bins=10, figsize=(10,5))\n        axes.append(ax)\n        plt.show()\n\n    # Perform an ANOVA test to check the statistical significance of differences between means of numerical columns\n    anova_results = pd.DataFrame(columns=['F-value', 'P-value'], index=df.columns)\n    if len(df.columns) > 1:\n        for i in range(len(df.columns)):\n            for j in range(i+1, len(df.columns)):\n                f_val, p_val = f_oneway(df[df.columns[i]], df[df.columns[j]])\n                anova_results.loc[df.columns[i], 'F-value'] = f_val\n                anova_results.loc[df.columns[i], 'P-value'] = p_val\n                anova_results.loc[df.columns[j], 'F-value'] = f_val\n                anova_results.loc[df.columns[j], 'P-value'] = p_val\n\n    return means, std_devs, axes, anova_results", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.feature_selection import f_oneway\n\ndef task_func(data_file_path: str):\n    # Read CSV file\n    df = pd.read_csv(data_file_path)\n\n    # Convert string representations of numbers with commas into floating point numbers\n    df = df.apply(pd.to_numeric, errors='ignore')\n\n    # Calculate the mean and standard deviation for each numerical column\n    means = df.mean()\n    std_devs = df.std()\n\n    # Generate a histogram plot for each numerical column\n    axes = []\n    for col in df.select_dtypes(include=[pd.np.number]):\n        ax = df[col].hist(bins=10, figsize=(10,5))\n        axes.append(ax)\n        plt.show()\n\n    # Perform an ANOVA test to check the statistical significance of differences between means of numerical columns\n    anova_results = pd.DataFrame(columns=['F-value', 'P-value'], index=df.columns)\n    if len(df.columns) > 1:\n        for i in range(len(df.columns)):\n            for j in range(i+1, len(df.columns)):\n                f_val, p_val = f_oneway(df[df.columns[i]], df[df.columns[j]])\n                anova_results.loc[df.columns[i], 'F-value'] = f_val\n                anova_results.loc[df.columns[i], 'P-value'] = p_val\n                anova_results.loc[df.columns[j], 'F-value'] = f_val\n                anova_results.loc[df.columns[j], 'P-value'] = p_val\n\n    return means, std_devs, axes, anova_results"}
{"task_id": "BigCodeBench/1085", "solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Lowercase the text\n    text = text.lower()\n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    # Split into words\n    words = text.split()\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    # Get the 10 most common words\n    top_10_words = word_counts.most_common(10)\n    # Create a bar chart\n    words, counts = zip(*top_10_words)\n    fig, ax = plt.subplots()\n    ax.bar(words, counts)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Counts')\n    ax.set_title('Top 10 most common words')\n    return top_10_words, ax", "raw_solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Lowercase the text\n    text = text.lower()\n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    # Split into words\n    words = text.split()\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    # Get the 10 most common words\n    top_10_words = word_counts.most_common(10)\n    # Create a bar chart\n    words, counts = zip(*top_10_words)\n    fig, ax = plt.subplots()\n    ax.bar(words, counts)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Counts')\n    ax.set_title('Top 10 most common words')\n    return top_10_words, ax"}
{"task_id": "BigCodeBench/1086", "solution": "import string\nimport random\nimport pandas as pd\nimport numpy as np\nNUM_SAMPLES = 1000\ndef task_func():\n    # Generate random strings\n    strings = [''.join(random.choices(string.ascii_letters, k=10)) for _ in range(NUM_SAMPLES)]\n\n    # Generate random floats\n    floats = np.random.uniform(0, 10000, NUM_SAMPLES).round(2)\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        'String Field': strings,\n        'Float Field': floats\n    })\n\n    # Format Float Field to have comma as thousands separator\n    df['Float Field'] = df['Float Field'].apply(lambda x: \"{:,}\".format(x))\n\n    return df", "raw_solution": "import string\nimport random\nimport pandas as pd\nimport numpy as np\n\n# Constants\nNUM_SAMPLES = 1000  # Number of samples\n\ndef task_func():\n    # Generate random strings\n    strings = [''.join(random.choices(string.ascii_letters, k=10)) for _ in range(NUM_SAMPLES)]\n\n    # Generate random floats\n    floats = np.random.uniform(0, 10000, NUM_SAMPLES).round(2)\n\n    # Create DataFrame\n    df = pd.DataFrame({\n        'String Field': strings,\n        'Float Field': floats\n    })\n\n    # Format Float Field to have comma as thousands separator\n    df['Float Field'] = df['Float Field'].apply(lambda x: \"{:,}\".format(x))\n\n    return df\n\n# Test the function\ndf = task_func()"}
{"task_id": "BigCodeBench/1087", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(mean=123456.908, std_dev=1.2, save_plots=False):\n    # Generate a random sample from a normal distribution\n    sample = np.random.normal(mean, std_dev, 1000)\n\n    # Calculate skewness and kurtosis\n    skewness = stats.skew(sample)\n    kurtosis = stats.kurtosis(sample)\n\n    # Create a histogram and a QQ plot\n    if save_plots:\n        plt.figure(figsize=(12, 6))\n        plt.subplot(1, 2, 1)\n        plt.hist(sample, bins=30, edgecolor='black')\n        plt.title('Histogram')\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n\n        plt.subplot(1, 2, 2)\n        stats.probplot(sample, plot=plt)\n        plt.title('QQ Plot')\n        plt.tight_layout()\n\n        # Save the plots\n        plt.savefig('hist_qq_plot.png')\n        plot_paths = ['hist_qq_plot.png']\n    else:\n        plot_paths = []\n\n    return skewness, kurtosis, plot_paths", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(mean=123456.908, std_dev=1.2, save_plots=False):\n    # Generate a random sample from a normal distribution\n    sample = np.random.normal(mean, std_dev, 1000)\n\n    # Calculate skewness and kurtosis\n    skewness = stats.skew(sample)\n    kurtosis = stats.kurtosis(sample)\n\n    # Create a histogram and a QQ plot\n    if save_plots:\n        plt.figure(figsize=(12, 6))\n        plt.subplot(1, 2, 1)\n        plt.hist(sample, bins=30, edgecolor='black')\n        plt.title('Histogram')\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n\n        plt.subplot(1, 2, 2)\n        stats.probplot(sample, plot=plt)\n        plt.title('QQ Plot')\n        plt.tight_layout()\n\n        # Save the plots\n        plt.savefig('hist_qq_plot.png')\n        plot_paths = ['hist_qq_plot.png']\n    else:\n        plot_paths = []\n\n    return skewness, kurtosis, plot_paths"}
{"task_id": "BigCodeBench/1088", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data=None):\n    if data is None:\n        return None\n    df = pd.DataFrame(data)\n    df[df < 0.5] = 0\n    scaler = StandardScaler()\n    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data=None):\n    if data is None:\n        return None\n    df = pd.DataFrame(data)\n    df[df < 0.5] = 0\n    scaler = StandardScaler()\n    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df"}
{"task_id": "BigCodeBench/1089", "solution": "import numpy as np\nfrom collections import Counter\ndef task_func(list_of_tuples):\n    # Initialize sum of numeric values and counter for categories\n    sum_of_values = 0\n    category_counter = Counter()\n\n    # Iterate over each tuple in the list\n    for value, category in list_of_tuples:\n        # Add numeric value to sum\n        sum_of_values += value\n        # Increment count for category\n        category_counter[category] += 1\n\n    # Return sum of values and counter dictionary\n    return (sum_of_values, dict(category_counter))", "raw_solution": "import numpy as np\nfrom collections import Counter\n\ndef task_func(list_of_tuples):\n    # Initialize sum of numeric values and counter for categories\n    sum_of_values = 0\n    category_counter = Counter()\n\n    # Iterate over each tuple in the list\n    for value, category in list_of_tuples:\n        # Add numeric value to sum\n        sum_of_values += value\n        # Increment count for category\n        category_counter[category] += 1\n\n    # Return sum of values and counter dictionary\n    return (sum_of_values, dict(category_counter))\n\n# Test the function\ntuples = [(1, 'a'), (2, 'b'), (3, 'a'), (4, 'b'), (5, 'a'), (6, 'b'), (7, 'a')]"}
{"task_id": "BigCodeBench/1090", "solution": "import ast\nimport json\nfrom collections import Counter\ndef task_func(file_pointer):\n    # Initialize a Counter object\n    key_counter = Counter()\n\n    # Read the JSON data from the file\n    with open(file_pointer, 'r') as file:\n        data = json.load(file)\n\n    # Iterate over each item in the JSON data\n    for item in data:\n        # If the item is a string, convert it to a dictionary\n        if isinstance(item, str):\n            item = ast.literal_eval(item)\n\n        # If the item is a dictionary, update the Counter with its keys\n        if isinstance(item, dict):\n            key_counter.update(item.keys())\n\n    return key_counter", "raw_solution": "import ast\nimport json\nfrom collections import Counter\n\ndef task_func(file_pointer):\n    # Initialize a Counter object\n    key_counter = Counter()\n\n    # Read the JSON data from the file\n    with open(file_pointer, 'r') as file:\n        data = json.load(file)\n\n    # Iterate over each item in the JSON data\n    for item in data:\n        # If the item is a string, convert it to a dictionary\n        if isinstance(item, str):\n            item = ast.literal_eval(item)\n\n        # If the item is a dictionary, update the Counter with its keys\n        if isinstance(item, dict):\n            key_counter.update(item.keys())\n\n    return key_counter"}
{"task_id": "BigCodeBench/1091", "solution": "import ast\nimport os\nimport glob\ndef task_func(directory):\n    # Initialize an empty list to store dictionaries\n    dict_list = []\n\n    # Get all text files in the directory\n    for file in glob.glob(os.path.join(directory, '*.txt')):\n        with open(file, 'r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    # Try to convert the Unicode string representation to a Python dictionary\n                    dict_obj = ast.literal_eval(line)\n                    # Check if the object is a dictionary\n                    if not isinstance(dict_obj, dict):\n                        raise ValueError(f\"Invalid dictionary representation in file: {file}\")\n                    dict_list.append(dict_obj)\n                except (SyntaxError, ValueError) as e:\n                    raise ValueError(f\"Invalid dictionary representation in file: {file}\")\n\n    return dict_list", "raw_solution": "import ast\nimport os\nimport glob\n\n# Constants\nDIRECTORY = 'data'\n\ndef task_func(directory):\n    # Initialize an empty list to store dictionaries\n    dict_list = []\n\n    # Get all text files in the directory\n    for file in glob.glob(os.path.join(directory, '*.txt')):\n        with open(file, 'r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    # Try to convert the Unicode string representation to a Python dictionary\n                    dict_obj = ast.literal_eval(line)\n                    # Check if the object is a dictionary\n                    if not isinstance(dict_obj, dict):\n                        raise ValueError(f\"Invalid dictionary representation in file: {file}\")\n                    dict_list.append(dict_obj)\n                except (SyntaxError, ValueError) as e:\n                    raise ValueError(f\"Invalid dictionary representation in file: {file}\")\n\n    return dict_list\n\n# Test the function\ntry:\n    dicts = task_func(DIRECTORY)\n    for d in dicts:\n        print(d)\nexcept ValueError as e:\n    print(e)"}
{"task_id": "BigCodeBench/1092", "solution": "import ast\nimport requests\nfrom bs4 import BeautifulSoup\ndef task_func(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except (requests.RequestException, ValueError):\n        return []\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    scripts = soup.find_all('script')\n\n    result = []\n    for script in scripts:\n        script_text = script.string\n        if script_text is None:\n            continue\n        try:\n            # Try to parse the script text as a Python dictionary\n            parsed = ast.literal_eval(script_text)\n            if isinstance(parsed, dict):\n                result.append(parsed)\n        except (SyntaxError, ValueError):\n            continue\n\n    return result", "raw_solution": "import ast\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef task_func(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except (requests.RequestException, ValueError):\n        return []\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    scripts = soup.find_all('script')\n\n    result = []\n    for script in scripts:\n        script_text = script.string\n        if script_text is None:\n            continue\n        try:\n            # Try to parse the script text as a Python dictionary\n            parsed = ast.literal_eval(script_text)\n            if isinstance(parsed, dict):\n                result.append(parsed)\n        except (SyntaxError, ValueError):\n            continue\n\n    return result"}
{"task_id": "BigCodeBench/1093", "solution": "import ast\nimport re\ndef task_func(text_file: str) -> list:\n    with open(text_file, 'r') as file:\n        data = file.read()\n\n    dict_strs = re.findall(r'{.*?}', data)\n    dicts = []\n    for dict_str in dict_strs:\n        try:\n            dicts.append(ast.literal_eval(dict_str))\n        except SyntaxError:\n            pass\n\n    return dicts", "raw_solution": "import ast\nimport re\n\ndef task_func(text_file: str) -> list:\n    with open(text_file, 'r') as file:\n        data = file.read()\n\n    dict_strs = re.findall(r'{.*?}', data)\n    dicts = []\n    for dict_str in dict_strs:\n        try:\n            dicts.append(ast.literal_eval(dict_str))\n        except SyntaxError:\n            pass\n\n    return dicts\n\n# Test the function\ndicts = task_func(\"another_sample.txt\")"}
{"task_id": "BigCodeBench/1094", "solution": "from nltk.tokenize import RegexpTokenizer\nfrom collections import Counter\nimport re\ndef task_func(text):\n    # Tokenize the text\n    tokenizer = RegexpTokenizer(r'\\$\\w+')\n    tokens = tokenizer.tokenize(text)\n\n    # Filter out words solely consisting of \"$\" symbols without any following alphanumeric characters\n    tokens = [token[1:] for token in tokens if token[1:]]\n\n    # Count the frequency of each word\n    counter = Counter(tokens)\n\n    # Return the five most frequent dollar-prefixed words along with their counts, ordered by most to least common\n    return counter.most_common(5)", "raw_solution": "from nltk.tokenize import RegexpTokenizer\nfrom collections import Counter\nimport re\n\ndef task_func(text):\n    # Tokenize the text\n    tokenizer = RegexpTokenizer(r'\\$\\w+')\n    tokens = tokenizer.tokenize(text)\n\n    # Filter out words solely consisting of \"$\" symbols without any following alphanumeric characters\n    tokens = [token[1:] for token in tokens if token[1:]]\n\n    # Count the frequency of each word\n    counter = Counter(tokens)\n\n    # Return the five most frequent dollar-prefixed words along with their counts, ordered by most to least common\n    return counter.most_common(5)\n\n# Test the function\ntext = \"$money $money $MONEY $MONEY $money $MONEY $1000 $1000 $1000 $10000 $100000 $1000000 $100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"}
{"task_id": "BigCodeBench/1095", "solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport os\ndef task_func(text, output_filename):\n    # Initialize tokenizer\n    tokenizer = RegexpTokenizer(r'\\b\\$\\w+')\n    \n    # Tokenize the text\n    tokens = tokenizer.tokenize(text)\n    \n    # Remove tokens that are solely composed of punctuation characters\n    tokens = [token for token in tokens if not all(char in punctuation for char in token)]\n    \n    # Write tokens to file\n    with open(output_filename, 'w') as f:\n        for token in tokens:\n            f.write(token[1:] + '\\n')  # Exclude the '$' character\n    \n    # Return absolute path to output file\n    return os.path.abspath(output_filename)\ntext = \"This is a test $text. $test2, $test3! $test4:test5; $test6?test7.\"\noutput_filename = \"output.txt\"", "raw_solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport os\n\ndef task_func(text, output_filename):\n    # Initialize tokenizer\n    tokenizer = RegexpTokenizer(r'\\b\\$\\w+')\n    \n    # Tokenize the text\n    tokens = tokenizer.tokenize(text)\n    \n    # Remove tokens that are solely composed of punctuation characters\n    tokens = [token for token in tokens if not all(char in punctuation for char in token)]\n    \n    # Write tokens to file\n    with open(output_filename, 'w') as f:\n        for token in tokens:\n            f.write(token[1:] + '\\n')  # Exclude the '$' character\n    \n    # Return absolute path to output file\n    return os.path.abspath(output_filename)\n\n# Test the function\ntext = \"This is a test $text. $test2, $test3! $test4:test5; $test6?test7.\"\noutput_filename = \"output.txt\""}
{"task_id": "BigCodeBench/1096", "solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport csv\nimport os\nPUNCTUATION = set(punctuation)\ndef task_func(text, filename):\n    tokenizer = RegexpTokenizer(r'\\$\\w+')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if not set(word).issubset(PUNCTUATION)]\n\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Word\"])\n        writer.writerows([[word] for word in words])\n\n    return os.path.abspath(filename)\ntext = \"$hello, $world! $test1, $test2. $test3...\"\nfilename = \"output.csv\"", "raw_solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport csv\nimport os\n\nPUNCTUATION = set(punctuation)\n\ndef task_func(text, filename):\n    tokenizer = RegexpTokenizer(r'\\$\\w+')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if not set(word).issubset(PUNCTUATION)]\n\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Word\"])\n        writer.writerows([[word] for word in words])\n\n    return os.path.abspath(filename)\n\n# Test the function\ntext = \"$hello, $world! $test1, $test2. $test3...\"\nfilename = \"output.csv\""}
{"task_id": "BigCodeBench/1097", "solution": "import re\nfrom string import punctuation\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\ndef task_func(text):\n    # Remove URLs\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n\n    # Remove punctuation\n    text = \"\".join(char for char in text if char not in punctuation)\n\n    # Split text into words\n    words = text.split()\n\n    # Remove stopwords\n    words = [word for word in words if word not in PREDEFINED_STOPWORDS]\n\n    # Join words back into a string\n    text = \" \".join(words)\n\n    return text\ntext = \"This is a test text with URL https://www.example.com, stopword 'is', and punctuation.\"", "raw_solution": "import re\nfrom string import punctuation\n\n# Predefined list of common stopwords\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\n\ndef task_func(text):\n    # Remove URLs\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n\n    # Remove punctuation\n    text = \"\".join(char for char in text if char not in punctuation)\n\n    # Split text into words\n    words = text.split()\n\n    # Remove stopwords\n    words = [word for word in words if word not in PREDEFINED_STOPWORDS]\n\n    # Join words back into a string\n    text = \" \".join(words)\n\n    return text\n\n# Test the function\ntext = \"This is a test text with URL https://www.example.com, stopword 'is', and punctuation.\""}
{"task_id": "BigCodeBench/1098", "solution": "import re\nfrom collections import Counter\ndef task_func(text, top_n):\n    # Remove URLs\n    url_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    text = url_pattern.sub('', text)\n\n    # Split the text into words\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n\n    # Count the words\n    word_counts = Counter(words)\n\n    # Return the N most common words\n    return word_counts.most_common(top_n)\ntext = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, http://example.com sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"", "raw_solution": "import re\nfrom collections import Counter\n\ndef task_func(text, top_n):\n    # Remove URLs\n    url_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    text = url_pattern.sub('', text)\n\n    # Split the text into words\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n\n    # Count the words\n    word_counts = Counter(words)\n\n    # Return the N most common words\n    return word_counts.most_common(top_n)\n\n# Test the function\ntext = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, http://example.com sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\""}
{"task_id": "BigCodeBench/1099", "solution": "import re\nfrom collections import Counter\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\ndef task_func(text):\n    # Remove URLs from text\n    text = re.sub(r'http[s]?://\\S+|www\\.\\S+', '', text)\n\n    # Tokenize text into words\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n\n    # Count words that are not stopwords\n    word_counts = Counter(word for word in words if word not in PREDEFINED_STOPWORDS)\n\n    # Convert Counter to list of tuples\n    result = [(word, count) for word, count in word_counts.items()]\n\n    return result", "raw_solution": "import re\nfrom collections import Counter\n\n# Predefined list of common stopwords\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\n\ndef task_func(text):\n    # Remove URLs from text\n    text = re.sub(r'http[s]?://\\S+|www\\.\\S+', '', text)\n\n    # Tokenize text into words\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n\n    # Count words that are not stopwords\n    word_counts = Counter(word for word in words if word not in PREDEFINED_STOPWORDS)\n\n    # Convert Counter to list of tuples\n    result = [(word, count) for word, count in word_counts.items()]\n\n    return result"}
{"task_id": "BigCodeBench/1100", "solution": "import re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndef task_func(texts):\n    # Remove URLs from the texts\n    texts = [re.sub(r'http\\S+|www.\\S+', '', text) for text in texts]\n\n    # Initialize TfidfVectorizer\n    vectorizer = TfidfVectorizer()\n\n    # Fit and transform the texts\n    tfidf_matrix = vectorizer.fit_transform(texts)\n\n    # Get the feature names\n    features = vectorizer.get_feature_names_out()\n\n    # Convert the sparse matrix to a dense matrix and round the values to 8 decimal places\n    tfidf_dense_matrix = tfidf_matrix.toarray().round(8)\n\n    # Convert the dense matrix to a list of tuples\n    tfidf_tuples = [tuple(row) for row in tfidf_dense_matrix]\n\n    return tfidf_tuples, list(features)\ntexts = [\"This is the first document.\", \"This document is the second document.\", \"And this is the third one.\"]", "raw_solution": "import re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ndef task_func(texts):\n    # Remove URLs from the texts\n    texts = [re.sub(r'http\\S+|www.\\S+', '', text) for text in texts]\n\n    # Initialize TfidfVectorizer\n    vectorizer = TfidfVectorizer()\n\n    # Fit and transform the texts\n    tfidf_matrix = vectorizer.fit_transform(texts)\n\n    # Get the feature names\n    features = vectorizer.get_feature_names_out()\n\n    # Convert the sparse matrix to a dense matrix and round the values to 8 decimal places\n    tfidf_dense_matrix = tfidf_matrix.toarray().round(8)\n\n    # Convert the dense matrix to a list of tuples\n    tfidf_tuples = [tuple(row) for row in tfidf_dense_matrix]\n\n    return tfidf_tuples, list(features)\n\n# Test the function\ntexts = [\"This is the first document.\", \"This document is the second document.\", \"And this is the third one.\"]"}
{"task_id": "BigCodeBench/1101", "solution": "import subprocess\nimport os\nimport glob\nimport time\ndef task_func(test_dir):\n    # Get all Python files in the directory\n    python_files = glob.glob(os.path.join(test_dir, '*.py'))\n\n    # Initialize an empty dictionary to store the execution times\n    execution_times = {}\n\n    # Iterate over all Python files\n    for file in python_files:\n        # Get the base name of the file (without the path)\n        base_name = os.path.basename(file)\n\n        # Start the timer\n        start_time = time.time()\n\n        # Run the Python file\n        subprocess.run(['python', file])\n\n        # Stop the timer\n        end_time = time.time()\n\n        # Calculate the execution time\n        execution_time = end_time - start_time\n\n        # Add the execution time to the dictionary\n        execution_times[base_name] = execution_time\n\n    # Return the dictionary\n    return execution_times", "raw_solution": "import subprocess\nimport os\nimport glob\nimport time\n\ndef task_func(test_dir):\n    # Get all Python files in the directory\n    python_files = glob.glob(os.path.join(test_dir, '*.py'))\n\n    # Initialize an empty dictionary to store the execution times\n    execution_times = {}\n\n    # Iterate over all Python files\n    for file in python_files:\n        # Get the base name of the file (without the path)\n        base_name = os.path.basename(file)\n\n        # Start the timer\n        start_time = time.time()\n\n        # Run the Python file\n        subprocess.run(['python', file])\n\n        # Stop the timer\n        end_time = time.time()\n\n        # Calculate the execution time\n        execution_time = end_time - start_time\n\n        # Add the execution time to the dictionary\n        execution_times[base_name] = execution_time\n\n    # Return the dictionary\n    return execution_times"}
{"task_id": "BigCodeBench/1102", "solution": "import subprocess\nimport shlex\nfrom datetime import datetime\ndef task_func(script_path: str) -> dict:\n    start_time = datetime.now()\n    with subprocess.Popen(shlex.split(f\"Rscript {script_path}\"), stdout=subprocess.PIPE, stderr=subprocess.PIPE) as proc:\n        stdout, stderr = proc.communicate()\n    end_time = datetime.now()\n\n    return {\n        \"start_time\": start_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n        \"end_time\": end_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n        \"stdout\": stdout.decode(\"utf-8\"),\n        \"stderr\": stderr.decode(\"utf-8\")\n    }", "raw_solution": "import subprocess\nimport shlex\nfrom datetime import datetime\n\ndef task_func(script_path: str) -> dict:\n    start_time = datetime.now()\n    with subprocess.Popen(shlex.split(f\"Rscript {script_path}\"), stdout=subprocess.PIPE, stderr=subprocess.PIPE) as proc:\n        stdout, stderr = proc.communicate()\n    end_time = datetime.now()\n\n    return {\n        \"start_time\": start_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n        \"end_time\": end_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n        \"stdout\": stdout.decode(\"utf-8\"),\n        \"stderr\": stderr.decode(\"utf-8\")\n    }\n\n# Test the function"}
{"task_id": "BigCodeBench/1103", "solution": "import subprocess\nimport shutil\nimport os\ndef task_func(script_path: str, temp_dir: str) -> str:\n    # Check if the script_path exists\n    if not os.path.exists(script_path):\n        return \"Script execution failed!\"\n\n    # Create a temporary directory\n    if not os.path.exists(temp_dir):\n        os.makedirs(temp_dir)\n\n    # Copy the script to the temporary directory\n    shutil.copy(script_path, temp_dir)\n\n    # Change the working directory to the temporary directory\n    os.chdir(temp_dir)\n\n    # Execute the script\n    try:\n        subprocess.check_output(['python', os.path.basename(script_path)], stderr=subprocess.STDOUT)\n        return \"Script executed successfully!\"\n    except subprocess.CalledProcessError:\n        return \"Script execution failed!\"", "raw_solution": "import subprocess\nimport shutil\nimport os\n\ndef task_func(script_path: str, temp_dir: str) -> str:\n    # Check if the script_path exists\n    if not os.path.exists(script_path):\n        return \"Script execution failed!\"\n\n    # Create a temporary directory\n    if not os.path.exists(temp_dir):\n        os.makedirs(temp_dir)\n\n    # Copy the script to the temporary directory\n    shutil.copy(script_path, temp_dir)\n\n    # Change the working directory to the temporary directory\n    os.chdir(temp_dir)\n\n    # Execute the script\n    try:\n        subprocess.check_output(['python', os.path.basename(script_path)], stderr=subprocess.STDOUT)\n        return \"Script executed successfully!\"\n    except subprocess.CalledProcessError:\n        return \"Script execution failed!\""}
{"task_id": "BigCodeBench/1104", "solution": "import subprocess\nimport os\nimport signal\ndef task_func(script_path: str, timeout: int = 60) -> str:\n    if not os.path.exists(script_path):\n        raise FileNotFoundError(f\"The file {script_path} does not exist.\")\n\n    proc = subprocess.Popen(['python', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    timer = threading.Timer(timeout, lambda: proc.send_signal(signal.SIGINT))\n    try:\n        timer.start()\n        stdout, stderr = proc.communicate()\n        if proc.returncode != 0:\n            return \"Script executed successfully.\"\n        else:\n            return \"Terminating process due to timeout.\"\n    finally:\n        timer.cancel()", "raw_solution": "import subprocess\nimport os\nimport signal\n\ndef task_func(script_path: str, timeout: int = 60) -> str:\n    if not os.path.exists(script_path):\n        raise FileNotFoundError(f\"The file {script_path} does not exist.\")\n\n    proc = subprocess.Popen(['python', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    timer = threading.Timer(timeout, lambda: proc.send_signal(signal.SIGINT))\n    try:\n        timer.start()\n        stdout, stderr = proc.communicate()\n        if proc.returncode != 0:\n            return \"Script executed successfully.\"\n        else:\n            return \"Terminating process due to timeout.\"\n    finally:\n        timer.cancel()\n\n# Test the function"}
{"task_id": "BigCodeBench/1105", "solution": "import subprocess\nimport os\nimport time\nimport glob\ndef task_func(r_script_path: str, output_path: str, duration: int) -> (bool, str):\n    start_time = time.time()\n    try:\n        # Execute the R script\n        subprocess.check_output(['Rscript', r_script_path])\n    except subprocess.CalledProcessError as e:\n        return (False, 'File not generated within the specified duration.')\n\n    # Wait for the specified duration\n    while time.time() - start_time < duration:\n        # Check if the output file exists\n        if glob.glob(output_path):\n            return (True, 'File generated successfully within the specified duration.')\n        # Sleep for a short duration to avoid busy waiting\n        time.sleep(0.1)\n\n    # If the output file is not generated within the specified duration\n    return (False, 'File not generated within the specified duration.')", "raw_solution": "import subprocess\nimport os\nimport time\nimport glob\n\ndef task_func(r_script_path: str, output_path: str, duration: int) -> (bool, str):\n    start_time = time.time()\n    try:\n        # Execute the R script\n        subprocess.check_output(['Rscript', r_script_path])\n    except subprocess.CalledProcessError as e:\n        return (False, 'File not generated within the specified duration.')\n\n    # Wait for the specified duration\n    while time.time() - start_time < duration:\n        # Check if the output file exists\n        if glob.glob(output_path):\n            return (True, 'File generated successfully within the specified duration.')\n        # Sleep for a short duration to avoid busy waiting\n        time.sleep(0.1)\n\n    # If the output file is not generated within the specified duration\n    return (False, 'File not generated within the specified duration.')\n\n# Test the function"}
{"task_id": "BigCodeBench/1106", "solution": "from datetime import datetime\nimport os\nfrom pathlib import Path\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(file_path):\n    # Get the creation time of the file\n    creation_time = os.path.getctime(file_path)\n    # Convert the creation time to a datetime object\n    creation_time_dt = datetime.fromtimestamp(creation_time)\n    # Format the datetime object to the desired string format\n    creation_time_str = creation_time_dt.strftime(DATE_FORMAT)\n    return creation_time_str\nfile_path = Path(__file__).resolve()", "raw_solution": "from datetime import datetime\nimport os\nfrom pathlib import Path\n\n# Constants\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(file_path):\n    # Get the creation time of the file\n    creation_time = os.path.getctime(file_path)\n    # Convert the creation time to a datetime object\n    creation_time_dt = datetime.fromtimestamp(creation_time)\n    # Format the datetime object to the desired string format\n    creation_time_str = creation_time_dt.strftime(DATE_FORMAT)\n    return creation_time_str\n\n# Test the function\nfile_path = Path(__file__).resolve()  # Use the path of the current script"}
{"task_id": "BigCodeBench/1107", "solution": "from datetime import datetime\nimport pytz\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(unix_timestamp, target_timezone):\n    # Convert Unix timestamp to datetime object\n    dt = datetime.utcfromtimestamp(unix_timestamp)\n\n    # Create a timezone object for the target timezone\n    tz = pytz.timezone(target_timezone)\n\n    # Localize the datetime object to the target timezone\n    dt = dt.replace(tzinfo=pytz.utc).astimezone(tz)\n\n    # Format the datetime object as a string\n    str_time = dt.strftime(DATE_FORMAT)\n\n    return str_time", "raw_solution": "from datetime import datetime\nimport pytz\n\n# Constants\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(unix_timestamp, target_timezone):\n    # Convert Unix timestamp to datetime object\n    dt = datetime.utcfromtimestamp(unix_timestamp)\n\n    # Create a timezone object for the target timezone\n    tz = pytz.timezone(target_timezone)\n\n    # Localize the datetime object to the target timezone\n    dt = dt.replace(tzinfo=pytz.utc).astimezone(tz)\n\n    # Format the datetime object as a string\n    str_time = dt.strftime(DATE_FORMAT)\n\n    return str_time\n\n# Test the function"}
{"task_id": "BigCodeBench/1108", "solution": "from collections import Counter\nimport re\ndef task_func(result):\n    url_values = [item['url'] for item in result if 'url' in item]\n    counter = Counter(url_values)\n    most_common_values = counter.most_common(1)\n    dict_most_common = {most_common_values[0][0]: most_common_values[0][1]}\n    return dict_most_common\nresult = [{'url': 'www.google.com', 'name': 'Google'}, {'url': 'www.google.com', 'name': 'Google'}, {'url': 'www.yahoo.com', 'name': 'Yahoo'}, {'name': 'Facebook'}, {'url': 'www.facebook.com', 'name': 'Facebook'}]", "raw_solution": "from collections import Counter\nimport re\n\ndef task_func(result):\n    url_values = [item['url'] for item in result if 'url' in item]\n    counter = Counter(url_values)\n    most_common_values = counter.most_common(1)\n    dict_most_common = {most_common_values[0][0]: most_common_values[0][1]}\n    return dict_most_common\n\n# Test the function\nresult = [{'url': 'www.google.com', 'name': 'Google'}, {'url': 'www.google.com', 'name': 'Google'}, {'url': 'www.yahoo.com', 'name': 'Yahoo'}, {'name': 'Facebook'}, {'url': 'www.facebook.com', 'name': 'Facebook'}]"}
{"task_id": "BigCodeBench/1109", "solution": "import os\nfrom nltk import word_tokenize\ndef task_func(file_path='File.txt'):\n    if not os.path.exists(file_path):\n        return \"File not found\"\n\n    with open(file_path, 'r') as file:\n        lines = file.readlines()\n\n    tokens = []\n    for line in lines:\n        tokens.extend(word_tokenize(line))\n\n    return tokens", "raw_solution": "import os\nfrom nltk import word_tokenize\n\ndef task_func(file_path='File.txt'):\n    if not os.path.exists(file_path):\n        return \"File not found\"\n\n    with open(file_path, 'r') as file:\n        lines = file.readlines()\n\n    tokens = []\n    for line in lines:\n        tokens.extend(word_tokenize(line))\n\n    return tokens\n\n# Test the function"}
{"task_id": "BigCodeBench/1110", "solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\ndef task_func(word_dict):\n    # Combine all words into one string\n    all_words = ''.join(word_dict.keys())\n\n    # Count the frequency of each letter\n    letter_counts = Counter(all_words)\n\n    # Filter out letters that are not in the values of the dictionary\n    letter_counts = {k: v for k, v in letter_counts.items() if k in word_dict.values()}\n\n    return letter_counts\nword_dict = {'hello': 'h', 'world': 'o', 'python': 't', 'programming': 'm'}", "raw_solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\n\ndef task_func(word_dict):\n    # Combine all words into one string\n    all_words = ''.join(word_dict.keys())\n\n    # Count the frequency of each letter\n    letter_counts = Counter(all_words)\n\n    # Filter out letters that are not in the values of the dictionary\n    letter_counts = {k: v for k, v in letter_counts.items() if k in word_dict.values()}\n\n    return letter_counts\n\n# Test the function\nword_dict = {'hello': 'h', 'world': 'o', 'python': 't', 'programming': 'm'}"}
{"task_id": "BigCodeBench/1111", "solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\nANIMAL = ['cat', 'camel', 'cow', 'dog', 'elephant', 'fox', 'giraffe', 'hippo', 'iguana', 'jaguar']\ndef task_func(animal_dict):\n    # Remove keys not in ANIMAL\n    animal_dict = {key: value for key, value in animal_dict.items() if key in ANIMAL}\n\n    # Flatten values and count frequencies\n    letter_counts = Counter(itertools.chain.from_iterable(animal_dict.values()))\n\n    # Sort by frequency in descending order\n    sorted_counts = sorted(letter_counts.items(), key=itemgetter(1), reverse=True)\n\n    # Convert back to dictionary\n    sorted_dict = {key: value for key, value in sorted_counts}\n\n    return sorted_dict\nanimal_dict = {'cat': 'meow', 'camel': 'hum', 'cow': 'moo', 'dog': 'bark', 'elephant': 'trumpet', 'fox': 'what', 'giraffe': 'hum', 'hippo': 'grunt', 'iguana': 'squawk', 'jaguar': 'roar', 'lion': 'roar'}", "raw_solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\n\n#CONSTANT\nANIMAL = ['cat', 'camel', 'cow', 'dog', 'elephant', 'fox', 'giraffe', 'hippo', 'iguana', 'jaguar']\n\ndef task_func(animal_dict):\n    # Remove keys not in ANIMAL\n    animal_dict = {key: value for key, value in animal_dict.items() if key in ANIMAL}\n\n    # Flatten values and count frequencies\n    letter_counts = Counter(itertools.chain.from_iterable(animal_dict.values()))\n\n    # Sort by frequency in descending order\n    sorted_counts = sorted(letter_counts.items(), key=itemgetter(1), reverse=True)\n\n    # Convert back to dictionary\n    sorted_dict = {key: value for key, value in sorted_counts}\n\n    return sorted_dict\n\n# Test the function\nanimal_dict = {'cat': 'meow', 'camel': 'hum', 'cow': 'moo', 'dog': 'bark', 'elephant': 'trumpet', 'fox': 'what', 'giraffe': 'hum', 'hippo': 'grunt', 'iguana': 'squawk', 'jaguar': 'roar', 'lion': 'roar'}"}
{"task_id": "BigCodeBench/1112", "solution": "import csv\nimport random\nfrom datetime import datetime, timedelta\nDATA = ['Temperature', 'Humidity', 'Pressure']\nRANGE = {\n    'Temperature': (-50, 50),\n    'Humidity': (0, 100),\n    'Pressure': (980, 1040)\n}\ndef task_func(file_name=\"data.csv\"):\n    # Generate data for each hour of the current day\n    data = [{\n        'Time': (datetime.now() + timedelta(hours=i)).strftime('%Y-%m-%d %H:00:00'),\n        'Temperature': random.randint(*RANGE['Temperature']),\n        'Humidity': random.randint(*RANGE['Humidity']),\n        'Pressure': random.randint(*RANGE['Pressure'])\n    } for i in range(24)]\n\n    # Write data to CSV file\n    with open(file_name, 'w', newline='') as file:\n        writer = csv.DictWriter(file, fieldnames=['Time'] + DATA)\n        writer.writeheader()\n        writer.writerows(data)\n\n    return file_name", "raw_solution": "import csv\nimport random\nfrom datetime import datetime, timedelta\n\n# Constants\nDATA = ['Temperature', 'Humidity', 'Pressure']\nRANGE = {\n    'Temperature': (-50, 50),\n    'Humidity': (0, 100),\n    'Pressure': (980, 1040)\n}\n\ndef task_func(file_name=\"data.csv\"):\n    # Generate data for each hour of the current day\n    data = [{\n        'Time': (datetime.now() + timedelta(hours=i)).strftime('%Y-%m-%d %H:00:00'),\n        'Temperature': random.randint(*RANGE['Temperature']),\n        'Humidity': random.randint(*RANGE['Humidity']),\n        'Pressure': random.randint(*RANGE['Pressure'])\n    } for i in range(24)]\n\n    # Write data to CSV file\n    with open(file_name, 'w', newline='') as file:\n        writer = csv.DictWriter(file, fieldnames=['Time'] + DATA)\n        writer.writeheader()\n        writer.writerows(data)\n\n    return file_name\n\n# Test the function"}
{"task_id": "BigCodeBench/1113", "solution": "import csv\nimport collections\ndef task_func(csv_file, emp_prefix='EMP$$'):\n    with open(csv_file, 'r') as file:\n        reader = csv.reader(file)\n        next(reader)  # Skip the header\n        emp_counts = collections.defaultdict(int)\n        for row in reader:\n            for cell in row:\n                if cell.startswith(emp_prefix):\n                    emp_counts[cell] += 1\n    return emp_counts\ncsv_file = 'test.csv'", "raw_solution": "import csv\nimport collections\n\ndef task_func(csv_file, emp_prefix='EMP$$'):\n    with open(csv_file, 'r') as file:\n        reader = csv.reader(file)\n        next(reader)  # Skip the header\n        emp_counts = collections.defaultdict(int)\n        for row in reader:\n            for cell in row:\n                if cell.startswith(emp_prefix):\n                    emp_counts[cell] += 1\n    return emp_counts\n\n# Test the function\ncsv_file = 'test.csv'"}
{"task_id": "BigCodeBench/1114", "solution": "from collections import defaultdict\nfrom random import randint\ndef task_func(dict1):\n    # Create a defaultdict to store the salaries by department\n    salaries_by_department = defaultdict(list)\n\n    # Iterate over the items in the input dictionary\n    for key, value in dict1.items():\n        # Check if the key starts with 'EMP$$'\n        if key.startswith('EMP$$'):\n            # Split the value into a list of salaries\n            salaries = list(map(int, value.split(',')))\n            # Add the salaries to the corresponding department in the defaultdict\n            salaries_by_department[key].extend(salaries)\n\n    return salaries_by_department", "raw_solution": "from collections import defaultdict\nfrom random import randint\n\ndef task_func(dict1):\n    # Create a defaultdict to store the salaries by department\n    salaries_by_department = defaultdict(list)\n\n    # Iterate over the items in the input dictionary\n    for key, value in dict1.items():\n        # Check if the key starts with 'EMP$$'\n        if key.startswith('EMP$$'):\n            # Split the value into a list of salaries\n            salaries = list(map(int, value.split(',')))\n            # Add the salaries to the corresponding department in the defaultdict\n            salaries_by_department[key].extend(salaries)\n\n    return salaries_by_department\n\n# Test the function\ntest_dict = {\n    'EMP$$1': '5000,6000,7000',\n    'EMP$$2': '8000,9000,10000',\n    'HR1': '5000,6000',\n    'HR2': '7000,8000',\n    'FINANCE1': '6000,7000',\n    'FINANCE2': '8000,9000'\n}\n"}
{"task_id": "BigCodeBench/1115", "solution": "import random\nfrom string import ascii_uppercase\ndef task_func(dict1):\n    unique_ids = []\n    for key in dict1.keys():\n        for i in range(dict1[key]):\n            random_string = ''.join(random.choice(ascii_uppercase) for _ in range(5))\n            unique_id = key + random_string\n            unique_ids.append(unique_id)\n    return unique_ids", "raw_solution": "import random\nfrom string import ascii_uppercase\n\ndef task_func(dict1):\n    unique_ids = []\n    for key in dict1.keys():\n        for i in range(dict1[key]):\n            random_string = ''.join(random.choice(ascii_uppercase) for _ in range(5))\n            unique_id = key + random_string\n            unique_ids.append(unique_id)\n    return unique_ids\n\n# Test the function\ndepartment_dict = {'IT': 3, 'HR': 2, 'Finance': 4}"}
{"task_id": "BigCodeBench/1116", "solution": "import random\nimport statistics\nfrom collections import Counter\ndef task_func(dict1):\n    # Filter employees in the department \"EMP$$\"\n    emp_age = [age for name, age in dict1.items() if name.startswith(\"EMP$$\")]\n\n    # Calculate mean\n    mean_age = statistics.mean(emp_age)\n\n    # Calculate median\n    median_age = statistics.median(emp_age)\n\n    # Calculate mode\n    mode_data = Counter(emp_age)\n    max_count = max(list(mode_data.values()))\n    mode_age = [age for age, count in mode_data.items() if count == max_count]\n\n    return (mean_age, median_age, mode_age)", "raw_solution": "import random\nimport statistics\nfrom collections import Counter\n\n# Constants\nAGE_RANGE = (22, 60)\n\ndef task_func(dict1):\n    # Filter employees in the department \"EMP$$\"\n    emp_age = [age for name, age in dict1.items() if name.startswith(\"EMP$$\")]\n\n    # Calculate mean\n    mean_age = statistics.mean(emp_age)\n\n    # Calculate median\n    median_age = statistics.median(emp_age)\n\n    # Calculate mode\n    mode_data = Counter(emp_age)\n    max_count = max(list(mode_data.values()))\n    mode_age = [age for age, count in mode_data.items() if count == max_count]\n\n    return (mean_age, median_age, mode_age)\n\n# Test the function\nemployees = {\"EMP$$John\": random.randint(22, 60), \"EMP$$Mike\": random.randint(22, 60), \n             \"EMP$$Sarah\": random.randint(22, 60), \"EMP$$Lisa\": random.randint(22, 60), \n             \"EMP$$Tom\": random.randint(22, 60), \"Mark\": random.randint(22, 60), \n             \"Eva\": random.randint(22, 60)}\n"}
{"task_id": "BigCodeBench/1117", "solution": "import collections\nimport random\nimport json\nLEVELS = ['Junior', 'Mid', 'Senior']\ndef task_func(department_data):\n    # Create a dictionary with department codes as keys and lists of employee levels as values\n    department_dict = {dept: random.choices(LEVELS, k=count) for dept, count in department_data.items()}\n\n    # Convert the dictionary to a JSON object\n    json_object = json.dumps(department_dict, indent=4)\n\n    return json_object\ndepartment_data = {'EMP$$': 3, 'MAN$$': 2, 'DEV$$': 4, 'HR$$': 5}", "raw_solution": "import collections\nimport random\nimport json\n\n# Constants\nPREFICES = ['EMP$$', 'MAN$$', 'DEV$$', 'HR$$']\nLEVELS = ['Junior', 'Mid', 'Senior']\n\ndef task_func(department_data):\n    # Create a dictionary with department codes as keys and lists of employee levels as values\n    department_dict = {dept: random.choices(LEVELS, k=count) for dept, count in department_data.items()}\n\n    # Convert the dictionary to a JSON object\n    json_object = json.dumps(department_dict, indent=4)\n\n    return json_object\n\n# Test the function\ndepartment_data = {'EMP$$': 3, 'MAN$$': 2, 'DEV$$': 4, 'HR$$': 5}"}
{"task_id": "BigCodeBench/1118", "solution": "import json\nimport csv\nimport requests\nfrom io import StringIO\nCSV_URL = 'https://example.com/data.csv'\nJSON_FILE = 'data.json'\ndef task_func(csv_url=CSV_URL, json_file_path=JSON_FILE):\n    # Download CSV file\n    csv_data = requests.get(csv_url)\n\n    # Read CSV data\n    csv_reader = csv.DictReader(StringIO(csv_data.text))\n    csv_data_list = [row for row in csv_reader]\n\n    # Convert CSV data to JSON\n    json_data = json.dumps(csv_data_list, indent=4)\n\n    # Save JSON data to file\n    with open(json_file_path, 'w') as json_file:\n        json_file.write(json_data)\n\n    return json_file_path", "raw_solution": "import json\nimport csv\nimport requests\nfrom io import StringIO\n\n# Constants\nCSV_URL = 'https://example.com/data.csv'\nJSON_FILE = 'data.json'\n\ndef task_func(csv_url=CSV_URL, json_file_path=JSON_FILE):\n    # Download CSV file\n    csv_data = requests.get(csv_url)\n\n    # Read CSV data\n    csv_reader = csv.DictReader(StringIO(csv_data.text))\n    csv_data_list = [row for row in csv_reader]\n\n    # Convert CSV data to JSON\n    json_data = json.dumps(csv_data_list, indent=4)\n\n    # Save JSON data to file\n    with open(json_file_path, 'w') as json_file:\n        json_file.write(json_data)\n\n    return json_file_path\n\n# Test the function"}
{"task_id": "BigCodeBench/1119", "solution": "import codecs\nimport random\nimport string\nimport hashlib\ndef task_func(password_length=10, salt=\"salty\"):\n    # Generate a random password\n    password = ''.join(random.choice(string.ascii_letters + string.digits + string.punctuation) for _ in range(password_length))\n\n    # Mix the password with the salt\n    salted_password = password + salt\n\n    # Hash the salted password using SHA256\n    hashed_password = hashlib.sha256(salted_password.encode()).hexdigest()\n\n    return hashed_password", "raw_solution": "import codecs\nimport random\nimport string\nimport hashlib\n\ndef task_func(password_length=10, salt=\"salty\"):\n    # Generate a random password\n    password = ''.join(random.choice(string.ascii_letters + string.digits + string.punctuation) for _ in range(password_length))\n\n    # Mix the password with the salt\n    salted_password = password + salt\n\n    # Hash the salted password using SHA256\n    hashed_password = hashlib.sha256(salted_password.encode()).hexdigest()\n\n    return hashed_password\n\n# Test the function"}
{"task_id": "BigCodeBench/1120", "solution": "import re\nimport urllib.parse\nimport requests\nimport json\ndef task_func(myString, API_KEY):\n    # Regular expression to match URLs\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    # Find all URLs in the string\n    urls = re.findall(url_pattern, myString)\n\n    # Initialize an empty dictionary to store the results\n    results = {}\n\n    # For each URL, extract the domain and make a request to the IP API\n    for url in urls:\n        domain = urllib.parse.urlparse(url).netloc\n        response = requests.get(f'https://ipapi.co/{domain}/json/')\n        # Check if the request was successful\n        if response.status_code == 200:\n            data = response.json()\n            # If the API key is valid, the 'country' field will be present\n            if 'country' in data:\n                results[domain] = data\n            else:\n                results[domain] = None\n        else:\n            results[domain] = None\n\n    return results", "raw_solution": "import re\nimport urllib.parse\nimport requests\nimport json\n\ndef task_func(myString, API_KEY):\n    # Regular expression to match URLs\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    # Find all URLs in the string\n    urls = re.findall(url_pattern, myString)\n\n    # Initialize an empty dictionary to store the results\n    results = {}\n\n    # For each URL, extract the domain and make a request to the IP API\n    for url in urls:\n        domain = urllib.parse.urlparse(url).netloc\n        response = requests.get(f'https://ipapi.co/{domain}/json/')\n        # Check if the request was successful\n        if response.status_code == 200:\n            data = response.json()\n            # If the API key is valid, the 'country' field will be present\n            if 'country' in data:\n                results[domain] = data\n            else:\n                results[domain] = None\n        else:\n            results[domain] = None\n\n    return results"}
{"task_id": "BigCodeBench/1121", "solution": "import re\nimport urllib.parse\nimport requests\nimport json\ndef task_func(myString, API_KEY):\n    # Regular expression to match URLs\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    # Find all URLs in the string\n    urls = re.findall(url_pattern, myString)\n\n    # Initialize an empty dictionary to store the results\n    results = {}\n\n    # For each URL, extract the domain and make a request to the IP API\n    for url in urls:\n        domain = urllib.parse.urlparse(url).netloc\n        response = requests.get(f'https://ipapi.co/{domain}/json/')\n        # Check if the request was successful\n        if response.status_code == 200:\n            data = response.json()\n            # If the API key is valid, the 'country' field will be present\n            if 'country' in data:\n                results[domain] = data\n            else:\n                results[domain] = None\n        else:\n            results[domain] = None\n\n    return results", "raw_solution": "import re\nimport urllib.parse\nimport requests\nimport json\n\ndef task_func(myString, API_KEY):\n    # Regular expression to match URLs\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    # Find all URLs in the string\n    urls = re.findall(url_pattern, myString)\n\n    # Initialize an empty dictionary to store the results\n    results = {}\n\n    # For each URL, extract the domain and make a request to the IP API\n    for url in urls:\n        domain = urllib.parse.urlparse(url).netloc\n        response = requests.get(f'https://ipapi.co/{domain}/json/')\n        # Check if the request was successful\n        if response.status_code == 200:\n            data = response.json()\n            # If the API key is valid, the 'country' field will be present\n            if 'country' in data:\n                results[domain] = data\n            else:\n                results[domain] = None\n        else:\n            results[domain] = None\n\n    return results"}
{"task_id": "BigCodeBench/1122", "solution": "import re\nimport socket\nimport urllib.parse\ndef task_func(myString):\n    # Regular expression to find URLs\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    # Find all URLs in the string\n    urls = re.findall(url_pattern, myString)\n\n    # Dictionary to store domain and IP address\n    domain_ip_dict = {}\n\n    for url in urls:\n        # Extract domain from URL\n        domain = urllib.parse.urlparse(url).netloc\n\n        try:\n            # Get IP address of domain\n            ip = socket.gethostbyname(domain)\n        except socket.gaierror:\n            # If domain cannot be resolved, set IP address to None\n            ip = None\n\n        # Add domain and IP address to dictionary\n        domain_ip_dict[domain] = ip\n\n    return domain_ip_dict", "raw_solution": "import re\nimport socket\nimport urllib.parse\n\ndef task_func(myString):\n    # Regular expression to find URLs\n    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    # Find all URLs in the string\n    urls = re.findall(url_pattern, myString)\n\n    # Dictionary to store domain and IP address\n    domain_ip_dict = {}\n\n    for url in urls:\n        # Extract domain from URL\n        domain = urllib.parse.urlparse(url).netloc\n\n        try:\n            # Get IP address of domain\n            ip = socket.gethostbyname(domain)\n        except socket.gaierror:\n            # If domain cannot be resolved, set IP address to None\n            ip = None\n\n        # Add domain and IP address to dictionary\n        domain_ip_dict[domain] = ip\n\n    return domain_ip_dict"}
{"task_id": "BigCodeBench/1123", "solution": "import re\nimport urllib.parse\nimport ssl\nimport socket\ndef task_func(myString):\n    # Regular expression to match https URLs\n    url_pattern = re.compile(r'https://[^\\s]+')\n    # Extract all https URLs\n    urls = url_pattern.findall(myString)\n\n    ssl_info = {}\n\n    for url in urls:\n        try:\n            # Parse the URL to get the domain\n            domain = urllib.parse.urlparse(url).netloc\n\n            # Create a context for SSL verification\n            context = ssl.create_default_context()\n\n            # Get the SSL certificate\n            with socket.create_connection((domain, 443)) as sock:\n                with context.wrap_socket(sock, server_hostname=domain) as ssock:\n                    print(ssock.getpeercert())\n                    # Get the certificate expiry date\n                    cert_expiry = ssock.getpeercert()['notAfter']\n\n                    # Add the domain and its SSL certificate expiry date to the dictionary\n                    ssl_info[domain] = cert_expiry\n        except:\n            # Ignore any URLs that cause an SSL error\n            continue\n\n    return ssl_info", "raw_solution": "import re\nimport urllib.parse\nimport ssl\nimport socket\n\ndef task_func(myString):\n    # Regular expression to match https URLs\n    url_pattern = re.compile(r'https://[^\\s]+')\n    # Extract all https URLs\n    urls = url_pattern.findall(myString)\n\n    ssl_info = {}\n\n    for url in urls:\n        try:\n            # Parse the URL to get the domain\n            domain = urllib.parse.urlparse(url).netloc\n\n            # Create a context for SSL verification\n            context = ssl.create_default_context()\n\n            # Get the SSL certificate\n            with socket.create_connection((domain, 443)) as sock:\n                with context.wrap_socket(sock, server_hostname=domain) as ssock:\n                    print(ssock.getpeercert())\n                    # Get the certificate expiry date\n                    cert_expiry = ssock.getpeercert()['notAfter']\n\n                    # Add the domain and its SSL certificate expiry date to the dictionary\n                    ssl_info[domain] = cert_expiry\n        except:\n            # Ignore any URLs that cause an SSL error\n            continue\n\n    return ssl_info"}
{"task_id": "BigCodeBench/1124", "solution": "import re\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nimport requests\ndef task_func(myString):\n    # Extract URL from string\n    url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n\n    if not url:\n        return \"No valid URL found in the provided string.\"\n\n    url = url[0]\n\n    # Fetch the content of the URL\n    try:\n        response = requests.get(url)\n    except requests.exceptions.RequestException as e:\n        return f\"Unable to fetch the content of the URL: {url}\"\n\n    # If the fetch is successful, parse the content to find the title\n    soup = BeautifulSoup(response.text, 'html.parser')\n    title = soup.find('title')\n\n    if title is None:\n        return \"No title tag found in the webpage.\"\n\n    return title.text", "raw_solution": "import re\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nimport requests\n\ndef task_func(myString):\n    # Extract URL from string\n    url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n\n    if not url:\n        return \"No valid URL found in the provided string.\"\n\n    url = url[0]\n\n    # Fetch the content of the URL\n    try:\n        response = requests.get(url)\n    except requests.exceptions.RequestException as e:\n        return f\"Unable to fetch the content of the URL: {url}\"\n\n    # If the fetch is successful, parse the content to find the title\n    soup = BeautifulSoup(response.text, 'html.parser')\n    title = soup.find('title')\n\n    if title is None:\n        return \"No title tag found in the webpage.\"\n\n    return title.text"}
{"task_id": "BigCodeBench/1125", "solution": "import re\nimport json\nimport requests\ndef task_func(myString, token):\n    # Extract URL from string\n    url = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    url = url[0] if url else None\n\n    if url:\n        # Prepare headers\n        headers = {\n            'Authorization': 'Bearer ' + token,\n            'Content-Type': 'application/json'\n        }\n\n        # Prepare payload\n        payload = {\n            'url': url\n        }\n\n        # Send POST request\n        response = requests.post('http://example.com/api', headers=headers, data=json.dumps(payload))\n\n        # Return response as dictionary\n        return response.json()\n    else:\n        return \"No URL found in the string\"", "raw_solution": "import re\nimport json\nimport requests\n\ndef task_func(myString, token):\n    # Extract URL from string\n    url = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    url = url[0] if url else None\n\n    if url:\n        # Prepare headers\n        headers = {\n            'Authorization': 'Bearer ' + token,\n            'Content-Type': 'application/json'\n        }\n\n        # Prepare payload\n        payload = {\n            'url': url\n        }\n\n        # Send POST request\n        response = requests.post('http://example.com/api', headers=headers, data=json.dumps(payload))\n\n        # Return response as dictionary\n        return response.json()\n    else:\n        return \"No URL found in the string\"\n\n# Test the function"}
{"task_id": "BigCodeBench/1126", "solution": "import re\nimport hashlib\ndef task_func(input_str):\n    # Remove all special characters, punctuation marks, and spaces from the input string\n    cleaned_str = re.sub(r'[^A-Za-z0-9]', '', input_str)\n\n    # Hash the cleaned string with SHA256\n    hash_object = hashlib.sha256(cleaned_str.encode())\n    hex_dig = hash_object.hexdigest()\n\n    return hex_dig", "raw_solution": "import re\nimport hashlib\n\ndef task_func(input_str):\n    # Remove all special characters, punctuation marks, and spaces from the input string\n    cleaned_str = re.sub(r'[^A-Za-z0-9]', '', input_str)\n\n    # Hash the cleaned string with SHA256\n    hash_object = hashlib.sha256(cleaned_str.encode())\n    hex_dig = hash_object.hexdigest()\n\n    return hex_dig\n\n# Test the function"}
{"task_id": "BigCodeBench/1127", "solution": "import os\nimport re\nimport hashlib\ndef task_func(path, delimiter):\n    # Split the path by the delimiter\n    components = re.split(delimiter, path)\n\n    # Initialize an empty list to store the tuples\n    result = []\n\n    # Iterate over each component\n    for component in components:\n        # If the component is a file, compute its hash\n        if os.path.isfile(component):\n            with open(component, 'rb') as file:\n                file_hash = hashlib.sha256()\n                chunk = file.read(8192)\n                while chunk:\n                    file_hash.update(chunk)\n                    chunk = file.read(8192)\n                result.append((component, file_hash.hexdigest()))\n        # If the component is not a file, append None to the hash\n        else:\n            result.append((component, None))\n\n    return result", "raw_solution": "import os\nimport re\nimport hashlib\n\ndef task_func(path, delimiter):\n    # Split the path by the delimiter\n    components = re.split(delimiter, path)\n\n    # Initialize an empty list to store the tuples\n    result = []\n\n    # Iterate over each component\n    for component in components:\n        # If the component is a file, compute its hash\n        if os.path.isfile(component):\n            with open(component, 'rb') as file:\n                file_hash = hashlib.sha256()\n                chunk = file.read(8192)\n                while chunk:\n                    file_hash.update(chunk)\n                    chunk = file.read(8192)\n                result.append((component, file_hash.hexdigest()))\n        # If the component is not a file, append None to the hash\n        else:\n            result.append((component, None))\n\n    return result\n\n# Test the function"}
{"task_id": "BigCodeBench/1128", "solution": "import json\nimport os\nimport hashlib\nimport base64\nimport time\ndef task_func(file_path, unknown_key):\n    # Read JSON file\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n\n    # Extract value from nested structure\n    value = data['A'][unknown_key]['maindata'][0]['Info']\n\n    # Hash the value\n    hash_obj = hashlib.sha256(value.encode())\n    hashed_value = hash_obj.hexdigest()\n\n    # Encode the hash to base64\n    base64_encoded_hash = base64.b64encode(hashed_value.encode()).decode()\n\n    # Create a new file with a timestamp in its name\n    timestamp = str(time.time()).replace('.', '')\n    new_file_path = os.path.join(os.getcwd(), f'hash_{timestamp}.txt')\n    with open(new_file_path, 'w') as f:\n        f.write(base64_encoded_hash)\n\n    return new_file_path", "raw_solution": "import json\nimport os\nimport hashlib\nimport base64\nimport time\n\ndef task_func(file_path, unknown_key):\n    # Read JSON file\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n\n    # Extract value from nested structure\n    value = data['A'][unknown_key]['maindata'][0]['Info']\n\n    # Hash the value\n    hash_obj = hashlib.sha256(value.encode())\n    hashed_value = hash_obj.hexdigest()\n\n    # Encode the hash to base64\n    base64_encoded_hash = base64.b64encode(hashed_value.encode()).decode()\n\n    # Create a new file with a timestamp in its name\n    timestamp = str(time.time()).replace('.', '')\n    new_file_path = os.path.join(os.getcwd(), f'hash_{timestamp}.txt')\n    with open(new_file_path, 'w') as f:\n        f.write(base64_encoded_hash)\n\n    return new_file_path"}
{"task_id": "BigCodeBench/1129", "solution": "import json\nimport requests\nimport os\nfrom datetime import datetime\ndef task_func(json_data, unknown_key, save_dir=None):\n    data = json.loads(json_data)\n    url = data[unknown_key]\n\n    if save_dir is None:\n        save_dir = os.getcwd()\n\n    response = requests.get(url)\n    filename = f\"{unknown_key}_{datetime.now().strftime('%Y%m%d%H%M%S%f')}.txt\"\n    filepath = os.path.join(save_dir, filename)\n\n    with open(filepath, 'wb') as f:\n        f.write(response.content)\n\n    return os.path.abspath(filepath)", "raw_solution": "import json\nimport requests\nimport os\nfrom datetime import datetime\n\ndef task_func(json_data, unknown_key, save_dir=None):\n    data = json.loads(json_data)\n    url = data[unknown_key]\n\n    if save_dir is None:\n        save_dir = os.getcwd()\n\n    response = requests.get(url)\n    filename = f\"{unknown_key}_{datetime.now().strftime('%Y%m%d%H%M%S%f')}.txt\"\n    filepath = os.path.join(save_dir, filename)\n\n    with open(filepath, 'wb') as f:\n        f.write(response.content)\n\n    return os.path.abspath(filepath)"}
{"task_id": "BigCodeBench/1130", "solution": "import os\nimport hashlib\nimport json\nfrom pathlib import Path\ndef task_func(directory: str) -> str:\n    hashes = {}\n    for foldername, subfolders, filenames in os.walk(directory):\n        for filename in filenames:\n            file_path = os.path.join(foldername, filename)\n            with open(file_path, 'rb') as f:\n                file_hash = hashlib.sha256()\n                while chunk := f.read(8192):\n                    file_hash.update(chunk)\n            hashes[file_path] = file_hash.hexdigest()\n\n    json_file_path = os.path.join(directory, 'hashes.json')\n    with open(json_file_path, 'w') as f:\n        json.dump(hashes, f)\n\n    return json_file_path", "raw_solution": "import os\nimport hashlib\nimport json\nfrom pathlib import Path\n\ndef task_func(directory: str) -> str:\n    hashes = {}\n    for foldername, subfolders, filenames in os.walk(directory):\n        for filename in filenames:\n            file_path = os.path.join(foldername, filename)\n            with open(file_path, 'rb') as f:\n                file_hash = hashlib.sha256()\n                while chunk := f.read(8192):\n                    file_hash.update(chunk)\n            hashes[file_path] = file_hash.hexdigest()\n\n    json_file_path = os.path.join(directory, 'hashes.json')\n    with open(json_file_path, 'w') as f:\n        json.dump(hashes, f)\n\n    return json_file_path"}
{"task_id": "BigCodeBench/1131", "solution": "import hashlib\nimport binascii\nimport sqlite3\ndef task_func(salt, cursor):\n    if not isinstance(salt, str):\n        raise TypeError(\"Salt must be a string\")\n\n    # Assuming the user table has columns 'username' and 'password'\n    cursor.execute(\"SELECT username, password FROM user\")\n    users = cursor.fetchall()\n\n    count = 0\n    for user in users:\n        username, password = user\n        hashed_password = hashlib.sha256(salt.encode() + password.encode()).hexdigest()\n        cursor.execute(\"UPDATE user SET password = ? WHERE username = ?\", (hashed_password, username))\n        count += 1\n\n    return count", "raw_solution": "import hashlib\nimport binascii\nimport sqlite3\n\ndef task_func(salt, cursor):\n    if not isinstance(salt, str):\n        raise TypeError(\"Salt must be a string\")\n\n    # Assuming the user table has columns 'username' and 'password'\n    cursor.execute(\"SELECT username, password FROM user\")\n    users = cursor.fetchall()\n\n    count = 0\n    for user in users:\n        username, password = user\n        hashed_password = hashlib.sha256(salt.encode() + password.encode()).hexdigest()\n        cursor.execute(\"UPDATE user SET password = ? WHERE username = ?\", (hashed_password, username))\n        count += 1\n\n    return count"}
{"task_id": "BigCodeBench/1132", "solution": "import os\nimport hashlib\nimport base64\ndef task_func(password, PREFIX=\"ME\", SALT_LENGTH=16):\n    if SALT_LENGTH < 0:\n        raise ValueError(\"SALT_LENGTH cannot be negative\")\n    salt = os.urandom(SALT_LENGTH)\n    salted_password = password + PREFIX + salt.hex()\n    hashed_password = hashlib.sha256(salted_password.encode())\n    encoded_password = base64.b64encode(hashed_password.digest())\n    return encoded_password.decode()", "raw_solution": "import os\nimport hashlib\nimport base64\n\ndef task_func(password, PREFIX=\"ME\", SALT_LENGTH=16):\n    if SALT_LENGTH < 0:\n        raise ValueError(\"SALT_LENGTH cannot be negative\")\n    salt = os.urandom(SALT_LENGTH)\n    salted_password = password + PREFIX + salt.hex()\n    hashed_password = hashlib.sha256(salted_password.encode())\n    encoded_password = base64.b64encode(hashed_password.digest())\n    return encoded_password.decode()\n\n# Test the function"}
{"task_id": "BigCodeBench/1133", "solution": "import json\nimport requests\ndef task_func(API_URL, endpoint, PREFIX):\n    try:\n        response = requests.get(API_URL + endpoint)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise RuntimeError(f\"Error fetching data from the API: {str(e)}\")\n\n    data = response.json()\n\n    filename = f\"{PREFIX}_{endpoint}.json\"\n    try:\n        with open(filename, 'w') as file:\n            json.dump(data, file)\n    except IOError as e:\n        raise RuntimeError(f\"Error writing to the file: {str(e)}\")\n\n    return filename", "raw_solution": "import json\nimport requests\n\ndef task_func(API_URL, endpoint, PREFIX):\n    try:\n        response = requests.get(API_URL + endpoint)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise RuntimeError(f\"Error fetching data from the API: {str(e)}\")\n\n    data = response.json()\n\n    filename = f\"{PREFIX}_{endpoint}.json\"\n    try:\n        with open(filename, 'w') as file:\n            json.dump(data, file)\n    except IOError as e:\n        raise RuntimeError(f\"Error writing to the file: {str(e)}\")\n\n    return filename"}
{"task_id": "BigCodeBench/1134", "solution": "import os\nimport glob\nimport hashlib\ndef task_func(source_dir, target_dir, prefix='#Hash: '):\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    file_paths = glob.glob(os.path.join(source_dir, '*'))\n\n    new_file_paths = []\n    for file_path in file_paths:\n        with open(file_path, 'rb') as f:\n            content = f.read()\n            md5_hash = hashlib.md5(content).hexdigest()\n            new_content = prefix + md5_hash + '\\n' + content.decode('utf-8')\n\n            new_file_path = os.path.join(target_dir, os.path.basename(file_path))\n            with open(new_file_path, 'w') as new_f:\n                new_f.write(new_content)\n\n            new_file_paths.append(new_file_path)\n\n    return new_file_paths", "raw_solution": "import os\nimport glob\nimport hashlib\n\ndef task_func(source_dir, target_dir, prefix='#Hash: '):\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    file_paths = glob.glob(os.path.join(source_dir, '*'))\n\n    new_file_paths = []\n    for file_path in file_paths:\n        with open(file_path, 'rb') as f:\n            content = f.read()\n            md5_hash = hashlib.md5(content).hexdigest()\n            new_content = prefix + md5_hash + '\\n' + content.decode('utf-8')\n\n            new_file_path = os.path.join(target_dir, os.path.basename(file_path))\n            with open(new_file_path, 'w') as new_f:\n                new_f.write(new_content)\n\n            new_file_paths.append(new_file_path)\n\n    return new_file_paths"}
{"task_id": "BigCodeBench/1135", "solution": "import requests\nimport collections\ndef task_func(user, API_URL = 'https://api.github.com/users/'):\n    response = requests.get(API_URL + user + '/repos')\n    data = response.json()\n\n    if response.status_code != 200:\n        return \"Error: User not found\"\n\n    repo_data = collections.defaultdict(list)\n\n    for repo in data:\n        repo_data[repo['name']] = repo['created_at']\n\n    sorted_repos = sorted(repo_data.items(), key=lambda x:x[1])\n\n    return [repo[0] for repo in sorted_repos]", "raw_solution": "import requests\nimport collections\n\ndef task_func(user, API_URL = 'https://api.github.com/users/'):\n    response = requests.get(API_URL + user + '/repos')\n    data = response.json()\n\n    if response.status_code != 200:\n        return \"Error: User not found\"\n\n    repo_data = collections.defaultdict(list)\n\n    for repo in data:\n        repo_data[repo['name']] = repo['created_at']\n\n    sorted_repos = sorted(repo_data.items(), key=lambda x:x[1])\n\n    return [repo[0] for repo in sorted_repos]\n\n# Test the function"}
{"task_id": "BigCodeBench/1136", "solution": "import bs4\nimport requests\nimport re\nimport csv\ndef task_func(url=\"http://example.com\", csv_path=\"emails.csv\", \n          regex=r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b\", \n          headers={'User-Agent': 'Mozilla/5.0'}):\n    \n    # Send a GET request to the URL\n    response = requests.get(url, headers=headers)\n\n    # Parse the content of the response with BeautifulSoup\n    soup = bs4.BeautifulSoup(response.content, 'html.parser')\n\n    # Find all text in the BeautifulSoup object\n    text = soup.get_text()\n\n    # Use the regular expression to find all email addresses in the text\n    emails = re.findall(regex, text)\n\n    # Write the emails to a CSV file\n    with open(csv_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Emails\"])\n        for email in emails:\n            writer.writerow([email])\n\n    return csv_path", "raw_solution": "import bs4\nimport requests\nimport re\nimport csv\n\ndef task_func(url=\"http://example.com\", csv_path=\"emails.csv\", \n          regex=r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b\", \n          headers={'User-Agent': 'Mozilla/5.0'}):\n    \n    # Send a GET request to the URL\n    response = requests.get(url, headers=headers)\n\n    # Parse the content of the response with BeautifulSoup\n    soup = bs4.BeautifulSoup(response.content, 'html.parser')\n\n    # Find all text in the BeautifulSoup object\n    text = soup.get_text()\n\n    # Use the regular expression to find all email addresses in the text\n    emails = re.findall(regex, text)\n\n    # Write the emails to a CSV file\n    with open(csv_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Emails\"])\n        for email in emails:\n            writer.writerow([email])\n\n    return csv_path"}
{"task_id": "BigCodeBench/1137", "solution": "import bs4\nimport requests\nimport re\nimport json\ndef task_func(url: str, output_path: str) -> list:\n    # Regular expression pattern for phone numbers\n    phone_pattern = re.compile(r'\\(?\\b\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b')\n\n    # If url starts with 'http', fetch the content, otherwise treat it as a local file\n    if url.startswith('http'):\n        response = requests.get(url)\n        content = bs4.BeautifulSoup(response.text, 'html.parser')\n    else:\n        with open(url, 'r') as file:\n            content = bs4.BeautifulSoup(file.read(), 'html.parser')\n\n    # Find all phone numbers in the content\n    phone_numbers = re.findall(phone_pattern, str(content))\n\n    # Save the phone numbers to the output file in JSON format\n    with open(output_path, 'w') as file:\n        json.dump(phone_numbers, file)\n\n    return phone_numbers", "raw_solution": "import bs4\nimport requests\nimport re\nimport json\n\ndef task_func(url: str, output_path: str) -> list:\n    # Regular expression pattern for phone numbers\n    phone_pattern = re.compile(r'\\(?\\b\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b')\n\n    # If url starts with 'http', fetch the content, otherwise treat it as a local file\n    if url.startswith('http'):\n        response = requests.get(url)\n        content = bs4.BeautifulSoup(response.text, 'html.parser')\n    else:\n        with open(url, 'r') as file:\n            content = bs4.BeautifulSoup(file.read(), 'html.parser')\n\n    # Find all phone numbers in the content\n    phone_numbers = re.findall(phone_pattern, str(content))\n\n    # Save the phone numbers to the output file in JSON format\n    with open(output_path, 'w') as file:\n        json.dump(phone_numbers, file)\n\n    return phone_numbers"}
{"task_id": "BigCodeBench/1138", "solution": "import numpy as np\nimport itertools\ndef task_func(matrix):\n    # Flatten the 2D array and sort it\n    flat_array = np.sort(matrix.flatten())\n\n    # Generate all unique combinations of two elements\n    combinations = list(itertools.combinations(flat_array, 2))\n\n    return flat_array, combinations\nmatrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])", "raw_solution": "import numpy as np\nimport itertools\n\ndef task_func(matrix):\n    # Flatten the 2D array and sort it\n    flat_array = np.sort(matrix.flatten())\n\n    # Generate all unique combinations of two elements\n    combinations = list(itertools.combinations(flat_array, 2))\n\n    return flat_array, combinations\n\n# Test the function\nmatrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nsorted_array, combinations = task_func(matrix)\n"}
{"task_id": "BigCodeBench/1139", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\ndef task_func(data):\n    # Split the data into train and test sets\n    X = data.iloc[:, :-1].values\n    y = data.iloc[:, 1].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Train the linear regression model\n    regressor = LinearRegression()\n    regressor.fit(X_train, y_train)\n\n    # Predict the scores\n    y_pred = regressor.predict(X_test)\n\n    # Calculate and return the mean squared error\n    mse = mean_squared_error(y_test, y_pred)\n    return mse\ndata = pd.DataFrame({\n    'Hours': [2.5, 5.1, 3.2, 8.5, 3.5, 1.5, 9.2, 5.5, 8.3, 2.7, 7.7, 5.9, 4.5, 3.3, 1.1, 8.9, 2.5, 1.9, 6.1, 7.4, 2.7, 4.8, 3.8, 6.9, 7.8],\n    'Scores': [21, 47, 27, 75, 30, 20, 88, 60, 81, 25, 85, 62, 41, 42, 17, 95, 30, 24, 67, 69, 30, 54, 35, 76, 86]\n})", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\ndef task_func(data):\n    # Split the data into train and test sets\n    X = data.iloc[:, :-1].values\n    y = data.iloc[:, 1].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Train the linear regression model\n    regressor = LinearRegression()\n    regressor.fit(X_train, y_train)\n\n    # Predict the scores\n    y_pred = regressor.predict(X_test)\n\n    # Calculate and return the mean squared error\n    mse = mean_squared_error(y_test, y_pred)\n    return mse\n\n# Test the function\ndata = pd.DataFrame({\n    'Hours': [2.5, 5.1, 3.2, 8.5, 3.5, 1.5, 9.2, 5.5, 8.3, 2.7, 7.7, 5.9, 4.5, 3.3, 1.1, 8.9, 2.5, 1.9, 6.1, 7.4, 2.7, 4.8, 3.8, 6.9, 7.8],\n    'Scores': [21, 47, 27, 75, 30, 20, 88, 60, 81, 25, 85, 62, 41, 42, 17, 95, 30, 24, 67, 69, 30, 54, 35, 76, 86]\n})"}
